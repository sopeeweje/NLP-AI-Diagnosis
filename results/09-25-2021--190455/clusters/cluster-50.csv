text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9610628,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Infrastructure', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multi-task learning', 'multitask', 'new technology', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2019,224899,0.025666829030835822
"Deep learning methods to predict the function of genetic variants in orofacial clefts Project Summary  Orofacial clefts (OFCs) comprise a significant fraction of human birth defects in all populations (ranging between 1/500 to 1/2500 live births) and represent a major public health challenge. Individuals born with OFCs require surgical, nutritional, dental, speech, medical and behavioral interventions, imposing a substantial economic and personal burden. There has been convincing evidence that non-syndromic OFCs represent human complex disorders with a multifactorial etiology including genetic risk factors, environmental exposures, and their complex interactions. So far, there have been ~10 genome-wide association studies (GWAS) conducted for non-syndromic CL/P (NSCL/P) and >15 genomic loci reported with compelling statistical support, including genes such as IRF6, PAX7, and ABCA4 and the 8q24 locus. In addition, next-generation sequencing (NGS) as well as exome array have been conducted with extra depth of genotyping that enable detection of rare variants associated with OFCs. However, gaps exist in how to interpret these variants and how to identify novel variants from the large volume of data, with high expectations for new methods and new models for “second- analysis” of the genome-wide data. In this proposal, we propose two complementary aims to carry out deep and second-analysis of genome-wide data for OFCs. In Aim 1, we propose a deep learning method to build in silico models that can predict the effect of genetic variants in the context of rich craniofacial epigenomic features. With substantial fine map of sequence patterns, ad hoc motifs will be revealed and variants that disturb these motifs will provide mechanistic insights on OFCs. In Aim 2, we shift our focus to the gene level and propose a network assisted method to discover sensibly combined genes in spatial and temporal points that are critical to orofacial development. We target on all forms of OFCs, with particular interest in NSCL/P. To guarantee the success of this proposal, we form a multi-disciplinary team and local computational infrastructure equipped with GPUs for the implementation of both aims. Our aims are non-overlapping; rather, they are integrated and strongly focused on our fundamental question of interest: how genetic variants function to cause OFCs. The successful completion of our proposal will lead to deep understanding of genetic components in OFCs. Project Narrative Orofacial clefts (OFCs) comprise a significant fraction of human birth defects in all populations and represent a major public health challenge. Substantial progress has been made to identify genes and variants for OFCs through recent genome-wide association studies and next- generation sequencing projects. In this proposal, we aim to develop computational methods to comprehensively fine map and interpret the effects of these genetics variants, which will eventually lead to understanding of the mechanisms and new therapies for OFCs.",Deep learning methods to predict the function of genetic variants in orofacial clefts,9764346,R03DE027711,"['8q24', 'Algorithms', 'Behavior Therapy', 'Binding Sites', 'Biological Process', 'Cleft Lip', 'Cleft lip with or without cleft palate', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Congenital Abnormality', 'Consensus', 'DNA', 'DNA Methylation', 'Data', 'Dental', 'Detection', 'Development', 'Disease', 'Economics', 'Environment', 'Environmental Exposure', 'Etiology', 'Explosion', 'Expression Profiling', 'FaceBase', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Human', 'Human Genome', 'Individual', 'Lead', 'Live Birth', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Nutritional', 'Operative Surgical Procedures', 'PAX7 gene', 'Pathway interactions', 'Pattern', 'Phenotype', 'Play', 'Population', 'Proteins', 'Public Health', 'RNA', 'RNA Binding', 'Reporting', 'Research', 'Resources', 'Role', 'Sample Size', 'Site', 'Speech', 'Time', 'Tissues', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'base', 'computer infrastructure', 'craniofacial', 'craniofacial development', 'deep learning', 'epigenomics', 'exome', 'expectation', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'insight', 'interest', 'learning strategy', 'multidimensional data', 'multidisciplinary', 'next generation sequencing', 'novel', 'novel therapeutics', 'orofacial', 'orofacial cleft', 'orofacial development', 'rare variant', 'risk variant', 'sequence learning', 'spatiotemporal', 'success', 'trait']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R03,2019,154000,0.035160980999289375
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9783881,U01EB029373,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIBIB,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2019,611358,0.0011613476878709094
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9666926,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'supervised learning', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2019,242725,0.01469674188159728
"A Multivariate Mediation and Deep Learning Framework for Genome-Connectome -Substance Use Research Substance use and addiction are complex biopsychosocial disorders influenced by both genetic and environmental factors. A key challenge in addiction genetics research is to understand how multiple genetic variants interactively influence addiction traits through impacting the central nervous system. To address this challenge, we propose a large-scale mediation analysis framework to identify addiction-related gene-brain circuitry pathways, using nicotine addiction as the targeted disorder, although the platform will be readily applicable for other addiction-related disorders and phenotypes. We will fully leverage the complex and interactive interdependent relationships between the imaging-genetics data and perform multivariate statistical inference with simultaneously increased statistical power and reduce false positive rates. The results will precisely identify multiple sets of genetic variants that interactively alter brain functional and structural circuitries, and then influence nicotine addiction. We will further supplement the mediation results with deep learning algorithms to study how genetic variants non-linearly and interactively coordinate to influence nicotine addiction and explain the phenotypic variance. Novel network topology based convolutional and pooling functions will be developed to achieve optimal prediction accuracy of addiction traits using genome-connectome pathways. All models and findings will be carefully validated through multiple independent large-sample data sets of imaging-genetics studies for nicotine addiction for ensuring the replicability and reliability of our findings derived from this framework. We plan to produce a freely available and user-friendly software incorporating the mediation analysis framework and deep learning algorithms enabling the complex whole genome - connectome analysis for addiction genetics research. Nicotine addiction is a worldwide public health priority and imposing health and economic burden on millions of individuals and families. This proposal seeks to identify how multiple genetic variants interactively influence the nicotine addiction through impacting brain circuitries. The improved understanding of genome-connectome pathways of addiction could lead to more effective treatment and prevention.",A Multivariate Mediation and Deep Learning Framework for Genome-Connectome -Substance Use Research,9810163,DP1DA048968,"['Address', 'Alcohol or Other Drugs use', 'Brain', 'Complex', 'Data', 'Data Set', 'Disease', 'Economic Burden', 'Ensure', 'Environmental Risk Factor', 'Family', 'Genes', 'Genetic', 'Genetic Research', 'Genetic study', 'Genome', 'Individual', 'Lead', 'Mediation', 'Modeling', 'Neuraxis', 'Nicotine Dependence', 'Pathway interactions', 'Phenotype', 'Prevention', 'Research', 'Sampling', 'Structure', 'Substance Addiction', 'addiction', 'base', 'biopsychosocial', 'brain circuitry', 'connectome', 'deep learning', 'deep learning algorithm', 'effective therapy', 'genetic variant', 'health economics', 'imaging genetics', 'improved', 'nicotine use', 'novel', 'public health priorities', 'trait', 'user friendly software', 'whole genome']",NIDA,UNIVERSITY OF MARYLAND BALTIMORE,DP1,2019,463500,0.03556073352943952
"Development of statistical genetics methodology We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies. In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meetings. We have further developed and tested a limited permutation method that allows estimation of false positive rates in conjunction with our recurrency approach. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Ongoing work has involved further research to improve control of false positive rates while retaining excellent power , adding approaches to increase power when number of features is very large and there are only interaction effects on risk of disease and comparison of our new methods to several other feature-selection schemes. We have also been developing and testing a new approach for specifically identifying which selected features are actually interacting as opposed to acting independently. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published three papers describing this method. We are currently developing The Machine Suite which will be an extension of r2VIM. A manuscript presenting the updates to our methods is under preparation and results will be presented at two upcoming scientific meetings.   We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Development of these analysis methods and tools are ongoing, driven by our own WES and WGS sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have worked on optimizing methods for performing multipoint analyses using extremely dense WES, WGS and exome chip data sets. Work is ongoing to improve pipelines for application of family-based methods for improved quality control in whole genome sequence data. Our WGS pipeline has been presented at several scientific meetings this past year.  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. Simulations are ongoing to compare our new methods to existing methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD and Dr. Chi-Yan Chiu (a Guest Researcher who is a faculty member at University of Tennessee Health Sciences Center), we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits as well as mixed effects models. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates.We have published multiple papers in this area in previous years and one paper has been published reporting these results has been published in this reporting period 1.  We have collaborated with members of Dr. Alexander Wilsons group (Genometrics Section, CSGB, NHGRI) on several methods development projects including an ongoing project to develop approaches for selecting significant variants from GWAS when no replication samples are available, such that false positive rates are well controlled. A manuscript reporting on our new approach and software has been published in this reporting period 2.  Finally we have continued a collaboration with Drs. Ingo Ruczinski and Alexander Bureau on approaches to identifying causal rare variants in pedigree data. We extended our existing methodology (Rare Variant Sharing, RVS) to introduce gene-based analyses, a partial sharing test based on RV sharing probabilities for subsets of affected relatives and a haplotype-based RV definition. RVS also has the desirable feature of not requiring external estimates of variant frequency or control samples, provides functionality to assess and address violations of key assumptions, and is available as open source software for genome-wide analysis.  We have published a paper reporting on this work this year 3. n/a",Development of statistical genetics methodology,10020054,ZIAHG000153,"['Address', 'Affect', 'African American', 'Area', 'Biological Models', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'European', 'Faculty', 'Family', 'Framingham Heart Study', 'Frequencies', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Health Sciences', 'Imagery', 'Individual', 'Linear Models', 'Machine Learning', 'Manuscripts', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Publishing', 'Quality Control', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scheme', 'Sequence Analysis', 'Statistical Methods', 'Structure', 'Tennessee', 'Testing', 'Universities', 'Update', 'Variant', 'Work', 'base', 'case control', 'caucasian American', 'classification trees', 'data mining', 'data warehouse', 'disorder risk', 'exome', 'flexibility', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'genome wide association study', 'genome-wide analysis', 'genomic data', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'novel', 'novel strategies', 'open source', 'oral cleft', 'programs', 'quality assurance', 'random forest', 'rare variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2019,394536,0.026579338590434008
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed understanding of admixture is essential for effective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on phenotype are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simplified models at the risk of inaccurate inferences. This proposal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to leverage this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate powerful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as effectively as homogeneous populations. The first step in obtaining a thorough understanding of admixture is a principled and scalable statistical framework to infer fine-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop effective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major impact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to efficiently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human phenotypes, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on fine-scale genomic structure and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can benefit from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9774249,R35GM125055,"['Admixture', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'structural genomics', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2019,332952,0.03276441067871565
"Statistical Methods For Gene/environment Interaction And Genetic Susceptibility Identification of causative SNPs in a genome-wide study can be challenging when individual SNPs have small marginal effects because testing thresholds must reflect the large number of SNPs under study. For complex diseases, particular combinations of SNPs may dramatically increase risk a kind of epistasis or gene-gene interaction. We are currently investigating the use of a machine learning technique for the discovery of sets of SNPs that together cause disease (causative SNPs) in case-parents data. First, we devised a way to use actual case-parent triad genotypes to create simulated genome-wide data sets that reflect realistic linkage disequilibrium structure and are seeded with known sets of causative SNPs. This manuscript was recently published, and the computer code is publicly available.  We are currently working to better characterize the genetic properties of populations simulated in this way.  Second, we implemented an existing stochastic search algorithm (called GA-KNN) that is based on an evolutionary algorithm to find multiple sets of k SNPs that are predictive of disease (here k is a small number, say 2 or 4). By cataloguing those SNPs which appear most frequently among the sets that are predictive of disease, we hope to uncover the sets of causative SNPS. In preliminary trials on simulated data seeded with two interacting sets of four SNPs each, our approach shows promise. In ongoing work, we are attempting to speed up the algorithm and to see whether the promising performance is maintained in more complex situations.  (see also Z01 ES040007; PI Clare Weinberg; Min Shi is also a within-lab collaborator on this project; her time is allocated in Weinberg's project but not in this one.) n/a",Statistical Methods For Gene/environment Interaction And Genetic Susceptibility,10012661,ZIAES045002,"['Algorithms', 'Alleles', 'Cataloging', 'Catalogs', 'Complex', 'Control Groups', 'Data', 'Data Set', 'Disease', 'Environment', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Predisposition to Disease', 'Genotype', 'Individual', 'Investigation', 'Linkage Disequilibrium', 'Machine Learning', 'Manuscripts', 'Methods', 'Modification', 'Parents', 'Performance', 'Population', 'Property', 'Publishing', 'Research Personnel', 'Risk', 'Siblings', 'Speed', 'Statistical Methods', 'Structure', 'Techniques', 'Testing', 'Time', 'Triad Acrylic Resin', 'Work', 'base', 'computer code', 'coping', 'design', 'disorder risk', 'gene environment interaction', 'gene interaction', 'genetic makeup', 'genetic variant', 'genome-wide', 'genome-wide analysis', 'method development', 'tool']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,ZIA,2019,35337,-0.001138559875385226
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9699440,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'machine learning algorithm', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2019,186101,0.02400810356418419
"Computational modeling of spatial genome organization and gene regulation PROJECT SUMMARY/ABSTRACT The three-dimensional (3D) organization of the genome plays an essential role in genome stability, gene regulation, and many diseases, including cancer. The recent development of high-throughput chromatin conformation capture (Hi-C) and its variants provide an unprecedented opportunity to investigate higher-order chromatin organization. Despite the rapidly accumulating resources for investigating 3D genome organization, our understanding of the regulatory mechanisms and functions of the genome organization remain largely incomplete. Hi-C analyses and 3D genome research are still in their early stage and face several challenges. First, high-resolution chromatin contact maps require extremely deep sequencing and hence have been achieved only for a few cell lines. Second, it is computationally challenging to complement 3D genome structure with one-dimensional (1D) genomic and epigenomic features. Third, recent studies have just begun to infer associations between chromatin interactions and genetic variants and to identify potential target genes of those variants at the genome-wide scale. Given these challenges and my unique multi-disciplinary training, my long-term research goal is to develop innovative computational and statistical methods to uncover the interplay between 3D genome structure and function. Speciﬁcally, in the next ﬁve years, I will i) develop computational approaches to enhance the resolution of existing Hi-C data and investigate ﬁne-scale 3D genome architecture as well as its spatiotemporal dynamics and ii) build scalable and interpretable machine learning models that leverage 1D epigenomic data to predict cell type-speciﬁc 3D chromatin interactions and gene expression and elucidate the function of 3D genome organization in gene regulation and human diseases. The completion of the proposed work will deepen our knowledge of 3D genome architecture as well as its functions in gene regulation and disease. PROJECT NARRATIVE The overarching mission of my research is to understand the interplay between genome architecture and gene regulation. Recent development of high-throughput chromatin conformation capture techniques has allowed us to look beyond the nucleotide sequence of DNA and investigate the principles of higher-order chromatin organization. I will develop innovative computational and statistical strategies to investigate 3D genome organization at an unprecedented scale, thereby elucidating the impacts of genome organization on gene regulation and disease.",Computational modeling of spatial genome organization and gene regulation,9798957,R35GM133678,"['3-Dimensional', 'Architecture', 'Base Sequence', 'Cell Line', 'Chromatin', 'Complement 3d', 'Computer Simulation', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Development', 'Dimensions', 'Disease', 'Face', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genome Stability', 'Genomics', 'Goals', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mission', 'Modeling', 'Play', 'Research', 'Resolution', 'Resources', 'Role', 'Statistical Methods', 'Structure', 'Techniques', 'Training', 'Variant', 'Work', 'cell type', 'chromosome conformation capture', 'deep sequencing', 'epigenomics', 'genetic variant', 'genome-wide', 'human disease', 'innovation', 'multidisciplinary', 'spatiotemporal']",NIGMS,UNIVERSITY OF CALIFORNIA RIVERSIDE,R35,2019,369984,-0.03213831793251803
"Development of New Genome Editing Agents Using RNA Modifying Enzymes Komor – Project Summary/Abstract - “Development of New Genome Editing Agents Using RNA Modifying Enzymes”  While targeted genome editing, the introduction of a specific modification in genomic DNA, has the potential to allow researchers to study and better understand mechanisms of human genetic diseases, traditional genome editing methods (including CRISPR-Cas9) that rely on the initial introduction of double stranded DNA breaks (DSB) suffer from modest genome editing efficiencies as well as unwanted gene alterations (indels), particularly when attempting to correct point mutations. Recently, a class of genome editing agents called single base editors was developed that does not involve DSBs, but rather uses a dCas9-tethered single-stranded DNA (ssDNA) modifying enzyme to directly chemically modify target nucleobases within a ~5 nucleotide window determined by the protospacer. Two classes of editors have been developed that use cytosine and adenine deamination chemistries to catalyze the conversion of C•G base pairs to T•A (CBEs), and A•T base pairs to G•C (ABEs), respectively. Here we propose the development and characterization of new base editors capable of facilitating new point mutations using methylation chemistry. We have use a bioinformatic approach to identify RNA modifying enzymes that have the potential to be repurposed into new base editors, and have rationally designed mutant libraries to use with directed evolution to convert these enzymes into base editors (Aim 1). Concurrently, we are developing a machine learning program that utilizes existing ssDNA modifying enzymes to identify putative mutations that will expand the substrate scope of the identified methyltransferases to ssDNA (Aim 2). Mutations identified from both strategies will then be tested and characterized for base editing in multiple orthogonal systems (Aim 3). The successful completion of the proposed work will represent a significant addition to existing base editing technologies, and will enable researchers to cleanly and efficiently install two additional types of point mutations into the genome of living cells, allowing researchers to quickly and effectively general model systems for the study of human genetic diseases. Komor – Project Narrative - “Development of New Genome Editing Agents Using RNA Modifying Enzymes” Base editing enables high efficiency genomic point mutation introduction in a variety of cell types and has the potential to allow researchers to better study human genetic diseases. We propose transformative improvements to current base editing technologies that will expand the types of point mutations that can be introduced by base editors. The tools developed here will enable researchers to cleanly and efficiently install additional types of point mutations into the genome of living cells for the study and potential treatment of human genetic diseases.",Development of New Genome Editing Agents Using RNA Modifying Enzymes,9876634,R21GM135736,"['Adenine', 'Adoption', 'Algorithms', 'Base Pairing', 'Bioinformatics', 'Biological Assay', 'Biological Models', 'CRISPR/Cas technology', 'Case Study', 'Cell Line', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Cytosine', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'Deamination', 'Development', 'Directed Molecular Evolution', 'Engineering', 'Enzymes', 'Escherichia coli', 'Evolution', 'Gene Mutation', 'Generations', 'Genetic Diseases', 'Genome', 'Genomic DNA', 'Genomics', 'Human', 'Human Genetics', 'In Vitro', 'Individual', 'Inosine', 'Lesion', 'Libraries', 'Link', 'Machine Learning', 'Mammalian Cell', 'Measures', 'Mediating', 'Methods', 'Methylation', 'Methyltransferase', 'Modification', 'Mutation', 'Nucleotides', 'Pathogenicity', 'Point Mutation', 'Program Development', 'Proteins', 'Purines', 'Pyrimidine', 'RNA', 'Research Personnel', 'Single-Stranded DNA', 'Site', 'Specificity', 'System', 'Technology', 'Testing', 'Transfer RNA', 'Uracil', 'Variant', 'Work', 'adenosine deaminase', 'base', 'cell type', 'combat', 'design', 'genome editing', 'insertion/deletion mutation', 'machine learning algorithm', 'molecular dynamics', 'mutant', 'novel', 'nucleobase', 'preference', 'programs', 'tool', 'transition mutation', 'transversion mutation']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2019,205479,-0.019295156997538844
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efficiently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be infinitely replicated. Their combination, the multiparental genetic reference population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, flies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions considered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and find variance-controlling genes; and more rigorous and expansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered include: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only fill significant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9672510,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'causal variant', 'computerized tools', 'design', 'fly', 'human disease', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2019,336445,0.03084403533211053
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9658531,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2019,479215,-0.013154856128190033
"Visualization, modeling and validation of chromatin interaction data The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Several recent high- throughput technologies based on Chromatin Conformation Capture (3C) have emerged (such as 4C, 5C, Hi-C and ChIA-PET) and given us an unprecedented opportunity to study the higher-order genome organization. Among them, Hi-C technology is of particular interest due to its unbiased genome-wide coverage that can measure chromatin interaction intensities between any two given genomic loci. However, Hi-C data analysis and interpretation are still in the early stages. One of the main challenges is how to efficiently visualize chromatin interaction data, so that the scientific community to visualize and use it for their own research. In addition, due to the complex experimental procedure and high sequencing cost, Hi-C has only been performed in a limited number of cell/tissue types. Finally, the underlying mechanism of chromatin interactions remains largely unclear. Therefore, the PI will propose the following aims: Aim 1. Build an interactive and customizable 3D genome browser. We will build an interactive and customizable 3D browser, which allows users to navigate Hi-C data and other high-throughput chromatin organization data, including ChIA-PET and Capture Hi-C. We have built a prototype of the 3D genome browser (www.3dgenome.org). Our browser will allow users to conveniently browse chromatin interaction data with other data types (such as ChIP-Seq and RNA-Seq) from the genomic region in the same window simultaneously. Our system will also empower the users to create their own session and query their own Hi-C and other epigenomic data. Aim 2. Impute chromatin interaction using other genomic/epigenomic information. We will predict Hi-C interaction frequencies using other available genomic and epigenomic data in the same cell type, such as ChIP-Seq data for histone modifications and transcription factors. We will build our prediction model and then systematically impute Hi-C interaction matrices for all 127 cell types whose epigenomes are available thanks to recent effort by the ENCODE and Roadmap Epigenome projects. Aim 3. Perform validation experiments for computational method in aim 1 and 2. We will perform 20 3C experiments in hESC and GM cell lines, coupled with genome engineering by CRISPR/Cas9, to evaluate Hi-C prediction method in aim 2. The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Although several recent high-throughput technologies including Hi-C have emerged and given us an unprecedented opportunity to study 3D chromatin interaction in high resolution, its analysis and interpretation are still in the early stages. Here we propose to develop a suite of statistical modeling and computational methods to model and validate chromatin interaction using other genomic/epigenomics data, and build an interactive and customizable 3D genome browser.","Visualization, modeling and validation of chromatin interaction data",9967363,R01HG009906,"['3-Dimensional', 'Address', 'CRISPR/Cas technology', 'Cell Line', 'Cell physiology', 'Cells', 'ChIP-seq', 'Chromatin', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Chromatin Remodeling Factor', 'Chromosome Territory', 'Communities', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Coupled', 'Data', 'Data Analyses', 'Dimensions', 'Distal', 'Elements', 'Environment', 'Event', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genome engineering', 'Genomic Segment', 'Genomics', 'Imagery', 'Intuition', 'Knock-out', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Molecular', 'Procedures', 'Regulator Genes', 'Regulatory Element', 'Research', 'Resolution', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Validation', 'Visit', 'base', 'cell type', 'chromosome conformation capture', 'convolutional neural network', 'cost', 'epigenome', 'epigenomics', 'experimental study', 'genome annotation', 'genome browser', 'genome-wide', 'high throughput technology', 'histone modification', 'human embryonic stem cell', 'interest', 'mammalian genome', 'performance tests', 'predictive modeling', 'prototype', 'random forest', 'repository', 'transcription factor', 'transcriptome sequencing', 'web site']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,102272,-0.03193962199793852
"Visualization, modeling and validation of chromatin interaction data The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Several recent high- throughput technologies based on Chromatin Conformation Capture (3C) have emerged (such as 4C, 5C, Hi-C and ChIA-PET) and given us an unprecedented opportunity to study the higher-order genome organization. Among them, Hi-C technology is of particular interest due to its unbiased genome-wide coverage that can measure chromatin interaction intensities between any two given genomic loci. However, Hi-C data analysis and interpretation are still in the early stages. One of the main challenges is how to efficiently visualize chromatin interaction data, so that the scientific community to visualize and use it for their own research. In addition, due to the complex experimental procedure and high sequencing cost, Hi-C has only been performed in a limited number of cell/tissue types. Finally, the underlying mechanism of chromatin interactions remains largely unclear. Therefore, the PI will propose the following aims: Aim 1. Build an interactive and customizable 3D genome browser. We will build an interactive and customizable 3D browser, which allows users to navigate Hi-C data and other high-throughput chromatin organization data, including ChIA-PET and Capture Hi-C. We have built a prototype of the 3D genome browser (www.3dgenome.org). Our browser will allow users to conveniently browse chromatin interaction data with other data types (such as ChIP-Seq and RNA-Seq) from the genomic region in the same window simultaneously. Our system will also empower the users to create their own session and query their own Hi-C and other epigenomic data. Aim 2. Impute chromatin interaction using other genomic/epigenomic information. We will predict Hi-C interaction frequencies using other available genomic and epigenomic data in the same cell type, such as ChIP-Seq data for histone modifications and transcription factors. We will build our prediction model and then systematically impute Hi-C interaction matrices for all 127 cell types whose epigenomes are available thanks to recent effort by the ENCODE and Roadmap Epigenome projects. Aim 3. Perform validation experiments for computational method in aim 1 and 2. We will perform 20 3C experiments in hESC and GM cell lines, coupled with genome engineering by CRISPR/Cas9, to evaluate Hi-C prediction method in aim 2. The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Although several recent high-throughput technologies including Hi-C have emerged and given us an unprecedented opportunity to study 3D chromatin interaction in high resolution, its analysis and interpretation are still in the early stages. Here we propose to develop a suite of statistical modeling and computational methods to model and validate chromatin interaction using other genomic/epigenomics data, and build an interactive and customizable 3D genome browser.","Visualization, modeling and validation of chromatin interaction data",9623355,R01HG009906,"['3-Dimensional', 'Address', 'CRISPR/Cas technology', 'Cell Line', 'Cell physiology', 'Cells', 'ChIP-seq', 'Chromatin', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Chromatin Remodeling Factor', 'Chromosome Territory', 'Communities', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Coupled', 'Data', 'Data Analyses', 'Dimensions', 'Distal', 'Elements', 'Environment', 'Event', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genome engineering', 'Genomic Segment', 'Genomics', 'Imagery', 'Intuition', 'Knock-out', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Molecular', 'Procedures', 'Regulator Genes', 'Regulatory Element', 'Research', 'Resolution', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Validation', 'Visit', 'base', 'cell type', 'chromosome conformation capture', 'convolutional neural network', 'cost', 'epigenome', 'epigenomics', 'experimental study', 'genome annotation', 'genome browser', 'genome-wide', 'high throughput technology', 'histone modification', 'human embryonic stem cell', 'interest', 'mammalian genome', 'performance tests', 'predictive modeling', 'prototype', 'random forest', 'repository', 'transcription factor', 'transcriptome sequencing', 'web site']",NHGRI,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R01,2019,284020,-0.03193962199793852
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9751141,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2019,1186500,0.0094728034843306
"Optimizing imputation for diverse populations in a distributed framework The NHGRI Genome Sequencing Program (GSP) will identify genomic variants relevant to health and disease by genome sequencing over 225,000 participants across a multitude of diseases. The GSP will also serve as a pilot for the Precision Medicine Initiative that aims to enroll and sequence more than a million people representative of U.S. ethnic diversity. Here, we propose a GSP analysis center focused on Multi- and Trans- ethnic Mapping of Mendelian and Complex Diseases. There is a growing recognition of the substantial scientific advantages, as well as public health importance, of conducting biomedical research across ethnically diverse cohorts. We propose to develop scalable methods that incorporate ancestry to optimize medical genomic study design and improve power for uncovering the role of common and rare variants in disease. Achieving this goal requires expertise across diverse domains of knowledge including: medical and population genomics, algorithm development for complex disease mapping, and expertise in management of large-scale databases. Here, we have assembled a world-class team of medical and population geneticists, computer scientists, statisticians and clinicians, with leading expertise in the development of novel and scalable strategies for characterizing sequence variants and their role in disease. Importantly, our group has been at the forefront of development of resources, study designs and methods to enable genomic research in U.S. minority populations. Our project has three main objectives. First, we will develop an Automated Scalable Ancestry Pipeline (ASAP) for common disease mapping in diverse populations. ASAP will improve the computational efficiency of existing state-of-the-art methods for ancestry inference and develop important extensions to linear mixed models (LMMs) and other mapping strategies leveraging local and global ancestry. We will also develop methods to refine phenotypes and identify common controls for disease studies and define endpoints. Secondly, we will develop tools and resources for trans- and multi-population rare variant discovery that incorporate patterns of local and sub-continental ancestry. We will also develop machine-learning tools for variant annotation that leverage ancestral information, patterns of sequence evolution, and protein structure in a unified framework. Furthermore, we will incorporate population-specific patterns of cellular phenotypes to improve functional prediction algorithms for non-coding and coding variants. Lastly, we will disseminate our results through web-based resource that empower the biomedical research community. We will augment existing resources including ClinGen by annotating and characterizing pathogenic variants across diverse populations. We will develop a secure web-server that allows sharing of summary statistics and analysis pipelines to enable discovery, fine-mapping and functional prediction of genetic variants. Our team has ample experience with NIH-funded consortia and is dedicated to meeting the overall GSP project goals through collaborative work with NHGRI leadership and other funded investigators. The goal of our project is to accelerate the discovery of DNA variation relevant to health and disease by analyzing data from over 225,000 ethnically and racially diverse patients that will undergo genome sequencing. Of particular importance is ensuring we have powerful statistical methods for analyzing data from underserved groups including U.S. minority populations. Achieving this goal requires expertise across many domains of knowledge including: medical and population genomics, algorithm development for disease mapping, and expertise in large-scale databases.  ",Optimizing imputation for diverse populations in a distributed framework,10016895,U01HG009080,"['Algorithms', 'Biomedical Research', 'Code', 'Communities', 'Complex', 'Computers', 'DNA', 'Data Analyses', 'Development', 'Disease', 'Enrollment', 'Ensure', 'Evolution', 'Funding', 'Genomics', 'Goals', 'Health', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Methods', 'Minority', 'Modeling', 'National Human Genome Research Institute', 'Participant', 'Pathogenicity', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Population Heterogeneity', 'Precision Medicine Initiative', 'Public Health', 'Research', 'Research Design', 'Research Personnel', 'Resource Development', 'Resources', 'Role', 'Scientist', 'Secure', 'Statistical Methods', 'Structural Protein', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Work', 'analysis pipeline', 'cohort', 'disorder control', 'ethnic diversity', 'experience', 'genetic variant', 'genome sequencing', 'improved', 'large-scale database', 'meetings', 'novel', 'online resource', 'prediction algorithm', 'programs', 'protein structure', 'racial diversity', 'rare variant', 'statistics', 'tool', 'web server']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U01,2019,422665,0.05535170750116535
"Center for Undiagnosed Diseases at Stanford Abstract The Undiagnosed Diseases Network (UDN) has increased access for patients with undiagnosed diseases to the nation’s leading clinicians and scientists. Phase II of the Network will facilitate the transition of UDN efforts toward sustainability, through the expansion of clinical sites, refinement of methods, and integration with regular clinical practice. Here, we propose a program of study that will (1) facilitate timely, accurate diagnosis of patients with undiagnosed diseases; (2) improve diagnostic rates through novel approaches to data analysis and integration; and (3) explore underlying mechanisms of disease to accelerate therapeutic drug discovery. In Aim 1, we propose to evaluate patients referred to the UDN through a protocol that includes pre-visit chart review and genetic counseling followed by an individualized visit during which standardized phenotypic and environmental data are collected. Biosamples facilitate genomic, multi-omic, and cellular evaluation of disease. Expansion of fibroblasts and, in selected cases, generation of induced Pluripotent Stem Cell (iPSC) lines facilitates scientific investigation of the underlying diseases. We will expand our program of patient outreach, particularly to under-served populations. We will extend our UDN-based genomic medicine educational program both in scope and by broadening its eligibility. In Aim 2, we propose to develop and implement novel methods in areas of high potential to increase diagnostic yield. This includes algorithms for the detection of small genomic insertions and deletions as well as large scale structural variation. We will develop alignment algorithms using graph reference genomes and promote the use of long-read sequencing technologies. We will apply machine learning to the systematic integration of RNA sequencing, metabolomic, and phenotypic data with the electronic medical record and the entire medical literature to improve diagnostic yield. In Aim 3, we propose to facilitate diagnosis through enhanced cellular and model organisms phenotyping. We will implement immunomic and metagenomic approaches such as T cell, B cell and unknown organism sequencing for undiagnosed cases. We will utilize methods for moderate- and high-throughput phenotyping of iPS-derived cells and promote novel drug discovery via high throughput drug screening both with FDA- approved drugs and large scale small molecule libraries. Beyond Phase II, Stanford Medicine has made a strong commitment to the continuation of the Center for Undiagnosed Diseases at Stanford through a multi- million dollar institutional commitment. In summary, we aim to build on the success of Phase I of the UDN by streamlining processes, maximizing collaboration and outreach, optimizing computational algorithms, extending scientific investigation towards therapeutic discovery, and promoting engagement of hospital leaders, clinicians, scientists, policy-makers, and philanthropists to ensure this national resource is sustained long beyond the duration of this award. Narrative We will refine the operations of the Center for Undiagnosed Diseases at Stanford in coordination with other Phase II sites of the Undiagnosed Diseases Network to diagnose the undiagnosed and facilitate a transition to sustainability. Our Center will bring Stanford’s long history in technology development, genomic data analysis, stem cell biology, and translational science to the team-based diagnosis and care of patients with undiagnosed disease. We will refine existing procedures to further optimize the diagnostic process and integrate care of the undiagnosed into clinical practice while preserving the scientific mission of the Undiagnosed Diseases Network.",Center for Undiagnosed Diseases at Stanford,9789914,U01HG010218,"['Algorithms', 'Animal Model', 'Area', 'Award', 'B-Lymphocytes', 'Biological Assay', 'Caring', 'Cell Line', 'Cell model', 'Cells', 'Child Health', 'Collaborations', 'Committee Membership', 'Computational algorithm', 'Computerized Medical Record', 'Consent', 'Country', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug Screening', 'Education', 'Eligibility Determination', 'Ensure', 'Evaluation', 'FDA approved', 'Family', 'Fibroblasts', 'Gene Silencing', 'Generations', 'Genetic Counseling', 'Genomic medicine', 'Genomics', 'Goals', 'Graph', 'Healthcare', 'Hospitals', 'Human', 'International', 'Investigation', 'Investments', 'Leadership', 'Libraries', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Metagenomics', 'Methods', 'Mission', 'Modeling', 'Multiomic Data', 'Network-based', 'Ontology', 'Organism', 'Organoids', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Policy Maker', 'Principal Investigator', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Recording of previous events', 'Research', 'Resources', 'Robotics', 'Role', 'Scientist', 'Site', 'Standardization', 'Structure', 'System', 'T-Lymphocyte', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underserved Population', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visit', 'accurate diagnosis', 'base', 'clinical practice', 'clinical research site', 'cohort', 'data integration', 'deep learning', 'drug discovery', 'experience', 'follow-up', 'genome-wide', 'genomic data', 'improved', 'induced pluripotent stem cell', 'innovation', 'insertion/deletion mutation', 'meetings', 'metabolomics', 'multiple omics', 'next generation', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'outreach', 'patient outreach', 'phenotypic data', 'preservation', 'programs', 'reference genome', 'relating to nervous system', 'research clinical testing', 'sample collection', 'screening', 'small molecule libraries', 'socioeconomics', 'stem cell biology', 'success', 'support network', 'technology development', 'tool', 'transcriptome sequencing', 'virtual']",NHGRI,STANFORD UNIVERSITY,U01,2019,1500000,-0.0023351266999561723
"Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease ABSTRACT Rapid progress in biomedical informatics has generated massive high-dimensional data sets (“big data”), ranging from clinical information and medical imaging to genomic sequence data. The scale and complexity of these data sets hold great promise, yet present substantial challenges. To fully exploit the potential informativeness of big data, there is an urgent need to find effective ways to integrate diverse data from different levels of informatics technologies. Existing approaches and methods for data integration to date have several important limitations. In this project, we propose novel statistical methods and strategies to integrate neuroimaging, multi-omics, and clinical/behavioral data sets. To increase power for association analysis compared to existing methods, we propose a novel multi-phenotype multi-variant association method that can evaluate the cumulative effect of common and rare variants in genes or regions of interest, incorporate prior biological knowledge on the multiple phenotype structure, identify associated phenotypes among multiple phenotypes, and be computationally efficient for high-dimensional phenotypes. To improve the prediction of clinical outcomes, we propose a novel machine learning strategy that can integrate multimodal neuroimaging and multi-omics data into a mathematical model and can incorporate prior biological knowledge to identify genomic interactions associated with clinical outcomes. The ongoing Alzheimer's Disease Neuroimaging Initiative (ADNI) and Indiana Memory and Aging Study (IMAS) projects as a test bed provide a unique opportunity to evaluate/validate the proposed methods. Specific Aims: Aim 1: to develop powerful statistical methods for multivariate tests of associations between multiple phenotypes and a single genetic variant or set of variants (common and rare) in regions of interest, and to develop methods for mediation analysis to integrate neuroimaging, genetic, and clinical data to test for direct and indirect genetic effects mediated through neuroimaging phenotypes on clinical outcomes; Aim 2: to develop a novel multivariate model that combines multi-omics and neuroimaging data using a machine learning strategy to predict individuals with disease or those at high-risk for developing disease, and to develop a novel multivariate model incorporating prior biological knowledge to identify genomic interactions associated with clinical outcomes; Aim 3: to evaluate and validate the proposed methods using real data from the ADNI and IMAS cohorts; and Aim 4: to disseminate and support publicly available user-friendly software that efficiently implements the proposed methods. RELEVANCE TO PUBLIC HEALTH: Alzheimer's disease (AD) as an exemplar is an increasingly common progressive neurodegenerative condition with no validated disease modifying treatment. The proposed multivariate methods are likely to help identify novel diagnostic biomarkers and therapeutic targets for AD. Identifying new susceptibility loci/biomarkers for AD has important implications for gaining greater insight into the molecular mechanisms underlying AD. NARRATIVE In this project, we propose novel statistical methods and strategies to integrate high-dimensional neuroimaging, multi-omics, and clinical/behavioral data sets, which aim to increase detection power for association analysis and improve the prediction of clinical outcomes. The development of an advanced integrative analysis platform will provide more comprehensive and integrated approaches to answering complex biological questions. The proposed multivariate analysis methods have a high potential impact on and important implications for gaining greater insight into the molecular mechanisms underlying complex diseases, as well as helping the development of earlier diagnostic tests and novel therapeutic targets.","Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease",9694279,R01LM012535,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Beds', 'Behavioral', 'Big Data', 'Biological', 'Brain', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Complex', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Progression', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Genomics', 'Genotype', 'Health', 'Heterogeneity', 'Indiana', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Medical Imaging', 'Memory', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Multivariate Analysis', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Phenotype', 'Positron-Emission Tomography', 'Proteomics', 'Public Health', 'Science', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Technology', 'Testing', 'Time', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cohort', 'data integration', 'diagnostic biomarker', 'disease classification', 'endophenotype', 'epigenomics', 'genetic association', 'genetic variant', 'high dimensionality', 'high risk', 'improved', 'insight', 'interest', 'learning strategy', 'mathematical model', 'metabolomics', 'multidimensional data', 'multimodality', 'multiple omics', 'neuroimaging', 'new therapeutic target', 'novel', 'novel diagnostics', 'predict clinical outcome', 'rare variant', 'risk variant', 'therapeutic target', 'transcriptomics', 'user friendly software']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2019,341691,-0.04323949771189575
"Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases ﻿    DESCRIPTION (provided by applicant): The NHGRI Genome Sequencing Program (GSP) will identify genomic variants relevant to health and disease by genome sequencing over 225,000 participants across a multitude of diseases. The GSP will also serve as a pilot for the Precision Medicine Initiative that aims to enroll and sequence more than a million people representative of U.S. ethnic diversity. Here, we propose a GSP analysis center focused on Multi- and Trans- ethnic Mapping of Mendelian and Complex Diseases. There is a growing recognition of the substantial scientific advantages, as well as public health importance, of conducting biomedical research across ethnically diverse cohorts. We propose to develop scalable methods that incorporate ancestry to optimize medical genomic study design and improve power for uncovering the role of common and rare variants in disease. Achieving this goal requires expertise across diverse domains of knowledge including: medical and population genomics, algorithm development for complex disease mapping, and expertise in management of large-scale databases. Here, we have assembled a world-class team of medical and population geneticists, computer scientists, statisticians and clinicians, with leading expertise in the development of novel and scalable strategies for characterizing sequence variants and their role in disease. Importantly, our group has been at the forefront of development of resources, study designs and methods to enable genomic research in U.S. minority populations. Our project has three main objectives. First, we will develop an Automated Scalable Ancestry Pipeline (ASAP) for common disease mapping in diverse populations. ASAP will improve the computational efficiency of existing state-of-the-art methods for ancestry inference and develop important extensions to linear mixed models (LMMs) and other mapping strategies leveraging local and global ancestry. We will also develop methods to refine phenotypes and identify common controls for disease studies and define endpoints. Secondly, we will develop tools and resources for trans- and multi-population rare variant discovery that incorporate patterns of local and sub-continental ancestry. We will also develop machine-learning tools for variant annotation that leverage ancestral information, patterns of sequence evolution, and protein structure in a unified framework. Furthermore, we will incorporate population-specific patterns of cellular phenotypes to improve functional prediction algorithms for non-coding and coding variants. Lastly, we will disseminate our results through web-based resource that empower the biomedical research community. We will augment existing resources including ClinGen by annotating and characterizing pathogenic variants across diverse populations. We will develop a secure web-server that allows sharing of summary statistics and analysis pipelines to enable discovery, fine-mapping and functional prediction of genetic variants. Our team has ample experience with NIH-funded consortia and is dedicated to meeting the overall GSP project goals through collaborative work with NHGRI leadership and other funded investigators. PUBLIC HEALTH RELEVANCE The goal of our project is to accelerate the discovery of DNA variation relevant to health and disease by analyzing data from over 225,000 ethnically and racially diverse patients that will undergo genome sequencing. Of particular importance is ensuring we have powerful statistical methods for analyzing data from underserved groups including U.S. minority populations. Achieving this goal requires expertise across many domains of knowledge including: medical and population genomics, algorithm development for disease mapping, and expertise in large-scale databases.",Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases,9685931,U01HG009080,"['Algorithms', 'Architecture', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Code', 'Communities', 'Complex', 'Computers', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Enrollment', 'Ensure', 'Evolution', 'Funding', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human Genome', 'Investigation', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Methylation', 'Minority', 'Modeling', 'Molecular Conformation', 'National Human Genome Research Institute', 'Participant', 'Pathogenicity', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Population Heterogeneity', 'Precision Medicine Initiative', 'Privatization', 'Protocols documentation', 'Public Health', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resource Development', 'Resources', 'Risk', 'Role', 'Scientist', 'Secure', 'Shoulder', 'Statistical Methods', 'Structural Protein', 'Target Populations', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Work', 'analysis pipeline', 'cohort', 'disorder control', 'ethnic diversity', 'experience', 'genetic variant', 'genome sequencing', 'genomic tools', 'improved', 'innovation', 'large-scale database', 'meetings', 'novel', 'online resource', 'patient privacy', 'phenome', 'prediction algorithm', 'predictive modeling', 'preservation', 'programs', 'protein structure', 'public health relevance', 'racial diversity', 'rare variant', 'simulation', 'statistics', 'tool', 'tool development', 'web server', 'web-based tool']",NHGRI,STANFORD UNIVERSITY,U01,2019,276777,0.05805977600330793
"Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases ﻿    DESCRIPTION (provided by applicant): The NHGRI Genome Sequencing Program (GSP) will identify genomic variants relevant to health and disease by genome sequencing over 225,000 participants across a multitude of diseases. The GSP will also serve as a pilot for the Precision Medicine Initiative that aims to enroll and sequence more than a million people representative of U.S. ethnic diversity. Here, we propose a GSP analysis center focused on Multi- and Trans- ethnic Mapping of Mendelian and Complex Diseases. There is a growing recognition of the substantial scientific advantages, as well as public health importance, of conducting biomedical research across ethnically diverse cohorts. We propose to develop scalable methods that incorporate ancestry to optimize medical genomic study design and improve power for uncovering the role of common and rare variants in disease. Achieving this goal requires expertise across diverse domains of knowledge including: medical and population genomics, algorithm development for complex disease mapping, and expertise in management of large-scale databases. Here, we have assembled a world-class team of medical and population geneticists, computer scientists, statisticians and clinicians, with leading expertise in the development of novel and scalable strategies for characterizing sequence variants and their role in disease. Importantly, our group has been at the forefront of development of resources, study designs and methods to enable genomic research in U.S. minority populations. Our project has three main objectives. First, we will develop an Automated Scalable Ancestry Pipeline (ASAP) for common disease mapping in diverse populations. ASAP will improve the computational efficiency of existing state-of-the-art methods for ancestry inference and develop important extensions to linear mixed models (LMMs) and other mapping strategies leveraging local and global ancestry. We will also develop methods to refine phenotypes and identify common controls for disease studies and define endpoints. Secondly, we will develop tools and resources for trans- and multi-population rare variant discovery that incorporate patterns of local and sub-continental ancestry. We will also develop machine-learning tools for variant annotation that leverage ancestral information, patterns of sequence evolution, and protein structure in a unified framework. Furthermore, we will incorporate population-specific patterns of cellular phenotypes to improve functional prediction algorithms for non-coding and coding variants. Lastly, we will disseminate our results through web-based resource that empower the biomedical research community. We will augment existing resources including ClinGen by annotating and characterizing pathogenic variants across diverse populations. We will develop a secure web-server that allows sharing of summary statistics and analysis pipelines to enable discovery, fine-mapping and functional prediction of genetic variants. Our team has ample experience with NIH-funded consortia and is dedicated to meeting the overall GSP project goals through collaborative work with NHGRI leadership and other funded investigators. PUBLIC HEALTH RELEVANCE The goal of our project is to accelerate the discovery of DNA variation relevant to health and disease by analyzing data from over 225,000 ethnically and racially diverse patients that will undergo genome sequencing. Of particular importance is ensuring we have powerful statistical methods for analyzing data from underserved groups including U.S. minority populations. Achieving this goal requires expertise across many domains of knowledge including: medical and population genomics, algorithm development for disease mapping, and expertise in large-scale databases.",Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases,9995640,U01HG009080,"['Algorithms', 'Architecture', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Code', 'Communities', 'Complex', 'Computers', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Enrollment', 'Ensure', 'Evolution', 'Funding', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human Genome', 'Investigation', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Methylation', 'Minority', 'Modeling', 'Molecular Conformation', 'National Human Genome Research Institute', 'Participant', 'Pathogenicity', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Population Heterogeneity', 'Precision Medicine Initiative', 'Privatization', 'Protocols documentation', 'Public Health', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resource Development', 'Resources', 'Risk', 'Role', 'Scientist', 'Secure', 'Shoulder', 'Statistical Methods', 'Structural Protein', 'Target Populations', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Work', 'analysis pipeline', 'cohort', 'disorder control', 'ethnic diversity', 'experience', 'genetic variant', 'genome sequencing', 'genomic tools', 'improved', 'innovation', 'large-scale database', 'meetings', 'novel', 'online resource', 'patient privacy', 'phenome', 'prediction algorithm', 'predictive modeling', 'preservation', 'programs', 'protein structure', 'public health relevance', 'racial diversity', 'rare variant', 'simulation', 'statistics', 'tool', 'tool development', 'web server', 'web-based tool']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U01,2019,728322,0.05805977600330793
"Algorithms to identify non-coding mutational burden and disease-relevant pathways PROJECT SUMMARY/ABSTRACT Type 2 diabetes mellitus (T2D) is a disease with complex, polygenic etiology with numerous contributing mechanisms. To devise new therapeutics to combat this epidemic, we need to identify causal genes and variants for T2D and related, cardiometabolic traits implicated by human genetic association. Recently, large- scale DNA biobanks attached to electronic health records have facilitated extensive phenotyping in surprising large sample sizes (>500,000 subjects), importantly in diverse ancestries. These data have enabled a dramatic expansion of the number of bona-fide associations for T2D and related traits. While the increase in statistical power is certainly welcome, new opportunities for how to use these data require new computational methods and analytical pipelines. In this renewal, we focus on three areas for new methods development, which we will create and subsequently deploy to accelerate the genetic dissection for cardiometabolic disease. First, the number of associated loci now available permit the opportunity to learn directly from the data, which non- coding sequences functionally relate to T2D risk. We propose to utilize techniques in machine learning to make predictions for T2D and related causal traits, used to identify and prioritize causal variants and functional elements that are disease-predictive. A second challenge is that the quantity and pace at which this data is being produced is outstripping the rate at which even highly expert quantitative scientists can explore and extract novel insights from the data. To combat this problem, we propose to develop an informatics toolkit with apps to perform compute-intensive, important analyses and visualization with these data, tethered to cloud- based or local computation infrastructure. Finally, one key observation that follows biobank-based data analysis is that, at each physically distinct associated locus, numerous additional conditionally independent associations segregate nearby. This series of alleles can be identified through existing methods, but their use in causal inference approaches (i.e., Mendelian Randomization) has not been extensively explored. Here, we will evaluate their utility and develop statistical pipelines to use this spectrum of variation to perform new causal inference studies. PROJECT NARRATIVE Identification of causal variants and genes underlying type-2 diabetes (T2D) and related cardiometabolic trait associations are key challenge impeding biological understand and therapeutic developments. New, large- scale data sets from DNA biobanks are poised to help overcome these challenges but require the development of new informatics and statistical methods to take full advantage of the data. In this renewal application, we will develop new methods, machine learning applications, informatics tools, and causal inference statistical approaches to identify pinpoint casual variants and genes contributing to T2D and related traits.",Algorithms to identify non-coding mutational burden and disease-relevant pathways,10007107,R56DK101478,"['Address', 'Adoption', 'Algorithms', 'Alleles', 'Area', 'Base Pairing', 'Biological', 'Catalogs', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Dissection', 'Electronic Health Record', 'Elements', 'Environment', 'Epidemic', 'Etiology', 'Exposure to', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Grant', 'Human Genetics', 'Imagery', 'Informatics', 'Infrastructure', 'Investigation', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Pathway interactions', 'Phenotype', 'Physiological', 'Randomized', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Scheme', 'Scientist', 'Series', 'Signal Transduction', 'Site', 'Statistical Methods', 'Techniques', 'Testing', 'Uncertainty', 'Untranslated RNA', 'Variant', 'base', 'biobank', 'burden of illness', 'cardiometabolism', 'causal variant', 'cloud based', 'cluster computing', 'combat', 'computer infrastructure', 'experimental study', 'falls', 'follow-up', 'functional genomics', 'genetic association', 'genetic variant', 'genome analysis', 'genome wide association study', 'genome-wide analysis', 'informatics\xa0tool', 'insight', 'instrument', 'method development', 'novel', 'novel therapeutics', 'parallelization', 'power analysis', 'task analysis', 'therapeutic development', 'trait']",NIDDK,UNIVERSITY OF PENNSYLVANIA,R56,2019,272474,0.02036045333926671
"Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations PROJECT SUMMARY/ABSTRACT  Myosins are a diverse and ubiquitous class of molecular motors that are responsible for generating much of the macroscopic force in the human body. The human genome encodes 38 different isoforms of myosin, and members of this group act as force sensors or generators for a diverse set of processes throughout the body. To serve this wide array of functions, each myosin isoform has been biophysically tuned for its physiological role. In fact, the tuning is so precise that missense variants in one myosin isoform, !-cardiac myosin, can cause a congenital cardiomyopathy that is the leading cause of sudden cardiac death in people under 30. And yet, it is unknown how particular variants cause disease, or how to infer the pathogenic potential for novel mutations.  Large differences in functional properties between myosin isoforms are not the result of large differences in coding sequence or overall topology. Neither foreknowledge of phylogeny nor crystal structure is sufﬁcient to predict an isoform's biophysical properties. Furthermore, mutations causing disease frequently occur in regions of the protein far from the site of their deleterious effects. Poor understanding of the biophysical regulation of motor function has hampered the development of pharmaceuticals and the interpretation of human genomic data.  My goal is to establish a mechanistic understanding of myosin motors that is capable of predicting if and how sequence variation changes biophysical properties and can cause cardiac disease. Since myosin kinetics are not apparent from sequence or overall structure, they must be determined by other factors. I hypothesize that kinetic differences result from differences in the allosteric networks in these proteins. Allosteric network in this context refers to the coordinated conformational ﬂuctuations that give protein regulation the appearance of action at a distance. To test this hypothesis, we will use our unique combination of enormous computational power for molecular simulation and cutting-edge machine learning tools for analyzing protein allostery.  Aim 1 is to identify the biophysical determinants of myosin isoforms' differing speeds. To test our hypothesis that allosteric networks are responsible for modulating dynamics, I will use molecular simulations of different myosin isoforms and compare their allosteric networks with biochemical data about their properties. Aim 1 directly addresses outstanding questions about normal molecular-biological function of the heart, putting it in line with NHLBI overarching objective #1.  Aim 2 is to determine the difference, at atomic resolution, between healthy and diseased !-cardiac myosin. I hypothesize that the pathogenicity of variants with an unknown molecular etiology is a consequence of allosteric disruption, and will use our computational tools to test this hypothesis by simulating a set of known-pathogenic variants. This aim uses techniques from data science to understand the genetic determinants of health, and will apply equally well to rare alleles in under-represented groups as to majority groups. It is directly addresses NHLBI overarching objectives #3, #4, and #7. PROJECT NARRATIVE  Myosins are a closely-related group of molecules that are responsible for generating much of the force in the human body, including the heartbeat, the movement of limbs, and driving food through the stomach and intestines. Small changes to the myosin genes can have large effects: in healthy people, these give rise to different myosins that perform different functions, and mutations in some myosin genes can give rise to diseases that cause of sudden cardiac death. This proposal aims to learn, at the level of atoms and interatomic bonds, why and how these subtle changes to the myosin gene can create such large effects in the protein's function.",Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations,9678589,F30HL146052,"['Actins', 'Address', 'Affinity', 'Appearance', 'Automobile Driving', 'Behavior', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Process', 'Biophysics', 'Cardiac Myosins', 'Cardiomyopathies', 'Catalysis', 'Chemistry', 'Clinical', 'Code', 'Congenital cardiomyopathy', 'Crystallization', 'Data', 'Data Science', 'Development', 'Disease', 'Drug Binding Site', 'Etiology', 'Food', 'Genes', 'Genetic Determinism', 'Genetic Variation', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Genome', 'Human body', 'Intestines', 'Kinetics', 'Learning', 'Machine Learning', 'Measures', 'Membrane Proteins', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'National Heart, Lung, and Blood Institute', 'Pathogenicity', 'Patient risk', 'Pharmacologic Substance', 'Phenotype', 'Phylogeny', 'Physics', 'Physiological', 'Process', 'Property', 'Protein Analysis', 'Protein Isoforms', 'Protein Region', 'Proteins', 'Regulation', 'Relaxation', 'Resolution', 'Risk stratification', 'Role', 'Signal Transduction', 'Site', 'Solvents', 'Speed', 'Stomach', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Underrepresented Groups', 'Variant', 'base', 'biophysical properties', 'computerized tools', 'disease-causing mutation', 'genomic data', 'heart function', 'improved', 'insight', 'limb movement', 'member', 'millisecond', 'molecular dynamics', 'novel', 'precision medicine', 'protein function', 'prototype', 'rare variant', 'rat Ran 2 protein', 'sensor', 'simulation', 'sudden cardiac death', 'tool', 'whole genome']",NHLBI,WASHINGTON UNIVERSITY,F30,2019,30442,-0.023912798793311093
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9785353,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Structure', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'nonsynonymous mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,ALBERT EINSTEIN COLLEGE OF MEDICINE,K99,2019,135945,-0.015730549230305518
"Methods development for ""Omics"" data With my graduate student Tao Jiang, we have been working on an extension of least absolute shrinkage and selection operator (Lasso) regression to address variable selection and modeling when sample sizes are limited compared to the data dimension. This is a common phenomenon in genome wide association studies.  We developed a new upper bound of the regularization parameter  in sparse group Lasso based on an estimated lower bound of the proportion of false null hypotheses with confidence (1-). The bound is estimated by applying the empirical distribution of dependent or independent p-values from single marker/variable analysis, where a second-level significance testing, the higher criticism statistic is used. An upper bound of tuning parameter in Lasso, , is decided corresponding to the lower bound of the proportion of false null hypotheses. Thus, the tuning range is narrow since the upper bound of  is lower. The final decision of non-zero estimates (e.g., significant loci in GWAS) will contain more variables so that the power of modified GWAS is higher than or equal to the original sparse group Lasso. Different correlation levels among variables in true regression models are also studied.  We demonstrate the performance of our method using both simulation experiments and a real data application in lipid trait genetics from the Action to Control Cardiovascular Risk in Diabetes (ACCORD) clinical trial.  Another project with Tao Jiang is focused on a machine learning approach for detecting same-species contamination in next generation sequencing analysis.  In this project, we have developed a machine method relying on support vector machines and corresponding software to detect same species contamination that can occur because of laboratory quality control issues, or from mixed samples in forensic application.  This is the first set of tools that can work directly on the .VCF files, and the approach recognizes a mixture of tumor and normal cells to prevent false positives.  Current extensions are being worked out to estimate the percentage of tumor vs. normal samples, and to estimate the number of individuals within forensic application.  In collaboration with Dr. Denis Fourches, his student Jeremy Ash and post doc Melaine  Kuenemann, my former postdoc Dr. Daniel Rotroff, I have been working on methods to integrate chemical structure information into metabolomics analyses.  Developing predictive and transparent approaches to the analysis of metabolite profiles across patient cohorts is of critical importance for understanding the events that trigger or modulate traits of interest (e.g., disease progression, drug metabolism, chemical risk assessment). However, metabolites' chemical structures are still rarely used in the statistical modeling workflows that establish these trait-metabolite relationships. Herein, we present a novel cheminformatics-based approach capable of identifying predictive, interpretable, and reproducible trait-metabolite relationships. As a proof-of-concept, we utilize a previously published case study consisting of metabolite profiles from non-small-cell lung cancer (NSCLC) adenocarcinoma patients and healthy controls. By characterizing each structurally annotated metabolite using both computed molecular descriptors and patient metabolite concentration profiles, we show that these complementary features enhance the identification and understanding of key metabolites associated with cancer. Ultimately, we built multi-metabolite classification models for assessing patients' cancer status using specific groups of metabolites identified based on high structural similarity through chemical clustering.  Additionally, with Dr. Jung-Ying Tzeng and several other collaborators at NCSU and UNC Chapel Hill, we have developed an approach for testing for associations of single rare variants.  Rare variants are of increasing interest to genetic association studies because of their etiological contributions to human complex diseases. Due to the rarity of the mutant events, rare variants are routinely analyzed on an aggregate level. While aggregation analyses improve the detection of global-level signal, they are not able to pinpoint causal variants within a variant set. To perform inference on a localized level, additional information, e.g., biological annotation, is often needed to boost the information content of a rare variant. Following the observation that important variants are likely to cluster together on functional domains, we propose a protein structure guided local test (POINT) to provide variant-specific association information using structure-guided aggregation of signal. Constructed under a kernel machine framework, POINT performs local association testing by borrowing information from neighboring variants in the 3-dimensional protein space in a data-adaptive fashion. Besides merely providing a list of promising variants, POINT assigns each variant a p-value to permit variant ranking and prioritization  Ongoing projects building onto methods for detecting gene-gene interactions are currently ongoing, using variance QTLs to prioritize single nucleotide polymorphisms for detecting gene-gene interactions. n/a","Methods development for ""Omics"" data",10008737,ZIAES103337,"['3-Dimensional', 'Address', 'Adenocarcinoma', 'Biological', 'Cancer Patient', 'Case Study', 'Chemical Structure', 'Chemicals', 'Classification', 'Clinical Trials', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Descriptor', 'Detection', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Disease Progression', 'Etiology', 'Event', 'Forensic Medicine', 'Genes', 'Genetic', 'Genomics', 'Human', 'Individual', 'Laboratories', 'Lasso', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Non-Small-Cell Lung Carcinoma', 'Normal Cell', 'Patients', 'Performance', 'Postdoctoral Fellow', 'Proteins', 'Publishing', 'Quality Control', 'Quantitative Trait Loci', 'Reproducibility', 'Risk Assessment', 'Sample Size', 'Sampling', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Models', 'Structural Protein', 'Structure', 'Students', 'Testing', 'Variant', 'Work', 'base', 'cardiovascular risk factor', 'causal variant', 'cheminformatics', 'cohort', 'drug metabolism', 'experimental study', 'gene interaction', 'genetic association', 'genome wide association study', 'graduate student', 'high dimensionality', 'improved', 'interest', 'metabolomics', 'method development', 'mutant', 'neoplastic cell', 'next generation sequencing', 'novel', 'prevent', 'protein structure', 'rare variant', 'simulation', 'tool', 'trait', 'tumor']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,ZIA,2019,353374,0.014261749573352715
"Statistical genetics of aging-related genomic and phenotypic change To help to analyze and understand aging-related ""complex"" traits that are affected by many genes and environmental factors, we have followed the path of developing statistical algorithms for the analyses of genome-wide genotyping and high-throughput sequencing studies. Our proposed new computational tools provide means to analyze additional types of data (e.g., to identify mitochondrial DNA (mtDNA) variants and to estimate mtDNA copy number) efficiently from whole-genome sequences. For experimental tests of the algorithms, we are capitalizing on the special advantages of the InCHIANTI project (see Annual Report AG001050) and SardiNIA project (see Annual Report AG000675) to help in the assembly of mitochondrial sequence data and multiple phenotypic data in the two Italian cohorts.   In order to conduct analyses on large-scale consortium data to study mtDNA variation and copy number, we have developed two computational programs, providing a general solution for the analysis of mtDNA dynamics based on whole-genome sequencing studies. One program (mitoCaller) is designed specifically to identify mtDNA variants; the other (mitoCalc) infers mtDNA copy number in a cell directly from genome sequences. Applying the programs to leukocyte sequences of 2,000 SardiNIA participants and 1,000 InCHIANTI participants, we have shown that heteroplasmies (mtDNA variants with more than one allele at a site) increase with age, and that copy number is relatively highly heritable and is correlated with metabolic traits, particularly central fat levels. In more recent work, we have increased the speed of mitoCalc 100-fold (fastMitoCalc). The new program is being applied to white cells of 65,000 deeply sequenced individuals (TOPMed program, NHLBI), for GWAS on copy number. We have also initiated the development of programs to test possible effects of mtDNA variants on traits and diseases.  With our expertise in studying mtDNA variation, we have an ongoing collaborative effort to study a special structural feature of DNA, G-quadruplex (G4) structures, as potential DNA roadblocks that perturb mitochondrial replication machinery. We used computational analyses of 3,000 individual genomes from two Italian cohorts to demonstrate an association between G4s and mtDNA variation. Using the software G4Hunter to predict G4-forming regions in mtDNA, we found statistically significant enrichment of mutations in stable G4 regions, with preferential occurrence of variants in the loop segments of G4 structures. Biochemical studies demonstrated a potent block of human mitochondrial replicative polymerase in DNA synthesis by G4 structure, which could be overcome by the G4-resolving helicase Pif1. Altogether, the computational and biochemical approaches indicate that mtDNA point mutations are enriched at stable G4 structures, consistent with replisome stalling at G-quadruplexes and reliance on error-prone DNA synthesis.  In another study, we have created a program that uses machine learning methods to measure effective rates of aging for individuals. We assess the extent to which an individual's physiological age could be determined as a composite score inferred from a broad range of biochemical and physiological traits from the SardiNIA and InCHIANTI longitudinal studies of aging. Physiological age inferred from our framework was highly correlated with chronological age (R2>0.8). We then defined a physiological aging rate (PAR) for each subject, a continuous trait measured as the ratio of the subjects predicted physiological age to his/her chronological age. We found that PARs were reproducible across follow-up studies, heritable (h2=0.3), and predictive of lifespan and mortality. Genome-wide association studies (GWAS) on the PARs identified both previously established age-associated loci and several new genetic associations. Our findings support a whole-body, pathology-independent aging effect that can be summarized by the physiological aging rate and our method can be used to evaluate the efficacy of treatments that target aging-related processes and disease. n/a",Statistical genetics of aging-related genomic and phenotypic change,10012627,ZIAAG000693,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Algorithms', 'Alleles', 'Ally', 'Annual Reports', 'Biochemical', 'Case-Control Studies', 'Cells', 'Chronology', 'Complex', 'Computer Analysis', 'Computer software', 'DNA', 'DNA biosynthesis', 'DNA copy number', 'Data', 'Disease', 'Environmental Risk Factor', 'Fatty acid glycerol esters', 'Follow-Up Studies', 'G-Quartets', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Leukocytes', 'Longevity', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Metabolic', 'Methods', 'Mitochondria', 'Mitochondrial DNA', 'Mutation', 'National Heart, Lung, and Blood Institute', 'Nuclear', 'Nucleotides', 'Participant', 'Pathology', 'Phenotype', 'Physiological', 'Point Mutation', 'Polymerase', 'Population Control', 'Process', 'Program Development', 'Reproducibility', 'Ribosomal DNA', 'Risk', 'Sardinia', 'Sequence Deletion', 'Site', 'Speed', 'Statistical Algorithm', 'Structure', 'Testing', 'Trans-Omics for Precision Medicine', 'Treatment Efficacy', 'Variant', 'Work', 'age effect', 'base', 'cohort', 'computerized tools', 'design', 'genetic analysis', 'genetic association', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'helicase', 'learning strategy', 'mortality', 'phenotypic data', 'programs', 'trait', 'whole genome']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2019,823193,0.02522952105713075
"NEIGHBORHOOD Consortium for POAG Genetics Primary open-angle glaucoma (POAG) is an intraocular pressure (IOP) related, progressive optic neuropathy that ultimately leads to blindness. Permanent visual field loss from POAG is a condition of public health significance worldwide. The etiology of POAG is poorly understood and primary prevention is not possible. Current treatments can slow but do not cure this progressive neuropathy. The overall goal of our research is to elucidate the pathogenesis of POAG allowing for implementation of effective screening and prevention strategies and development of novel therapies. POAG has significant heritability and recent genome-wide association studies, including our NEIGHBORHOOD GWAS, have identified 30 POAG loci defined by common genomic variants. However, in addition to common variants the complex POAG genetic architecture is likely to also include contributions from rare coding variants as has been discovered for other complex traits. Large-scale studies of rare coding variation and glaucoma have not yet been done. Of the current POAG loci, the majority appear to contribute to disease through elevation of IOP. However, approximately one third of U.S. glaucoma cases are ‘normal’ tension (NTG), charaterized by progressive optic nerve degeneration despite normal IOP. Our prior NTG GWAS identified two loci: 8q22, a loci not found in POAG GWASs and CDKN2BAS, a locus known to effect ganglion cell vulnerability. There results suggest that genes associated with NTG can influence susceptiblity to optic nerve degeneration, and that identification of these optic-nerve-related loci is more likely using NTG cases and controls for GWAS, rather than POAG overall. For the next funding period we propose the following specific aims: 1) complete a larger-scale well-powered NTG GWAS to discover novel loci; 2) assess contributions of rare coding variants to NTG and high-tension POAG (HTG) using whole exome sequencing; 3) explore potential protective effects of dietary factors and medications on cases with high-risk variants in POAG loci related to lipid metabolism and to mitochondrial function; and 4) support additional clinical data collection for the NEIGHBORHOOD. Primary open angle glaucoma (POAG) causes permanent loss of vision and is a condition of public health significance worldwide, affecting millions of people. The etiology of POAG is poorly understood and effective means of primary prevention and curative therapies are not available. In this proposal, our collaborative consortium will complete genetic studies to identify risk factors for POAG and the normal tension subgroup with the ultimate goals of developing effective screening and prevention strategies and novel therapies targeted to the molecular events responsible for the disease.",NEIGHBORHOOD Consortium for POAG Genetics,9819220,R01EY022305,"['ATP binding cassette transporter 1', 'Affect', 'Artificial Intelligence', 'Biological', 'Biological Process', 'Blindness', 'CAV1 gene', 'Clinical Data', 'Code', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Dietary Factors', 'Disease', 'Etiology', 'Event', 'Frequencies', 'Funding', 'Fundus', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic screening method', 'Genetic study', 'Genotype', 'Glaucoma', 'Goals', 'Haplotypes', 'Health system', 'Heritability', 'Human', 'Image', 'Investigation', 'Lipids', 'Machine Learning', 'Mitochondria', 'Molecular', 'Nerve Degeneration', 'Neuropathy', 'Optic Nerve', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiologic Intraocular Pressure', 'Prevention strategy', 'Prevention therapy', 'Primary Open Angle Glaucoma', 'Primary Prevention', 'Process', 'Public Health', 'Research', 'Resources', 'Retinal Ganglion Cells', 'Risk', 'Risk Factors', 'Sampling', 'Subgroup', 'Testing', 'Variant', 'Visual Fields', 'Vitamin B Complex', 'case control', 'clinical phenotype', 'cohort', 'curative treatments', 'exome', 'exome sequencing', 'ganglion cell', 'genetic architecture', 'genetic information', 'genetic variant', 'genome wide association study', 'genome-wide', 'high risk', 'lipid metabolism', 'new therapeutic target', 'novel', 'novel therapeutics', 'optic nerve disorder', 'protective effect', 'protective factors', 'risk variant', 'screening', 'therapeutic target', 'trait']",NEI,MASSACHUSETTS EYE AND EAR INFIRMARY,R01,2019,872775,0.013855591310254139
"Genetic determinants of puberty and later life health outcomes My long-term objective is to build on my existing track record in understanding the genetic mechanisms that influence differences in pubertal developmental timing and how they impact associated adverse health outcomes. Puberty is a key adolescent developmental milestone that is strongly associated with later life health outcomes, such as poor cardiometabolic health, type 2 diabetes, cancer, and osteoporosis. Hundreds of genetic variants across the genome are known to affect the timing of puberty (assessed by age at menarche in girls and age at voice break in boys), but the sex-specific impact of this genetic variation on health outcomes in adolescence and adulthood remain poorly characterized, particularly for boys. Furthermore, another key puberty trait, the pubertal height growth spurt, is less well characterized genetically, but reflects influences from pubertal timing, height growth potential, and body mass, and deeper investigation may reveal novel insights into the links between puberty and health outcomes. During the mentored K99 phase of this proposal, I will use a machine learning approach to choose the best variants across the genome that predict pubertal timing to build optimized polygenic scores (Aim 1a). These male and female-specific polygenic scores will then be tested for association across hundreds of clinical outcomes in biobanks composed of electronic health records (EHR) in tens of thousands of children and adults (Aim 1b). Subsequently, in the independent R00 phase, I will use causal inference analyses to understand the causal impact of genetically determined pubertal timing on identified health outcomes (Aim 1c). Meanwhile, I will combine what I have learned during Aim 1 with my previous expertise to lead a genome-wide association study of the pubertal height growth spurt in the Early Growth Genetics (EGG) consortium, combining longitudinal data from ~35,000 children across multiple cohorts, followed by trans-ethnic fine-mapping (Aim 2a). Finally, I will apply the pipeline developed in Aim 1 to derive PGS for pubertal growth and determine clinically relevant health outcomes linked to differences in pubertal growth trajectories (Aims 2b-d). In this Pathway to Independence proposal, I will complete training in computational and biomedical informatics techniques to capitalize on large-scale data resources, including linked genetic and EHR data from medical and population-based biobanks and longitudinal adolescent cohorts in the EGG consortium. My mentorship committee is composed of a team of world-renowned experts in genomics, informatics, and computational approaches, who have a strong track record in transitioning postdoctoral fellows into independent researchers. Combining my previous expertise with the proposed research and training objectives, together with a strong mentorship team, the securing of EGG leadership in this phenotypic area, and career development activities, I will be uniquely poised to achieve my goal of transitioning to an independent researcher with the skills needed to advance our understanding of the genetic underpinnings of pubertal development and its linked adult outcomes. This research will reveal novel understanding of the sex-specific molecular regulation of pubertal timing and how differences in pubertal timing are related to adverse adult health outcomes. This work will ultimately lead to studies that identify key areas where early interventions may mitigate the negative health effects of earlier or later than average pubertal timing, which serves the NICHD’s mission of ensuring that all children achieve their full potential for healthy lives.",Genetic determinants of puberty and later life health outcomes,9805815,K99HD099330,"['Address', 'Adolescence', 'Adolescent', 'Adult', 'Affect', 'Age', 'Age at Menarche', 'Area', 'Award', 'Bioinformatics', 'Child', 'Childhood', 'Clinical', 'Collaborations', 'Data', 'Development', 'Disease', 'Early Intervention', 'Elderly', 'Electronic Health Record', 'Ensure', 'Etiology', 'Female', 'Foundations', 'Genetic', 'Genetic Determinism', 'Genetic Risk', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth', 'Health', 'Height', 'Heritability', 'Individual', 'Informatics', 'International', 'Investigation', 'Knowledge', 'Lead', 'Leadership', 'Life', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Medical', 'Menarche', 'Mentors', 'Mentorship', 'Meta-Analysis', 'Methods', 'Mission', 'Modeling', 'Molecular', 'National Institute of Child Health and Human Development', 'Non-Insulin-Dependent Diabetes Mellitus', 'Onset of illness', 'Osteoporosis', 'Outcome', 'Pathway interactions', 'Patients', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Prevention strategy', 'Puberty', 'Public Health', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Research Training', 'Risk Factors', 'Secure', 'Signal Transduction', 'Speed', 'Techniques', 'Testing', 'Traction', 'Training', 'Translating', 'Variant', 'Voice', 'Work', 'biobank', 'biomedical informatics', 'boys', 'cardiometabolism', 'career', 'career development', 'clinical care', 'clinical risk', 'clinically relevant', 'cohort', 'data resource', 'experience', 'genetic variant', 'genome wide association study', 'girls', 'informatics training', 'insight', 'longitudinal analysis', 'male', 'men', 'novel', 'phenome', 'population based', 'pubertal timing', 'sex', 'sexual dimorphism', 'skills', 'tool', 'trait', 'virtual']",NICHD,CHILDREN'S HOSP OF PHILADELPHIA,K99,2019,131733,0.011985183576134735
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9786822,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,399965,0.00815219951469505
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9786822,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,400000,0.00815219951469505
"Micropublications for Automating Genome Sequence Variant Interpretation from Medical Literature PROJECT SUMMARY Accurate and efficient interpretation of genomic variants for clinical decision making is predicated on ready access to useful information in the medical literature. The sheer number of potentially relevant articles that must be examined during this curation process poses a major challenge in ensuring the accuracy and reproducibility of clinical variant interpretation as it is time-consuming and the results highly user-dependent. To this end, we have developed the Mastermind Genomic Search Engine - a commercial database that automatically organizes disease, gene and variant information from the medical literature by systematically indexing millions of scientific articles. In direct comparison to manually developed databases of genetic variants, we have achieved greater than 97% concordance and accurately identified >50% more variants with an average of 3-fold more references demonstrating the effectiveness of our automated approach. Currently, Mastermind is used by over 1800 variant scientists in 25 different countries to more quickly curate literature for genetic variants in clinical settings. In response to feedback from ClinGen curators and others, the present proposal seeks to create a framework to facilitate literature curation and clinical variant interpretation activities within Mastermind by 1) prioritizing relevant references and external database entries containing content meaningful to variant classification guidelines, 2) assembling this information into a “micropublication” text format with codified data fields including population frequencies, computational predictions, reference citations and relevant sentence fragments with conclusive content, 3) allowing users to manually review, alter and augment pre-populated entries and 4) providing a platform to share and continuously update this information with other variant scientists in the Mastermind community and elsewhere. Developing tools that allow for collaborative curation in real-time at the point of interaction with source material (i.e. individual articles) will mitigate reproducibility challenges plaguing other large-scale crowd-sourced projects. In contrast to genetic variant databases of user submitted classification information and associated data, the present proposal seeks to create enhanced curation tools to fill such variant databases with more accurate and reproducible data and in a way that would promote dramatic scaling of variant curation activities including those undertaken by groups like ClinVar. To test this approach, we will work with industry partners engaged in variant curation activities to 1) determine the requisite data fields, 2) integrate external database information, 3) test the accuracy and relevance of results and the overall efficacy of the approach using hundreds of manually curated genetic variants, and 4) solicit and incorporate feedback from our development partners to iterate and refine the software features for the greatest effect. Within the $4B genome sequencing software market, there is significant commercial potential and scientific merit in bringing more automated techniques of data analysis to large-scale genome sequencing variant interpretation as described in this proposal. [Word count – 447; Line count - 30] PROJECT NARRATIVE Successful completion of the present project will contribute to the public health mission of the NIH by promoting more widespread adoption of genome sequencing by making the interpretation of genome variant data more accurate, reproducible and cost-effective in clinical and research laboratories. The community of users that can benefit from this work include geneticists, oncologists, pathologists, researchers and patients. [Two sentences]",Micropublications for Automating Genome Sequence Variant Interpretation from Medical Literature,9776985,R43HG010446,"['Address', 'Adoption', 'Algorithms', 'Authorship', 'Blinded', 'Categories', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Communities', 'Computer software', 'Consultations', 'Consumption', 'Country', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Effectiveness', 'Ensure', 'Feedback', 'Frequencies', 'Future', 'Genetic Databases', 'Genome', 'Genomics', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Knowledge', 'Laboratory Research', 'Light', 'Literature', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mission', 'Modification', 'Oncologist', 'Pathogenicity', 'Pathologist', 'Patients', 'Phase', 'Population', 'Population Database', 'Process', 'PubMed', 'Public Health', 'Published Comment', 'Publishing', 'Recommendation', 'Reproducibility', 'Research Personnel', 'Scientist', 'Semantics', 'Source', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Variant', 'Work', 'clinical decision-making', 'clinical practice', 'cost effective', 'crowdsourcing', 'design', 'genetic variant', 'genome sequencing', 'genome-wide', 'indexing', 'industry partner', 'information classification', 'literature citation', 'novel', 'peer', 'preservation', 'response', 'search engine', 'standardize guidelines', 'success', 'tool']",NHGRI,"GENOMENON, INC.",R43,2019,152946,0.02075721528051414
"Integrated Clinical and Transcriptomic Profiling to Characterize Disease Phenotype PROJECT SUMMARY Exome and whole-genome sequencing are becoming increasingly routine approaches in cancer[1], common disease[2]and rare disease diagnosis.[3] Despite their success, our ability to fully interpret the clinical relevance of personal genome variation remains a significant gap[4-6]. Considering this, the most crucial need is more genotype-phenotype data that link genetic variation with disease causation. The objective of this proposal is to improve the clinical interpretation of genetic variation; in particular, by developing integrative approaches that predict the effect of genetic variation on clinical phenotype. This proposal addresses the hypothesis, supported by preliminary data, that combining patient transcriptomic data with genotypic and clinical data (as opposed to each alone) offers a better mechanistic understanding of disease natural history, from initial presentation to progression. The specific aims are designed such that each independently add substantial functional genomic information, over and above previously available patient genetic data, to further resolve the clinical phenotype. Aim 1 establishes a comprehensive and widely-shared dataset of patient transcriptomic (and genetic) variation across multiple cancer, cardiovascular and thrombosis/bleeding phenotypes, in patients with somatically-acquired myeloproliferative neoplasms (MPN) and select other rare heritable blood diseases (HBD). Aim 2 methodically determines differential RNA expression and processing between clinically-relevant subgroups of MPN and HBD patients. Aim 3 brings these elements together – and applies two integrative Bayesian and machine learning approaches, RIVER[24] (RNA-informed variant effect on regulation) and LASSO[25] (Least Absolute Shrinkage and Selection Operator), to resolve the functional and clinical relevance of rare variants; and identify signatures most predictive of disease risk or progression. Completion of these aims will contribute new scientific knowledge on how integrating transcriptomic data improves clinical genomic analyses in other genetic (and rare) diseases. In addition, this project will enable the Principal Investigator to develop expertise in the informatics and data science aspects of genomic medicine that complement her current background in biophysics, biochemistry and translational hematology. Combined with additional informatics training at Stanford University through coursework, seminars, one-on-one advising from project mentors, and interactions with the wider statistics, bioinformatics and genomics communities, this project will prepare the Principal Investigator to launch an independent academic career in genomic medicine. PROJECT NARRATIVE Accurate clinical interpretation of genetic variation in personal genome data is an essential component of personalized medicine approaches and the precise genetic diagnosis toward achieving improved public health. This project will integrate genetic and clinical modifiers with functional genomic information (RNA sequencing) from adequately-powered, disease-relevant cells; and provide direct insight into transcriptional perturbations caused by genetic variation.",Integrated Clinical and Transcriptomic Profiling to Characterize Disease Phenotype,9786811,K08HG010061,"['Address', 'Adult', 'Age Factors', 'Alleles', 'Alternative Splicing', 'Bayesian Modeling', 'Bayesian learning', 'Biochemistry', 'Bioinformatics', 'Biological Markers', 'Biophysics', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood specimen', 'Body mass index', 'Cardiovascular system', 'Cells', 'Clinical', 'Clinical Data', 'Communities', 'Complement', 'DNA Sequence', 'Data', 'Data Science', 'Data Set', 'Databases', 'Demographic Factors', 'Disease', 'Disease Progression', 'Disease stratification', 'Elements', 'Etiology', 'Evaluation', 'Foundations', 'Functional disorder', 'Future', 'Gender', 'Gene Expression', 'Gene Expression Profiling', 'Gene Fusion', 'Genetic', 'Genetic Heterogeneity', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Hematological Disease', 'Hematology', 'Hemorrhage', 'Heritability', 'Informatics', 'Investigation', 'Knowledge', 'Laboratories', 'Lasso', 'Lead', 'Link', 'Malignant Neoplasms', 'Medical Genetics', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Myeloproliferative disease', 'Other Genetics', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Principal Investigator', 'Process', 'Protein Isoforms', 'Public Health', 'RNA', 'RNA Processing', 'Rare Diseases', 'Reference Standards', 'Regulation', 'Research Training', 'Resources', 'Rivers', 'Sampling', 'Severities', 'Subgroup', 'System', 'Thrombosis', 'Tissue-Specific Gene Expression', 'Training', 'Universities', 'Untranslated RNA', 'Validation', 'Variant', 'Whole Blood', 'actionable mutation', 'base', 'biobank', 'career', 'clinical phenotype', 'clinically relevant', 'cohort', 'data integration', 'design', 'disease diagnosis', 'disease natural history', 'disease phenotype', 'disorder risk', 'exome', 'experience', 'functional genomics', 'genetic disorder diagnosis', 'genetic variant', 'genome sequencing', 'genomic data', 'improved', 'informatics training', 'insight', 'knowledge base', 'multidisciplinary', 'novel', 'patient stratification', 'personalized medicine', 'phenotypic data', 'prediction algorithm', 'prospective', 'rare cancer', 'rare variant', 'regression algorithm', 'statistics', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'variant of unknown significance', 'whole genome']",NHGRI,STANFORD UNIVERSITY,K08,2019,190941,0.029221089307737595
"Central Sequencing Initiative Summary of ongoing projects organized by topic:   I. CLINICAL DIAGNOSTICS AND CONSULTATION  A. CLIA reports in CRIS. A central deliverable for our initiative is the clinical analysis and CLIA reporting into the CC medical record. This has been completed for approximately 600 patients since January 2019 and is a major accomplishment.  B. Operational development and refinement. Given the scale of our initiative, we dedicate significant attention to optimizing the efficiency of our workflow and anticipating potential disruptions related to policy adjustment or special circumstances. Specifically, this year we have increased automation of data entry into reporting and tracking processes, developed a new rapid turnaround time workflow for rare cases with high clinical urgency, and developed new CRIMSON workflows related to the new requirement for each patient to have a documented patient visit plan from a physician specifying sequencing prior to order activation.  C. Integration of medical geneticist in suite of consultation offerings. Recognizing room for improvement in our clinical consultation service for complex cases, we've started collaborating with a NIAID-NIAMS medical geneticist and are working concurrently with the NHGRI genetics consult service so we can continue to provide educational opportunities to genetics fellows. This has proven to be a clinically valuable service in multiple cases with complex clinical presentations or clinically significant molecular diagnoses outside the immune system.  D. Reanalysis. Clinical reanalysis of exome data is known to be an important source of new diagnoses over time. We are implementing a limited re-analysis workflow to be alerted to recent publications on variants in our database, which in rare cases provides sufficient evidence to merit a new molecular diagnosis.   E. Childrens collaboration. The CSI works with Gigi Notarangelo to recruit young patients from Children National Health System (site-PI: Mike Keller). The CSI protocol is the first protocol to be formally submitted under the new reliance agreement, paving the way for future studies and opening up a referral source of very young research participants who cannot typically be seen at the CC.   II. DISCOVERY  A. New gene disease discovery. The CSI is contributing to at least three ongoing projects with DIR investigators characterizing new gene-disease relationships. There is a significant opportunity to further exploit this data for discovery.  B. Collaboration with NHGRI on UTR and mosaic variants.  We have an ongoing collaboration with NHGRI to evaluate and develop more effective approaches for detection of clinically relevant variants in the untranslated regions of genes and clinically relevant mosaic variation.  C. Collaboration with multiple groups on computable phenotypic data. The CSI has built a highly valuable dataset of genomic data associated with detailed clinical records, manually coded with relevant phenotypic terms.  The integration of computable phenotypic and laboratory data into genomics is an area of great interest across the field.  We are working with NLM for more efficient text mining approaches, the NIAID epidemiological unit on phenotypic modeling for machine learning in large datasets from other health centers, and other extramural collaborators on tailoring phenotypic data analysis approaches for Mendelian disorders of the immune system.  D. Collaboration with The Genotype Ascertainment Cohort (TGAC), hosted by NHGRI. The CSI seeks to model genomic data sharing approaches that optimize both patient confidentiality and research productivity. In addition to the required deposition into dbGAP, CSI contributes data to TGAC. Exome and genome data from patients in contributing cohorts, including CSI, are available to view in aggregate by DIR researchers. This project is designed to enable further study of individuals via genomic ascertainment without prior knowledge of phenotype.  CSI staff has also participated in the review board for patient access requests.   III. SOCIAL AND BEHAVIORAL RESEARCH, POLICY  A. Negative results comprehension. The CSI is studying patient perceptions and understanding of the inconclusive negative exome results released in the medical record without specific counseling. The objective of this substudy is to use survey and interview data to better understand how well patients understand their negative exome sequencing results and to identify patient characteristics associated with poor understanding. Modification of our policy or specific educational interventions may follow if needed.  B. Secondary findings follow up collaboration. The CSI is collaboratively studying the clinical follow up of secondary findings with researchers at NHGRI.  There is some evidence that a minority of participants do not seek recommended follow up care for the potentially life threatening disorders which are returned on CSI as secondary findings.  The objective of this substudy is to better understand patient cognitive, emotional, and behavioral reactions to receiving a secondary finding, over time, including the motivators and barriers to clinical follow up.  C. Participating in facilitated discussions about policies on genetic research in humans at NIAID DIR. These discussions covered issues about quality of data, quality of analysis, and return of results, primarily focusing on the latter. n/a",Central Sequencing Initiative,10016049,ZICAI001244,"['Address', 'Agreement', 'Area', 'Attention', 'Automation', 'Behavioral', 'Behavioral Research', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Complex', 'Comprehension', 'Confidentiality of Patient Information', 'Consent', 'Consult', 'Consultations', 'Counseling', 'Data', 'Data Analyses', 'Data Discovery', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Education', 'Educational Intervention', 'Emotional', 'Enrollment', 'Epidemiology', 'Evaluation', 'Extramural Activities', 'Feedback', 'Future', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Research', 'Genome', 'Genomics', 'Genotype', 'Health', 'Health system', 'Human', 'Immune System Diseases', 'Immune system', 'Individual', 'Infrastructure', 'Institutes', 'Interview', 'Knowledge', 'Laboratories', 'Language', 'Life', 'Machine Learning', 'Manuals', 'Medical', 'Medical Records', 'Medical center', 'Medicine', 'Mendelian disorder', 'Minority', 'Mission', 'Modeling', 'Modification', 'Molecular', 'Molecular Diagnosis', 'Mosaicism', 'National Human Genome Research Institute', 'National Institute of Allergy and Infectious Disease', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Participant', 'Patients', 'Perception', 'Phenotype', 'Physicians', 'Policies', 'Process', 'Productivity', 'Protocols documentation', 'Publications', 'Reaction', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Robotics', 'Rotation', 'SNP array', 'Secure', 'Services', 'Site', 'Source', 'Specific qualifier value', 'Students', 'Surveys', 'Testing', 'Time', 'United States National Institutes of Health', 'Untranslated Regions', 'Variant', 'Visit', 'Work', 'clinical care', 'clinical diagnostics', 'clinically relevant', 'clinically significant', 'cohort', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'exome', 'exome sequencing', 'follow-up', 'genetic counselor', 'genomic data', 'interest', 'lectures', 'meetings', 'pediatric patients', 'phenotypic data', 'recruit', 'sample collection', 'social', 'text searching']",NIAID,NATIONAL INSTITUTE OF ALLERGY AND INFECTIOUS DISEASES,ZIC,2019,1443862,0.01852857429826889
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9693291,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2019,397125,0.029888191579696397
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9765970,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Simulation', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Imagery', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2019,433604,-0.011948245291722058
"Whole Genome Sequencing in Irish Multiplex Schizophrenia Families Project Summary: Although affected members of multiplex schizophrenia pedigrees have substantially elevated recurrence risk compared to singleton cases, the mean polygenic risk scores between these groups do not differ, suggesting that one source of this higher familial recurrence risk is rare, higher impact variation. We will collect whole genome sequence (WGS) from 600 affected members of multiplex schizophrenia pedigrees to identify rare variation shared by affected individuals within and between pedigrees potentially accounting for the increased recurrence risk, and reducing the `variant space' under consideration. After QC and calling in our existing pipeline, a) familial sequence variants in the exome will be directly analyzed in 2000 Irish cases and 2000 Irish controls with 30X exome sequence data in production currently, and b) variants outside the exome will be imputed into 3600 Irish singleton schizophrenia or bipolar disorder cases and 3000 Irish population controls with GWAS framework data; 3781 additional UK10K controls with 10X WGS are available to increase analysis power. This imputed dataset will be analyzed using recently developed methods for kernel-based tests of variation aggregated over a defined interval (such as a gene) that avoid the inflation of type-1 error. We use multiple sources of genomic information to develop weights for each position in the genome (indexing the prior probability that a change at the site has functional consequence) and each variant detected (indexing the probability that observed changes have functional consequence), and we propose to improve the existing genomic information sources for this weighting in a number of ways. In aim 3, prioritized variants from aim 2a/2b will be directly genotyped in the case/control samples by custom microarray; individual genes or genesets showing enrichment of variation in cases (if any are observed) will be resequenced in the case/control sample. In Aim 4, the directly assessed genotypic and sequence data from aim 3 will be analyzed using standard methods to identify individual associated variants, and variant-enriched genes, genesets or other functional sequences. We seek to unambiguously identify 1) individual variants that are significantly more common in cases, or 2) individual genes or other functional sequences or 3) gene- or functional sequence sets enriched for variation in cases to provide critical information about the brain systems perturbed in schizophrenia, and the mechanisms by which such alleles increase risk. Project Narrative Rare sequence variation has been implicated in many human complex traits, incuding schizophrenia, and has been studied in unrelated cases and controls and parent:offspring trios, but remains unstudied in multiplex families. Sequencing the genomes of such families will allow conprehensive identification of variation in protein coding genes, non-coding expressed loci, regulatory sequences, and evolutionarily conserved regions, as well as detection of structural variation, and testing these alleles in a large case/control series of the same ethnic and geographic origin offers significant advantages over prior study designs, and has the potential to identify individual alleles, variant enriched genes, variant enriched non-genic sequences, and/or variant enriched genesets contributing to SCH risk in the Irish population. Such variants offer great potential for understanding the functional impact of risk alleles and improving mechanistic understanding of schizophrenia and related disorders.",Whole Genome Sequencing in Irish Multiplex Schizophrenia Families,9749268,R01MH114593,"['Accounting', 'Affect', 'Alleles', 'Biological Assay', 'Biology', 'Bipolar Disorder', 'Brain', 'Code', 'Complex', 'Custom', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Face', 'Family', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Human', 'Individual', 'Ireland', 'LGALS3BP gene', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Methods', 'Nucleotides', 'Parents', 'Phase', 'Population', 'Population Control', 'Positioning Attribute', 'Principal Investigator', 'Probability', 'Process', 'Production', 'Proteins', 'Psychotic Disorders', 'Recurrence', 'Research Design', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Schizophrenia', 'Series', 'Signal Transduction', 'Site', 'Source', 'Structure', 'System', 'Testing', 'Untranslated RNA', 'Variant', 'Weight', 'base', 'case control', 'design', 'effective therapy', 'exome', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'indexing', 'member', 'offspring', 'power analysis', 'programs', 'risk variant', 'sample collection', 'trait', 'whole genome', 'working group']",NIMH,VIRGINIA COMMONWEALTH UNIVERSITY,R01,2019,430191,0.002409678583561809
"Biomedical Computing and Informatics Strategies for Infectious Disease Research ﻿    DESCRIPTION (provided by applicant): An important goal of infectious disease research is to develop genetic predictors of susceptibility. Our success in this endeavor will depend critically on the informatics methods and software that are available for making sense of high-dimensional genetic and genomic data. The goal of this research program is to develop, evaluate, distribute and support new and novel biomedical computing algorithms and open-source software for identifying combinations of genetic predictors of clinically important infectious disease outcomes. This application will target the growing body of rare genetic variants identified by high-throughput DNA sequencing. Our clinical application will focus on the prediction of antiretroviral response in clinical trials for HIV/AIDS. We propose here a highly innovative Hierarchical Rare Variant Collapsing Machine (HRVCM) algorithm for identifying and collapsing combinations of rare variants across gene regions (AIM 1). We will then integrate these new collapsed HRVCM variables into our popular Multifactor Dimensionality Reduction (MDR) method that will assess them in combination with common single-nucleotide polymorphisms (SNPs) from genome-wide association studies or GWAS (AIM 2). Our novel HRVCM-MDR approach will, for the first time, make it possible to assess non-additive interactions among sets of rare and common variants simultaneously in genetic studies of infectious diseases. We will apply these new and novel methods to approximately 13 million rare and common variants from nearly 3000 subjects that participated in an AIDS Clinical Trials Group (ACTG) study to evaluate risk for virologic failure with efavirenz-containing antiretroviral therapy (ART) regimens (AIM 3). Finally, we will release all methods as open source to the biomedical research community through our freely available MDR software package (AIM 4). PUBLIC HEALTH RELEVANCE: The overall goal of this application is to develop innovative new computational methods for the genetic analysis of infectious diseases. We will focus on the development of methods that are able to detect synergistic effects of multiple genetic variants regardless of whether they are rare of common in human populations. We will apply these methods to the study of HIV/AIDS vaccination response.",Biomedical Computing and Informatics Strategies for Infectious Disease Research,9658422,R01AI116794,"['AIDS clinical trial group', 'AIDS/HIV problem', 'Algorithmic Analysis', 'Algorithms', 'Anti-Retroviral Agents', 'Bioinformatics', 'Biomedical Computing', 'Biomedical Research', 'Clinical Trials', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Dimensions', 'Disease Outcome', 'Disease susceptibility', 'Failure', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic Segment', 'Goals', 'Graph', 'High-Throughput DNA Sequencing', 'Human', 'Infectious Diseases Research', 'Informatics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Population', 'Predisposition', 'Regimen', 'Research', 'Risk', 'Single Nucleotide Polymorphism', 'Statistical Data Interpretation', 'Time', 'Vaccination', 'Variant', 'antiretroviral therapy', 'base', 'biomedical informatics', 'clinical application', 'clinical predictors', 'design', 'efavirenz', 'gene interaction', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'high dimensionality', 'innovation', 'method development', 'novel', 'open source', 'programs', 'public health relevance', 'rare variant', 'response', 'simulation', 'success', 'virology']",NIAID,UNIVERSITY OF PENNSYLVANIA,R01,2019,475263,0.05388442562430904
"Statistical Methods For Genetic Epidemiology Despite some advances due to the extensive work that has been done to associate genetic variants with diseases, those variants explain a small proportion of the heritability of most heritable health problems.  The birth defect, oral cleft, is a good example.  The recurrence risk is know to be about 30-40 fold in a subsequent sibling, but known variants explain little of that recurrence. Given the protective redundancy designed into many biologic pathways, it may be that a number of particular SNPs must be simultaneously present before this defect is expressed. Given that combination, an environmental exposure might also be important. The availability of our algorithm for simulating genomic data with realistic linkage structure provides us with a laboratory for development of new methods for assessing both GxGxG interactions and GxGxE interactions. n/a",Statistical Methods For Genetic Epidemiology,10007472,ZIAES040007,"['Affect', 'Algorithms', 'Biological', 'Biometry', 'Book Chapters', 'Bronchopulmonary Dysplasia', 'Case Study', 'Chromosome Mapping', 'Collaborations', 'Complication', 'Computer software', 'Congenital Abnormality', 'Data', 'Data Set', 'Defect', 'Disease', 'Environmental Exposure', 'Environmental Risk Factor', 'Family', 'First Degree Relative', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic study', 'Genotype', 'Health', 'Heritability', 'Individual', 'Joints', 'Life', 'Linkage Disequilibrium', 'Machine Learning', 'Mediating', 'Methods', 'Mitochondria', 'Modeling', 'Nuclear', 'Paper', 'Parents', 'Pathway interactions', 'Pennsylvania', 'Premature Birth', 'Preparation', 'Proxy', 'Publishing', 'Recurrence', 'Risk', 'Siblings', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Survivors', 'Toy', 'Triad Acrylic Resin', 'Universities', 'Variant', 'Very Low Birth Weight Infant', 'Work', 'base', 'case control', 'design', 'disorder risk', 'early onset', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genomic data', 'improved', 'laboratory development', 'novel strategies', 'oral cleft', 'simulation', 'trait']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,ZIA,2019,247362,0.014448004630616294
"Modulation of Lung Disease by Genetic/Epigenetic Profiling Project Summary/Abstract Therapeutic management of lung disorders hallmarked by the loss-of-function of the Cystic Fibrosis (CF) Transmembrane conductance Regulator (CFTR) leading to CF are challenged by genetic and epigenetic diversity found in the CF population. Given the Precision Medicine Initiative (All of Us for You (https://allofus.nih.gov/) and the large amount of genomic and phenomic diversity found in patients, it is now generally recognized that we must find new approaches to address the complexity in CF presentation in the clinic. This will require an understanding of fundamental principles dictating disease onset at birth, defined by familial genetic variation, and its progression, influenced by epigenetic programs, both unique to the individual. This proposal is about understanding the role of genetic and epigenetic diversity in CF in response to Histone DeACetylase (HDAC) activity. We have shown these relationships to be responsive to the activity of HDACs, proteins that manage the acetylation/deacetylation balance of the genome and the proteome (the epigenome) to integrate the complex functions linking the genome to the proteome and phenome. Based on the premise that the genome and epigenome are sensitive to manipulation(s) that will favor increased functionality of the CFTR variant fold, the objective of this proposal is to mechanistically define the impact of HDAC modulation on CFTR function observed at the bench and the bedside. We hypothesize that CF can be best understood based on the rationale that disease can be defined by the collective of variation found in the CF population that alters CFTR sequence-to-function-to-structure relationships in the individual as now described using Variation Spatial Profiling (VSP) and the new principle of Spatial CoVariance (SCV) (Wang and Balch, 2018, In press). It is the objective of this proposal to apply VSP/SCV to analysis of the role of the epigenome in CF. Key goals to be achieved in this proposal are to 1) define molecular, cellular and physiological states that 2) describe the role of genetic/epigenetic/proteomic diversity in the CF population to 3) provide a sequence-to-function-to-structure characterization of disease in the individual. Aim 1 will explore the impact of HDAC inhibitors (HDACi) to define, from a biochemical/genetic diversity perspective, how variation across the entire CF population will respond to rebalancing of acetylation/deacetylation dynamics. Aim 2 will focus on the role of HDAC7 in the management of CF genetic diversity using molecular, biochemical and cellular approaches. Aim 3 will analyze the role of select HDAC7-sensitive CFTR interactors to address their role in the management of CF variation from an epigenetic perspective. We hypothesize that the completion of these Aims will describe relationships in the population that define the epigenome-linked genome features that impact progression of CF in the individual. Our integrated genome/epigenome/proteome platform will advance our understanding of the contribution of genetic diversity in the progression and management of CF as a complex disease. Project Narrative CF is a complex loss-of-function disease caused by genetic and epigenetic variation in the Cystic Fibrosis Transmembrane conductance Regulator (CFTR). We will focus on understanding spatial relationships defined by genetic diversity across the CF population that are sensitive to Histone DeACetylase (HDAC) activity to understand the role of the acetylation/deacetylation balance in facilitating function in the individual. We will use a combination of genomic/epigenomic/proteomic approaches based on the principles of Variation Spatial Profiling (VSP) and Spatial CoVariance (SCV) to dissect the role of HDAC in integrated pathways that affect CFTR variant synthesis, folding, trafficking and stability/function at the cell surface that may be responsive to chemical and/or biological manipulation of the epigenome.",Modulation of Lung Disease by Genetic/Epigenetic Profiling,9739114,R01HL095524,"['Acetylation', 'Address', 'Affect', 'Amino Acids', 'Automobile Driving', 'Biochemical', 'Biochemical Genetics', 'Biological', 'Biology', 'Birth', 'Cell Death', 'Cell surface', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Collection', 'Complex', 'Cystic Fibrosis', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Deacetylation', 'Disease', 'Disease Progression', 'Environment', 'Epigenetic Process', 'Equilibrium', 'Fibrosis', 'Funding', 'Gaussian model', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'HDAC7 histone deacetylase', 'Health', 'Histone Deacetylase', 'Histone Deacetylase Inhibitor', 'Human', 'Immune', 'Individual', 'Inflammatory Response', 'Lead', 'Link', 'Lung diseases', 'Machine Learning', 'Membrane', 'Mendelian disorder', 'Modification', 'Molecular', 'Mucous body substance', 'Onset of illness', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Precision Medicine Initiative', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Role', 'Structure', 'System', 'Therapeutic', 'Tissues', 'Variant', 'base', 'bench to bedside', 'cystic fibrosis patients', 'epigenetic profiling', 'epigenetic variation', 'epigenome', 'epigenomics', 'genomic platform', 'healthspan', 'insight', 'loss of function', 'novel strategies', 'phenome', 'phenomics', 'programs', 'response', 'spatial relationship', 'success', 'trafficking', 'transcription factor']",NHLBI,SCRIPPS RESEARCH INSTITUTE,R01,2019,483750,0.023575375927765752
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9658524,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'actionable mutation', 'base', 'disease phenotype', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'learning strategy', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2019,305167,0.010289206738990645
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9616870,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'cost', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'novel sequencing technology', 'phenotypic data', 'pleiotropism', 'population stratification', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2019,297373,0.06363588442940873
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9693289,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'analysis pipeline', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2019,864186,0.06065930035622768
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9731524,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'nonsynonymous mutation', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2019,300000,-0.01868828976759812
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9825986,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Simulation', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'actionable mutation', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2019,232291,0.0037676289542466195
"Systems Biology Analysis of Cardiac Electrical Activity and Arrhythmias. Cardiac arrhythmias are a leading cause of morbidity and mortality in the United States. Abnormalities in heart rate, cardiac conduction (PR and QRS) and repolarization (QT) measured on the ECG predispose to the clinically important cardiac arrhythmias of atrial fibrillation (AF) and ventricular fibrillation (VF) / sudden cardiac death (SCD). We examine the genomic basis of these ECG endophenotypes in order to deconstruct arrhythmias into more proximate traits and discrete components, allowing us to better understand underlying mechanisms, provide insight into arrhythmia generation, and help target development of novel therapies.  The molecular architecture of cardiac electrical activity and arrhythmias is not fully understood, but likely involves genomic, epigenomic, and environmental influences. Over the past 10 years, we have identified numerous common loci associated with cardiac electrical activity and arrhythmias, yet these common variants account for only a portion of the heritability of electrophysiologic and arrhythmic phenotypes. The agnostic examination of genotype-phenotype associations employed in genome- wide association studies (GWAS) does not incorporate knowledge of functional genomic regions or important biologic relationships. Additionally, we currently lack an understanding of the molecular mechanisms connecting mostly intergenic and intronic GWAS signals to phenotype. We therefore hypothesize that a systems biology approach integrating genetic sequence variation with omic data (epigenomic, transcriptomic, and proteomic data) will uncover novel associations and elucidate biologic mechanisms associated with arrhythmia-related phenotypes. We further hypothesize that examining the simultaneous association between sequence variation and multiple cardiac electrophysiologic phenotypes will help uncover additional novel mechanisms associated with cardiac electrical activity and arrhythmias.  TOPMed's combination of rich phenotype data, with whole genome sequence (WGS), epigenomic, transcriptomic, and proteomic data, provides a unique opportunity to more comprehensively explore these hypotheses. We leverage sequence, omic, and phenotype data from multiple cohort studies to efficiently and cost-effectively examine and dissect association of omic factors with cardiac electrophysiology and arrhythmia risk. Our application is an ambitious yet eminently feasible effort that integrates clinical, genetic, and systems biology expertise. We aim to discover associations using omics data (Aims 1 and 2) and elucidate specific genes and biologic pathways underlying these associations (Aims 3 and 4). Our ultimate goal is to identify pathways, genes, and genetic variation that are clinically relevant, and therefore potentially the target of new therapies, diagnostics, or risk predictions. Narrative Cardiac arrhythmias are a major cause of morbidity and mortality in the United States. This proposal aims to use genomic, epigenomic, transcriptomic, and proteomic data, combined with complex systems biology and pleiotropic analyses, to better understand the underlying pathways and genes involved in normal electrophysiology and arrhythmia formation. The identification of biologic factors that influence cardiac electrical activity and arrhythmias will provide insight into the mechanisms of arrhythmia generation, and perhaps identify better targets for drug development and prevention.",Systems Biology Analysis of Cardiac Electrical Activity and Arrhythmias.,9737693,R01HL141989,"['Address', 'Affect', 'Architecture', 'Arrhythmia', 'Atrial Fibrillation', 'Bayesian Modeling', 'Biological', 'Biological Factors', 'Biological Process', 'Cardiac', 'Cardiac Electrophysiologic Techniques', 'Clinical', 'Cohort Studies', 'Complex', 'Data', 'Development', 'Diagnostic', 'Drug Targeting', 'Electrocardiogram', 'Electrophysiology (science)', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genomic Segment', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Goals', 'Grouping', 'Heart', 'Heart Rate', 'Heritability', 'Knowledge', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Medical Genetics', 'Methods', 'Methylation', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Multiomic Data', 'Pathway interactions', 'Pattern', 'Phenotype', 'Population', 'Prevention', 'Proteins', 'Proteomics', 'Regulator Genes', 'Risk', 'Signal Transduction', 'Site', 'Systems Biology', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'Variant', 'Ventricular Fibrillation', 'base', 'causal variant', 'clinical phenotype', 'clinically relevant', 'cost', 'drug development', 'endophenotype', 'epigenomics', 'functional genomics', 'genome wide association study', 'heart electrical activity', 'insight', 'mortality', 'new therapeutic target', 'novel', 'novel therapeutics', 'phenotypic data', 'pleiotropism', 'rare variant', 'sudden cardiac death', 'trait', 'transcriptomics', 'whole genome']",NHLBI,UNIVERSITY OF WASHINGTON,R01,2019,490901,0.013407060751618214
"Genetic Factors in Keratoconus DESCRIPTION (provided by applicant): The purpose of this grant is to develop techniques for use in the 'early' detection of keratoconus (KC) and identify genetic variants that contribute to is development. KC is a complex genetic eye disorder and a leading cause of corneal transplantation in the young, with approximately 300,000 affected individuals in the US. Undiagnosed, subclinical KC is one of the major causes for complications of LASIK (Laser-in-situ- Keratomilieusis) surgery, commonly performed for vision correction. In the past two decades we have made major improvements to the early diagnosis of KC and have also made significant contributions to the delineation of major genetic determinants of KC through genome wide linkage studies (GWLS), fine mapping, and genome wide association studies (GWAS). In this proposal, we intend to follow up on these studies using new powerful approaches to achieve the following specific aims: In Aim 1 we will combine corneal optical coherence tomography (OCT) and Pentacam HR Scheimpflug Tomography (PST), new technologies that measure both the anterior and posterior surface of the cornea, with videokeratography (VK), a method which revolutionized KC diagnosis, to characterize criteria and to improve the diagnosis of subclinical KC. In Aim 2, to identify additional KC genes, we will perform a 2.5 million SNP GWAS, with an additional 6,000 SNPs, to fine- map already identified genes. We will confirm these results in a separate cohort of KC patients. For this two- stage GWAS design we are assembling the largest group of KC patients described to date: 2000 KC patients in total, 1,000 for the GWAS discovery stage and 1,000 for the confirmation stage. The controls for GWAS discovery will come from the Cardiovascular Health Study (CHS; 3300) and for confirmation will come from 400 subjects with VK, PST, and OCT measurements under Aim 1 and 600 ""convenience controls"" from the Cholesterol and Pharmacogenetics (CAP) study. In our current state of knowledge, the most cost-effective approach to increase the number of identified KC genes is to proceed with the expanded GWAS proposed herein. In Aim 3, we will test the impact of the genes identified in Aim 2 on the 'early' subclinical phenotypes identified through the use o VK, PST and OCT measures in Aim 1. Lastly, for the second part of Aim 3, we will investigate the potential function of KC variants by testing their ability to influence gene structure, expression and function in corneal cell models, including iPS cells derived from corneal keratocytes developed by our research team. The results of these studies will help advance our understanding of the genetic susceptibility to KC and may result in novel treatment options to slow the progression of the disease. PUBLIC HEALTH RELEVANCE: Improving methods for the 'early' detection of keratoconus will help patients avoid complications of LASIK surgery, allow us to identify genetic variants that contribute to its development, and design therapies to retard its progression.",Genetic Factors in Keratoconus,9634922,R01EY009052,"['Affect', 'Anterior', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cells', 'Clinical', 'Collaborations', 'Complex', 'Cornea', 'Custom', 'Data', 'Development', 'Diagnosis', 'Discriminant Analysis', 'Disease Progression', 'Early Diagnosis', 'Epidemiology', 'Etiology', 'Eye', 'Eye diseases', 'Family member', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Predisposition to Disease', 'Genetic Transcription', 'Genetic Variation', 'Genotype', 'Grant', 'Immunohistochemistry', 'In Situ', 'Individual', 'Keratoconus', 'Keratoplasty', 'Knowledge', 'Laser In Situ Keratomileusis', 'Lasers', 'Lead', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Pathogenesis', 'Patients', 'Pharmacogenetics', 'Phenotype', 'Research', 'Research Design', 'Reverse Transcriptase Polymerase Chain Reaction', 'Risk', 'Structural Genes', 'Surface', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Variant', 'Videokeratographies', 'Vision', 'base', 'bead chip', 'cardiovascular health', 'cholesterol control', 'cohort', 'cost effective', 'design', 'follow-up', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide linkage', 'improved', 'indexing', 'induced pluripotent stem cell', 'new technology', 'novel', 'prevent', 'protein expression', 'protein function', 'public health relevance', 'therapy design', 'tomography', 'tool', 'trait']",NEI,CEDARS-SINAI MEDICAL CENTER,R01,2019,714430,0.028673247548816293
"Integrate gene expression data to characterize the contribution of rare genetic risk factors to structural birth defects Project Summary  We aim to maximize discovery of new risk genes and elucidate the genetic architecture of structural birth defects. To achieve that, we propose cross-disease genetic analysis of both protein-coding and noncoding variants and integration of gene expression data to prioritize candidate risk genes.  Better understanding of the genetic basis of structural birth defects will lead to new insights into human developmental biology and will provide targets for medical intervention and treatment. Recent large-scale genome and exome sequencing studies of birth defects have identified new risk genes, especially through the analysis of de novo variants in protein coding regions. However, we are still far from complete understanding of the genetic causes of birth defects. Estimates are that there are 400- 800 risk genes of large effect size for birth defects such as congenital heart disease, and the vast majority of these genes are unknown. This is primarily due to the lack of statistical power. While increasing sample size is essential and is part of the core deliverables of the Gabriella Miller Kids First (GMKF) programs, we also need to develop and apply new analytical methods that improve power and maximize the utility of the available genetic data by using other types of data and biological knowledge. In addition, in most prior studies, the analysis of rare genetic variation has been focused on small variants in the coding regions or large copy number variants (CNV). The data and methods to interrogate the contribution of rare noncoding variants is rudimentary, limiting our understanding of genetic architecture of these diseases. In this study, we propose two aims to address these questions by leverage GMKF cross-disease whole genome sequencing data sets: Specific Aim 1. Elucidate genetic architecture by cross-disease analysis of rare coding and non-coding variants. Specific Aim 2. Integrate gene expression with genome sequencing data to improve discovery and biological interpretation of risk genes of structural birth defects.  The proposed study will maximize the genetic discovery potential of the GMKF WGS data sets for birth defects and improve our understanding of the pleiotropic effects and tissue specificity of risk genes and variants. The analytical approaches developed in this study will be applicable to genetic data of birth defects and developmental disorders from future GMKF cohorts and other programs. Project Narrative We propose to analyze whole genome sequencing data from the Gabriella Miller Kids First cohorts using new computational approaches that maximize the risk gene discovery and improve interpretation of candidate genes. Our research will enhance the utility of Kids First program generated data and improve our understanding of the genetics of birth defects.",Integrate gene expression data to characterize the contribution of rare genetic risk factors to structural birth defects,9727073,R03HL147197,"['Address', 'Award', 'Bioinformatics', 'Biological', 'Candidate Disease Gene', 'Code', 'Collaborations', 'Computing Methodologies', 'Congenital Abnormality', 'Congenital diaphragmatic hernia', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Developmental Biology', 'Disease', 'Ensure', 'Esophageal', 'Funding', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Risk', 'Genetic Transcription', 'Genetic Variation', 'Human', 'Human Development', 'Intervention', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Methods', 'Molecular', 'Multiple Birth Offspring', 'Neurodevelopmental Disorder', 'Open Reading Frames', 'Organ', 'Pathway interactions', 'Pattern', 'Proteins', 'Research', 'Role', 'Sample Size', 'Specificity', 'Structural Congenital Anomalies', 'Structural Genes', 'Tissues', 'Untranslated RNA', 'Variant', 'analytical method', 'autism spectrum disorder', 'base', 'body system', 'brain cell', 'cell type', 'cohort', 'congenital heart disorder', 'developmental disease', 'dosage', 'exome', 'exome sequencing', 'functional genomics', 'gene discovery', 'genetic analysis', 'genetic architecture', 'genetic risk factor', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'improved', 'insight', 'interest', 'learning strategy', 'novel', 'pleiotropism', 'programs', 'rare variant', 'risk variant', 'single-cell RNA sequencing', 'whole genome']",NHLBI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2019,157574,0.014531710450492646
"PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A) PROJECT SUMMARY  Since its inception 40 years ago, in vitro fertilization (IVF) has resulted in the birth of more than 1 million babies in the United States, and has revolutionized the field of reproductive medicine. Unfortunately, the success rate of IVF is still exceedingly low, especially for women >40 years old, with only 15.5% of implanted embryos resulting in pregnancy. This is partly due to the cytological method used for pre-implantation screening, which cannot detect the most common genetic defect during IVF, aneuploidy (i.e. chromosomal copy-number variation). Aneuploidy is linked to higher rates of miscarriage, and occurs more often in women >40 years of age; thus, aneuploidy has been a frequent target for genetic screening to improve IVF outcomes.  Pre-implantation genetic testing for aneuploidy (PGT-A) refers to a variety of techniques aimed at detecting changes in chromosomal copy number, with the goal of identifying high-quality euploid embryos for implantation. Recent advances in next-generation sequencing (NGS) technologies have made it possible to screen embryos at higher levels of precision, and across a wider range of genetic defects, including mosaicism, triploidy and single nucleotide polymorphisms (SNPs). Despite these remarkable advances, there are still significant challenges with PGT-A sequencing. Indeed, the most commonly implemented software for PGT-A (i.e. BlueFuse® ) are bundled with specific sequencing platforms (i.e. VeriSeq®), and are only designed to test for aneuploidy. Furthermore, existing pipelines are not user-friendly or customizable, which is a serious obstacle prohibiting the use of NGS by clinicians / embryologists. A more accessible bioinformatics platform is desperately needed that will bridge the gap between PGT-A sequencing and IVF outcomes.  Basepair™ is an innovator in efficient, user-friendly, web-based NGS analysis systems, with fully automated ChIP-, RNA-, ATAC-, and DNA-Seq bioinformatics pipelines available online. Here, Basepair will deliver PiNDA™, the first fully integrated software solution for comprehensive PGT-A analysis. In Aim 1, we will develop modules to test for specific chromosomal abnormalities, including mosaicism and triploidy, and validate each model with training data derived from somatic cell lines with known chromosomal aberrations. In Aim 2, we will integrate our modules into the PiNDA software system, creating a user-friendly, web-based interface that will perform full data analysis (raw data to full summary report) in <15 minutes, with no manual input required. Final data will be accessible via Basepair’s online portal, facilitating rapid data transfer from embryologists to physicians, and supporting the integration of NGS tests in IVF. Our innovative bioinformatics platform will accelerate NGS analysis for IVF, improving rates of pregnancy and advancing research in the success of IVF procedures. PROJECT NARRATIVE  In vitro fertilization (IVF) methods have begun to leverage next-generation sequencing technologies for pre-implantation genetic testing of aneuploidy (PGT-A), expanding the array of chromosomal abnormalities that can be accurately detected. However, the vast majority of software can only distinguish one type of genetic defect (i.e. aneuploidy), are difficult to use, and are tied to distinct sequencing platforms, limiting the clinical utility of resulting analyses. Basepair™ Inc. is a pioneer in user-friendly, web-based bioinformatics pipelines, providing comprehensive services for a wide range of sequencing projects. Here, Basepair will develop an inclusive suite of software for PGT-A, compatible with sequencing data from multiple platforms. This product will be of high value to the field and will help bridge the gap between advances in DNA sequencing and IVF technology.",PiNDA - Fully integrated software platform for Preimplantation Genetic Testing - Aneuploidy (PGT-A),9846492,R43HD100280,"['ATAC-seq', 'Age-Years', 'Algorithms', 'Aneuploid Cells', 'Aneuploidy', 'Bioinformatics', 'Biopsy', 'Birth', 'Cell Line', 'Cell division', 'Centers for Disease Control and Prevention (U.S.)', 'ChIP-seq', 'Chromosome abnormality', 'Clinical', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'Culture Media', 'Cytology', 'DNA sequencing', 'Data', 'Data Analyses', 'Embryo', 'Feedback', 'Fertility Agents', 'Fertilization in Vitro', 'Genetic Screening', 'Goals', 'Harvest', 'Implant', 'Letters', 'Link', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Morphology', 'Mosaicism', 'Mutation', 'Online Systems', 'Outcome', 'Phase', 'Physicians', 'Polymorphism Analysis', 'Pregnancy', 'Pregnancy Rate', 'Preimplantation Diagnosis', 'Procedures', 'Reporting', 'Reproductive Medicine', 'Research', 'Role', 'Sampling', 'Services', 'Single Nucleotide Polymorphism', 'Somatic Cell', 'Specificity', 'Spontaneous abortion', 'Summary Reports', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Training', 'Triploidy', 'United States', 'Uterus', 'Woman', 'analysis pipeline', 'aneuploidy analysis', 'cell free DNA', 'design', 'early embryonic stage', 'egg', 'implantation', 'improved', 'innovation', 'natural Blastocyst Implantation', 'next generation sequencing', 'phase 1 study', 'preimplantation', 'screening', 'sequencing platform', 'software development', 'software systems', 'sperm cell', 'success', 'transcriptome sequencing', 'user-friendly', 'web based interface']",NICHD,"BASEPAIR, INC.",R43,2019,298717,0.016276345082232854
"Cardiac genetic effects across HLBS phenotypes Forward genetic genome-wide association studies (GWAS) have successfully mapped thousands of loci regulating disorders of the heart, lung, blood and sleep (HLBS), implicating widespread sequence variation within the non-coding genome. However, their functions, mechanisms of action and how they impact disease is still unclear. To solve this new and important GWAS bottleneck, we use a functional genomics-inspired reverse genetics strategy to identify the `transcriptional machinery' (transcription factors (TF), cis-regulatory elements (CRE), target genes) controlling HLBS-relevant tissue functions and how DNA variants in them affect HLBS diseases. Taking advantage of our long-standing expertise and successes in complex, cardiovascular disorders, and novel computational methods we have recently developed, we propose novel genomics analyses of the Trans-Omics for Precision Medicine (TOPMed) Program phenotypes and their whole genome sequences, together with publicly available epigenomics data, to identify the molecular bases of HLBS disease. We will first focus on the transcriptional machinery controlling heart physiology and its disorders before exploring other HLBS-relevant tissues and disorders in collaboration with other TOPMed investigators. Our specific aims are: (1) Identifying the transcriptional machinery in the heart and other HLBS relevant tissues; and, (2) Connecting genomic variation in the transcriptional machinery to HLBS traits. Our approach will enable identification of the core molecular components that control HLBS tissues and how they are compromised in HLBS disorders. The major hypothesis explaining the results of heart, lung, blood and sleep (HLBS) genome-wide association studies (GWAS) is that sequence variants at specific cis-regulatory elements (CRE or enhancer) affect the binding of their cognate transcription factors (TF) to alter expression of specific HLBS genes and, thereby, modulate variation in the phenotype and disorders. In this proposal, we advance new computational approaches to identify the `transcriptional machinery' (TF, CRE, target genes) controlling HLBS-relevant tissue functions so that the effects of causal genetic variation can be identified within identified trait loci genome- wide. This tissue-based view provides an alternative, complementary approach for understanding HLBS trait and disease variation, a major public health challenge.",Cardiac genetic effects across HLBS phenotypes,9692018,R01HL141980,"['ATAC-seq', 'Affect', 'Algorithms', 'Base Pairing', 'Binding', 'Blood', 'Cardiac', 'Cardiovascular Diseases', 'Chromatin', 'Code', 'Collaborations', 'Complex', 'Computing Methodologies', 'DNA', 'DNase I hypersensitive sites sequencing', 'Data', 'Disease', 'Enhancers', 'Family', 'Gene Expression', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Heart', 'Heart Diseases', 'Hematological Disease', 'Individual', 'Lead', 'Link', 'Lung', 'Lung diseases', 'Machine Learning', 'Maps', 'Minor', 'Modeling', 'Molecular', 'Peripheral', 'Phenotype', 'Physiology', 'Public Health', 'Publishing', 'Quality Control', 'Regulator Genes', 'Regulatory Element', 'Research Personnel', 'Resources', 'Role', 'Sample Size', 'Sleep', 'Sleep Disorders', 'Testing', 'Tissues', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Weight', 'base', 'causal variant', 'epigenomics', 'functional genomics', 'gene discovery', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'genomic data', 'genomic variation', 'histone modification', 'improved', 'novel', 'novel strategies', 'programs', 'rare variant', 'reverse genetics', 'success', 'trait', 'transcription factor', 'transcriptome sequencing', 'whole genome']",NHLBI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,436249,-0.03364842301999166
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9702844,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'causal variant', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genome sequencing', 'genome-wide', 'human disease', 'human model', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'web server', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,300191,0.03529626778050059
"Massively parallel functional analyses of human PTEN variants Project Summary  We are now able to routinely sequence human genomes at single-base resolution. However, our ability to interpret the functional consequences of detected mutations has lagged behind. Computational approaches scale well but have poor accuracy, whereas retrospective analysis of detected variants has high accuracy but does not scale well. In order to solve this problem, a new experimental paradigm has emerged to empirically characterize the effects of mutations with high accuracy at scale. This approach takes advantage of recent and ongoing improvements in DNA synthesis and sequencing, and has the potential to offer unprecedented insight into protein biochemistry and human disease. We believe these insights will prove to be critical for unlocking the potential of genomic medicine.  In this project we seek to comprehensively assess multiple molecular effects of PTEN mutations on protein function, and assess the utility of this data as a predictor for human clinical phenotype. The PTEN protein is a tumor suppressor that is frequently mutated in diverse human cancers and in the germline of some individuals with overgrowth disorders, cancer predisposition syndromes, or autism. Currently, it is impossible to predict the effects of the vast majority of PTEN germline mutations. Since the phenotypic spectrum of PTEN mutation carriers is broad, it would be highly valuable to understand the ways in which phenotypic outcomes arise from PTEN mutation genotypes.  In Aim 1, we will first employ a yeast-based screen to assess the effects all PTEN single amino acid mutations on lipid phosphatase activity, the primary biochemical function of PTEN protein. It is known that several pathogenic variants are destabilized. Therefore, in Aim 2, we will perform a second, independent screen to assess the steady state protein stability of all PTEN single amino acid mutations. In Aim 3, we will use the data derived from this study as well as publically available biochemical information to train a classifier model to predict the relationship between the mutation genotypes and clinical phenotypes observed in humans. These data will increase our fundamental understanding of PTEN function and the role of mutations in diverse disorders, and could provide a valuable clinical tool that would increase the quality of life for PTEN mutation carriers. Project Narrative  Mutations in the gene PTEN are causal for a diverse set of clinical disorders ranging from cancer to autism spectrum disorder. Here, we seek to gain new fundamental insights into the functional relationships between PTEN mutations and clinical presentations by prospectively characterizing the effects of all single amino acid PTEN mutations in parallel. These data will allow the creation of new models that can predict risk of specific PTEN mutations for different clinical outcomes and potentially lead to personalized therapies, early interventions, and optimal outcomes for PTEN mutation carriers.",Massively parallel functional analyses of human PTEN variants,9794010,F31HD095571,"['Affect', 'Amino Acids', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biology', 'Biophysics', 'Cataloging', 'Catalogs', 'Cell Separation', 'Cell Survival', 'Cells', 'Characteristics', 'Clinic', 'Clinical', 'Complex', 'Coupled', 'Coupling', 'DNA biosynthesis', 'DNA sequencing', 'Data', 'Data Set', 'Deletion Mutation', 'Development', 'Disease', 'Early Intervention', 'FRAP1 gene', 'Fluorescence', 'Genes', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Germ-Line Mutation', 'Goals', 'Growth', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Lead', 'Light', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Metabolism', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Outcome', 'PTEN gene', 'PTEN protein', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Phosphatidylinositols', 'Phosphoric Monoester Hydrolases', 'Play', 'Predisposition', 'Problem Solving', 'Process', 'Protein Biochemistry', 'Proteins', 'Pythons', 'Quality of life', 'Reaction', 'Resolution', 'Risk', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Syndrome', 'Techniques', 'Temperature', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tumor Suppressor Proteins', 'Ubiquitination', 'Variant', 'Yeast Model System', 'Yeasts', 'accurate diagnosis', 'autism spectrum disorder', 'base', 'clinical phenotype', 'experimental study', 'fitness', 'genomic signature', 'genomic variation', 'high throughput technology', 'human disease', 'improved', 'insight', 'mutation carrier', 'next generation', 'novel', 'open source', 'personalized medicine', 'prediction algorithm', 'predictive modeling', 'prospective', 'protein function', 'screening', 'synthetic biology', 'tool', 'tumorigenic']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,F31,2019,45016,-0.028597242523643228
"Discovering Novel Structural Genomic Rearrangements Using Deep Neural Networks Abstract Accurately detecting structural variation in the genome is a challenging task. Many approaches have been developed over the last few decades, yet it is estimated that tens of thousands of variants are still being missed in a given sample. Many of these variants are missed due to the limitations of using short-read sequencing to identify large variants. Although many of these missed variants are located within complex regions of the genome, it has been shown that some still have clinical relevance making their discovery important. New platforms have been developed for sequencing the genome using long-reads and show promise for overcoming many of these limitations creating the ability to identify the full spectrum of simple and complex structural variants. Because this technology is relatively young, new computational approaches to support the analysis of long-read sequencing data can aid in the discovery of these variants which are still being missed. In addition to detecting novel variation in samples with long-read sequencing data, computational approaches can be developed to leverage these novel variant calls to reanalyze the hundreds of thousands of short-read datasets currently available. In this proposal, we plan to develop new computational approaches to identify novel structural variation in the genome. In Aim 1, we will apply a recurrence approach to analyze long read sequencing datasets utilizing deep neural networks. In Aim 2, we will develop a tool to derive profiles of structural variants predicted in long- reads which can be used to identify and genotype structural variants calls in short read data-sets. Together, these approaches will allow researchers to accurately characterize structural variation in both long and short- read datasets. Narrative Structural variation has been implicated in numerous human diseases but there are still tens of thousands of variants being overlooked in the genome. The proposed research aims to detect novel variation by developing new computational tools to analyze data generated by state-of-the-art sequencing methods. These tools will aid in the discovery of variants associated with human health.",Discovering Novel Structural Genomic Rearrangements Using Deep Neural Networks,9755117,F31HG010569,"['Affect', 'Algorithms', 'Benchmarking', 'Biological Sciences', 'Categories', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Resequencing', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Future', 'Genome', 'Genotype', 'Haplotypes', 'Health', 'Human', 'Human Genome', 'Image', 'Image Analysis', 'Label', 'Methods', 'Molecular', 'Molecular Computations', 'Pattern', 'Process', 'Recurrence', 'Repetitive Sequence', 'Research', 'Research Personnel', 'Sampling', 'Structure', 'Techniques', 'Technology', 'Training', 'Validation', 'Variant', 'base', 'clinically relevant', 'comparative', 'computerized tools', 'cost', 'deep learning', 'deep neural network', 'design', 'genome sequencing', 'human disease', 'insertion/deletion mutation', 'new technology', 'novel', 'reference genome', 'structural genomics', 'tool']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F31,2019,37153,0.036809251200961686
"EMR-Linked Biobank for Translational Genomics ﻿    DESCRIPTION (provided by applicant): Medical care informed by genomic information is beginning to move into clinical practice. The Electronic Medical Records and Genomics (eMERGE) network through its initial phases has provided much of the groundwork for this transformation. The Geisinger Health System project, ""EMR-Linked Biobank for Translational Genomics"" intends to build on the knowledge and experience from eMERGE phase II to accelerate discovery and implementation while expanding our understanding of the sociocultural implications of genomics in medicine. We will accomplish this goal through three specific aims: 1) Use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery in the proposed disorders: familial hypercholesterolemia and chronic rhinosinusitis, 2) Develop and test approaches for implementation of genomic information in clinical practice, 3) Explore, develop and implement novel approaches for family-centered communication around clinically relevant genomic results. We currently have over 60,000 patients broadly consented for research with a large and increasing proportion consented for return of results and deposition in the electronic health record. Over 18,000 patients are genotyped on high density platforms. Our two proposed phenotypes, familial hypercholesterolemia (FH) and chronic rhinosinusitis (CRS) were chosen because both conditions have a significant public health impact in the United States, but they are also ideally suited to the specific aims of the project. They provide opportunities for innovation and extension of current eMERGE methods. While many of these innovations will take advantage of the sequencing done as part of the project, there are several other areas emphasized in the funding opportunity that will broaden the scope of eMERGE research. One of the areas of emphasis for eMERGE III is exploring the familial return of actionable results. FH is well suited to this, as the current clinical recommendation is cascade testing of family members for all diagnosed patients. Currently this relies on the patient to contact at risk family members, but this is less than optimal. We will explore this issue using qualitative and quantitative methods and use the results to design and test novel family communication strategies. Gene-environment interactions play an important role in the development and severity of disease. These are very difficult to study. We propose novel approaches that leverage the assets of Geisinger Health System and the eMERGE Network to develop and apply methods to extend existing projects that study the impact of environment on CRS. This would include the first large scale environment-wide association studies (EWAS). Finally, we propose to lead efforts to apply the tools of economic modeling and analysis to eMERGE projects to begin to quantify the value of implementation of genomic medicine in the US healthcare system. These proposed innovations will magnify the already significant impact that the eMERGE program has had in moving genomic medicine from a dream to a reality. PUBLIC HEALTH RELEVANCE: Through this application GHS seeks to continue its participation in the eMERGE Network for Phase III - Study Investigators U01 (RFA-HG-14-025) funding opportunity. We propose 3 specific aims: 1) use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery and validation of gene-phenotype associations; 2) develop and test approaches for implementation of genomic information in clinical practice; develop and implement novel approaches for family-centered communication around clinically relevant genomic results",EMR-Linked Biobank for Translational Genomics,9902000,U01HG008679,"['Adult', 'Algorithms', 'Ambulatory Care', 'Area', 'Attitude', 'Candidate Disease Gene', 'Caring', 'Catchment Area', 'Child', 'Clinical', 'Communication', 'Computerized Medical Record', 'Consent', 'County', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Dreams', 'Economic Models', 'Ecosystem', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Ensure', 'Environment', 'Familial Hypercholesterolemia', 'Familial disease', 'Family', 'Family member', 'Foundations', 'Funding Opportunities', 'Generations', 'Genes', 'Genomic medicine', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Group Practice', 'Health', 'Health Insurance', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Information Systems', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Integrated Health Care Systems', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Outcome Study', 'Participant', 'Patient Care', 'Patients', 'Pennsylvania', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Population', 'Process', 'Prognostic Factor', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Rural', 'Rural Population', 'Safety', 'Severity of illness', 'Site', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Treatment outcome', 'United States', 'Validation', 'Variant', 'base', 'biobank', 'case finding', 'chronic rhinosinusitis', 'clinical care', 'clinical practice', 'clinically relevant', 'density', 'design', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genotyped patients', 'implementation research', 'implementation strategy', 'innovation', 'inpatient service', 'interest', 'meetings', 'novel', 'novel strategies', 'personalized health care', 'phase 3 study', 'phenome', 'population based', 'programs', 'public health relevance', 'screening', 'tool', 'trait', 'translational genomics', 'treatment response']",NHGRI,GEISINGER CLINIC,U01,2019,730148,0.021998801240977726
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9593020,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Tests', 'Heritability', 'Human', 'Infrastructure', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deaf', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hard of hearing', 'hearing impairment', 'hearing loss phenotype', 'hearing preservation', 'hearing threshold', 'hereditary hearing loss', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2019,480576,0.041186791525711405
"IBD Gene Mapping by Clinical and Population Subset PROJECT SUMMARY Inflammatory bowel disease (IBD), Crohn's disease (CD) and ulcerative colitis (UC) are complex genetic disorders of the gastrointestinal tract, and a major health burden to patients and society. Tremendous progress has been made in dissecting IBD genetic etiology with identification of over 200 IBD loci by genome wide association studies (GWAS) but mainly limited to persons of European ancestry. The IBD Genetics Consortium (IBDGC) was established to facilitate multicenter collaborative studies of 6 Genetics Research Centers (GRCs) organized with a Data Coordinating Center (DCC). Our GRC at Johns Hopkins (JHGRC) has contributed to all IBDGC studies, meeting recruitment objectives and taking roles in IBDGC leadership positions. Our particular focus is on African American (AA) IBD genetics. We performed the first large-scale evaluation of European loci in the AA population, replicating several genes, but also finding unique African-ancestral variants within these loci, as well as identified multiple admixture significant loci. We also published the first AA IBD genome-wide association study (GWAS), a collaborative effort that identified two African-specific gene loci, and replicated multiple additional European loci. We have also explored why some loci with proven risk variants in Europeans and other populations only cause disease in one ancestral population but not others. More research in AA IBD is needed to understand the etiology of IBD in this ancestrally distinct, major American population. In this application we will re-evaluate the AA GWAS by better imputation, evaluate whole genome sequencing data to test low frequency and rare variants, and perform an evaluation for chromosome X variants. We will recruit a large number of AA IBD patients through our own and multiple Satellite Recruitment Centers to power a second AA IBD GWAS, both UC and CD, and meta-analyze with the first to identify more novel loci, identify more African specific risk variants, and replicate known loci for this population and replicate our admixture loci. We will also incorporate diverse data sources to incorporate into our GWAS analyses including RNA-Seq currently being generated on lymophoblastoid cell lines from AA CD cases and controls, and RNA-Seq that we will generate in colonic biopsies from UC cases and controls. We will evaluate chromatin differences and expression of genes in cell types relevant to IBD from European, AA and East Asian ancestries in an effort to better understand locus heterogeneity by ancestry. We will continue to participate in all IBDGC activities to maximize the Impact of IBD genetics research by this cooperative funding mechanism. According to the Center for Disease Control and Prevention, an estimated 1.4 million Americans suffer from Inflammatory Bowel Disease (IBD), a chronic debilitating disorder with no cure that includes Crohn's disease and ulcerative colitis. IBD ranks in the top 5 in prevalence for gastrointestinal disorders and represents a significant financial burden to society requiring a lifetime of medical care. This proposed research aims to determine the genetic variations that cause IBD which will aid in developing preventive measures, improving the quality of care with better treatments and educating patients through genetic counseling.",IBD Gene Mapping by Clinical and Population Subset,9780486,U01DK062431,"['ATAC-seq', 'Admixture', 'African', 'African American', 'Algorithms', 'American', 'Asians', 'Biopsy', 'Caring', 'Cell Line', 'Centers for Disease Control and Prevention (U.S.)', 'Charge', 'Chromatin', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Coculture Techniques', 'Cohort Studies', 'Collaborations', 'Complex', 'Crohn&apos', 's disease', 'DNA', 'Data', 'Data Coordinating Center', 'Data Sources', 'Databases', 'Disease', 'Effectiveness', 'Enhancers', 'Epithelium', 'Ethnic Origin', 'Etiology', 'European', 'Evaluation', 'Financial Hardship', 'Fostering', 'Frequencies', 'Funding', 'Funding Mechanisms', 'Future', 'Gastrointestinal Diseases', 'Gastrointestinal tract structure', 'Gene Expression', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Diseases', 'Genetic Predisposition to Disease', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Goals', 'Health', 'Heterogeneity', 'Hispanics', 'Human Characteristics', 'Individual', 'Inflammatory Bowel Diseases', 'Investigation', 'Lead', 'Leadership', 'Linkage Disequilibrium', 'Machine Learning', 'Medical', 'Modeling', 'Nature', 'Other Genetics', 'Pathway Analysis', 'Patients', 'Pattern', 'Persons', 'Phase', 'Phenotype', 'Point Mutation', 'Population', 'Population Genetics', 'Positioning Attribute', 'Prevalence', 'Preventive measure', 'Publications', 'Publishing', 'Quality of Care', 'Research', 'Resources', 'Role', 'Sampling', 'Societies', 'Source', 'Testing', 'Ulcerative Colitis', 'Universities', 'Update', 'Variant', 'Work', 'X Chromosome', 'base', 'case control', 'cell type', 'differential expression', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'improved', 'insight', 'interest', 'macrophage', 'meetings', 'novel', 'novel strategies', 'racial disparity', 'rare variant', 'recruit', 'risk variant', 'sex', 'study population', 'transcriptome sequencing', 'two-dimensional', 'whole genome']",NIDDK,RBHS-ROBERT WOOD JOHNSON MEDICAL SCHOOL,U01,2019,467173,0.025295219552930272
"Comprehensive Characterization of Adaptive Regulatory Variation Linked to Human Disease Project Summary/ Abstract  Over the past decade there has been a rapid expansion of genome-wide association studies (GWAS), as well as the development of large-scale consortia like the UKBioBank and the All of Us project. While the number of genetic associations to human traits and disease is soaring, tools to characterize and interpret these variants are lacking. One challenge to realizing the potential of genomics is that over 99% of human genetic variation is non-coding, regulatory sequences. However, ‘regulatory grammar’ – the complex pattern of sequences that interact with transcription factors to control gene expression, is poorly understood. A repertoire of well-characterized causal variants is needed to build generalizable models with which to unlock insights into the genetic basis of human health and history.  Natural selection is a powerful driver of human genetic variation. As our species has encountered new climates, dramatic alterations in diet, and novel pathogens, these selective pressures have left hundreds of signatures of adaptation in our genomes, reflected in our species’ diversity of disease risk and morphology. For selection to have acted positively on them, these adaptive alleles must exhibit relatively strong phenotypic effects, and they continue to contribute to modern traits and disease (e.g. height or sickle cell anemia). Salient examples of human adaptation include immunity, metabolism, and morphology, all of which have extensive, unresolved GWAS signals. This renders the lens of recent evolution a powerful, but underutilized, tool for identifying alleles that contribute to phenotypic variation in modern association studies.  This proposal aims to expand the repertoire of well-characterized GWAS signals, by A) using evolution to prioritize adaptive variants, and B) applying novel, high-throughput experimental and computational tools to comprehensively decipher the functions of regulatory variants. These approaches will identify much needed causal variants, devise paradigms for their study, and inform future predictive models to characterize them. During the mentored phase of the K99, I will first develop methods to colocalize signals of selection and GWAS, and then use Variant Effect Predictions (VEP) to predict their function. I will then employ high-through methods such as a the massively parallel reporter assay and CRISPR non-coding screen to functionally characterize them directly. From the adaptive GWAS alleles our screens identify, we will make in-vivo system to more deeply characterize them during the Independent R00 phase. During this time I will deploy a variety of genomic tools such as ChIP, ChIA-PET, and RNA-seq to understand the adaptive variants’ molecular etiology. I will use the empirical data fro these studies, and the MPRA/HCR-FlowFISH screens to build more accurate VEP models. ! Project Narrative While thousands of genomic regions have been linked to human evolution and diseases, many of the genetic variants responsible are non-coding and thus difficult to interpret. I propose to identify adaptive human alleles underlying genome wide association studies and comprehensively characterize them using novel computational and experimental tools. I will then make in-vivo models of these to test their function and effects on fitness, improving future predictions of how genetic variants impact human evolution and health.",Comprehensive Characterization of Adaptive Regulatory Variation Linked to Human Disease,9805238,K99HG010669,"['African', 'Alleles', 'Biological Assay', 'CCRL2 gene', 'CRISPR interference', 'CRISPR screen', 'CRISPR/Cas technology', 'Cell Line', 'Cell model', 'Cells', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Climate', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Computer Simulation', 'Data', 'Databases', 'Deoxyribonucleases', 'Development', 'Diet', 'Disease', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exhibits', 'Future', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Health', 'Height', 'Histones', 'Human', 'Human Genetics', 'Immunity', 'Lassa Fever', 'Left', 'Link', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Mentors', 'Metabolism', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Morphology', 'National Human Genome Research Institute', 'Natural Selections', 'Neural Network Simulation', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Preparation', 'Recording of previous events', 'Regulatory Element', 'Reporter', 'Reporting', 'Research', 'Scanning', 'Sickle Cell Anemia', 'Signal Transduction', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Untranslated RNA', 'Variant', 'biobank', 'causal variant', 'cell type', 'computerized tools', 'disorder risk', 'fitness', 'genetic association', 'genetic variant', 'genome editing', 'genome wide association study', 'genomic tools', 'human disease', 'improved', 'in vivo', 'in vivo Model', 'insight', 'lens', 'mouse model', 'novel', 'pathogen', 'predictive modeling', 'pressure', 'tool', 'trait', 'transcription factor', 'transcriptome sequencing']",NHGRI,"BROAD INSTITUTE, INC.",K99,2019,124916,-0.02530886329388672
"Genome Based Influenza Vaccine Strain Selection using Machine Learning No abstract available PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection using Machine Learning,10044945,R01AI116744,[' '],NIAID,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2019,147704,0.018223544037501236
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9729028,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2019,1002519,0.004211554028128526
"Epi25 Clinical Phenotyping R03 PROJECT SUMMARY Clinical genetic data suggests that specific categories of epilepsy have genetic contributors, and there may be some overlap between categories. The Epi25 Collaborative was formed among more than 40 cohorts from around the world to sequence as many as 25,000 genomes or exomes. As of 2017, the collaborative has sequenced more than 13,000 exomes and clinical data has been collected for more than 8,000 cases. This project will complete the collection and review of the clinical data for each sample in the Epi25 collection to facilitate the translation of genomic and clinical discoveries into improved care for patients. The clinical and genomic data from Epi25 will be a global resource, shared with the research community for years to come. Epi25's governance structure, membership, and other information are available online at www.epi-25.org. In this project, clinical data is entered by contributors into Red Cap forms or uploaded directly into the Epi25 database. The clinical data is then checked by a computer algorithm that looks for key eligibility criteria for each participant. Errors and missing data are sent to the Phenotyping Coordinator to review and resolve, with the help of the contributing site. PROJECT NARRATIVE In 2014, collaborators from around the world created the Epi25 Collaborative to exome sequence as many as 25,000 patients with epilepsy. The collaborative has more than 6,200 exomes generated in year 2016, an additional 7,500 on sequencers in 2017, and more than 1,000 ready for sequencing in 2018. This project will review and correct errors for the descriptive epilepsy data for each sample sequenced in Epi25, to reveal the genetic underpinnings of common epilepsies.",Epi25 Clinical Phenotyping R03,9753389,R03NS108145,"['Absence Epilepsy', 'Artificial Intelligence', 'Autosomal Dominant Partial Epilepsy with Auditory Features', 'Autosomal dominant nocturnal frontal lobe epilepsy\xa0', 'Categories', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Computational algorithm', 'Data', 'Data Discovery', 'Databases', 'Eligibility Determination', 'Epilepsy', 'Ethnic Origin', 'Family', 'Genes', 'Genetic', 'Genetic Databases', 'Genetic Determinism', 'Genetic Translation', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Hand', 'International', 'Juvenile Myoclonic Epilepsy', 'Major Depressive Disorder', 'Medical Genetics', 'Methods', 'Neurodevelopmental Disorder', 'Partial Epilepsies', 'Participant', 'Patient Care', 'Patients', 'Pattern', 'Phenotype', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Site', 'Standardization', 'Structure', 'Syndrome', 'Temporal Lobe Epilepsy', 'Testing', 'Translations', 'Twin Studies', 'Variant', 'autism spectrum disorder', 'clinical phenotype', 'cohort', 'dravet syndrome', 'exome', 'genomic data', 'improved', 'informatics\xa0tool', 'phenotypic data', 'rare variant', 'sample collection']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R03,2019,60925,0.01081352205946183
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9735436,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,454366,0.029614080757234557
"Enhancing molecular diagnosis in children with multiple congenital anomalies using clinically focused splicing prediction algorithms The training included in this career development award promotes the applicant's development as a physician-scientist during his the PhD phase of his MD/PhD training in transdisciplinary computational genomics. The applicant has previously completed a Master's Degree in Mathematics, and has had extensive instruction in general computational biology. This unique melding of high-level computational expertise and interest in applied genomics has led to the development of this innovative project. He is now being co-mentored by Drs. Barash and Bhoj to gain complementary practical training in predictive algorithm development and molecular genetics. In both his clinical and research interests he is dedicated to improving the rate of molecular diagnosis for children with rare Mendelian disorders. His short-term goals include developing and refining his skills in RNA splicing prediction and human genetic variation analysis in exome and genome data. In addition, he will gain new insight into experimental design, data interpretation, and scientific communication skills to ensure his successful post-doctoral transition. His co-mentors for the proposal are Drs. Yoseph Barash and Elizabeth Bhoj, international leaders in computational genomics and molecular genetics. In addition he will be supported by outstanding resources of the MSTP at Penn, which has an extensive proven track record of successful previous awardees.  The applicant has been pursuing work in creating an improved computational pipeline for the analysis of variants from exome and genome data. Specifically he is capturing the intronic and synonymous variants that are generally removed from the analysis pipeline because of the difficulty in determining the pathogenicity of such variants. As there are many intronic and synonymous variants that are known to cause Mendelain disorders, this clearly leads to missed diagnoses. In Aim 1 he will generate an interpretable algorithm for prioritizing general splicing variants that guides functional validation. In Aim 2 he will identify novel variants and genes for mechanistic evaluation in the pathogenesis of congenital anomalies. This algorithm will be generally applicable, significantly enhancing our ability to provide molecular diagnoses for all patients with suspected Mendelian disorders. In addition, this proposal will allow the candidate to gain experience, knowledge, and new skills to successfully lay the foundation as a physician-scientist in computational genomics. Many children who are born with multiple medical issues have a genetic cause for their differences, but even the best tests cannot identify the genetic cause. This project will develop new computer technology to do a more complete analysis of their genetic testing information to help diagnose more of these children.",Enhancing molecular diagnosis in children with multiple congenital anomalies using clinically focused splicing prediction algorithms,9760051,F30HD098803,"['Address', 'Algorithms', 'Alternative Splicing', 'Benchmarking', 'Cells', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Code', 'Communication', 'Computational Biology', 'Computational Molecular Biology', 'Computers', 'Critical Thinking', 'Data', 'Data Analyses', 'Data Set', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Evaluation', 'Excision', 'Exhibits', 'Exons', 'Experimental Designs', 'Foundations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human', 'Human Genetics', 'Instruction', 'International', 'Introns', 'K-Series Research Career Programs', 'Knowledge', 'Libraries', 'Manuals', 'Master&apos', 's Degree', 'Mathematics', 'Medical', 'Mendelian disorder', 'Mentors', 'Mentorship', 'Messenger RNA', 'Modeling', 'Molecular Diagnosis', 'Molecular Genetics', 'Normal tissue morphology', 'Pathogenesis', 'Pathogenicity', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Physicians', 'Postdoctoral Fellow', 'Protein Isoforms', 'RNA Splicing', 'Regulation', 'Resources', 'Reverse Transcriptase Polymerase Chain Reaction', 'Scientist', 'Site', 'Syndrome', 'Technology', 'Testing', 'Tissues', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Work', 'analysis pipeline', 'career', 'causal variant', 'clinical application', 'cohort', 'congenital anomaly', 'deep learning', 'exome', 'exome sequencing', 'experience', 'genetic variant', 'improved', 'innovation', 'insight', 'interest', 'novel', 'prediction algorithm', 'reference genome', 'skills', 'standard of care', 'transcriptome sequencing']",NICHD,UNIVERSITY OF PENNSYLVANIA,F30,2019,50016,0.03160683534943365
"EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE ﻿    DESCRIPTION (provided by applicant): The eMERGE III Clinical Center proposal from Partners HealthCare leverages a large biobank, clinical data in the electronic medical records (EMR) for >4 million participants from the largest integrated health care provider in New England, advanced bioinformatics expertise and state-of-the-art genetic analysis. We propose three aims. (1) Aim 1. Discovery. We will test the hypothesis that common and rare variants from a custom chip including 50,000 loss of function (LoF) alleles will be associated with cardiovascular, neuropsychiatric and immune-mediated phenotypes derived from the EMR. We are currently genotyping 25,000 Partners HealthCare Biobank subjects with a custom chip that includes LoF alleles from 63,000 exomes that we have analyzed. (2) Aim 2. Penetrance and Pleiotropy. We will test the hypothesis that sequencing a set of established genes or loci will allow us to discover additional variation, and define penetrance and pleiotropy using EMR phenotypes. Rare variants in genes selected by the eMERGE network will be studied for penetrance and pleiotropic outcomes by PheWAS and chart review. In addition, we are poised to perform recall-by-genotype studies because all Biobank participants have provided consent for such callback. (3) Aim 3. Implementation. We will test the hypothesis that physicians will alter their surveillance and treatment of patients based upon voluntary return of actionable variants to provide safe and cost-effective benefits to patients. We will screen our entire Biobank population of 25,000 individuals for pathogenic variants in the LDLR gene, the leading genetic cause of premature coronary artery disease, and conduct an exploratory trial in disclosing this information. Biobank participants with pathogenic variants in LDLR will be offered enrollment into a randomized trial, in which their finding will be CLIA-confirmed, and in one arm, this result will be communicated to their physicians through the EMR. Over one year, we will collect the following outcomes through participant surveys and EMR queries: physician visits, laboratory testing, changes in medication prescriptions, LDL levels, medical costs and the number of family members screened and treated as a result of the intervention. We will collaborate with the entire eMERGE III Network to incorporate what we learn from this pilot trial into large-scale implementation protocols for the genes selected by the Network for sequencing. Finally, we will participate in all Network activities to enhance the movement of genetics into clinical practice. PUBLIC HEALTH RELEVANCE: The discovery and clinical use of genetic variants associated with both rare Mendelian and more common complex diseases promises to dramatically change the practice of medicine. Our eMERGE III project will leverage a large Biobank and a rich electronic medical record to define the phenotypic impact of mutations emerging from sequencing and then return results on selected variants to Biobank participants using a clinical trial.",EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE,9882457,U01HG008685,"['Algorithms', 'Alleles', 'Area', 'Asthma', 'Attention deficit hyperactivity disorder', 'Bioinformatics', 'Biology', 'Bipolar Disorder', 'CTLA4 gene', 'Callback', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computerized Medical Record', 'Congestive Heart Failure', 'Consent', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Cost Effectiveness Analysis', 'Custom', 'DRD2 gene', 'Data', 'Disease', 'Electronic Medical Records and Genomics Network', 'Enrollment', 'Family member', 'Funding', 'Genes', 'Genetic', 'Genomic medicine', 'Genotype', 'Goals', 'HLA-DRB1', 'Health Personnel', 'Healthcare', 'Immune', 'Individual', 'Inflammatory Bowel Diseases', 'Informatics', 'Intervention', 'LDL Cholesterol Lipoproteins', 'LDLR gene', 'Laboratories', 'Learning', 'Low-Density Lipoproteins', 'Mediating', 'Medical Care Costs', 'Medicine', 'Mental Depression', 'Mining', 'Movement', 'Multiple Sclerosis', 'Mutation', 'New England', 'Newborn Infant', 'Outcome', 'Participant', 'Pathogenicity', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Population Attributable Risks', 'Protocols documentation', 'Public Health', 'Research', 'Rheumatoid Arthritis', 'Schizophrenia', 'Source', 'Stream', 'Stroke', 'Surveys', 'TCF7L2 gene', 'TNFRSF1A gene', 'TYK2', 'Testing', 'Variant', 'Visit', 'actionable mutation', 'arm', 'base', 'biobank', 'biomarker panel', 'clinical care', 'clinical practice', 'clinical sequencing', 'clinically actionable', 'cost effective', 'design', 'exome', 'experience', 'genetic analysis', 'genetic information', 'genetic variant', 'hypercholesterolemia', 'implementation research', 'loss of function', 'machine learning algorithm', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'pilot trial', 'pleiotropism', 'premature', 'public health relevance', 'randomized trial', 'rare variant', 'support tools']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2019,800708,0.04641073535949764
"Quantum-inspired generative machine learning over large datasets to infer new pleiotropic effects of genetic variants in multiple neuropsyciatric diseases Abstract In this supplement, we propose developing new computational approaches for psychiatric genetics, building on emergent strengths of deep learning and quantum computing. These approaches, utilizing very large external medical and genetic datasets, will allow automatic extension of the existing annotations of human genetic variants and of protein expression markers in brain to numerous under-studied neuropsychiatric diseases. Narratives Request for a supplemental funding to RO1MH110905 (2/2-Measuring translational dynamics and the proteome to identify potential brain biomarkers for psychiatric disease).",Quantum-inspired generative machine learning over large datasets to infer new pleiotropic effects of genetic variants in multiple neuropsyciatric diseases,9631714,R01MH110905,"['Algorithms', 'Biological Markers', 'Brain', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Funding', 'Genetic', 'Genetic Diseases', 'Human Genetics', 'Machine Learning', 'Measures', 'Medical Genetics', 'Mental disorders', 'Proteome', 'deep learning', 'genetic variant', 'link protein', 'neuropsychiatric disorder', 'pleiotropism', 'protein expression', 'psychogenetics', 'quantum', 'quantum computing']",NIMH,UNIVERSITY OF CHICAGO,R01,2018,144180,0.020409664027231406
"Mathematical Models and Statistical Methods for Large-Scale Population Genomics ﻿    DESCRIPTION (provided by applicant):     Technological advances in DNA sequencing have dramatically increased the availability of genomic variation data over the past few years. This development offers a powerful window into understanding the genetic basis of human biology and disease risk. To facilitate achieving this goal, it is crucial to develop efficient analytical methods that will allow researchers to more fuly utilize the information in genomic data and consider more complex models than previously possible. The central goal of this project is to tackle this important challenge, by carrying out te following Specific Aims: In Aim 1, we will develop efficient inference tools for whole-genome population genomic analysis by extending our ongoing work on coalescent hidden Markov models and apply them to large-scale data. The methods we develop will enable researchers to analyze large samples under general demographic models involving multiple populations with population splits, migration, and admixture, as well as variable effective population sizes and temporal samples (ancient DNA). Multi-locus full-likelihood computation is often prohibitive in most population genetic models with high complexity. To address this problem, we will develop in Aim 2 a novel likelihood-free inference framework for population genomic analysis by applying a highly active area of machine learning research called deep learning. We will apply the method to various parameter estimation and classification problems in population genomics, particularly joint inference of selection and demography. In addition to carrying out technical research, we will develop a useful software package that will allow researchers from the population genomics community to utilize deep learning in their own research. It is becoming increasingly more popular to utilize time-series genetic variation data at the whole-genome scale to infer allele frequency changes over a time course. This development creates new opportunities to identify genomic regions under selective pressure and to estimate their associated fitness parameters. In Aim 3, we will develop new statistical methods to take full advantage of this novel data source at both short and long evolutionary timescales. Specifically, we will develop and apply efficient statistical inference methods for analyzing time-series genomic variation data from experimental evolution and ancient DNA samples. Useful open-source software will be developed for each specific aim. The novel methods developed in this project will help to analyze and interpret genetic variation data at the whole-genome scale. PUBLIC HEALTH RELEVANCE:     This project will develop several novel statistical methods for analyzing and interpreting human genetic variation data at the whole-genome scale. The computational tools stemming from this research will enable efficient and accurate inference under complex population genetic models, thereby broadly facilitating research efforts to understand the genetic basis of human biology and disease risk.",Mathematical Models and Statistical Methods for Large-Scale Population Genomics,9552183,R01GM094402,"['Accounting', 'Address', 'Admixture', 'Affect', 'Age', 'Algorithms', 'Alleles', 'Area', 'Classification', 'Communities', 'Complex', 'Computer software', 'DNA', 'DNA sequencing', 'Data', 'Data Sources', 'Demography', 'Development', 'Diffusion', 'Event', 'Evolution', 'Gene Frequency', 'Genetic', 'Genetic Models', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Human Biology', 'Human Genetics', 'Individual', 'Joints', 'Link', 'Machine Learning', 'Mathematics', 'Methods', 'Modeling', 'Mutation', 'Phase', 'Physiologic pulse', 'Population', 'Population Genetics', 'Population Sizes', 'Recording of previous events', 'Research', 'Research Personnel', 'STEM research', 'Sampling', 'Series', 'Site', 'Statistical Methods', 'Technology', 'Time', 'Time Series Analysis', 'Trees', 'Uncertainty', 'Work', 'analytical method', 'base', 'computer based statistical methods', 'computerized tools', 'deep learning', 'disorder risk', 'fitness', 'flexibility', 'genetic analysis', 'genetic selection', 'genome-wide', 'genomic data', 'genomic variation', 'human disease', 'interest', 'markov model', 'mathematical model', 'migration', 'novel', 'open source', 'pressure', 'public health relevance', 'tool', 'whole genome']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2018,297725,0.05697026825496183
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9406205,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'predictive modeling', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2018,372603,0.025666829030835822
"Deep learning methods to predict the function of genetic variants in orofacial clefts Project Summary  Orofacial clefts (OFCs) comprise a significant fraction of human birth defects in all populations (ranging between 1/500 to 1/2500 live births) and represent a major public health challenge. Individuals born with OFCs require surgical, nutritional, dental, speech, medical and behavioral interventions, imposing a substantial economic and personal burden. There has been convincing evidence that non-syndromic OFCs represent human complex disorders with a multifactorial etiology including genetic risk factors, environmental exposures, and their complex interactions. So far, there have been ~10 genome-wide association studies (GWAS) conducted for non-syndromic CL/P (NSCL/P) and >15 genomic loci reported with compelling statistical support, including genes such as IRF6, PAX7, and ABCA4 and the 8q24 locus. In addition, next-generation sequencing (NGS) as well as exome array have been conducted with extra depth of genotyping that enable detection of rare variants associated with OFCs. However, gaps exist in how to interpret these variants and how to identify novel variants from the large volume of data, with high expectations for new methods and new models for “second- analysis” of the genome-wide data. In this proposal, we propose two complementary aims to carry out deep and second-analysis of genome-wide data for OFCs. In Aim 1, we propose a deep learning method to build in silico models that can predict the effect of genetic variants in the context of rich craniofacial epigenomic features. With substantial fine map of sequence patterns, ad hoc motifs will be revealed and variants that disturb these motifs will provide mechanistic insights on OFCs. In Aim 2, we shift our focus to the gene level and propose a network assisted method to discover sensibly combined genes in spatial and temporal points that are critical to orofacial development. We target on all forms of OFCs, with particular interest in NSCL/P. To guarantee the success of this proposal, we form a multi-disciplinary team and local computational infrastructure equipped with GPUs for the implementation of both aims. Our aims are non-overlapping; rather, they are integrated and strongly focused on our fundamental question of interest: how genetic variants function to cause OFCs. The successful completion of our proposal will lead to deep understanding of genetic components in OFCs. Project Narrative Orofacial clefts (OFCs) comprise a significant fraction of human birth defects in all populations and represent a major public health challenge. Substantial progress has been made to identify genes and variants for OFCs through recent genome-wide association studies and next- generation sequencing projects. In this proposal, we aim to develop computational methods to comprehensively fine map and interpret the effects of these genetics variants, which will eventually lead to understanding of the mechanisms and new therapies for OFCs.",Deep learning methods to predict the function of genetic variants in orofacial clefts,9508953,R03DE027711,"['8q24', 'Algorithms', 'Behavior Therapy', 'Binding Sites', 'Biological Process', 'Cleft Lip', 'Cleft lip with or without cleft palate', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Congenital Abnormality', 'Consensus', 'DNA', 'DNA Methylation', 'Data', 'Dental', 'Detection', 'Development', 'Disease', 'Economics', 'Environment', 'Environmental Exposure', 'Etiology', 'Explosion', 'Expression Profiling', 'FaceBase', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Human', 'Human Genome', 'Individual', 'Lead', 'Live Birth', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Nutritional', 'Operative Surgical Procedures', 'PAX7 gene', 'Pathway interactions', 'Pattern', 'Phenotype', 'Play', 'Population', 'Proteins', 'Public Health', 'RNA', 'RNA Binding', 'Reporting', 'Research', 'Resources', 'Role', 'Sample Size', 'Site', 'Speech', 'Time', 'Tissues', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'base', 'computer infrastructure', 'craniofacial', 'craniofacial development', 'deep learning', 'epigenomics', 'exome', 'expectation', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'insight', 'interest', 'learning strategy', 'multidisciplinary', 'next generation sequencing', 'novel', 'novel therapeutics', 'orofacial', 'orofacial cleft', 'orofacial development', 'rare variant', 'risk variant', 'sequence learning', 'spatiotemporal', 'success', 'trait']",NIDCR,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R03,2018,154000,0.035160980999289375
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell- based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off- target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,9678132,U01HL145793,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'learning strategy', 'next generation', 'novel', 'novel therapeutics', 'response', 'safety testing', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NHLBI,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2018,651251,0.0011613476878709094
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9617314,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Supervision', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2018,249000,0.01469674188159728
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed un- derstanding of admixture is essential for e ective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on pheno- type are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simpli ed models at the risk of inaccurate inferences. This pro- posal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to lever- age this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate power- ful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as e ectively as homogeneous populations. The rst step in obtaining a thorough understanding of admixture is a principled and scalable statis- tical framework to infer ne-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop e ective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major im- pact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to eciently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human pheno- types, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on ne-scale genomic struc- ture and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can bene t from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9547454,R35GM125055,"['Admixture', 'Age', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2018,332952,0.03136232410291851
"Genetic characterization of atypical parkinsonism The Neurodegenerative Diseases Research Unit (NDRU) focuses on atypical parkinsonism syndromes to unravel molecular genetic mechanisms involved in the pathophysiology of parkinsonism, to study molecular relationships to more common neurodegenerative diseases and to discover targets for rational therapeutic development. NDRU is highly-collaborative and data-driven, combining interdisciplinary clinical and genomic research toward improving knowledge about parkinsonism syndromes.  Over the last year, we have undertaken three main projects. 1.	Genetic characterization of pathologically confirmed neurodegenerative diseases: We performed genotyping of pathologically confirmed neurodegenerative diseases using the Illumina NeuroChip array. These data are being used for machine learning applications and genotype-phenotype correlations.   2.	Genome sequencing of non-Alzheimer dementia cases and neurologically healthy individuals: NDRU is a leading member of an ambitious intramural genome sequencing project that will generate a unique resource for genetic research. Specifically, this project will produce genome sequence data of 3000 Lewy body dementia cases, 3000 frontotemporal dementia cases and 2000 neurologically healthy controls. The overall aim of this ongoing project is to expand genetic discovery efforts to non-Alzheimer dementias. All data will be made available to the research community.   3.    Genome-wide association study in multiple system atrophy: To investigate common genetic variants in multiple system atrophy, we are currently performing a follow up genome-wide association study. n/a",Genetic characterization of atypical parkinsonism,9770367,ZIANS003154,"['Clinical', 'Communities', 'Data', 'Frontotemporal Dementia', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Research', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Knowledge', 'Laboratories', 'Lewy Body Dementia', 'Machine Learning', 'Modernization', 'Molecular', 'Molecular Genetics', 'Multiple System Atrophy', 'Nerve Degeneration', 'Neurochip', 'Neurodegenerative Disorders', 'Neurologic', 'Parkinsonian Disorders', 'Pathologic', 'Pathway interactions', 'Phenotype', 'Research', 'Syndrome', 'Therapeutic', 'clinical Diagnosis', 'follow-up', 'genetic architecture', 'genetic resource', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'improved', 'member', 'non-alzheimer dementia', 'therapeutic development']",NINDS,NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE,ZIA,2018,938563,0.04434623033385174
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efﬁciently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be inﬁnitely replicated. Their combination, the multiparental genetic refer- ence population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, ﬂies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions consid- ered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and ﬁnd variance-controlling genes; and more rigorous and ex- pansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered in- clude: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only ﬁll signiﬁcant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientiﬁc output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9485688,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'computerized tools', 'design', 'human disease', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2018,336445,0.03096373541902469
"Selective Whole Genome Amplification - Enabling Microbial Population Genomics Microbial population genetic research has been crucial for understanding pathogen dynamics, virulence, host specificity, and many other topics; in many cases uncovering unexpected and transformative biological processes. However, conventional population genetic analyses are limited by the quantity of sequence data from each sample. The temporal, spatial, and evolutionary resolution of techniques that rely on single gene sequences or multi-locus sequence typing are often insufficient to study biological processes on fine scales, precisely the scales at which many evolutionary and mechanistic process occur. Population genomics offers a vast quantity of sequence information for inferring evolutionary and ecological processes on very fine spatial and temporal scales, inferences that are critical to understanding and eventually controlling many infectious diseases. The promise of population genomics is tempered, however, by difficulties in isolating and preparing microbes for next-generation sequencing. We have developed the selective whole genome amplification (SWGA) technology to sequence microbial genomes from complex biological specimens without relying on labor-intensive laboratory culture, even if the focal microbial genome constitutes only a miniscule fraction of the natural sample. The primary hindrance to popular adoption of SWGA for microbial genomic studies is not its effectiveness in producing samples suitable for next-generation sequencing but in the upfront investment needed to develop an effective protocol to amplify the genome of a specific microbial species. Identifying an SWGA protocol that consistently results in selective and even amplification across the target genome is currently hindered by computationally-inefficient software that can evaluate a very limited set of the potentially effective solutions. Further, this software uses marginally-effective optimality criteria as there is currently only a limited understanding of the true criteria that result in highly-selective and even amplification of a target genome. As a result, SWGA protocol development is currently costly in both time and resources. A primary goal of the proposed research is to identify the criteria that result in optimal SWGA by analyzing next- generation sequencing data with advanced machine learning techniques. These optimality criteria will be integrated into a freely-available, computationally-efficient swga development program that will reduce the upfront investment in SWGA protocol development, thus allowing researchers to address medically- and biologically-important questions in any microbial species. In the near term, this project will also generate effective SWGA protocols for four microbial species which can be used immediately to address fundamental questions in evolutionary biology, disease progression, and emerging infectious disease dynamics. From a global disease perspective, this work is imperative as the majority of microbial species cannot easily be cultured and are in danger of becoming bystanders in the genomics revolution that is currently elucidating evolutionary processes and molecular mechanisms in cultivable microbial species. Addressing many of the major outstanding questions about pathogen evolution will require analyses of populations of microbial genomes. Although population genomic studies would provide the analytical resolution to investigate evolutionary and mechanistic processes on fine spatial and temporal scales – precisely the scales at which these processes occur – microbial population genomic research is currently hindered by the practicalities of obtaining sufficient quantities of genomes to analyze. We propose to develop an innovative, cost-effective, practical, and publically-available technology to collect sufficient quantities of microbial genomic DNA necessary for next-generation microbial genome sequencing.",Selective Whole Genome Amplification - Enabling Microbial Population Genomics,9507167,R21AI137433,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Biological', 'Biological Process', 'Biology', 'Characteristics', 'Communicable Diseases', 'Complex', 'Computer software', 'Coupling', 'DNA', 'Data', 'Development', 'Disease', 'Disease Progression', 'Effectiveness', 'Emerging Communicable Diseases', 'Evolution', 'Foundations', 'Genes', 'Genetic Research', 'Genome', 'Genomic DNA', 'Genomics', 'Goals', 'Health', 'Human', 'Investigation', 'Investments', 'Laboratory culture', 'Machine Learning', 'Medical', 'Metaphor', 'Methods', 'Microbe', 'Microbial Genome Sequencing', 'Microsatellite Repeats', 'Molecular', 'Organism', 'Population', 'Population Analysis', 'Population Genetics', 'Process', 'Program Development', 'Protocols documentation', 'Recording of previous events', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Shapes', 'Specificity', 'Specimen', 'System', 'Techniques', 'Technology', 'Time', 'Virulence', 'Work', 'cost', 'cost effective', 'design', 'genetic analysis', 'genetic approach', 'host-microbe interactions', 'improved', 'innovation', 'microbial', 'microbial genome', 'next generation', 'next generation sequencing', 'novel', 'pathogen', 'prevent', 'protocol development', 'vector', 'whole genome']",NIAID,UNIVERSITY OF PENNSYLVANIA,R21,2018,242837,0.02400810356418419
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9486266,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2018,479215,-0.013154856128190033
"Center for Undiagnosed Diseases at Stanford Abstract The Undiagnosed Diseases Network (UDN) has increased access for patients with undiagnosed diseases to the nation’s leading clinicians and scientists. Phase II of the Network will facilitate the transition of UDN efforts toward sustainability, through the expansion of clinical sites, refinement of methods, and integration with regular clinical practice. Here, we propose a program of study that will (1) facilitate timely, accurate diagnosis of patients with undiagnosed diseases; (2) improve diagnostic rates through novel approaches to data analysis and integration; and (3) explore underlying mechanisms of disease to accelerate therapeutic drug discovery. In Aim 1, we propose to evaluate patients referred to the UDN through a protocol that includes pre-visit chart review and genetic counseling followed by an individualized visit during which standardized phenotypic and environmental data are collected. Biosamples facilitate genomic, multi-omic, and cellular evaluation of disease. Expansion of fibroblasts and, in selected cases, generation of induced Pluripotent Stem Cell (iPSC) lines facilitates scientific investigation of the underlying diseases. We will expand our program of patient outreach, particularly to under-served populations. We will extend our UDN-based genomic medicine educational program both in scope and by broadening its eligibility. In Aim 2, we propose to develop and implement novel methods in areas of high potential to increase diagnostic yield. This includes algorithms for the detection of small genomic insertions and deletions as well as large scale structural variation. We will develop alignment algorithms using graph reference genomes and promote the use of long-read sequencing technologies. We will apply machine learning to the systematic integration of RNA sequencing, metabolomic, and phenotypic data with the electronic medical record and the entire medical literature to improve diagnostic yield. In Aim 3, we propose to facilitate diagnosis through enhanced cellular and model organisms phenotyping. We will implement immunomic and metagenomic approaches such as T cell, B cell and unknown organism sequencing for undiagnosed cases. We will utilize methods for moderate- and high-throughput phenotyping of iPS-derived cells and promote novel drug discovery via high throughput drug screening both with FDA- approved drugs and large scale small molecule libraries. Beyond Phase II, Stanford Medicine has made a strong commitment to the continuation of the Center for Undiagnosed Diseases at Stanford through a multi- million dollar institutional commitment. In summary, we aim to build on the success of Phase I of the UDN by streamlining processes, maximizing collaboration and outreach, optimizing computational algorithms, extending scientific investigation towards therapeutic discovery, and promoting engagement of hospital leaders, clinicians, scientists, policy-makers, and philanthropists to ensure this national resource is sustained long beyond the duration of this award. Narrative We will refine the operations of the Center for Undiagnosed Diseases at Stanford in coordination with other Phase II sites of the Undiagnosed Diseases Network to diagnose the undiagnosed and facilitate a transition to sustainability. Our Center will bring Stanford’s long history in technology development, genomic data analysis, stem cell biology, and translational science to the team-based diagnosis and care of patients with undiagnosed disease. We will refine existing procedures to further optimize the diagnostic process and integrate care of the undiagnosed into clinical practice while preserving the scientific mission of the Undiagnosed Diseases Network.",Center for Undiagnosed Diseases at Stanford,9593406,U01HG010218,"['Algorithms', 'Animal Model', 'Area', 'Award', 'B-Lymphocytes', 'Biological Assay', 'Caring', 'Cell Line', 'Cell model', 'Cells', 'Child Health', 'Collaborations', 'Committee Membership', 'Computational algorithm', 'Computerized Medical Record', 'Consent', 'Country', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug Screening', 'Education', 'Eligibility Determination', 'Ensure', 'Evaluation', 'FDA approved', 'Family', 'Fibroblasts', 'Gene Silencing', 'Generations', 'Genetic Counseling', 'Genomic medicine', 'Genomics', 'Goals', 'Graph', 'Healthcare', 'Hospitals', 'Human', 'International', 'Investigation', 'Investments', 'Leadership', 'Libraries', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Metagenomics', 'Methods', 'Mission', 'Modeling', 'Network-based', 'Ontology', 'Organism', 'Organoids', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Policy Maker', 'Principal Investigator', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Recording of previous events', 'Research', 'Resources', 'Robotics', 'Role', 'Scientist', 'Site', 'Standardization', 'System', 'T-Lymphocyte', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underserved Population', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visit', 'accurate diagnosis', 'base', 'clinical practice', 'clinical research site', 'cohort', 'data integration', 'deep learning', 'drug discovery', 'experience', 'follow-up', 'genome-wide', 'genomic data', 'improved', 'induced pluripotent stem cell', 'innovation', 'insertion/deletion mutation', 'meetings', 'metabolomics', 'multiple omics', 'next generation', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'outreach', 'patient outreach', 'phenotypic data', 'programs', 'reference genome', 'relating to nervous system', 'research clinical testing', 'sample collection', 'screening', 'small molecule libraries', 'socioeconomics', 'stem cell biology', 'success', 'support network', 'technology development', 'tool', 'transcriptome sequencing', 'virtual']",NHGRI,STANFORD UNIVERSITY,U01,2018,1420000,-0.0023351266999561723
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9562959,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2018,1186500,0.0094728034843306
"Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease ABSTRACT Rapid progress in biomedical informatics has generated massive high-dimensional data sets (“big data”), ranging from clinical information and medical imaging to genomic sequence data. The scale and complexity of these data sets hold great promise, yet present substantial challenges. To fully exploit the potential informativeness of big data, there is an urgent need to find effective ways to integrate diverse data from different levels of informatics technologies. Existing approaches and methods for data integration to date have several important limitations. In this project, we propose novel statistical methods and strategies to integrate neuroimaging, multi-omics, and clinical/behavioral data sets. To increase power for association analysis compared to existing methods, we propose a novel multi-phenotype multi-variant association method that can evaluate the cumulative effect of common and rare variants in genes or regions of interest, incorporate prior biological knowledge on the multiple phenotype structure, identify associated phenotypes among multiple phenotypes, and be computationally efficient for high-dimensional phenotypes. To improve the prediction of clinical outcomes, we propose a novel machine learning strategy that can integrate multimodal neuroimaging and multi-omics data into a mathematical model and can incorporate prior biological knowledge to identify genomic interactions associated with clinical outcomes. The ongoing Alzheimer's Disease Neuroimaging Initiative (ADNI) and Indiana Memory and Aging Study (IMAS) projects as a test bed provide a unique opportunity to evaluate/validate the proposed methods. Specific Aims: Aim 1: to develop powerful statistical methods for multivariate tests of associations between multiple phenotypes and a single genetic variant or set of variants (common and rare) in regions of interest, and to develop methods for mediation analysis to integrate neuroimaging, genetic, and clinical data to test for direct and indirect genetic effects mediated through neuroimaging phenotypes on clinical outcomes; Aim 2: to develop a novel multivariate model that combines multi-omics and neuroimaging data using a machine learning strategy to predict individuals with disease or those at high-risk for developing disease, and to develop a novel multivariate model incorporating prior biological knowledge to identify genomic interactions associated with clinical outcomes; Aim 3: to evaluate and validate the proposed methods using real data from the ADNI and IMAS cohorts; and Aim 4: to disseminate and support publicly available user-friendly software that efficiently implements the proposed methods. RELEVANCE TO PUBLIC HEALTH: Alzheimer's disease (AD) as an exemplar is an increasingly common progressive neurodegenerative condition with no validated disease modifying treatment. The proposed multivariate methods are likely to help identify novel diagnostic biomarkers and therapeutic targets for AD. Identifying new susceptibility loci/biomarkers for AD has important implications for gaining greater insight into the molecular mechanisms underlying AD. NARRATIVE In this project, we propose novel statistical methods and strategies to integrate high-dimensional neuroimaging, multi-omics, and clinical/behavioral data sets, which aim to increase detection power for association analysis and improve the prediction of clinical outcomes. The development of an advanced integrative analysis platform will provide more comprehensive and integrated approaches to answering complex biological questions. The proposed multivariate analysis methods have a high potential impact on and important implications for gaining greater insight into the molecular mechanisms underlying complex diseases, as well as helping the development of earlier diagnostic tests and novel therapeutic targets.","Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease",9515964,R01LM012535,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Beds', 'Behavioral', 'Big Data', 'Biological', 'Biological Markers', 'Brain', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Complex', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Progression', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Genomics', 'Genotype', 'Health', 'Heterogeneity', 'Indiana', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Medical Imaging', 'Memory', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Phenotype', 'Positron-Emission Tomography', 'Proteomics', 'Public Health', 'Science', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Technology', 'Testing', 'Time', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cohort', 'data integration', 'diagnostic biomarker', 'disease classification', 'endophenotype', 'epigenomics', 'genetic association', 'genetic variant', 'high dimensionality', 'high risk', 'improved', 'insight', 'interest', 'learning strategy', 'mathematical model', 'metabolomics', 'multimodality', 'multiple omics', 'neuroimaging', 'new therapeutic target', 'novel', 'novel diagnostics', 'predict clinical outcome', 'rare variant', 'risk variant', 'therapeutic target', 'transcriptomics', 'user friendly software']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2018,341899,-0.04323949771189575
"Statistical genetics of aging-related genomic and phenotypic change To help to analyze and understand aging-related ""complex"" traits that are affected by many genes and environmental factors, we have followed the path of developing statistical algorithms for the analyses of genome-wide genotyping and high-throughput sequencing studies. Our proposed new computational tools provide means to analyze additional types of data e.g., to identify mitochondrial DNA (mtDNA) variants and to estimate mtDNA copy number efficiently from whole-genome sequences. For experimental tests of the algorithms, we are capitalizing on the special advantages of the SardiNIA project (see Annual Report AG000675) and InCHIANTI project (see Annual Report AG001050) to help in the assembly of mitochondrial sequence data and multiple phenotypic data in the two Italian cohorts. At the same time, we are carrying out genome-wide association studies (GWAS) and epidemiological analyses with NIA and other collaborators for a series of age-related traits.   In order to conduct analyses on large-scale consortium data to study mtDNA variation and copy number, we have developed two computational programs, providing a general solution for the analysis of mtDNA dynamics based on whole-genome sequencing studies. One program (mitoCaller) is designed specifically to identify mtDNA variants; the other (mitoCalc) infers mtDNA copy number in a cell directly from genome sequences. Applying the programs to leukocyte sequences of 2,000 SardiNIA participants and 1,000 InCHIANTI participants, we have shown that heteroplasmies (mtDNA variants with more than one allele at a site) increase with age, and that copy number is relatively highly heritable and is correlated with metabolic traits, particularly central fat levels. In more recent work, we have increased the speed of mitoCalc 100-fold (fastMitoCalc). The new program is being applied to white cells of 65,000 deeply sequenced individuals (TOPMed program, NHLBI), for GWAS on copy number. We have also initiated the development of programs to test possible effects of mtDNA variants on traits and diseases.  In another study, we have created a program that uses machine learning methods to measure effective rates of aging for individuals. We assess the extent to which an individual's physiological age could be determined as a composite score inferred from a broad range of biochemical and physiological data. Data were collected in the SardiNIA population study. We use machine learning strategies on data for 6,000 Sardinian participants, who ranged in age from 12 to 81. The best predictive models are determined from multiple combinations of dimensionality reduction, classification, and regression algorithms. They reach very strong correlations (R > 0.9) between predicted and actual ages, and show relative stability in successive visits of the same individuals (R>0.5). We then define an Effective Rate of Aging (ERA) for each participant, a trait measured as the ratio of an individual's predicted age to his/her chronological age. The inference that individuals have a characteristic rate of aging is supported by findings that in the SardiNIA cohort, the inferred values of ERA shows genetic heritability of 40%. This has been sufficient to initiate genome-wide association studies that identify genetic variants influencing the rate of aging.  In an ongoing collaborative effort, we study a special structural feature of DNA, G-quadruplex (G4) structures as potential DNA roadblocks that perturb mitochondrial replication machinery. The computational analyses of whole-genome sequences from two large Italian cohorts demonstrated an association between G4s and mitochondrial DNA variation. We found significant enrichment of mutations in stable G4 regions, with preferential enrichment of variants in the loop segments of G4 structures. Biochemical studies demonstrated a potent block of human mitochondrial replicative polymerase in DNA synthesis by G4 structure, which could be overcome by the G4-resolving helicase Pif1. Altogether, our results suggest that mitochondrial variants are enriched at stable G4 structures, which effectively delay or stall the mitochondrial replisome in vitro. n/a",Statistical genetics of aging-related genomic and phenotypic change,9779533,ZIAAG000693,"['Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Software', 'Algorithms', 'Alleles', 'Ally', 'Annual Reports', 'Biochemical', 'Case-Control Studies', 'Cells', 'Characteristics', 'Chronology', 'Classification', 'Complex', 'Computer Analysis', 'DNA', 'DNA biosynthesis', 'DNA copy number', 'Data', 'Dimensions', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Fatty acid glycerol esters', 'G-Quartets', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'High-Throughput Nucleotide Sequencing', 'Human', 'In Vitro', 'Individual', 'Leukocytes', 'Machine Learning', 'Measures', 'Metabolic', 'Mitochondria', 'Mitochondrial DNA', 'Mutation', 'National Heart, Lung, and Blood Institute', 'Nuclear', 'Nucleotides', 'Participant', 'Phenotype', 'Physiological', 'Polymerase', 'Population Control', 'Population Study', 'Program Development', 'Ribosomal DNA', 'Risk', 'Sardinia', 'Sequence Deletion', 'Series', 'Site', 'Speed', 'Statistical Algorithm', 'Structure', 'Testing', 'Time', 'Trans-Omics for Precision Medicine', 'Variant', 'Visit', 'Work', 'age related', 'base', 'cohort', 'computerized tools', 'design', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'helicase', 'learning strategy', 'phenotypic data', 'predictive modeling', 'programs', 'trait', 'whole genome']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2018,606211,0.030947833973207075
"Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases ﻿    DESCRIPTION (provided by applicant): The NHGRI Genome Sequencing Program (GSP) will identify genomic variants relevant to health and disease by genome sequencing over 225,000 participants across a multitude of diseases. The GSP will also serve as a pilot for the Precision Medicine Initiative that aims to enroll and sequence more than a million people representative of U.S. ethnic diversity. Here, we propose a GSP analysis center focused on Multi- and Trans- ethnic Mapping of Mendelian and Complex Diseases. There is a growing recognition of the substantial scientific advantages, as well as public health importance, of conducting biomedical research across ethnically diverse cohorts. We propose to develop scalable methods that incorporate ancestry to optimize medical genomic study design and improve power for uncovering the role of common and rare variants in disease. Achieving this goal requires expertise across diverse domains of knowledge including: medical and population genomics, algorithm development for complex disease mapping, and expertise in management of large-scale databases. Here, we have assembled a world-class team of medical and population geneticists, computer scientists, statisticians and clinicians, with leading expertise in the development of novel and scalable strategies for characterizing sequence variants and their role in disease. Importantly, our group has been at the forefront of development of resources, study designs and methods to enable genomic research in U.S. minority populations. Our project has three main objectives. First, we will develop an Automated Scalable Ancestry Pipeline (ASAP) for common disease mapping in diverse populations. ASAP will improve the computational efficiency of existing state-of-the-art methods for ancestry inference and develop important extensions to linear mixed models (LMMs) and other mapping strategies leveraging local and global ancestry. We will also develop methods to refine phenotypes and identify common controls for disease studies and define endpoints. Secondly, we will develop tools and resources for trans- and multi-population rare variant discovery that incorporate patterns of local and sub-continental ancestry. We will also develop machine-learning tools for variant annotation that leverage ancestral information, patterns of sequence evolution, and protein structure in a unified framework. Furthermore, we will incorporate population-specific patterns of cellular phenotypes to improve functional prediction algorithms for non-coding and coding variants. Lastly, we will disseminate our results through web-based resource that empower the biomedical research community. We will augment existing resources including ClinGen by annotating and characterizing pathogenic variants across diverse populations. We will develop a secure web-server that allows sharing of summary statistics and analysis pipelines to enable discovery, fine-mapping and functional prediction of genetic variants. Our team has ample experience with NIH-funded consortia and is dedicated to meeting the overall GSP project goals through collaborative work with NHGRI leadership and other funded investigators. PUBLIC HEALTH RELEVANCE The goal of our project is to accelerate the discovery of DNA variation relevant to health and disease by analyzing data from over 225,000 ethnically and racially diverse patients that will undergo genome sequencing. Of particular importance is ensuring we have powerful statistical methods for analyzing data from underserved groups including U.S. minority populations. Achieving this goal requires expertise across many domains of knowledge including: medical and population genomics, algorithm development for disease mapping, and expertise in large-scale databases.",Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases,9462637,U01HG009080,"['Algorithms', 'Architecture', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Code', 'Communities', 'Complex', 'Computers', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Enrollment', 'Ensure', 'Evolution', 'Funding', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human Genome', 'Internet', 'Investigation', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Methylation', 'Minority', 'Modeling', 'Molecular Conformation', 'National Human Genome Research Institute', 'Participant', 'Pathogenicity', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Population Heterogeneity', 'Precision Medicine Initiative', 'Privatization', 'Protocols documentation', 'Public Health', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resource Development', 'Resources', 'Risk', 'Role', 'Scientist', 'Secure', 'Shoulder', 'Statistical Methods', 'Target Populations', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Work', 'cohort', 'disorder control', 'ethnic diversity', 'experience', 'genetic variant', 'genome sequencing', 'genomic tools', 'improved', 'innovation', 'large-scale database', 'meetings', 'novel', 'online resource', 'patient privacy', 'phenome', 'prediction algorithm', 'predictive modeling', 'programs', 'protein structure', 'public health relevance', 'racial diversity', 'rare variant', 'simulation', 'statistics', 'tool', 'tool development', 'web-based tool']",NHGRI,STANFORD UNIVERSITY,U01,2018,921743,0.05805977600330793
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies (1-3). In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meetings. We have further developed and tested a limited permutation method that allows estimation of false positive rates in conjunction with our recurrency approach. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Ongoing work has involved further research to improve control of false positive rates while retaining excellent power and comparison of our new methods to several other feature-selection schemes. We have also been developing and testing a new approach for specifically identifying which selected features are actually interacting as opposed to acting independently. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published three papers describing this method. We are currently developing The Machine Suite which will be an extension of r2VIM. A manuscript presenting the updates to our methods is under preparation.   We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011 and another in 2014. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.  We have worked on optimizing methods for performing multipoint analyses using extremely dense WES and exome chip data sets, and have shown that several linkage methods that purport to adequately adjust for intermarker linkage disequilibrium do not control false positive rates adequately when data of this extreme density is analyzed. This research was awarded a platform presentation at the 2015 International Genetic Epidemiology Society meeting (CL Simpson). Work is ongoing to improve pipelines for application of family-based methods for improved quality control in whole genome sequence data. A chapter that reviewed and compared parametric and non-parametric linkage analysis methods and their relevance to modern genomic data was published this year (1).  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. Simulations are ongoing to compare our new methods to existing methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits as well as mixed effects models. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. Two papers extending these methods to pedigree data are currently under review. We are now in the process of applying these approaches to several of our genome-wide datasets.  Finally, we have collaborated with members of Dr. Alexander Wilsons group (Genometrics Section, CSGB, NHGRI) on several methods development projects including an ongoing project to develop approaches for selecting significant variants from GWAS when no replication samples are available, such that false positive rates are well controlled. A manuscript is under review for this recent project. n/a",Development of statistical genetics methodology,9795949,ZIAHG000153,"['African American', 'Award', 'Biological Models', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'International', 'Linear Models', 'Linkage Disequilibrium', 'Machine Learning', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Modernization', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Process', 'Publishing', 'Quality Control', 'Recurrence', 'Research', 'Running', 'Sampling', 'Scheme', 'Sequence Analysis', 'Societies', 'Statistical Methods', 'Structure', 'Testing', 'Trees', 'Update', 'Variant', 'Work', 'base', 'case control', 'caucasian American', 'data mining', 'data warehouse', 'density', 'exome', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genetic pedigree', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'novel', 'novel strategies', 'oral cleft', 'programs', 'quality assurance', 'rare variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2018,432702,0.032395543710905216
"Computational evaluation of the causal role of somatic mutations in human aging Project Abstract Although genome instability has long been considered as one of the major causal factors of aging, little is known about the actual number of genome alterations per cell and their effects on aging organisms, most notably humans. In the research proposed here I will take a single cell approach to identify the most common types of somatic mutations, i.e., base substitutions, small INDELS, copy number variation, genome structural variation and retrotranspositions, in human B lymphocytes as a function of age. The overarching goal is then to estimate functional effects of these DNA mutations accumulated during human aging in this particular cell type, which will also serve as a model for studying somatic mutations and their consequences in other cell types. This could never be tested before, because it was never possible to analyze random somatic mutations in a tissue by sequencing bulk DNA from that tissue (mutations are low- abundant), I will achieve this goal by utilizing a new, single-cell, whole genome sequencing (SCWGS) protocol that we developed. In this project I will focus on human B lymphocytes from individuals varying in age from about 30 to over 100 years and determine the genome-wide frequency and location of the different types of mutations in multiple cells from each individual (Aim 1). Preliminary results already show a significant increase of both base substitution mutations and CNVs with age, with a substantial number of these mutations in B cell genomic regions that are potentially functional. Hence, in Aim 2 I will predict the actual functional effects of these potentially functional, age-related mutations using machine learning approaches and integrative network analysis. Finally, in Aim 3 I will empirically test these predictions as to whether the mutation loads observed affect B cell's ability of response to stimulus. Hence, to test the long-standing hypothesis of genome instability as a causal factor in aging ,I will determine age-related mutations in single cells at four levels: (1) number of mutations, mutation spectra and genome distribution in individual cells; (2) potential functional effects of individual mutations, i.e., non-synonymous mutations in exons and mutations in gene regulatory regions; (3) mutations collectively affecting the gene regulatory network; and (4) relationship between mutation load and B cell activation status. In summary, the results of the proposed project will, for the first time uncover possible direct functional effects of somatic mutations on cellular function. Project Narrative Genome instability is considered as one of the major factors of aging and age-related diseases. This research aims to study somatic DNA mutations in normal blood cells (B lymphocytes) of humans of different ages and evaluate the functional effect of these mutations. It will dramatically improve the knowledge of DNA mutations in aging and deepen the understanding of genome instability as a basic aging mechanism in human.",Computational evaluation of the causal role of somatic mutations in human aging,9527264,K99AG056656,"['3&apos', ' Untranslated Regions', '5&apos', ' Untranslated Regions', 'Affect', 'Age', 'Aging', 'B-Cell Activation', 'B-Lymphocytes', 'Binding Sites', 'Blood Cells', 'CRISPR/Cas technology', 'Cancer Etiology', 'Cell Count', 'Cell physiology', 'Cells', 'Centenarian', 'Code', 'Collecting Cell', 'Copy Number Polymorphism', 'DNA', 'DNA Damage', 'DNA Repair', 'DNA Replication Damage', 'DNA Sequence Alteration', 'DNA Transposable Elements', 'DNA amplification', 'Data', 'Defect', 'Deoxyribonuclease I', 'Disease', 'Elderly', 'Enhancers', 'Evaluation', 'Exons', 'Frequencies', 'Functional disorder', 'Genes', 'Genome', 'Genomic Instability', 'Genomic Segment', 'Goals', 'Human', 'Hypersensitivity', 'Immunization', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Location', 'Locus Control Region', 'Machine Learning', 'Mentors', 'Methods', 'Mutation', 'Mutation Analysis', 'Mutation Spectra', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Organism', 'Pathway Analysis', 'Process', 'Proteins', 'Protocols documentation', 'RNA', 'RNA amplification', 'Regulator Genes', 'Research', 'Retrotransposition', 'Role', 'Site', 'Software Tools', 'Somatic Cell', 'Somatic Mutation', 'Source', 'Stimulus', 'Study models', 'Testing', 'Time', 'Tissues', 'Variant', 'age related', 'base', 'cell type', 'crosslink', 'dietary restriction', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'promoter', 'repair enzyme', 'repaired', 'response', 'single cell sequencing', 'single cell technology', 'theories', 'transcription factor', 'whole genome']",NIA,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",K99,2018,40760,-0.015730549230305518
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9544417,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,399949,0.00815219951469505
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9544417,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,400000,0.00815219951469505
"An integrative approach to functionalize GWAS hits in MI and stroke ﻿    DESCRIPTION (provided by applicant): Coronary heart disease (CHD) and cerebrovascular disease result from platelet thrombus formation at the site of a ruptured atherosclerotic plaque. Numerous studies have shown enhanced platelet reactivity, and increased platelet count and volume are risk factors for CHD events and fatality, and a recent NHLBI Working Group concluded that variation in platelet reactivity is a major determinant of ischemic events, like MI or stroke. Genome wide association studies (GWASs) have identified numerous common genetic variants associated with the risk of CHD and platelet function parameters, but most of the positive ""hits"" are not causative of the phenotype. To understand the cellular mechanisms by which these variants affect platelet function it is imperative to know the repertoire of mRNAs, miRNAs and lncRNAs expressed in the cell of interest. Our team has been a leader in the field of platelet transcriptomics as well as functional assessment of variants in platelet genes. We have profiled mRNAs and miRNAs from 183 subjects using multiple platforms and have also performed platelet RNA-seq on 14 different subjects. This information provides a critical ability to filter, prioritize and obtain variant functional insights for evaluating GWAS SNPs associated with MI, stroke and platelet parameters. We have identified 142 mRNAs and 9 miRNAs that are expressed in platelets and linked to these GWAS hits. The goals of this proposal are to identify, assay, and validate functional variation previously tagged in GWASs of platelet-mediated ischemic arterial disease and of platelet phenotypes. Aim 1 will identify GWAS-linked mRNAs, miRNAs and lncRNAs that are functional in platelets. Candidate RNAs will be refined by association with platelet function, eQTLs and QTLs using our previously generated platelet RNA data. We will develop a supervised machine-learning, statistical pattern matching algorithm to prioritize likely platelet-functional genes. Gene-level assays in which we knock down mRNA, miRNA and lncRNA in our human megakaryocyte culture system, followed by assays for integrin activation and quantification of platelet number and volume will be used to confirm platelet functionality. Aim 2 will identify functionally divergent SNPs and haplotypes. We will impute missing SNPs and perform fine-mapping to the phenotypes of interest. Variants will be prioritized by association strength, annotation data, and predicted function using publically available resources and our own platelet eQTL data. Non-coding candidates will be tested by reporter gene assay and non-synonymous variants will be tested using functional assays in cell lines in which the endogenous gene has been silenced. We will validate our findings with a replication analysis in which we use an independent cohort dataset to quantify the association of the tested variants with the original GWAS phenotype. PUBLIC HEALTH RELEVANCE:  Platelet-mediated arterial thrombosis in the coronary or cerebrovascular circulation is the major cause of mortality and morbidity in the U.S. Numerous DNA variations have been associated with these disorders, but the causal genes are unknown. This research will test whether genes near these DNA variations - and candidate variations themselves - alter platelet function or number to understand better the molecular mechanisms causing heart attacks and strokes.",An integrative approach to functionalize GWAS hits in MI and stroke,9528639,R01HL128234,"['Affect', 'Algorithms', 'Alleles', 'Amino Acids', 'Binding', 'Bioinformatics', 'Biological Assay', 'Blood Platelets', 'CD34 gene', 'Cell Line', 'Cells', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'ChIP-seq', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Coronary Circulation', 'Coronary heart disease', 'Coupled', 'DNA', 'Data', 'Data Set', 'Disease', 'Distal', 'Enhancers', 'Event', 'Gene Expression', 'Genes', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Human', 'Individual', 'Integrins', 'Intergenic Sequence', 'Introns', 'Investigation', 'Laboratories', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Mediator of activation protein', 'Megakaryocytes', 'Messenger RNA', 'Methods', 'MicroRNAs', 'Molecular', 'Morbidity - disease rate', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'Nucleic Acid Regulatory Sequences', 'Pathologic', 'Pattern', 'Phenotype', 'Platelet Count measurement', 'Prevention', 'Production', 'Protocols documentation', 'RNA', 'Reporter Genes', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Sentinel', 'Site', 'Stroke', 'Supervision', 'System', 'Testing', 'Thrombosis', 'Thrombus', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'atherosclerotic plaque rupture', 'base', 'clinical phenotype', 'clinically relevant', 'cohort', 'database of Genotypes and Phenotypes', 'falls', 'genetic variant', 'genome wide association study', 'genome-wide', 'human subject', 'insight', 'inter-individual variation', 'interest', 'knock-down', 'mortality', 'promoter', 'protein function', 'public health relevance', 'screening', 'small hairpin RNA', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'working group']",NHLBI,THOMAS JEFFERSON UNIVERSITY,R01,2018,392470,-0.00579755974951502
"Integrated Clinical and Transcriptomic Profiling to Characterize Disease Phenotype PROJECT SUMMARY Exome and whole-genome sequencing are becoming increasingly routine approaches in cancer[1], common disease[2]and rare disease diagnosis.[3] Despite their success, our ability to fully interpret the clinical relevance of personal genome variation remains a significant gap[4-6]. Considering this, the most crucial need is more genotype-phenotype data that link genetic variation with disease causation. The objective of this proposal is to improve the clinical interpretation of genetic variation; in particular, by developing integrative approaches that predict the effect of genetic variation on clinical phenotype. This proposal addresses the hypothesis, supported by preliminary data, that combining patient transcriptomic data with genotypic and clinical data (as opposed to each alone) offers a better mechanistic understanding of disease natural history, from initial presentation to progression. The specific aims are designed such that each independently add substantial functional genomic information, over and above previously available patient genetic data, to further resolve the clinical phenotype. Aim 1 establishes a comprehensive and widely-shared dataset of patient transcriptomic (and genetic) variation across multiple cancer, cardiovascular and thrombosis/bleeding phenotypes, in patients with somatically-acquired myeloproliferative neoplasms (MPN) and select other rare heritable blood diseases (HBD). Aim 2 methodically determines differential RNA expression and processing between clinically-relevant subgroups of MPN and HBD patients. Aim 3 brings these elements together – and applies two integrative Bayesian and machine learning approaches, RIVER[24] (RNA-informed variant effect on regulation) and LASSO[25] (Least Absolute Shrinkage and Selection Operator), to resolve the functional and clinical relevance of rare variants; and identify signatures most predictive of disease risk or progression. Completion of these aims will contribute new scientific knowledge on how integrating transcriptomic data improves clinical genomic analyses in other genetic (and rare) diseases. In addition, this project will enable the Principal Investigator to develop expertise in the informatics and data science aspects of genomic medicine that complement her current background in biophysics, biochemistry and translational hematology. Combined with additional informatics training at Stanford University through coursework, seminars, one-on-one advising from project mentors, and interactions with the wider statistics, bioinformatics and genomics communities, this project will prepare the Principal Investigator to launch an independent academic career in genomic medicine. PROJECT NARRATIVE Accurate clinical interpretation of genetic variation in personal genome data is an essential component of personalized medicine approaches and the precise genetic diagnosis toward achieving improved public health. This project will integrate genetic and clinical modifiers with functional genomic information (RNA sequencing) from adequately-powered, disease-relevant cells; and provide direct insight into transcriptional perturbations caused by genetic variation.",Integrated Clinical and Transcriptomic Profiling to Characterize Disease Phenotype,9666548,K08HG010061,"['Address', 'Adult', 'Age Factors', 'Algorithms', 'Alleles', 'Alternative Splicing', 'Bayesian Modeling', 'Biochemistry', 'Bioinformatics', 'Biological Markers', 'Biophysics', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood specimen', 'Body mass index', 'Cardiovascular system', 'Cells', 'Clinical', 'Clinical Data', 'Communities', 'Complement', 'DNA Sequence', 'Data', 'Data Science', 'Data Set', 'Databases', 'Demographic Factors', 'Disease', 'Disease Progression', 'Disease stratification', 'Elements', 'Etiology', 'Evaluation', 'Foundations', 'Functional disorder', 'Future', 'Gender', 'Gene Expression', 'Gene Expression Profiling', 'Gene Fusion', 'Genetic', 'Genetic Heterogeneity', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Hematological Disease', 'Hematology', 'Hemorrhage', 'Heritability', 'Informatics', 'Investigation', 'Knowledge', 'Laboratories', 'Lasso', 'Lead', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Medical Genetics', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Myeloproliferative disease', 'Other Genetics', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Principal Investigator', 'Process', 'Protein Isoforms', 'Public Health', 'RNA', 'RNA Processing', 'Rare Diseases', 'Reference Standards', 'Regulation', 'Research Training', 'Resources', 'Rivers', 'Sampling', 'Severities', 'Subgroup', 'System', 'Thrombosis', 'Tissue-Specific Gene Expression', 'Training', 'Universities', 'Untranslated RNA', 'Validation', 'Variant', 'Whole Blood', 'actionable mutation', 'base', 'biobank', 'career', 'clinical phenotype', 'clinically relevant', 'cohort', 'data integration', 'design', 'disease diagnosis', 'disease natural history', 'disease phenotype', 'disorder risk', 'exome', 'experience', 'functional genomics', 'genetic disorder diagnosis', 'genetic variant', 'genome sequencing', 'genomic data', 'improved', 'informatics training', 'insight', 'knowledge base', 'multidisciplinary', 'novel', 'patient stratification', 'personalized medicine', 'phenotypic data', 'prediction algorithm', 'prospective', 'rare cancer', 'rare variant', 'statistics', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'variant of unknown significance', 'whole genome']",NHGRI,STANFORD UNIVERSITY,K08,2018,190941,0.029221089307737595
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9498252,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Generic Drugs', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'cancer therapy', 'computerized data processing', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,"BROAD INSTITUTE, INC.",R01,2018,158992,0.029888191579696397
"Whole Genome Sequencing in Irish Multiplex Schizophrenia Families Project Summary: Although affected members of multiplex schizophrenia pedigrees have substantially elevated recurrence risk compared to singleton cases, the mean polygenic risk scores between these groups do not differ, suggesting that one source of this higher familial recurrence risk is rare, higher impact variation. We will collect whole genome sequence (WGS) from 600 affected members of multiplex schizophrenia pedigrees to identify rare variation shared by affected individuals within and between pedigrees potentially accounting for the increased recurrence risk, and reducing the `variant space' under consideration. After QC and calling in our existing pipeline, a) familial sequence variants in the exome will be directly analyzed in 2000 Irish cases and 2000 Irish controls with 30X exome sequence data in production currently, and b) variants outside the exome will be imputed into 3600 Irish singleton schizophrenia or bipolar disorder cases and 3000 Irish population controls with GWAS framework data; 3781 additional UK10K controls with 10X WGS are available to increase analysis power. This imputed dataset will be analyzed using recently developed methods for kernel-based tests of variation aggregated over a defined interval (such as a gene) that avoid the inflation of type-1 error. We use multiple sources of genomic information to develop weights for each position in the genome (indexing the prior probability that a change at the site has functional consequence) and each variant detected (indexing the probability that observed changes have functional consequence), and we propose to improve the existing genomic information sources for this weighting in a number of ways. In aim 3, prioritized variants from aim 2a/2b will be directly genotyped in the case/control samples by custom microarray; individual genes or genesets showing enrichment of variation in cases (if any are observed) will be resequenced in the case/control sample. In Aim 4, the directly assessed genotypic and sequence data from aim 3 will be analyzed using standard methods to identify individual associated variants, and variant-enriched genes, genesets or other functional sequences. We seek to unambiguously identify 1) individual variants that are significantly more common in cases, or 2) individual genes or other functional sequences or 3) gene- or functional sequence sets enriched for variation in cases to provide critical information about the brain systems perturbed in schizophrenia, and the mechanisms by which such alleles increase risk. Project Narrative Rare sequence variation has been implicated in many human complex traits, incuding schizophrenia, and has been studied in unrelated cases and controls and parent:offspring trios, but remains unstudied in multiplex families. Sequencing the genomes of such families will allow conprehensive identification of variation in protein coding genes, non-coding expressed loci, regulatory sequences, and evolutionarily conserved regions, as well as detection of structural variation, and testing these alleles in a large case/control series of the same ethnic and geographic origin offers significant advantages over prior study designs, and has the potential to identify individual alleles, variant enriched genes, variant enriched non-genic sequences, and/or variant enriched genesets contributing to SCH risk in the Irish population. Such variants offer great potential for understanding the functional impact of risk alleles and improving mechanistic understanding of schizophrenia and related disorders.",Whole Genome Sequencing in Irish Multiplex Schizophrenia Families,9555069,R01MH114593,"['Accounting', 'Affect', 'Alleles', 'Biological Assay', 'Biology', 'Bipolar Disorder', 'Brain', 'Code', 'Complex', 'Custom', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Face', 'Family', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Human', 'Individual', 'Ireland', 'LGALS3BP gene', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Methods', 'Nucleotides', 'Parents', 'Phase', 'Population', 'Population Control', 'Positioning Attribute', 'Principal Investigator', 'Probability', 'Process', 'Production', 'Proteins', 'Psychotic Disorders', 'Recurrence', 'Research Design', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Schizophrenia', 'Series', 'Signal Transduction', 'Site', 'Source', 'System', 'Testing', 'Untranslated RNA', 'Variant', 'Weight', 'base', 'case control', 'design', 'effective therapy', 'exome', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'indexing', 'member', 'offspring', 'power analysis', 'programs', 'risk variant', 'sample collection', 'trait', 'whole genome', 'working group']",NIMH,VIRGINIA COMMONWEALTH UNIVERSITY,R01,2018,457798,0.002409678583561809
"Biomedical Computing and Informatics Strategies for Infectious Disease Research ﻿    DESCRIPTION (provided by applicant): An important goal of infectious disease research is to develop genetic predictors of susceptibility. Our success in this endeavor will depend critically on the informatics methods and software that are available for making sense of high-dimensional genetic and genomic data. The goal of this research program is to develop, evaluate, distribute and support new and novel biomedical computing algorithms and open-source software for identifying combinations of genetic predictors of clinically important infectious disease outcomes. This application will target the growing body of rare genetic variants identified by high-throughput DNA sequencing. Our clinical application will focus on the prediction of antiretroviral response in clinical trials for HIV/AIDS. We propose here a highly innovative Hierarchical Rare Variant Collapsing Machine (HRVCM) algorithm for identifying and collapsing combinations of rare variants across gene regions (AIM 1). We will then integrate these new collapsed HRVCM variables into our popular Multifactor Dimensionality Reduction (MDR) method that will assess them in combination with common single-nucleotide polymorphisms (SNPs) from genome-wide association studies or GWAS (AIM 2). Our novel HRVCM-MDR approach will, for the first time, make it possible to assess non-additive interactions among sets of rare and common variants simultaneously in genetic studies of infectious diseases. We will apply these new and novel methods to approximately 13 million rare and common variants from nearly 3000 subjects that participated in an AIDS Clinical Trials Group (ACTG) study to evaluate risk for virologic failure with efavirenz-containing antiretroviral therapy (ART) regimens (AIM 3). Finally, we will release all methods as open source to the biomedical research community through our freely available MDR software package (AIM 4). PUBLIC HEALTH RELEVANCE: The overall goal of this application is to develop innovative new computational methods for the genetic analysis of infectious diseases. We will focus on the development of methods that are able to detect synergistic effects of multiple genetic variants regardless of whether they are rare of common in human populations. We will apply these methods to the study of HIV/AIDS vaccination response.",Biomedical Computing and Informatics Strategies for Infectious Disease Research,9430380,R01AI116794,"['AIDS clinical trial group', 'AIDS/HIV problem', 'Algorithmic Analysis', 'Algorithms', 'Anti-Retroviral Agents', 'Bioinformatics', 'Biomedical Computing', 'Biomedical Research', 'Clinical Trials', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Dimensions', 'Disease Outcome', 'Disease susceptibility', 'Failure', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic Segment', 'Goals', 'Graph', 'High-Throughput DNA Sequencing', 'Human', 'Infectious Diseases Research', 'Informatics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Population', 'Predisposition', 'Regimen', 'Research', 'Risk', 'Single Nucleotide Polymorphism', 'Statistical Data Interpretation', 'Time', 'Vaccination', 'Variant', 'antiretroviral therapy', 'base', 'biomedical informatics', 'clinical application', 'clinical predictors', 'design', 'efavirenz', 'gene interaction', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'high dimensionality', 'innovation', 'method development', 'novel', 'open source', 'programs', 'public health relevance', 'rare variant', 'response', 'simulation', 'success', 'virology']",NIAID,UNIVERSITY OF PENNSYLVANIA,R01,2018,401907,0.05388442562430904
"Biomedical Computing and Informatics Strategies for Infectious Disease Research ﻿    DESCRIPTION (provided by applicant): An important goal of infectious disease research is to develop genetic predictors of susceptibility. Our success in this endeavor will depend critically on the informatics methods and software that are available for making sense of high-dimensional genetic and genomic data. The goal of this research program is to develop, evaluate, distribute and support new and novel biomedical computing algorithms and open-source software for identifying combinations of genetic predictors of clinically important infectious disease outcomes. This application will target the growing body of rare genetic variants identified by high-throughput DNA sequencing. Our clinical application will focus on the prediction of antiretroviral response in clinical trials for HIV/AIDS. We propose here a highly innovative Hierarchical Rare Variant Collapsing Machine (HRVCM) algorithm for identifying and collapsing combinations of rare variants across gene regions (AIM 1). We will then integrate these new collapsed HRVCM variables into our popular Multifactor Dimensionality Reduction (MDR) method that will assess them in combination with common single-nucleotide polymorphisms (SNPs) from genome-wide association studies or GWAS (AIM 2). Our novel HRVCM-MDR approach will, for the first time, make it possible to assess non-additive interactions among sets of rare and common variants simultaneously in genetic studies of infectious diseases. We will apply these new and novel methods to approximately 13 million rare and common variants from nearly 3000 subjects that participated in an AIDS Clinical Trials Group (ACTG) study to evaluate risk for virologic failure with efavirenz-containing antiretroviral therapy (ART) regimens (AIM 3). Finally, we will release all methods as open source to the biomedical research community through our freely available MDR software package (AIM 4). PUBLIC HEALTH RELEVANCE: The overall goal of this application is to develop innovative new computational methods for the genetic analysis of infectious diseases. We will focus on the development of methods that are able to detect synergistic effects of multiple genetic variants regardless of whether they are rare of common in human populations. We will apply these methods to the study of HIV/AIDS vaccination response.",Biomedical Computing and Informatics Strategies for Infectious Disease Research,9430380,R01AI116794,"['AIDS clinical trial group', 'AIDS/HIV problem', 'Algorithmic Analysis', 'Algorithms', 'Anti-Retroviral Agents', 'Bioinformatics', 'Biomedical Computing', 'Biomedical Research', 'Clinical Trials', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Dimensions', 'Disease Outcome', 'Disease susceptibility', 'Failure', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic Segment', 'Goals', 'Graph', 'High-Throughput DNA Sequencing', 'Human', 'Infectious Diseases Research', 'Informatics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Population', 'Predisposition', 'Regimen', 'Research', 'Risk', 'Single Nucleotide Polymorphism', 'Statistical Data Interpretation', 'Time', 'Vaccination', 'Variant', 'antiretroviral therapy', 'base', 'biomedical informatics', 'clinical application', 'clinical predictors', 'design', 'efavirenz', 'gene interaction', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'high dimensionality', 'innovation', 'method development', 'novel', 'open source', 'programs', 'public health relevance', 'rare variant', 'response', 'simulation', 'success', 'virology']",NIAID,UNIVERSITY OF PENNSYLVANIA,R01,2018,473070,0.05388442562430904
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9445086,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'actionable mutation', 'base', 'disease phenotype', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'learning strategy', 'metabolomics', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,305167,0.010289206738990645
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9405576,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'cost', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'novel sequencing technology', 'phenotypic data', 'pleiotropism', 'population stratification', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2018,297619,0.06363588442940873
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9509468,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2018,300000,-0.01868828976759812
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9483341,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2018,864186,0.06065930035622768
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases Project Summary (unchanged) Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically “on” and “off” state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by a diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: · To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity · To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. Health Narrative (unchanged) Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9700377,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Development', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Genes', 'Genomics', 'Goals', 'Health', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Research', 'Research Personnel', 'Signal Transduction', 'Site', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'inhibitor/antagonist', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'predictive test', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2018,74718,-0.020167258729250556
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9559432,DP5OD019820,"['Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genomics', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'convict', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high dimensionality', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2018,325325,0.02690504125980334
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9559432,DP5OD019820,"['Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genomics', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'convict', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high dimensionality', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2018,1,0.02690504125980334
"Regulation of mRNA splicing by intronic genetic variants ﻿    DESCRIPTION (provided by applicant): Genetic variations in introns commonly impact cellular functions by causing alterations in mRNA splicing. The abnormal inclusion and exclusion of exons often change protein functions and cellular phenotypes. Although many intronic variations have known functions, with the adoption of next generation sequencing, many more intronic variants have been discovered for which the functional impact is unknown. Thus, it is important to be able to predict the impact of the variants without needing to test them all in expensive and laborious assays. Although there are informatics algorithms that predict the impact of genetic variants on pre-mRNA splicing, their ability to predict the effect on protein function and ultimately disease and therapeutic phenotypes is lacking. In addition, there is a need for high-throughput cellular assays to test the results of these predictions on cellular functions. The studies proposed here will fulfill these needs by developing algorithms that prioritize the intronic variants by their potential impact on splicing and gene function, and developing a high-throughput assay to functionally test thousands of these predictions. These novel technologies will be applied to the effect of intronic variants on the pharmacogenomics of two clinically important oncology drugs, clofarabine and paclitaxel. Our long-term goals are to be able to predict the functional impact of genomic variants on human disease and therapeutic response. Our central hypothesis is that intronic genetic variants alter mRNA splicing and consequently protein function that ultimately affects the cellular response to drug therapy. Our first aim will be to develop computational algorithms that prioritize intronic variants based on their impacts on pre-mRNA splicing and protein function. Using a variety of genomic and structural features and large sets of genomic data, we will develop a bioinformatics algorithm specifically designed to prioritize intronic variants based on their potential impacts on pre-mRNA splicing and protein function. Our second aim will be to identify functional intronic variants associated with drug-induced cytotoxicity. Using existing genomics and cellular cytotoxic response data from populations of human cell lines, we will identify functional intronic variants that contribute to individuals' responses to clofarabine and paclitaxel cytotoxicity. Our third aim will be to functionally test the impact of the prioritized intronic variants on pre-mRNA splicing and drug cytotoxicity. Using our novel high- throughput functional splicing assay, we will test the effects of predicted functional variants from Aim 2 on pre- mRNA splicing. In addition, we will validate the effect of the intronic variants on cytotoxicity using exon specific siRNA and CRISPR/Cas technology to manipulate the target gene splicing. Upon completion of these studies, we expect to have developed bioinformatics algorithms that can accurately prioritize the intronic variants based on their functional impact on pre-mRNA splicing and protein function. Also, we will have tested thousands of variants in a cellular pre-mRNA splicing assay and validated the impact of several of these functional variants on paclitaxel and clofarabine cytotoxicity. PUBLIC HEALTH RELEVANCE    Project Narrative The goal of this project is to design and implement a set of bioinformatics algorithms and high-throughput experimental assays for prioritizing functional intronic variants that contribute to phenotypic differences by affecting pre-mRNA splicing. The developed model, including a molecular validation component, will be used to systematically evaluate the functions of such variants that are associated with drug-induced cytotoxicity. The same strategy can also be used to study the etiology of complex diseases. This goal is directly relevant to the missions of NIH to improve the capability of disease diagnosis, treatment, and prevention.",Regulation of mRNA splicing by intronic genetic variants,9491760,R01CA213466,"['Adoption', 'Affect', 'Algorithms', 'Alternative Splicing', 'Bioinformatics', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Cell Line', 'Cell physiology', 'Cell-Mediated Cytolysis', 'Cellular Assay', 'Clinical', 'Clinical Research', 'Clofarabine', 'Complex', 'Computational algorithm', 'Computers', 'Data', 'Disease', 'Etiology', 'Exclusion', 'Exons', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genomics', 'Goals', 'Human', 'Human Cell Line', 'Human Genetics', 'Informatics', 'Introns', 'Machine Learning', 'Messenger RNA', 'Mission', 'Modeling', 'Molecular', 'Paclitaxel', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Population Genetics', 'Prevention', 'Publishing', 'RNA Splicing', 'Regulation', 'Research', 'Small Interfering RNA', 'Source', 'Spliced Genes', 'Test Result', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Work', 'base', 'cell type', 'cytotoxic', 'cytotoxicity', 'design', 'disease diagnosis', 'disease phenotype', 'functional genomics', 'gene function', 'genetic variant', 'genomic data', 'genomic predictors', 'genomic variation', 'high throughput screening', 'human disease', 'improved', 'individual response', 'mRNA Precursor', 'multidisciplinary', 'new technology', 'next generation sequencing', 'novel', 'oncology', 'prediction algorithm', 'protein function', 'protein structure', 'public health relevance', 'response', 'transcriptome sequencing', 'treatment response']",NCI,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2018,558312,0.018537658025378972
"Visualization, modeling and validation of chromatin interaction data The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Several recent high- throughput technologies based on Chromatin Conformation Capture (3C) have emerged (such as 4C, 5C, Hi-C and ChIA-PET) and given us an unprecedented opportunity to study the higher-order genome organization. Among them, Hi-C technology is of particular interest due to its unbiased genome-wide coverage that can measure chromatin interaction intensities between any two given genomic loci. However, Hi-C data analysis and interpretation are still in the early stages. One of the main challenges is how to efficiently visualize chromatin interaction data, so that the scientific community to visualize and use it for their own research. In addition, due to the complex experimental procedure and high sequencing cost, Hi-C has only been performed in a limited number of cell/tissue types. Finally, the underlying mechanism of chromatin interactions remains largely unclear. Therefore, the PI will propose the following aims: Aim 1. Build an interactive and customizable 3D genome browser. We will build an interactive and customizable 3D browser, which allows users to navigate Hi-C data and other high-throughput chromatin organization data, including ChIA-PET and Capture Hi-C. We have built a prototype of the 3D genome browser (www.3dgenome.org). Our browser will allow users to conveniently browse chromatin interaction data with other data types (such as ChIP-Seq and RNA-Seq) from the genomic region in the same window simultaneously. Our system will also empower the users to create their own session and query their own Hi-C and other epigenomic data. Aim 2. Impute chromatin interaction using other genomic/epigenomic information. We will predict Hi-C interaction frequencies using other available genomic and epigenomic data in the same cell type, such as ChIP-Seq data for histone modifications and transcription factors. We will build our prediction model and then systematically impute Hi-C interaction matrices for all 127 cell types whose epigenomes are available thanks to recent effort by the ENCODE and Roadmap Epigenome projects. Aim 3. Perform validation experiments for computational method in aim 1 and 2. We will perform 20 3C experiments in hESC and GM cell lines, coupled with genome engineering by CRISPR/Cas9, to evaluate Hi-C prediction method in aim 2. The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Although several recent high-throughput technologies including Hi-C have emerged and given us an unprecedented opportunity to study 3D chromatin interaction in high resolution, its analysis and interpretation are still in the early stages. Here we propose to develop a suite of statistical modeling and computational methods to model and validate chromatin interaction using other genomic/epigenomics data, and build an interactive and customizable 3D genome browser.","Visualization, modeling and validation of chromatin interaction data",9425925,R01HG009906,"['Address', 'Biological Neural Networks', 'CRISPR/Cas technology', 'Cell Count', 'Cell Line', 'Cell physiology', 'Cells', 'ChIP-seq', 'Chromatin', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Chromatin Remodeling Factor', 'Chromosome Territory', 'Communities', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Coupled', 'Data', 'Data Analyses', 'Dimensions', 'Distal', 'Elements', 'Environment', 'Event', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Gene Targeting', 'Genes', 'Genome', 'Genome engineering', 'Genomic Segment', 'Genomics', 'Imagery', 'Intuition', 'Knock-out', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Molecular', 'Procedures', 'Regulator Genes', 'Regulatory Element', 'Research', 'Resolution', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Validation', 'Visit', 'base', 'cell type', 'chromosome conformation capture', 'cost', 'epigenome', 'epigenomics', 'experimental study', 'forest', 'genome annotation', 'genome browser', 'genome-wide', 'high throughput technology', 'histone modification', 'human embryonic stem cell', 'interest', 'mammalian genome', 'performance tests', 'predictive modeling', 'prototype', 'repository', 'transcription factor', 'transcriptome sequencing', 'web site']",NHGRI,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R01,2018,383250,-0.03193962199793852
"Genetic Factors in Keratoconus DESCRIPTION (provided by applicant): The purpose of this grant is to develop techniques for use in the 'early' detection of keratoconus (KC) and identify genetic variants that contribute to is development. KC is a complex genetic eye disorder and a leading cause of corneal transplantation in the young, with approximately 300,000 affected individuals in the US. Undiagnosed, subclinical KC is one of the major causes for complications of LASIK (Laser-in-situ- Keratomilieusis) surgery, commonly performed for vision correction. In the past two decades we have made major improvements to the early diagnosis of KC and have also made significant contributions to the delineation of major genetic determinants of KC through genome wide linkage studies (GWLS), fine mapping, and genome wide association studies (GWAS). In this proposal, we intend to follow up on these studies using new powerful approaches to achieve the following specific aims: In Aim 1 we will combine corneal optical coherence tomography (OCT) and Pentacam HR Scheimpflug Tomography (PST), new technologies that measure both the anterior and posterior surface of the cornea, with videokeratography (VK), a method which revolutionized KC diagnosis, to characterize criteria and to improve the diagnosis of subclinical KC. In Aim 2, to identify additional KC genes, we will perform a 2.5 million SNP GWAS, with an additional 6,000 SNPs, to fine- map already identified genes. We will confirm these results in a separate cohort of KC patients. For this two- stage GWAS design we are assembling the largest group of KC patients described to date: 2000 KC patients in total, 1,000 for the GWAS discovery stage and 1,000 for the confirmation stage. The controls for GWAS discovery will come from the Cardiovascular Health Study (CHS; 3300) and for confirmation will come from 400 subjects with VK, PST, and OCT measurements under Aim 1 and 600 ""convenience controls"" from the Cholesterol and Pharmacogenetics (CAP) study. In our current state of knowledge, the most cost-effective approach to increase the number of identified KC genes is to proceed with the expanded GWAS proposed herein. In Aim 3, we will test the impact of the genes identified in Aim 2 on the 'early' subclinical phenotypes identified through the use o VK, PST and OCT measures in Aim 1. Lastly, for the second part of Aim 3, we will investigate the potential function of KC variants by testing their ability to influence gene structure, expression and function in corneal cell models, including iPS cells derived from corneal keratocytes developed by our research team. The results of these studies will help advance our understanding of the genetic susceptibility to KC and may result in novel treatment options to slow the progression of the disease. PUBLIC HEALTH RELEVANCE: Improving methods for the 'early' detection of keratoconus will help patients avoid complications of LASIK surgery, allow us to identify genetic variants that contribute to its development, and design therapies to retard its progression.",Genetic Factors in Keratoconus,9467545,R01EY009052,"['Affect', 'Anterior', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cells', 'Clinical', 'Collaborations', 'Complex', 'Cornea', 'Custom', 'Data', 'Development', 'Diagnosis', 'Discriminant Analysis', 'Disease Progression', 'Early Diagnosis', 'Epidemiology', 'Etiology', 'Eye', 'Eye diseases', 'Family member', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Predisposition to Disease', 'Genetic Transcription', 'Genetic Variation', 'Genotype', 'Grant', 'Immunohistochemistry', 'In Situ', 'Individual', 'Keratoconus', 'Keratoplasty', 'Knowledge', 'Laser In Situ Keratomileusis', 'Lasers', 'Lead', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Pathogenesis', 'Patients', 'Pharmacogenetics', 'Phenotype', 'Research', 'Research Design', 'Reverse Transcriptase Polymerase Chain Reaction', 'Risk', 'Surface', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Variant', 'Videokeratographies', 'Vision', 'base', 'bead chip', 'cardiovascular health', 'cholesterol control', 'cohort', 'cost effective', 'design', 'follow-up', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide linkage', 'improved', 'indexing', 'induced pluripotent stem cell', 'new technology', 'novel', 'prevent', 'protein expression', 'protein function', 'public health relevance', 'therapy design', 'tomography', 'tool', 'trait']",NEI,CEDARS-SINAI MEDICAL CENTER,R01,2018,759253,0.028673247548816293
"Cardiac genetic effects across HLBS phenotypes Forward genetic genome-wide association studies (GWAS) have successfully mapped thousands of loci regulating disorders of the heart, lung, blood and sleep (HLBS), implicating widespread sequence variation within the non-coding genome. However, their functions, mechanisms of action and how they impact disease is still unclear. To solve this new and important GWAS bottleneck, we use a functional genomics-inspired reverse genetics strategy to identify the `transcriptional machinery' (transcription factors (TF), cis-regulatory elements (CRE), target genes) controlling HLBS-relevant tissue functions and how DNA variants in them affect HLBS diseases. Taking advantage of our long-standing expertise and successes in complex, cardiovascular disorders, and novel computational methods we have recently developed, we propose novel genomics analyses of the Trans-Omics for Precision Medicine (TOPMed) Program phenotypes and their whole genome sequences, together with publicly available epigenomics data, to identify the molecular bases of HLBS disease. We will first focus on the transcriptional machinery controlling heart physiology and its disorders before exploring other HLBS-relevant tissues and disorders in collaboration with other TOPMed investigators. Our specific aims are: (1) Identifying the transcriptional machinery in the heart and other HLBS relevant tissues; and, (2) Connecting genomic variation in the transcriptional machinery to HLBS traits. Our approach will enable identification of the core molecular components that control HLBS tissues and how they are compromised in HLBS disorders. The major hypothesis explaining the results of heart, lung, blood and sleep (HLBS) genome-wide association studies (GWAS) is that sequence variants at specific cis-regulatory elements (CRE or enhancer) affect the binding of their cognate transcription factors (TF) to alter expression of specific HLBS genes and, thereby, modulate variation in the phenotype and disorders. In this proposal, we advance new computational approaches to identify the `transcriptional machinery' (TF, CRE, target genes) controlling HLBS-relevant tissue functions so that the effects of causal genetic variation can be identified within identified trait loci genome- wide. This tissue-based view provides an alternative, complementary approach for understanding HLBS trait and disease variation, a major public health challenge.",Cardiac genetic effects across HLBS phenotypes,9521873,R01HL141980,"['ATAC-seq', 'Affect', 'Algorithms', 'Base Pairing', 'Binding', 'Blood', 'Cardiac', 'Cardiovascular Diseases', 'Chromatin', 'Code', 'Collaborations', 'Complex', 'Computing Methodologies', 'DNA', 'DNase I hypersensitive sites sequencing', 'Data', 'Disease', 'Enhancers', 'Family', 'Gene Expression', 'Gene Frequency', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Heart', 'Heart Diseases', 'Hematological Disease', 'Individual', 'Lead', 'Link', 'Lung', 'Lung diseases', 'Machine Learning', 'Maps', 'Minor', 'Modeling', 'Molecular', 'Peripheral', 'Phenotype', 'Physiology', 'Public Health', 'Publishing', 'Quality Control', 'Regulator Genes', 'Regulatory Element', 'Research Personnel', 'Resources', 'Role', 'Sample Size', 'Sleep', 'Sleep Disorders', 'Testing', 'Tissues', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Weight', 'base', 'epigenomics', 'functional genomics', 'gene discovery', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'genomic data', 'genomic variation', 'histone modification', 'improved', 'novel', 'novel strategies', 'programs', 'rare variant', 'reverse genetics', 'success', 'trait', 'transcription factor', 'transcriptome sequencing', 'whole genome']",NHLBI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2018,438051,-0.03364842301999166
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9494629,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'human model', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,300473,0.03529626778050059
"Massively parallel functional analyses of human PTEN variants Project Summary  We are now able to routinely sequence human genomes at single-base resolution. However, our ability to interpret the functional consequences of detected mutations has lagged behind. Computational approaches scale well but have poor accuracy, whereas retrospective analysis of detected variants has high accuracy but does not scale well. In order to solve this problem, a new experimental paradigm has emerged to empirically characterize the effects of mutations with high accuracy at scale. This approach takes advantage of recent and ongoing improvements in DNA synthesis and sequencing, and has the potential to offer unprecedented insight into protein biochemistry and human disease. We believe these insights will prove to be critical for unlocking the potential of genomic medicine.  In this project we seek to comprehensively assess multiple molecular effects of PTEN mutations on protein function, and assess the utility of this data as a predictor for human clinical phenotype. The PTEN protein is a tumor suppressor that is frequently mutated in diverse human cancers and in the germline of some individuals with overgrowth disorders, cancer predisposition syndromes, or autism. Currently, it is impossible to predict the effects of the vast majority of PTEN germline mutations. Since the phenotypic spectrum of PTEN mutation carriers is broad, it would be highly valuable to understand the ways in which phenotypic outcomes arise from PTEN mutation genotypes.  In Aim 1, we will first employ a yeast-based screen to assess the effects all PTEN single amino acid mutations on lipid phosphatase activity, the primary biochemical function of PTEN protein. It is known that several pathogenic variants are destabilized. Therefore, in Aim 2, we will perform a second, independent screen to assess the steady state protein stability of all PTEN single amino acid mutations. In Aim 3, we will use the data derived from this study as well as publically available biochemical information to train a classifier model to predict the relationship between the mutation genotypes and clinical phenotypes observed in humans. These data will increase our fundamental understanding of PTEN function and the role of mutations in diverse disorders, and could provide a valuable clinical tool that would increase the quality of life for PTEN mutation carriers. Project Narrative  Mutations in the gene PTEN are causal for a diverse set of clinical disorders ranging from cancer to autism spectrum disorder. Here, we seek to gain new fundamental insights into the functional relationships between PTEN mutations and clinical presentations by prospectively characterizing the effects of all single amino acid PTEN mutations in parallel. These data will allow the creation of new models that can predict risk of specific PTEN mutations for different clinical outcomes and potentially lead to personalized therapies, early interventions, and optimal outcomes for PTEN mutation carriers.",Massively parallel functional analyses of human PTEN variants,9539482,F31HD095571,"['Affect', 'Amino Acids', 'Autistic Disorder', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biology', 'Biophysics', 'Cataloging', 'Catalogs', 'Cell Separation', 'Cell Survival', 'Cells', 'Characteristics', 'Clinic', 'Clinical', 'Complex', 'Coupled', 'Coupling', 'DNA biosynthesis', 'DNA sequencing', 'Data', 'Data Set', 'Deletion Mutation', 'Development', 'Disease', 'Early Intervention', 'FRAP1 gene', 'Fluorescence', 'Genes', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Germ-Line Mutation', 'Goals', 'Growth', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Lead', 'Light', 'Lipids', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Metabolism', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Outcome', 'PTEN gene', 'PTEN protein', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Phenotype', 'Phosphatidylinositols', 'Phosphoric Monoester Hydrolases', 'Play', 'Predisposition', 'Problem Solving', 'Process', 'Protein Biochemistry', 'Proteins', 'Pythons', 'Quality of life', 'Reaction', 'Resolution', 'Risk', 'Role', 'Signal Pathway', 'Signal Transduction', 'Site', 'Syndrome', 'Techniques', 'Temperature', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tumor Suppressor Proteins', 'Ubiquitination', 'Variant', 'Yeast Model System', 'Yeasts', 'accurate diagnosis', 'autism spectrum disorder', 'base', 'clinical phenotype', 'experimental study', 'fitness', 'genomic signature', 'genomic variation', 'high throughput technology', 'human disease', 'improved', 'insight', 'mutation carrier', 'next generation', 'novel', 'open source', 'personalized medicine', 'prediction algorithm', 'predictive modeling', 'prospective', 'protein function', 'screening', 'synthetic biology', 'tool', 'tumorigenic']",NICHD,OREGON HEALTH & SCIENCE UNIVERSITY,F31,2018,44524,-0.028597242523643228
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9393258,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Audiometry', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Impaired Persons', 'Heritability', 'Human', 'Inherited', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Research Infrastructure', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hearing impairment', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'preservation', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2018,564086,0.041186791525711405
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9748023,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Audiometry', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Impaired Persons', 'Heritability', 'Human', 'Inherited', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Research Infrastructure', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hearing impairment', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'preservation', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2018,53375,0.041186791525711405
"EMR-Linked Biobank for Translational Genomics ﻿    DESCRIPTION (provided by applicant): Medical care informed by genomic information is beginning to move into clinical practice. The Electronic Medical Records and Genomics (eMERGE) network through its initial phases has provided much of the groundwork for this transformation. The Geisinger Health System project, ""EMR-Linked Biobank for Translational Genomics"" intends to build on the knowledge and experience from eMERGE phase II to accelerate discovery and implementation while expanding our understanding of the sociocultural implications of genomics in medicine. We will accomplish this goal through three specific aims: 1) Use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery in the proposed disorders: familial hypercholesterolemia and chronic rhinosinusitis, 2) Develop and test approaches for implementation of genomic information in clinical practice, 3) Explore, develop and implement novel approaches for family-centered communication around clinically relevant genomic results. We currently have over 60,000 patients broadly consented for research with a large and increasing proportion consented for return of results and deposition in the electronic health record. Over 18,000 patients are genotyped on high density platforms. Our two proposed phenotypes, familial hypercholesterolemia (FH) and chronic rhinosinusitis (CRS) were chosen because both conditions have a significant public health impact in the United States, but they are also ideally suited to the specific aims of the project. They provide opportunities for innovation and extension of current eMERGE methods. While many of these innovations will take advantage of the sequencing done as part of the project, there are several other areas emphasized in the funding opportunity that will broaden the scope of eMERGE research. One of the areas of emphasis for eMERGE III is exploring the familial return of actionable results. FH is well suited to this, as the current clinical recommendation is cascade testing of family members for all diagnosed patients. Currently this relies on the patient to contact at risk family members, but this is less than optimal. We will explore this issue using qualitative and quantitative methods and use the results to design and test novel family communication strategies. Gene-environment interactions play an important role in the development and severity of disease. These are very difficult to study. We propose novel approaches that leverage the assets of Geisinger Health System and the eMERGE Network to develop and apply methods to extend existing projects that study the impact of environment on CRS. This would include the first large scale environment-wide association studies (EWAS). Finally, we propose to lead efforts to apply the tools of economic modeling and analysis to eMERGE projects to begin to quantify the value of implementation of genomic medicine in the US healthcare system. These proposed innovations will magnify the already significant impact that the eMERGE program has had in moving genomic medicine from a dream to a reality. PUBLIC HEALTH RELEVANCE: Through this application GHS seeks to continue its participation in the eMERGE Network for Phase III - Study Investigators U01 (RFA-HG-14-025) funding opportunity. We propose 3 specific aims: 1) use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery and validation of gene-phenotype associations; 2) develop and test approaches for implementation of genomic information in clinical practice; develop and implement novel approaches for family-centered communication around clinically relevant genomic results",EMR-Linked Biobank for Translational Genomics,9515974,U01HG008679,"['Adult', 'Algorithms', 'Ambulatory Care', 'Area', 'Attitude', 'Candidate Disease Gene', 'Caring', 'Catchment Area', 'Child', 'Clinical', 'Communication', 'Computerized Medical Record', 'Consent', 'County', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Dreams', 'Economic Models', 'Ecosystem', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Ensure', 'Environment', 'Familial Hypercholesterolemia', 'Familial disease', 'Family', 'Family member', 'Foundations', 'Funding Opportunities', 'Generations', 'Genes', 'Genomic medicine', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Group Practice', 'Health', 'Health Insurance', 'Health care facility', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Information Systems', 'Institute of Medicine (U.S.)', 'Integrated Health Care Systems', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Outcome Study', 'Participant', 'Patient Care', 'Patients', 'Pennsylvania', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Population', 'Process', 'Prognostic Factor', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Rural', 'Rural Population', 'Safety', 'Severity of illness', 'Site', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Treatment outcome', 'United States', 'Validation', 'Variant', 'base', 'biobank', 'case finding', 'chronic rhinosinusitis', 'clinical care', 'clinical practice', 'clinically relevant', 'density', 'design', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genotyped patients', 'implementation research', 'implementation strategy', 'innovation', 'inpatient service', 'interest', 'meetings', 'novel', 'novel strategies', 'personalized health care', 'phase 3 study', 'phenome', 'population based', 'programs', 'public health relevance', 'screening', 'tool', 'trait', 'translational genomics', 'treatment response']",NHGRI,GEISINGER CLINIC,U01,2018,871212,0.021998801240977726
"IBD Gene Mapping by Clinical and Population Subset PROJECT SUMMARY Inflammatory bowel disease (IBD), Crohn's disease (CD) and ulcerative colitis (UC) are complex genetic disorders of the gastrointestinal tract, and a major health burden to patients and society. Tremendous progress has been made in dissecting IBD genetic etiology with identification of over 200 IBD loci by genome wide association studies (GWAS) but mainly limited to persons of European ancestry. The IBD Genetics Consortium (IBDGC) was established to facilitate multicenter collaborative studies of 6 Genetics Research Centers (GRCs) organized with a Data Coordinating Center (DCC). Our GRC at Johns Hopkins (JHGRC) has contributed to all IBDGC studies, meeting recruitment objectives and taking roles in IBDGC leadership positions. Our particular focus is on African American (AA) IBD genetics. We performed the first large-scale evaluation of European loci in the AA population, replicating several genes, but also finding unique African-ancestral variants within these loci, as well as identified multiple admixture significant loci. We also published the first AA IBD genome-wide association study (GWAS), a collaborative effort that identified two African-specific gene loci, and replicated multiple additional European loci. We have also explored why some loci with proven risk variants in Europeans and other populations only cause disease in one ancestral population but not others. More research in AA IBD is needed to understand the etiology of IBD in this ancestrally distinct, major American population. In this application we will re-evaluate the AA GWAS by better imputation, evaluate whole genome sequencing data to test low frequency and rare variants, and perform an evaluation for chromosome X variants. We will recruit a large number of AA IBD patients through our own and multiple Satellite Recruitment Centers to power a second AA IBD GWAS, both UC and CD, and meta-analyze with the first to identify more novel loci, identify more African specific risk variants, and replicate known loci for this population and replicate our admixture loci. We will also incorporate diverse data sources to incorporate into our GWAS analyses including RNA-Seq currently being generated on lymophoblastoid cell lines from AA CD cases and controls, and RNA-Seq that we will generate in colonic biopsies from UC cases and controls. We will evaluate chromatin differences and expression of genes in cell types relevant to IBD from European, AA and East Asian ancestries in an effort to better understand locus heterogeneity by ancestry. We will continue to participate in all IBDGC activities to maximize the Impact of IBD genetics research by this cooperative funding mechanism. According to the Center for Disease Control and Prevention, an estimated 1.4 million Americans suffer from Inflammatory Bowel Disease (IBD), a chronic debilitating disorder with no cure that includes Crohn's disease and ulcerative colitis. IBD ranks in the top 5 in prevalence for gastrointestinal disorders and represents a significant financial burden to society requiring a lifetime of medical care. This proposed research aims to determine the genetic variations that cause IBD which will aid in developing preventive measures, improving the quality of care with better treatments and educating patients through genetic counseling.",IBD Gene Mapping by Clinical and Population Subset,9567544,U01DK062431,"['ATAC-seq', 'Admixture', 'African', 'African American', 'Algorithms', 'American', 'Asians', 'Biopsy', 'Caring', 'Cell Line', 'Centers for Disease Control and Prevention (U.S.)', 'Charge', 'Chromatin', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Coculture Techniques', 'Cohort Studies', 'Collaborations', 'Complex', 'Crohn&apos', 's disease', 'DNA', 'Data', 'Data Coordinating Center', 'Data Sources', 'Databases', 'Disease', 'Effectiveness', 'Enhancers', 'Epithelium', 'Ethnic Origin', 'Etiology', 'European', 'Evaluation', 'Fostering', 'Frequencies', 'Funding', 'Funding Mechanisms', 'Future', 'Gastrointestinal Diseases', 'Gastrointestinal tract structure', 'Gene Expression', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Diseases', 'Genetic Predisposition to Disease', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Goals', 'Health', 'Heterogeneity', 'Hispanics', 'Human Characteristics', 'Individual', 'Inflammatory Bowel Diseases', 'Investigation', 'Lead', 'Leadership', 'Linkage Disequilibrium', 'Machine Learning', 'Medical', 'Modeling', 'Nature', 'Other Genetics', 'Pathway Analysis', 'Patients', 'Pattern', 'Persons', 'Phase', 'Phenotype', 'Point Mutation', 'Population', 'Population Genetics', 'Positioning Attribute', 'Prevalence', 'Preventive measure', 'Publications', 'Publishing', 'Quality of Care', 'Research', 'Resources', 'Role', 'Sampling', 'Societies', 'Source', 'Testing', 'Ulcerative Colitis', 'Universities', 'Update', 'Variant', 'Work', 'X Chromosome', 'base', 'case control', 'cell type', 'differential expression', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'improved', 'insight', 'interest', 'macrophage', 'meetings', 'novel', 'novel strategies', 'racial disparity', 'rare variant', 'recruit', 'risk variant', 'sex', 'study population', 'transcriptome sequencing', 'two-dimensional', 'whole genome']",NIDDK,RBHS-ROBERT WOOD JOHNSON MEDICAL SCHOOL,U01,2018,477338,0.025295219552930272
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9416160,R00HG008171,"['Advisory Committees', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Code', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'cancer drug resistance', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'targeted nucleases', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2018,242325,-0.010643671940506002
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9548692,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2018,1002519,0.004211554028128526
"EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE ﻿    DESCRIPTION (provided by applicant): The eMERGE III Clinical Center proposal from Partners HealthCare leverages a large biobank, clinical data in the electronic medical records (EMR) for >4 million participants from the largest integrated health care provider in New England, advanced bioinformatics expertise and state-of-the-art genetic analysis. We propose three aims. (1) Aim 1. Discovery. We will test the hypothesis that common and rare variants from a custom chip including 50,000 loss of function (LoF) alleles will be associated with cardiovascular, neuropsychiatric and immune-mediated phenotypes derived from the EMR. We are currently genotyping 25,000 Partners HealthCare Biobank subjects with a custom chip that includes LoF alleles from 63,000 exomes that we have analyzed. (2) Aim 2. Penetrance and Pleiotropy. We will test the hypothesis that sequencing a set of established genes or loci will allow us to discover additional variation, and define penetrance and pleiotropy using EMR phenotypes. Rare variants in genes selected by the eMERGE network will be studied for penetrance and pleiotropic outcomes by PheWAS and chart review. In addition, we are poised to perform recall-by-genotype studies because all Biobank participants have provided consent for such callback. (3) Aim 3. Implementation. We will test the hypothesis that physicians will alter their surveillance and treatment of patients based upon voluntary return of actionable variants to provide safe and cost-effective benefits to patients. We will screen our entire Biobank population of 25,000 individuals for pathogenic variants in the LDLR gene, the leading genetic cause of premature coronary artery disease, and conduct an exploratory trial in disclosing this information. Biobank participants with pathogenic variants in LDLR will be offered enrollment into a randomized trial, in which their finding will be CLIA-confirmed, and in one arm, this result will be communicated to their physicians through the EMR. Over one year, we will collect the following outcomes through participant surveys and EMR queries: physician visits, laboratory testing, changes in medication prescriptions, LDL levels, medical costs and the number of family members screened and treated as a result of the intervention. We will collaborate with the entire eMERGE III Network to incorporate what we learn from this pilot trial into large-scale implementation protocols for the genes selected by the Network for sequencing. Finally, we will participate in all Network activities to enhance the movement of genetics into clinical practice. PUBLIC HEALTH RELEVANCE: The discovery and clinical use of genetic variants associated with both rare Mendelian and more common complex diseases promises to dramatically change the practice of medicine. Our eMERGE III project will leverage a large Biobank and a rich electronic medical record to define the phenotypic impact of mutations emerging from sequencing and then return results on selected variants to Biobank participants using a clinical trial.",EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE,9493516,U01HG008685,"['Algorithms', 'Alleles', 'Area', 'Asthma', 'Attention deficit hyperactivity disorder', 'Bioinformatics', 'Biology', 'Bipolar Disorder', 'CTLA4 gene', 'Callback', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computerized Medical Record', 'Congestive Heart Failure', 'Consent', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Cost Effectiveness Analysis', 'Custom', 'DRD2 gene', 'Data', 'Disease', 'Electronic Medical Records and Genomics Network', 'Enrollment', 'Family member', 'Funding', 'Genes', 'Genetic', 'Genomic medicine', 'Genotype', 'Goals', 'HLA-DRB1', 'Health Personnel', 'Healthcare', 'Immune', 'Individual', 'Inflammatory Bowel Diseases', 'Informatics', 'Intervention', 'LDL Cholesterol Lipoproteins', 'LDLR gene', 'Laboratories', 'Learning', 'Low-Density Lipoproteins', 'Machine Learning', 'Mediating', 'Medical Care Costs', 'Medicine', 'Mental Depression', 'Mining', 'Movement', 'Multiple Sclerosis', 'Mutation', 'New England', 'Newborn Infant', 'Outcome', 'Participant', 'Pathogenicity', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Population Attributable Risks', 'Protocols documentation', 'Public Health', 'Research', 'Rheumatoid Arthritis', 'Schizophrenia', 'Source', 'Stream', 'Stroke', 'Surveys', 'TCF7L2 gene', 'TNFRSF1A gene', 'TYK2', 'Testing', 'Variant', 'Visit', 'actionable mutation', 'arm', 'base', 'biobank', 'biomarker panel', 'clinical care', 'clinical practice', 'clinical sequencing', 'clinically actionable', 'cost effective', 'design', 'exome', 'experience', 'genetic analysis', 'genetic information', 'genetic variant', 'hypercholesterolemia', 'implementation research', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'pilot trial', 'pleiotropism', 'premature', 'public health relevance', 'randomized trial', 'rare variant', 'support tools']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2018,953224,0.04641073535949764
"Epi25 Clinical Phenotyping R03 PROJECT SUMMARY Clinical genetic data suggests that specific categories of epilepsy have genetic contributors, and there may be some overlap between categories. The Epi25 Collaborative was formed among more than 40 cohorts from around the world to sequence as many as 25,000 genomes or exomes. As of 2017, the collaborative has sequenced more than 13,000 exomes and clinical data has been collected for more than 8,000 cases. This project will complete the collection and review of the clinical data for each sample in the Epi25 collection to facilitate the translation of genomic and clinical discoveries into improved care for patients. The clinical and genomic data from Epi25 will be a global resource, shared with the research community for years to come. Epi25's governance structure, membership, and other information are available online at www.epi-25.org. In this project, clinical data is entered by contributors into Red Cap forms or uploaded directly into the Epi25 database. The clinical data is then checked by a computer algorithm that looks for key eligibility criteria for each participant. Errors and missing data are sent to the Phenotyping Coordinator to review and resolve, with the help of the contributing site. PROJECT NARRATIVE In 2014, collaborators from around the world created the Epi25 Collaborative to exome sequence as many as 25,000 patients with epilepsy. The collaborative has more than 6,200 exomes generated in year 2016, an additional 7,500 on sequencers in 2017, and more than 1,000 ready for sequencing in 2018. This project will review and correct errors for the descriptive epilepsy data for each sample sequenced in Epi25, to reveal the genetic underpinnings of common epilepsies.",Epi25 Clinical Phenotyping R03,9584612,R03NS108145,"['Absence Epilepsy', 'Artificial Intelligence', 'Autosomal Dominant Partial Epilepsy with Auditory Features', 'Categories', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Computational algorithm', 'Data', 'Data Discovery', 'Databases', 'Eligibility Determination', 'Epilepsy', 'Ethnic Origin', 'Family', 'Frontal Lobe Epilepsy', 'Genes', 'Genetic', 'Genetic Databases', 'Genetic Determinism', 'Genetic Translation', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Hand', 'Informatics', 'International', 'Juvenile Myoclonic Epilepsy', 'Major Depressive Disorder', 'Medical Genetics', 'Methods', 'Neurodevelopmental Disorder', 'Partial Epilepsies', 'Participant', 'Patient Care', 'Patients', 'Pattern', 'Phenotype', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Site', 'Standardization', 'Structure', 'Syndrome', 'Temporal Lobe Epilepsy', 'Testing', 'Translations', 'Twin Studies', 'Variant', 'autism spectrum disorder', 'clinical phenotype', 'cohort', 'dravet syndrome', 'exome', 'genomic data', 'improved', 'phenotypic data', 'rare variant', 'sample collection', 'tool']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R03,2018,75911,0.01081352205946183
"Investigating the clinical ontologies of loss-of-function and gain-of-function human gene variants No abstract available PROJECT NARRATIVE Genome-wide association studies (GWAS) have successfully described the roles of many human genes by analyzing large populations with shared traits, but these phenotype-based methodologies have incompletely described the clinical implications of numerous genes. I propose to address this knowledge gap by taking an unbiased, genotype-first approach to describing the relationships between dysfunctional genes and human disease traits through gene-burden phenome-wide association studies (PheWAS), essentially intersecting data from our healthcare system-based biobank database comprised of genotype data, whole-exome sequencing, and electronic health records (EHR). In addition to capturing the disease implications of rare, loss-of-function mutations on a genome-wide scale, my proposed project has the potential to define the roles of known and novel gain-of-function mutations in human disease, offering a direction for follow-up functional studies as well as a platform for more efficient therapeutic discoveries.",Investigating the clinical ontologies of loss-of-function and gain-of-function human gene variants,9681800,F30HG010442,"['Address', 'African American', 'Animal Model', 'Authorization documentation', 'Basic Science', 'Big Data', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computational Biology', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Doctor of Philosophy', 'Electronic Health Record', 'Environment', 'Fellowship', 'Frequencies', 'Funding', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genotype', 'Goals', 'Grant', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Laboratories', 'Literature', 'Measurement', 'Medicine', 'Mentorship', 'Methodology', 'Methods', 'Mutation', 'Natural Language Processing', 'Ontology', 'Participant', 'Patients', 'Pennsylvania', 'Phenotype', 'Physicians', 'Play', 'Population', 'Population Analysis', 'Privatization', 'Recontacts', 'Records', 'Regression Analysis', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Scientist', 'Serum', 'Structure', 'Students', 'Suggestion', 'Testing', 'Therapeutic', 'Tissue Model', 'Training', 'Universities', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'cardiometabolism', 'career', 'design', 'disease phenotype', 'exome sequencing', 'experimental study', 'follow-up', 'gain of function', 'gain of function mutation', 'gene discovery', 'gene product', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'human disease', 'human tissue', 'loss of function', 'loss of function mutation', 'medical schools', 'novel', 'phenome', 'pre-doctoral', 'precision medicine', 'programs', 'quantitative imaging', 'rare variant', 'recruit', 'symposium', 'text searching', 'tool', 'trait', 'translational approach']",NHGRI,UNIVERSITY OF PENNSYLVANIA,F30,2018,49524,0.002731313965239998
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9536132,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Comorbidity', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependence', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Electrophysiology (science)', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Mood Disorders', 'National Human Genome Research Institute', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Phenotype', 'Population', 'Prosencephalon', 'Psychiatry', 'Psychotic Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Standardization', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'experimental study', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'insight', 'interest', 'molecular phenotype', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'public health relevance', 'relating to nervous system', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2018,3291017,0.005450084718056185
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,9205487,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Immunology procedure', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Ships', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'Surveillance Program', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'experimental study', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza surveillance', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2017,372603,0.025666829030835822
"Mathematical Models and Statistical Methods for Large-Scale Population Genomics ﻿    DESCRIPTION (provided by applicant):     Technological advances in DNA sequencing have dramatically increased the availability of genomic variation data over the past few years. This development offers a powerful window into understanding the genetic basis of human biology and disease risk. To facilitate achieving this goal, it is crucial to develop efficient analytical methods that will allow researchers to more fuly utilize the information in genomic data and consider more complex models than previously possible. The central goal of this project is to tackle this important challenge, by carrying out te following Specific Aims: In Aim 1, we will develop efficient inference tools for whole-genome population genomic analysis by extending our ongoing work on coalescent hidden Markov models and apply them to large-scale data. The methods we develop will enable researchers to analyze large samples under general demographic models involving multiple populations with population splits, migration, and admixture, as well as variable effective population sizes and temporal samples (ancient DNA). Multi-locus full-likelihood computation is often prohibitive in most population genetic models with high complexity. To address this problem, we will develop in Aim 2 a novel likelihood-free inference framework for population genomic analysis by applying a highly active area of machine learning research called deep learning. We will apply the method to various parameter estimation and classification problems in population genomics, particularly joint inference of selection and demography. In addition to carrying out technical research, we will develop a useful software package that will allow researchers from the population genomics community to utilize deep learning in their own research. It is becoming increasingly more popular to utilize time-series genetic variation data at the whole-genome scale to infer allele frequency changes over a time course. This development creates new opportunities to identify genomic regions under selective pressure and to estimate their associated fitness parameters. In Aim 3, we will develop new statistical methods to take full advantage of this novel data source at both short and long evolutionary timescales. Specifically, we will develop and apply efficient statistical inference methods for analyzing time-series genomic variation data from experimental evolution and ancient DNA samples. Useful open-source software will be developed for each specific aim. The novel methods developed in this project will help to analyze and interpret genetic variation data at the whole-genome scale. PUBLIC HEALTH RELEVANCE:     This project will develop several novel statistical methods for analyzing and interpreting human genetic variation data at the whole-genome scale. The computational tools stemming from this research will enable efficient and accurate inference under complex population genetic models, thereby broadly facilitating research efforts to understand the genetic basis of human biology and disease risk.",Mathematical Models and Statistical Methods for Large-Scale Population Genomics,9328097,R01GM094402,"['Accounting', 'Address', 'Admixture', 'Affect', 'Age', 'Algorithms', 'Alleles', 'Area', 'Classification', 'Communities', 'Complex', 'Computer software', 'DNA', 'DNA sequencing', 'Data', 'Data Sources', 'Demography', 'Development', 'Diffusion', 'Event', 'Evolution', 'Gene Frequency', 'Genetic', 'Genetic Models', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Human Biology', 'Human Genetics', 'Individual', 'Joints', 'Learning', 'Link', 'Machine Learning', 'Mathematics', 'Methods', 'Modeling', 'Mutation', 'Phase', 'Physiologic pulse', 'Population', 'Population Genetics', 'Population Sizes', 'Recording of previous events', 'Research', 'Research Personnel', 'STEM research', 'Sampling', 'Series', 'Site', 'Statistical Methods', 'Technology', 'Time', 'Time Series Analysis', 'Trees', 'Uncertainty', 'Work', 'analytical method', 'base', 'computer based statistical methods', 'computerized tools', 'disorder risk', 'fitness', 'flexibility', 'genetic analysis', 'genetic selection', 'genome-wide', 'genomic data', 'genomic variation', 'human disease', 'interest', 'markov model', 'mathematical model', 'migration', 'novel', 'open source', 'pressure', 'public health relevance', 'tool', 'whole genome']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2017,298655,0.05697026825496183
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,9397848,F32GM116381,"['Acceleration', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mutation', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'admixture mapping', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'learning strategy', 'melanoma', 'offspring', 'public health relevance', 'rare variant', 'rate of change', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2017,510,0.030679903301302415
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,9278228,F32GM116381,"['Acceleration', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mutation', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'admixture mapping', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'learning strategy', 'melanoma', 'offspring', 'public health relevance', 'rare variant', 'rate of change', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2017,36307,0.030679903301302415
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9333402,K99HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Supervision', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",K99,2017,37785,0.01469674188159728
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed un- derstanding of admixture is essential for e ective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on pheno- type are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simpli ed models at the risk of inaccurate inferences. This pro- posal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to lever- age this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate power- ful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as e ectively as homogeneous populations. The rst step in obtaining a thorough understanding of admixture is a principled and scalable statis- tical framework to infer ne-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop e ective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major im- pact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to eciently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human pheno- types, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on ne-scale genomic struc- ture and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can bene t from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9382936,R35GM125055,"['Admixture', 'Age', 'Alleles', 'Architecture', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'insight', 'novel', 'reference genome', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2017,225087,0.03136232410291851
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,9213314,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'DNA sequencing', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Supervision', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'learning strategy', 'mRNA Precursor', 'novel', 'prediction algorithm', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2017,17892,-0.00736560330970851
"Genetic characterization of atypical parkinsonism The Neurodegenerative Diseases Research Unit (NDRU) focuses on atypical parkinsonism syndromes to unravel molecular genetic mechanisms involved in the pathophysiology, to study molecular relationships to more common neurodegenerative diseases and to discover targets for rational therapeutic development.  Over the last year, we have undertaken several ambitious projects. 1.	As part of a large consortium effort, we have been involved in the development of a genotyping array called the NeuroChip. This genotyping platform is designed for rapid, affordable, comprehensive and high-throughput genotyping of genetic mutations and risk variants associated with neurological diseases, including atypical parkinsonism syndromes. We have optimized, annotated and validated the content of the NeuroChip (Blauwendraat et al, Neurobiology of Aging, 2017). This platform will be useful for molecular diagnostics and genetic research. 2.	We performed NeuroChip genotyping in cohorts with neurodegenerative dementias, including Alzheimers disease, Lewy body dementia and progressive supranuclear palsy. We applied machine learning to pathologically confirmed cohorts diagnosed with these dementia syndromes. When we tested the derived algorithms in additional cohorts, we found that our models can successfully discriminate patients from control subjects based on genetic data. This highlights the potential ability of using machine learning as ancillary diagnostic tools. Such research could improve early diagnosis of neurodegenerative dementias.  3.	We performed NeuroChip genotyping on diverse neurodegenerative diseases from brain banks across North America and collaborating sites in Europe. Evaluations of genotype-phenotype correlations are currently ongoing. 4.	We are part of an ambitious intramural genome sequencing project that will generate a unique resource for genetic research in non-Alzheimer dementias. Specifically, this project will produce genome sequence data of 2000 Lewy body dementia cases, 2000 frontotemporal dementia cases and 1500 neurologically healthy controls. The overall aim of this ongoing project is to expand genetic discovery efforts to non-Alzheimer dementias. All data will be made publicly available to the research community. n/a",Genetic characterization of atypical parkinsonism,9563181,ZIANS003154,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Architecture', 'Brain Diseases', 'Communities', 'DNA Sequence Alteration', 'Data', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostics Research', 'Early Diagnosis', 'Europe', 'Evaluation', 'Frontotemporal Dementia', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Research', 'Genetic Risk', 'Genetic study', 'Genome', 'Genomic approach', 'Genotype', 'Laboratories', 'Lewy Body Dementia', 'Machine Learning', 'Modeling', 'Modernization', 'Molecular', 'Molecular Genetics', 'Multiple System Atrophy', 'Nerve Degeneration', 'Neurobiology', 'Neurochip', 'Neurodegenerative Disorders', 'Neurologic', 'North America', 'Parkinsonian Disorders', 'Pathologic', 'Pathway interactions', 'Patients', 'Phenotype', 'Progressive Supranuclear Palsy', 'Research', 'Site', 'Syndrome', 'Testing', 'Therapeutic', 'base', 'clinical Diagnosis', 'cohort', 'design', 'genetic resource', 'genetic variant', 'genome sequencing', 'improved', 'molecular diagnostics', 'nervous system disorder', 'neurodegenerative dementia', 'non-alzheimer dementia', 'risk variant', 'therapeutic development', 'tool']",NINDS,NATIONAL INSTITUTE OF NEUROLOGICAL DISORDERS AND STROKE,ZIA,2017,747571,0.006640036855108018
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9344966,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Molecular Profiling', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2017,1186500,0.0094728034843306
"Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease ABSTRACT Rapid progress in biomedical informatics has generated massive high-dimensional data sets (“big data”), ranging from clinical information and medical imaging to genomic sequence data. The scale and complexity of these data sets hold great promise, yet present substantial challenges. To fully exploit the potential informativeness of big data, there is an urgent need to find effective ways to integrate diverse data from different levels of informatics technologies. Existing approaches and methods for data integration to date have several important limitations. In this project, we propose novel statistical methods and strategies to integrate neuroimaging, multi-omics, and clinical/behavioral data sets. To increase power for association analysis compared to existing methods, we propose a novel multi-phenotype multi-variant association method that can evaluate the cumulative effect of common and rare variants in genes or regions of interest, incorporate prior biological knowledge on the multiple phenotype structure, identify associated phenotypes among multiple phenotypes, and be computationally efficient for high-dimensional phenotypes. To improve the prediction of clinical outcomes, we propose a novel machine learning strategy that can integrate multimodal neuroimaging and multi-omics data into a mathematical model and can incorporate prior biological knowledge to identify genomic interactions associated with clinical outcomes. The ongoing Alzheimer's Disease Neuroimaging Initiative (ADNI) and Indiana Memory and Aging Study (IMAS) projects as a test bed provide a unique opportunity to evaluate/validate the proposed methods. Specific Aims: Aim 1: to develop powerful statistical methods for multivariate tests of associations between multiple phenotypes and a single genetic variant or set of variants (common and rare) in regions of interest, and to develop methods for mediation analysis to integrate neuroimaging, genetic, and clinical data to test for direct and indirect genetic effects mediated through neuroimaging phenotypes on clinical outcomes; Aim 2: to develop a novel multivariate model that combines multi-omics and neuroimaging data using a machine learning strategy to predict individuals with disease or those at high-risk for developing disease, and to develop a novel multivariate model incorporating prior biological knowledge to identify genomic interactions associated with clinical outcomes; Aim 3: to evaluate and validate the proposed methods using real data from the ADNI and IMAS cohorts; and Aim 4: to disseminate and support publicly available user-friendly software that efficiently implements the proposed methods. RELEVANCE TO PUBLIC HEALTH: Alzheimer's disease (AD) as an exemplar is an increasingly common progressive neurodegenerative condition with no validated disease modifying treatment. The proposed multivariate methods are likely to help identify novel diagnostic biomarkers and therapeutic targets for AD. Identifying new susceptibility loci/biomarkers for AD has important implications for gaining greater insight into the molecular mechanisms underlying AD. NARRATIVE In this project, we propose novel statistical methods and strategies to integrate high-dimensional neuroimaging, multi-omics, and clinical/behavioral data sets, which aim to increase detection power for association analysis and improve the prediction of clinical outcomes. The development of an advanced integrative analysis platform will provide more comprehensive and integrated approaches to answering complex biological questions. The proposed multivariate analysis methods have a high potential impact on and important implications for gaining greater insight into the molecular mechanisms underlying complex diseases, as well as helping the development of earlier diagnostic tests and novel therapeutic targets.","Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease",9287487,R01LM012535,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Beds', 'Behavioral', 'Big Data', 'Biological', 'Biological Markers', 'Brain', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Complex', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Progression', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Genomics', 'Genotype', 'Health', 'Heterogeneity', 'Indiana', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Medical Imaging', 'Memory', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Phenotype', 'Positron-Emission Tomography', 'Proteomics', 'Public Health', 'Science', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Technology', 'Testing', 'Time', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cohort', 'data integration', 'diagnostic biomarker', 'disease classification', 'endophenotype', 'epigenomics', 'genetic association', 'genetic variant', 'high dimensionality', 'high risk', 'improved', 'insight', 'interest', 'learning strategy', 'mathematical model', 'metabolomics', 'multimodality', 'neuroimaging', 'new therapeutic target', 'novel', 'novel diagnostics', 'predict clinical outcome', 'rare variant', 'risk variant', 'therapeutic target', 'transcriptomics', 'user friendly software']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2017,367055,-0.04323949771189575
"Statistical genetics of aging-related genomic and phenotypic change To help to analyze and understand aging-related ""complex"" traits that are affected by many genes and environmental factors, we have followed the path of developing statistical algorithms for the analyses of genome-wide genotyping and high-throughput sequencing studies. Our proposed new computational tools provide means to analyze additional types of data e.g., to identify mitochondrial DNA (mtDNA) variants and to estimate mtDNA copy number efficiently from whole-genome sequences. For experimental tests of the algorithms, we are capitalizing on the special advantages of the SardiNIA project (see Annual Report AG000675) to help in the assembly of mitochondrial sequence data and multiple phenotypic data in the founder Sardinian population. At the same time, we are carrying out genome-wide association studies (GWAS) and epidemiological analyses with NIA and other collaborators for a series of age-related traits in the Sardinian cohort. In the past year, for example, this has involved us in epidemiological analyses for frailty-related traits (walking speed, grip strength and bone density) and hearing capacity as a function of age and sex.  In order to conduct analyses on large-scale consortium data to study mtDNA variation and copy number, we have developed two computational programs, providing a general solution for the analysis of mtDNA dynamics based on whole-genome sequencing studies. One program (mitoCaller) is designed specifically to identify mtDNA variants; the other (mitoCalc) infers mtDNA copy number in a cell directly from genome sequences. Applying the programs to leukocyte sequences of 2,000 SardiNIA participants, we have shown that heteroplasmies (mtDNA variants with more than one allele at a site) increase with age, and that copy number is relatively highly heritable and is correlated with metabolic traits, particularly central fat levels. In more recent work, we have increased the speed ofmitoCalc 100-fold (fastMitoCalc). The new program is being applied to white cells of 50,000 deep sequenced individuals (TOPMed program, NHLBI), for GWAS on copy number. We have also initiated analyses of possible effects of mtDNA copy number or variants on traits and diseases.  In another study, we have created a program that uses machine learning methods to measure physiological rates of aging of individuals. We assess the extent to which an individual's physiological age could be determined as a composite score inferred from a broad range of biochemical and physiological data. Data were collected in the SardiNIA population study. We use machine learning strategies on data for 6,000 Sardinian participants, who ranged in age from 12 to 81. The best predictive models are determined from multiple combinations of dimensionality reduction, classification, and regression algorithms. They reach very strong correlations (R > 0.9) between predicted and actual ages, and show relative stability in successive visits of the same individuals (R>0.5). We then define an Effective Rate of Aging (ERA) for each participant, a trait measured as the ratio of an individual's predicted age to his/her chronological age. The inference that individuals have a characteristic rate of aging is supported by findings that in the SardiNIA cohort, the inferred values of ERA shows genetic heritability of 40%. This has been sufficient to initiate genome-wide association studies that identify genetic variants influencing the rate of aging.  In an ongoing collaborative effort, we study a special structural feature of DNA, G-quadruplex (G4) structures as potential DNA roadblocks that perturb mitochondrial replication machinery. Computational analysis of mtDNA variants associated with predicted G4-forming structures in two large population cohorts are assessing G4 mtDNA as a factor contributing to genetic variability and disease risk. At the same time, biochemical studies are being performed in a reconstituted system to assess mitochondrial replisome progression through difficult-to-replicate sequences characterized by G4 structure. The study of possible mtDNA replication blockades complements analysis of the unique SardiNIA and InChianti populations to identify G4-associated mutations that affect age-related traits. n/a",Statistical genetics of aging-related genomic and phenotypic change,9549333,ZIAAG000693,"['Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Software', 'Algorithms', 'Alleles', 'Ally', 'Alpha Cell', 'Annual Reports', 'Biochemical', 'Bone Density', 'Case-Control Studies', 'Characteristics', 'Chronology', 'Classification', 'Complement', 'Complex', 'Computer Analysis', 'DNA', 'DNA biosynthesis', 'DNA copy number', 'Data', 'Dimensions', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Fatty acid glycerol esters', 'G-Quartets', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hand Strength', 'Hearing', 'Heritability', 'High-Throughput Nucleotide Sequencing', 'Individual', 'Leukocytes', 'Machine Learning', 'Measures', 'Metabolic', 'Mitochondria', 'Mitochondrial DNA', 'Mutation', 'National Heart, Lung, and Blood Institute', 'Nuclear', 'Nucleotides', 'Participant', 'Phenotype', 'Physiological', 'Population', 'Population Study', 'Ribosomal DNA', 'Risk', 'Sardinia', 'Sequence Deletion', 'Series', 'Site', 'Speed', 'Statistical Algorithm', 'Structure', 'System', 'Testing', 'Time', 'Trans-Omics for Precision Medicine', 'Variant', 'Visit', 'Work', 'age related', 'base', 'cohort', 'computerized tools', 'design', 'disorder risk', 'frailty', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'learning strategy', 'phenotypic data', 'predictive modeling', 'programs', 'reconstitution', 'sex', 'trait', 'walking speed', 'whole genome']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2017,1071207,0.03224150842640826
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies (1-3). In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods (1). We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data and this paper (2). Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meetings. We have further developed and tested a limited permutation method that allows estimation of false positive rates in conjunction with our recurrency approach. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published two papers describing this method, including one this year (1). We are currently developing The Machine Suite which will be an extension of r2VIM. A manuscript presenting the updates to our methods is under preparation.   We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011 and another in 2014. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.  We have worked on optimizing methods for performing multipoint analyses using extremely dense WES and exome chip data sets, and have shown that several linkage methods that purport to adequately adjust for intermarker linkage disequilibrium do not control false positive rates adequately when data of this extreme density is analyzed. This research was awarded a platform presentation at the 2015 International Genetic Epidemiology Society meeting (CL Simpson).  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. Simulations are ongoing to compare our new methods to existing methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits as well as mixed effects models. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. Two papers were published this year presenting a comparison of fixed and mixed effect models and presenting extensions to these methods for multivariate analysis  (3, 4). We are now in the process of applying these approaches to several of our genome-wide datasets.  This year we have also collaborated with various investigators in our International Consortium for Prostate Cancer Genetics (see report HG200331-13, Genetic Epidemiology of Cancer) to develop and test two new methods. One is a gene-based association method for rare variant analysis (5) and one is a novel machine-learning-based method for annotation of genetic variants that combines existing prediction approaches with protein-prediction modeling (6).  Finally, we have collaborated with members of Dr. Alexander Wilsons group (Genometrics Section, CSGB, NHGRI) on several methods development projects including an ongoing project to develop approaches for selecting significant variants from GWAS when no replication samples are available, such that false positive rates are well controlled. A manuscript is under preparation for this recent project. n/a",Development of statistical genetics methodology,9570581,ZIAHG000153,"['African American', 'Award', 'Biological Models', 'Caucasians', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genetic Annotation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'International', 'Linear Models', 'Linkage Disequilibrium', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Multivariate Analysis', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Process', 'Proteins', 'Publishing', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Scheme', 'Sequence Analysis', 'Societies', 'Statistical Methods', 'Structure', 'Testing', 'Trees', 'Update', 'Variant', 'Work', 'base', 'cancer epidemiology', 'cancer genetics', 'case control', 'data mining', 'density', 'exome', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'novel', 'oral cleft', 'programs', 'quality assurance', 'rare variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2017,519269,0.03309496109350295
"Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases ﻿    DESCRIPTION (provided by applicant): The NHGRI Genome Sequencing Program (GSP) will identify genomic variants relevant to health and disease by genome sequencing over 225,000 participants across a multitude of diseases. The GSP will also serve as a pilot for the Precision Medicine Initiative that aims to enroll and sequence more than a million people representative of U.S. ethnic diversity. Here, we propose a GSP analysis center focused on Multi- and Trans- ethnic Mapping of Mendelian and Complex Diseases. There is a growing recognition of the substantial scientific advantages, as well as public health importance, of conducting biomedical research across ethnically diverse cohorts. We propose to develop scalable methods that incorporate ancestry to optimize medical genomic study design and improve power for uncovering the role of common and rare variants in disease. Achieving this goal requires expertise across diverse domains of knowledge including: medical and population genomics, algorithm development for complex disease mapping, and expertise in management of large-scale databases. Here, we have assembled a world-class team of medical and population geneticists, computer scientists, statisticians and clinicians, with leading expertise in the development of novel and scalable strategies for characterizing sequence variants and their role in disease. Importantly, our group has been at the forefront of development of resources, study designs and methods to enable genomic research in U.S. minority populations. Our project has three main objectives. First, we will develop an Automated Scalable Ancestry Pipeline (ASAP) for common disease mapping in diverse populations. ASAP will improve the computational efficiency of existing state-of-the-art methods for ancestry inference and develop important extensions to linear mixed models (LMMs) and other mapping strategies leveraging local and global ancestry. We will also develop methods to refine phenotypes and identify common controls for disease studies and define endpoints. Secondly, we will develop tools and resources for trans- and multi-population rare variant discovery that incorporate patterns of local and sub-continental ancestry. We will also develop machine-learning tools for variant annotation that leverage ancestral information, patterns of sequence evolution, and protein structure in a unified framework. Furthermore, we will incorporate population-specific patterns of cellular phenotypes to improve functional prediction algorithms for non-coding and coding variants. Lastly, we will disseminate our results through web-based resource that empower the biomedical research community. We will augment existing resources including ClinGen by annotating and characterizing pathogenic variants across diverse populations. We will develop a secure web-server that allows sharing of summary statistics and analysis pipelines to enable discovery, fine-mapping and functional prediction of genetic variants. Our team has ample experience with NIH-funded consortia and is dedicated to meeting the overall GSP project goals through collaborative work with NHGRI leadership and other funded investigators. PUBLIC HEALTH RELEVANCE The goal of our project is to accelerate the discovery of DNA variation relevant to health and disease by analyzing data from over 225,000 ethnically and racially diverse patients that will undergo genome sequencing. Of particular importance is ensuring we have powerful statistical methods for analyzing data from underserved groups including U.S. minority populations. Achieving this goal requires expertise across many domains of knowledge including: medical and population genomics, algorithm development for disease mapping, and expertise in large-scale databases.",Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases,9268656,U01HG009080,"['Algorithms', 'Architecture', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Code', 'Communities', 'Complex', 'Computers', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Enrollment', 'Ensure', 'Evolution', 'Funding', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human Genome', 'Internet', 'Investigation', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Methylation', 'Minority', 'Modeling', 'Molecular Conformation', 'National Human Genome Research Institute', 'Participant', 'Pathogenicity', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Population Heterogeneity', 'Precision Medicine Initiative', 'Privatization', 'Protocols documentation', 'Public Health', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resource Development', 'Resources', 'Risk', 'Role', 'Scientist', 'Secure', 'Shoulder', 'Statistical Methods', 'Target Populations', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Work', 'cohort', 'disorder control', 'ethnic diversity', 'experience', 'genetic variant', 'genome sequencing', 'genomic tools', 'improved', 'innovation', 'large-scale database', 'meetings', 'novel', 'online resource', 'patient privacy', 'phenome', 'prediction algorithm', 'programs', 'protein structure', 'public health relevance', 'racial diversity', 'rare variant', 'simulation', 'statistics', 'tool', 'tool development', 'web-based tool']",NHGRI,STANFORD UNIVERSITY,U01,2017,923476,0.05805977600330793
"Decrypting Variants of Uncertain Significance in Long-QT Syndrome DESCRIPTION (provided by applicant): Clinical genetic testing has become standard-of-care for many diseases including hundreds of inherited conditions. However, interpreting genetic test results is often confounded by the discovery of 'variants of unknown significance' (VUS) for which there is insufficient data or inadequate predictive tools to establish whether or not a particular variant predisposes to a disease. This problem is particularly vexing for genetic disorders with strong allelic heterogeneity and a preponderance of 'private' mutations such as the congenital long-QT syndrome (LQTS), which predisposes young adults and children to sudden death from cardiac arrhythmias. With the anticipated incorporation of personal exome or genome data into routine clinical care, interpreting VUS will become an even greater challenge especially when variants in genes associated with human disorders are incidentally discovered. Unfortunately, there are no reliable methods to predict a priori whether a given variant predisposes an individual to a particular disorder or whether the change is merely a benign rare variant. We propose to develop a novel paradigm for distinguishing disease-causing mutations from benign variants in LQTS as a model for other inherited arrhythmia syndromes and channelopathies. We will focus on variants in KCNQ1, the most commonly mutated gene in LQTS. The central hypothesis of this proposal is that a holistic predictive model that relates experimentally determined protein structure and dynamics to function and disease is highly accurate even for novel variants. Our ultimate objectives are to develop a data-trained, web-accessible algorithm that classifies VUS discovered in KCNQ1 based on reliable predictions of the structure and dynamics of the affected protein, and to achieve prediction accuracy to levels needed to inform medical decisions. The medical importance of correctly classifying KCNQ1 variants provides strong justification for having a dedicated and highly-tailored gene-specific prediction model. The ability to distinguish deleterious from neutral variants would help avoid unnecessary and potentially harmful interventions in carriers of benign alleles, and save the lives of those with true mutations. We propose to collect extensive electrophysiological, biochemical and structural data on a large set of KCNQ1 variants discovered in LQTS subjects as well as several suspected benign or neutral variants (Aims 1-2), then use these data to iteratively train and validate a machine learning based algorithm that can differentiate benign from deleterious KCNQ1 alleles among a set of new VUS (Aim 3). Our proposal is innovative in the use of a multidisciplinary approach to functionally and structurally annotate genomic variant data for a medically important gene at an unprecedented scale, and then to use these experimental findings to train/test a novel computational system to achieve clinical-grade predictions. Targeting KCNQ1 will also validate an approach for parallel work that can be utilized to predict the medical significance of variants in closely related potassium channels associated with heritable epilepsy (KCNQ2, KCNQ3) or deafness (KCNQ4). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a method to reliably predict the consequences of genetic variants of unknown significance discovered in the course of genetic testing in the congenital long-QT syndrome (LQTS), a cause of sudden cardiac death in children and young adults. We propose a multidisciplinary experimental approach including electrophysiology, biochemistry and structural biology deployed on a large scale to generate information on at least 110 genetic variants in the main gene responsible for LQTS (KCNQ1), which encodes a potassium channel required for normal electrical activity in the heart. Our final product will be a data-trained computational strategy that will outperform existing methods for accurately predicting the functional consequences of novel KCNQ1 genetic variants, enhance the value of genetic testing in LQTS and provide for more informed medical decisions.",Decrypting Variants of Uncertain Significance in Long-QT Syndrome,9313321,R01HL122010,"['Affect', 'Algorithms', 'Alleles', 'Anti-Arrhythmia Agents', 'Arrhythmia', 'Benign', 'Biochemical', 'Biochemistry', 'Biological', 'Cardiac', 'Cell surface', 'Child', 'Clinical', 'Computer Simulation', 'Dangerousness', 'Data', 'Data Set', 'Defibrillators', 'Development', 'Disease', 'Electrophysiology (science)', 'Epilepsy', 'First Degree Relative', 'Genes', 'Genetic screening method', 'Genome', 'Goals', 'Heart', 'Hereditary Disease', 'Heritability', 'Heterogeneity', 'Human', 'Impairment', 'Implant', 'Individual', 'Inherited', 'Intervention', 'Ion Channel', 'Link', 'Long QT Syndrome', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Online Systems', 'Other Genetics', 'Patient Care', 'Patients', 'Physicians', 'Potassium Channel', 'Predisposition', 'Privatization', 'Protein Dynamics', 'Proteins', 'Research Personnel', 'Resources', 'Structure', 'Sudden Death', 'Syndrome', 'System', 'Test Result', 'Testing', 'Therapeutic', 'Training', 'Variant', 'Work', 'base', 'clinical care', 'cost', 'deafness', 'design', 'disease-causing mutation', 'exome', 'experimental study', 'genetic variant', 'heart rhythm', 'individual patient', 'innovation', 'interdisciplinary approach', 'knowledge base', 'multidisciplinary', 'novel', 'prediction algorithm', 'predictive modeling', 'predictive tools', 'proband', 'protein function', 'protein structure', 'protein transport', 'public health relevance', 'rare variant', 'standard of care', 'structural biology', 'sudden cardiac death', 'trafficking', 'variant of unknown significance', 'web-accessible', 'young adult']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2017,1280593,0.027901898463696805
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,9528959,U41HG007497,"['Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Computational algorithm', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Phenotype', 'Population', 'Process', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'deletion detection', 'design', 'experimental study', 'genetic analysis', 'genetic variant', 'improved', 'integration site', 'method development', 'novel', 'tool']",NHGRI,JACKSON LABORATORY,U41,2017,1986604,0.028885365375899325
"From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations DESCRIPTION (provided by applicant): Genomic medicine offers hope for improved diagnostic methods and for more effective, patient-specific therapies. Genome-wide associated studies (GWAS) elucidate genetic markers that improve clinical understanding of risks and mechanisms for many diseases and conditions and that may ultimately guide diagnosis and therapy on a patient-specific basis. This project will expand on existing work to identify gene-phenotype associations across the genome and phenome, deploying new phenome-wide associations study (PheWAS) methods to deeply investigate electronic medical record (EMR)-derived phenotypes across common and rare variants across the genome. The project is enabled by large DNA biobanks coupled to de-identified copies of EMR. This project has three specific aims. First, we will expand the PheWAS phenotype library to include both binary traits and continuous variables incorporating about 7000 phenotypes derived from natural language processing, laboratory data, and report data. The second aim is to perform a PheWAS for common and rare variants using extant genome-wide and exome variant data and the broader set of phenotypes derived in Aim 1. We will analyze associations using single variant and multi-variant aggregation methods. We will validate the efficacy of our methods in Aim 2 by comparing to known associations. The third aim is to develop a standards-based infrastructure to share PheWAS results and develop tools to enable others to perform PheWAS. The tools generated from this project will not only expand the capabilities of the current PheWAS methodology, but will also broadly enable clinical research and subsequent genetic studies. Project Narrative Genomic medicine offers hope for improved diagnosis and for more effective, patient- specific therapies. This PheWAS proposal will develop new methods to identify detailed phenotypes and diseases from electronic medical records and then find novel genetic associations from existing genomic data.",From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations,9332465,R01LM010685,"['Address', 'Adopted', 'Architecture', 'Atrial Fibrillation', 'Biology', 'Body mass index', 'Cardiac', 'Catalogs', 'Clinic', 'Clinical', 'Clinical Research', 'Code', 'Comorbidity', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'DNA Databases', 'Data', 'Data Reporting', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Documentation', 'Drug Exposure', 'Etiology', 'Exclusion', 'Funding', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Grant', 'Health system', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Laboratories', 'Lead', 'Libraries', 'Link', 'Mainstreaming', 'Measures', 'Methodological Studies', 'Methods', 'National Human Genome Research Institute', 'Natural Language Processing', 'Nature', 'Obesity', 'Pathway interactions', 'Patients', 'Peer Review', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Rare Diseases', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Scanning', 'Single Nucleotide Polymorphism', 'Site', 'Surveys', 'Testing', 'Variant', 'Work', 'base', 'biobank', 'cohort', 'disorder subtype', 'endophenotype', 'exome', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'next generation', 'novel', 'phenome', 'pleiotropism', 'rare variant', 'tool', 'trait']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,458957,0.04946401788744983
"An integrative approach to functionalize GWAS hits in MI and stroke ﻿    DESCRIPTION (provided by applicant): Coronary heart disease (CHD) and cerebrovascular disease result from platelet thrombus formation at the site of a ruptured atherosclerotic plaque. Numerous studies have shown enhanced platelet reactivity, and increased platelet count and volume are risk factors for CHD events and fatality, and a recent NHLBI Working Group concluded that variation in platelet reactivity is a major determinant of ischemic events, like MI or stroke. Genome wide association studies (GWASs) have identified numerous common genetic variants associated with the risk of CHD and platelet function parameters, but most of the positive ""hits"" are not causative of the phenotype. To understand the cellular mechanisms by which these variants affect platelet function it is imperative to know the repertoire of mRNAs, miRNAs and lncRNAs expressed in the cell of interest. Our team has been a leader in the field of platelet transcriptomics as well as functional assessment of variants in platelet genes. We have profiled mRNAs and miRNAs from 183 subjects using multiple platforms and have also performed platelet RNA-seq on 14 different subjects. This information provides a critical ability to filter, prioritize and obtain variant functional insights for evaluating GWAS SNPs associated with MI, stroke and platelet parameters. We have identified 142 mRNAs and 9 miRNAs that are expressed in platelets and linked to these GWAS hits. The goals of this proposal are to identify, assay, and validate functional variation previously tagged in GWASs of platelet-mediated ischemic arterial disease and of platelet phenotypes. Aim 1 will identify GWAS-linked mRNAs, miRNAs and lncRNAs that are functional in platelets. Candidate RNAs will be refined by association with platelet function, eQTLs and QTLs using our previously generated platelet RNA data. We will develop a supervised machine-learning, statistical pattern matching algorithm to prioritize likely platelet-functional genes. Gene-level assays in which we knock down mRNA, miRNA and lncRNA in our human megakaryocyte culture system, followed by assays for integrin activation and quantification of platelet number and volume will be used to confirm platelet functionality. Aim 2 will identify functionally divergent SNPs and haplotypes. We will impute missing SNPs and perform fine-mapping to the phenotypes of interest. Variants will be prioritized by association strength, annotation data, and predicted function using publically available resources and our own platelet eQTL data. Non-coding candidates will be tested by reporter gene assay and non-synonymous variants will be tested using functional assays in cell lines in which the endogenous gene has been silenced. We will validate our findings with a replication analysis in which we use an independent cohort dataset to quantify the association of the tested variants with the original GWAS phenotype. PUBLIC HEALTH RELEVANCE:  Platelet-mediated arterial thrombosis in the coronary or cerebrovascular circulation is the major cause of mortality and morbidity in the U.S. Numerous DNA variations have been associated with these disorders, but the causal genes are unknown. This research will test whether genes near these DNA variations - and candidate variations themselves - alter platelet function or number to understand better the molecular mechanisms causing heart attacks and strokes.",An integrative approach to functionalize GWAS hits in MI and stroke,9276780,R01HL128234,"['Affect', 'Algorithms', 'Alleles', 'Amino Acids', 'Arterial Fatty Streak', 'Binding', 'Bioinformatics', 'Biological Assay', 'Blood Platelets', 'CD34 gene', 'Cell Line', 'Cells', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'ChIP-seq', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Coronary Circulation', 'Coronary heart disease', 'Coupled', 'DNA', 'Data', 'Data Set', 'Disease', 'Distal', 'Enhancers', 'Event', 'Gene Expression', 'Genes', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Human', 'Individual', 'Integrins', 'Intergenic Sequence', 'Introns', 'Investigation', 'Laboratories', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Mediator of activation protein', 'Megakaryocytes', 'Messenger RNA', 'Methods', 'MicroRNAs', 'Molecular', 'Morbidity - disease rate', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'Nucleic Acid Regulatory Sequences', 'Pathologic', 'Pattern', 'Phenotype', 'Platelet Count measurement', 'Prevention', 'Production', 'Protocols documentation', 'RNA', 'Reporter Genes', 'Reporting', 'Reproducibility', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Rupture', 'Sentinel', 'Site', 'Stroke', 'Supervision', 'System', 'Testing', 'Thrombosis', 'Thrombus', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'base', 'clinical phenotype', 'clinically relevant', 'cohort', 'database of Genotypes and Phenotypes', 'falls', 'genetic variant', 'genome wide association study', 'genome-wide', 'human subject', 'insight', 'inter-individual variation', 'interest', 'knock-down', 'mortality', 'promoter', 'protein function', 'public health relevance', 'screening', 'small hairpin RNA', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'working group']",NHLBI,THOMAS JEFFERSON UNIVERSITY,R01,2017,392409,-0.00579755974951502
"Fast and Robust Methods for Large Scale Genotype Phenotype Association Study ﻿    DESCRIPTION (provided by applicant): A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Thanks to the advanced sequencing technologies, an enormous amount of genetic variants have been identified and cataloged. Such data hold great potential to understand how genes affect phenotypes and contribute to the susceptibility to environmental stimulus. However, the existing computational methods for analyzing and interpreting the high‐throughput genetic data are still in their infancy.    We propose to systematically investigate the computational and statistical principles in modeling and discovering genetic basis of complex phenotypes. The proposed research provides answers to the following fundamental questions in genetic association study: (1) How to effectively and efficiently assess statistical significance of the findings? (2) How to account for the relatedness between samples in genetic association study? (3) How to accurately capture possible interactions between multiple genetic factors and their joint contribution to phenotypic variation? In particular, we will develop data structures and efficient algorithms for accurate and robust significance assessment that account for local population structure and joint effect of multiple genetic factors.    The proposed computational tools will be integrated into software packages under common application framework adopted by the broad scientific community. PUBLIC HEALTH RELEVANCE: A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Existing methods are not able to adequately address the complexity of high throughput data. Innovative computational models and methods developed in this project will enable scientists more effectively analyze the research data, thus further understanding of human diseases and speed the development diagnostic tools, cures, and therapies.",Fast and Robust Methods for Large Scale Genotype Phenotype Association Study,9300990,R01GM115833,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Sciences', 'Catalogs', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Marker Expression', 'Genetic Markers', 'Genotype', 'Information Networks', 'Joints', 'Machine Learning', 'Measures', 'Methods', 'Mining', 'Modeling', 'Mus', 'Negative Finding', 'Noise', 'Performance', 'Phenotype', 'Phylogeny', 'Pilot Projects', 'Population', 'Predisposition', 'Property', 'Publications', 'Quantitative Trait Loci', 'Research', 'Research Institute', 'Sampling', 'Scientist', 'Speed', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Trees', 'Variant', 'base', 'computerized tools', 'data mining', 'exhaustion', 'experience', 'genetic association', 'genetic variant', 'human disease', 'improved', 'infancy', 'innovation', 'interest', 'novel', 'public health relevance', 'tool', 'trait']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2017,274718,0.02739799025213435
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,9250803,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'experimental study', 'genomic data', 'hazard', 'high dimensionality', 'human genomics', 'improved', 'individual patient', 'loss of function', 'novel', 'patient biomarkers', 'personalized genomic medicine', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'simulation', 'survival outcome', 'theories', 'treatment response', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2017,66026,0.0024939869268235083
"Whole Genome Sequencing in Irish Multiplex Schizophrenia Families Project Summary: Although affected members of multiplex schizophrenia pedigrees have substantially elevated recurrence risk compared to singleton cases, the mean polygenic risk scores between these groups do not differ, suggesting that one source of this higher familial recurrence risk is rare, higher impact variation. We will collect whole genome sequence (WGS) from 600 affected members of multiplex schizophrenia pedigrees to identify rare variation shared by affected individuals within and between pedigrees potentially accounting for the increased recurrence risk, and reducing the `variant space' under consideration. After QC and calling in our existing pipeline, a) familial sequence variants in the exome will be directly analyzed in 2000 Irish cases and 2000 Irish controls with 30X exome sequence data in production currently, and b) variants outside the exome will be imputed into 3600 Irish singleton schizophrenia or bipolar disorder cases and 3000 Irish population controls with GWAS framework data; 3781 additional UK10K controls with 10X WGS are available to increase analysis power. This imputed dataset will be analyzed using recently developed methods for kernel-based tests of variation aggregated over a defined interval (such as a gene) that avoid the inflation of type-1 error. We use multiple sources of genomic information to develop weights for each position in the genome (indexing the prior probability that a change at the site has functional consequence) and each variant detected (indexing the probability that observed changes have functional consequence), and we propose to improve the existing genomic information sources for this weighting in a number of ways. In aim 3, prioritized variants from aim 2a/2b will be directly genotyped in the case/control samples by custom microarray; individual genes or genesets showing enrichment of variation in cases (if any are observed) will be resequenced in the case/control sample. In Aim 4, the directly assessed genotypic and sequence data from aim 3 will be analyzed using standard methods to identify individual associated variants, and variant-enriched genes, genesets or other functional sequences. We seek to unambiguously identify 1) individual variants that are significantly more common in cases, or 2) individual genes or other functional sequences or 3) gene- or functional sequence sets enriched for variation in cases to provide critical information about the brain systems perturbed in schizophrenia, and the mechanisms by which such alleles increase risk. Project Narrative Rare sequence variation has been implicated in many human complex traits, incuding schizophrenia, and has been studied in unrelated cases and controls and parent:offspring trios, but remains unstudied in multiplex families. Sequencing the genomes of such families will allow conprehensive identification of variation in protein coding genes, non-coding expressed loci, regulatory sequences, and evolutionarily conserved regions, as well as detection of structural variation, and testing these alleles in a large case/control series of the same ethnic and geographic origin offers significant advantages over prior study designs, and has the potential to identify individual alleles, variant enriched genes, variant enriched non-genic sequences, and/or variant enriched genesets contributing to SCH risk in the Irish population. Such variants offer great potential for understanding the functional impact of risk alleles and improving mechanistic understanding of schizophrenia and related disorders.",Whole Genome Sequencing in Irish Multiplex Schizophrenia Families,9403711,R01MH114593,"['Accounting', 'Affect', 'Alleles', 'Biological Assay', 'Biology', 'Bipolar Disorder', 'Brain', 'Code', 'Complex', 'Custom', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Economic Inflation', 'Face', 'Family', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Human', 'Individual', 'Ireland', 'LGALS3BP gene', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Methods', 'Nucleotides', 'Parents', 'Phase', 'Population', 'Population Control', 'Positioning Attribute', 'Principal Investigator', 'Probability', 'Process', 'Production', 'Proteins', 'Psychotic Disorders', 'Recurrence', 'Research Design', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Schizophrenia', 'Series', 'Signal Transduction', 'Site', 'Source', 'System', 'Testing', 'Untranslated RNA', 'Variant', 'Weight', 'base', 'case control', 'design', 'effective therapy', 'exome', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'indexing', 'member', 'offspring', 'power analysis', 'programs', 'risk variant', 'sample collection', 'trait', 'whole genome', 'working group']",NIMH,VIRGINIA COMMONWEALTH UNIVERSITY,R01,2017,464747,0.002409678583561809
"Biomedical Computing and Informatics Strategies for Infectious Disease Research ﻿    DESCRIPTION (provided by applicant): An important goal of infectious disease research is to develop genetic predictors of susceptibility. Our success in this endeavor will depend critically on the informatics methods and software that are available for making sense of high-dimensional genetic and genomic data. The goal of this research program is to develop, evaluate, distribute and support new and novel biomedical computing algorithms and open-source software for identifying combinations of genetic predictors of clinically important infectious disease outcomes. This application will target the growing body of rare genetic variants identified by high-throughput DNA sequencing. Our clinical application will focus on the prediction of antiretroviral response in clinical trials for HIV/AIDS. We propose here a highly innovative Hierarchical Rare Variant Collapsing Machine (HRVCM) algorithm for identifying and collapsing combinations of rare variants across gene regions (AIM 1). We will then integrate these new collapsed HRVCM variables into our popular Multifactor Dimensionality Reduction (MDR) method that will assess them in combination with common single-nucleotide polymorphisms (SNPs) from genome-wide association studies or GWAS (AIM 2). Our novel HRVCM-MDR approach will, for the first time, make it possible to assess non-additive interactions among sets of rare and common variants simultaneously in genetic studies of infectious diseases. We will apply these new and novel methods to approximately 13 million rare and common variants from nearly 3000 subjects that participated in an AIDS Clinical Trials Group (ACTG) study to evaluate risk for virologic failure with efavirenz-containing antiretroviral therapy (ART) regimens (AIM 3). Finally, we will release all methods as open source to the biomedical research community through our freely available MDR software package (AIM 4). PUBLIC HEALTH RELEVANCE: The overall goal of this application is to develop innovative new computational methods for the genetic analysis of infectious diseases. We will focus on the development of methods that are able to detect synergistic effects of multiple genetic variants regardless of whether they are rare of common in human populations. We will apply these methods to the study of HIV/AIDS vaccination response.",Biomedical Computing and Informatics Strategies for Infectious Disease Research,9232970,R01AI116794,"['AIDS clinical trial group', 'AIDS/HIV problem', 'Algorithmic Analysis', 'Algorithms', 'Anti-Retroviral Agents', 'Bioinformatics', 'Biomedical Computing', 'Biomedical Research', 'Clinical Trials', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Dimensions', 'Disease Outcome', 'Disease susceptibility', 'Failure', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic Segment', 'Goals', 'Graph', 'High-Throughput DNA Sequencing', 'Human', 'Infectious Diseases Research', 'Informatics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Population', 'Predisposition', 'Regimen', 'Research', 'Risk', 'Single Nucleotide Polymorphism', 'Statistical Data Interpretation', 'Time', 'Vaccination', 'Variant', 'antiretroviral therapy', 'base', 'biomedical informatics', 'clinical application', 'clinical predictors', 'design', 'efavirenz', 'gene interaction', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'high dimensionality', 'innovation', 'method development', 'novel', 'open source', 'programs', 'public health relevance', 'rare variant', 'response', 'simulation', 'success', 'virology']",NIAID,UNIVERSITY OF PENNSYLVANIA,R01,2017,536755,0.05388442562430904
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9275537,U01HG009086,"['Accounting', 'Affect', 'Architecture', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2017,864186,0.06065930035622768
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9301599,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2017,300000,-0.01868828976759812
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,9461800,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Productivity', 'Protocols documentation', 'Publications', 'Recruitment Activity', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Standardization', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost efficient', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic epidemiology', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'programs', 'public health relevance', 'rare variant', 'software development', 'study population', 'success', 'symposium', 'tool', 'web site', 'whole genome', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2017,710189,0.02058656111228219
"Regulation of mRNA splicing by intronic genetic variants ﻿    DESCRIPTION (provided by applicant): Genetic variations in introns commonly impact cellular functions by causing alterations in mRNA splicing. The abnormal inclusion and exclusion of exons often change protein functions and cellular phenotypes. Although many intronic variations have known functions, with the adoption of next generation sequencing, many more intronic variants have been discovered for which the functional impact is unknown. Thus, it is important to be able to predict the impact of the variants without needing to test them all in expensive and laborious assays. Although there are informatics algorithms that predict the impact of genetic variants on pre-mRNA splicing, their ability to predict the effect on protein function and ultimately disease and therapeutic phenotypes is lacking. In addition, there is a need for high-throughput cellular assays to test the results of these predictions on cellular functions. The studies proposed here will fulfill these needs by developing algorithms that prioritize the intronic variants by their potential impact on splicing and gene function, and developing a high-throughput assay to functionally test thousands of these predictions. These novel technologies will be applied to the effect of intronic variants on the pharmacogenomics of two clinically important oncology drugs, clofarabine and paclitaxel. Our long-term goals are to be able to predict the functional impact of genomic variants on human disease and therapeutic response. Our central hypothesis is that intronic genetic variants alter mRNA splicing and consequently protein function that ultimately affects the cellular response to drug therapy. Our first aim will be to develop computational algorithms that prioritize intronic variants based on their impacts on pre-mRNA splicing and protein function. Using a variety of genomic and structural features and large sets of genomic data, we will develop a bioinformatics algorithm specifically designed to prioritize intronic variants based on their potential impacts on pre-mRNA splicing and protein function. Our second aim will be to identify functional intronic variants associated with drug-induced cytotoxicity. Using existing genomics and cellular cytotoxic response data from populations of human cell lines, we will identify functional intronic variants that contribute to individuals' responses to clofarabine and paclitaxel cytotoxicity. Our third aim will be to functionally test the impact of the prioritized intronic variants on pre-mRNA splicing and drug cytotoxicity. Using our novel high- throughput functional splicing assay, we will test the effects of predicted functional variants from Aim 2 on pre- mRNA splicing. In addition, we will validate the effect of the intronic variants on cytotoxicity using exon specific siRNA and CRISPR/Cas technology to manipulate the target gene splicing. Upon completion of these studies, we expect to have developed bioinformatics algorithms that can accurately prioritize the intronic variants based on their functional impact on pre-mRNA splicing and protein function. Also, we will have tested thousands of variants in a cellular pre-mRNA splicing assay and validated the impact of several of these functional variants on paclitaxel and clofarabine cytotoxicity. PUBLIC HEALTH RELEVANCE    Project Narrative The goal of this project is to design and implement a set of bioinformatics algorithms and high-throughput experimental assays for prioritizing functional intronic variants that contribute to phenotypic differences by affecting pre-mRNA splicing. The developed model, including a molecular validation component, will be used to systematically evaluate the functions of such variants that are associated with drug-induced cytotoxicity. The same strategy can also be used to study the etiology of complex diseases. This goal is directly relevant to the missions of NIH to improve the capability of disease diagnosis, treatment, and prevention.",Regulation of mRNA splicing by intronic genetic variants,9280888,R01CA213466,"['Adoption', 'Affect', 'Algorithms', 'Alternative Splicing', 'Bioinformatics', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Cell Line', 'Cell physiology', 'Cell-Mediated Cytolysis', 'Cellular Assay', 'Clinical', 'Clinical Research', 'Clofarabine', 'Complex', 'Computational algorithm', 'Computers', 'Data', 'Disease', 'Etiology', 'Exclusion', 'Exons', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genomics', 'Goals', 'Human', 'Human Cell Line', 'Human Genetics', 'Individual', 'Informatics', 'Introns', 'Machine Learning', 'Messenger RNA', 'Mission', 'Modeling', 'Molecular', 'Paclitaxel', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Population Genetics', 'Prevention', 'Publishing', 'RNA Splicing', 'Regulation', 'Research', 'Small Interfering RNA', 'Source', 'Spliced Genes', 'Test Result', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Work', 'base', 'cell type', 'cytotoxic', 'cytotoxicity', 'design', 'disease diagnosis', 'disease phenotype', 'functional genomics', 'gene function', 'genetic variant', 'genomic data', 'genomic predictors', 'genomic variation', 'high throughput screening', 'human disease', 'improved', 'mRNA Precursor', 'multidisciplinary', 'new technology', 'next generation sequencing', 'novel', 'oncology', 'prediction algorithm', 'protein function', 'protein structure', 'public health relevance', 'response', 'transcriptome sequencing', 'treatment response']",NCI,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2017,557164,0.018537658025378972
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9207474,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'cost', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'phenotypic data', 'pleiotropism', 'population stratification', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2017,297842,0.06363588442940873
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9349367,DP5OD019820,"['Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genomics', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'convict', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high dimensionality', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2017,326784,0.02690504125980334
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9349367,DP5OD019820,"['Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genomics', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Tissues', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'convict', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high dimensionality', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2017,1,0.02690504125980334
"Genomics-based prediction of antibiotic failure in S. aureus infections ﻿    DESCRIPTION (provided by applicant)    The Gram positive bacterium Staphylococcus aureus is both an asymptomatic human colonizer and a pathogen that can cause infections in multiple tissue sites, including blood, skin and soft tissue, bone, and internal organs. Methicillin resistant Staphylococcus aureus (MRSA) is a common cause of death by hospital infections (HA-MRSA) and is now also a common community acquired infection (CA-MRSA). Vancomycin (a glycopeptide antibiotic) is the most commonly prescribed drug to treat MRSA infections. High-level resistance (minimal inhibitory concentration (MIC) ≥16 μg/ml) to vancomycin encoded by the mobile vanA gene is rare due to a fitness burden on S. aureus. However, it is more common to encounter strains with mutations conferring intermediate resistance to vancomycin arising from selection during the course of antibiotic therapy. The genetic basis of these vancomycin intermediate S. aureus (VISA) and heterogeneous resistant (hVISA) (MIC 2-8 μg/ml) strains involves a large number of different genomic mutations that result in cell wall thickening through changes in cellular signaling and regulation. Routine phenotypic testing in clinical labs probably underestimates the incidence of VISA and hVISA. Due to the fact that mutations in several genes have been linked with VISA, genetic-based detection of intermediate vancomycin resistance has not been developed for routine clinical microbiological use. In our preliminary work, we created an extensive catalog of sequenced clinical and laboratory-selected VISA as well as databases of SNPs and genetic variation in thousands of public S. aureus genomes. In this work we plan to extend these studies toward development of a sequence-based testing protocol that could be used for large numbers of clinical strains. In Specific Aim 1 we plan to extend our knowledge of the mutations that cause VISA by sequencing a panel of 300 novel mutants strains spontaneously selected from 40 S. aureus parent genotypes. We estimate, based on the results of the preliminary data, that this number of strains will be sufficient identify mutations found in 95% of VISA strains. These data will be used for creation of a comprehensive VISA detection assay based on whole genome data with an accuracy of at least 95%. In Specific Aim 2 we will use the information learned from Aim 1 to create a multiplex PCR sequence test for VISA, VRSA and other resistance determinants of S. aureus based on the commercially available Fluidigm platform. We will ultimately aim to have an assay that can be used to monitor systemic MRSA infections, such as bacteremia, to detect development of VISA in its early stages in clinical specimens from the patient. The test will also be able to detect other S. aureus resistance phenotypes and call the genotype of the strain. PUBLIC HEALTH RELEVANCE    Vancomycin is an antibiotic commonly used to treat methicillin resistant Staphylococcus aureus (MRSA) infections in chronically ill patients. The efficacy of this relatively cheap and well-tolerated therapy is compromised by mutations in the genome of the bacterium. In this project we propose to develop a genetic test based on a library of MRSA genome sequences with known antibiotic susceptibility level that identifies bacteria with diminished resistance to vancomycin.",Genomics-based prediction of antibiotic failure in S. aureus infections,9241329,R21AI121860,"['Address', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotic susceptibility', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Base Sequence', 'Biological Assay', 'Blood', 'Catalogs', 'Cause of Death', 'Cell Wall', 'Chronically Ill', 'Clinical', 'Clinical Microbiology', 'Community-Acquired Infections', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Evolution', 'Failure', 'Frequencies', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Glycopeptide Antibiotics', 'Goals', 'Gram-Positive Bacteria', 'Healthcare', 'Human', 'Incidence', 'Infection', 'Intermediate resistance', 'Knowledge', 'Laboratories', 'Lead', 'Libraries', 'Link', 'Machine Learning', 'Methicillin', 'Modeling', 'Monitor', 'Mutation', 'Nosocomial Infections', 'Organ', 'Parents', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Protocols documentation', 'Regulation', 'Resistance', 'Signal Transduction', 'Site', 'Skin Tissue', 'Specimen', 'Staphylococcus aureus', 'Testing', 'Tissues', 'Training', 'Treatment Failure', 'University Hospitals', 'Vancomycin', 'Vancomycin Resistance', 'Vancomycin-resistant S. aureus', 'Variant', 'Virulence', 'Work', 'base', 'bone', 'design', 'economic cost', 'fitness', 'genetic predictors', 'genetic variant', 'interest', 'methicillin resistant Staphylococcus aureus', 'mortality', 'mutant', 'novel', 'pathogen', 'phenotypic data', 'pleiotropism', 'public health relevance', 'soft tissue', 'tool', 'whole genome']",NIAID,EMORY UNIVERSITY,R21,2017,195000,0.021577880803660496
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases. PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9275505,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2017,300742,0.03529626778050059
"F-CAP: Functionalization of Variants in Clinically Actionable Pharmacogenes ﻿    DESCRIPTION (provided by applicant): Patient-to-patient variability in response to drugs creates a significant challenge for the safe and effective treatment of many human diseases. Pharmacogenomics seeks to address this challenge by linking drug response to patient genotypes at important loci, termed pharmacogenes, in order to better customize patient treatments. Genetic variation in pharmacogenes is extensive. For example, amongst 12 CYP genes, 10% of people carry at least one rare, potentially deleterious variant. Unfortunately, only a small number of variants have been unambiguously linked to alterations in drug response. Clearly, new approaches are needed to annotate the consequences of the huge pool of variants of unknown significance, including those already identified by existing large-scale sequencing programs, and those that will be discovered as clinical sequencing becomes routine. In this proposal, we seek to address this problem directly and at a scale never before possible by taking advantage of new technologies in sequencing and functional analysis. Our resource, termed F-CAP (Functionalization of Variants in Clinically Actionable Pharmacogenes) will test all possible substitutions at all amino acid residues in some of the most clinically important pharmacogenes and disseminate these data to the medical and research communities. In order to accomplish this, we will use deep mutational scanning, a method we have developed that allows parallelized, and quantitative measurements to be performed on libraries of genetic variants. In Aim 1 we will create these libraries, starting with five of the most important CPIC level A or B priority genes (CYP2C9, CYP2C19, CYP2D6, TPMT and VKORC1), and test the stability and enzymatic activity of each variant en masse using a pooled selection strategy. In Aim 2, we will integrate these data to create an impact score. This impact score provides a numerical value for a variant's functional effects that is amenable to easy integration into prescribing guidelines being developed by the pharmacogenomics community. Aim 3 will validate this score for a subset of variants that span the impact score spectrum using therapeutically relevant substrates for each pharmacogene. Finally, Aim 4 describes a key component of this resource: the dissemination of our findings to the entire pharmacogenomics community through partnership with CPIC and PharmGKB. In addition, we will make available our raw and processed data via a custom web resource that will also be developed in Aim 4. This resource will provide a series of fully annotated datasets describing the functional consequences of every possible single mutation in a series of key pharmacogenes, thereby greatly advancing the field of personalized medicine. PUBLIC HEALTH RELEVANCE: Pharmacogenomics seeks to identify genetic sources of inter-individual variability in drug response, with the goal of personalizing drug selection and dose to improve patient outcomes. A key barrier to using pharmacogenomic information is lack of clarity about the functional impact of variants, which hampers the provision of clear, unambiguous guidance to health care providers. We propose to connect pharmacogenomic variant discovery with novel high-throughput experimental approaches to deliver a resource to guide the use of individual pharmacogenomic information in personalizing drug treatment.",F-CAP: Functionalization of Variants in Clinically Actionable Pharmacogenes,9302807,R24GM115277,"['Address', 'Affect', 'Algorithms', 'Amino Acids', 'Applications Grants', 'Biochemical', 'Biological Assay', 'CYP2C19 gene', 'CYP2C9 gene', 'CYP2D6 gene', 'Catalogs', 'Cellular Assay', 'Classification', 'Clinical', 'Code', 'Communities', 'Custom', 'Data', 'Data Set', 'Databases', 'Dose', 'Elements', 'Funding', 'Gene Library', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Guidelines', 'Health Personnel', 'High-Throughput DNA Sequencing', 'In Vitro', 'Individual', 'Large-Scale Sequencing', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Research', 'Methods', 'Monoclonal Antibody R24', 'Mutate', 'Mutation', 'Numerical value', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Plant Roots', 'Positioning Attribute', 'Process', 'Resources', 'Series', 'Source', 'TPMT gene', 'Testing', 'Therapeutic Uses', 'Translations', 'Variant', 'clinical sequencing', 'clinically actionable', 'effective therapy', 'exome', 'genetic disorder diagnosis', 'genetic information', 'genetic variant', 'genotyped patients', 'human disease', 'improved', 'interest', 'mutation screening', 'new technology', 'novel', 'novel strategies', 'online resource', 'personalized medicine', 'programs', 'public health relevance', 'response', 'stability testing', 'tool', 'user-friendly', 'variant of unknown significance']",NIGMS,UNIVERSITY OF WASHINGTON,R24,2017,737011,0.015341724603797577
"Genetic Factors in Keratoconus DESCRIPTION (provided by applicant): The purpose of this grant is to develop techniques for use in the 'early' detection of keratoconus (KC) and identify genetic variants that contribute to is development. KC is a complex genetic eye disorder and a leading cause of corneal transplantation in the young, with approximately 300,000 affected individuals in the US. Undiagnosed, subclinical KC is one of the major causes for complications of LASIK (Laser-in-situ- Keratomilieusis) surgery, commonly performed for vision correction. In the past two decades we have made major improvements to the early diagnosis of KC and have also made significant contributions to the delineation of major genetic determinants of KC through genome wide linkage studies (GWLS), fine mapping, and genome wide association studies (GWAS). In this proposal, we intend to follow up on these studies using new powerful approaches to achieve the following specific aims: In Aim 1 we will combine corneal optical coherence tomography (OCT) and Pentacam HR Scheimpflug Tomography (PST), new technologies that measure both the anterior and posterior surface of the cornea, with videokeratography (VK), a method which revolutionized KC diagnosis, to characterize criteria and to improve the diagnosis of subclinical KC. In Aim 2, to identify additional KC genes, we will perform a 2.5 million SNP GWAS, with an additional 6,000 SNPs, to fine- map already identified genes. We will confirm these results in a separate cohort of KC patients. For this two- stage GWAS design we are assembling the largest group of KC patients described to date: 2000 KC patients in total, 1,000 for the GWAS discovery stage and 1,000 for the confirmation stage. The controls for GWAS discovery will come from the Cardiovascular Health Study (CHS; 3300) and for confirmation will come from 400 subjects with VK, PST, and OCT measurements under Aim 1 and 600 ""convenience controls"" from the Cholesterol and Pharmacogenetics (CAP) study. In our current state of knowledge, the most cost-effective approach to increase the number of identified KC genes is to proceed with the expanded GWAS proposed herein. In Aim 3, we will test the impact of the genes identified in Aim 2 on the 'early' subclinical phenotypes identified through the use o VK, PST and OCT measures in Aim 1. Lastly, for the second part of Aim 3, we will investigate the potential function of KC variants by testing their ability to influence gene structure, expression and function in corneal cell models, including iPS cells derived from corneal keratocytes developed by our research team. The results of these studies will help advance our understanding of the genetic susceptibility to KC and may result in novel treatment options to slow the progression of the disease. PUBLIC HEALTH RELEVANCE: Improving methods for the 'early' detection of keratoconus will help patients avoid complications of LASIK surgery, allow us to identify genetic variants that contribute to its development, and design therapies to retard its progression.",Genetic Factors in Keratoconus,9238774,R01EY009052,"['Affect', 'Anterior', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cells', 'Clinical', 'Collaborations', 'Complex', 'Cornea', 'Custom', 'Data', 'Development', 'Diagnosis', 'Discriminant Analysis', 'Disease Progression', 'Early Diagnosis', 'Epidemiology', 'Etiology', 'Eye', 'Eye diseases', 'Family member', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Predisposition to Disease', 'Genetic Transcription', 'Genetic Variation', 'Genotype', 'Grant', 'Immunohistochemistry', 'In Situ', 'Individual', 'Keratoconus', 'Keratoplasty', 'Knowledge', 'Lasers', 'Lead', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Pathogenesis', 'Patients', 'Pharmacogenetics', 'Phenotype', 'Research', 'Research Design', 'Reverse Transcriptase Polymerase Chain Reaction', 'Risk', 'Surface', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Variant', 'Videokeratographies', 'Vision', 'base', 'bead chip', 'cardiovascular health', 'cholesterol control', 'cohort', 'cost effective', 'design', 'follow-up', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide linkage', 'improved', 'indexing', 'induced pluripotent stem cell', 'new technology', 'novel', 'prevent', 'protein expression', 'protein function', 'public health relevance', 'therapy design', 'tomography', 'tool', 'trait']",NEI,CEDARS-SINAI MEDICAL CENTER,R01,2017,770725,0.028673247548816293
"Integrative interpretation of the organismal consequences of non-coding variation ﻿    DESCRIPTION (provided by applicant): Our capacity to sequence human genomes has exceeded our ability to interpret genetic variation, particularly in non-coding regions. To address this challenge, we recently developed a novel framework, Combined Annotation Dependent Depletion (CADD), for estimating the deleteriousness of any genetic variant. CADD defines an objective, data-rich, and quantitative integration of many genomic annotations into a single measure of variant effect at the organismal level. The goals of this R01 proposal are to further develop the CADD framework, to apply it in the context of ongoing genetic studies of both rare and common human diseases, and to experimentally evaluate its predictions. In Specific Aim 1, we will substantially modify CADD in both straightforward and creative ways, with the goal of dramatically improving CADD's ability to annotate non- coding variants, not only to estimate their organismal effects but also to provide insights into molecular mechanisms. In Specific Aim 2, we will apply CADD to a variety of ongoing whole genome sequencing studies of human disease, especially those in which non-coding variants are either known or suspected to be causal. As part of this effort, we will develop new statistical frameworks that directly incorporat CADD into traditional genome-wide discovery approaches. In Specific Aim 3, we will perform a combination of high-throughput (massively parallel reporter assays), medium-throughput (CRISPR/Cas9), and low-throughput (in vivo mouse transgenics) experimental assays for systematic and targeted assessment of CADD predictions. This proposal includes both computational and experimental innovations, and builds on established collaborative relationships between investigators with complementary strengths. The completion of our aims will yield novel methods, data, and resources with which to annotate whole genome sequences, broadly enabling the field to more effectively identify and mechanistically understand non-coding genetic variants that are causally relevant to human disease. PUBLIC HEALTH RELEVANCE: As we enter an era of personalized medicine, a deep understanding of human genomes will be increasingly important to public health, contributing to the unraveling of the genetic basis of human disease, as well as serving an increasing role in clinical diagnostics. However, our limited understanding of the functional consequences of most genetic variants, especially those that do not alter protein sequence, represents a major obstacle. This proposal seeks to dramatically improve our ability to identify and interpret ""non-coding"" variants that causally contribute to human disease. A recently developed computational approach will be substantially improved and evaluated in a variety of genetic studies, and its predictions will be experimentally validated. This project will provide much needed methods and resources to address the looming analytical challenges associated with individual whole genome sequencing in both biomedical research and patient care.",Integrative interpretation of the organismal consequences of non-coding variation,9228346,R01CA197139,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biomedical Research', 'CRISPR/Cas technology', 'Cell Line', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Complex', 'Data', 'Data Set', 'Development', 'Disease', 'Event', 'Feedback', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Individual', 'Machine Learning', 'Measures', 'Mendelian disorder', 'Methods', 'MicroRNAs', 'Molecular', 'Mus', 'Mutation', 'Nature', 'Nucleotides', 'Organism', 'Pathogenicity', 'Patient Care', 'Phenotype', 'Property', 'Public Health', 'Quantitative Trait Loci', 'RNA Binding', 'RNA Splicing', 'Regulatory Element', 'Reporter', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Site', 'Structure', 'System', 'Testing', 'Tissues', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Translating', 'Untranslated RNA', 'Variant', 'Vocabulary', 'Weight', 'candidate identification', 'clinical diagnostics', 'data resource', 'disease phenotype', 'exome', 'exome sequencing', 'experimental study', 'follow-up', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'in vivo', 'innovation', 'insertion/deletion mutation', 'insight', 'novel', 'novel diagnostics', 'personalized medicine', 'public health relevance', 'trait', 'transcription factor', 'whole genome']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,632716,0.03258401100693396
"OMOP information model for eMERGE phenotyping ﻿    DESCRIPTION (provided by applicant): Medical care informed by genomic information is beginning to move into clinical practice. The Electronic Medical Records and Genomics (eMERGE) network through its initial phases has provided much of the groundwork for this transformation. The Geisinger Health System project, ""EMR-Linked Biobank for Translational Genomics"" intends to build on the knowledge and experience from eMERGE phase II to accelerate discovery and implementation while expanding our understanding of the sociocultural implications of genomics in medicine. We will accomplish this goal through three specific aims: 1) Use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery in the proposed disorders: familial hypercholesterolemia and chronic rhinosinusitis, 2) Develop and test approaches for implementation of genomic information in clinical practice, 3) Explore, develop and implement novel approaches for family-centered communication around clinically relevant genomic results. We currently have over 60,000 patients broadly consented for research with a large and increasing proportion consented for return of results and deposition in the electronic health record. Over 18,000 patients are genotyped on high density platforms. Our two proposed phenotypes, familial hypercholesterolemia (FH) and chronic rhinosinusitis (CRS) were chosen because both conditions have a significant public health impact in the United States, but they are also ideally suited to the specific aims of the project. They provide opportunities for innovation and extension of current eMERGE methods. While many of these innovations will take advantage of the sequencing done as part of the project, there are several other areas emphasized in the funding opportunity that will broaden the scope of eMERGE research. One of the areas of emphasis for eMERGE III is exploring the familial return of actionable results. FH is well suited to this, as the current clinical recommendation is cascade testing of family members for all diagnosed patients. Currently this relies on the patient to contact at risk family members, but this is less than optimal. We will explore this issue using qualitative and quantitative methods and use the results to design and test novel family communication strategies. Gene-environment interactions play an important role in the development and severity of disease. These are very difficult to study. We propose novel approaches that leverage the assets of Geisinger Health System and the eMERGE Network to develop and apply methods to extend existing projects that study the impact of environment on CRS. This would include the first large scale environment-wide association studies (EWAS). Finally, we propose to lead efforts to apply the tools of economic modeling and analysis to eMERGE projects to begin to quantify the value of implementation of genomic medicine in the US healthcare system. These proposed innovations will magnify the already significant impact that the eMERGE program has had in moving genomic medicine from a dream to a reality. PUBLIC HEALTH RELEVANCE: Through this application GHS seeks to continue its participation in the eMERGE Network for Phase III - Study Investigators U01 (RFA-HG-14-025) funding opportunity. We propose 3 specific aims: 1) use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery and validation of gene-phenotype associations; 2) develop and test approaches for implementation of genomic information in clinical practice; develop and implement novel approaches for family-centered communication around clinically relevant genomic results",OMOP information model for eMERGE phenotyping,9481767,U01HG008679,"['Adult', 'Algorithms', 'Ambulatory Care', 'Area', 'Attitude', 'Candidate Disease Gene', 'Caring', 'Catchment Area', 'Child', 'Clinical', 'Communication', 'Computerized Medical Record', 'Consent', 'County', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Dreams', 'Economic Models', 'Ecosystem', 'Electronic Health Record', 'Ensure', 'Environment', 'Familial Hypercholesterolemia', 'Familial disease', 'Family', 'Family member', 'Foundations', 'Funding Opportunities', 'Generations', 'Genes', 'Genomic medicine', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Group Practice', 'Health', 'Health Insurance', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Information Systems', 'Inpatients', 'Institute of Medicine (U.S.)', 'Integrated Health Care Systems', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Outcome Study', 'Participant', 'Patient Care', 'Patients', 'Pennsylvania', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Population', 'Process', 'Prognostic Factor', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Rural', 'Rural Population', 'Safety', 'Severity of illness', 'Site', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Treatment outcome', 'United States', 'Validation', 'Variant', 'base', 'biobank', 'case finding', 'chronic rhinosinusitis', 'clinical care', 'clinical practice', 'clinically relevant', 'density', 'design', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genotyped patients', 'implementation research', 'information model', 'innovation', 'interest', 'meetings', 'novel', 'novel strategies', 'personalized health care', 'phase 3 study', 'phenome', 'population based', 'programs', 'public health relevance', 'screening', 'tool', 'trait', 'translational genomics', 'treatment response']",NHGRI,GEISINGER CLINIC,U01,2017,100000,0.021120533715429865
"EMR-Linked Biobank for Translational Genomics ﻿    DESCRIPTION (provided by applicant): Medical care informed by genomic information is beginning to move into clinical practice. The Electronic Medical Records and Genomics (eMERGE) network through its initial phases has provided much of the groundwork for this transformation. The Geisinger Health System project, ""EMR-Linked Biobank for Translational Genomics"" intends to build on the knowledge and experience from eMERGE phase II to accelerate discovery and implementation while expanding our understanding of the sociocultural implications of genomics in medicine. We will accomplish this goal through three specific aims: 1) Use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery in the proposed disorders: familial hypercholesterolemia and chronic rhinosinusitis, 2) Develop and test approaches for implementation of genomic information in clinical practice, 3) Explore, develop and implement novel approaches for family-centered communication around clinically relevant genomic results. We currently have over 60,000 patients broadly consented for research with a large and increasing proportion consented for return of results and deposition in the electronic health record. Over 18,000 patients are genotyped on high density platforms. Our two proposed phenotypes, familial hypercholesterolemia (FH) and chronic rhinosinusitis (CRS) were chosen because both conditions have a significant public health impact in the United States, but they are also ideally suited to the specific aims of the project. They provide opportunities for innovation and extension of current eMERGE methods. While many of these innovations will take advantage of the sequencing done as part of the project, there are several other areas emphasized in the funding opportunity that will broaden the scope of eMERGE research. One of the areas of emphasis for eMERGE III is exploring the familial return of actionable results. FH is well suited to this, as the current clinical recommendation is cascade testing of family members for all diagnosed patients. Currently this relies on the patient to contact at risk family members, but this is less than optimal. We will explore this issue using qualitative and quantitative methods and use the results to design and test novel family communication strategies. Gene-environment interactions play an important role in the development and severity of disease. These are very difficult to study. We propose novel approaches that leverage the assets of Geisinger Health System and the eMERGE Network to develop and apply methods to extend existing projects that study the impact of environment on CRS. This would include the first large scale environment-wide association studies (EWAS). Finally, we propose to lead efforts to apply the tools of economic modeling and analysis to eMERGE projects to begin to quantify the value of implementation of genomic medicine in the US healthcare system. These proposed innovations will magnify the already significant impact that the eMERGE program has had in moving genomic medicine from a dream to a reality. PUBLIC HEALTH RELEVANCE: Through this application GHS seeks to continue its participation in the eMERGE Network for Phase III - Study Investigators U01 (RFA-HG-14-025) funding opportunity. We propose 3 specific aims: 1) use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery and validation of gene-phenotype associations; 2) develop and test approaches for implementation of genomic information in clinical practice; develop and implement novel approaches for family-centered communication around clinically relevant genomic results",EMR-Linked Biobank for Translational Genomics,9285815,U01HG008679,"['Adult', 'Algorithms', 'Ambulatory Care', 'Area', 'Attitude', 'Candidate Disease Gene', 'Caring', 'Catchment Area', 'Child', 'Clinical', 'Communication', 'Computerized Medical Record', 'Consent', 'County', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Dreams', 'Economic Models', 'Ecosystem', 'Electronic Health Record', 'Ensure', 'Environment', 'Familial Hypercholesterolemia', 'Familial disease', 'Family', 'Family member', 'Foundations', 'Funding Opportunities', 'Generations', 'Genes', 'Genomic medicine', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Group Practice', 'Health', 'Health Insurance', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Information Systems', 'Inpatients', 'Institute of Medicine (U.S.)', 'Integrated Health Care Systems', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Outcome Study', 'Participant', 'Patient Care', 'Patients', 'Pennsylvania', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Population', 'Process', 'Prognostic Factor', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Rural', 'Rural Population', 'Safety', 'Severity of illness', 'Site', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Treatment outcome', 'United States', 'Validation', 'Variant', 'base', 'biobank', 'case finding', 'chronic rhinosinusitis', 'clinical care', 'clinical practice', 'clinically relevant', 'density', 'design', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genotyped patients', 'implementation research', 'innovation', 'interest', 'meetings', 'novel', 'novel strategies', 'personalized health care', 'phase 3 study', 'phenome', 'population based', 'programs', 'public health relevance', 'screening', 'tool', 'trait', 'translational genomics', 'treatment response']",NHGRI,GEISINGER CLINIC,U01,2017,871212,0.021998801240977726
"Predicting causal non-coding variants in a founder population DESCRIPTION (provided by applicant): In order to characterize the molecular and cellular causes of human disease, it will be essential to unravel the functional impact of genetic variation. However, we are currently unable to predict the impact of the majority genetic variants that lie in non-coding regions of the genome, where indeed most complex disease-associated variants are found. Additionally, recent evidence suggests that a significant fraction of the non-coding genome is likely to be functional, often playing a role in gene regulation. Therefore, our limited understanding of non- coding variation is a critical hurdle to characterizing the genetic basis of disease. The goal of this project is to develop methods for interpreting non-coding genetic variation: to provide a robust and extensible Bayesian method for predicting causal variants from full genomes, to identify and validate a large set of functional non- coding variants using CRISPR technology, and to predict disease-relevant traits likely to be affected by each variant. Our project will leverage a unique cohort from a founder population in Sardinia, with genome sequence and/or transcriptome data available from 3000 individuals, along with extensive phenotyping for hundreds of traits. We will combine advanced statistical modeling with experimental validation based on genome engineering to identify causal non-coding variants affecting biomedical traits in the cohort, along with predicting functional mechanisms through which these variants ultimately perturb the cell. In Aim 1, we develop computational methods for predicting causal non-coding variation from full genomes, incorporating informative genomic features including epigenetic data, sequence motifs, and conservation information into a Bayesian approach jointly modeling multiple transcriptomic signals. We will optimize and apply these methods on genome and transcriptome data available for the Sardinia cohort to identify a large set of variants predicted to causally affect gene expression. Based on these predictions, in Aim 2, we connect putative causal variants with the diverse set of disease-relevant traits measured in the cohort, using network inference to capture the cascade from genetic variation to gene expression to disease. We will develop methods to integrate across variants, using the models in Aim 1, to identify the common causal mechanisms related to each trait. In Aim 3, we validate the causal impact of non-coding variants predicted to affect high-level traits. We will us genome editing through CRISPR to introduce individual genetic variants into cell lines and use qPCR to validate the predicted effects on gene expression. Finally, a major goal throughout this proposal will be to provide the research community with convenient computational tools for the prediction of causal non-coding variants from individual genomes, updated on an ongoing basis to integrate the most recent genomic annotations and public data in order to provide the best possible accuracy in predicting causal variants and the traits they are likely to affect. Our projet will greatly advance our understanding of non-coding genetic variation, the specific mechanisms affected by causal variants, and the downstream consequences to the cell and individual health. PUBLIC HEALTH RELEVANCE:  Understanding the impact of variation in the entire genome, beyond the well-studied protein-coding regions, is essential to understanding the relationship between genetics and human health. This proposal addresses the problem of identifying functional non-coding genetic variants and predicting the impact of each variant on hundreds of disease-relevant traits. Our approach will focus on integrative, transformative methods for understanding mechanisms underlying the function of the human genome.",Predicting causal non-coding variants in a founder population,9306895,R01HG008150,"['Address', 'Affect', 'Algorithmic Analysis', 'Alleles', 'Bayesian Method', 'Biological Assay', 'Biology', 'CRISPR/Cas technology', 'Cataloging', 'Catalogs', 'Categories', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complex', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Epigenetic Process', 'Family', 'Founder Generation', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Genetic', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Inherited', 'Link', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Nucleotides', 'Open Reading Frames', 'Pathogenesis', 'Phenotype', 'Play', 'Population', 'Property', 'RNA Splicing', 'Research', 'Resolution', 'Resources', 'Role', 'Sampling', 'Sardinia', 'Signal Transduction', 'Statistical Models', 'Supervision', 'System', 'Techniques', 'Testing', 'Transcript', 'Untranslated RNA', 'Update', 'Validation', 'Variant', 'Widespread Disease', 'base', 'cohort', 'computerized tools', 'data modeling', 'density', 'disease phenotype', 'disorder risk', 'functional genomics', 'genetic linkage analysis', 'genetic predictors', 'genetic variant', 'genome annotation', 'genome editing', 'genome sequencing', 'genomic data', 'genomic variation', 'human data', 'human disease', 'human genome sequencing', 'improved', 'innovation', 'insertion/deletion mutation', 'learning strategy', 'molecular phenotype', 'novel', 'prediction algorithm', 'public health relevance', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NHGRI,STANFORD UNIVERSITY,R01,2017,454272,0.0020113280727801198
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9232830,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Audiometry', 'Biological Preservation', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Computer Simulation', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Developing Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Impaired Persons', 'Hereditary Disease', 'Heritability', 'Human', 'Inherited', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Research Infrastructure', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical phenotype', 'clinically significant', 'cohort', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'hearing impairment', 'improved', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'tool']",NIDCD,UNIVERSITY OF IOWA,R01,2017,564086,0.041186791525711405
"IBD Gene Mapping by Clinical and Population Subset PROJECT SUMMARY Inflammatory bowel disease (IBD), Crohn's disease (CD) and ulcerative colitis (UC) are complex genetic disorders of the gastrointestinal tract, and a major health burden to patients and society. Tremendous progress has been made in dissecting IBD genetic etiology with identification of over 200 IBD loci by genome wide association studies (GWAS) but mainly limited to persons of European ancestry. The IBD Genetics Consortium (IBDGC) was established to facilitate multicenter collaborative studies of 6 Genetics Research Centers (GRCs) organized with a Data Coordinating Center (DCC). Our GRC at Johns Hopkins (JHGRC) has contributed to all IBDGC studies, meeting recruitment objectives and taking roles in IBDGC leadership positions. Our particular focus is on African American (AA) IBD genetics. We performed the first large-scale evaluation of European loci in the AA population, replicating several genes, but also finding unique African-ancestral variants within these loci, as well as identified multiple admixture significant loci. We also published the first AA IBD genome-wide association study (GWAS), a collaborative effort that identified two African-specific gene loci, and replicated multiple additional European loci. We have also explored why some loci with proven risk variants in Europeans and other populations only cause disease in one ancestral population but not others. More research in AA IBD is needed to understand the etiology of IBD in this ancestrally distinct, major American population. In this application we will re-evaluate the AA GWAS by better imputation, evaluate whole genome sequencing data to test low frequency and rare variants, and perform an evaluation for chromosome X variants. We will recruit a large number of AA IBD patients through our own and multiple Satellite Recruitment Centers to power a second AA IBD GWAS, both UC and CD, and meta-analyze with the first to identify more novel loci, identify more African specific risk variants, and replicate known loci for this population and replicate our admixture loci. We will also incorporate diverse data sources to incorporate into our GWAS analyses including RNA-Seq currently being generated on lymophoblastoid cell lines from AA CD cases and controls, and RNA-Seq that we will generate in colonic biopsies from UC cases and controls. We will evaluate chromatin differences and expression of genes in cell types relevant to IBD from European, AA and East Asian ancestries in an effort to better understand locus heterogeneity by ancestry. We will continue to participate in all IBDGC activities to maximize the Impact of IBD genetics research by this cooperative funding mechanism. According to the Center for Disease Control and Prevention, an estimated 1.4 million Americans suffer from Inflammatory Bowel Disease (IBD), a chronic debilitating disorder with no cure that includes Crohn's disease and ulcerative colitis. IBD ranks in the top 5 in prevalence for gastrointestinal disorders and represents a significant financial burden to society requiring a lifetime of medical care. This proposed research aims to determine the genetic variations that cause IBD which will aid in developing preventive measures, improving the quality of care with better treatments and educating patients through genetic counseling.",IBD Gene Mapping by Clinical and Population Subset,9402477,U01DK062431,"['ATAC-seq', 'Admixture', 'African', 'African American', 'Algorithms', 'American', 'Asians', 'Biopsy', 'Caring', 'Cell Line', 'Centers for Disease Control and Prevention (U.S.)', 'Charge', 'Chromatin', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Coculture Techniques', 'Cohort Studies', 'Collaborations', 'Complex', 'Crohn&apos', 's disease', 'DNA', 'Data', 'Data Coordinating Center', 'Data Sources', 'Databases', 'Disease', 'Effectiveness', 'Enhancers', 'Epithelium', 'Ethnic Origin', 'Etiology', 'European', 'Evaluation', 'Fostering', 'Frequencies', 'Funding', 'Funding Mechanisms', 'Future', 'Gastrointestinal Diseases', 'Gastrointestinal tract structure', 'Gene Expression', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Predisposition to Disease', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Goals', 'Health', 'Hereditary Disease', 'Heterogeneity', 'Hispanics', 'Human Characteristics', 'Individual', 'Inflammatory Bowel Diseases', 'Investigation', 'Lead', 'Leadership', 'Linkage Disequilibrium', 'Machine Learning', 'Medical', 'Modeling', 'Nature', 'Other Genetics', 'Pathway Analysis', 'Patients', 'Pattern', 'Persons', 'Phase', 'Phenotype', 'Point Mutation', 'Population', 'Population Genetics', 'Positioning Attribute', 'Prevalence', 'Preventive measure', 'Publications', 'Publishing', 'Quality of Care', 'Recruitment Activity', 'Research', 'Resources', 'Role', 'Sampling', 'Societies', 'Source', 'Testing', 'Ulcerative Colitis', 'Universities', 'Update', 'Variant', 'Work', 'X Chromosome', 'base', 'case control', 'cell type', 'differential expression', 'disorder prevention', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'improved', 'insight', 'interest', 'macrophage', 'meetings', 'novel', 'novel strategies', 'racial disparity', 'rare variant', 'risk variant', 'sex', 'study population', 'transcriptome sequencing', 'two-dimensional', 'whole genome']",NIDDK,RBHS-ROBERT WOOD JOHNSON MEDICAL SCHOOL,U01,2017,505613,0.025295219552930272
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9258454,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'RNA library', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'experimental study', 'functional genomics', 'genetic element', 'genome analysis', 'genome editing', 'genome-wide', 'genomic predictors', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2017,244439,-0.010643671940506002
"EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE ﻿    DESCRIPTION (provided by applicant): The eMERGE III Clinical Center proposal from Partners HealthCare leverages a large biobank, clinical data in the electronic medical records (EMR) for >4 million participants from the largest integrated health care provider in New England, advanced bioinformatics expertise and state-of-the-art genetic analysis. We propose three aims. (1) Aim 1. Discovery. We will test the hypothesis that common and rare variants from a custom chip including 50,000 loss of function (LoF) alleles will be associated with cardiovascular, neuropsychiatric and immune-mediated phenotypes derived from the EMR. We are currently genotyping 25,000 Partners HealthCare Biobank subjects with a custom chip that includes LoF alleles from 63,000 exomes that we have analyzed. (2) Aim 2. Penetrance and Pleiotropy. We will test the hypothesis that sequencing a set of established genes or loci will allow us to discover additional variation, and define penetrance and pleiotropy using EMR phenotypes. Rare variants in genes selected by the eMERGE network will be studied for penetrance and pleiotropic outcomes by PheWAS and chart review. In addition, we are poised to perform recall-by-genotype studies because all Biobank participants have provided consent for such callback. (3) Aim 3. Implementation. We will test the hypothesis that physicians will alter their surveillance and treatment of patients based upon voluntary return of actionable variants to provide safe and cost-effective benefits to patients. We will screen our entire Biobank population of 25,000 individuals for pathogenic variants in the LDLR gene, the leading genetic cause of premature coronary artery disease, and conduct an exploratory trial in disclosing this information. Biobank participants with pathogenic variants in LDLR will be offered enrollment into a randomized trial, in which their finding will be CLIA-confirmed, and in one arm, this result will be communicated to their physicians through the EMR. Over one year, we will collect the following outcomes through participant surveys and EMR queries: physician visits, laboratory testing, changes in medication prescriptions, LDL levels, medical costs and the number of family members screened and treated as a result of the intervention. We will collaborate with the entire eMERGE III Network to incorporate what we learn from this pilot trial into large-scale implementation protocols for the genes selected by the Network for sequencing. Finally, we will participate in all Network activities to enhance the movement of genetics into clinical practice. PUBLIC HEALTH RELEVANCE: The discovery and clinical use of genetic variants associated with both rare Mendelian and more common complex diseases promises to dramatically change the practice of medicine. Our eMERGE III project will leverage a large Biobank and a rich electronic medical record to define the phenotypic impact of mutations emerging from sequencing and then return results on selected variants to Biobank participants using a clinical trial.",EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE,9477855,U01HG008685,"['Algorithms', 'Alleles', 'Area', 'Asthma', 'Attention deficit hyperactivity disorder', 'Bioinformatics', 'Biology', 'Bipolar Disorder', 'CTLA4 gene', 'Callback', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computerized Medical Record', 'Congestive Heart Failure', 'Consent', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Cost Effectiveness Analysis', 'Custom', 'DRD2 gene', 'Data', 'Disease', 'Enrollment', 'Family member', 'Funding', 'Genes', 'Genetic', 'Genomic medicine', 'Genotype', 'Goals', 'HLA-DRB1', 'Health Personnel', 'Healthcare', 'Immune', 'Individual', 'Inflammatory Bowel Diseases', 'Informatics', 'Intervention', 'LDL Cholesterol Lipoproteins', 'LDLR gene', 'Laboratories', 'Learning', 'Low-Density Lipoproteins', 'Machine Learning', 'Mediating', 'Medical', 'Medicine', 'Mental Depression', 'Mining', 'Movement', 'Multiple Sclerosis', 'Mutation', 'New England', 'Newborn Infant', 'Outcome', 'Participant', 'Pathogenicity', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Population Attributable Risks', 'Protocols documentation', 'Public Health', 'Research', 'Rheumatoid Arthritis', 'Schizophrenia', 'Source', 'Stream', 'Stroke', 'Surveys', 'TCF7L2 gene', 'TNFRSF1A gene', 'TYK2', 'Testing', 'Variant', 'Visit', 'arm', 'base', 'biobank', 'biomarker panel', 'clinical care', 'clinical practice', 'clinical sequencing', 'clinically actionable', 'cost', 'cost effective', 'design', 'exome', 'experience', 'genetic analysis', 'genetic information', 'genetic variant', 'hypercholesterolemia', 'implementation research', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'pilot trial', 'pleiotropism', 'premature', 'public health relevance', 'randomized trial', 'rare variant', 'support tools']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2017,100000,0.04641073535949764
"EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE ﻿    DESCRIPTION (provided by applicant): The eMERGE III Clinical Center proposal from Partners HealthCare leverages a large biobank, clinical data in the electronic medical records (EMR) for >4 million participants from the largest integrated health care provider in New England, advanced bioinformatics expertise and state-of-the-art genetic analysis. We propose three aims. (1) Aim 1. Discovery. We will test the hypothesis that common and rare variants from a custom chip including 50,000 loss of function (LoF) alleles will be associated with cardiovascular, neuropsychiatric and immune-mediated phenotypes derived from the EMR. We are currently genotyping 25,000 Partners HealthCare Biobank subjects with a custom chip that includes LoF alleles from 63,000 exomes that we have analyzed. (2) Aim 2. Penetrance and Pleiotropy. We will test the hypothesis that sequencing a set of established genes or loci will allow us to discover additional variation, and define penetrance and pleiotropy using EMR phenotypes. Rare variants in genes selected by the eMERGE network will be studied for penetrance and pleiotropic outcomes by PheWAS and chart review. In addition, we are poised to perform recall-by-genotype studies because all Biobank participants have provided consent for such callback. (3) Aim 3. Implementation. We will test the hypothesis that physicians will alter their surveillance and treatment of patients based upon voluntary return of actionable variants to provide safe and cost-effective benefits to patients. We will screen our entire Biobank population of 25,000 individuals for pathogenic variants in the LDLR gene, the leading genetic cause of premature coronary artery disease, and conduct an exploratory trial in disclosing this information. Biobank participants with pathogenic variants in LDLR will be offered enrollment into a randomized trial, in which their finding will be CLIA-confirmed, and in one arm, this result will be communicated to their physicians through the EMR. Over one year, we will collect the following outcomes through participant surveys and EMR queries: physician visits, laboratory testing, changes in medication prescriptions, LDL levels, medical costs and the number of family members screened and treated as a result of the intervention. We will collaborate with the entire eMERGE III Network to incorporate what we learn from this pilot trial into large-scale implementation protocols for the genes selected by the Network for sequencing. Finally, we will participate in all Network activities to enhance the movement of genetics into clinical practice. PUBLIC HEALTH RELEVANCE: The discovery and clinical use of genetic variants associated with both rare Mendelian and more common complex diseases promises to dramatically change the practice of medicine. Our eMERGE III project will leverage a large Biobank and a rich electronic medical record to define the phenotypic impact of mutations emerging from sequencing and then return results on selected variants to Biobank participants using a clinical trial.",EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE,9284512,U01HG008685,"['Algorithms', 'Alleles', 'Area', 'Asthma', 'Attention deficit hyperactivity disorder', 'Bioinformatics', 'Biology', 'Bipolar Disorder', 'CTLA4 gene', 'Callback', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computerized Medical Record', 'Congestive Heart Failure', 'Consent', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Cost Effectiveness Analysis', 'Custom', 'DRD2 gene', 'Data', 'Disease', 'Enrollment', 'Family member', 'Funding', 'Genes', 'Genetic', 'Genomic medicine', 'Genotype', 'Goals', 'HLA-DRB1', 'Health Personnel', 'Healthcare', 'Immune', 'Individual', 'Inflammatory Bowel Diseases', 'Informatics', 'Intervention', 'LDL Cholesterol Lipoproteins', 'LDLR gene', 'Laboratories', 'Learning', 'Low-Density Lipoproteins', 'Machine Learning', 'Mediating', 'Medical', 'Medicine', 'Mental Depression', 'Mining', 'Movement', 'Multiple Sclerosis', 'Mutation', 'New England', 'Newborn Infant', 'Outcome', 'Participant', 'Pathogenicity', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Population Attributable Risks', 'Protocols documentation', 'Public Health', 'Research', 'Rheumatoid Arthritis', 'Schizophrenia', 'Source', 'Stream', 'Stroke', 'Surveys', 'TCF7L2 gene', 'TNFRSF1A gene', 'TYK2', 'Testing', 'Variant', 'Visit', 'arm', 'base', 'biobank', 'biomarker panel', 'clinical care', 'clinical practice', 'clinical sequencing', 'clinically actionable', 'cost', 'cost effective', 'design', 'exome', 'experience', 'genetic analysis', 'genetic information', 'genetic variant', 'hypercholesterolemia', 'implementation research', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'pilot trial', 'pleiotropism', 'premature', 'public health relevance', 'randomized trial', 'rare variant', 'support tools']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2017,916160,0.04641073535949764
"Systematic, Genome-Scale Functional Characterization of Conserved smORFs PROJECT SUMMARY Short peptides (10-100aa) are important regulators of physiology, development and metabolism, however their detection is difficult due to size and abundance. A stunning 30% of annotated human smORF genes include disease-associated variants mapped within exons, compared to 15% of human genes in general. Further, many smORFs are conserved across the entire metazoan phylogeny from invertebrates to vertebrates including man. These ultra-conserved functional smORF genes we call the Conserved smORF Catalog or CSC. These genes have been conserved across more than 500myr of evolution, and yet we know almost nothing at all about their functions. Due to a century of genetic analysis, the genome of the model organism Drosophila melanogaster has the most complete functional annotation among metazoans. Functional annotations derived from Drosophila have been instrumental in hypothesis-based drug development for more than thirty years, and more recently have made possible the biological interpretation of hundreds of SNPs detected in genome-wide association studies (GWAS). Hence, functional annotations derived in fly for conserved genes are transferable to human and are of direct clinical relevance. Remarkably, less than 10% of smORFs in Drosophila have been studied functionally, or experimentally verified as generating peptides. A combination of genome engineering, computational, molecular, and functional studies will be used to systematically and comprehensively characterize the CSC, representing the first genome-scale characterization of smORFs in any organism providing a wealth of information on the biological functions of this poorly studied class of proteins. In total, we will characterize and functionally annotate ~400 conserved smORFs using CRISPR knockout followed by phenotyping and rescue assays. We will assess the phenotypes of the mutants, measuring viability, morphology, fecundity and fertility, lifespan, metabolism (sugar and lipid levels), and a number of behavioral phenotypes. For smORFs with robust phenotypes, we will then attempt to rescue a subset of these mutants in three ways: first, by inserting the whole deleted RNA; second, with a version of the RNA with the smORF(s) removed by the addition a stop codon; and lastly, using a micro- construct containing only the smORF and the endogenous promoter. We will generate direct evidence for translation using tagged expression analysis and targeted MS/MS to scan for predicted polypeptides in the whole embryo and tissue dissection samples. In addition to validating the existence of the predicted molecules, this dataset will provide a foundational gold standard for further development of tools for the computational prediction of functional micropeptides. These studies are directed toward the understanding of basic life processes and lay the foundation for promoting better human health. PROJECT NARRATIVE As a public resource, our studies will combine genome-scale phenotyping with detailed functional characterization that will assess the effects of evolutionary conserved small open reading frames (smORFs) on animal viability, development, fecundity, metabolism, longevity and behavior. We will apply state-of-the art methods in Ribosomal profiling, CRISPR genome engineering and targeted mass spectrometry together with the development of new computational tools and analyses to generate a foundational gold standard dataset for the study of smORFs and the prediction of functional smORFs in genome annotation. Many of the genes encoding these molecules have been found to play important roles in human diseases such as neurodegeneration, developmental disorders and cancer.","Systematic, Genome-Scale Functional Characterization of Conserved smORFs",9228843,R01HG009352,"['Adipose tissue', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Animals', 'Arthropods', 'Autoimmune Diseases', 'Behavior', 'Behavioral', 'Biological', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Catalogs', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Codon Nucleotides', 'Collection', 'Computer Analysis', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Dissection', 'Drosophila genus', 'Drosophila melanogaster', 'Drug Targeting', 'Evolution', 'Exons', 'Fertility', 'Foundations', 'Frameshift Mutation', 'Gene Transfer', 'Genes', 'Genetic Transcription', 'Genome', 'Genome engineering', 'Gold', 'Health', 'Human', 'Human Genome', 'Image', 'In Situ', 'Invertebrates', 'Knock-out', 'Life', 'Lipids', 'Literature', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Messenger RNA', 'Metabolism', 'Methods', 'Molecular', 'Morphology', 'Muscle', 'National Human Genome Research Institute', 'Nerve Degeneration', 'Nervous system structure', 'Neurodegenerative Disorders', 'Neurotransmitters', 'Ontology', 'Open Reading Frames', 'Organism', 'Peptides', 'Phenotype', 'Phylogeny', 'Physiology', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Reproducibility', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Scanning', 'System', 'Technology', 'Terminator Codon', 'Time', 'Tissues', 'Translating', 'Translations', 'Variant', 'Vertebrates', 'adipokines', 'base', 'clinically relevant', 'computerized tools', 'developmental disease', 'drug development', 'drug resource', 'embryo tissue', 'fly', 'gene function', 'genetic analysis', 'genome annotation', 'genome wide association study', 'genome-wide', 'human disease', 'in situ imaging', 'insight', 'knock-down', 'man', 'mutant', 'novel', 'overexpression', 'polypeptide', 'promoter', 'ribosome profiling', 'sugar', 'tool', 'tool development', 'translational genomics', 'virtual']",NHGRI,UNIVERSITY OF CALIF-LAWRENC BERKELEY LAB,R01,2017,1002725,0.004211554028128526
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9320861,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Comorbidity', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electrophysiology (science)', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Human Genome Research Institute', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Phenotype', 'Population', 'Prediction of Response to Therapy', 'Prosencephalon', 'Psychiatry', 'Psychotic Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Standardization', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'experimental study', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'insight', 'interest', 'molecular phenotype', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'public health relevance', 'relating to nervous system', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2017,2548493,0.005450084718056185
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9320861,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Comorbidity', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electrophysiology (science)', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Human Genome Research Institute', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Phenotype', 'Population', 'Prediction of Response to Therapy', 'Prosencephalon', 'Psychiatry', 'Psychotic Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Standardization', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'experimental study', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'insight', 'interest', 'molecular phenotype', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'public health relevance', 'relating to nervous system', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2017,750000,0.005450084718056185
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control. PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,8994718,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Health', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Peptide Sequence Determination', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'flu', 'genome sequencing', 'genomic data', 'genomic signature', 'improved', 'influenza outbreak', 'influenza virus vaccine', 'influenzavirus', 'learning strategy', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'receptor binding', 'research study', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2016,370329,0.025666829030835822
"Mathematical Models and Statistical Methods for Large-Scale Population Genomics ﻿    DESCRIPTION (provided by applicant):     Technological advances in DNA sequencing have dramatically increased the availability of genomic variation data over the past few years. This development offers a powerful window into understanding the genetic basis of human biology and disease risk. To facilitate achieving this goal, it is crucial to develop efficient analytical methods that will allow researchers to more fuly utilize the information in genomic data and consider more complex models than previously possible. The central goal of this project is to tackle this important challenge, by carrying out te following Specific Aims: In Aim 1, we will develop efficient inference tools for whole-genome population genomic analysis by extending our ongoing work on coalescent hidden Markov models and apply them to large-scale data. The methods we develop will enable researchers to analyze large samples under general demographic models involving multiple populations with population splits, migration, and admixture, as well as variable effective population sizes and temporal samples (ancient DNA). Multi-locus full-likelihood computation is often prohibitive in most population genetic models with high complexity. To address this problem, we will develop in Aim 2 a novel likelihood-free inference framework for population genomic analysis by applying a highly active area of machine learning research called deep learning. We will apply the method to various parameter estimation and classification problems in population genomics, particularly joint inference of selection and demography. In addition to carrying out technical research, we will develop a useful software package that will allow researchers from the population genomics community to utilize deep learning in their own research. It is becoming increasingly more popular to utilize time-series genetic variation data at the whole-genome scale to infer allele frequency changes over a time course. This development creates new opportunities to identify genomic regions under selective pressure and to estimate their associated fitness parameters. In Aim 3, we will develop new statistical methods to take full advantage of this novel data source at both short and long evolutionary timescales. Specifically, we will develop and apply efficient statistical inference methods for analyzing time-series genomic variation data from experimental evolution and ancient DNA samples. Useful open-source software will be developed for each specific aim. The novel methods developed in this project will help to analyze and interpret genetic variation data at the whole-genome scale. PUBLIC HEALTH RELEVANCE:     This project will develop several novel statistical methods for analyzing and interpreting human genetic variation data at the whole-genome scale. The computational tools stemming from this research will enable efficient and accurate inference under complex population genetic models, thereby broadly facilitating research efforts to understand the genetic basis of human biology and disease risk.",Mathematical Models and Statistical Methods for Large-Scale Population Genomics,9145232,R01GM094402,"['Accounting', 'Address', 'Admixture', 'Affect', 'Age', 'Alleles', 'Area', 'Classification', 'Communities', 'Complex', 'Computer software', 'DNA', 'DNA Resequencing', 'DNA Sequence', 'Data', 'Data Sources', 'Demography', 'Development', 'Diffusion', 'Event', 'Evolution', 'Gene Frequency', 'Genetic', 'Genetic Models', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Health', 'Human Biology', 'Human Genetics', 'Individual', 'Joints', 'Learning', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'Mutation', 'Phase', 'Physiologic pulse', 'Population', 'Population Genetics', 'Population Sizes', 'Recording of previous events', 'Research', 'Research Personnel', 'Sampling', 'Series', 'Site', 'Statistical Methods', 'Technology', 'Time', 'Trees', 'Uncertainty', 'Work', 'analytical method', 'base', 'computer based statistical methods', 'computerized tools', 'coping', 'disorder risk', 'fitness', 'genetic analysis', 'genetic selection', 'genome-wide', 'genomic data', 'genomic variation', 'human disease', 'interest', 'markov model', 'mathematical model', 'migration', 'novel', 'open source', 'pressure', 'stem', 'tool', 'whole genome']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2016,303092,0.05697026825496183
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,9117987,F32GM116381,"['Acceleration', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Chromosome Mapping', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Health', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mutation', 'Mutation Spectra', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'admixture mapping', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'learning strategy', 'melanoma', 'offspring', 'rare variant', 'rate of change', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2016,56118,0.030679903301302415
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9180486,K99HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'abstracting', 'base', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'learning strategy', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'tool']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",K99,2016,83411,0.01469674188159728
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,8991662,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'learning strategy', 'mRNA Precursor', 'novel', 'prediction algorithm', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2016,43576,-0.00736560330970851
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,9288249,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Mendelian disorder', 'Methodology', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinical sequencing', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic counselor', 'genetic variant', 'genome analysis', 'genome sequencing', 'genome-wide', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web portal', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2016,900000,0.055671522470836954
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,9288249,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Mendelian disorder', 'Methodology', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinical sequencing', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic counselor', 'genetic variant', 'genome analysis', 'genome sequencing', 'genome-wide', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web portal', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2016,162125,0.055671522470836954
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,9134491,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Mendelian disorder', 'Methodology', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinical sequencing', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic counselor', 'genetic variant', 'genome analysis', 'genome sequencing', 'genome-wide', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web portal', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2016,2234652,0.055671522470836954
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,9268117,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost effectiveness', 'cost efficient', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2016,1378926,0.007428793979583403
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease. The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,9126587,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Bayesian Modeling', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genetic study', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2016,241086,0.03776379856897066
"Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases ﻿    DESCRIPTION (provided by applicant): The NHGRI Genome Sequencing Program (GSP) will identify genomic variants relevant to health and disease by genome sequencing over 225,000 participants across a multitude of diseases. The GSP will also serve as a pilot for the Precision Medicine Initiative that aims to enroll and sequence more than a million people representative of U.S. ethnic diversity. Here, we propose a GSP analysis center focused on Multi- and Trans- ethnic Mapping of Mendelian and Complex Diseases. There is a growing recognition of the substantial scientific advantages, as well as public health importance, of conducting biomedical research across ethnically diverse cohorts. We propose to develop scalable methods that incorporate ancestry to optimize medical genomic study design and improve power for uncovering the role of common and rare variants in disease. Achieving this goal requires expertise across diverse domains of knowledge including: medical and population genomics, algorithm development for complex disease mapping, and expertise in management of large-scale databases. Here, we have assembled a world-class team of medical and population geneticists, computer scientists, statisticians and clinicians, with leading expertise in the development of novel and scalable strategies for characterizing sequence variants and their role in disease. Importantly, our group has been at the forefront of development of resources, study designs and methods to enable genomic research in U.S. minority populations. Our project has three main objectives. First, we will develop an Automated Scalable Ancestry Pipeline (ASAP) for common disease mapping in diverse populations. ASAP will improve the computational efficiency of existing state-of-the-art methods for ancestry inference and develop important extensions to linear mixed models (LMMs) and other mapping strategies leveraging local and global ancestry. We will also develop methods to refine phenotypes and identify common controls for disease studies and define endpoints. Secondly, we will develop tools and resources for trans- and multi-population rare variant discovery that incorporate patterns of local and sub-continental ancestry. We will also develop machine-learning tools for variant annotation that leverage ancestral information, patterns of sequence evolution, and protein structure in a unified framework. Furthermore, we will incorporate population-specific patterns of cellular phenotypes to improve functional prediction algorithms for non-coding and coding variants. Lastly, we will disseminate our results through web-based resource that empower the biomedical research community. We will augment existing resources including ClinGen by annotating and characterizing pathogenic variants across diverse populations. We will develop a secure web-server that allows sharing of summary statistics and analysis pipelines to enable discovery, fine-mapping and functional prediction of genetic variants. Our team has ample experience with NIH-funded consortia and is dedicated to meeting the overall GSP project goals through collaborative work with NHGRI leadership and other funded investigators.         PUBLIC HEALTH RELEVANCE The goal of our project is to accelerate the discovery of DNA variation relevant to health and disease by analyzing data from over 225,000 ethnically and racially diverse patients that will undergo genome sequencing. Of particular importance is ensuring we have powerful statistical methods for analyzing data from underserved groups including U.S. minority populations. Achieving this goal requires expertise across many domains of knowledge including: medical and population genomics, algorithm development for disease mapping, and expertise in large-scale databases.              ",Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases,9132536,U01HG009080,"['Algorithms', 'Architecture', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Code', 'Communities', 'Complex', 'Computers', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Enrollment', 'Ensure', 'Evolution', 'Funding', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human Genome', 'Internet', 'Investigation', 'Knowledge', 'Leadership', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Methods', 'Methylation', 'Minority', 'Modeling', 'Molecular Conformation', 'National Human Genome Research Institute', 'Online Systems', 'Participant', 'Pathogenicity', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Population Heterogeneity', 'Precision Medicine Initiative', 'Protocols documentation', 'Public Health', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resource Development', 'Resources', 'Risk', 'Role', 'Scientist', 'Secure', 'Shoulder', 'Statistical Methods', 'Target Populations', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Work', 'cohort', 'disorder control', 'empowered', 'ethnic diversity', 'experience', 'genetic variant', 'genome sequencing', 'genomic tools', 'improved', 'innovation', 'large-scale database', 'meetings', 'novel', 'patient privacy', 'phenome', 'prediction algorithm', 'programs', 'protein structure', 'public health relevance', 'racial diversity', 'rare variant', 'simulation', 'statistics', 'tool', 'tool development']",NHGRI,STANFORD UNIVERSITY,U01,2016,974394,0.05805977600330793
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies (1-3). In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods (1,2). We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data and this paper is in press. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meeting and a manuscript in development. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published a paper describing this method(2). We are currently developing The Machine Suite which will be an extension of r2VIM.  We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011 and another in 2014. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.  This year we have worked on optimizing methods for performing multipoint analyses using extremely dense WES and exome chip data sets, and have shown that several linkage methods that purport to adequately adjust for intermarker linkage disequilibrium do not control false positive rates adequately when data of this extreme density is analyzed. This research was awarded a platform presentation at the 2015 International Genetic Epidemiology Society meeting (CL Simpson).  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. A paper this year was published presenting an extension to these methods for mixed effect models (4). We are now in the process of applying these approaches to several of our genome-wide datasets.  Finally, we have collaborated with members of Dr. Alexander Wilsons group (Genometrics Section, CSGB, NHGRI) on several methods development projects including testing of their TRAP method (5) and an ongoing project to develop approaches for selecting significant variants from GWAS when no replication samples are available, such that false positive rates are well controlled. n/a",Development of statistical genetics methodology,9359824,ZIAHG000153,"['African American', 'Award', 'Biological Models', 'Caucasians', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'International', 'Linear Models', 'Linkage Disequilibrium', 'Logistic Regressions', 'Machine Learning', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Probability', 'Process', 'Publishing', 'Research', 'Running', 'Sampling', 'Scheme', 'Sequence Analysis', 'Societies', 'Statistical Methods', 'Structure', 'Testing', 'Trees', 'Variant', 'Work', 'base', 'case control', 'data mining', 'density', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'learning strategy', 'meetings', 'member', 'method development', 'novel', 'oral cleft', 'programs', 'quality assurance', 'rare variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2016,485269,0.0323701953825969
"Decrypting Variants of Uncertain Significance in Long-QT Syndrome DESCRIPTION (provided by applicant): Clinical genetic testing has become standard-of-care for many diseases including hundreds of inherited conditions. However, interpreting genetic test results is often confounded by the discovery of 'variants of unknown significance' (VUS) for which there is insufficient data or inadequate predictive tools to establish whether or not a particular variant predisposes to a disease. This problem is particularly vexing for genetic disorders with strong allelic heterogeneity and a preponderance of 'private' mutations such as the congenital long-QT syndrome (LQTS), which predisposes young adults and children to sudden death from cardiac arrhythmias. With the anticipated incorporation of personal exome or genome data into routine clinical care, interpreting VUS will become an even greater challenge especially when variants in genes associated with human disorders are incidentally discovered. Unfortunately, there are no reliable methods to predict a priori whether a given variant predisposes an individual to a particular disorder or whether the change is merely a benign rare variant. We propose to develop a novel paradigm for distinguishing disease-causing mutations from benign variants in LQTS as a model for other inherited arrhythmia syndromes and channelopathies. We will focus on variants in KCNQ1, the most commonly mutated gene in LQTS. The central hypothesis of this proposal is that a holistic predictive model that relates experimentally determined protein structure and dynamics to function and disease is highly accurate even for novel variants. Our ultimate objectives are to develop a data-trained, web-accessible algorithm that classifies VUS discovered in KCNQ1 based on reliable predictions of the structure and dynamics of the affected protein, and to achieve prediction accuracy to levels needed to inform medical decisions. The medical importance of correctly classifying KCNQ1 variants provides strong justification for having a dedicated and highly-tailored gene-specific prediction model. The ability to distinguish deleterious from neutral variants would help avoid unnecessary and potentially harmful interventions in carriers of benign alleles, and save the lives of those with true mutations. We propose to collect extensive electrophysiological, biochemical and structural data on a large set of KCNQ1 variants discovered in LQTS subjects as well as several suspected benign or neutral variants (Aims 1-2), then use these data to iteratively train and validate a machine learning based algorithm that can differentiate benign from deleterious KCNQ1 alleles among a set of new VUS (Aim 3). Our proposal is innovative in the use of a multidisciplinary approach to functionally and structurally annotate genomic variant data for a medically important gene at an unprecedented scale, and then to use these experimental findings to train/test a novel computational system to achieve clinical-grade predictions. Targeting KCNQ1 will also validate an approach for parallel work that can be utilized to predict the medical significance of variants in closely related potassium channels associated with heritable epilepsy (KCNQ2, KCNQ3) or deafness (KCNQ4). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a method to reliably predict the consequences of genetic variants of unknown significance discovered in the course of genetic testing in the congenital long-QT syndrome (LQTS), a cause of sudden cardiac death in children and young adults. We propose a multidisciplinary experimental approach including electrophysiology, biochemistry and structural biology deployed on a large scale to generate information on at least 110 genetic variants in the main gene responsible for LQTS (KCNQ1), which encodes a potassium channel required for normal electrical activity in the heart. Our final product will be a data-trained computational strategy that will outperform existing methods for accurately predicting the functional consequences of novel KCNQ1 genetic variants, enhance the value of genetic testing in LQTS and provide for more informed medical decisions.",Decrypting Variants of Uncertain Significance in Long-QT Syndrome,9111957,R01HL122010,"['Affect', 'Algorithms', 'Alleles', 'Anti-Arrhythmia Agents', 'Arrhythmia', 'Benign', 'Biochemical', 'Biochemistry', 'Biological', 'Cardiac', 'Cell surface', 'Child', 'Clinical', 'Computer Simulation', 'Data', 'Data Set', 'Defibrillators', 'Development', 'Disease', 'Electrophysiology (science)', 'Epilepsy', 'First Degree Relative', 'Genes', 'Genetic screening method', 'Genome', 'Goals', 'Heart', 'Hereditary Disease', 'Heterogeneity', 'Human', 'Implant', 'Individual', 'Inherited', 'Intervention', 'Ion Channel', 'Link', 'Long QT Syndrome', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Online Systems', 'Other Genetics', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Potassium Channel', 'Predisposition', 'Protein Dynamics', 'Proteins', 'Research Personnel', 'Resources', 'Structure', 'Sudden Death', 'Syndrome', 'System', 'Test Result', 'Testing', 'Therapeutic', 'Training', 'Variant', 'Work', 'base', 'clinical care', 'deafness', 'design', 'disease-causing mutation', 'exome', 'genetic variant', 'genome sequencing', 'heart rhythm', 'individual patient', 'innovation', 'interdisciplinary approach', 'knowledge base', 'multidisciplinary', 'novel', 'prediction algorithm', 'predictive modeling', 'predictive tools', 'proband', 'protein function', 'protein structure', 'protein transport', 'public health relevance', 'rare variant', 'research study', 'standard of care', 'structural biology', 'sudden cardiac death', 'trafficking', 'variant of unknown significance', 'web-accessible', 'young adult']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2016,1277210,0.027901898463696805
"Statistical and computational analysis in whole genome sequencing studies. DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges. PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.",Statistical and computational analysis in whole genome sequencing studies.,9103177,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Health', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'learning strategy', 'meetings', 'population based', 'programs', 'whole genome']",NHGRI,STANFORD UNIVERSITY,R01,2016,300000,0.05332740445230103
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,9208745,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'deletion detection', 'design', 'genetic variant', 'genome sequencing', 'improved', 'integration site', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2016,2868077,0.028885365375899325
"An integrative approach to functionalize GWAS hits in MI and stroke ﻿    DESCRIPTION (provided by applicant): Coronary heart disease (CHD) and cerebrovascular disease result from platelet thrombus formation at the site of a ruptured atherosclerotic plaque. Numerous studies have shown enhanced platelet reactivity, and increased platelet count and volume are risk factors for CHD events and fatality, and a recent NHLBI Working Group concluded that variation in platelet reactivity is a major determinant of ischemic events, like MI or stroke. Genome wide association studies (GWASs) have identified numerous common genetic variants associated with the risk of CHD and platelet function parameters, but most of the positive ""hits"" are not causative of the phenotype. To understand the cellular mechanisms by which these variants affect platelet function it is imperative to know the repertoire of mRNAs, miRNAs and lncRNAs expressed in the cell of interest. Our team has been a leader in the field of platelet transcriptomics as well as functional assessment of variants in platelet genes. We have profiled mRNAs and miRNAs from 183 subjects using multiple platforms and have also performed platelet RNA-seq on 14 different subjects. This information provides a critical ability to filter, prioritize and obtain variant functional insights for evaluating GWAS SNPs associated with MI, stroke and platelet parameters. We have identified 142 mRNAs and 9 miRNAs that are expressed in platelets and linked to these GWAS hits. The goals of this proposal are to identify, assay, and validate functional variation previously tagged in GWASs of platelet-mediated ischemic arterial disease and of platelet phenotypes. Aim 1 will identify GWAS-linked mRNAs, miRNAs and lncRNAs that are functional in platelets. Candidate RNAs will be refined by association with platelet function, eQTLs and QTLs using our previously generated platelet RNA data. We will develop a supervised machine-learning, statistical pattern matching algorithm to prioritize likely platelet-functional genes. Gene-level assays in which we knock down mRNA, miRNA and lncRNA in our human megakaryocyte culture system, followed by assays for integrin activation and quantification of platelet number and volume will be used to confirm platelet functionality. Aim 2 will identify functionally divergent SNPs and haplotypes. We will impute missing SNPs and perform fine-mapping to the phenotypes of interest. Variants will be prioritized by association strength, annotation data, and predicted function using publically available resources and our own platelet eQTL data. Non-coding candidates will be tested by reporter gene assay and non-synonymous variants will be tested using functional assays in cell lines in which the endogenous gene has been silenced. We will validate our findings with a replication analysis in which we use an independent cohort dataset to quantify the association of the tested variants with the original GWAS phenotype. PUBLIC HEALTH RELEVANCE:  Platelet-mediated arterial thrombosis in the coronary or cerebrovascular circulation is the major cause of mortality and morbidity in the U.S. Numerous DNA variations have been associated with these disorders, but the causal genes are unknown. This research will test whether genes near these DNA variations - and candidate variations themselves - alter platelet function or number to understand better the molecular mechanisms causing heart attacks and strokes.",An integrative approach to functionalize GWAS hits in MI and stroke,9115225,R01HL128234,"['Affect', 'Algorithms', 'Alleles', 'Amino Acids', 'Arterial Fatty Streak', 'Binding', 'Bioinformatics', 'Biological Assay', 'Blood Platelet Disorders', 'Blood Platelets', 'CD34 gene', 'Cell Line', 'Cells', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'ChIP-seq', 'Coronary Circulation', 'Coronary heart disease', 'Coupled', 'DNA', 'Data', 'Data Set', 'Disease', 'Distal', 'Enhancers', 'Event', 'Gene Expression', 'Genes', 'Genotype', 'Goals', 'Haplotypes', 'Health', 'Human', 'Individual', 'Integrins', 'Introns', 'Investigation', 'Laboratories', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Mediator of activation protein', 'Megakaryocytes', 'Messenger RNA', 'Methods', 'MicroRNAs', 'Molecular', 'Morbidity - disease rate', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'Nucleic Acid Regulatory Sequences', 'Pathologic', 'Pattern', 'Phenotype', 'Platelet Activation', 'Platelet Count measurement', 'Positron-Emission Tomography', 'Prevention', 'Production', 'Protocols documentation', 'RNA', 'Reporter Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Rupture', 'Sentinel', 'Site', 'Stroke', 'System', 'Testing', 'Thrombosis', 'Thrombus', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'base', 'clinical phenotype', 'clinically relevant', 'cohort', 'falls', 'genetic variant', 'genome wide association study', 'genome-wide', 'human subject', 'insight', 'inter-individual variation', 'interest', 'knock-down', 'mortality', 'promoter', 'protein function', 'screening', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'working group']",NHLBI,THOMAS JEFFERSON UNIVERSITY,R01,2016,392349,-0.00579755974951502
"From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations DESCRIPTION (provided by applicant): Genomic medicine offers hope for improved diagnostic methods and for more effective, patient-specific therapies. Genome-wide associated studies (GWAS) elucidate genetic markers that improve clinical understanding of risks and mechanisms for many diseases and conditions and that may ultimately guide diagnosis and therapy on a patient-specific basis. This project will expand on existing work to identify gene-phenotype associations across the genome and phenome, deploying new phenome-wide associations study (PheWAS) methods to deeply investigate electronic medical record (EMR)-derived phenotypes across common and rare variants across the genome. The project is enabled by large DNA biobanks coupled to de-identified copies of EMR. This project has three specific aims. First, we will expand the PheWAS phenotype library to include both binary traits and continuous variables incorporating about 7000 phenotypes derived from natural language processing, laboratory data, and report data. The second aim is to perform a PheWAS for common and rare variants using extant genome-wide and exome variant data and the broader set of phenotypes derived in Aim 1. We will analyze associations using single variant and multi-variant aggregation methods. We will validate the efficacy of our methods in Aim 2 by comparing to known associations. The third aim is to develop a standards-based infrastructure to share PheWAS results and develop tools to enable others to perform PheWAS. The tools generated from this project will not only expand the capabilities of the current PheWAS methodology, but will also broadly enable clinical research and subsequent genetic studies. Project Narrative Genomic medicine offers hope for improved diagnosis and for more effective, patient- specific therapies. This PheWAS proposal will develop new methods to identify detailed phenotypes and diseases from electronic medical records and then find novel genetic associations from existing genomic data.",From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations,9128740,R01LM010685,"['Address', 'Adopted', 'Architecture', 'Atrial Fibrillation', 'Biology', 'Body mass index', 'Cardiac', 'Cataloging', 'Catalogs', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'DNA Databases', 'Data', 'Data Reporting', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Documentation', 'Drug Exposure', 'Exclusion', 'Funding', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Grant', 'Health system', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Laboratories', 'Lead', 'Libraries', 'Link', 'Mainstreaming', 'Measures', 'Methodology', 'Methods', 'National Human Genome Research Institute', 'Natural Language Processing', 'Nature', 'Obesity', 'Pathway interactions', 'Patients', 'Peer Review', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Rare Diseases', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Scanning', 'Single Nucleotide Polymorphism', 'Site', 'Surveys', 'Testing', 'Variant', 'Work', 'base', 'biobank', 'cohort', 'disease phenotype', 'disorder subtype', 'endophenotype', 'exome', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'next generation', 'novel', 'phenome', 'pleiotropism', 'rare variant', 'software development', 'tool', 'trait']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2016,473040,0.04946401788744983
"Fast and Robust Methods for Large Scale Genotype Phenotype Association Study ﻿    DESCRIPTION (provided by applicant): A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Thanks to the advanced sequencing technologies, an enormous amount of genetic variants have been identified and cataloged. Such data hold great potential to understand how genes affect phenotypes and contribute to the susceptibility to environmental stimulus. However, the existing computational methods for analyzing and interpreting the high‐throughput genetic data are still in their infancy.    We propose to systematically investigate the computational and statistical principles in modeling and discovering genetic basis of complex phenotypes. The proposed research provides answers to the following fundamental questions in genetic association study: (1) How to effectively and efficiently assess statistical significance of the findings? (2) How to account for the relatedness between samples in genetic association study? (3) How to accurately capture possible interactions between multiple genetic factors and their joint contribution to phenotypic variation? In particular, we will develop data structures and efficient algorithms for accurate and robust significance assessment that account for local population structure and joint effect of multiple genetic factors.    The proposed computational tools will be integrated into software packages under common application framework adopted by the broad scientific community. PUBLIC HEALTH RELEVANCE: A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Existing methods are not able to adequately address the complexity of high throughput data. Innovative computational models and methods developed in this project will enable scientists more effectively analyze the research data, thus further understanding of human diseases and speed the development diagnostic tools, cures, and therapies.",Fast and Robust Methods for Large Scale Genotype Phenotype Association Study,9144814,R01GM115833,"['Accounting', 'Address', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Marker Expression', 'Genetic Markers', 'Genotype', 'Health', 'Information Networks', 'Joints', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Mining', 'Modeling', 'Mus', 'Noise', 'Performance', 'Phenotype', 'Phylogeny', 'Pilot Projects', 'Population', 'Predisposition', 'Property', 'Publications', 'Quantitative Trait Loci', 'Research', 'Research Institute', 'Sampling', 'Scientist', 'Speed', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Trees', 'Variant', 'base', 'computerized tools', 'data mining', 'experience', 'genetic association', 'genetic variant', 'human disease', 'improved', 'infancy', 'innovation', 'interest', 'novel', 'tool', 'trait']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2016,278157,0.02739799025213435
"Fast and Robust Methods for Large Scale Genotype Phenotype Association Study ﻿    DESCRIPTION (provided by applicant): A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Thanks to the advanced sequencing technologies, an enormous amount of genetic variants have been identified and cataloged. Such data hold great potential to understand how genes affect phenotypes and contribute to the susceptibility to environmental stimulus. However, the existing computational methods for analyzing and interpreting the high‐throughput genetic data are still in their infancy.    We propose to systematically investigate the computational and statistical principles in modeling and discovering genetic basis of complex phenotypes. The proposed research provides answers to the following fundamental questions in genetic association study: (1) How to effectively and efficiently assess statistical significance of the findings? (2) How to account for the relatedness between samples in genetic association study? (3) How to accurately capture possible interactions between multiple genetic factors and their joint contribution to phenotypic variation? In particular, we will develop data structures and efficient algorithms for accurate and robust significance assessment that account for local population structure and joint effect of multiple genetic factors.    The proposed computational tools will be integrated into software packages under common application framework adopted by the broad scientific community. PUBLIC HEALTH RELEVANCE: A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Existing methods are not able to adequately address the complexity of high throughput data. Innovative computational models and methods developed in this project will enable scientists more effectively analyze the research data, thus further understanding of human diseases and speed the development diagnostic tools, cures, and therapies.",Fast and Robust Methods for Large Scale Genotype Phenotype Association Study,9272965,R01GM115833,"['Accounting', 'Address', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Marker Expression', 'Genetic Markers', 'Genotype', 'Health', 'Information Networks', 'Joints', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Mining', 'Modeling', 'Mus', 'Noise', 'Performance', 'Phenotype', 'Phylogeny', 'Pilot Projects', 'Population', 'Predisposition', 'Property', 'Publications', 'Quantitative Trait Loci', 'Research', 'Research Institute', 'Sampling', 'Scientist', 'Speed', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Trees', 'Variant', 'base', 'computerized tools', 'data mining', 'experience', 'genetic association', 'genetic variant', 'human disease', 'improved', 'infancy', 'innovation', 'interest', 'novel', 'tool', 'trait']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2016,85370,0.02739799025213435
"Discovery and analysis of structural variation in whole genome sequences DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities. PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.",Discovery and analysis of structural variation in whole genome sequences,9118280,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Alteration', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'genomic variation', 'improved', 'interest', 'markov model', 'rare variant', 'structural genomics', 'tool', 'virtual', 'whole genome']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2016,380625,0.05141617580059473
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,9041640,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'genomic data', 'hazard', 'human genomics', 'improved', 'individual patient', 'loss of function', 'novel', 'patient biomarkers', 'personalized genomic medicine', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'survival outcome', 'theories', 'treatment response', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2016,255295,0.0024939869268235083
"Biomedical Computing and Informatics Strategies for Infectious Disease Research ﻿    DESCRIPTION (provided by applicant): An important goal of infectious disease research is to develop genetic predictors of susceptibility. Our success in this endeavor will depend critically on the informatics methods and software that are available for making sense of high-dimensional genetic and genomic data. The goal of this research program is to develop, evaluate, distribute and support new and novel biomedical computing algorithms and open-source software for identifying combinations of genetic predictors of clinically important infectious disease outcomes. This application will target the growing body of rare genetic variants identified by high-throughput DNA sequencing. Our clinical application will focus on the prediction of antiretroviral response in clinical trials for HIV/AIDS. We propose here a highly innovative Hierarchical Rare Variant Collapsing Machine (HRVCM) algorithm for identifying and collapsing combinations of rare variants across gene regions (AIM 1). We will then integrate these new collapsed HRVCM variables into our popular Multifactor Dimensionality Reduction (MDR) method that will assess them in combination with common single-nucleotide polymorphisms (SNPs) from genome-wide association studies or GWAS (AIM 2). Our novel HRVCM-MDR approach will, for the first time, make it possible to assess non-additive interactions among sets of rare and common variants simultaneously in genetic studies of infectious diseases. We will apply these new and novel methods to approximately 13 million rare and common variants from nearly 3000 subjects that participated in an AIDS Clinical Trials Group (ACTG) study to evaluate risk for virologic failure with efavirenz-containing antiretroviral therapy (ART) regimens (AIM 3). Finally, we will release all methods as open source to the biomedical research community through our freely available MDR software package (AIM 4).         PUBLIC HEALTH RELEVANCE: The overall goal of this application is to develop innovative new computational methods for the genetic analysis of infectious diseases. We will focus on the development of methods that are able to detect synergistic effects of multiple genetic variants regardless of whether they are rare of common in human populations. We will apply these methods to the study of HIV/AIDS vaccination response.            ",Biomedical Computing and Informatics Strategies for Infectious Disease Research,9106116,R01AI116794,"['AIDS clinical trial group', 'AIDS/HIV problem', 'Algorithms', 'Anti-Retroviral Agents', 'Bioinformatics', 'Biomedical Computing', 'Biomedical Research', 'Clinical Trials', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Disease Outcome', 'Disease susceptibility', 'Failure', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic Segment', 'Goals', 'Graph', 'High-Throughput DNA Sequencing', 'Human', 'Infectious Diseases Research', 'Informatics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Population', 'Predisposition', 'Regimen', 'Research', 'Risk', 'Single Nucleotide Polymorphism', 'Statistical Data Interpretation', 'Time', 'Vaccination', 'Variant', 'antiretroviral therapy', 'base', 'biomedical informatics', 'clinical application', 'design', 'efavirenz', 'gene interaction', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'innovation', 'method development', 'novel', 'open source', 'programs', 'public health relevance', 'rare variant', 'response', 'simulation', 'simulation software', 'success']",NIAID,UNIVERSITY OF PENNSYLVANIA,R01,2016,571791,0.05388442562430904
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community.         PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.            ","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",9132585,U01HG009086,"['Accounting', 'Affect', 'Architecture', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic screening method', 'Genetic study', 'Genome', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Learning', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Validation', 'Variant', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'functional genomics', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'research study', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2016,854333,0.06065930035622768
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,9116916,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug Regulations', 'Drug resistance', 'Family', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Health', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2016,300000,-0.01868828976759812
"Regulation of mRNA splicing by intronic genetic variants ﻿    DESCRIPTION (provided by applicant): Genetic variations in introns commonly impact cellular functions by causing alterations in mRNA splicing. The abnormal inclusion and exclusion of exons often change protein functions and cellular phenotypes. Although many intronic variations have known functions, with the adoption of next generation sequencing, many more intronic variants have been discovered for which the functional impact is unknown. Thus, it is important to be able to predict the impact of the variants without needing to test them all in expensive and laborious assays. Although there are informatics algorithms that predict the impact of genetic variants on pre-mRNA splicing, their ability to predict the effect on protein function and ultimately disease and therapeutic phenotypes is lacking. In addition, there is a need for high-throughput cellular assays to test the results of these predictions on cellular functions. The studies proposed here will fulfill these needs by developing algorithms that prioritize the intronic variants by their potential impact on splicing and gene function, and developing a high-throughput assay to functionally test thousands of these predictions. These novel technologies will be applied to the effect of intronic variants on the pharmacogenomics of two clinically important oncology drugs, clofarabine and paclitaxel. Our long-term goals are to be able to predict the functional impact of genomic variants on human disease and therapeutic response. Our central hypothesis is that intronic genetic variants alter mRNA splicing and consequently protein function that ultimately affects the cellular response to drug therapy. Our first aim will be to develop computational algorithms that prioritize intronic variants based on their impacts on pre-mRNA splicing and protein function. Using a variety of genomic and structural features and large sets of genomic data, we will develop a bioinformatics algorithm specifically designed to prioritize intronic variants based on their potential impacts on pre-mRNA splicing and protein function. Our second aim will be to identify functional intronic variants associated with drug-induced cytotoxicity. Using existing genomics and cellular cytotoxic response data from populations of human cell lines, we will identify functional intronic variants that contribute to individuals' responses to clofarabine and paclitaxel cytotoxicity. Our third aim will be to functionally test the impact of the prioritized intronic variants on pre-mRNA splicing and drug cytotoxicity. Using our novel high- throughput functional splicing assay, we will test the effects of predicted functional variants from Aim 2 on pre- mRNA splicing. In addition, we will validate the effect of the intronic variants on cytotoxicity using exon specific siRNA and CRISPR/Cas technology to manipulate the target gene splicing. Upon completion of these studies, we expect to have developed bioinformatics algorithms that can accurately prioritize the intronic variants based on their functional impact on pre-mRNA splicing and protein function. Also, we will have tested thousands of variants in a cellular pre-mRNA splicing assay and validated the impact of several of these functional variants on paclitaxel and clofarabine cytotoxicity.         PUBLIC HEALTH RELEVANCE    Project Narrative The goal of this project is to design and implement a set of bioinformatics algorithms and high-throughput experimental assays for prioritizing functional intronic variants that contribute to phenotypic differences by affecting pre-mRNA splicing. The developed model, including a molecular validation component, will be used to systematically evaluate the functions of such variants that are associated with drug-induced cytotoxicity. The same strategy can also be used to study the etiology of complex diseases. This goal is directly relevant to the missions of NIH to improve the capability of disease diagnosis, treatment, and prevention.            ",Regulation of mRNA splicing by intronic genetic variants,9071997,R01CA213466,"['Adoption', 'Affect', 'Algorithms', 'Alternative Splicing', 'Bioinformatics', 'Biological Assay', 'Biological Process', 'CRISPR/Cas technology', 'Cell Line', 'Cell physiology', 'Cell-Mediated Cytolysis', 'Cellular Assay', 'Clinical Research', 'Clofarabine', 'Complex', 'Computational algorithm', 'Computers', 'Data', 'Disease', 'Etiology', 'Exclusion', 'Exons', 'Genes', 'Genetic Variation', 'Genomics', 'Goals', 'Human', 'Human Cell Line', 'Human Genetics', 'Individual', 'Informatics', 'Introns', 'Machine Learning', 'Messenger RNA', 'Mission', 'Modeling', 'Molecular', 'Paclitaxel', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Population', 'Population Genetics', 'Prevention', 'Publishing', 'RNA Splicing', 'Regulation', 'Research', 'Small Interfering RNA', 'Source', 'Spliced Genes', 'Test Result', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Work', 'base', 'cytotoxic', 'cytotoxicity', 'design', 'disease diagnosis', 'disease phenotype', 'functional genomics', 'gene function', 'genetic variant', 'genomic data', 'genomic variation', 'high throughput screening', 'human disease', 'improved', 'mRNA Precursor', 'multidisciplinary', 'new technology', 'next generation sequencing', 'novel', 'oncology', 'prediction algorithm', 'protein function', 'protein structure', 'public health relevance', 'response', 'structural genomics', 'transcriptome sequencing', 'treatment response']",NCI,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2016,576262,0.018537658025378972
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3).         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.                ",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9055844,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Population', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Staging', 'Statistical Methods', 'Stratification', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'pleiotropism', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'statistics', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2016,309883,0.06363588442940873
"Genetic Factors in Keratoconus The purpose of this grant is to develop techniques for use in the ‘early’ detection of keratoconus (KC) and identify genetic variants that contribute to its development. KC is a complex genetic eye disorder and a leading cause of corneal transplantation in the young, with approximately 300,000 affected individuals in the US. Undiagnosed, subclinical KC is one of the major causes for complications of LASIK (Laser-in-situ- Keratomilieusis) surgery, commonly performed for vision correction. In the past two decades we have made major improvements to the early diagnosis of KC and have also made significant contributions to the delineation of major genetic determinants of KC through genome wide linkage studies (GWLS), fine mapping, and genome wide association studies (GWAS). In this proposal, we intend to follow up on these studies using new powerful approaches to achieve the following specific aims: In Aim 1 we will combine corneal optical coherence tomography (OCT) and Pentacam HR Scheimpflug Tomography (PST), new technologies that measure both the anterior and posterior surface of the cornea, with videokeratography (VK), a method which revolutionized KC diagnosis, to characterize criteria and to improve the diagnosis of subclinical KC. In Aim 2, to identify additional KC genes, we will perform a 2.5 million SNP GWAS, with an additional 6,000 SNPs, to finemap already identified genes. We will confirm these results in a separate cohort of KC patients. For this twostage GWAS design we are assembling the largest group of KC patients described to date: 2000 KC patients in total, 1,000 for the GWAS discovery stage and 1,000 for the confirmation stage. The controls for GWAS discovery will come from the Cardiovascular Health Study (CHS; 3300) and for confirmation will come from 400 subjects with VK, PST, and OCT measurements under Aim 1 and 600 “convenience controls” f rom the Cholesterol and Pharmacogenetics (CAP) study. In our current state of knowledge, the most cost-effective approach to increase the number of identified KC genes is to proceed with the expanded GWAS proposed herein. In Aim 3, we will test the impact of the genes identified in Aim 2 on the ‘early’ subclinical phenotypes identified through the use of VK, PST and OCT measures in Aim 1. Lastly, for the second part of Aim 3, we will investigate the potential function of KC variants by testing their ability to influence gene structure, expression and function in corneal cell models, including iPS cells derived from corneal keratocytes developed by our research team. The results of these studies will help advance our understanding of the genetic susceptibility to KC and may result in novel treatment options to slow the progression of the disease. Improving methods for the ‘early’ detection of keratoconus will help patients avoid complications of LASIK surgery, allow us to identify genetic variants that contribute to its development, and design therapies to retard its progression.",Genetic Factors in Keratoconus,9353966,R01EY009052,"['Affect', 'Anterior', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cells', 'Cholesterol', 'Collaborations', 'Complex', 'Cornea', 'Custom', 'Data', 'Development', 'Diagnosis', 'Discriminant Analysis', 'Disease Progression', 'Early Diagnosis', 'Epidemiology', 'Etiology', 'Eye', 'Eye diseases', 'Family member', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Predisposition to Disease', 'Genetic Transcription', 'Genetic Variation', 'Genotype', 'Grant', 'Immunohistochemistry', 'In Situ', 'Individual', 'Keratoconus', 'Keratoplasty', 'Knowledge', 'Lasers', 'Lead', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Pathogenesis', 'Patients', 'Pharmacogenetics', 'Phenotype', 'Research', 'Research Design', 'Reverse Transcriptase Polymerase Chain Reaction', 'Risk', 'Staging', 'Surface', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Variant', 'Videokeratographies', 'Vision', 'base', 'bead chip', 'cardiovascular health', 'cohort', 'cost effective', 'design', 'follow-up', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide linkage', 'improved', 'indexing', 'induced pluripotent stem cell', 'new technology', 'novel', 'prevent', 'protein expression', 'protein function', 'therapy design/development', 'tomography', 'tool', 'trait']",NEI,CEDARS-SINAI MEDICAL CENTER,R01,2016,100384,0.027342972912958226
"F-CAP: Functionalization of Variants in Clinically Actionable Pharmacogenes ﻿    DESCRIPTION (provided by applicant): Patient-to-patient variability in response to drugs creates a significant challenge for the safe and effective treatment of many human diseases. Pharmacogenomics seeks to address this challenge by linking drug response to patient genotypes at important loci, termed pharmacogenes, in order to better customize patient treatments. Genetic variation in pharmacogenes is extensive. For example, amongst 12 CYP genes, 10% of people carry at least one rare, potentially deleterious variant. Unfortunately, only a small number of variants have been unambiguously linked to alterations in drug response. Clearly, new approaches are needed to annotate the consequences of the huge pool of variants of unknown significance, including those already identified by existing large-scale sequencing programs, and those that will be discovered as clinical sequencing becomes routine. In this proposal, we seek to address this problem directly and at a scale never before possible by taking advantage of new technologies in sequencing and functional analysis. Our resource, termed F-CAP (Functionalization of Variants in Clinically Actionable Pharmacogenes) will test all possible substitutions at all amino acid residues in some of the most clinically important pharmacogenes and disseminate these data to the medical and research communities. In order to accomplish this, we will use deep mutational scanning, a method we have developed that allows parallelized, and quantitative measurements to be performed on libraries of genetic variants. In Aim 1 we will create these libraries, starting with five of the most important CPIC level A or B priority genes (CYP2C9, CYP2C19, CYP2D6, TPMT and VKORC1), and test the stability and enzymatic activity of each variant en masse using a pooled selection strategy. In Aim 2, we will integrate these data to create an impact score. This impact score provides a numerical value for a variant's functional effects that is amenable to easy integration into prescribing guidelines being developed by the pharmacogenomics community. Aim 3 will validate this score for a subset of variants that span the impact score spectrum using therapeutically relevant substrates for each pharmacogene. Finally, Aim 4 describes a key component of this resource: the dissemination of our findings to the entire pharmacogenomics community through partnership with CPIC and PharmGKB. In addition, we will make available our raw and processed data via a custom web resource that will also be developed in Aim 4. This resource will provide a series of fully annotated datasets describing the functional consequences of every possible single mutation in a series of key pharmacogenes, thereby greatly advancing the field of personalized medicine. PUBLIC HEALTH RELEVANCE: Pharmacogenomics seeks to identify genetic sources of inter-individual variability in drug response, with the goal of personalizing drug selection and dose to improve patient outcomes. A key barrier to using pharmacogenomic information is lack of clarity about the functional impact of variants, which hampers the provision of clear, unambiguous guidance to health care providers. We propose to connect pharmacogenomic variant discovery with novel high-throughput experimental approaches to deliver a resource to guide the use of individual pharmacogenomic information in personalizing drug treatment.",F-CAP: Functionalization of Variants in Clinically Actionable Pharmacogenes,9110269,R24GM115277,"['Address', 'Affect', 'Algorithms', 'Amino Acids', 'Applications Grants', 'Biochemical', 'Biological Assay', 'CYP2C19 gene', 'CYP2C9 gene', 'CYP2D6 gene', 'Cataloging', 'Catalogs', 'Cellular Assay', 'Classification', 'Code', 'Communities', 'Custom', 'Data', 'Data Set', 'Databases', 'Dose', 'Elements', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Guidelines', 'Health', 'Health Personnel', 'High-Throughput DNA Sequencing', 'In Vitro', 'Individual', 'Internet', 'Large-Scale Sequencing', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Research', 'Methods', 'Monoclonal Antibody R24', 'Mutate', 'Mutation', 'Numerical value', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Plant Roots', 'Positioning Attribute', 'Resources', 'Scanning', 'Series', 'Source', 'TPMT gene', 'Testing', 'Translations', 'Variant', 'clinical sequencing', 'clinically actionable', 'computerized data processing', 'effective therapy', 'exome', 'genetic disorder diagnosis', 'genetic information', 'genetic variant', 'genotyped patients', 'human disease', 'improved', 'interest', 'new technology', 'novel', 'novel strategies', 'personalized medicine', 'programs', 'response', 'stability testing', 'tool', 'user-friendly', 'variant of unknown significance']",NIGMS,UNIVERSITY OF WASHINGTON,R24,2016,747826,0.015341724603797577
"Mechanisms underlying complex trait human disease DESCRIPTION (provided by applicant): There is now an explosion of new genome scale data relating genetic variation within the human population to phenotype, and particularly to common disease. Microarray technology has identified 100s of loci where the presence of particular variants is associated with altered risk of many common diseases; complete sequencing of individual exomes in cancer samples has discovered many somatic mutations in a variety of genes; and sequencing of 1000 human genomes has provided an almost complete inventory of common population variants. Further, these data are only the first in an ever-increasing flood, as even faster and cheaper sequencing technologies come on line. The results hold promise for major advances in treatment and diagnosis of common human diseases. Extracting the expected benefits is not straightforward, and will necessitate acquiring detailed knowledge of the mechanisms linking genetic variation to disease. This project focuses on one aspect of this challenge - using the new genomic data to identify new therapeutic opportunities. We will investigate those principles underlying complex trait disease that are particularly relevant to tha goal. We introduce a three stage mechanistic framework, relating genomic variation to the function of impacted gene products, the impact of these altered functions on pathways, processes and subsystems; and finally the consequences for complex trait disease phenotypes. We will develop computational methods to address key questions concerning three major aspects of the framework (1) How large are the changes in protein function brought about by the genomic variants underlying complex trait disease? What role do different classes of genomic and protein level mechanism, such as expression, non-synonymous changes and splicing, play in these variants? (2) How complete is the set genes with strong influence on the disease phenotypes discovered by current technologies, and how can missing genes be imputed from the genomic and network data? (3) What is the distribution of coupling between the activity of genes involved in disease mechanism and disease phenotypes? The results will deepen understanding of these aspects of complex disease, and provide a basis for identifying potential new drug targets from GWAS and other genomic studies. PUBLIC HEALTH RELEVANCE: New technologies are now providing extensive information on human genetic variation associated with increased risk of a wide range of common human disease, such as Alzheimer's, diabetes, heart disease, and many cancers. These data hold the promise for the development of new therapies, and realizing those benefits requires the acquisition of complementary knowledge of the mechanisms that link genetic variation to disease risk. This project is focused on analysis of the relationship between genetic variation and common disease with the goal of identifying new therapeutic opportunities.",Mechanisms underlying complex trait human disease,9068178,R01GM104436,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Complex', 'Computing Methodologies', 'Coupled', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Equipment and supply inventories', 'Explosion', 'Floods', 'Frequencies', 'Future', 'Genes', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heart Diseases', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Information Networks', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mendelian disorder', 'Methods', 'Microarray Analysis', 'Minor', 'Modeling', 'Molecular', 'Other Genetics', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Play', 'Population', 'Process', 'Proteins', 'RNA Splicing', 'Risk', 'Role', 'Sampling', 'Somatic Mutation', 'Staging', 'Technology', 'Therapeutic', 'Translations', 'Variant', 'Work', 'base', 'disease phenotype', 'disorder risk', 'exome', 'exome sequencing', 'gene function', 'gene product', 'genetic information', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic data', 'genomic variation', 'human disease', 'improved', 'insight', 'new technology', 'new therapeutic target', 'novel therapeutics', 'protein function', 'rare variant', 'risk variant', 'therapeutic target', 'tool', 'trait']",NIGMS,"UNIV OF MARYLAND, COLLEGE PARK",R01,2016,288036,0.04032943719375217
"Genetic Factors in Keratoconus DESCRIPTION (provided by applicant): The purpose of this grant is to develop techniques for use in the 'early' detection of keratoconus (KC) and identify genetic variants that contribute to is development. KC is a complex genetic eye disorder and a leading cause of corneal transplantation in the young, with approximately 300,000 affected individuals in the US. Undiagnosed, subclinical KC is one of the major causes for complications of LASIK (Laser-in-situ- Keratomilieusis) surgery, commonly performed for vision correction. In the past two decades we have made major improvements to the early diagnosis of KC and have also made significant contributions to the delineation of major genetic determinants of KC through genome wide linkage studies (GWLS), fine mapping, and genome wide association studies (GWAS). In this proposal, we intend to follow up on these studies using new powerful approaches to achieve the following specific aims: In Aim 1 we will combine corneal optical coherence tomography (OCT) and Pentacam HR Scheimpflug Tomography (PST), new technologies that measure both the anterior and posterior surface of the cornea, with videokeratography (VK), a method which revolutionized KC diagnosis, to characterize criteria and to improve the diagnosis of subclinical KC. In Aim 2, to identify additional KC genes, we will perform a 2.5 million SNP GWAS, with an additional 6,000 SNPs, to fine- map already identified genes. We will confirm these results in a separate cohort of KC patients. For this two- stage GWAS design we are assembling the largest group of KC patients described to date: 2000 KC patients in total, 1,000 for the GWAS discovery stage and 1,000 for the confirmation stage. The controls for GWAS discovery will come from the Cardiovascular Health Study (CHS; 3300) and for confirmation will come from 400 subjects with VK, PST, and OCT measurements under Aim 1 and 600 ""convenience controls"" from the Cholesterol and Pharmacogenetics (CAP) study. In our current state of knowledge, the most cost-effective approach to increase the number of identified KC genes is to proceed with the expanded GWAS proposed herein. In Aim 3, we will test the impact of the genes identified in Aim 2 on the 'early' subclinical phenotypes identified through the use o VK, PST and OCT measures in Aim 1. Lastly, for the second part of Aim 3, we will investigate the potential function of KC variants by testing their ability to influence gene structure, expression and function in corneal cell models, including iPS cells derived from corneal keratocytes developed by our research team. The results of these studies will help advance our understanding of the genetic susceptibility to KC and may result in novel treatment options to slow the progression of the disease. PUBLIC HEALTH RELEVANCE: Improving methods for the 'early' detection of keratoconus will help patients avoid complications of LASIK surgery, allow us to identify genetic variants that contribute to its development, and design therapies to retard its progression.",Genetic Factors in Keratoconus,8984882,R01EY009052,"['Affect', 'Anterior', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cells', 'Collaborations', 'Complex', 'Cornea', 'Custom', 'Data', 'Development', 'Diagnosis', 'Discriminant Analysis', 'Disease Progression', 'Early Diagnosis', 'Epidemiology', 'Etiology', 'Eye', 'Eye diseases', 'Family member', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Predisposition to Disease', 'Genetic Transcription', 'Genetic Variation', 'Genotype', 'Grant', 'Health', 'Immunohistochemistry', 'In Situ', 'Individual', 'Keratoconus', 'Keratoplasty', 'Knowledge', 'Lasers', 'Lead', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Pathogenesis', 'Patients', 'Pharmacogenetics', 'Phenotype', 'Research', 'Research Design', 'Reverse Transcriptase Polymerase Chain Reaction', 'Risk', 'Staging', 'Surface', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Variant', 'Videokeratographies', 'Vision', 'base', 'bead chip', 'cardiovascular health', 'cholesterol control', 'cohort', 'cost effective', 'design', 'follow-up', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide linkage', 'improved', 'indexing', 'induced pluripotent stem cell', 'new technology', 'novel', 'prevent', 'protein expression', 'protein function', 'therapy design/development', 'tomography', 'tool', 'trait']",NEI,CEDARS-SINAI MEDICAL CENTER,R01,2016,652794,0.028673247548816293
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9135552,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Health', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2016,324169,0.02690504125980334
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,9135552,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Enrollment', 'Equilibrium', 'Event', 'Formulation', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Health', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Polynomial Models', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'data to knowledge', 'flexibility', 'genetic makeup', 'genetic signature', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'patient subsets', 'personalized medicine', 'predictive marker', 'predictive modeling', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2016,1,0.02690504125980334
"Genomics-based prediction of antibiotic failure in S. aureus infections ﻿    DESCRIPTION (provided by applicant)    The Gram positive bacterium Staphylococcus aureus is both an asymptomatic human colonizer and a pathogen that can cause infections in multiple tissue sites, including blood, skin and soft tissue, bone, and internal organs. Methicillin resistant Staphylococcus aureus (MRSA) is a common cause of death by hospital infections (HA-MRSA) and is now also a common community acquired infection (CA-MRSA). Vancomycin (a glycopeptide antibiotic) is the most commonly prescribed drug to treat MRSA infections. High-level resistance (minimal inhibitory concentration (MIC) ≥16 μg/ml) to vancomycin encoded by the mobile vanA gene is rare due to a fitness burden on S. aureus. However, it is more common to encounter strains with mutations conferring intermediate resistance to vancomycin arising from selection during the course of antibiotic therapy. The genetic basis of these vancomycin intermediate S. aureus (VISA) and heterogeneous resistant (hVISA) (MIC 2-8 μg/ml) strains involves a large number of different genomic mutations that result in cell wall thickening through changes in cellular signaling and regulation. Routine phenotypic testing in clinical labs probably underestimates the incidence of VISA and hVISA. Due to the fact that mutations in several genes have been linked with VISA, genetic-based detection of intermediate vancomycin resistance has not been developed for routine clinical microbiological use. In our preliminary work, we created an extensive catalog of sequenced clinical and laboratory-selected VISA as well as databases of SNPs and genetic variation in thousands of public S. aureus genomes. In this work we plan to extend these studies toward development of a sequence-based testing protocol that could be used for large numbers of clinical strains. In Specific Aim 1 we plan to extend our knowledge of the mutations that cause VISA by sequencing a panel of 300 novel mutants strains spontaneously selected from 40 S. aureus parent genotypes. We estimate, based on the results of the preliminary data, that this number of strains will be sufficient identify mutations found in 95% of VISA strains. These data will be used for creation of a comprehensive VISA detection assay based on whole genome data with an accuracy of at least 95%. In Specific Aim 2 we will use the information learned from Aim 1 to create a multiplex PCR sequence test for VISA, VRSA and other resistance determinants of S. aureus based on the commercially available Fluidigm platform. We will ultimately aim to have an assay that can be used to monitor systemic MRSA infections, such as bacteremia, to detect development of VISA in its early stages in clinical specimens from the patient. The test will also be able to detect other S. aureus resistance phenotypes and call the genotype of the strain.             PUBLIC HEALTH RELEVANCE    Vancomycin is an antibiotic commonly used to treat methicillin resistant Staphylococcus aureus (MRSA) infections in chronically ill patients. The efficacy of this relatively cheap and well-tolerated therapy is compromised by mutations in the genome of the bacterium. In this project we propose to develop a genetic test based on a library of MRSA genome sequences with known antibiotic susceptibility level that identifies bacteria with diminished resistance to vancomycin.            ",Genomics-based prediction of antibiotic failure in S. aureus infections,9017369,R21AI121860,"['Address', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotic susceptibility', 'Antibiotics', 'Bacteremia', 'Bacteria', 'Base Sequence', 'Biological Assay', 'Blood', 'Cataloging', 'Catalogs', 'Cause of Death', 'Cell Wall', 'Chronically Ill', 'Clinical', 'Community-Acquired Infections', 'Complex', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Drug Prescriptions', 'Evolution', 'Failure', 'Frequencies', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Glycopeptide Antibiotics', 'Goals', 'Gram-Positive Bacteria', 'Healthcare', 'Human', 'Incidence', 'Infection', 'Intermediate resistance', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Methicillin', 'Modeling', 'Monitor', 'Mutation', 'Nosocomial Infections', 'Organ', 'Parents', 'Patients', 'Phenotype', 'Protocols documentation', 'Regulation', 'Resistance', 'Signal Transduction', 'Site', 'Skin Tissue', 'Specimen', 'Staging', 'Staphylococcus aureus', 'Testing', 'Tissues', 'Training', 'Treatment Failure', 'University Hospitals', 'Vancomycin', 'Vancomycin Resistance', 'Vancomycin-resistant S. aureus', 'Variant', 'Virulence', 'Work', 'base', 'bone', 'clinical sequencing', 'design', 'economic cost', 'fitness', 'genetic predictors', 'genetic variant', 'genome sequencing', 'interest', 'methicillin resistant Staphylococcus aureus', 'mortality', 'mutant', 'novel', 'pathogen', 'pleiotropism', 'public health relevance', 'soft tissue', 'tool', 'whole genome']",NIAID,EMORY UNIVERSITY,R21,2016,234000,0.021577880803660496
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,9065945,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost efficient', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'study population', 'success', 'symposium', 'tool', 'web site', 'whole genome', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2016,728166,0.02058656111228219
"High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms ﻿    DESCRIPTION (provided by applicant): Mutations are the ultimate source of genetic variation and one of the driving forces of evolution. Both the absolute mutation rate and the relative rate among mutation subtypes fluctuate along the genome, affected by adjacent nucleotide motifs and local features such as GC content and replication timing. Characterizing regional variation of mutation patterns is critical for understanding genome evolution and to identify variants causing genetic diseases. However, mutation rate and molecular spectrum are difficult to measure at high resolution, genomewide, and in an unbiased fashion. Estimates based on common variants and between- species substitutions are confounded by natural selection, population demographic history, and biased gene conversion (BGC). Methods relying on incidence rates of monogenic diseases or finding de novo variants by trio sequencing can inform global trends, but do not provide sufficient data to assess fine-scale local parameters. This study will overcome these limitations by using the extremely rare variants (ERVs) as a new data source to characterize patterns of recent germline variation in humans. ERVs, defined in this study as singletons in 30,000 samples, are becoming available via large-scale whole-genome sequencing (WGS) of population samples. Unlike common variants or substitutions, ERVs arose very recently and are largely unaffected by selection, BGC, etc. We will analyze 200-300 million singleton variants observed in 30,000 subjects at 20-30X coverage. The regional distribution of ERV subtypes will establish a quantitative atlas of the rate and spectrum of human germline mutations mostly unaltered by selection. We will share this resource with the research community and apply it to determine the impact of local genomic features and epigenomic attributes. We will use the systematic departures between ERVs and variants of higher frequencies (polymorphisms and substitutions) to infer local effects of selection, and this may uncover hitherto unknown functional regions of the genome. By comparing mutation signatures in ERVs with those in somatic variations observed in diverse cancers we will attribute distinct mutational signatures to known biochemical processes and thus infer the major contributors to new germline mutations in the human genome. This subtype-specific atlas will also be used to predict the probability of observing every possible single-base mutation in the genome, thus facilitating the interpretation of candidate causal variants of human diseases. We will assess mutation pattern differences among European Americans, African Americans and Latinos, and seek to discover genetic modifiers of germline mutation rate by finding functionally damaging mutations that show increased ERV counts in the surrounding genomic region, potentially identifying both known and previous unknown ""mutator"" genes that play a role in transmission fidelity in humans. This research will provide an essential resource to study the genesis and maintenance of germline mutations in humans. Understanding such a fundamental process will be the basis for a deeper understanding of human evolution and diseases.         PUBLIC HEALTH RELEVANCE: We will study the patterns of inherited mutations in humans using approximately 250 million extremely rare DNA variants in human populations. Our results will allow the prediction of the rate of new mutations at every site in the genome based on features of the surrounding DNA sequence, thus providing a common resource to study the arrival and maintenance of mutations in humans. Understanding such a basic process is important for answering fundamental questions in human evolution, the cause of inherited diseases, and the role of DNA abnormality in cancer and aging.            ",High-resolution map of human germline mutation patterns and inference of mutagenic mechanisms,9083570,R01GM118928,"['Address', 'Affect', 'African American', 'Aging', 'Algorithms', 'Alleles', 'American', 'Atlases', 'Biochemical Process', 'Biological Factors', 'Biological Process', 'Biology', 'Child', 'Chromatin', 'Communities', 'Complex', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Demographic Factors', 'Dependence', 'Disease', 'Environmental Risk Factor', 'European', 'Evolution', 'Family', 'Foundations', 'Frequencies', 'Future', 'Gene Conversion', 'Generations', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Germ-Line Mutation', 'Guanine + Cytosine Composition', 'Hereditary Disease', 'High-Throughput Nucleotide Sequencing', 'Human', 'Human Genetics', 'Human Genome', 'Incidence', 'Individual', 'Inherited', 'Internet', 'Latino', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'Mismatch Repair', 'Modeling', 'Molecular', 'Mutagenesis', 'Mutation', 'Natural Selections', 'Nucleotides', 'Parents', 'Pathogenicity', 'Pattern', 'Play', 'Population', 'Positioning Attribute', 'Probability', 'Process', 'Recording of previous events', 'Research', 'Resolution', 'Resource Sharing', 'Resources', 'Rest', 'Role', 'Sampling', 'Selection Bias', 'Site', 'Somatic Mutation', 'Source', 'Techniques', 'Technology', 'Time', 'Tissues', 'Variant', 'Weight', 'actionable mutation', 'base', 'data sharing', 'density', 'driving force', 'epigenomics', 'genetic evolution', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'next generation sequencing', 'prototype', 'public health relevance', 'rare variant', 'repository', 'transmission process', 'trend', 'whole genome']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2016,300999,0.03529626778050059
"EMR-Linked Biobank for Translational Genomics ﻿    DESCRIPTION (provided by applicant): Medical care informed by genomic information is beginning to move into clinical practice. The Electronic Medical Records and Genomics (eMERGE) network through its initial phases has provided much of the groundwork for this transformation. The Geisinger Health System project, ""EMR-Linked Biobank for Translational Genomics"" intends to build on the knowledge and experience from eMERGE phase II to accelerate discovery and implementation while expanding our understanding of the sociocultural implications of genomics in medicine. We will accomplish this goal through three specific aims: 1) Use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery in the proposed disorders: familial hypercholesterolemia and chronic rhinosinusitis, 2) Develop and test approaches for implementation of genomic information in clinical practice, 3) Explore, develop and implement novel approaches for family-centered communication around clinically relevant genomic results. We currently have over 60,000 patients broadly consented for research with a large and increasing proportion consented for return of results and deposition in the electronic health record. Over 18,000 patients are genotyped on high density platforms. Our two proposed phenotypes, familial hypercholesterolemia (FH) and chronic rhinosinusitis (CRS) were chosen because both conditions have a significant public health impact in the United States, but they are also ideally suited to the specific aims of the project. They provide opportunities for innovation and extension of current eMERGE methods. While many of these innovations will take advantage of the sequencing done as part of the project, there are several other areas emphasized in the funding opportunity that will broaden the scope of eMERGE research. One of the areas of emphasis for eMERGE III is exploring the familial return of actionable results. FH is well suited to this, as the current clinical recommendation is cascade testing of family members for all diagnosed patients. Currently this relies on the patient to contact at risk family members, but this is less than optimal. We will explore this issue using qualitative and quantitative methods and use the results to design and test novel family communication strategies. Gene-environment interactions play an important role in the development and severity of disease. These are very difficult to study. We propose novel approaches that leverage the assets of Geisinger Health System and the eMERGE Network to develop and apply methods to extend existing projects that study the impact of environment on CRS. This would include the first large scale environment-wide association studies (EWAS). Finally, we propose to lead efforts to apply the tools of economic modeling and analysis to eMERGE projects to begin to quantify the value of implementation of genomic medicine in the US healthcare system. These proposed innovations will magnify the already significant impact that the eMERGE program has had in moving genomic medicine from a dream to a reality. PUBLIC HEALTH RELEVANCE: Through this application GHS seeks to continue its participation in the eMERGE Network for Phase III - Study Investigators U01 (RFA-HG-14-025) funding opportunity. We propose 3 specific aims: 1) use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery and validation of gene-phenotype associations; 2) develop and test approaches for implementation of genomic information in clinical practice; develop and implement novel approaches for family-centered communication around clinically relevant genomic results",EMR-Linked Biobank for Translational Genomics,9248725,U01HG008679,"['Adult', 'Algorithms', 'Ambulatory Care', 'Area', 'Attitude', 'Candidate Disease Gene', 'Caring', 'Catchment Area', 'Child', 'Clinical', 'Communication', 'Computerized Medical Record', 'Consent', 'County', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Dreams', 'Economic Models', 'Ecosystem', 'Electronic Health Record', 'Ensure', 'Environment', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Funding Opportunities', 'Generations', 'Genes', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Group Practice', 'Health', 'Health Insurance', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Information Systems', 'Inpatients', 'Institute of Medicine (U.S.)', 'Integrated Health Care Systems', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Pennsylvania', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Population', 'Process', 'Prognostic Factor', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Rural', 'Rural Population', 'Safety', 'Severity of illness', 'Site', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Treatment outcome', 'United States', 'Validation', 'Variant', 'base', 'biobank', 'case finding', 'chronic rhinosinusitis', 'clinical care', 'clinical practice', 'clinically relevant', 'density', 'design', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic epidemiology', 'genetic variant', 'genotyped patients', 'implementation research', 'innovation', 'interest', 'meetings', 'novel', 'novel strategies', 'personalized health care', 'phase 3 study', 'phenome', 'population based', 'programs', 'screening', 'systems research', 'tool', 'trait', 'treatment response']",NHGRI,GEISINGER CLINIC,U01,2016,98294,0.021998801240977726
"EMR-Linked Biobank for Translational Genomics ﻿    DESCRIPTION (provided by applicant): Medical care informed by genomic information is beginning to move into clinical practice. The Electronic Medical Records and Genomics (eMERGE) network through its initial phases has provided much of the groundwork for this transformation. The Geisinger Health System project, ""EMR-Linked Biobank for Translational Genomics"" intends to build on the knowledge and experience from eMERGE phase II to accelerate discovery and implementation while expanding our understanding of the sociocultural implications of genomics in medicine. We will accomplish this goal through three specific aims: 1) Use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery in the proposed disorders: familial hypercholesterolemia and chronic rhinosinusitis, 2) Develop and test approaches for implementation of genomic information in clinical practice, 3) Explore, develop and implement novel approaches for family-centered communication around clinically relevant genomic results. We currently have over 60,000 patients broadly consented for research with a large and increasing proportion consented for return of results and deposition in the electronic health record. Over 18,000 patients are genotyped on high density platforms. Our two proposed phenotypes, familial hypercholesterolemia (FH) and chronic rhinosinusitis (CRS) were chosen because both conditions have a significant public health impact in the United States, but they are also ideally suited to the specific aims of the project. They provide opportunities for innovation and extension of current eMERGE methods. While many of these innovations will take advantage of the sequencing done as part of the project, there are several other areas emphasized in the funding opportunity that will broaden the scope of eMERGE research. One of the areas of emphasis for eMERGE III is exploring the familial return of actionable results. FH is well suited to this, as the current clinical recommendation is cascade testing of family members for all diagnosed patients. Currently this relies on the patient to contact at risk family members, but this is less than optimal. We will explore this issue using qualitative and quantitative methods and use the results to design and test novel family communication strategies. Gene-environment interactions play an important role in the development and severity of disease. These are very difficult to study. We propose novel approaches that leverage the assets of Geisinger Health System and the eMERGE Network to develop and apply methods to extend existing projects that study the impact of environment on CRS. This would include the first large scale environment-wide association studies (EWAS). Finally, we propose to lead efforts to apply the tools of economic modeling and analysis to eMERGE projects to begin to quantify the value of implementation of genomic medicine in the US healthcare system. These proposed innovations will magnify the already significant impact that the eMERGE program has had in moving genomic medicine from a dream to a reality. PUBLIC HEALTH RELEVANCE: Through this application GHS seeks to continue its participation in the eMERGE Network for Phase III - Study Investigators U01 (RFA-HG-14-025) funding opportunity. We propose 3 specific aims: 1) use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery and validation of gene-phenotype associations; 2) develop and test approaches for implementation of genomic information in clinical practice; develop and implement novel approaches for family-centered communication around clinically relevant genomic results",EMR-Linked Biobank for Translational Genomics,9134825,U01HG008679,"['Adult', 'Algorithms', 'Ambulatory Care', 'Area', 'Attitude', 'Candidate Disease Gene', 'Caring', 'Catchment Area', 'Child', 'Clinical', 'Communication', 'Computerized Medical Record', 'Consent', 'County', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Dreams', 'Economic Models', 'Ecosystem', 'Electronic Health Record', 'Ensure', 'Environment', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Funding Opportunities', 'Generations', 'Genes', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Group Practice', 'Health', 'Health Insurance', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Information Systems', 'Inpatients', 'Institute of Medicine (U.S.)', 'Integrated Health Care Systems', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Pennsylvania', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Population', 'Process', 'Prognostic Factor', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Rural', 'Rural Population', 'Safety', 'Severity of illness', 'Site', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Treatment outcome', 'United States', 'Validation', 'Variant', 'base', 'biobank', 'case finding', 'chronic rhinosinusitis', 'clinical care', 'clinical practice', 'clinically relevant', 'density', 'design', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic epidemiology', 'genetic variant', 'genotyped patients', 'implementation research', 'innovation', 'interest', 'meetings', 'novel', 'novel strategies', 'personalized health care', 'phase 3 study', 'phenome', 'population based', 'programs', 'screening', 'systems research', 'tool', 'trait', 'treatment response']",NHGRI,GEISINGER CLINIC,U01,2016,873141,0.021998801240977726
"Integrative interpretation of the organismal consequences of non-coding variation ﻿    DESCRIPTION (provided by applicant): Our capacity to sequence human genomes has exceeded our ability to interpret genetic variation, particularly in non-coding regions. To address this challenge, we recently developed a novel framework, Combined Annotation Dependent Depletion (CADD), for estimating the deleteriousness of any genetic variant. CADD defines an objective, data-rich, and quantitative integration of many genomic annotations into a single measure of variant effect at the organismal level. The goals of this R01 proposal are to further develop the CADD framework, to apply it in the context of ongoing genetic studies of both rare and common human diseases, and to experimentally evaluate its predictions. In Specific Aim 1, we will substantially modify CADD in both straightforward and creative ways, with the goal of dramatically improving CADD's ability to annotate non- coding variants, not only to estimate their organismal effects but also to provide insights into molecular mechanisms. In Specific Aim 2, we will apply CADD to a variety of ongoing whole genome sequencing studies of human disease, especially those in which non-coding variants are either known or suspected to be causal. As part of this effort, we will develop new statistical frameworks that directly incorporat CADD into traditional genome-wide discovery approaches. In Specific Aim 3, we will perform a combination of high-throughput (massively parallel reporter assays), medium-throughput (CRISPR/Cas9), and low-throughput (in vivo mouse transgenics) experimental assays for systematic and targeted assessment of CADD predictions. This proposal includes both computational and experimental innovations, and builds on established collaborative relationships between investigators with complementary strengths. The completion of our aims will yield novel methods, data, and resources with which to annotate whole genome sequences, broadly enabling the field to more effectively identify and mechanistically understand non-coding genetic variants that are causally relevant to human disease. PUBLIC HEALTH RELEVANCE: As we enter an era of personalized medicine, a deep understanding of human genomes will be increasingly important to public health, contributing to the unraveling of the genetic basis of human disease, as well as serving an increasing role in clinical diagnostics. However, our limited understanding of the functional consequences of most genetic variants, especially those that do not alter protein sequence, represents a major obstacle. This proposal seeks to dramatically improve our ability to identify and interpret ""non-coding"" variants that causally contribute to human disease. A recently developed computational approach will be substantially improved and evaluated in a variety of genetic studies, and its predictions will be experimentally validated. This project will provide much needed methods and resources to address the looming analytical challenges associated with individual whole genome sequencing in both biomedical research and patient care.",Integrative interpretation of the organismal consequences of non-coding variation,9024484,R01CA197139,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Binding', 'Biological Assay', 'Biomedical Research', 'CRISPR/Cas technology', 'Cell Line', 'Chromosome Mapping', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Complex Genetic Trait', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Event', 'Feedback', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Individual', 'Machine Learning', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'MicroRNAs', 'Molecular', 'Mus', 'Mutation', 'Nature', 'Nucleotides', 'Organism', 'Pathogenicity', 'Patient Care', 'Peptide Sequence Determination', 'Phenotype', 'Property', 'Public Health', 'Quantitative Trait Loci', 'RNA Binding', 'RNA Splicing', 'Regulatory Element', 'Reporter', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Site', 'Structure', 'System', 'Testing', 'Tissues', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Translating', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Vocabulary', 'Weight', 'base', 'candidate identification', 'disease phenotype', 'exome', 'exome sequencing', 'follow-up', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'human genome sequencing', 'improved', 'in vivo', 'innovation', 'insertion/deletion mutation', 'insight', 'novel', 'novel diagnostics', 'personalized medicine', 'research study', 'trait', 'transcription factor', 'whole genome']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,636532,0.03258401100693396
"Predicting causal non-coding variants in a founder population DESCRIPTION (provided by applicant): In order to characterize the molecular and cellular causes of human disease, it will be essential to unravel the functional impact of genetic variation. However, we are currently unable to predict the impact of the majority genetic variants that lie in non-coding regions of the genome, where indeed most complex disease-associated variants are found. Additionally, recent evidence suggests that a significant fraction of the non-coding genome is likely to be functional, often playing a role in gene regulation. Therefore, our limited understanding of non- coding variation is a critical hurdle to characterizing the genetic basis of disease. The goal of this project is to develop methods for interpreting non-coding genetic variation: to provide a robust and extensible Bayesian method for predicting causal variants from full genomes, to identify and validate a large set of functional non- coding variants using CRISPR technology, and to predict disease-relevant traits likely to be affected by each variant. Our project will leverage a unique cohort from a founder population in Sardinia, with genome sequence and/or transcriptome data available from 3000 individuals, along with extensive phenotyping for hundreds of traits. We will combine advanced statistical modeling with experimental validation based on genome engineering to identify causal non-coding variants affecting biomedical traits in the cohort, along with predicting functional mechanisms through which these variants ultimately perturb the cell. In Aim 1, we develop computational methods for predicting causal non-coding variation from full genomes, incorporating informative genomic features including epigenetic data, sequence motifs, and conservation information into a Bayesian approach jointly modeling multiple transcriptomic signals. We will optimize and apply these methods on genome and transcriptome data available for the Sardinia cohort to identify a large set of variants predicted to causally affect gene expression. Based on these predictions, in Aim 2, we connect putative causal variants with the diverse set of disease-relevant traits measured in the cohort, using network inference to capture the cascade from genetic variation to gene expression to disease. We will develop methods to integrate across variants, using the models in Aim 1, to identify the common causal mechanisms related to each trait. In Aim 3, we validate the causal impact of non-coding variants predicted to affect high-level traits. We will us genome editing through CRISPR to introduce individual genetic variants into cell lines and use qPCR to validate the predicted effects on gene expression. Finally, a major goal throughout this proposal will be to provide the research community with convenient computational tools for the prediction of causal non-coding variants from individual genomes, updated on an ongoing basis to integrate the most recent genomic annotations and public data in order to provide the best possible accuracy in predicting causal variants and the traits they are likely to affect. Our projet will greatly advance our understanding of non-coding genetic variation, the specific mechanisms affected by causal variants, and the downstream consequences to the cell and individual health. PUBLIC HEALTH RELEVANCE:  Understanding the impact of variation in the entire genome, beyond the well-studied protein-coding regions, is essential to understanding the relationship between genetics and human health. This proposal addresses the problem of identifying functional non-coding genetic variants and predicting the impact of each variant on hundreds of disease-relevant traits. Our approach will focus on integrative, transformative methods for understanding mechanisms underlying the function of the human genome.",Predicting causal non-coding variants in a founder population,9116910,R01HG008150,"['Address', 'Affect', 'Algorithms', 'Alleles', 'Bayesian Method', 'Biological Assay', 'Biology', 'CRISPR/Cas technology', 'Cataloging', 'Catalogs', 'Categories', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complex', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Epigenetic Process', 'Family', 'Founder Generation', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Genetic', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human Genetics', 'Human Genome', 'Individual', 'Inherited', 'Link', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Nucleotides', 'Open Reading Frames', 'Pathogenesis', 'Phenotype', 'Play', 'Population', 'Property', 'RNA Splicing', 'Research', 'Resolution', 'Resources', 'Role', 'Sampling', 'Sardinia', 'Signal Transduction', 'Statistical Models', 'System', 'Techniques', 'Testing', 'Transcript', 'Untranslated RNA', 'Update', 'Validation', 'Variant', 'Widespread Disease', 'base', 'cohort', 'computerized tools', 'data modeling', 'density', 'disease phenotype', 'disorder risk', 'functional genomics', 'genetic linkage analysis', 'genetic variant', 'genome annotation', 'genome editing', 'genome sequencing', 'genomic data', 'human data', 'human disease', 'human genome sequencing', 'improved', 'innovation', 'insertion/deletion mutation', 'learning strategy', 'molecular phenotype', 'novel', 'prediction algorithm', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NHGRI,STANFORD UNIVERSITY,R01,2016,454272,0.0020113280727801198
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,8974432,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,"BROAD INSTITUTE, INC.",K99,2016,25020,-0.010643671940506002
"Genome engineering tools for functional screening of non-coding elements DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root). PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.",Genome engineering tools for functional screening of non-coding elements,9242250,R00HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'CRISPR library', 'CRISPR screen', 'CRISPR/Cas technology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Health', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'laboratory experience', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool', 'whole genome']",NHGRI,NEW YORK GENOME CENTER,R00,2016,246031,-0.010643671940506002
"EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE ﻿    DESCRIPTION (provided by applicant): The eMERGE III Clinical Center proposal from Partners HealthCare leverages a large biobank, clinical data in the electronic medical records (EMR) for >4 million participants from the largest integrated health care provider in New England, advanced bioinformatics expertise and state-of-the-art genetic analysis. We propose three aims. (1) Aim 1. Discovery. We will test the hypothesis that common and rare variants from a custom chip including 50,000 loss of function (LoF) alleles will be associated with cardiovascular, neuropsychiatric and immune-mediated phenotypes derived from the EMR. We are currently genotyping 25,000 Partners HealthCare Biobank subjects with a custom chip that includes LoF alleles from 63,000 exomes that we have analyzed. (2) Aim 2. Penetrance and Pleiotropy. We will test the hypothesis that sequencing a set of established genes or loci will allow us to discover additional variation, and define penetrance and pleiotropy using EMR phenotypes. Rare variants in genes selected by the eMERGE network will be studied for penetrance and pleiotropic outcomes by PheWAS and chart review. In addition, we are poised to perform recall-by-genotype studies because all Biobank participants have provided consent for such callback. (3) Aim 3. Implementation. We will test the hypothesis that physicians will alter their surveillance and treatment of patients based upon voluntary return of actionable variants to provide safe and cost-effective benefits to patients. We will screen our entire Biobank population of 25,000 individuals for pathogenic variants in the LDLR gene, the leading genetic cause of premature coronary artery disease, and conduct an exploratory trial in disclosing this information. Biobank participants with pathogenic variants in LDLR will be offered enrollment into a randomized trial, in which their finding will be CLIA-confirmed, and in one arm, this result will be communicated to their physicians through the EMR. Over one year, we will collect the following outcomes through participant surveys and EMR queries: physician visits, laboratory testing, changes in medication prescriptions, LDL levels, medical costs and the number of family members screened and treated as a result of the intervention. We will collaborate with the entire eMERGE III Network to incorporate what we learn from this pilot trial into large-scale implementation protocols for the genes selected by the Network for sequencing. Finally, we will participate in all Network activities to enhance the movement of genetics into clinical practice. PUBLIC HEALTH RELEVANCE: The discovery and clinical use of genetic variants associated with both rare Mendelian and more common complex diseases promises to dramatically change the practice of medicine. Our eMERGE III project will leverage a large Biobank and a rich electronic medical record to define the phenotypic impact of mutations emerging from sequencing and then return results on selected variants to Biobank participants using a clinical trial.",EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE,9134764,U01HG008685,"['Algorithms', 'Alleles', 'Area', 'Asthma', 'Attention deficit hyperactivity disorder', 'Bioinformatics', 'Biology', 'Bipolar Disorder', 'CTLA4 gene', 'Callback', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computerized Medical Record', 'Congestive Heart Failure', 'Consent', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Cost Effectiveness Analysis', 'Custom', 'DRD2 gene', 'Data', 'Disease', 'Enrollment', 'Family member', 'Funding', 'Genes', 'Genetic', 'Genomic medicine', 'Genotype', 'Goals', 'HLA-DRB1', 'Health', 'Health Personnel', 'Healthcare', 'Immune', 'Individual', 'Inflammatory Bowel Diseases', 'Informatics', 'Intervention', 'LDL Cholesterol Lipoproteins', 'LDLR gene', 'Laboratories', 'Learning', 'Low-Density Lipoproteins', 'Machine Learning', 'Mediating', 'Medical', 'Medicine', 'Mental Depression', 'Mining', 'Movement', 'Multiple Sclerosis', 'Mutation', 'New England', 'Newborn Infant', 'Outcome', 'Participant', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Population Attributable Risks', 'Protocols documentation', 'Public Health', 'Research', 'Rheumatoid Arthritis', 'Schizophrenia', 'Source', 'Stream', 'Stroke', 'Surveys', 'TCF7L2 gene', 'TNFRSF1A gene', 'TYK2', 'Testing', 'Variant', 'Visit', 'arm', 'base', 'biobank', 'biomarker panel', 'clinical care', 'clinical practice', 'clinical sequencing', 'clinically actionable', 'cost', 'cost effective', 'design', 'exome', 'exome sequencing', 'experience', 'genetic analysis', 'genetic information', 'genetic variant', 'hypercholesterolemia', 'implementation research', 'loss of function', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'pilot trial', 'pleiotropism', 'premature', 'randomized trial', 'rare variant', 'support tools']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2016,953224,0.04641073535949764
"Genetic Variants, Epigenome and Retinal Disease Phenotypes Analyses of IRD genes in Israeli and Indigenous South Africa population:  In colloboration with our colleagues in Israel and South Africa, we performed NGS based analysis (whole exome sequencing, WES) on families with diverse IRD phenotypes. In addition to mutations in known genes (publsihed previously), we also reported unusual findings (Beryozkin et al. 2016). The analysis of 16 South African families have revealed seven different mutations (including six novel) in six distinct families, significantly enhancing the molecular diagnosis of IRD (40%) in South Africa.   Novel Genes/Genetic Defects in IRDs: Our WES analyses have led to identification of two novel IRD genes providing insights into retinal pathways and function. (1) We identified mutations in centrosomal-cilia gene CEP78 by WES in patients with cone-rod degeneration and sensorineural hearing loss (Namburi et al. 2016). (2) A combined candidate gene and WES analysis led to discovery of a rare, heterozygous frameshift mutation in FZD5 in autosomal dominant non-syndromic coloboma and implicated WNT-FZD signaling in pathogenesis of coloboma (Liu et al. 2016).  	  Genetics of AMD  Common and Rare Variant Analysis As a part of International Age-related Macular Degeneration Genomics Consortium (IAMDGC, we have participated in analysis of 16,144 patients and 17,832 controls using a custom-designed HumanCoreExome Chip. This remarkable study identified 52 independently associated common and rare variants at 34 loci. Presence of very rare coding variants in CFH, CFI and TIMP3 and a splice variant in SLC16A8 suggested their causal roles in AMD (Fritsche et al. 2016). We believe that a similar consortium like approach will be useful in dissecting genetic risk alleles for diabetic retinopathy (Mishra et al. 2016). To discover additional rare variants and characterize the GWAS locus further, we performed whole genome sequencing of 2,394 cases and 2,393 controls and the analysis is in progress. We also generated WES data in 19 large multigenerational AMD families to ascertain high-penetrance causative allele(s). To enhance the power of analysis, we are collaborating with other groups to extract useful information.    Functional Genomic Analysis of AMD  Current variants/loci can explain 50-60% of AMD heritability, with ARMS2 and CFH accounting for bulk of the effect. Our collaborative studies suggest increased retinal mitochondrial DNA damage in patients with CFH risk alleles (Ferrington et al. 2016). However, causal variants and underlying mechanisms remain largely unknown for majority of the loci. Thus we are now focusing on dissection of relative contributions of variants, genes and pathways to AMD pathology.   A Reference Transcriptome of Adult Human Retina:. We have generated a reference transcriptome of the normal human retina by RNA-seq analysis of 128 healthy donor samples (from Dr. D Ferrington) We have characterized both annotated coding regions as well as  un-annotated transcripts using de novo assembly,. This dataset would be valuable for the vision community while designing interventions for retinal diseases.  Gene and Pathways Associated with AMD Progression: To elucidate genetic underpinnings of progression of AMD phenotypes, AREDS1 data is being examined in collaborative studies. However, lack of longitudinal clinical information in most datasets makes it harder to replicate our findings. Thus we are taking advantage of transcriptomic studies of 390 donor AMD retinas (197 early, 127 intermediate, 66 advanced). We are focusing on AMD-associated and IRD genes, and novel coding and noncoding RNA genes from the region of 34 AMD loci. We are using WGCNA, GO analysis and random forest based approaches for identifying disease pathways and networks that are disrupted during AMD pathogenesis.   Contribution to Genomic Data Analysis Our large genotyping data has contributed to generation of genome-wide maps of human variants (1000 Genome Project Consortium, 2015) and development of statistical methods (Fan et al. 2016) and imputation (McCarthy et al. 2016; Das et al. 2016) to analyze human genome data.  Mouse Models of Retinal Degeneration  We are using mouse models to investigate disease mechanisms and test potential therapies. In one such study we demonstrated that RPGR is glutamylated by TTLL5 and that the Rpgr- and Ttll5-knockout mice show similar phenotypes (Sun et al. 2016).   Mitochondrial Dysfunction as a Marker of PR DIstress in Retinal and Macular Degeneration  Our transcriptome analyses of aging and degenerating photoreceptors indicated a small yet discrete change in mitochondria-associated genes. To test the impact of aging and disease on mitochondrial function, we are examining mitochondrial metabolism (Rueda et al. 2016) and directly measured oxygen consumption rate (OCR) in acutely isolated, ex vivo mouse retina and demonstrated that healthy adult photoreceptors have low reserve capacity and would therefore be more vulnerable to altered homeostasis (Kooragayala et al. 2015). The retinas of Pde6brd1/rd1, Cep290rd16/rd16 and Rpgrip1-/- mice have dysfunctional or no photoreceptors, and reveal reduced OCR and high mitochondrial reserve capacity. Our studies will help provide physiological bases for photoreceptor dysfunction in retinal diseases. n/a","Genetic Variants, Epigenome and Retinal Disease Phenotypes",9362427,ZIAEY000546,"['Accounting', 'Adult', 'Age related macular degeneration', 'Aging', 'Alleles', 'Benign', 'Candidate Disease Gene', 'Cilia', 'Clinical', 'Code', 'Coloboma', 'Communities', 'Complex', 'Custom', 'DNA Damage', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetic Retinopathy', 'Disease', 'Disease Pathway', 'Disease susceptibility', 'Dissection', 'Distress', 'Epigenetic Process', 'Family', 'Frameshift Mutation', 'Functional disorder', 'Gene Mutation', 'Generations', 'Genes', 'Genetic', 'Genetic Heterogeneity', 'Genetic Risk', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Homeostasis', 'Human', 'Human Genome', 'Indigenous', 'Individual', 'Inherited', 'International', 'Israel', 'Knockout Mice', 'Macular degeneration', 'Maps', 'Measures', 'Medical Genetics', 'Mitochondria', 'Mitochondrial DNA', 'Molecular Diagnosis', 'Mus', 'Mutation', 'Nucleotides', 'Oxygen Consumption', 'Pathogenesis', 'Pathology', 'Pathway interactions', 'Patients', 'Penetrance', 'Phenotype', 'Photoreceptors', 'Physiological', 'Population', 'RNA Splicing', 'RPGR gene', 'Reporting', 'Research Design', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Role', 'Sampling', 'Scientist', 'Sensorineural Hearing Loss', 'Sequence Analysis', 'Signal Transduction', 'South Africa', 'South African', 'Statistical Methods', 'TIMP3 gene', 'Testing', 'Transcript', 'Untranslated RNA', 'Variant', 'Vision', 'base', 'chemotactic factor inactivator', 'cone-rod degeneration', 'design', 'disease phenotype', 'disorder of macula of retina', 'epigenome', 'exome sequencing', 'forest', 'functional genomics', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic data', 'insight', 'mitochondrial dysfunction', 'mitochondrial metabolism', 'mouse model', 'novel', 'power analysis', 'rare variant', 'risk variant', 'targeted treatment', 'therapy design', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NEI,NATIONAL EYE INSTITUTE,ZIA,2016,2781377,0.020000743435669027
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9114170,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Genes', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Health', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Prediction of Response to Therapy', 'Prosencephalon', 'Psychiatry', 'Psychotic Mood Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2016,2560433,0.005450084718056185
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID) DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust. PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9114170,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Genes', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Health', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Prediction of Response to Therapy', 'Prosencephalon', 'Psychiatry', 'Psychotic Mood Disorders', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resolution', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Transcript', 'Transcriptional Regulation', 'Translations', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatric disorder', 'neuropsychiatric symptom', 'neuropsychiatry', 'neuroregulation', 'novel', 'outcome forecast', 'patient population', 'phenomenological models', 'predicting response', 'prognostic', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NIMH,HARVARD MEDICAL SCHOOL,P50,2016,750000,0.005450084718056185
"Genome Based Influenza Vaccine Strain Selection  using Machine Learning ﻿    DESCRIPTION (provided by applicant):     Influenza A virus causes both pandemic and seasonal outbreaks, leading to loss of from thousands to millions of human lives within a short time period. Vaccination is the best option to prevent and minimize the effects of influenza outbreaks. Rapid selection of a well-matched influenza vaccine strain is the key to developing an effective vaccination program. However, this is a non-trivial task due to three major challenges in influenza vaccine strain selection: labor an time intensive virus isolation and serology-based antigenic characterization, poor growth of selected strains in chicken embryonic eggs during production, and biased sampling in influenza surveillance. Each year, many scientists worldwide, including thousands from the United States, are working altogether to select an optimal vaccine strain. However, incorrect vaccine strains have still been frequently chosen in the past decades.  Recent advances in genomic sequencing allow us to rapidly and economically sequence influenza genomes from the isolates and from the clinical samples. Sequencing influenza genomes has become a routine and important component in influenza surveillance. The objectives of this project are to develop a sequence-based strategy for influenza antigenic variant identification and to optimize vaccine strain selection using genomic data. To achieve these aims, we will develop machine learning based computational methods to estimate antigenic distances among influenza viruses by directly using their genome sequences. We will then identify the key residues and mutations in influenza genomes affecting influenza antigenic drift events. Such information will allow us to select most promising virus strains as candidates for vaccine production. Since economical virus production requires the selected virus strains to grow easily in chicken embryonic eggs, we also propose the development of a machine learning based method that can predict the growth ability of a virus strain based on its sequence information. This integrated genome based influenza vaccine strain selection system will be developed for detecting antigenic variants for influenza A viruses.  This project will help us provide fundamental technology that employs genomic signatures determining influenza antigenicity and growth ability in chicken embryonic eggs, which are the two key issues for efficient and effective influenza vaccine strain development. The resulting genome based vaccine strain selection strategy will significantly reduce the human labor needed for serological characterization, decrease the time required to select an effective strain that will grow well in eggs, and increase the likelihood of correct influenza vaccine candidate selection. Thus, this project will lead to significant technological advances in influenza prevention and control.         PUBLIC HEALTH RELEVANCE:     This study is to develop and validate a genome based strategy for influenza vaccine strain selection, and it will lead to significant technological advances in influenza prevention and control.                ",Genome Based Influenza Vaccine Strain Selection  using Machine Learning,8859887,R01AI116744,"['Affect', 'Africa', 'Algorithms', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Binding Sites', 'Biological Assay', 'Chickens', 'Clinical', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Development', 'Disease Outbreaks', 'Effectiveness', 'Embryo', 'Epidemic', 'Event', 'Future', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Head', 'Hemagglutination', 'Hemagglutinin', 'Human', 'Influenza', 'Influenza A virus', 'Influenza prevention', 'Lead', 'Learning', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Mutagenesis', 'Mutation', 'Peptide Sequence Determination', 'Phenotype', 'Procedures', 'Process', 'Production', 'Proteins', 'Public Health', 'Publishing', 'Research Infrastructure', 'Resources', 'Sampling', 'Sampling Biases', 'Scientist', 'Seasons', 'Serologic tests', 'Serological', 'Site', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Vaccination', 'Vaccine Production', 'Vaccines', 'Variant', 'Viral', 'Virus', 'Work', 'base', 'candidate selection', 'egg', 'flu', 'genome sequencing', 'improved', 'influenza outbreak', 'influenza virus vaccine', 'influenzavirus', 'multitask', 'new technology', 'novel', 'pandemic disease', 'prevent', 'programs', 'public health relevance', 'receptor binding', 'research study', 'vaccine candidate']",NIAID,MISSISSIPPI STATE UNIVERSITY,R01,2015,381704,0.025666829030835822
"Mathematical Models and Statistical Methods for Large-Scale Population Genomics ﻿    DESCRIPTION (provided by applicant):     Technological advances in DNA sequencing have dramatically increased the availability of genomic variation data over the past few years. This development offers a powerful window into understanding the genetic basis of human biology and disease risk. To facilitate achieving this goal, it is crucial to develop efficient analytical methods that will allow researchers to more fuly utilize the information in genomic data and consider more complex models than previously possible. The central goal of this project is to tackle this important challenge, by carrying out te following Specific Aims: In Aim 1, we will develop efficient inference tools for whole-genome population genomic analysis by extending our ongoing work on coalescent hidden Markov models and apply them to large-scale data. The methods we develop will enable researchers to analyze large samples under general demographic models involving multiple populations with population splits, migration, and admixture, as well as variable effective population sizes and temporal samples (ancient DNA). Multi-locus full-likelihood computation is often prohibitive in most population genetic models with high complexity. To address this problem, we will develop in Aim 2 a novel likelihood-free inference framework for population genomic analysis by applying a highly active area of machine learning research called deep learning. We will apply the method to various parameter estimation and classification problems in population genomics, particularly joint inference of selection and demography. In addition to carrying out technical research, we will develop a useful software package that will allow researchers from the population genomics community to utilize deep learning in their own research. It is becoming increasingly more popular to utilize time-series genetic variation data at the whole-genome scale to infer allele frequency changes over a time course. This development creates new opportunities to identify genomic regions under selective pressure and to estimate their associated fitness parameters. In Aim 3, we will develop new statistical methods to take full advantage of this novel data source at both short and long evolutionary timescales. Specifically, we will develop and apply efficient statistical inference methods for analyzing time-series genomic variation data from experimental evolution and ancient DNA samples. Useful open-source software will be developed for each specific aim. The novel methods developed in this project will help to analyze and interpret genetic variation data at the whole-genome scale.         PUBLIC HEALTH RELEVANCE:     This project will develop several novel statistical methods for analyzing and interpreting human genetic variation data at the whole-genome scale. The computational tools stemming from this research will enable efficient and accurate inference under complex population genetic models, thereby broadly facilitating research efforts to understand the genetic basis of human biology and disease risk.                ",Mathematical Models and Statistical Methods for Large-Scale Population Genomics,8887722,R01GM094402,"['Accounting', 'Address', 'Admixture', 'Affect', 'Age', 'Alleles', 'Area', 'Classification', 'Communities', 'Complex', 'Computer software', 'DNA', 'DNA Resequencing', 'DNA Sequence', 'Data', 'Data Sources', 'Demography', 'Development', 'Diffusion', 'Event', 'Evolution', 'Gene Frequency', 'Genetic', 'Genetic Models', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Human Biology', 'Human Genetics', 'Individual', 'Joints', 'Learning', 'Link', 'Machine Learning', 'Methods', 'Modeling', 'Mutation', 'Phase', 'Physiologic pulse', 'Population', 'Population Genetics', 'Population Sizes', 'Recording of previous events', 'Research', 'Research Personnel', 'Sampling', 'Series', 'Site', 'Statistical Methods', 'Technology', 'Time', 'Trees', 'Uncertainty', 'Work', 'analytical method', 'base', 'computer based statistical methods', 'computerized tools', 'coping', 'disorder risk', 'fitness', 'genetic analysis', 'genetic selection', 'genome-wide', 'genomic variation', 'human disease', 'interest', 'markov model', 'mathematical model', 'migration', 'novel', 'open source', 'pressure', 'public health relevance', 'stem', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2015,303504,0.05697026825496183
"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",Tracing the evolution of the human mutation rate,8982093,F32GM116381,"['Acceleration', 'Admixture', 'Affect', 'Africa', 'African', 'African American', 'Alleles', 'American', 'Americas', 'Architecture', 'Asians', 'Autistic Disorder', 'Base Pairing', 'Bayesian Analysis', 'Cancer Biology', 'Child', 'Chromosome Mapping', 'Collection', 'DNA Damage', 'DNA biosynthesis', 'Disease', 'Doctor of Philosophy', 'Employee Strikes', 'Environment', 'Europe', 'European', 'Event', 'Evolution', 'Exhibits', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Germ-Line Mutation', 'Health', 'Hereditary Disease', 'Human', 'Individual', 'Latino', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Methods', 'Mutation', 'Mutation Spectra', 'Native Americans', 'Natural Language Processing', 'Parents', 'Pongidae', 'Population', 'Process', 'Recording of previous events', 'Research', 'Risk', 'Risk Factors', 'Schizophrenia', 'Signal Transduction', 'Site', 'Somatic Mutation', 'Techniques', 'Testing', 'Time', 'Variant', 'Work', 'base', 'design', 'developmental disease', 'disorder risk', 'experience', 'follow-up', 'genetic risk factor', 'genetic variant', 'improved', 'insight', 'melanoma', 'offspring', 'rare variant', 'success', 'trait', 'transition mutation']",NIGMS,STANFORD UNIVERSITY,F32,2015,50690,0.030679903301302415
"Predicting Impact of Genetic Variation on Splicing ﻿    DESCRIPTION (provided by applicant): The genetic code not only determines protein amino acid residue sequence but also defines the 'splicing code' of cis- and trans-acting regulatory elements that control pre-mRNA splicing. Single nucleotide variant (SNV) changes at key regions in pre-mRNA may disrupt splicing resulting in disease [1, 2]. Understanding which SNVs cause aberrant splicing and which are benign is important for understanding disease pathogenesis. SNVs at consensus splice sites, at exon-intron junctions, are known to cause aberrant splicing and contribute to at least 10% of inherited diseases [2]. However, SNVs outside consensus splice sites can still disrupt splicing [3]. Current, bioinformatics tools limit analysis to SNVs at or near consensus splice sites and lack the ability to generalize to SNVs beyond the consensus splice site [4-7]. In this application, I propose to substantially improve the ability to interpret the consequences of mutations on pre-mRNA splicing. This goal will be achieved by: 1) developing novel features, useful in predicting the impact of variation on cis- splicing regulation; 2) training a supervised machine learning algorithm that uses the novel features to predict the impact of SNVs; 3) sharing the algorithm in a publically available software package; and 4) comparing algorithm predictions to the relationships between SNVs and splicing patterns derived from matched DNA- and RNA-sequencing studies.         PUBLIC HEALTH RELEVANCE: Genetic sequences not only encode the amino acids of proteins but also regulate many critical biological functions, including pre-mRNA splicing. The impact of genetic variation on splicing is not well understood. The goal of this research project i to computationally identify features of variants useful in predicting aberrant splicing, then incorporate the features into a machine learning algorithm and test the utility of the predictions using publically available sequencing studies. 1            ",Predicting Impact of Genetic Variation on Splicing,8833507,F31HG007804,"['Algorithms', 'Amino Acids', 'Benign', 'Bioinformatics', 'Biological', 'Biological Process', 'Cell physiology', 'Characteristics', 'Code', 'Comparative Study', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Consensus', 'DNA', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Exons', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genomics', 'Goals', 'Inherited', 'Introns', 'Label', 'Location', 'Machine Learning', 'Methods', 'Mutation', 'Nucleotides', 'Pathogenesis', 'Pattern', 'Performance', 'Play', 'Proteins', 'RNA Sequences', 'RNA Splicing', 'Regulation', 'Regulatory Element', 'Research Project Grants', 'Role', 'Site', 'Structure', 'Testing', 'Training', 'Transcript', 'Variant', 'base', 'improved', 'interest', 'mRNA Precursor', 'novel', 'public health relevance', 'tool', 'transcriptome sequencing']",NHGRI,JOHNS HOPKINS UNIVERSITY,F31,2015,43120,-0.00736560330970851
"Informatics Tools for High-Throughput Sequences Data Analysis DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK. The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.",Informatics Tools for High-Throughput Sequences Data Analysis,8788050,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2015,967608,0.016360186341458693
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,9052542,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation sequencing', 'novel', 'prevent', 'public health relevance', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U01,2015,130994,0.006370329738487989
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,9120986,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Internet', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Mendelian disorder', 'Methodology', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinical sequencing', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic counselor', 'genetic variant', 'genome analysis', 'genome sequencing', 'genome-wide', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2015,68720,0.055671522470836954
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,9047616,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Internet', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Mendelian disorder', 'Methodology', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinical sequencing', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic counselor', 'genetic variant', 'genome analysis', 'genome sequencing', 'genome-wide', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2015,249543,0.055671522470836954
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,8919725,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Internet', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Mendelian disorder', 'Methodology', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinical sequencing', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic counselor', 'genetic variant', 'genome analysis', 'genome sequencing', 'genome-wide', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2015,750001,0.055671522470836954
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,8919725,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Internet', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Mendelian disorder', 'Methodology', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinical sequencing', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic counselor', 'genetic variant', 'genome analysis', 'genome sequencing', 'genome-wide', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2015,2339999,0.055671522470836954
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment. In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8899486,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Massive Parallel Sequencing', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'genetic variant', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'screening', 'software systems', 'targeted sequencing', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2015,574693,0.033647712103883246
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8889700,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2015,2005492,0.007428793979583403
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies, and have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. This year we have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods (1). We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data and this paper was recently accepted for publication. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meeting and a manuscript in development. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access. We are currently developing The Machine Suite which will be an extension of r2VIM and are writing several book chapters on maching learning in collaboration with Dr. James Malley of CIT.  We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published this year (2) presenting some of this work. This novel method was also described and used in a recent applied analysis of oral cleft GWAS data and a paper was published this year (3). Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011 an another in 2014. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.  This year we have worked on optimizing methods for performing multipoint analyses using extremely dense WES and exome chip data sets, and have shown that several linkage methods that purport to adequately adjust for intermarker linkage disequilibrium do not control false positive rates adequately when data of this extreme density is analyzed. This research was awarded a platform presentation at the upcoming 2015 International Genetic Epidemiology Society meeting (CL Simpson).  Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models.  In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. A paper this year was published presenting an extension to these methods for pleiotropy analyses (4). We are now in the process of applying these approaches to several of our genome-wide datasets.  Dr. Emily Holzinger has also published three papers on machine learning methods this year, in collaboration with her PhD mentor, as an extension of her PhD work and independent of Dr. Bailey-Wilson(5-7). n/a",Development of statistical genetics methodology,9152711,ZIAHG000153,"['African American', 'Award', 'Biological Models', 'Book Chapters', 'Caucasians', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'International', 'Learning', 'Linear Models', 'Linkage Disequilibrium', 'Logistic Regressions', 'Machine Learning', 'Manuscripts', 'Mentors', 'Meta-Analysis', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Probability', 'Process', 'Publications', 'Publishing', 'Research', 'Running', 'Scheme', 'Sequence Analysis', 'Societies', 'Solutions', 'Statistical Methods', 'Structure', 'Testing', 'Trees', 'Variant', 'Work', 'Writing', 'base', 'case control', 'data mining', 'density', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'genome-wide', 'improved', 'meetings', 'novel', 'oral cleft', 'pleiotropism', 'programs', 'quality assurance', 'rare variant', 'simulation', 'targeted sequencing', 'tool', 'trait', 'web site']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2015,473837,0.031393742600715466
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease. The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8919917,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Bayesian Modeling', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genetic study', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2015,241086,0.03776379856897066
"Statistical and computational analysis in whole genome sequencing studies. DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges. PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.",Statistical and computational analysis in whole genome sequencing studies.,8930750,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Health', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'meetings', 'population based', 'programs']",NHGRI,STANFORD UNIVERSITY,R01,2015,292499,0.05332740445230103
"Decrypting Variants of Uncertain Significance in Long-QT Syndrome DESCRIPTION (provided by applicant): Clinical genetic testing has become standard-of-care for many diseases including hundreds of inherited conditions. However, interpreting genetic test results is often confounded by the discovery of 'variants of unknown significance' (VUS) for which there is insufficient data or inadequate predictive tools to establish whether or not a particular variant predisposes to a disease. This problem is particularly vexing for genetic disorders with strong allelic heterogeneity and a preponderance of 'private' mutations such as the congenital long-QT syndrome (LQTS), which predisposes young adults and children to sudden death from cardiac arrhythmias. With the anticipated incorporation of personal exome or genome data into routine clinical care, interpreting VUS will become an even greater challenge especially when variants in genes associated with human disorders are incidentally discovered. Unfortunately, there are no reliable methods to predict a priori whether a given variant predisposes an individual to a particular disorder or whether the change is merely a benign rare variant. We propose to develop a novel paradigm for distinguishing disease-causing mutations from benign variants in LQTS as a model for other inherited arrhythmia syndromes and channelopathies. We will focus on variants in KCNQ1, the most commonly mutated gene in LQTS. The central hypothesis of this proposal is that a holistic predictive model that relates experimentally determined protein structure and dynamics to function and disease is highly accurate even for novel variants. Our ultimate objectives are to develop a data-trained, web-accessible algorithm that classifies VUS discovered in KCNQ1 based on reliable predictions of the structure and dynamics of the affected protein, and to achieve prediction accuracy to levels needed to inform medical decisions. The medical importance of correctly classifying KCNQ1 variants provides strong justification for having a dedicated and highly-tailored gene-specific prediction model. The ability to distinguish deleterious from neutral variants would help avoid unnecessary and potentially harmful interventions in carriers of benign alleles, and save the lives of those with true mutations. We propose to collect extensive electrophysiological, biochemical and structural data on a large set of KCNQ1 variants discovered in LQTS subjects as well as several suspected benign or neutral variants (Aims 1-2), then use these data to iteratively train and validate a machine learning based algorithm that can differentiate benign from deleterious KCNQ1 alleles among a set of new VUS (Aim 3). Our proposal is innovative in the use of a multidisciplinary approach to functionally and structurally annotate genomic variant data for a medically important gene at an unprecedented scale, and then to use these experimental findings to train/test a novel computational system to achieve clinical-grade predictions. Targeting KCNQ1 will also validate an approach for parallel work that can be utilized to predict the medical significance of variants in closely related potassium channels associated with heritable epilepsy (KCNQ2, KCNQ3) or deafness (KCNQ4). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a method to reliably predict the consequences of genetic variants of unknown significance discovered in the course of genetic testing in the congenital long-QT syndrome (LQTS), a cause of sudden cardiac death in children and young adults. We propose a multidisciplinary experimental approach including electrophysiology, biochemistry and structural biology deployed on a large scale to generate information on at least 110 genetic variants in the main gene responsible for LQTS (KCNQ1), which encodes a potassium channel required for normal electrical activity in the heart. Our final product will be a data-trained computational strategy that will outperform existing methods for accurately predicting the functional consequences of novel KCNQ1 genetic variants, enhance the value of genetic testing in LQTS and provide for more informed medical decisions.",Decrypting Variants of Uncertain Significance in Long-QT Syndrome,8892240,R01HL122010,"['Affect', 'Algorithms', 'Alleles', 'Anti-Arrhythmia Agents', 'Arrhythmia', 'Benign', 'Biochemical', 'Biochemistry', 'Biological', 'Cardiac', 'Caring', 'Cell surface', 'Child', 'Clinical', 'Computer Simulation', 'Data', 'Data Set', 'Defibrillators', 'Development', 'Disease', 'Electrophysiology (science)', 'Epilepsy', 'First Degree Relative', 'Genes', 'Genetic screening method', 'Genome', 'Goals', 'Heart', 'Hereditary Disease', 'Heterogeneity', 'Human', 'Implant', 'Individual', 'Inherited', 'Intervention', 'Ion Channel', 'Link', 'Long QT Syndrome', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Online Systems', 'Other Genetics', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Potassium Channel', 'Predisposition', 'Protein Dynamics', 'Proteins', 'Research Personnel', 'Resources', 'Structure', 'Sudden Death', 'Syndrome', 'System', 'Test Result', 'Testing', 'Therapeutic', 'Training', 'Variant', 'Work', 'base', 'clinical care', 'deafness', 'design', 'disease-causing mutation', 'exome', 'genetic variant', 'genome sequencing', 'heart rhythm', 'innovation', 'interdisciplinary approach', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'proband', 'protein function', 'protein structure', 'protein transport', 'public health relevance', 'rare variant', 'research study', 'structural biology', 'sudden cardiac death', 'tool', 'trafficking', 'variant of unknown significance', 'web-accessible', 'young adult']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2015,1254784,0.027901898463696805
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,8920443,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'deletion detection', 'design', 'genetic variant', 'genome sequencing', 'improved', 'integration site', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2015,2663757,0.028885365375899325
"Human-Specific Gain and Loss of Function DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university. PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.",Human-Specific Gain and Loss of Function,8796200,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomic Segment', 'Genomic approach', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2015,54194,0.017722626892623418
"An integrative approach to functionalize GWAS hits in MI and stroke ﻿    DESCRIPTION (provided by applicant): Coronary heart disease (CHD) and cerebrovascular disease result from platelet thrombus formation at the site of a ruptured atherosclerotic plaque. Numerous studies have shown enhanced platelet reactivity, and increased platelet count and volume are risk factors for CHD events and fatality, and a recent NHLBI Working Group concluded that variation in platelet reactivity is a major determinant of ischemic events, like MI or stroke. Genome wide association studies (GWASs) have identified numerous common genetic variants associated with the risk of CHD and platelet function parameters, but most of the positive ""hits"" are not causative of the phenotype. To understand the cellular mechanisms by which these variants affect platelet function it is imperative to know the repertoire of mRNAs, miRNAs and lncRNAs expressed in the cell of interest. Our team has been a leader in the field of platelet transcriptomics as well as functional assessment of variants in platelet genes. We have profiled mRNAs and miRNAs from 183 subjects using multiple platforms and have also performed platelet RNA-seq on 14 different subjects. This information provides a critical ability to filter, prioritize and obtain variant functional insights for evaluating GWAS SNPs associated with MI, stroke and platelet parameters. We have identified 142 mRNAs and 9 miRNAs that are expressed in platelets and linked to these GWAS hits. The goals of this proposal are to identify, assay, and validate functional variation previously tagged in GWASs of platelet-mediated ischemic arterial disease and of platelet phenotypes. Aim 1 will identify GWAS-linked mRNAs, miRNAs and lncRNAs that are functional in platelets. Candidate RNAs will be refined by association with platelet function, eQTLs and QTLs using our previously generated platelet RNA data. We will develop a supervised machine-learning, statistical pattern matching algorithm to prioritize likely platelet-functional genes. Gene-level assays in which we knock down mRNA, miRNA and lncRNA in our human megakaryocyte culture system, followed by assays for integrin activation and quantification of platelet number and volume will be used to confirm platelet functionality. Aim 2 will identify functionally divergent SNPs and haplotypes. We will impute missing SNPs and perform fine-mapping to the phenotypes of interest. Variants will be prioritized by association strength, annotation data, and predicted function using publically available resources and our own platelet eQTL data. Non-coding candidates will be tested by reporter gene assay and non-synonymous variants will be tested using functional assays in cell lines in which the endogenous gene has been silenced. We will validate our findings with a replication analysis in which we use an independent cohort dataset to quantify the association of the tested variants with the original GWAS phenotype.         PUBLIC HEALTH RELEVANCE:  Platelet-mediated arterial thrombosis in the coronary or cerebrovascular circulation is the major cause of mortality and morbidity in the U.S. Numerous DNA variations have been associated with these disorders, but the causal genes are unknown. This research will test whether genes near these DNA variations - and candidate variations themselves - alter platelet function or number to understand better the molecular mechanisms causing heart attacks and strokes.            ",An integrative approach to functionalize GWAS hits in MI and stroke,8985084,R01HL128234,"['Affect', 'Algorithms', 'Alleles', 'Amino Acids', 'Arterial Fatty Streak', 'Binding', 'Bioinformatics', 'Biological Assay', 'Blood Platelet Disorders', 'Blood Platelets', 'CD34 gene', 'Cell Line', 'Cells', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'ChIP-seq', 'Coronary Circulation', 'Coronary heart disease', 'Coupled', 'DNA', 'Data', 'Data Set', 'Disease', 'Distal', 'Enhancers', 'Event', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genotype', 'Goals', 'Haplotypes', 'Human', 'Individual', 'Integrins', 'Introns', 'Investigation', 'Laboratories', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Mediator of activation protein', 'Megakaryocytes', 'Messenger RNA', 'Methods', 'MicroRNAs', 'Molecular', 'Morbidity - disease rate', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'Nucleic Acid Regulatory Sequences', 'Pathologic', 'Pattern', 'Phenotype', 'Platelet Activation', 'Platelet Count measurement', 'Positron-Emission Tomography', 'Prevention', 'Production', 'Protocols documentation', 'RNA', 'Reporter Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Rupture', 'Sentinel', 'Site', 'Stroke', 'System', 'Testing', 'Thrombosis', 'Thrombus', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'base', 'clinical phenotype', 'clinically relevant', 'cohort', 'falls', 'genetic variant', 'genome wide association study', 'genome-wide', 'human subject', 'insight', 'interest', 'knock-down', 'mortality', 'promoter', 'protein function', 'public health relevance', 'screening', 'transcription factor', 'transcriptome sequencing', 'transcriptomics', 'working group']",NHLBI,THOMAS JEFFERSON UNIVERSITY,R01,2015,406469,-0.00579755974951502
"From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations DESCRIPTION (provided by applicant): Genomic medicine offers hope for improved diagnostic methods and for more effective, patient-specific therapies. Genome-wide associated studies (GWAS) elucidate genetic markers that improve clinical understanding of risks and mechanisms for many diseases and conditions and that may ultimately guide diagnosis and therapy on a patient-specific basis. This project will expand on existing work to identify gene-phenotype associations across the genome and phenome, deploying new phenome-wide associations study (PheWAS) methods to deeply investigate electronic medical record (EMR)-derived phenotypes across common and rare variants across the genome. The project is enabled by large DNA biobanks coupled to de-identified copies of EMR. This project has three specific aims. First, we will expand the PheWAS phenotype library to include both binary traits and continuous variables incorporating about 7000 phenotypes derived from natural language processing, laboratory data, and report data. The second aim is to perform a PheWAS for common and rare variants using extant genome-wide and exome variant data and the broader set of phenotypes derived in Aim 1. We will analyze associations using single variant and multi-variant aggregation methods. We will validate the efficacy of our methods in Aim 2 by comparing to known associations. The third aim is to develop a standards-based infrastructure to share PheWAS results and develop tools to enable others to perform PheWAS. The tools generated from this project will not only expand the capabilities of the current PheWAS methodology, but will also broadly enable clinical research and subsequent genetic studies. Project Narrative Genomic medicine offers hope for improved diagnosis and for more effective, patient- specific therapies. This PheWAS proposal will develop new methods to identify detailed phenotypes and diseases from electronic medical records and then find novel genetic associations from existing genomic data.",From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations,8919743,R01LM010685,"['Address', 'Adopted', 'Architecture', 'Atrial Fibrillation', 'Biology', 'Body mass index', 'Cardiac', 'Cataloging', 'Catalogs', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'DNA Databases', 'Data', 'Data Reporting', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Documentation', 'Drug Exposure', 'Exclusion', 'Funding', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Health system', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Laboratories', 'Lead', 'Libraries', 'Link', 'Mainstreaming', 'Measures', 'Medicine', 'Methodology', 'Methods', 'National Human Genome Research Institute', 'Natural Language Processing', 'Nature', 'Obesity', 'Pathway interactions', 'Patients', 'Peer Review', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Rare Diseases', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Scanning', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Surveys', 'Testing', 'Variant', 'Work', 'base', 'biobank', 'cohort', 'disease phenotype', 'disorder subtype', 'endophenotype', 'exome', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'improved', 'next generation', 'novel', 'phenome', 'pleiotropism', 'rare variant', 'software development', 'tool', 'trait']",NLM,VANDERBILT UNIVERSITY,R01,2015,125155,0.04946401788744983
"Fast and Robust Methods for Large Scale Genotype Phenotype Association Study ﻿    DESCRIPTION (provided by applicant): A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Thanks to the advanced sequencing technologies, an enormous amount of genetic variants have been identified and cataloged. Such data hold great potential to understand how genes affect phenotypes and contribute to the susceptibility to environmental stimulus. However, the existing computational methods for analyzing and interpreting the high‐throughput genetic data are still in their infancy.    We propose to systematically investigate the computational and statistical principles in modeling and discovering genetic basis of complex phenotypes. The proposed research provides answers to the following fundamental questions in genetic association study: (1) How to effectively and efficiently assess statistical significance of the findings? (2) How to account for the relatedness between samples in genetic association study? (3) How to accurately capture possible interactions between multiple genetic factors and their joint contribution to phenotypic variation? In particular, we will develop data structures and efficient algorithms for accurate and robust significance assessment that account for local population structure and joint effect of multiple genetic factors.    The proposed computational tools will be integrated into software packages under common application framework adopted by the broad scientific community.         PUBLIC HEALTH RELEVANCE: A fundamental challenge in life sciences is the characterization of genetic factors that underlie phenotypic differences. Existing methods are not able to adequately address the complexity of high throughput data. Innovative computational models and methods developed in this project will enable scientists more effectively analyze the research data, thus further understanding of human diseases and speed the development diagnostic tools, cures, and therapies.              ",Fast and Robust Methods for Large Scale Genotype Phenotype Association Study,8946076,R01GM115833,"['Accounting', 'Address', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Bioinformatics', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Development', 'Diagnostic', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Marker Expression', 'Genetic Markers', 'Genotype', 'Information Networks', 'Joints', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Mining', 'Modeling', 'Mus', 'Noise', 'Performance', 'Phenotype', 'Phylogeny', 'Pilot Projects', 'Population', 'Predisposition', 'Property', 'Publications', 'Quantitative Trait Loci', 'Research', 'Research Institute', 'Sampling', 'Scientist', 'Speed', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Trees', 'Variant', 'base', 'computerized tools', 'data mining', 'experience', 'genetic association', 'genetic variant', 'human disease', 'improved', 'infancy', 'innovation', 'interest', 'novel', 'public health relevance', 'tool', 'trait']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2015,294994,0.02739799025213435
"Discovery and analysis of structural variation in whole genome sequences DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities. PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.",Discovery and analysis of structural variation in whole genome sequences,8906910,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Alteration', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'genomic variation', 'improved', 'interest', 'markov model', 'rare variant', 'structural genomics', 'tool', 'virtual']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2015,371408,0.05141617580059473
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,8858662,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Human', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'hazard', 'improved', 'loss of function', 'novel', 'personalized genomic medicine', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'theories', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2015,248912,0.0024939869268235083
"F-CAP: Functionalization of Variants in Clinically Actionable Pharmacogenes ﻿    DESCRIPTION (provided by applicant): Patient-to-patient variability in response to drugs creates a significant challenge for the safe and effective treatment of many human diseases. Pharmacogenomics seeks to address this challenge by linking drug response to patient genotypes at important loci, termed pharmacogenes, in order to better customize patient treatments. Genetic variation in pharmacogenes is extensive. For example, amongst 12 CYP genes, 10% of people carry at least one rare, potentially deleterious variant. Unfortunately, only a small number of variants have been unambiguously linked to alterations in drug response. Clearly, new approaches are needed to annotate the consequences of the huge pool of variants of unknown significance, including those already identified by existing large-scale sequencing programs, and those that will be discovered as clinical sequencing becomes routine. In this proposal, we seek to address this problem directly and at a scale never before possible by taking advantage of new technologies in sequencing and functional analysis. Our resource, termed F-CAP (Functionalization of Variants in Clinically Actionable Pharmacogenes) will test all possible substitutions at all amino acid residues in some of the most clinically important pharmacogenes and disseminate these data to the medical and research communities. In order to accomplish this, we will use deep mutational scanning, a method we have developed that allows parallelized, and quantitative measurements to be performed on libraries of genetic variants. In Aim 1 we will create these libraries, starting with five of the most important CPIC level A or B priority genes (CYP2C9, CYP2C19, CYP2D6, TPMT and VKORC1), and test the stability and enzymatic activity of each variant en masse using a pooled selection strategy. In Aim 2, we will integrate these data to create an impact score. This impact score provides a numerical value for a variant's functional effects that is amenable to easy integration into prescribing guidelines being developed by the pharmacogenomics community. Aim 3 will validate this score for a subset of variants that span the impact score spectrum using therapeutically relevant substrates for each pharmacogene. Finally, Aim 4 describes a key component of this resource: the dissemination of our findings to the entire pharmacogenomics community through partnership with CPIC and PharmGKB. In addition, we will make available our raw and processed data via a custom web resource that will also be developed in Aim 4. This resource will provide a series of fully annotated datasets describing the functional consequences of every possible single mutation in a series of key pharmacogenes, thereby greatly advancing the field of personalized medicine.         PUBLIC HEALTH RELEVANCE: Pharmacogenomics seeks to identify genetic sources of inter-individual variability in drug response, with the goal of personalizing drug selection and dose to improve patient outcomes. A key barrier to using pharmacogenomic information is lack of clarity about the functional impact of variants, which hampers the provision of clear, unambiguous guidance to health care providers. We propose to connect pharmacogenomic variant discovery with novel high-throughput experimental approaches to deliver a resource to guide the use of individual pharmacogenomic information in personalizing drug treatment.            ",F-CAP: Functionalization of Variants in Clinically Actionable Pharmacogenes,8933744,R24GM115277,"['Address', 'Affect', 'Algorithms', 'Amino Acids', 'Applications Grants', 'Biochemical', 'Biological Assay', 'CYP2C19 gene', 'CYP2C9 gene', 'CYP2D6 gene', 'Cataloging', 'Catalogs', 'Cellular Assay', 'Classification', 'Code', 'Communities', 'Custom', 'Data', 'Data Set', 'Databases', 'Dose', 'Elements', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Guidelines', 'Health Personnel', 'High-Throughput DNA Sequencing', 'In Vitro', 'Individual', 'Internet', 'Large-Scale Sequencing', 'Libraries', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Research', 'Methods', 'Monoclonal Antibody R24', 'Mutate', 'Mutation', 'Numerical value', 'Outcome', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Plant Roots', 'Positioning Attribute', 'Relative (related person)', 'Resources', 'Scanning', 'Series', 'Source', 'TPMT gene', 'Testing', 'Translations', 'Variant', 'clinical sequencing', 'clinically actionable', 'computerized data processing', 'effective therapy', 'exome', 'genetic disorder diagnosis', 'genetic information', 'genetic variant', 'human disease', 'improved', 'interest', 'new technology', 'novel', 'novel strategies', 'personalized medicine', 'programs', 'public health relevance', 'response', 'stability testing', 'tool', 'user-friendly', 'variant of unknown significance']",NIGMS,UNIVERSITY OF WASHINGTON,R24,2015,751729,0.015341724603797577
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,8929328,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Drug Formulations', 'Enrollment', 'Equilibrium', 'Event', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Health', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'flexibility', 'genetic makeup', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'personalized medicine', 'predictive modeling', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2015,329422,0.02690504125980334
"Data-Driven Statistical Learning with Applications to Genomics DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software. PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.",Data-Driven Statistical Learning with Applications to Genomics,8929328,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Drug Formulations', 'Enrollment', 'Equilibrium', 'Event', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Health', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'flexibility', 'genetic makeup', 'high throughput analysis', 'individualized medicine', 'interest', 'novel', 'patient population', 'personalized medicine', 'predictive modeling', 'relating to nervous system', 'response', 'statistics', 'targeted treatment', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2015,1,0.02690504125980334
"Mechanisms underlying complex trait human disease DESCRIPTION (provided by applicant): There is now an explosion of new genome scale data relating genetic variation within the human population to phenotype, and particularly to common disease. Microarray technology has identified 100s of loci where the presence of particular variants is associated with altered risk of many common diseases; complete sequencing of individual exomes in cancer samples has discovered many somatic mutations in a variety of genes; and sequencing of 1000 human genomes has provided an almost complete inventory of common population variants. Further, these data are only the first in an ever-increasing flood, as even faster and cheaper sequencing technologies come on line. The results hold promise for major advances in treatment and diagnosis of common human diseases. Extracting the expected benefits is not straightforward, and will necessitate acquiring detailed knowledge of the mechanisms linking genetic variation to disease. This project focuses on one aspect of this challenge - using the new genomic data to identify new therapeutic opportunities. We will investigate those principles underlying complex trait disease that are particularly relevant to tha goal. We introduce a three stage mechanistic framework, relating genomic variation to the function of impacted gene products, the impact of these altered functions on pathways, processes and subsystems; and finally the consequences for complex trait disease phenotypes. We will develop computational methods to address key questions concerning three major aspects of the framework (1) How large are the changes in protein function brought about by the genomic variants underlying complex trait disease? What role do different classes of genomic and protein level mechanism, such as expression, non-synonymous changes and splicing, play in these variants? (2) How complete is the set genes with strong influence on the disease phenotypes discovered by current technologies, and how can missing genes be imputed from the genomic and network data? (3) What is the distribution of coupling between the activity of genes involved in disease mechanism and disease phenotypes? The results will deepen understanding of these aspects of complex disease, and provide a basis for identifying potential new drug targets from GWAS and other genomic studies. PUBLIC HEALTH RELEVANCE: New technologies are now providing extensive information on human genetic variation associated with increased risk of a wide range of common human disease, such as Alzheimer's, diabetes, heart disease, and many cancers. These data hold the promise for the development of new therapies, and realizing those benefits requires the acquisition of complementary knowledge of the mechanisms that link genetic variation to disease risk. This project is focused on analysis of the relationship between genetic variation and common disease with the goal of identifying new therapeutic opportunities.",Mechanisms underlying complex trait human disease,8854112,R01GM104436,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Complex', 'Computing Methodologies', 'Coupled', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Drug Targeting', 'Equipment and supply inventories', 'Explosion', 'Floods', 'Frequencies', 'Future', 'Genes', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heart Diseases', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Information Networks', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Mendelian disorder', 'Methods', 'Microarray Analysis', 'Minor', 'Modeling', 'Molecular', 'Other Genetics', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Play', 'Population', 'Process', 'Proteins', 'RNA Splicing', 'Relative (related person)', 'Risk', 'Role', 'Sampling', 'Somatic Mutation', 'Staging', 'Technology', 'Therapeutic', 'Translations', 'Variant', 'Work', 'base', 'disease phenotype', 'disorder risk', 'exome', 'exome sequencing', 'gene function', 'genetic information', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genomic variation', 'human disease', 'improved', 'insight', 'new technology', 'novel therapeutics', 'protein function', 'rare variant', 'risk variant', 'therapeutic target', 'tool', 'trait']",NIGMS,"UNIV OF MARYLAND, COLLEGE PARK",R01,2015,288058,0.04032943719375217
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,8849936,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2015,681355,0.02058656111228219
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,9121301,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2015,124339,0.02058656111228219
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies.         PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.            ",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,8984471,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug Regulations', 'Drug resistance', 'Family', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'molecular dynamics', 'mutant', 'novel', 'personalized medicine', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2015,300000,-0.01868828976759812
"Genetic Factors in Keratoconus     DESCRIPTION (provided by applicant): The purpose of this grant is to develop techniques for use in the 'early' detection of keratoconus (KC) and identify genetic variants that contribute to is development. KC is a complex genetic eye disorder and a leading cause of corneal transplantation in the young, with approximately 300,000 affected individuals in the US. Undiagnosed, subclinical KC is one of the major causes for complications of LASIK (Laser-in-situ- Keratomilieusis) surgery, commonly performed for vision correction. In the past two decades we have made major improvements to the early diagnosis of KC and have also made significant contributions to the delineation of major genetic determinants of KC through genome wide linkage studies (GWLS), fine mapping, and genome wide association studies (GWAS). In this proposal, we intend to follow up on these studies using new powerful approaches to achieve the following specific aims: In Aim 1 we will combine corneal optical coherence tomography (OCT) and Pentacam HR Scheimpflug Tomography (PST), new technologies that measure both the anterior and posterior surface of the cornea, with videokeratography (VK), a method which revolutionized KC diagnosis, to characterize criteria and to improve the diagnosis of subclinical KC. In Aim 2, to identify additional KC genes, we will perform a 2.5 million SNP GWAS, with an additional 6,000 SNPs, to fine- map already identified genes. We will confirm these results in a separate cohort of KC patients. For this two- stage GWAS design we are assembling the largest group of KC patients described to date: 2000 KC patients in total, 1,000 for the GWAS discovery stage and 1,000 for the confirmation stage. The controls for GWAS discovery will come from the Cardiovascular Health Study (CHS; 3300) and for confirmation will come from 400 subjects with VK, PST, and OCT measurements under Aim 1 and 600 ""convenience controls"" from the Cholesterol and Pharmacogenetics (CAP) study. In our current state of knowledge, the most cost-effective approach to increase the number of identified KC genes is to proceed with the expanded GWAS proposed herein. In Aim 3, we will test the impact of the genes identified in Aim 2 on the 'early' subclinical phenotypes identified through the use o VK, PST and OCT measures in Aim 1. Lastly, for the second part of Aim 3, we will investigate the potential function of KC variants by testing their ability to influence gene structure, expression and function in corneal cell models, including iPS cells derived from corneal keratocytes developed by our research team. The results of these studies will help advance our understanding of the genetic susceptibility to KC and may result in novel treatment options to slow the progression of the disease.         PUBLIC HEALTH RELEVANCE: Improving methods for the 'early' detection of keratoconus will help patients avoid complications of LASIK surgery, allow us to identify genetic variants that contribute to its development, and design therapies to retard its progression.            ",Genetic Factors in Keratoconus,8817912,R01EY009052,"['Affect', 'Anterior', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cells', 'Collaborations', 'Complex', 'Cornea', 'Custom', 'Data', 'Development', 'Diagnosis', 'Discriminant Analysis', 'Disease Progression', 'Early Diagnosis', 'Epidemiology', 'Etiology', 'Eye', 'Eye diseases', 'Family member', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Predisposition to Disease', 'Genetic Transcription', 'Genetic Variation', 'Genotype', 'Grant', 'Immunohistochemistry', 'In Situ', 'Individual', 'Keratoconus', 'Keratoplasty', 'Knowledge', 'Lasers', 'Lead', 'Literature', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Molecular', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Pathogenesis', 'Patients', 'Pharmacogenetics', 'Phenotype', 'Relative (related person)', 'Research', 'Research Design', 'Reverse Transcriptase Polymerase Chain Reaction', 'Risk', 'Staging', 'Surface', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Variant', 'Videokeratographies', 'Vision', 'base', 'bead chip', 'cardiovascular health', 'cholesterol control', 'cohort', 'cost effective', 'design', 'follow-up', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide linkage', 'improved', 'indexing', 'induced pluripotent stem cell', 'new technology', 'novel', 'prevent', 'protein expression', 'protein function', 'public health relevance', 'therapy design/development', 'tomography', 'tool', 'trait']",NEI,CEDARS-SINAI MEDICAL CENTER,R01,2015,661520,0.028673247548816293
"Integrative interpretation of the organismal consequences of non-coding variation ﻿    DESCRIPTION (provided by applicant): Our capacity to sequence human genomes has exceeded our ability to interpret genetic variation, particularly in non-coding regions. To address this challenge, we recently developed a novel framework, Combined Annotation Dependent Depletion (CADD), for estimating the deleteriousness of any genetic variant. CADD defines an objective, data-rich, and quantitative integration of many genomic annotations into a single measure of variant effect at the organismal level. The goals of this R01 proposal are to further develop the CADD framework, to apply it in the context of ongoing genetic studies of both rare and common human diseases, and to experimentally evaluate its predictions. In Specific Aim 1, we will substantially modify CADD in both straightforward and creative ways, with the goal of dramatically improving CADD's ability to annotate non- coding variants, not only to estimate their organismal effects but also to provide insights into molecular mechanisms. In Specific Aim 2, we will apply CADD to a variety of ongoing whole genome sequencing studies of human disease, especially those in which non-coding variants are either known or suspected to be causal. As part of this effort, we will develop new statistical frameworks that directly incorporat CADD into traditional genome-wide discovery approaches. In Specific Aim 3, we will perform a combination of high-throughput (massively parallel reporter assays), medium-throughput (CRISPR/Cas9), and low-throughput (in vivo mouse transgenics) experimental assays for systematic and targeted assessment of CADD predictions. This proposal includes both computational and experimental innovations, and builds on established collaborative relationships between investigators with complementary strengths. The completion of our aims will yield novel methods, data, and resources with which to annotate whole genome sequences, broadly enabling the field to more effectively identify and mechanistically understand non-coding genetic variants that are causally relevant to human disease.         PUBLIC HEALTH RELEVANCE: As we enter an era of personalized medicine, a deep understanding of human genomes will be increasingly important to public health, contributing to the unraveling of the genetic basis of human disease, as well as serving an increasing role in clinical diagnostics. However, our limited understanding of the functional consequences of most genetic variants, especially those that do not alter protein sequence, represents a major obstacle. This proposal seeks to dramatically improve our ability to identify and interpret ""non-coding"" variants that causally contribute to human disease. A recently developed computational approach will be substantially improved and evaluated in a variety of genetic studies, and its predictions will be experimentally validated. This project will provide much needed methods and resources to address the looming analytical challenges associated with individual whole genome sequencing in both biomedical research and patient care.                ",Integrative interpretation of the organismal consequences of non-coding variation,8792292,R01CA197139,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Binding', 'Biological Assay', 'Biomedical Research', 'Cell Line', 'Chromosome Mapping', 'Clinical', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'Complex Genetic Trait', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Disease', 'Event', 'Feedback', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic approach', 'Genomics', 'Goals', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Individual', 'Machine Learning', 'Maps', 'Measures', 'Mendelian disorder', 'Methods', 'MicroRNAs', 'Molecular', 'Mus', 'Mutation', 'Nature', 'Nucleotides', 'Organism', 'Pathogenicity', 'Patient Care', 'Peptide Sequence Determination', 'Phenotype', 'Property', 'Public Health', 'Quantitative Trait Loci', 'RNA Binding', 'RNA Splicing', 'Regulatory Element', 'Reporter', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Site', 'Structure', 'System', 'Testing', 'Tissues', 'Training', 'Transcriptional Regulation', 'Transgenic Mice', 'Translating', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Vocabulary', 'Weight', 'base', 'candidate identification', 'disease phenotype', 'exome', 'exome sequencing', 'follow-up', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome-wide', 'human disease', 'human genome sequencing', 'improved', 'in vivo', 'innovation', 'insertion/deletion mutation', 'insight', 'novel', 'novel diagnostics', 'personalized medicine', 'public health relevance', 'research study', 'trait', 'transcription factor']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,666593,0.03258401100693396
"EMR-Linked Biobank for Translational Genomics ﻿    DESCRIPTION (provided by applicant): Medical care informed by genomic information is beginning to move into clinical practice. The Electronic Medical Records and Genomics (eMERGE) network through its initial phases has provided much of the groundwork for this transformation. The Geisinger Health System project, ""EMR-Linked Biobank for Translational Genomics"" intends to build on the knowledge and experience from eMERGE phase II to accelerate discovery and implementation while expanding our understanding of the sociocultural implications of genomics in medicine. We will accomplish this goal through three specific aims: 1) Use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery in the proposed disorders: familial hypercholesterolemia and chronic rhinosinusitis, 2) Develop and test approaches for implementation of genomic information in clinical practice, 3) Explore, develop and implement novel approaches for family-centered communication around clinically relevant genomic results. We currently have over 60,000 patients broadly consented for research with a large and increasing proportion consented for return of results and deposition in the electronic health record. Over 18,000 patients are genotyped on high density platforms. Our two proposed phenotypes, familial hypercholesterolemia (FH) and chronic rhinosinusitis (CRS) were chosen because both conditions have a significant public health impact in the United States, but they are also ideally suited to the specific aims of the project. They provide opportunities for innovation and extension of current eMERGE methods. While many of these innovations will take advantage of the sequencing done as part of the project, there are several other areas emphasized in the funding opportunity that will broaden the scope of eMERGE research. One of the areas of emphasis for eMERGE III is exploring the familial return of actionable results. FH is well suited to this, as the current clinical recommendation is cascade testing of family members for all diagnosed patients. Currently this relies on the patient to contact at risk family members, but this is less than optimal. We will explore this issue using qualitative and quantitative methods and use the results to design and test novel family communication strategies. Gene-environment interactions play an important role in the development and severity of disease. These are very difficult to study. We propose novel approaches that leverage the assets of Geisinger Health System and the eMERGE Network to develop and apply methods to extend existing projects that study the impact of environment on CRS. This would include the first large scale environment-wide association studies (EWAS). Finally, we propose to lead efforts to apply the tools of economic modeling and analysis to eMERGE projects to begin to quantify the value of implementation of genomic medicine in the US healthcare system. These proposed innovations will magnify the already significant impact that the eMERGE program has had in moving genomic medicine from a dream to a reality.         PUBLIC HEALTH RELEVANCE: Through this application GHS seeks to continue its participation in the eMERGE Network for Phase III - Study Investigators U01 (RFA-HG-14-025) funding opportunity. We propose 3 specific aims: 1) use existing biospecimens, genotype and sequence data and EMR-generated phenotypes for discovery and validation of gene-phenotype associations; 2) develop and test approaches for implementation of genomic information in clinical practice; develop and implement novel approaches for family-centered communication around clinically relevant genomic results                ",EMR-Linked Biobank for Translational Genomics,8968014,U01HG008679,"['Adult', 'Algorithms', 'Ambulatory Care', 'Area', 'Attitude', 'Candidate Disease Gene', 'Caring', 'Catchment Area', 'Child', 'Clinical', 'Communication', 'Computerized Medical Record', 'Consent', 'County', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Data', 'Deposition', 'Development', 'Diagnosis', 'Disease', 'Dreams', 'Economic Models', 'Ecosystem', 'Electronic Health Record', 'Ensure', 'Environment', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Funding Opportunities', 'Generations', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Group Practice', 'Health', 'Health Insurance', 'Health system', 'Healthcare', 'Healthcare Systems', 'Individual', 'Information Systems', 'Inpatients', 'Institute of Medicine (U.S.)', 'Integrated Health Care Systems', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Pennsylvania', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Population', 'Process', 'Prognostic Factor', 'Provider', 'Public Health', 'Recommendation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Rural', 'Rural Population', 'Safety', 'Severity of illness', 'Site', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Treatment outcome', 'United States', 'Validation', 'Variant', 'base', 'biobank', 'case finding', 'chronic rhinosinusitis', 'clinical care', 'clinical practice', 'clinically relevant', 'density', 'design', 'epidemiology study', 'experience', 'gene environment interaction', 'genetic epidemiology', 'genetic variant', 'implementation research', 'innovation', 'interest', 'meetings', 'novel', 'novel strategies', 'phase 3 study', 'phenome', 'population based', 'programs', 'public health relevance', 'screening', 'systems research', 'tool', 'trait', 'treatment response']",NHGRI,GEISINGER CLINIC,U01,2015,899776,0.021998801240977726
"Predicting causal non-coding variants in a founder population Enter the text here that is the new abstract information for your application. This section must be no longer than 30 lines of text. In order to characterize the molecular and cellular causes of human disease, it will be essential to unravel the functional impact of genetic variation. However, we are currently unable to predict the impact of the majority of genetic variants that lie in non-coding regions of the genome, where indeed most complex disease-associated variants are found. Additionally, recent evidence suggests that a significant fraction of the non-coding genome is likely to be functional, often playing a role in gene regulation. Therefore, our limited understanding of non- coding variation is a critical hurdle to characterizing the genetic basis of disease. The goal of this project is to develop methods for interpreting non-coding genetic variation: to provide a robust and extensible Bayesian method for predicting causal variants from full genomes, to identify and validate a large set of functional non- coding variants using CRISPR technology, and to predict disease-relevant traits likely to be affected by each variant. Our project will leverage the increasing availability of cohorts such as UK10K, GTEx, CARTaGENE and SardiNIA, with genome sequence and transcriptome data available from thousands of individuals, along with extensive phenotyping for hundreds of traits. We will combine advanced statistical modeling with experimental validation based on genome engineering to identify causal non-coding variants affecting biomedical traits in the cohort, along with predicting functional mechanisms through which these variants ultimately perturb the cell. In Aim 1, we develop computational methods for predicting causal non-coding variation from full genomes, incorporating multiple informative genomic features into a Bayesian approach. We will optimize and apply these methods on genome and transcriptome data available for well-studied and broadly-accessible cohorts to identify a large set of variants predicted to causally affect gene expression. Based on these predictions, in Aim 2, we connect putative causal variants with the diverse set of disease- relevant traits measured in the cohort, using network inference to capture the cascade from genetic variation to gene expression to disease. We will develop methods to integrate across variants, using the models in Aim 1, to identify the common causal mechanisms related to each trait. In Aim 3, we validate the causal impact of non-coding variants predicted to affect high-level traits. We will use genome editing through CRISPR to introduce individual genetic variants into cell lines and use qPCR to validate the predicted effects on gene expression. Finally, a major goal throughout this proposal will be to provide the research community with convenient computational tools for the prediction of causal non-coding variants from individual genomes, updated on an ongoing basis to integrate the most recent genomic annotations and public data in order to provide the best possible accuracy in predicting causal variants and the traits they are likely to affect. Our project will greatly advance our understanding of non-coding genetic variation, the specific mechanisms affected by causal variants, and the downstream consequences to the cell and individual health. 2. PUBLIC HEALTH RELEVANCE:  Understanding the impact of variation in the entire genome, beyond the well-studied protein-coding regions, is essential to understanding the relationship between genetics and human health. This proposal addresses the problem of identifying functional non-coding genetic variants and predicting the impact of each variant on hundreds of disease-relevant traits. Our approach will focus on integrative, transformative methods for understanding mechanisms underlying the function of the human genome.                ",Predicting causal non-coding variants in a founder population,8792751,R01HG008150,"['Address', 'Affect', 'Algorithms', 'Alleles', 'Bayesian Method', 'Biological Assay', 'Biology', 'Cataloging', 'Catalogs', 'Categories', 'Cell Line', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complex', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Epigenetic Process', 'Family', 'Founder Generation', 'Frequencies', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genetic', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomic Segment', 'Genomics', 'Goals', 'Health', 'Human Genetics', 'Human Genome', 'Individual', 'Inherited', 'Link', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Nucleotides', 'Open Reading Frames', 'Pathogenesis', 'Phenotype', 'Play', 'Population', 'Property', 'RNA Splicing', 'Research', 'Resolution', 'Resources', 'Role', 'Sampling', 'Sardinia', 'Signal Transduction', 'Statistical Models', 'System', 'Techniques', 'Technology', 'Testing', 'Transcript', 'Untranslated RNA', 'Update', 'Validation', 'Variant', 'Widespread Disease', 'base', 'cohort', 'computerized tools', 'data modeling', 'density', 'disease phenotype', 'disorder risk', 'functional genomics', 'genetic linkage analysis', 'genetic variant', 'genome annotation', 'genome editing', 'genome sequencing', 'genome-wide', 'human data', 'human disease', 'human genome sequencing', 'improved', 'innovation', 'insertion/deletion mutation', 'molecular phenotype', 'novel', 'public health relevance', 'trait', 'transcriptome sequencing', 'transcriptomics']",NHGRI,STANFORD UNIVERSITY,R01,2015,477647,0.002079882737605528
"Enhanced Gene Identification in Complex Traits Using Kernel Machines DESCRIPTION (provided by applicant):     Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5). PUBLIC HEALTH RELEVANCE:     Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8894057,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'methylation pattern', 'next generation sequencing', 'novel', 'open source', 'population based', 'predictive modeling', 'rare variant', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2015,341249,0.02202035580048733
"Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies DESCRIPTION (provided by applicant): Common mental disorders such as Alzheimer's disease and schizophrenia are largely heritable with complex genetic underpinnings. Large-scale genome-wide association studies that contrast DNA sequence data from patients and controls have recently identified novel genetic risk variants for these disorders. Nevertheless, the processes through which genotype increases risk are yet to be fully characterized.  Neuroimaging offers a richer picture of the underlying disease processes than a clinical diagnosis. Thus the joint analysis of neuroimaging and genetics data promises to advance our understanding of these processes. Today, neuroimaging genetics studies however face important challenges that obstruct progress: small sample sizes, modest effect sizes, and the extreme dimensionality of the data limit statistical power and thus our ability to explore the complex and subtle associations between genes, neuroanatomy and clinical decline. Currently, the prevalent approach in neuroimaging genetics is to concentrate the analysis on a small number of anatomic regions of interest and/or candidate genes and often ignore a large portion of the data. The core goal of the proposed project is to develop computational tools that will take full advantage of the richness in the datasets and facilitate the exploration of the multifaceted associations between genotype, neuroimaging measurements and clinical phenotype. The proposed project will use advanced multivariate pattern analysis methods such as support vector machines to compute image-based and genetic scores that reflect pathology. We will validate the tools based on their association with classical biomarkers of disease. Finally, we will develop a model that uses both imaging and genotype data to predict future clinical outcome. We expect these tools will enable progress along three directions relevant to complex mental disorders, e.g. late-onset Alzheimer's disease (AD): (1) confirming and characterizing risk genes, (2) identifying disease-specific anatomical alterations in healthy individuals, and (3) early diagnosis and prognosis. The project will (1) use three already-collected large-scale datasets to apply the developed tools to AD, (2) build on cutting-edge image processing algorithms that we have been developing, and (3) allow the candidate to receive further training in neuroanatomy, mental disorders and genetics, forming the foundation for his future career as an independent researcher. n/a",Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies,8916113,K25EB013649,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Anatomy', 'Biological Markers', 'Brain', 'Candidate Disease Gene', 'Clinical', 'Clinical Trials', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Dementia', 'Development', 'Disease', 'Early Diagnosis', 'Event', 'Exhibits', 'Face', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Research', 'Genetic Risk', 'Genetic screening method', 'Genetic study', 'Genotype', 'Goals', 'Hereditary Disease', 'Hippocampus (Brain)', 'Image', 'Individual', 'Joints', 'Late Onset Alzheimer Disease', 'Lead', 'Logistic Regressions', 'Machine Learning', 'Measurement', 'Mental disorders', 'Methods', 'Mining', 'Modeling', 'Motivation', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Probability', 'Process', 'Recruitment Activity', 'Research Personnel', 'Risk', 'Sample Size', 'Schizophrenia', 'Testing', 'Thick', 'Training', 'base', 'career', 'clinical Diagnosis', 'clinical phenotype', 'cognitive performance', 'computerized tools', 'data modeling', 'disorder risk', 'entorhinal cortex', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'high risk', 'image processing', 'improved', 'in vivo', 'interest', 'mild cognitive impairment', 'molecular pathology', 'neuroimaging', 'novel', 'outcome forecast', 'pre-clinical', 'programs', 'risk variant', 'tool']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,K25,2015,175392,-0.03483764794465721
"Genome engineering tools for functional screening of non-coding elements     DESCRIPTION (provided by applicant): A major goal since the completion of the Human Genome Project has been to understand all functional elements in the human genome and the role they play in normal biological processes and disease. To that end, large pooled libraries of RNA interference (RNAi) reagents have been developed for genome-wide loss-of-function screens but have been hindered by 3 problems: 1) the incompleteness of protein depletion inherent in partial knock-down; 2) off-target effects from the seed sequence; and 3) genetic elements that are not transcribed are inaccessible to manipulation. Genome engineering using precisely targeted nucleases has emerged as an innovative technology to modify the genome and causally interrogate the role of different functional elements. Recently, I developed a new technology for functional genomic screening using the RNA- guided CRISPR/Cas9 nuclease (Shalem*, Sanjana*, et al., Science, 2014). Since CRISPR works on the DNA level, it is possible to manipulate non-coding elements that are inaccessible to RNAi. The research goal of this proposal is to develop new biological tools and analysis techniques for functional annotation of non-coding elements using pooled CRISPR screens.  Mentored phase: First, I plan to develop and optimize high-throughput CRISPR non-coding mutagenesis libraries targeting introns, UTRs, promoters, non-coding RNAs, and intergenic regions to enable screening at high-resolution with megabase-scale coverage. Next, I will validate functional non-coding elements and use this large dataset to find unifying principles of how non-coding elements regulate gene expression. Independent phase: I plan to develop a novel CRISPR architecture for tiled deletion screens capable of deleting many segments over entire chromosomes or even entire genomes. With this technology and the increased screening throughput it enables, I will be able to develop a long-term independent research program in several possible directions, including further genome biology, personalized functional genomics, and predictive diagnostics for drug-genome interactions.  The two primary areas of training needed to help me succeed in my research goals are 1) CRISPR technology development (mentor: Dr. Feng Zhang) and 2) knowledge of human genetics and non-coding variation (mentor: Dr. David Altshuler). Each mentor is an established expert in these fields. My career development plan integrates additional laboratory training, specialized tutorials in human genetics from world experts, local and national presentations of my research, and courses in scientific writing, grantsmanship and job search strategies. To assist with science- and career-related decisions, I have assembled an Advisory Committee with a team of established, senior genomics experts: Drs. Eric Lander, Steven Hyman, and David Root. The Broad Institute is an ideal environment: All Mentors and Advisors are located in one building and there are facilities for high-throughput functional screening in th RNAi Platform (Director: Dr. Root).         PUBLIC HEALTH RELEVANCE: This project seeks to transform our understanding of the human genome by developing a new kind of functional assay capable of directly editing the genome and analyzing how this genome editing impacts the growth, development, and drug resistance of human cells. The remarkable feature of this assay is its high capacity, which can test thousands of genome variations in a single experiment. This research will also improve our understanding of which parts of the genome are essential to life and which parts of the genome might be responsible for the proliferation of cancer cells.                ",Genome engineering tools for functional screening of non-coding elements,8804084,K99HG008171,"['Advisory Committees', 'Antineoplastic Agents', 'Architecture', 'Area', 'Beryllium', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Process', 'Biology', 'Cells', 'Chromosomes', 'Chromosomes, Human, Pair 21', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Code', 'DNA', 'Data', 'Data Set', 'Development Plans', 'Diagnostic', 'Disease', 'Drug resistance', 'Elements', 'Environment', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic Variation', 'Genome', 'Genome engineering', 'Genomics', 'Genotype', 'Goals', 'Growth and Development function', 'Guide RNA', 'Human', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Indium', 'Institutes', 'Intercistronic Region', 'Introns', 'Knock-out', 'Knowledge', 'Laboratories', 'Libraries', 'Life', 'Machine Learning', 'Mentors', 'Modeling', 'Modification', 'Mutagenesis', 'Mutation', 'National Human Genome Research Institute', 'Nature', 'Occupations', 'Paper', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Plant Roots', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Proteins', 'RNA Interference', 'Reagent', 'Relative (related person)', 'Repetitive Sequence', 'Research', 'Resolution', 'Role', 'Science', 'Seeds', 'Stem cells', 'Subfamily lentivirinae', 'Techniques', 'Technology', 'Testing', 'Training', 'Untranslated RNA', 'Untranslated Regions', 'Variant', 'Work', 'Writing', 'cancer cell', 'career', 'career development', 'clinically relevant', 'deletion library', 'design', 'experience', 'functional genomics', 'genetic element', 'genome editing', 'genome-wide', 'improved', 'innovative technologies', 'insertion/deletion mutation', 'knock-down', 'loss of function', 'loss of function mutation', 'new technology', 'novel', 'nuclease', 'overexpression', 'programs', 'promoter', 'public health relevance', 'repaired', 'research study', 'scaffold', 'screening', 'small hairpin RNA', 'technology development', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",K99,2015,99937,-0.010643671940506002
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8840551,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'genetic variant', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,219004,-0.034809816632239934
"EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE ﻿    DESCRIPTION (provided by applicant): The eMERGE III Clinical Center proposal from Partners HealthCare leverages a large biobank, clinical data in the electronic medical records (EMR) for >4 million participants from the largest integrated health care provider in New England, advanced bioinformatics expertise and state-of-the-art genetic analysis. We propose three aims. (1) Aim 1. Discovery. We will test the hypothesis that common and rare variants from a custom chip including 50,000 loss of function (LoF) alleles will be associated with cardiovascular, neuropsychiatric and immune-mediated phenotypes derived from the EMR. We are currently genotyping 25,000 Partners HealthCare Biobank subjects with a custom chip that includes LoF alleles from 63,000 exomes that we have analyzed. (2) Aim 2. Penetrance and Pleiotropy. We will test the hypothesis that sequencing a set of established genes or loci will allow us to discover additional variation, and define penetrance and pleiotropy using EMR phenotypes. Rare variants in genes selected by the eMERGE network will be studied for penetrance and pleiotropic outcomes by PheWAS and chart review. In addition, we are poised to perform recall-by-genotype studies because all Biobank participants have provided consent for such callback. (3) Aim 3. Implementation. We will test the hypothesis that physicians will alter their surveillance and treatment of patients based upon voluntary return of actionable variants to provide safe and cost-effective benefits to patients. We will screen our entire Biobank population of 25,000 individuals for pathogenic variants in the LDLR gene, the leading genetic cause of premature coronary artery disease, and conduct an exploratory trial in disclosing this information. Biobank participants with pathogenic variants in LDLR will be offered enrollment into a randomized trial, in which their finding will be CLIA-confirmed, and in one arm, this result will be communicated to their physicians through the EMR. Over one year, we will collect the following outcomes through participant surveys and EMR queries: physician visits, laboratory testing, changes in medication prescriptions, LDL levels, medical costs and the number of family members screened and treated as a result of the intervention. We will collaborate with the entire eMERGE III Network to incorporate what we learn from this pilot trial into large-scale implementation protocols for the genes selected by the Network for sequencing. Finally, we will participate in all Network activities to enhance the movement of genetics into clinical practice.         PUBLIC HEALTH RELEVANCE: The discovery and clinical use of genetic variants associated with both rare Mendelian and more common complex diseases promises to dramatically change the practice of medicine. Our eMERGE III project will leverage a large Biobank and a rich electronic medical record to define the phenotypic impact of mutations emerging from sequencing and then return results on selected variants to Biobank participants using a clinical trial.                ",EMERGE PHASE III CLINICAL CENTER AT PARTNERS HEALTHCARE,8968123,U01HG008685,"['Algorithms', 'Alleles', 'Area', 'Asthma', 'Attention deficit hyperactivity disorder', 'Bioinformatics', 'Biology', 'Bipolar Disorder', 'CTLA4 gene', 'Callback', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Computerized Medical Record', 'Congestive Heart Failure', 'Consent', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Cost Effectiveness Analysis', 'Custom', 'DRD2 gene', 'Data', 'Disease', 'Enrollment', 'Family member', 'Funding', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'HLA-DRB1', 'Health Personnel', 'Healthcare', 'Immune', 'Individual', 'Inflammatory Bowel Diseases', 'Informatics', 'Intervention', 'LDL Cholesterol Lipoproteins', 'LDLR gene', 'Laboratories', 'Learning', 'Low-Density Lipoproteins', 'Machine Learning', 'Mediating', 'Medical', 'Medicine', 'Mental Depression', 'Mining', 'Movement', 'Multiple Sclerosis', 'Mutation', 'New England', 'Newborn Infant', 'Outcome', 'Participant', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Phenotype', 'Physicians', 'Population', 'Population Attributable Risks', 'Protocols documentation', 'Public Health', 'Research', 'Rheumatoid Arthritis', 'Schizophrenia', 'Source', 'Stream', 'Stroke', 'Surveys', 'TCF7L2 gene', 'TNFRSF1A gene', 'TYK2', 'Testing', 'Variant', 'Visit', 'arm', 'base', 'biobank', 'clinical care', 'clinical practice', 'clinical sequencing', 'clinically actionable', 'cost', 'cost effective', 'design', 'exome', 'exome sequencing', 'experience', 'genetic analysis', 'genetic information', 'genetic variant', 'hypercholesterolemia', 'implementation research', 'loss of function', 'neuropsychiatry', 'novel', 'pilot trial', 'pleiotropism', 'premature', 'public health relevance', 'randomized trial', 'rare variant', 'tool']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,U01,2015,972425,0.04641073535949764
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,8836569,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,2687363,0.0041650048410910795
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9132876,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,413294,0.0041650048410910795
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9133491,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,115911,0.0041650048410910795
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9117098,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'phenomenological models', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2015,194377,0.005450084718056185
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),9117098,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'phenomenological models', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2015,200000,0.005450084718056185
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),8929310,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'phenomenological models', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2015,2563635,0.005450084718056185
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),8929310,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Research Domain Criteria', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Untranslated RNA', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical investigation', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'phenomenological models', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2015,750000,0.005450084718056185
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8683213,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,221252,-0.00349683596145226
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8601147,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2014,989800,0.016360186341458693
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,8686917,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Association', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation sequencing', 'novel', 'prevent', 'public health relevance', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U01,2014,277488,0.006370329738487989
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,8738706,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Association', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic screening method', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Internet', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Methodology', 'Metric', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Professional counselor', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic variant', 'genome analysis', 'genome sequencing', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2014,2351999,0.055671522470836954
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics   Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8712451,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Massive Parallel Sequencing', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'genetic variant', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'screening', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2014,606168,0.033647712103883246
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8725717,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2014,2015775,0.007428793979583403
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations     DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease.              The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.            ",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8725211,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Bayesian Modeling', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2014,241086,0.03776379856897066
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.  The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects is ongoing. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We have created programs for calculating permutation p-values for the linkage results obtained when using propensity scores in LODPAL in the S.A.G.E. program package and have created programs that convert multipoint IBD sharing values calculated in SIMWALK2 so that they can be used by LODPAL in place of the IBD sharing calculated by the GENIBD program. The SIMWALK2 results are often more accurate than the approximations from GENIBD and calculation time is much faster. This year we have utilized propensity scores in IBDReg, have completed development of a program to compute empirical p-values and are applying these methods to Dr. Bailey-Wilson's prostate cancer data.  We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies, and have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. This year we have published a paper showing a method for estimating interaction effect sizes 1. We have developed a recurrency method in Random Forests that seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and are also applying this method to GAW18 data. Several manuscripts presenting this work are in preparation or submitted. We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets. This novel method was used in a recent applied analysis of oral cleft GWAS data and a paper is under review.  We have used the GAW17 simulated whole-exome sequence (WES) data to develop novel tools for analysis and interpretation of WES data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. This paper has been published for publication in BMC Proceedings (2014). Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data. In addition, this year we contributed to the development of an approach to analysis of very rare variants in WES/WGS data using exact probabilities 2 that was recently published in Bioinformatics. Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models. In collaboration with Dr. Ruzong Fan at NICHD, we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates Two papers were published presenting this work 3,4. We are now in the process of applying these approaches to several of our genome-wide datasets. n/a",Development of statistical genetics methodology,8948354,ZIAHG000153,"['African American', 'Bioinformatics', 'Biological Models', 'Caucasians', 'Caucasoid Race', 'Classification', 'Collaborations', 'Complex', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'Linear Models', 'Logistic Regressions', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Child Health and Human Development', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Process', 'Publications', 'Publishing', 'Running', 'Scheme', 'Sequence Analysis', 'Simulate', 'Solutions', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'Trees', 'Variant', 'Work', 'base', 'case control', 'data mining', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'genome-wide', 'improved', 'novel', 'oral cleft', 'programs', 'quality assurance', 'rare variant', 'simulation', 'tool', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2014,462019,0.025063421603693035
"Statistical and computational analysis in whole genome sequencing studies.     DESCRIPTION (provided by applicant): This project will investigate several issues arising from the statistical and computational analysis of whole genome sequencing (WGS) based genomics studies. In the area of data management in WGS studies, we address the rapidly increasing cost associated with the transfer and storage of the massive files for the sequence reads and their associated quality scores. We will develop data compression methods to achieve a further compression of several folds beyond current standards, with minimal incurred errors. In the area of secondary analysis, we will develop new statistical learning methods to improve variant quality score recalibration and to filter out unreliable calls. This will improve te reliability of the key information provided by the WGS data, which are the variants calls indicating the locations where the genome differs from the reference and the nature of the differences. We will study methods for case-control studies based on WGS. In particular, we will develop statistical models to enable the integrating of information from multiple types of variants to obtain more powerful tests of association. We will apply the methods developed in this aim to the analysis of WGS data from a study on abdominal aortic aneurysm. Finally, we will address selected new questions associated with population scale WGS projects. Several national programs have recently been initiated to generate WGS data for hundreds of thousands of individuals with longitudinal medical records. The availability of this comprehensive data on a population scale will open up a rich frontier for genome medicine and will pose many new challenges for statistical analysis. We will formulate some of these new challenges and develop the statistical methods needed to meet these challenges.         PUBLIC HEALTH RELEVANCE: The research in this project concerns the design and implementation of statistical and computational methods for the analysis of data from whole genome sequencing studies. Methods will be developed for sequence quality score compression, variant call filtering, and methods for case-control association analysis and mega-cohort analysis based on whole genome sequencing.                ",Statistical and computational analysis in whole genome sequencing studies.,8750827,R01HG007834,"['Abdominal Aortic Aneurysm', 'Address', 'Area', 'Case-Control Studies', 'Cohort Analysis', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Compression', 'Genome', 'Genomics', 'Goals', 'Individual', 'Location', 'Machine Learning', 'Medical Records', 'Medicine', 'Methods', 'Nature', 'Population', 'Reading', 'Research', 'Statistical Methods', 'Statistical Models', 'Testing', 'Variant', 'base', 'case control', 'computerized data processing', 'cost', 'data management', 'design', 'frontier', 'genome sequencing', 'improved', 'meetings', 'population based', 'programs', 'public health relevance']",NHGRI,STANFORD UNIVERSITY,R01,2014,300000,0.05332740445230103
"Decrypting Variants of Uncertain Significance in Long-QT Syndrome     DESCRIPTION (provided by applicant): Clinical genetic testing has become standard-of-care for many diseases including hundreds of inherited conditions. However, interpreting genetic test results is often confounded by the discovery of 'variants of unknown significance' (VUS) for which there is insufficient data or inadequate predictive tools to establish whether or not a particular variant predisposes to a disease. This problem is particularly vexing for genetic disorders with strong allelic heterogeneity and a preponderance of 'private' mutations such as the congenital long-QT syndrome (LQTS), which predisposes young adults and children to sudden death from cardiac arrhythmias. With the anticipated incorporation of personal exome or genome data into routine clinical care, interpreting VUS will become an even greater challenge especially when variants in genes associated with human disorders are incidentally discovered. Unfortunately, there are no reliable methods to predict a priori whether a given variant predisposes an individual to a particular disorder or whether the change is merely a benign rare variant. We propose to develop a novel paradigm for distinguishing disease-causing mutations from benign variants in LQTS as a model for other inherited arrhythmia syndromes and channelopathies. We will focus on variants in KCNQ1, the most commonly mutated gene in LQTS. The central hypothesis of this proposal is that a holistic predictive model that relates experimentally determined protein structure and dynamics to function and disease is highly accurate even for novel variants. Our ultimate objectives are to develop a data-trained, web-accessible algorithm that classifies VUS discovered in KCNQ1 based on reliable predictions of the structure and dynamics of the affected protein, and to achieve prediction accuracy to levels needed to inform medical decisions. The medical importance of correctly classifying KCNQ1 variants provides strong justification for having a dedicated and highly-tailored gene-specific prediction model. The ability to distinguish deleterious from neutral variants would help avoid unnecessary and potentially harmful interventions in carriers of benign alleles, and save the lives of those with true mutations. We propose to collect extensive electrophysiological, biochemical and structural data on a large set of KCNQ1 variants discovered in LQTS subjects as well as several suspected benign or neutral variants (Aims 1-2), then use these data to iteratively train and validate a machine learning based algorithm that can differentiate benign from deleterious KCNQ1 alleles among a set of new VUS (Aim 3). Our proposal is innovative in the use of a multidisciplinary approach to functionally and structurally annotate genomic variant data for a medically important gene at an unprecedented scale, and then to use these experimental findings to train/test a novel computational system to achieve clinical-grade predictions. Targeting KCNQ1 will also validate an approach for parallel work that can be utilized to predict the medical significance of variants in closely related potassium channels associated with heritable epilepsy (KCNQ2, KCNQ3) or deafness (KCNQ4).          PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a method to reliably predict the consequences of genetic variants of unknown significance discovered in the course of genetic testing in the congenital long-QT syndrome (LQTS), a cause of sudden cardiac death in children and young adults. We propose a multidisciplinary experimental approach including electrophysiology, biochemistry and structural biology deployed on a large scale to generate information on at least 110 genetic variants in the main gene responsible for LQTS (KCNQ1), which encodes a potassium channel required for normal electrical activity in the heart. Our final product will be a data-trained computational strategy that will outperform existing methods for accurately predicting the functional consequences of novel KCNQ1 genetic variants, enhance the value of genetic testing in LQTS and provide for more informed medical decisions.                ",Decrypting Variants of Uncertain Significance in Long-QT Syndrome,8786636,R01HL122010,"['Affect', 'Algorithms', 'Alleles', 'Anti-Arrhythmia Agents', 'Arrhythmia', 'Benign', 'Biochemical', 'Biochemistry', 'Biological', 'Cardiac', 'Caring', 'Cell surface', 'Child', 'Clinical', 'Computer Simulation', 'Data', 'Data Set', 'Defibrillators', 'Development', 'Disease', 'Electrophysiology (science)', 'Epilepsy', 'First Degree Relative', 'Genes', 'Genetic screening method', 'Genome', 'Genomics', 'Goals', 'Heart', 'Hereditary Disease', 'Heterogeneity', 'Human', 'Implant', 'Individual', 'Inherited', 'Intervention', 'Ion Channel', 'Link', 'Long QT Syndrome', 'Machine Learning', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Online Systems', 'Other Genetics', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Potassium Channel', 'Predisposition', 'Protein Dynamics', 'Proteins', 'Research Personnel', 'Resources', 'Structure', 'Sudden Death', 'Syndrome', 'System', 'Test Result', 'Testing', 'Therapeutic', 'Training', 'Variant', 'Work', 'base', 'clinical care', 'deafness', 'design', 'disease-causing mutation', 'exome', 'genetic variant', 'genome sequencing', 'heart rhythm', 'innovation', 'interdisciplinary approach', 'knowledge base', 'multidisciplinary', 'novel', 'predictive modeling', 'proband', 'protein function', 'protein structure', 'protein transport', 'public health relevance', 'rare variant', 'research study', 'structural biology', 'sudden cardiac death', 'tool', 'trafficking', 'web-accessible', 'young adult']",NHLBI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2014,1308724,0.027901898463696805
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,8737934,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Detection', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Site', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'design', 'genetic variant', 'genome sequencing', 'improved', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2014,2684060,0.028885365375899325
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8635216,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2014,51530,0.017722626892623418
"From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations     DESCRIPTION (provided by applicant): Genomic medicine offers hope for improved diagnostic methods and for more effective, patient-specific therapies. Genome-wide associated studies (GWAS) elucidate genetic markers that improve clinical understanding of risks and mechanisms for many diseases and conditions and that may ultimately guide diagnosis and therapy on a patient-specific basis. This project will expand on existing work to identify gene-phenotype associations across the genome and phenome, deploying new phenome-wide associations study (PheWAS) methods to deeply investigate electronic medical record (EMR)-derived phenotypes across common and rare variants across the genome. The project is enabled by large DNA biobanks coupled to de-identified copies of EMR. This project has three specific aims. First, we will expand the PheWAS phenotype library to include both binary traits and continuous variables incorporating about 7000 phenotypes derived from natural language processing, laboratory data, and report data. The second aim is to perform a PheWAS for common and rare variants using extant genome-wide and exome variant data and the broader set of phenotypes derived in Aim 1. We will analyze associations using single variant and multi-variant aggregation methods. We will validate the efficacy of our methods in Aim 2 by comparing to known associations. The third aim is to develop a standards-based infrastructure to share PheWAS results and develop tools to enable others to perform PheWAS. The tools generated from this project will not only expand the capabilities of the current PheWAS methodology, but will also broadly enable clinical research and subsequent genetic studies.             Project Narrative Genomic medicine offers hope for improved diagnosis and for more effective, patient- specific therapies. This PheWAS proposal will develop new methods to identify detailed phenotypes and diseases from electronic medical records and then find novel genetic associations from existing genomic data.",From GWAS to PheWAS: Scanning the EMR Phenome for Gene-disease Associations,8816305,R01LM010685,"['Address', 'Adopted', 'Architecture', 'Atrial Fibrillation', 'Biology', 'Body mass index', 'Cardiac', 'Cataloging', 'Catalogs', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'DNA Databases', 'Data', 'Data Reporting', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Disease Association', 'Documentation', 'Drug Exposure', 'Exclusion', 'Funding', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Health system', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Laboratories', 'Lead', 'Libraries', 'Link', 'Mainstreaming', 'Measures', 'Medicine', 'Methodology', 'Methods', 'National Human Genome Research Institute', 'Natural Language Processing', 'Nature', 'Obesity', 'Pathway interactions', 'Patients', 'Peer Review', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Rare Diseases', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Scanning', 'Single Nucleotide Polymorphism', 'Site', 'Solutions', 'Surveys', 'Testing', 'Variant', 'Work', 'base', 'biobank', 'cohort', 'disease phenotype', 'disorder subtype', 'endophenotype', 'exome', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'improved', 'next generation', 'novel', 'phenome', 'pleiotropism', 'rare variant', 'software development', 'tool', 'trait']",NLM,VANDERBILT UNIVERSITY,R01,2014,481897,0.04946401788744983
"Heterogeneous and Robust Survival Analysis in Genomic Studies     DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed.         PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.            ",Heterogeneous and Robust Survival Analysis in Genomic Studies,8696520,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Human', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Medicine', 'Methods', 'Modeling', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'hazard', 'improved', 'loss of function', 'novel', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'theories', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,255295,0.0024939869268235083
"Discovery and analysis of structural variation in whole genome sequences     DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities.         PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.            ",Discovery and analysis of structural variation in whole genome sequences,8733748,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Gene Mutation', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'improved', 'interest', 'markov model', 'public health relevance', 'rare variant', 'structural genomics', 'tool', 'virtual']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2014,374673,0.05141617580059473
"Developing Stats Methods to Detect Rare Genetics Variants in Human Complex Pedigrees We have developed pedigree-based rare variants analysis approach by treating each affected relatives as dependent pairs and the dependency will be accounted for using correlation matrix. This work led to two publications. We are now working on using a haplotype-based approach to identify causal variants for human diseases such as schizophrenia, bipolar and obsessive compulsive disorder. We have obtained the relevant data sets from dbGap which will allow us to compare the statistical properties (in an empirical sense) given by various types of analytical methods.  We have made contribution to a bipolar study in the Plain People in the Amish community, led by Dr. Francis McMahon (Chief, Human Genetics Branch, Intramural Research Program). n/a",Developing Stats Methods to Detect Rare Genetics Variants in Human Complex Pedigrees,8940009,ZIAMH002930,"['Accounting', 'Affect', 'Amish', 'Base Sequence', 'Code', 'Communities', 'Complex', 'Coupled', 'DNA', 'Data', 'Data Set', 'Dependency', 'Development', 'Disease', 'Disease model', 'Family', 'Genes', 'Genetic', 'Genomics', 'Haplotypes', 'Human', 'Human Genetics', 'Individual', 'Intramural Research Program', 'Literature', 'Machine Learning', 'Mental disorders', 'Methods', 'Modeling', 'Mutation', 'Obsessive-Compulsive Disorder', 'Phenotype', 'Population', 'Property', 'Publications', 'Relative (related person)', 'Research Design', 'Role', 'Schizophrenia', 'Scientist', 'Statistical Methods', 'Sum', 'Technology', 'Testing', 'Variant', 'Weight', 'Work', 'analytical method', 'base', 'database of Genotypes and Phenotypes', 'design', 'exome sequencing', 'genetic linkage analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome wide association study', 'human disease', 'interest', 'large scale simulation', 'next generation sequencing', 'novel', 'population based', 'rare variant', 'statistics', 'trait']",NIMH,NATIONAL INSTITUTE OF MENTAL HEALTH,ZIA,2014,398146,0.024449843256709305
"Data-Driven Statistical Learning with Applications to Genomics     DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software.         PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.            ",Data-Driven Statistical Learning with Applications to Genomics,8796068,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Drug Formulations', 'Enrollment', 'Equilibrium', 'Event', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Simulate', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'flexibility', 'high throughput analysis', 'interest', 'novel', 'patient population', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2014,361063,0.02690504125980334
"Data-Driven Statistical Learning with Applications to Genomics     DESCRIPTION (provided by applicant): This project involves the development of statistical and computational methods for the analysis of high throughput biological data. Effective methods for analyzing this data must balance two opposing ideals. They must be (a) flexible and sufficiently data-adaptive to deal with the data's complex structure, yet (b) sufficiently simpe and transparent to interpret their results and analyze their uncertainty (so as not to mislead with conviction). This is additionally challenging because these datasets are massive, so attacking these problems requires a marriage of statistical and computational ideas. This project develops frameworks for attacking several problems involving this biological data. These frameworks balance flexibility and simplicity and are computationally tractable even on massive datasets. This application has three specific aims. Aim 1: A flexible and computationally tractable framework for building predictive models. Commonly we are interested in modelling phenotypic traits of an individual using omics data. We would like to find a small subset of genetic features which are important in phenotype expression level. In this approach, I propose a method for flexibly modelling a response variable (e.g. phenotype) with a small, adaptively chosen subset of features, in a computationally scalable fashion. Aim 2: A framework for jointly identifying and testing regions which differ across conditions. For example, in the context of methylation data measured in normal and cancer tissue samples, one might expect that some regions are more methylated in one tissue type or the other. These regions might suggest targets for therapy. However, we do not have the background biological knowledge to pre-specify regions to test. I propose an approach which adaptively selects regions and then tests them in a principled way. This approach is based on a convex formulation to the problem, using shrinkage to achieve sparse differences. Aim 3: A principled framework for developing and evaluating predictive biomarkers during clinical trials. Modern treatments target specific genetic abnormalities that are generally present in only a subset of patients with a disease. A major current goal in medicine is to develop biomarkers that identify those patients likely to benefit from treatment. I propose a framework for developing and testing biomarkers during large-scale clinical trials. This framework simultaneously builds these biomarkers and applies them to restrict enrollment into the trial to only those likely to benefit from treatment. The statistical tools that result from th proposed research will be implemented in freely available software.         PUBLIC HEALTH RELEVANCE: Recent advances in high-throughput biotechnology have provided us with a wealth of new biological data, a large step towards unlocking the tantalizing promise of personalized medicine: the tailoring of treatment to the genetic makeup of each individual and disease. However, classical statistical and computational tools have proven unable to exploit the extensive information these new experimental technologies bring to bear. This project focuses on building new flexible, data-adaptive tools to translate this wealth of low level information into actionable discoveries, and actual biological understanding.            ",Data-Driven Statistical Learning with Applications to Genomics,8796068,DP5OD019820,"['Accounting', 'Address', 'Bayesian Modeling', 'Biological', 'Biological Markers', 'Biology', 'Biotechnology', 'Cancer Patient', 'Clinical Trials', 'Clinical Trials Design', 'Code', 'Complex', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Drug Formulations', 'Enrollment', 'Equilibrium', 'Event', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Measurement', 'Measures', 'Medicine', 'Memory', 'Methods', 'Methylation', 'Modeling', 'Molecular Abnormality', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Population', 'Proteomics', 'Reading', 'Research', 'Research Personnel', 'Science', 'Simulate', 'Single Nucleotide Polymorphism', 'Site', 'Somatic Mutation', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Telomerase', 'Testing', 'Time', 'Tissue Sample', 'Translating', 'Uncertainty', 'Update', 'Ursidae Family', 'Variant', 'Work', 'base', 'computerized tools', 'flexibility', 'high throughput analysis', 'interest', 'novel', 'patient population', 'predictive modeling', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'tool', 'trait', 'transcriptome sequencing']",OD,UNIVERSITY OF WASHINGTON,DP5,2014,1,0.02690504125980334
"Informatic Profiling of Clinically Relevant Mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic Profiling of Clinically Relevant Mutation,8722025,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome sequencing', 'genetic regulatory protein', 'genetic variant', 'genome annotation', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2014,114720,0.008010808593222854
"Mechanisms underlying complex trait human disease     DESCRIPTION (provided by applicant): There is now an explosion of new genome scale data relating genetic variation within the human population to phenotype, and particularly to common disease. Microarray technology has identified 100s of loci where the presence of particular variants is associated with altered risk of many common diseases; complete sequencing of individual exomes in cancer samples has discovered many somatic mutations in a variety of genes; and sequencing of 1000 human genomes has provided an almost complete inventory of common population variants. Further, these data are only the first in an ever-increasing flood, as even faster and cheaper sequencing technologies come on line. The results hold promise for major advances in treatment and diagnosis of common human diseases. Extracting the expected benefits is not straightforward, and will necessitate acquiring detailed knowledge of the mechanisms linking genetic variation to disease. This project focuses on one aspect of this challenge - using the new genomic data to identify new therapeutic opportunities. We will investigate those principles underlying complex trait disease that are particularly relevant to tha goal. We introduce a three stage mechanistic framework, relating genomic variation to the function of impacted gene products, the impact of these altered functions on pathways, processes and subsystems; and finally the consequences for complex trait disease phenotypes. We will develop computational methods to address key questions concerning three major aspects of the framework (1) How large are the changes in protein function brought about by the genomic variants underlying complex trait disease? What role do different classes of genomic and protein level mechanism, such as expression, non-synonymous changes and splicing, play in these variants? (2) How complete is the set genes with strong influence on the disease phenotypes discovered by current technologies, and how can missing genes be imputed from the genomic and network data? (3) What is the distribution of coupling between the activity of genes involved in disease mechanism and disease phenotypes? The results will deepen understanding of these aspects of complex disease, and provide a basis for identifying potential new drug targets from GWAS and other genomic studies.         PUBLIC HEALTH RELEVANCE: New technologies are now providing extensive information on human genetic variation associated with increased risk of a wide range of common human disease, such as Alzheimer's, diabetes, heart disease, and many cancers. These data hold the promise for the development of new therapies, and realizing those benefits requires the acquisition of complementary knowledge of the mechanisms that link genetic variation to disease risk. This project is focused on analysis of the relationship between genetic variation and common disease with the goal of identifying new therapeutic opportunities.                ",Mechanisms underlying complex trait human disease,8738688,R01GM104436,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Complex', 'Computing Methodologies', 'Coupled', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Drug Targeting', 'Equipment and supply inventories', 'Explosion', 'Floods', 'Frequencies', 'Future', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heart Diseases', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Information Networks', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microarray Analysis', 'Minor', 'Modeling', 'Molecular', 'Other Genetics', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Play', 'Population', 'Process', 'Proteins', 'RNA Splicing', 'Relative (related person)', 'Risk', 'Role', 'Sampling', 'Somatic Mutation', 'Staging', 'Technology', 'Therapeutic', 'Translations', 'Variant', 'Work', 'base', 'disease phenotype', 'disorder risk', 'exome', 'exome sequencing', 'gene function', 'genetic variant', 'genome sequencing', 'genome wide association study', 'human disease', 'improved', 'insight', 'new technology', 'novel therapeutics', 'protein function', 'public health relevance', 'rare variant', 'risk variant', 'therapeutic target', 'tool', 'trait']",NIGMS,"UNIV OF MARYLAND, COLLEGE PARK",R01,2014,288080,0.04032943719375217
"NHGRI PAGE Coordinating Center     DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE.         PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.                ",NHGRI PAGE Coordinating Center,8728994,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Metric', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2014,690507,0.02058656111228219
"Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies    DESCRIPTION (provided by applicant): Common mental disorders such as Alzheimer's disease and schizophrenia are largely heritable with complex genetic underpinnings. Large-scale genome-wide association studies that contrast DNA sequence data from patients and controls have recently identified novel genetic risk variants for these disorders. Nevertheless, the processes through which genotype increases risk are yet to be fully characterized.  Neuroimaging offers a richer picture of the underlying disease processes than a clinical diagnosis. Thus the joint analysis of neuroimaging and genetics data promises to advance our understanding of these processes. Today, neuroimaging genetics studies however face important challenges that obstruct progress: small sample sizes, modest effect sizes, and the extreme dimensionality of the data limit statistical power and thus our ability to explore the complex and subtle associations between genes, neuroanatomy and clinical decline. Currently, the prevalent approach in neuroimaging genetics is to concentrate the analysis on a small number of anatomic regions of interest and/or candidate genes and often ignore a large portion of the data. The core goal of the proposed project is to develop computational tools that will take full advantage of the richness in the datasets and facilitate the exploration of the multifaceted associations between genotype, neuroimaging measurements and clinical phenotype. The proposed project will use advanced multivariate pattern analysis methods such as support vector machines to compute image-based and genetic scores that reflect pathology. We will validate the tools based on their association with classical biomarkers of disease. Finally, we will develop a model that uses both imaging and genotype data to predict future clinical outcome. We expect these tools will enable progress along three directions relevant to complex mental disorders, e.g. late-onset Alzheimer's disease (AD): (1) confirming and characterizing risk genes, (2) identifying disease-specific anatomical alterations in healthy individuals, and (3) early diagnosis and prognosis. The project will (1) use three already-collected large-scale datasets to apply the developed tools to AD, (2) build on cutting-edge image processing algorithms that we have been developing, and (3) allow the candidate to receive further training in neuroanatomy, mental disorders and genetics, forming the foundation for his future career as an independent researcher.       n/a",Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies,8726983,K25EB013649,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Anatomy', 'Biological Markers', 'Brain', 'Candidate Disease Gene', 'Clinical', 'Clinical Trials', 'Cognitive', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Dementia', 'Development', 'Disease', 'Early Diagnosis', 'Event', 'Exhibits', 'Face', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Research', 'Genetic Risk', 'Genotype', 'Goals', 'Hereditary Disease', 'Hippocampus (Brain)', 'Image', 'Individual', 'Joints', 'Late Onset Alzheimer Disease', 'Lead', 'Logistic Regressions', 'Machine Learning', 'Measurement', 'Mental disorders', 'Methods', 'Mining', 'Modeling', 'Motivation', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Probability', 'Process', 'Recruitment Activity', 'Research Personnel', 'Risk', 'Sample Size', 'Schizophrenia', 'Testing', 'Thick', 'Training', 'base', 'career', 'clinical Diagnosis', 'clinical phenotype', 'computerized tools', 'data modeling', 'disorder risk', 'entorhinal cortex', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'high risk', 'image processing', 'improved', 'in vivo', 'interest', 'mild cognitive impairment', 'molecular pathology', 'neuroimaging', 'novel', 'outcome forecast', 'pre-clinical', 'programs', 'risk variant', 'tool']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,K25,2014,175392,-0.03483764794465721
"Enhanced Gene Identification in Complex Traits Using Kernel Machines     DESCRIPTION (provided by applicant):     Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5).         PUBLIC HEALTH RELEVANCE:     Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.            ",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8729618,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Pattern', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Simulate', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'next generation sequencing', 'novel', 'open source', 'population based', 'public health relevance', 'rare variant', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2014,343000,0.02202035580048733
"Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning  Detecting Genome-Wide Epistasis with Efficient Bayesian Network Learning Epistasis is the interaction between two or more genes to affect phenotype. It is now widely accepted that epistasis plays an important role in susceptibility to many common diseases. The advent of high-throughput technologies has enabled genome-wide association studies (GWAS or GWA studies). It is compelling that we be able to detect epistasis using GWAS data. However, so far GWA studies have mainly focused on the association of a single gene or loci with a disease. The crucial challenge to analyzing epistasis using GWAS data is finding a way to efficiently handle high-dimensional data sets. The only possible solution is to design efficient algorithms that allow us to find the most relevant epistasic relationships without doing an exhaustive investigation. To the Principal Investigator's knowledge, no current method can do this. This career award will investigate this problem. The specific aims are as follows: (Aim 1) develop and evaluate efficient Bayesian network-based methods for learning candidate genes associated with diseases from GWAS sets. Such genes would provide candidates for follow-up biological studies, (Aim 2) implement the methods in a pilot GWAS system for use by researchers when conducting a GWAS, (Aim 3) develop simulated genome-wide data sets and evaluate the pilot system using these data sets, and (Aim 4) conduct GWA studies concerning breast cancer and lung cancer. Aim 1 will be addressed by developing a succinct Bayesian network model representing epistasis, efficient algorithms which are tailored to investigating such models, integration of the algorithms into methods for learning epistasis, and using simulated datasets to test the effectiveness of the methods and compare their performance to other methods. Aim 2 will be met by implementing the methods in a pilot GWAS system. Aim 3 will be satisfied by developing synthetic data sets similar to those found in GWA studies, and using them to evaluate the system. Aim 4 will be achieved by conducting GWA studies concerning breast and lung cancer. By conducting these studies, we can (1) substantiate previous results concerning the genetic basis of these diseases; (2) possibly obtain interesting new findings pertaining to these diseases. The main hypothesis is that the proposed method will be an advance over existing methods in that it will make it computationally feasible to learn epistatic relationships from genome-wide data and it will therefore yield better discovery performance than existing methods.  Learning gene-gene interactions from genome-wide association studies (GWAS) data is an important and challenging task in genetic epidemiology. This project will develop and evaluate a pilot GWAS system for performing this task. Advances obtained in analyzing GWAS data sets could enable us to learn the genetic basis of many diseases and thereby substantially improve the quality of personalized patient care.",Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning,8628875,R00LM010822,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Award', 'BRCA1 gene', 'BRCA2 gene', 'Bayesian Modeling', 'Biological', 'Biological Neural Networks', 'Cancer-Predisposing Gene', 'Candidate Disease Gene', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Effectiveness', 'Family history of', 'GAB2 gene', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Programming', 'Germ-Line Mutation', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Network-based', 'Patient Care', 'Performance', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Regression Analysis', 'Research', 'Research Personnel', 'Role', 'Simulate', 'Site', 'Solutions', 'Statistical Methods', 'System', 'Testing', 'Woman', 'Work', 'base', 'cancer cell', 'career', 'combinatorial', 'computer based statistical methods', 'data mining', 'design', 'follow-up', 'forest', 'gene interaction', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high throughput technology', 'improved', 'interest', 'malignant breast neoplasm', 'meetings']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2014,204812,0.017490379327295014
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8642168,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,207764,-0.034809816632239934
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8640966,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2014,2699376,0.0041650048410910795
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8699810,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic DNA', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,641093,0.039981424442075975
"EMR Phenotype and Community Engaged Genomic Associations    DESCRIPTION (provided by applicant): The electronic medical record (EMR) can be leveraged for high throughput phenotyping of large numbers of patients for genomics research. As part of eMERGE-l, we used EMR-based algorithms to enable genome- wide association studies (GWAS) of several primary and network-wide phenotypes. The present application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. The Mayo eMERGE-ll cohort (n=6916) includes the 3769 eMERGE-l patients and an additional 3147 individuals, the majority (90%) genotyped on the same lllumina 660W platform. We will work with other eMERGE-ll sites to expand and validate the library of electronic phenotyping algorithms to enable GWAS of multiple phenotypes of interest. A major focus of our application is to translate recent GWAS findings to clinical practice. Our specific aims are: Specific aim 1. Conduct EMR-based GWAS to identify common genetic variants that influence a) inter-individual variation in cardiorespiratory fitness and response to statin medications and b) susceptibility to venous thromboembolism and colon polyps. Specific aim 2. Quantify genetic risk of a common 'complex' disease - coronary heart disease (CHD) - and an adverse drug response - statin myopathy. We will develop risk communication tools that convey the clinical and genetic components of risk to both patients and care providers. Specific aim 3. Develop informatics approaches to incorporate genomic data into the EMR, including links to clinical decision support. Specific aim 4. Conduct a randomized-clinical trial to investigate how patients respond to genetically informed CHD-risk. We will re-consent 150 eMERGE-l patients without CHD, communicate the results via a genetic counselor, and discuss in detail the implications of the testing relevant to disease risk. The effectiveness of the communication and the patients' comprehension of risk, their hopes and concerns, and planned changes in lifestyle will be assessed by surveys and interviews after the patient-counselor encounter. As part of our ongoing efforts in community consultation, we will establish a community advisory group specific to this project.       RELEVANCE (See instructions): The proposed application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. We will develop tools to incorporate genomic information in the EMR. In addition, we will investigate clinical, translational, and ethical aspects of genetic testing for complex diseases and assess the response of patients to genetic testing.              n/a",EMR Phenotype and Community Engaged Genomic Associations,8724540,U01HG006379,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Bioethics', 'Cardiology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Colonic Polyps', 'Communication', 'Communication Tools', 'Communities', 'Complex', 'Comprehension', 'Computerized Medical Record', 'Consent', 'Coronary heart disease', 'Data', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Dose', 'Drops', 'Drug usage', 'Early Diagnosis', 'Effectiveness', 'Electronic library', 'Empirical Research', 'Epidemiologist', 'Ethical Issues', 'Ethics', 'Future', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Informatics', 'Instruction', 'Interview', 'Knowledge', 'Laboratories', 'Libraries', 'Life Style', 'Link', 'Medicine', 'Methods', 'Myopathy', 'Natural Language Processing', 'Patient Care', 'Patients', 'Perception', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Predisposition', 'Preventive', 'Principal Investigator', 'Procedures', 'Professional counselor', 'Provider', 'Public Health', 'Publishing', 'Randomized Clinical Trials', 'Research', 'Research Infrastructure', 'Risk', 'Risk Factors', 'Scientist', 'Site', 'Staging', 'Surveys', 'Testing', 'Text', 'Thromboembolism', 'Translating', 'Variant', 'Venous', 'Work', 'adverse outcome', 'base', 'clinical practice', 'clinical risk', 'cohort', 'community consultation', 'cost', 'disorder risk', 'exome sequencing', 'experience', 'fitness', 'genetic risk assessment', 'genetic variant', 'genome wide association study', 'heart disease risk', 'interest', 'open source', 'point of care', 'repository', 'response', 'screening', 'tool']",NHGRI,MAYO CLINIC ROCHESTER,U01,2014,164026,0.024116369211643972
"EMR Phenotype and Community Engaged Genomic Associations    DESCRIPTION (provided by applicant): The electronic medical record (EMR) can be leveraged for high throughput phenotyping of large numbers of patients for genomics research. As part of eMERGE-l, we used EMR-based algorithms to enable genome- wide association studies (GWAS) of several primary and network-wide phenotypes. The present application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. The Mayo eMERGE-ll cohort (n=6916) includes the 3769 eMERGE-l patients and an additional 3147 individuals, the majority (90%) genotyped on the same lllumina 660W platform. We will work with other eMERGE-ll sites to expand and validate the library of electronic phenotyping algorithms to enable GWAS of multiple phenotypes of interest. A major focus of our application is to translate recent GWAS findings to clinical practice. Our specific aims are: Specific aim 1. Conduct EMR-based GWAS to identify common genetic variants that influence a) inter-individual variation in cardiorespiratory fitness and response to statin medications and b) susceptibility to venous thromboembolism and colon polyps. Specific aim 2. Quantify genetic risk of a common 'complex' disease - coronary heart disease (CHD) - and an adverse drug response - statin myopathy. We will develop risk communication tools that convey the clinical and genetic components of risk to both patients and care providers. Specific aim 3. Develop informatics approaches to incorporate genomic data into the EMR, including links to clinical decision support. Specific aim 4. Conduct a randomized-clinical trial to investigate how patients respond to genetically informed CHD-risk. We will re-consent 150 eMERGE-l patients without CHD, communicate the results via a genetic counselor, and discuss in detail the implications of the testing relevant to disease risk. The effectiveness of the communication and the patients' comprehension of risk, their hopes and concerns, and planned changes in lifestyle will be assessed by surveys and interviews after the patient-counselor encounter. As part of our ongoing efforts in community consultation, we will establish a community advisory group specific to this project.       RELEVANCE (See instructions): The proposed application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. We will develop tools to incorporate genomic information in the EMR. In addition, we will investigate clinical, translational, and ethical aspects of genetic testing for complex diseases and assess the response of patients to genetic testing.              n/a",EMR Phenotype and Community Engaged Genomic Associations,8724540,U01HG006379,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Bioethics', 'Cardiology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Colonic Polyps', 'Communication', 'Communication Tools', 'Communities', 'Complex', 'Comprehension', 'Computerized Medical Record', 'Consent', 'Coronary heart disease', 'Data', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Dose', 'Drops', 'Drug usage', 'Early Diagnosis', 'Effectiveness', 'Electronic library', 'Empirical Research', 'Epidemiologist', 'Ethical Issues', 'Ethics', 'Future', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Informatics', 'Instruction', 'Interview', 'Knowledge', 'Laboratories', 'Libraries', 'Life Style', 'Link', 'Medicine', 'Methods', 'Myopathy', 'Natural Language Processing', 'Patient Care', 'Patients', 'Perception', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Predisposition', 'Preventive', 'Principal Investigator', 'Procedures', 'Professional counselor', 'Provider', 'Public Health', 'Publishing', 'Randomized Clinical Trials', 'Research', 'Research Infrastructure', 'Risk', 'Risk Factors', 'Scientist', 'Site', 'Staging', 'Surveys', 'Testing', 'Text', 'Thromboembolism', 'Translating', 'Variant', 'Venous', 'Work', 'adverse outcome', 'base', 'clinical practice', 'clinical risk', 'cohort', 'community consultation', 'cost', 'disorder risk', 'exome sequencing', 'experience', 'fitness', 'genetic risk assessment', 'genetic variant', 'genome wide association study', 'heart disease risk', 'interest', 'open source', 'point of care', 'repository', 'response', 'screening', 'tool']",NHGRI,MAYO CLINIC ROCHESTER,U01,2014,982592,0.024116369211643972
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),8698507,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Clinical Trials', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Functional RNA', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2014,2625284,0.005450084718056185
"Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID)     DESCRIPTION (provided by applicant): As a result of the accelerated pace of development of technologies for characterizing the human genome, the rate-limiting step for large scale genomic investigation in clinical populations is now phenotyping. This is particularly the case for neuropsychiatric (NP) illness, where phenotypes are complex, biomarkers are lacking, and the primary cell types of interest are difficult to access directly. It has become apparent that both rare and common genetic variation contributes to disease risk and that this risk crosses traditional diagnostic boundaries in psychiatry. Taking advantage of a large, already-established NP biobank could dramatically accelerate progress toward understanding the cross-disorder mechanism of action of disease liability genes. This study proposes novel applications of emerging technologies in informatics and cellular neurobiology to eliminate this phenotyping bottleneck. In doing so, it will accelerate investigation of clinical and cellular phenotypes for understanding single and multilocus/polygenic associations. Aim 1: Adapt and expand one of the largest NP cellular biobanks by parsing electronic health records with gold-standard assessment of cognition and other RDoC phenotypes. Aim 2: Define the genome-wide multidimensional functional genomics (MFG) landscape in NP disease into which the transcriptomic signature (RNA-seq) of each induced neuron (IN) representing a clinically characterized individual is projected. The projection provides the mapping from molecular to phenotypic characterization and a directionality towards healthful/neurotypical states used in Aim 3. Aim 3: Develop a probabilistic model of gene expression dependencies that will predict which small molecular perturbations are likely to shift the IN transcriptomic signature in a healthful direction in the MFG and to then update the model based on measured perturbations in the MFG. Aim 4: Select patient samples to study in greater detail for epigenetic (DNA methylation, histone marks and RNA editing) and transcriptional control particularly with regard to activity dependent changes that have been implicated in many NP diseases. Aim 5: Here we assess just how well the clinical phenotypes are informed by the genome-wide characterizations and assess which is more robust.          PUBLIC HEALTH RELEVANCE: This study is designed to answer the question: can we use the fruits of the first phases of the human genome project to create a new and more robust scheme of classifying neuropsychiatric disease, one that is more reliable with regard to prognosis of these diseases, more insightful as to the biological aberration in each category and, therefore, more effective in treating the patient.                ",Neuropsychiatric Genome-Scale and RDOC Individualized Domains (N-GRID),8698507,P50MH106933,"['Agonist', 'Alcohol or Other Drugs use', 'Anxiety Disorders', 'Biological', 'Biological Markers', 'Categories', 'Cells', 'Cellular Neurobiology', 'Clinical', 'Clinical Trials', 'Code', 'Cognition', 'Cognitive', 'Complex', 'Computer Simulation', 'Consent Forms', 'DNA Methylation', 'DSM-IV', 'Dependency', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Emerging Technologies', 'Enrollment', 'Epigenetic Process', 'Equipment and supply inventories', 'Fibroblasts', 'Fruit', 'Functional RNA', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Healthcare Systems', 'Histones', 'Human Genome', 'Human Genome Project', 'Individual', 'Informatics', 'Investigation', 'Laboratories', 'Maps', 'Measurement', 'Measures', 'Methodology', 'Modeling', 'Molecular', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'Neurons', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Prosencephalon', 'Psychiatry', 'Public Domains', 'RNA', 'RNA Editing', 'RNA Splicing', 'Resources', 'Risk', 'Running', 'Sampling', 'Scheme', 'Small RNA', 'Statistical Models', 'Stress', 'Symptoms', 'Testing', 'Transcript', 'Transcriptional Regulation', 'Update', 'Visit', 'Vocabulary', 'base', 'biobank', 'cell type', 'clinical phenotype', 'clinically relevant', 'design', 'disorder risk', 'functional genomics', 'genome sequencing', 'genome-wide', 'high risk', 'induced pluripotent stem cell', 'insight', 'interest', 'neuropsychiatry', 'novel', 'outcome forecast', 'prognostic', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'technology development', 'transcriptome sequencing', 'transcriptomics']",NIMH,HARVARD MEDICAL SCHOOL,P50,2014,750000,0.005450084718056185
"Pharmacogenomics of serotonin-specific reuptake inhibitors     DESCRIPTION (provided by applicant): Neuropsychiatric disorders, such as depression, have not shown conclusive linkage or association study results. Today, an enormous portion of heritability for depression remains unexplained. Rather than reiterating studies attempting to identify genetic variants underlying depression pathophysiology, I propose a different approach of evaluating genetic variation in the safety and efficacy of the major class of antidepressants. I will identify patients with the quantitative and discrete phenotypes of serotonin-specific reuptake inhibitor (SSRI) response (as measured through the Patient's Health Questionnaire-9 pre- and post-SSRI treatment), and SSRI-associated serious side effects, such as abnormal bleeding and serotonin syndrome. After identification of these phenotypes from the electronic Medical Records and Genetic Epidemiology (eMERGE) consortium, I will perform a genome-wide association study (GWAS) on 50,109 subjects to identify candidate genes involved in SSRI pharmacology and then leverage overlapping exome sequence data to identify rare, potentially causative mutations. As many GWAS and rare variant studies suffer from a lack of functional validation (i.e., that the identified variant truly causes the phenotype), I will functionally valiate these identified rare mutations in the model organism Saccharomyces cerevisiae using a yeast growth-based assay as a direct measure of protein function. The P450 enzyme CYP3A4, which has been implicated in SSRI metabolism, will be used as a proof of concept for the yeast assay. Finally, I will then use this yeast growth assay to perform deep mutational scanning to create a pharmacogenomic map of all possible mutations and their effect on enzyme hydrolysis, thereby linking DNA sequence to protein function. This work will provide a unique resource for understanding SSRI pharmacology. Through completion of a GWAS on the pharmacogenomic phenotypes of SSRI response and separately, risk of SSRI-associated bleeding and serotonin syndrome, I will likely identify numerous candidate genes that may further inform on the metabolism, transport, and mechanism of action of SSRIs, thereby furthering basic science. Moreover, through functional validation and creation of a pharmacogenomic map with deep mutational scanning, I will create an invaluable resource for clinicians to interpret the likely efect of their patient's rare mutation. Through this project, I hope to further the effort to bring personalized, genomic medicine into clinical practice, to decrease the morbidity and mortality of depression, which is estimated by the Center for Disease Control to affect 1 in 10 adults in the U.S.          PUBLIC HEALTH RELEVANCE: Depression is affects 1 in 10 adults in the United States and is one of the leading causes of disability. Depression is primarily treated with serotonin-specific reuptake inhibitors (SSRIs). Understanding how mutations in genes affect SSRI response and risk of side effects forwards the implementation of personalized, genomic medicine into evidence-based clinical practice. This integration of genomic information will likely greatly decrease the morbidity of depression in the United States and globally.            ",Pharmacogenomics of serotonin-specific reuptake inhibitors,8841610,F31MH101905,"['Address', 'Adult', 'Adverse effects', 'Affect', 'Algorithms', 'American', 'Amino Acid Sequence', 'Animal Model', 'Antidepressive Agents', 'Basic Science', 'Bioinformatics', 'Biological Assay', 'Biology', 'CYP3A4 gene', 'Candidate Disease Gene', 'Centers for Disease Control and Prevention (U.S.)', 'Code', 'Complementary DNA', 'Computerized Medical Record', 'Cytochrome P450', 'DNA Sequence', 'Data', 'Development', 'Disease', 'Environment', 'Enzymes', 'Fellowship', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Growth', 'Health', 'Hemorrhage', 'Heritability', 'Human', 'Hydrolysis', 'ICD-9', 'Incidence', 'International', 'Knowledge', 'Laboratories', 'Link', 'Logistic Regressions', 'Maps', 'Measures', 'Medical', 'Medical Genetics', 'Medicine', 'Mental Depression', 'Metabolism', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Mutation', 'Natural Language Processing', 'Patients', 'Peptide Sequence Determination', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacology', 'Pharmacotherapy', 'Phenotype', 'Physicians', 'Play', 'Population', 'Proteins', 'Questionnaires', 'Regression Analysis', 'Resources', 'Risk', 'Role', 'Saccharomyces cerevisiae', 'Safety', 'Scanning', 'Scientist', 'Selective Serotonin Reuptake Inhibitor', 'Serotonin', 'Serotonin Syndrome', 'Site-Directed Mutagenesis', 'Testing', 'Training', 'Translating', 'United States', 'United States National Institutes of Health', 'Validation', 'Variant', 'Visit', 'Work', 'Yeasts', 'absorption', 'base', 'clinical phenotype', 'clinical practice', 'disability', 'disease classification', 'evidence base', 'exome sequencing', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'inhibitor/antagonist', 'mortality', 'mutant', 'neuropsychiatry', 'novel', 'protein function', 'public health relevance', 'rare variant', 'response', 'reuptake', 'skills']",NIMH,UNIVERSITY OF WASHINGTON,F31,2014,35141,0.015676401229715746
"From GWAS to PheWAS: Scanning the EMR phenome for gene-disease associations    DESCRIPTION (provided by applicant): Genomic medicine offers hope for improved diagnostic methods and for more effective, patient-specific therapies. Genome-wide associated studies (GWAS) elucidate genetic markers that improve understanding of risks and causes for many diseases, and may guide diagnosis and therapy on a patient-specific basis. This project will take another approach to identify gene-disease associations: perform ""reverse GWAS,"" or phenome- wide association study (PheWAS), to determine which phenotypes are associated with a given genotype. The project is enabled by a large DNA biobank coupled to a de- identified copy of the electronic medical record. This project has four specific aims. First, the project will develop and validate a standardized approach to extract disease phenotypes from EMR records, integrating national standard terminologies of clinical disorders and descriptors relating to treatment and diagnosis of each disease to create a sharable knowledge base. The project will use natural language processing, structured data queries, and heuristic and machine learning methods to accurately identify patients with each disease and corresponding controls. The second aim is to perform PheWAS analyses using existing genotype data. To validate the method, the project will use PheWAS to ""rediscover"" SNPs with known disease associations. The project will also investigate statistical methods for large-scale multiple hypothesis testing to discover novel phenotype associations. The third aim is to apply the PheWAS algorithms in four other sites with EMR-linked DNA biobanks and compare results. In the fourth aim, the project will validate novel phenotype-genotype associations discovered through PheWAS with new genotyping in a previously untested population. The tools generated from this project will not only make PheWAS possible, but will also broadly enable clinical research and subsequent genetic studies.           The promise of genomic medicine is to predict individuals' disease risk and treatment given their genetic information. This project will develop methods to identify diseases from electronic medical records and then find novel genetic associations from existing genomic data.",From GWAS to PheWAS: Scanning the EMR phenome for gene-disease associations,8528722,R01LM010685,"['Academic Medical Centers', 'Algorithms', 'Appointment', 'Blood specimen', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Clinical Trials', 'Clinical and Translational Science Awards', 'Code', 'Computerized Medical Record', 'Coupled', 'DNA', 'DNA Databases', 'Data', 'Data Element', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Disease Association', 'Enrollment', 'Expert Systems', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Genotype', 'Goals', 'Hand', 'Individual', 'Institution', 'Investigation', 'Joints', 'Laboratories', 'Letters', 'Link', 'Machine Learning', 'Manuals', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Records', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Scanning', 'Secure', 'Single Nucleotide Polymorphism', 'Site', 'Statistical Methods', 'Structure', 'Syndrome', 'Techniques', 'Terminology', 'Testing', 'Text', 'Time', 'United States National Institutes of Health', 'Update', 'Validation', 'analytical method', 'base', 'biobank', 'biomedical informatics', 'case control', 'cohort', 'disease phenotype', 'disorder risk', 'experience', 'genetic association', 'genome-wide', 'heuristics', 'improved', 'knowledge base', 'novel', 'novel strategies', 'patient population', 'phenome', 'phenomics', 'research clinical testing', 'tool', 'treatment response']",NLM,VANDERBILT UNIVERSITY,R01,2013,305913,0.036214385338776044
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8518436,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,220626,-0.00349683596145226
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8416349,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2013,964551,0.016360186341458693
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,8549925,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Association', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation sequencing', 'novel', 'prevent', 'public health relevance', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2013,54233,0.006370329738487989
"Clinically Relevant Genome Variation Database We propose to create the world's premier database of genetic variants relevant to clinical care (Clinically Relevant Genetic Variants Resource or CRVR). We will provide transparent data synthesis and consensus opinion on the clinical utility of a given genetic variant across a spectrum of genetic lesions including single nucleotide changes, small indels and structural variants. We will integrate with ClinVar, PharmGKB, and OMIM and draw upon NHGRI initiatives including the Genome Sequencing and Analysis and Mendelian Disorders Sequencing Centers, and the Clinical Sequencing Exploratory Research Centers. We will work closely with other CRVR sites and NHGRI funded initiatives to improve deposition of data from clinical laboratories. Our database will be built through three Aims. Aim 1 will engage and energize the clinical genomics community around CRVR efforts. We will partner with the other CRVR and U41 investigators in this activity as they will focus on engagement of professional societies, clinical testing laboratories, and the broader clinical genomics community to ensure creation of a CRVR resource that meets anticipated community needs including assembly of Disease-Specific and Mutation Type Working Groups (DSWGs and MTWGs) comprised of expert clinical geneticists and molecular diagnosticians to establish metrics for the initial classification of variants and integration of guidelines from professional organizations. Aim 2 will involve creation of a CRVR CoreDB resource through expert review of the existing literature, locus databases, and NHGRI initiatives. We will disseminate consensus findings on clinically relevant genetic variants and the clinical implications of these variants, with supporting evidence and documentation of the consensus process. Information will be aggregated using standard ontologies and advanced methodologies for handling heterogeneous data to create a Core Database (CoreDB). The consensus of expert review will be disseminated through a user-friendly web Portal (vetted by Genetic Counseling WG), web services for data mining, and consensus clinical guidelines to the appropriate clinical and research communities. The results will be organized by gene, variant, disease, pathway, and literature. Supporting evidence will also be curated and disseminated, and the resource will be updated continuously as new information accumulates. Aim 3 will involve deployment of machine-learning algorithms for semi- automatic identification of putative Clinically Relevant Variants (CRVs). We will undertake data mining of the clinical and epidemiological genetics literature and existing databases to identify putative clinically important variants. This will involve mining data from ClinVar, OMIM, CSER, and the Mendelian centers aggregated in Aim 2. The Working Groups formed in Aim 1 will establish criteria and oversee curators vetting variants. We will develop and optimize disease- and gene-specific machine learning algorithms to facilitate rapid classification of variants based on data provided by genetic testing services via ClinVar. We will integrate population-genetic data inferred from at least 25 reference populations from the 1000 Genomes Project and other large endeavors into our machine learning approaches so as to infer the global relevance of CRVs discovered here. PUBLIC HEALTH RELEVANCE: We propose to create a unified, public, and freely available database of genetic alterations relevant to clinical care. Our ultimate goal is to empower clinicians, genetic counselors, and patients to make informed decisions based on DNA testing. Because much of the information required for such decisions is scattered among public and private databases, we propose combining the medical literature, expert summary of millions of de- identified genetic tests, and results from current and past NIH-funded genetic studies into a single unified database.",Clinically Relevant Genome Variation Database,8574128,U01HG007436,"['Algorithms', 'American', 'Bioinformatics', 'Biological Assay', 'Cataloging', 'Catalogs', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Clinical Research', 'Collaborations', 'Communities', 'Consensus', 'DNA', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Disease', 'Disease Association', 'Disease Pathway', 'Documentation', 'Ensure', 'Epidemiology', 'Funding', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Population Study', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human Genetics', 'Internet', 'Knowledge', 'Laboratories', 'Lesion', 'Letters', 'Literature', 'Machine Learning', 'Medical', 'Medical Genetics', 'Medicine', 'Methodology', 'Metric', 'Molecular', 'Mutation', 'National Human Genome Research Institute', 'North Carolina', 'Nucleotides', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phase', 'Population', 'Population Genetics', 'Process', 'Professional Organizations', 'Professional counselor', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Societies', 'Test Result', 'Testing', 'Translating', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'base', 'clinical care', 'clinically relevant', 'college', 'data exchange', 'data mining', 'design', 'empowered', 'gene function', 'genetic variant', 'genome analysis', 'genome sequencing', 'improved', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research clinical testing', 'response', 'user-friendly', 'web services', 'working group']",NHGRI,STANFORD UNIVERSITY,U01,2013,1400000,0.055671522470836954
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics   Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8514562,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'Sequence Analysis', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'screening', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2013,588237,0.033647712103883246
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8722983,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,115680,0.007428793979583403
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8548395,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,1871839,0.007428793979583403
"Information Explorer: a Suite of Tools for Cross-study Genetic Loci Discovery    DESCRIPTION (provided by applicant): Databases such as dbGaP represent extremely valuable resources of data that have been assembled across multiple cohorts. The increasing development of cost-effective high-throughput genotyping and sequencing technologies are resulting in vast amounts of genetic data. While such databases were formed in order to archive and distribute the results of previously performed genetic association analyses, an increasing number of studies have provided de-identified individual-level genotypic and phenotypic data that are made available to outside researchers who have obtained the appropriate authorization. While the amount of data made available has increased dramatically in recent years, relatively little has been done in order to facilitate phenotype harmonization across studies. Many genetic epidemiologic studies of cardiovascular disease have multiple variables related to any given phenotype, resulting from different definitions and multiple measurements or subsets of data. A researcher searching such databases for the availability of phenotype and genotype combinations is confronted with a veritable mountain of variables to sift through. This often requires visiting multiple websites to gain additional information about variables that are listed on databases, and examination of data distributions to assess similarities across cohorts. While the naming strategy for genetic variants is largely standardized across studies (e.g. ""rs"" numbers for single nucleotide polymorphisms or SNPs), this is often not the case for phenotype variables. For a given study, there are often numerous versions of phenotypic variables. Researchers currently have to analyze and compare increasingly larger numbers of variables that have varying degrees of documentation associated with them to obtain the desired information. This is a time-consuming process that may still miss the most appropriate variables. Moreover, every researcher that wants to compare the same datasets often needs to start from scratch since there are no tools to share the phenotype comparison results. The availability of informatic tools to make phenotype mapping more efficient and improve its accuracy, along with intuitive phenotype query tools, would provide a major resource for researchers utilizing these databases. The tools we are proposing would allow researchers to (1) Quickly obtain the information needed to assess whether a specific study will be useful for the hypothesis of interest; (2) Exclude variables that do not meet research criteria; (3) Ascertain which studies have combinations of phenotype and genetic information of interest; and (4) More easily expand research questions beyond the most basic main-effects to more complex analyses such as gene-by-environment interactions and multivariate tests incorporating multiple phenotypes. The increased utility will also enable larger meta-analyses to be performed, as researchers will be able to more quickly hone in on outcomes, exclusionary variables and covariates of interest, leading to increased statistical power to detect genetic associations.        While the amount of genomic data (e.g., GWAS, sequencing, etc.) made available has increased dramatically in recent years, relatively little has been done in order to facilitate phenotype harmonization across studies. The tools we are proposing would allow researchers to quickly identify data sets of interest, expand research questions beyond the most basic main-effects to more complex analyses such as gene-by-environment interactions and multivariate test incorporating multiple phenotypes, and perform larger meta-analyses easily by honing in on outcomes, exclusionary variables and covariates of interest with increased statistical power to detect genetic associations.         ",Information Explorer: a Suite of Tools for Cross-study Genetic Loci Discovery,8733017,UH3HL108780,"['Archives', 'Artificial Intelligence', 'Authorization documentation', 'Bioinformatics', 'Biological', 'Blood', 'Cardiovascular Diseases', 'Classification', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Documentation', 'Epidemiologic Studies', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Genotype', 'Heart', 'Hereditary Disease', 'Human', 'Individual', 'Informatics', 'Information Retrieval', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Names', 'Online Systems', 'Outcome', 'Performance', 'Phenotype', 'Postdoctoral Fellow', 'Process', 'Research', 'Research Personnel', 'Resources', 'Single Nucleotide Polymorphism', 'Sleep', 'Solid', 'Source', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'Visit', 'Work', 'base', 'cohort', 'cost effective', 'data structure', 'database of Genotypes and Phenotypes', 'experience', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'graduate student', 'improved', 'interest', 'meetings', 'repository', 'scale up', 'software development', 'symposium', 'text searching', 'tool', 'trait', 'usability', 'web site']",NHLBI,UNIVERSITY OF SOUTHERN CALIFORNIA,UH3,2013,500000,0.028139437800961543
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations     DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease.              The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.            ",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8550119,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2013,232648,0.03776379856897066
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects is ongoing. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We have created programs for calculating permutation p-values for the linkage results obtained when using propensity scores in LODPAL in the S.A.G.E. program package and have created programs that convert multipoint IBD sharing values calculated in SIMWALK2 so that they can be used by LODPAL in place of the IBD sharing calculated by the GENIBD program. The SIMWALK2 results are often more accurate than the approximations from GENIBD and calculation time is much faster. This year we have utilized propensity scores in IBDReg, are developing a program to compute empirical p-values and are performing studies of its performance. We plan on applying these methods to Dr. Bailey-Wilson's lung cancer and prostate cancer data.   We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies, and have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We are currently pursuing several novel methods utilizing probability machines, synthetic variables and meta-analysis using Random Forests. We have developed a recurrency method in Random Forests that seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data. One manuscript is in revision and others are in preparation. We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets. This novel method is undergoing additional testing.   We have used the GAW17 simulated whole-exome sequence (WES) data to develop novel tools for analysis and interpretation of WES data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two papers presenting these results were published in late 2011. In particular we showed that family-based studies such as two point linkage analysis controlled false positive rates well and were more powerful than most methods that utilized the same number of unrelated individuals for detection of rare variants of large effect. We followed this up with a linkage study in the GAW18 to evaluate significance thresholds for linkage analysis in whole genome sequence data and found that false positive rates were less well controlled for WGS data than WES, suggesting that more stringent thresholds might be necessary. This paper has been accepted for publication in BMC Proceedings 1 . Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  We have recently completed development of a sequence data quality assurance pipeline, a visualization program to display regions where individuals share multiple rare variants, and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have developed programs to analyze runs of homozygosity data across different types of genotype and sequence data.   Given the limitations of the GAW simulated datasets, we have developed and tested our own simulation pipeline to simulate genome-wide association data with realistic haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations are allowing us to test and compare analysis methods across a wide array of biological models including complex trait models that include geneXgene and gene by environment interactions. To date, we have shown that Random Forests, Pinpoint and logistic regression all have similar good control of false positive rate under the null, and that under simple additive models of disease causation, these 3 methods have similar power to detect a small number of causal variants of small to moderate effect size. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives. Simulations are ongoing to compare additional methods and to test the methods using more complex biological models.  In collaboration with Dr. Qing Li in my section and Dr. Ingo Ruczinski at Johns Hopkins Bloomberg School of Public Health, an R program has been developed to simulate case-parent trio data for use in testing our ongoing development of methods for analyzing trio data.  Dr. Li in my section has also been developing a haplotype-based association method to analyze longitudinal data in collaboration with Dr. Kelly Benke at Johns Hopkins Bloomberg School of Public Health. n/a",Development of statistical genetics methodology,8750668,ZIAHG000153,"['African American', 'Biological Models', 'Caucasians', 'Caucasoid Race', 'Classification', 'Collaborations', 'Complex', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Etiology', 'European', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'Imagery', 'Individual', 'Logistic Regressions', 'Machine Learning', 'Malignant neoplasm of lung', 'Malignant neoplasm of prostate', 'Manuscripts', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Population', 'Preparation', 'Probability', 'Public Health Schools', 'Publications', 'Publishing', 'Running', 'Scheme', 'Sequence Analysis', 'Simulate', 'Solutions', 'Statistical Methods', 'Structure', 'Testing', 'Time', 'Trees', 'Variant', 'base', 'case control', 'data mining', 'exome', 'exome sequencing', 'flexibility', 'forest', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'improved', 'method development', 'novel', 'programs', 'quality assurance', 'simulation', 'tool', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2013,551144,0.02787097445867284
"Machine Learning Prediction of Cancer Susceptibility No abstract available  PROJECT NARRATIVE The technology to measure information about the human genome is advancing at a rapid pace. Despite these advance, the computational methods for analyzing the data have not kept pace. We will develop new computer algorithms and software that can be used to identify genetic biomarkers of common human diseases. We will then apply these new computational methods to identifying genetic biomarkers of bladder cancer in an epidemiological study from New Hampshire.",Machine Learning Prediction of Cancer Susceptibility,8528718,R01LM009012,"['Age', 'Algorithms', 'Architecture', 'Characteristics', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data Analyses', 'Detection', 'Development', 'Environmental Exposure', 'Epidemiologic Studies', 'Evaluation', 'Family', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Variation', 'Goals', 'Human Genome', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of urinary bladder', 'Measures', 'Methods', 'Modeling', 'Modification', 'New Hampshire', 'Predisposition', 'Research', 'Single Nucleotide Polymorphism', 'Susceptibility Gene', 'Technology', 'Testing', 'Validation', 'analytical method', 'base', 'cancer type', 'combinatorial', 'gene environment interaction', 'genome wide association study', 'genome-wide', 'heuristics', 'human disease', 'improved', 'novel', 'novel strategies', 'open source', 'population based', 'programs', 'statistics']",NLM,DARTMOUTH COLLEGE,R01,2013,339879,-0.01784061711807741
"An Integrative Analysis of Structural Variation for the 1000 Genomes Project DESCRIPTION (provided by applicant): Structural variation (SV), involving deletions, duplications, insertions and inversions of DNA segments, accounts for a large proportion of human genetic diversity. Comprehensive identification and analysis of these genetic variants will help us more fully elucidate the biology of their functional effects on human health and demography. Despite recent advances, the tools and data needed to comprehensively identify all types of SVs, genotype each variant, integrate and phase these variants remain lacking. Indeed, the data released from the early phases of the 1000 Genomes Project (1000GP) (1000 Genomes Project Consortium, 2010; 1000 Genomes Project Consortium, 2012) are biased primarily towards the detection of deletions within relatively unique regions of the genome. As a consortium, we propose to pool expertise from various research groups to provide an integrative analysis of SVs by combining rigorous computational algorithmic development with extensive experimental validation. The new algorithms we develop and the high confidence lists of SVs obtained will be rapidly made available as a public resource. n/a",An Integrative Analysis of Structural Variation for the 1000 Genomes Project,8589933,U41HG007497,"['Accounting', 'Algorithms', 'Alleles', 'Benchmarking', 'Biology', 'Chromosomes', 'Complement', 'Complex', 'Consensus', 'DNA', 'DNA Insertion Elements', 'Data', 'Demography', 'Detection', 'Development', 'Future', 'Gene Conversion', 'Genetic Variation', 'Genome', 'Genotype', 'Goals', 'Gold', 'Haplotypes', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Nucleotides', 'Phase', 'Population', 'Process', 'Reading', 'Repetitive Sequence', 'Research', 'Resolution', 'Resources', 'Sampling', 'Site', 'Statistical Models', 'Technology', 'Validation', 'Variant', 'base', 'design', 'genetic variant', 'genome sequencing', 'improved', 'method development', 'novel', 'research study', 'tool']",NHGRI,JACKSON LABORATORY,U41,2013,2766009,0.028885365375899325
"Advanced Methods In Statistical Genetics Statistical models for genetics data are often surprisingly challenging, and often require advanced and new statistical methods. Using probability machines on whole genome data is a recent invention, with the original research on probability machines appearing in Methods of Information in Medicine (September 2011). Our methods point to refined and personalized probability predictions using a wide range of biomarkers, medical information and whole genome data. The detection of childhood-onset schizophrenia using 800,000 snps using probability machines has error rates of 15% or less, and the list of predictive snps can be filtered down to a list of less than a few hundred. Other studies of psychiatric conditions (ADHD, bipolar) are also now underway using probability machines and personalized medicine, subject-specific predictions. n/a",Advanced Methods In Statistical Genetics,8746529,ZIACT000268,"['Accounting', 'Attention deficit hyperactivity disorder', 'Biological Markers', 'Biological Neural Networks', 'Books', 'Childhood', 'Classification', 'Clinical', 'Data', 'Data Set', 'Detection', 'Disease model', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Human', 'Human Genome', 'Logic', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Other Genetics', 'Outcome', 'Phenotype', 'Probability', 'Process', 'Research', 'Scheme', 'Schizophrenia', 'Signal Transduction', 'Statistical Methods', 'Statistical Models', 'Transcription Initiation Site', 'Universities', 'base', 'fly', 'forest', 'novel strategies', 'programs']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2013,85800,0.024672560843156333
"Human-Specific Gain and Loss of Function     DESCRIPTION (provided by applicant): The proposed research will seek to utilize population genetic data to distinguish regions of the human genome experiencing purifying selection from unconstrained genomic regions. Because genomic sequences subject to selective constraint perform functions beneficial to the organism, this work will reveal previously unknown functional regions of the human genome. In particular, since this approach does not rely on comparisons between humans and closely related species, it can uncover regions acquiring or losing selective constraint after humans split from other great apes. Regions acquiring function during this time period would represent an important class of recent human adaptations, and could reveal molecular changes responsible for uniquely human phenotypes. Beyond its evolutionary importance, this work would improve the functional annotation of the human genome, revealing functional regions that could result in harmful effects if disrupted, and that cannot be detected from comparative genomic techniques. In addition to revealing human-specific gains-of- function, the proposed project would allow for detection of losses-of-function occurring since the human- chimpanzee divergence. These events could also underlie important phenotypic changes in recent human evolution, as several known human-specific losses-of-function were adaptive. Even fitness-neutral losses of function are informative, as they may reveal differences in selective pressures allowing certain functions to be lost in humans but requiring them to be maintained in our relatives. Finally, the work proposed here will combine population genetic and phylogenetic data to reveal constrained regions with better accuracy than can be achieved by examining either of these types of data alone. This will result in further improvements to the functional annotation of the human genome, especially with respect to non-protein-coding functional regions that cannot be reliably detected by ab initio techniques.  Performing this research will improve the applicant's knowledge of population genetics and computational methods that can leverage polymorphism to draw inferences about the selective and functional importance of different genomic loci. Instruction from a sponsor and co-sponsor with expertise in both of these areas, as well as interaction with other faculty members and postdocs at the sponsor's institution, will be invaluable for improving the applicant's skills. This experience wil greatly enhance the applicant's chances of achieving his goal of succeeding as an independent scientist running a lab at a research university.         PUBLIC HEALTH RELEVANCE: In addition to its evolutionary significance, the proposed research will reveal previously unknown regions of the human genome that perform beneficial functions. Because disruptions of these regions would have harmful effects, these findings will allow for more complete analyses of the genetic basis of disease in humans.            ",Human-Specific Gain and Loss of Function,8457179,F32GM105231,"['Address', 'Area', 'Beryllium', 'Code', 'Computing Methodologies', 'Data', 'Detection', 'Disease', 'Elements', 'Event', 'Evolution', 'Explosion', 'Faculty', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Indium', 'Institution', 'Instruction', 'Knowledge', 'Machine Learning', 'Mammals', 'Methods', 'Molecular', 'Mutation', 'Organism', 'Pan Genus', 'Phenotype', 'Phylogenetic Analysis', 'Pongidae', 'Population', 'Population Genetics', 'Postdoctoral Fellow', 'Relative (related person)', 'Research', 'Role', 'Running', 'Scientist', 'Techniques', 'Time', 'Universities', 'Variant', 'Work', 'base', 'comparative genomics', 'driving force', 'experience', 'fitness', 'functional genomics', 'gain of function', 'genetic analysis', 'human population genetics', 'improved', 'loss of function', 'meetings', 'member', 'novel', 'pressure', 'public health relevance', 'skills']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",F32,2013,47114,0.017722626892623418
"Discovery and analysis of structural variation in whole genome sequences     DESCRIPTION (provided by applicant):     The whole genome sequencing of large cohorts of individuals is quickly becoming a common tool for researchers to investigate the genetic basis of many disease phenotypes. The primary goals are to discover the underlying genetic variation that cause or contribute to these diseases as well as to correctly identify these variants in a diagnostic setting. These differences typicall consist of single base changes (SNPs), but can also encompass larger, more complex chromosomal rearrangements in the form of structural variation (SV) which are much more difficult to detect even with modern sequencing technologies. A number of approaches have been published that have studied this problem, but even the largest scale endeavors have only focused on deletion events and reported a sensitivity of <70%. Complex chromosomal rearrangements are even less well studied. Thus, it is paramount that accurate methods are developed which can detect all types of SVs at high specificity from sequence data. This proposal aims to improve the overall ability of researchers to identify and analyze genetic variation from whole genome sequences. An important, and often overlooked, aspect of SV discovery is the fact that typical paired-end, read depth, and split read approaches will identify different sets of non-overlapping variants at varying degrees of accuracy. In Aim 1, we will develop a unified SV discovery algorithm that can incorporate all of these different sources of information in a probabilistic fashion. Such a method would be useful for research, in particular with the identification of rare variants, as well as clinical applications which require a great del of accuracy and have thus far been limited to older karyotyping and microarray approaches. This would identify the majority of structural variants, however there are many regions in genomic sequences which are complex in nature, defined as consisting of multiple neighboring or overlapping chromosomal rearrangements that are challenging to resolve with typical SV detection approaches. In Aim 2, we propose methods to resolve these complex regions and assess their frequency and impact. Furthermore, a crucial step in medical genetics is the comparison of identified genetic mutations to databases of known pathogenic and benign variants. This is currently problematic with SVs, as they have often been originally reported with varying degrees of breakpoint resolution that can hamper the correct assignment of the variant. This issue is compounded further in more complex regions with multiple breakpoints, for which simplistic comparison methods do not work well. In Aim 3, we will develop and implement a system that describes and utilizes variant profiles to identify whether an individual's sequence data contains a variant of interest. Overall, this project will advance our understanding of the human genome as well as provide tools for use in the general research and clinical communities.         PUBLIC HEALTH RELEVANCE:     The rearrangement of chromosomal material in the form of structural variation is directly responsible for many disease phenotypes, however our ability to detect and resolve these events from whole genome sequence data is currently limited. We propose a number of strategies for improving the detection and analysis of structural genomic variation between individuals and resolving their underlying structure and function. These approaches will have direct application to the clinical diagnosis of such events and the future of personalized genomics.            ",Discovery and analysis of structural variation in whole genome sequences,8528145,R01HG007068,"['Address', 'Algorithms', 'Alleles', 'Area', 'Benign', 'Chromosomal Rearrangement', 'Clinical', 'Communities', 'Complex', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Disease', 'Event', 'Frequencies', 'Future', 'Gene Mutation', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Individual', 'Inherited', 'Karyotype determination procedure', 'Length', 'Machine Learning', 'Medical', 'Medical Genetics', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Organism', 'Pathogenicity', 'Population', 'Publishing', 'Reading', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Scanning', 'Seeds', 'Source', 'Specificity', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Variant', 'Work', 'base', 'clinical Diagnosis', 'clinical application', 'cohort', 'direct application', 'disease phenotype', 'genetic variant', 'genome sequencing', 'improved', 'interest', 'markov model', 'public health relevance', 'structural genomics', 'tool', 'virtual']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2013,382699,0.05141617580059473
"Comparative Genomics Unit Research Bioinformatics Developments  The Comparative Genomics Unit continues to develop, maintain, and distribute several software tools for the analysis of DNA sequence data.  This year we released a new mutation detection program, Shimmer, which detects somatic single nucleotide and small indel variants using hypothesis testing with correction for multiple testing.  In addition to making this program publicly available on github, we have published a report in Bioinformatics detailing Shimmers algorithm and describing its sensitivity and specificity when run on simulated data and real sequence data from the melanoma cell line COLO-829 Hansen et al., 2013.  We also continue to update and maintain the publicly available code for our genotyping program, bam2mpg, along with its recently introduced MPV scoring option.    In other work on somatic variant detection, we have developed a new copy number variant (CNV) detection algorithm, bardCNV, which predicts copy number alterations from matched sequence datasets (e.g., from tumor and normal tissue from the same individual, or parental cell lines and their derived child cell lines).  Using machine learning, bardCNV trains on observed read depths and variant allele frequencies, then predicts overall cell ploidy and purity, as well as copy number state for one or both alleles in haploid or diploid regions, respectively.  This year, our group participated in the Cancer Genome Atlas (TCGA) projects Benchmark 4 exercise by submitting VCF files with single nucleotide, small indel, and copy number variant predictions using Shimmer, MPV, and bardCNV for the exercises two breast cancer cell lines.  Another project in its early stages in the Comparative Genomics Unit is the development of a general purpose CNV caller.  This new caller combines both read depth and allele frequency information provided by sequence data with a hidden Markov model, and will be suitable for case/control, population survey, and parent-child trios data, to detect both germline and de novo CNVs.  It can also improve SNV calling in duplicated regions.  In collaboration with members of Leslie Bieseckers research group, we are also investigating the reliability of currently available CNV detection software in a comparison study.  For phylogenetic analyses, we have developed a fast, scalable and flexible method called PartFinder, and applied it to a variety of multi-species comparative genomics datasets to show their various levels of phylogenetic incongruence Prasad et al., 2012. We found significant correlations of incongruence across the genomes of human-chimpanzee-gorilla relative to genomic features like GC content, conservation and SNP density.  Whole Exome Pipeline Developments  In collaboration with the NISC Bioinformatics group, the Mullikin group continues to develop its software pipeline for the analysis of next generation sequence from captured exomic DNA.  This year, the pipeline was amended to include in its output variant frequencies from NHLBIs GO exome project, as well as Polyphen2 predictions of variant functional impact.  In addition, variant reports now include filtering for various modes of Mendelian inheritance when applicable.  Collaborative Work  Our groups collaboration with Daphne Bell has contributed to the publication of two papers reporting increased somatic mutation rates in multiple genes in endometrial cancers Price et al., 2013, Le Gallo et al., 2012.  These studies involved the analysis of both Sanger and next-generation (Illumina) sequencing, as well as statistical analyses of study design and gene mutation rates.  We have worked with numerous collaborators on the application and interpretation of results from the NISC whole exome sequencing (WES) pipeline.  Together with Ben Solomon and others, we investigated how one can apply WES genomic analysis for newborn screening Solomon et al., 2012, and in another study we looked for differences between monozygotic twins that might explain their discordant features of VACTERL association Solomon et al., 2013.  In two separate WES studies, new disease-related gene mutations were found, one related to early onset of EMARDD Pierson et al., 2013 through the homozygous deletion of exon 7 in the MEGF10 gene and the other causing a congenital neutrophil defect syndrome caused by mutations in the VPS45 gene Vilboux et al., 2013.  In the field of common disease, we reviewed known secondary cardiac disease variants in an exome cohort for prevalence and return of results with recomendations for follow-up Ng et al., 2013.  Finally, we compared X chromosome exome capture versus X chromosome sorting followed by next generation sequencing to evaluate the efficacy of these two approaches Teer et al., 2013.  Comparative sequence analyses of species other than human resulted in five publications for this reporting period.  Three of these publications resulted from our prior efforts on assembly and variation detection of the cat genome, as we have reported in prior years.  A better understanding of the extent of linkage disequilibrium across domestic cat breeds is described here Alhaddad et al., 2013.  Using cat SNPs genotyped across many breeds identified the gene that gives the Cornish Rex its curly coat trait Gandolfi et al., 2013.  In addition, using SNP genotype array analysis, we identified the gene responsible for tabby pattern variation in domestic cats, as well as the rare king cheetah phenotype as mutation in the gene Taqpep, which helps to establish a periodic pre-pattern during skin development Kaelin et al., 2012.  Using traditional BAC sequencing and assembly of Sanger reads, we investigated the segmental duplication expansions in primates, showing the evolutionary dynamics of the LRRC37 gene family Giannuzzi et al., 2013.  And finally, using an array of technologies and sequencing methods, we looked at genetic diversity and population history across the great apes Prado-Martinez et al., 2013. n/a",Comparative Genomics Unit Research,8750687,ZIAHG200330,"['Algorithms', 'Alleles', 'Benchmarking', 'Bioinformatics', 'Breast Cancer Cell', 'Breeding', 'Cancer cell line', 'Cell Line', 'Cells', 'Cheetahs', 'Child', 'Code', 'Collaborations', 'Communities', 'Computer software', 'DNA', 'DNA Sequence Analysis', 'Daphne plant', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Diploidy', 'Disease', 'Endometrial Carcinoma', 'Exercise', 'Exons', 'Felis catus', 'Frequencies', 'Gene Family', 'Gene Frequency', 'Gene Mutation', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Gorilla gorilla', 'Guanine + Cytosine Composition', 'Haploidy', 'Heart Diseases', 'Human', 'Human Genome', 'Individual', 'Institutes', 'Linkage Disequilibrium', 'Machine Learning', 'Melanoma Cell', 'Methods', 'Monozygotic Twinning', 'Monozygotic twins', 'Mutation', 'Mutation Detection', 'National Human Genome Research Institute', 'Neonatal Screening', 'Normal tissue morphology', 'Nucleotides', 'Output', 'Pan Genus', 'Paper', 'Parents', 'Pattern', 'Performance', 'Phenotype', 'Phylogenetic Analysis', 'Play', 'Ploidies', 'Pongidae', 'Population', 'Prevalence', 'Primates', 'Publications', 'Publishing', 'Reading', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'SNP genotyping', 'Sensitivity and Specificity', 'Sequence Analysis', 'Simulate', 'Skin', 'Software Tools', 'Somatic Mutation', 'Sorting - Cell Movement', 'Staging', 'Syndrome', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Training', 'Tumor Tissue', 'United States National Institutes of Health', 'Update', 'Variant', 'Work', 'X Chromosome', 'case control', 'cat genome', 'cohort', 'comparative', 'comparative genomics', 'density', 'early onset', 'exome', 'exome sequencing', 'fascinate', 'flexibility', 'follow-up', 'improved', 'markov model', 'member', 'neutrophil', 'next generation', 'next generation sequencing', 'population survey', 'programs', 'tool', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2013,1327152,-0.004196272402395251
"Developing Stats Methods to Detect Rare Genetics Variants in Human Pedigrees We have developed pedigree-based rare variants analysis approach by treating each affected relatives as dependent pairs and the dependency will be accounted for using correlation matrix. This work led to two publications. We are now working on using a haplotype-based approach to identify causal variants for human diseases such as schizophrenia, bipolar and obsessive compulsive disorder. We have obtained the relevant data sets from dbGap which will allow us to compare the statistical properties (in an empirical sense) given by various types of analytical methods.  In the future, we will also make contribution to a bipolar study in the Plain People in the Amish community, led by Dr. Francis McMahon (Chief, Human Genetics Branch, Intramural Research Program). n/a",Developing Stats Methods to Detect Rare Genetics Variants in Human Pedigrees,8745754,ZIAMH002930,"['Accounting', 'Affect', 'Algorithms', 'Amish', 'Base Sequence', 'Code', 'Communities', 'Complex', 'Coupled', 'DNA', 'Data', 'Data Set', 'Dependency', 'Development', 'Disease', 'Disease model', 'Family', 'Future', 'Genes', 'Genetic', 'Genomics', 'Haplotypes', 'Human', 'Human Genetics', 'Individual', 'Intramural Research Program', 'Literature', 'Machine Learning', 'Mental disorders', 'Methods', 'Modeling', 'Mutation', 'Nasopharynx Carcinoma', 'Obsessive-Compulsive Disorder', 'Phenotype', 'Population', 'Property', 'Publications', 'Relative (related person)', 'Research Design', 'Role', 'Schizophrenia', 'Scientist', 'Sequence Analysis', 'Statistical Methods', 'Sum', 'Technology', 'Testing', 'Variant', 'Weight', 'Work', 'analytical method', 'base', 'database of Genotypes and Phenotypes', 'design', 'exome sequencing', 'family structure', 'genetic linkage analysis', 'genetic pedigree', 'genetic variant', 'genome sequencing', 'genome wide association study', 'human disease', 'interest', 'large scale simulation', 'next generation sequencing', 'novel', 'population based', 'statistics', 'trait']",NIMH,NATIONAL INSTITUTE OF MENTAL HEALTH,ZIA,2013,347588,0.023519902536078593
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8526549,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome sequencing', 'genetic regulatory protein', 'genetic variant', 'genome annotation', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2013,444076,0.008010808593222854
"Mechanisms underlying complex trait human disease     DESCRIPTION (provided by applicant): There is now an explosion of new genome scale data relating genetic variation within the human population to phenotype, and particularly to common disease. Microarray technology has identified 100s of loci where the presence of particular variants is associated with altered risk of many common diseases; complete sequencing of individual exomes in cancer samples has discovered many somatic mutations in a variety of genes; and sequencing of 1000 human genomes has provided an almost complete inventory of common population variants. Further, these data are only the first in an ever-increasing flood, as even faster and cheaper sequencing technologies come on line. The results hold promise for major advances in treatment and diagnosis of common human diseases. Extracting the expected benefits is not straightforward, and will necessitate acquiring detailed knowledge of the mechanisms linking genetic variation to disease. This project focuses on one aspect of this challenge - using the new genomic data to identify new therapeutic opportunities. We will investigate those principles underlying complex trait disease that are particularly relevant to tha goal. We introduce a three stage mechanistic framework, relating genomic variation to the function of impacted gene products, the impact of these altered functions on pathways, processes and subsystems; and finally the consequences for complex trait disease phenotypes. We will develop computational methods to address key questions concerning three major aspects of the framework (1) How large are the changes in protein function brought about by the genomic variants underlying complex trait disease? What role do different classes of genomic and protein level mechanism, such as expression, non-synonymous changes and splicing, play in these variants? (2) How complete is the set genes with strong influence on the disease phenotypes discovered by current technologies, and how can missing genes be imputed from the genomic and network data? (3) What is the distribution of coupling between the activity of genes involved in disease mechanism and disease phenotypes? The results will deepen understanding of these aspects of complex disease, and provide a basis for identifying potential new drug targets from GWAS and other genomic studies.         PUBLIC HEALTH RELEVANCE: New technologies are now providing extensive information on human genetic variation associated with increased risk of a wide range of common human disease, such as Alzheimer's, diabetes, heart disease, and many cancers. These data hold the promise for the development of new therapies, and realizing those benefits requires the acquisition of complementary knowledge of the mechanisms that link genetic variation to disease risk. This project is focused on analysis of the relationship between genetic variation and common disease with the goal of identifying new therapeutic opportunities.                ",Mechanisms underlying complex trait human disease,8431505,R01GM104436,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Complex', 'Computing Methodologies', 'Coupled', 'Coupling', 'Data', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Drug Targeting', 'Equipment and supply inventories', 'Explosion', 'Floods', 'Frequencies', 'Future', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heart Diseases', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Individual', 'Information Networks', 'Knowledge', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microarray Analysis', 'Minor', 'Modeling', 'Molecular', 'Other Genetics', 'Pathway Analysis', 'Pathway interactions', 'Phenotype', 'Play', 'Population', 'Process', 'Proteins', 'RNA Splicing', 'Relative (related person)', 'Risk', 'Role', 'Sampling', 'Somatic Mutation', 'Staging', 'Technology', 'Therapeutic', 'Translations', 'Variant', 'Work', 'base', 'disease phenotype', 'disorder risk', 'exome', 'exome sequencing', 'gene function', 'genetic variant', 'genome sequencing', 'genome wide association study', 'human disease', 'improved', 'insight', 'new technology', 'novel therapeutics', 'protein function', 'public health relevance', 'risk variant', 'therapeutic target', 'tool', 'trait']",NIGMS,"UNIV OF MARYLAND, COLLEGE PARK",R01,2013,278213,0.04032943719375217
"NHGRI PAGE Coordinating Center     DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE.         PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.                ",NHGRI PAGE Coordinating Center,8573120,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Metric', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2013,720000,0.02058656111228219
"Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies    DESCRIPTION (provided by applicant): Common mental disorders such as Alzheimer's disease and schizophrenia are largely heritable with complex genetic underpinnings. Large-scale genome-wide association studies that contrast DNA sequence data from patients and controls have recently identified novel genetic risk variants for these disorders. Nevertheless, the processes through which genotype increases risk are yet to be fully characterized.  Neuroimaging offers a richer picture of the underlying disease processes than a clinical diagnosis. Thus the joint analysis of neuroimaging and genetics data promises to advance our understanding of these processes. Today, neuroimaging genetics studies however face important challenges that obstruct progress: small sample sizes, modest effect sizes, and the extreme dimensionality of the data limit statistical power and thus our ability to explore the complex and subtle associations between genes, neuroanatomy and clinical decline. Currently, the prevalent approach in neuroimaging genetics is to concentrate the analysis on a small number of anatomic regions of interest and/or candidate genes and often ignore a large portion of the data. The core goal of the proposed project is to develop computational tools that will take full advantage of the richness in the datasets and facilitate the exploration of the multifaceted associations between genotype, neuroimaging measurements and clinical phenotype. The proposed project will use advanced multivariate pattern analysis methods such as support vector machines to compute image-based and genetic scores that reflect pathology. We will validate the tools based on their association with classical biomarkers of disease. Finally, we will develop a model that uses both imaging and genotype data to predict future clinical outcome. We expect these tools will enable progress along three directions relevant to complex mental disorders, e.g. late-onset Alzheimer's disease (AD): (1) confirming and characterizing risk genes, (2) identifying disease-specific anatomical alterations in healthy individuals, and (3) early diagnosis and prognosis. The project will (1) use three already-collected large-scale datasets to apply the developed tools to AD, (2) build on cutting-edge image processing algorithms that we have been developing, and (3) allow the candidate to receive further training in neuroanatomy, mental disorders and genetics, forming the foundation for his future career as an independent researcher.       n/a",Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies,8535152,K25EB013649,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Anatomy', 'Biological Markers', 'Brain', 'Candidate Disease Gene', 'Clinical', 'Clinical Trials', 'Cognitive', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Dementia', 'Development', 'Disease', 'Early Diagnosis', 'Event', 'Exhibits', 'Face', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Research', 'Genetic Risk', 'Genotype', 'Goals', 'Hereditary Disease', 'Hippocampus (Brain)', 'Image', 'Individual', 'Joints', 'Late Onset Alzheimer Disease', 'Lead', 'Logistic Regressions', 'Machine Learning', 'Measurement', 'Mental disorders', 'Methods', 'Mining', 'Modeling', 'Motivation', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Probability', 'Process', 'Recruitment Activity', 'Research Personnel', 'Risk', 'Sample Size', 'Schizophrenia', 'Testing', 'Thick', 'Training', 'base', 'career', 'clinical Diagnosis', 'clinical phenotype', 'computerized tools', 'data modeling', 'disorder risk', 'entorhinal cortex', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'high risk', 'image processing', 'improved', 'in vivo', 'interest', 'mild cognitive impairment', 'molecular pathology', 'neuroimaging', 'novel', 'outcome forecast', 'pre-clinical', 'programs', 'risk variant', 'tool']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,K25,2013,175392,-0.03483764794465721
"Enhanced Gene Identification in Complex Traits Using Kernel Machines DESCRIPTION (provided by applicant):  Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5). PUBLIC HEALTH RELEVANCE:  Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8598704,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Pattern', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Simulate', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'next generation sequencing', 'novel', 'open source', 'population based', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2013,350000,0.02202035580048733
"Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning  Detecting Genome-Wide Epistasis with Efficient Bayesian Network Learning Epistasis is the interaction between two or more genes to affect phenotype. It is now widely accepted that epistasis plays an important role in susceptibility to many common diseases. The advent of high-throughput technologies has enabled genome-wide association studies (GWAS or GWA studies). It is compelling that we be able to detect epistasis using GWAS data. However, so far GWA studies have mainly focused on the association of a single gene or loci with a disease. The crucial challenge to analyzing epistasis using GWAS data is finding a way to efficiently handle high-dimensional data sets. The only possible solution is to design efficient algorithms that allow us to find the most relevant epistasic relationships without doing an exhaustive investigation. To the Principal Investigator's knowledge, no current method can do this. This career award will investigate this problem. The specific aims are as follows: (Aim 1) develop and evaluate efficient Bayesian network-based methods for learning candidate genes associated with diseases from GWAS sets. Such genes would provide candidates for follow-up biological studies, (Aim 2) implement the methods in a pilot GWAS system for use by researchers when conducting a GWAS, (Aim 3) develop simulated genome-wide data sets and evaluate the pilot system using these data sets, and (Aim 4) conduct GWA studies concerning breast cancer and lung cancer. Aim 1 will be addressed by developing a succinct Bayesian network model representing epistasis, efficient algorithms which are tailored to investigating such models, integration of the algorithms into methods for learning epistasis, and using simulated datasets to test the effectiveness of the methods and compare their performance to other methods. Aim 2 will be met by implementing the methods in a pilot GWAS system. Aim 3 will be satisfied by developing synthetic data sets similar to those found in GWA studies, and using them to evaluate the system. Aim 4 will be achieved by conducting GWA studies concerning breast and lung cancer. By conducting these studies, we can (1) substantiate previous results concerning the genetic basis of these diseases; (2) possibly obtain interesting new findings pertaining to these diseases. The main hypothesis is that the proposed method will be an advance over existing methods in that it will make it computationally feasible to learn epistatic relationships from genome-wide data and it will therefore yield better discovery performance than existing methods.  Learning gene-gene interactions from genome-wide association studies (GWAS) data is an important and challenging task in genetic epidemiology. This project will develop and evaluate a pilot GWAS system for performing this task. Advances obtained in analyzing GWAS data sets could enable us to learn the genetic basis of many diseases and thereby substantially improve the quality of personalized patient care.",Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning,8440362,R00LM010822,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Award', 'BRCA1 gene', 'BRCA2 gene', 'Biological', 'Biological Neural Networks', 'Cancer-Predisposing Gene', 'Candidate Disease Gene', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Effectiveness', 'Family history of', 'GAB2 gene', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Programming', 'Germ-Line Mutation', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Network-based', 'Patient Care', 'Performance', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Regression Analysis', 'Research', 'Research Personnel', 'Role', 'Simulate', 'Site', 'Solutions', 'Statistical Methods', 'System', 'Testing', 'Woman', 'Work', 'base', 'cancer cell', 'career', 'combinatorial', 'computer based statistical methods', 'data mining', 'design', 'follow-up', 'forest', 'gene interaction', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high throughput technology', 'improved', 'interest', 'malignant breast neoplasm', 'meetings', 'network models']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2013,193848,0.017490379327295014
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8599826,R01CA180777,"['Bees', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,214832,-0.034809816632239934
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8447583,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2013,2703817,0.0041650048410910795
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.          Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8537965,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2013,624741,0.039981424442075975
"EMR Phenotype and Community Engaged Genomic Associations    DESCRIPTION (provided by applicant): The electronic medical record (EMR) can be leveraged for high throughput phenotyping of large numbers of patients for genomics research. As part of eMERGE-l, we used EMR-based algorithms to enable genome- wide association studies (GWAS) of several primary and network-wide phenotypes. The present application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. The Mayo eMERGE-ll cohort (n=6916) includes the 3769 eMERGE-l patients and an additional 3147 individuals, the majority (90%) genotyped on the same lllumina 660W platform. We will work with other eMERGE-ll sites to expand and validate the library of electronic phenotyping algorithms to enable GWAS of multiple phenotypes of interest. A major focus of our application is to translate recent GWAS findings to clinical practice. Our specific aims are: Specific aim 1. Conduct EMR-based GWAS to identify common genetic variants that influence a) inter-individual variation in cardiorespiratory fitness and response to statin medications and b) susceptibility to venous thromboembolism and colon polyps. Specific aim 2. Quantify genetic risk of a common 'complex' disease - coronary heart disease (CHD) - and an adverse drug response - statin myopathy. We will develop risk communication tools that convey the clinical and genetic components of risk to both patients and care providers. Specific aim 3. Develop informatics approaches to incorporate genomic data into the EMR, including links to clinical decision support. Specific aim 4. Conduct a randomized-clinical trial to investigate how patients respond to genetically informed CHD-risk. We will re-consent 150 eMERGE-l patients without CHD, communicate the results via a genetic counselor, and discuss in detail the implications of the testing relevant to disease risk. The effectiveness of the communication and the patients' comprehension of risk, their hopes and concerns, and planned changes in lifestyle will be assessed by surveys and interviews after the patient-counselor encounter. As part of our ongoing efforts in community consultation, we will establish a community advisory group specific to this project.       RELEVANCE (See instructions): The proposed application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. We will develop tools to incorporate genomic information in the EMR. In addition, we will investigate clinical, translational, and ethical aspects of genetic testing for complex diseases and assess the response of patients to genetic testing.              n/a",EMR Phenotype and Community Engaged Genomic Associations,8520368,U01HG006379,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Bioethics', 'Cardiology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Colonic Polyps', 'Communication', 'Communication Tools', 'Communities', 'Complex', 'Comprehension', 'Computerized Medical Record', 'Consent', 'Coronary heart disease', 'Data', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Dose', 'Drops', 'Drug usage', 'Early Diagnosis', 'Effectiveness', 'Electronic library', 'Empirical Research', 'Epidemiologist', 'Ethical Issues', 'Ethics', 'Future', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Informatics', 'Instruction', 'Interview', 'Knowledge', 'Laboratories', 'Libraries', 'Life Style', 'Link', 'Medicine', 'Methods', 'Myopathy', 'Natural Language Processing', 'Patient Care', 'Patients', 'Perception', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Predisposition', 'Preventive', 'Principal Investigator', 'Procedures', 'Professional counselor', 'Provider', 'Public Health', 'Publishing', 'Randomized Clinical Trials', 'Research', 'Research Infrastructure', 'Risk', 'Risk Factors', 'Scientist', 'Site', 'Staging', 'Surveys', 'Testing', 'Text', 'Thromboembolism', 'Translating', 'Variant', 'Venous', 'Work', 'adverse outcome', 'base', 'clinical practice', 'clinical risk', 'cohort', 'community consultation', 'cost', 'disorder risk', 'exome sequencing', 'experience', 'fitness', 'genetic risk assessment', 'genetic variant', 'genome wide association study', 'heart disease risk', 'interest', 'open source', 'point of care', 'repository', 'response', 'screening', 'tool']",NHGRI,MAYO CLINIC ROCHESTER,U01,2013,951710,0.024116369211643972
"EMR Phenotype and Community Engaged Genomic Associations    DESCRIPTION (provided by applicant): The electronic medical record (EMR) can be leveraged for high throughput phenotyping of large numbers of patients for genomics research. As part of eMERGE-l, we used EMR-based algorithms to enable genome- wide association studies (GWAS) of several primary and network-wide phenotypes. The present application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. The Mayo eMERGE-ll cohort (n=6916) includes the 3769 eMERGE-l patients and an additional 3147 individuals, the majority (90%) genotyped on the same lllumina 660W platform. We will work with other eMERGE-ll sites to expand and validate the library of electronic phenotyping algorithms to enable GWAS of multiple phenotypes of interest. A major focus of our application is to translate recent GWAS findings to clinical practice. Our specific aims are: Specific aim 1. Conduct EMR-based GWAS to identify common genetic variants that influence a) inter-individual variation in cardiorespiratory fitness and response to statin medications and b) susceptibility to venous thromboembolism and colon polyps. Specific aim 2. Quantify genetic risk of a common 'complex' disease - coronary heart disease (CHD) - and an adverse drug response - statin myopathy. We will develop risk communication tools that convey the clinical and genetic components of risk to both patients and care providers. Specific aim 3. Develop informatics approaches to incorporate genomic data into the EMR, including links to clinical decision support. Specific aim 4. Conduct a randomized-clinical trial to investigate how patients respond to genetically informed CHD-risk. We will re-consent 150 eMERGE-l patients without CHD, communicate the results via a genetic counselor, and discuss in detail the implications of the testing relevant to disease risk. The effectiveness of the communication and the patients' comprehension of risk, their hopes and concerns, and planned changes in lifestyle will be assessed by surveys and interviews after the patient-counselor encounter. As part of our ongoing efforts in community consultation, we will establish a community advisory group specific to this project.       RELEVANCE (See instructions): The proposed application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. We will develop tools to incorporate genomic information in the EMR. In addition, we will investigate clinical, translational, and ethical aspects of genetic testing for complex diseases and assess the response of patients to genetic testing.              n/a",EMR Phenotype and Community Engaged Genomic Associations,8729073,U01HG006379,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Bioethics', 'Cardiology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Colonic Polyps', 'Communication', 'Communication Tools', 'Communities', 'Complex', 'Comprehension', 'Computerized Medical Record', 'Consent', 'Coronary heart disease', 'Data', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Dose', 'Drops', 'Drug usage', 'Early Diagnosis', 'Effectiveness', 'Electronic library', 'Empirical Research', 'Epidemiologist', 'Ethical Issues', 'Ethics', 'Future', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Informatics', 'Instruction', 'Interview', 'Knowledge', 'Laboratories', 'Libraries', 'Life Style', 'Link', 'Medicine', 'Methods', 'Myopathy', 'Natural Language Processing', 'Patient Care', 'Patients', 'Perception', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Predisposition', 'Preventive', 'Principal Investigator', 'Procedures', 'Professional counselor', 'Provider', 'Public Health', 'Publishing', 'Randomized Clinical Trials', 'Research', 'Research Infrastructure', 'Risk', 'Risk Factors', 'Scientist', 'Site', 'Staging', 'Surveys', 'Testing', 'Text', 'Thromboembolism', 'Translating', 'Variant', 'Venous', 'Work', 'adverse outcome', 'base', 'clinical practice', 'clinical risk', 'cohort', 'community consultation', 'cost', 'disorder risk', 'exome sequencing', 'experience', 'fitness', 'genetic risk assessment', 'genetic variant', 'genome wide association study', 'heart disease risk', 'interest', 'open source', 'point of care', 'repository', 'response', 'screening', 'tool']",NHGRI,MAYO CLINIC ROCHESTER,U01,2013,168421,0.024116369211643972
"From GWAS to PheWAS: Scanning the EMR phenome for gene-disease associations    DESCRIPTION (provided by applicant): Genomic medicine offers hope for improved diagnostic methods and for more effective, patient-specific therapies. Genome-wide associated studies (GWAS) elucidate genetic markers that improve understanding of risks and causes for many diseases, and may guide diagnosis and therapy on a patient-specific basis. This project will take another approach to identify gene-disease associations: perform ""reverse GWAS,"" or phenome- wide association study (PheWAS), to determine which phenotypes are associated with a given genotype. The project is enabled by a large DNA biobank coupled to a de- identified copy of the electronic medical record. This project has four specific aims. First, the project will develop and validate a standardized approach to extract disease phenotypes from EMR records, integrating national standard terminologies of clinical disorders and descriptors relating to treatment and diagnosis of each disease to create a sharable knowledge base. The project will use natural language processing, structured data queries, and heuristic and machine learning methods to accurately identify patients with each disease and corresponding controls. The second aim is to perform PheWAS analyses using existing genotype data. To validate the method, the project will use PheWAS to ""rediscover"" SNPs with known disease associations. The project will also investigate statistical methods for large-scale multiple hypothesis testing to discover novel phenotype associations. The third aim is to apply the PheWAS algorithms in four other sites with EMR-linked DNA biobanks and compare results. In the fourth aim, the project will validate novel phenotype-genotype associations discovered through PheWAS with new genotyping in a previously untested population. The tools generated from this project will not only make PheWAS possible, but will also broadly enable clinical research and subsequent genetic studies.           The promise of genomic medicine is to predict individuals' disease risk and treatment given their genetic information. This project will develop methods to identify diseases from electronic medical records and then find novel genetic associations from existing genomic data.",From GWAS to PheWAS: Scanning the EMR phenome for gene-disease associations,8326646,R01LM010685,"['Academic Medical Centers', 'Algorithms', 'Appointment', 'Blood specimen', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Clinical Trials', 'Clinical and Translational Science Awards', 'Code', 'Computerized Medical Record', 'Coupled', 'DNA', 'DNA Databases', 'Data', 'Data Element', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Disease Association', 'Enrollment', 'Expert Systems', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Genotype', 'Goals', 'Hand', 'Individual', 'Institution', 'Investigation', 'Joints', 'Laboratories', 'Letters', 'Link', 'Machine Learning', 'Manuals', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Records', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Scanning', 'Secure', 'Single Nucleotide Polymorphism', 'Site', 'Statistical Methods', 'Structure', 'Syndrome', 'Techniques', 'Terminology', 'Testing', 'Text', 'Time', 'United States National Institutes of Health', 'Update', 'Validation', 'analytical method', 'base', 'biobank', 'biomedical informatics', 'case control', 'cohort', 'disease phenotype', 'disorder risk', 'experience', 'genetic association', 'genome-wide', 'heuristics', 'improved', 'knowledge base', 'novel', 'novel strategies', 'patient population', 'phenome', 'phenomics', 'research clinical testing', 'tool', 'treatment response']",NLM,VANDERBILT UNIVERSITY,R01,2012,332514,0.036214385338776044
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.        PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.              DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8350385,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Base Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'RNA', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'tool', 'transcription factor', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2012,220000,-0.0006256794643095473
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.      PUBLIC HEALTH RELEVANCE: The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.              The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8237596,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Delivery Systems', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2012,1010000,0.02278657934241959
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8494858,U01HG004695,"['Address', 'Algorithms', 'Area', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Hypersensitivity', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'RNA', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2012,371054,0.020214231990030935
"Accelerating Curation of GWAS Catalog by Automatic Text Mining     DESCRIPTION (provided by applicant): A genome-wide association study (GWAS) is an approach to detecting genetic variations associated with particular diseases or traits by scanning markers across the genomes of a large-scale sample of subjects in a high-throughput manner. In less than a decade, GWAS studies have been successfully producing discovery and replication of many new disease loci. Discovered genetic associations have led to development of better strategies to diagnose, treat and prevent diseases. The number of GWAS is growing rapidly. There is a need for a database that allows researchers to easily query and search for previous results. A well-curated database also provides a resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes. Such a database has been created and maintained by the National Human Genome Research Institute (NHGRI), called ""A Catalog of Published Genome-Wide Association Studies"" (Catalog of GWAS). The catalog has led to interesting characterization of previous results in GWAS and NHGRI has continued to update and curate the catalog regularly. However, this is performed by manually extracting information from published GWAS articles. As a result, the coverage is low compared to the volume of all GWAS publications and would be impossible to catch up the pace of new publications. The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. Our proposal is to use the curated data currently available from NHGRI as the training examples and apply novel machine-learning algorithms to train an information extractor to allow accurate automatic extraction. Given our recent success in applying machine learning to biological text mining, we are confident that this will lead to a useful tool to improve the productivity of curators and solve the coverage problem. Our first specific aim is to develop an accurate information extractor. Our second specific aim is to develop an easy-to-use curation tool for curators to efficiently check and correct errors from automatic information extraction so that their curation productivity can be improved by 18 folds. Then we will adapt the tool to extraction and curation of research papers reporting association studies using data from next generation sequencing. Currently, study design and the reporting of GWAS results using NGS data are not standardized. These results have not been considered to be included in the catalog yet. However, we expect that the limitations will be overcome and the methodology will converge soon. We will closely monitor the progress and adapt the tool to allow for inclusion of the NGS data. Finally, we will distribute the software to the public domain so that volunteers or interested parties can create their own catalog locally. It is our goal to share the developed software with the research community to advance the field. The new algorithms developed in this project and the entire development cycle, from design to deployment, will also contribute to the state-of-the- arts of biological text mining.        PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.              The goal of this project is to develop a new tool to automatically extract the information from research articles for the curation of the catalog of GWAS. The catalog contains information about SNP-trait/disease associations that are extracted from published genome-wide association studies. A well-curated catalog of GWAS allows researchers to easily query and search for previous results and provides a useful resource for overview and summarization investigations of associated genetic sites and may help suggest pleiotropic genes.            ",Accelerating Curation of GWAS Catalog by Automatic Text Mining,8348769,U01HG006894,"['Algorithms', 'Area', 'Biological', 'Cataloging', 'Catalogs', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Association', 'Ensure', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human Genetics', 'Investigation', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Methodology', 'Monitor', 'National Human Genome Research Institute', 'Paper', 'Productivity', 'Public Domains', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Site', 'Standardization', 'Surveys', 'Technology', 'Text', 'Training', 'Update', 'Workload', 'base', 'design', 'genetic association', 'genome wide association study', 'improved', 'interest', 'next generation', 'novel', 'prevent', 'software development', 'success', 'text searching', 'tool', 'trait', 'user-friendly', 'volunteer']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2012,247879,0.010992540223256703
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics   Project Summary  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8336850,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Screening procedure', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'Sequence Analysis', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2012,637782,0.033647712103883246
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8402447,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Set', 'Development', 'Disease', 'Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2012,2460045,0.007428793979583403
"Information Explorer: a Suite of Tools for Cross-study Genetic Loci Discovery    DESCRIPTION (provided by applicant): Databases such as dbGaP represent extremely valuable resources of data that have been assembled across multiple cohorts. The increasing development of cost-effective high-throughput genotyping and sequencing technologies are resulting in vast amounts of genetic data. While such databases were formed in order to archive and distribute the results of previously performed genetic association analyses, an increasing number of studies have provided de-identified individual-level genotypic and phenotypic data that are made available to outside researchers who have obtained the appropriate authorization. While the amount of data made available has increased dramatically in recent years, relatively little has been done in order to facilitate phenotype harmonization across studies. Many genetic epidemiologic studies of cardiovascular disease have multiple variables related to any given phenotype, resulting from different definitions and multiple measurements or subsets of data. A researcher searching such databases for the availability of phenotype and genotype combinations is confronted with a veritable mountain of variables to sift through. This often requires visiting multiple websites to gain additional information about variables that are listed on databases, and examination of data distributions to assess similarities across cohorts. While the naming strategy for genetic variants is largely standardized across studies (e.g. ""rs"" numbers for single nucleotide polymorphisms or SNPs), this is often not the case for phenotype variables. For a given study, there are often numerous versions of phenotypic variables. Researchers currently have to analyze and compare increasingly larger numbers of variables that have varying degrees of documentation associated with them to obtain the desired information. This is a time-consuming process that may still miss the most appropriate variables. Moreover, every researcher that wants to compare the same datasets often needs to start from scratch since there are no tools to share the phenotype comparison results. The availability of informatic tools to make phenotype mapping more efficient and improve its accuracy, along with intuitive phenotype query tools, would provide a major resource for researchers utilizing these databases. The tools we are proposing would allow researchers to (1) Quickly obtain the information needed to assess whether a specific study will be useful for the hypothesis of interest; (2) Exclude variables that do not meet research criteria; (3) Ascertain which studies have combinations of phenotype and genetic information of interest; and (4) More easily expand research questions beyond the most basic main-effects to more complex analyses such as gene-by-environment interactions and multivariate tests incorporating multiple phenotypes. The increased utility will also enable larger meta-analyses to be performed, as researchers will be able to more quickly hone in on outcomes, exclusionary variables and covariates of interest, leading to increased statistical power to detect genetic associations.        While the amount of genomic data (e.g., GWAS, sequencing, etc.) made available has increased dramatically in recent years, relatively little has been done in order to facilitate phenotype harmonization across studies. The tools we are proposing would allow researchers to quickly identify data sets of interest, expand research questions beyond the most basic main-effects to more complex analyses such as gene-by-environment interactions and multivariate test incorporating multiple phenotypes, and perform larger meta-analyses easily by honing in on outcomes, exclusionary variables and covariates of interest with increased statistical power to detect genetic associations.         ",Information Explorer: a Suite of Tools for Cross-study Genetic Loci Discovery,8303362,UH2HL108780,"['Archives', 'Artificial Intelligence', 'Authorization documentation', 'Bioinformatics', 'Biological', 'Blood', 'Cardiovascular Diseases', 'Classification', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Documentation', 'Epidemiologic Studies', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Genotype', 'Heart', 'Hereditary Disease', 'Human', 'Individual', 'Informatics', 'Information Retrieval', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Names', 'Online Systems', 'Outcome', 'Performance', 'Phenotype', 'Postdoctoral Fellow', 'Process', 'Research', 'Research Personnel', 'Resources', 'Single Nucleotide Polymorphism', 'Sleep', 'Solid', 'Source', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'Visit', 'Work', 'base', 'cohort', 'cost effective', 'data structure', 'database of Genotypes and Phenotypes', 'experience', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'graduate student', 'improved', 'interest', 'meetings', 'repository', 'scale up', 'software development', 'symposium', 'text searching', 'tool', 'trait', 'usability', 'web site']",NHLBI,UNIVERSITY OF SOUTHERN CALIFORNIA,UH2,2012,440305,0.028139437800961543
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8228154,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'ChIP-seq', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,323572,-0.013382918288155563
"Statistical Modeling of Complex Traits in Genetic Reference Super-Populations     DESCRIPTION (provided by applicant):     Genetic crosses in model organisms play an essential role in understanding the heritable architecture of medically relevant phenotypes. Traditionally, such crosses have tended to be on a small scale with either limited power to detect genetic effects or limited resolution to localize causal variants. Recently, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, have spurred the development of more sophisticated and powerful experimental designs. Genetic Resource Populations (GRPs) use economies of scale to provide cost-effective and replicable platforms for genetic studies. This project concerns the largest, most ambitious GRP in mouse genetics to date, the Collaborative Cross (CC), and a series of crosses and designs related to or derived from it: the Diversity Outbred (DO) cross, the CC Recombinant Inbred Cross (CC-RIX) and the diallel. Experiments on each separate cross provide distinct information about the heritable architecture of a target complex disease. In combination, this Genetic Reference Super-Population (GRSP) potentially provides an unparalleled basis for cross-study replication and integration in mouse genetics. This project aims to develop statistical methods that advance the current state of complex trait analysis of these populations separately, and, by exploiting the unique structure that connects them, proposes to develop a statistical framework that allows for their joint use.  Aim 1 develops a Bayesian probabilistic framework for haplotype-based analysis of quantitative trait loci (QTL). Aim 1a develops a statistical software module for flexible haplotype-based analysis, which can be ex- tended by the researcher to model a rich variety of designs and disease types. Aim 1b will adapt machine learning techniques to provide posterior inference of the allelic series of a QTL. Aim 1c will incorporate Bayesian modeling of polygenic effects.  Aim 2 and 3 concern joint analysis, building on the foundation set by Aim 1. Aim 2 develops methods to optimize experimental design of follow-up studies in one population given results from another. Aim 2a uses the diallel to inform design of CC/CC-RIX/DO experiments. Aim 2b uses partial data on CC/CC-RIX/DO to guide collection of additional data. Aim 3 explores models for jointly analyzing multiple populations in the GRSP, using complementary datasets to stabilize analysis at single QTL (Aim 3a) and across multiple QTL (Aim 3b).  These aims address specific and persistent challenges in the cost-effective design and efficient analysis of multiparent genetic data, in particular the CC, DO, CC-RIX and diallel. The project will generate tools useful for a wide range of model organism crosses and can be applied to the genetic study of any complex disease.        PUBLIC HEALTH RELEVANCE:     The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.                  The proposed research will lead to improvements in the analysis and design of genetic studies on animal models of human disease. Because the project focuses on statistical methodology applied to experimental mouse populations, the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in the mouse.            ",Statistical Modeling of Complex Traits in Genetic Reference Super-Populations,8420828,R01GM104125,"['Accounting', 'Address', 'Affect', 'Animal Model', 'Anxiety', 'Architecture', 'Asthma', 'Basic Science', 'Biomedical Research', 'Collection', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Etiology', 'Experimental Designs', 'Foundations', 'Funding', 'Generations', 'Genetic', 'Genetic Crosses', 'Genetic Programming', 'Genotype', 'Haplotypes', 'Heart Diseases', 'Human Genetics', 'Hybrids', 'Inbreeding', 'Influentials', 'Interdisciplinary Study', 'Joints', 'Lead', 'Machine Learning', 'Maps', 'Medical', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Output', 'Pattern', 'Phenotype', 'Play', 'Plug-in', 'Population', 'Population Analysis', 'Quantitative Trait Loci', 'Randomized', 'Recombinants', 'Relative (related person)', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Variant', 'Weight', 'base', 'cost', 'cost effective', 'design', 'disease phenotype', 'experience', 'flexibility', 'follow-up', 'genetic resource', 'human disease', 'insight', 'interest', 'population based', 'prospective', 'research study', 'response', 'simulation', 'success', 'tool', 'trait']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2012,241086,0.036124927316178806
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8280356,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2012,218662,0.009123670646845421
"Advanced Methods In Statistical Genetics Statistical models for genetics data are often surprisingly challenging, and often require advanced and new statistical methods. Using probability machines on whole genome data is a recent invention, with the original research on probability machines appearing in Methods of Information in Medicine (September 2011). Our methods point to refined and personalized probability predictions using a wide range of biomarkers, medical information and whole genome data. The detection of childhood-onset schizophrenia using 800,000 snps using probability machines has error rates of 15% or less, and the list of predictive snps can be filtered down to a list of less than a few hundred. Other studies of psychiatric conditions (ADHD, bipolar) are also now underway using probability machines and personalized medicine, subject-specific predictions. n/a",Advanced Methods In Statistical Genetics,8565487,ZIACT000268,"['Accounting', 'Attention deficit hyperactivity disorder', 'Biological Markers', 'Biological Neural Networks', 'Books', 'Childhood', 'Classification', 'Clinical', 'Data', 'Data Set', 'Detection', 'Disease model', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Human', 'Human Genome', 'Logic', 'Machine Learning', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Other Genetics', 'Outcome', 'Phenotype', 'Probability', 'Process', 'Research', 'Scheme', 'Schizophrenia', 'Signal Transduction', 'Statistical Methods', 'Statistical Models', 'Transcription Initiation Site', 'Universities', 'base', 'fly', 'forest', 'novel strategies', 'programs']",CIT,CENTER  FOR INFORMATION TECHNOLOGY,ZIA,2012,11052,0.024672560843156333
"Developing Stats Methods to Detect Rare Genetics Variants in Human Pedigrees Next-generation sequencing technologies coupled with the efficient DNA capture methods provide exome sequencing approach to investigate the genetic basis of complex phenotypes. Unlike whole genome association studies (GWAS) which can only discover variation in DNA that is frequent in the population (great than 1%), exome sequencing is a great choice for scientists today who might be interested in looking for rare mutations. Furthermore, exome sequencing has the advantage of testing comprehensively the role of coding variation, both common and rare. It is anticipated that every gene may harbor functionally relevant variants.   Recently, a number of statistical methods become available for analyzing the contribution of rare variants to the development of complex traits. These methods include Combined Multivariate and Collapsing (CMC) Method, Multivariate test of collapsed sub-groups Hotelling T2 test, MANOVA, Fishers product method, Weighted Sum Method and Kernel-based adaptive test. While the merits of these methods have been evaluated extensively for population-based association studies, none of these methods in their current form can be used to analyze the pedigree based association analysis using exome sequencing data.   We will develop pedigree-based rare variants analysis approach by treating each affected relatives as dependent pairs and the dependency will be accounted for using correlation matrix. Under the null hypothesis of no association of a set of rare variants with the diseases, the new statistic we have developed is asymptotically distributed as a central distribution.  Further, we will use the estimated IBD based weights to account for the dependency of the related affected or unaffected pairs generated from same pedigrees. This method will be used to analyze approximately bipolar disorder pedigrees with exome data. Simulation studies will be used for determining power and type I errors. This method will be used to analyze approximately 100 bipolar disorder pedigrees with exome data as well as data sets with other mental disorders in the future. n/a",Developing Stats Methods to Detect Rare Genetics Variants in Human Pedigrees,8556988,ZIAMH002930,"['Accounting', 'Affect', 'Base Sequence', 'Bipolar Disorder', 'Code', 'Complex', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dependency', 'Development', 'Disease', 'Disease model', 'Family', 'Future', 'Genes', 'Genetic', 'Genomics', 'Human', 'Individual', 'Literature', 'Machine Learning', 'Mental disorders', 'Methods', 'Mutation', 'Phenotype', 'Population', 'Relative (related person)', 'Research Design', 'Role', 'Scientist', 'Statistical Methods', 'Sum', 'Technology', 'Testing', 'Variant', 'Weight', 'Work', 'base', 'design', 'exome', 'genetic linkage analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'interest', 'large scale simulation', 'next generation', 'novel', 'population based', 'simulation', 'statistics', 'tool', 'trait']",NIMH,NATIONAL INSTITUTE OF MENTAL HEALTH,ZIA,2012,201240,0.04510768184172135
"Genometric analysis of quantitative traits Methods Development  Because non-independence of marker data is particularly relevant in next generation sequencing data, most of the theoretical work during the past year has focused on the testing and implementation of Tiled regression, a linear regression based method for intra-familial tests of association that address non-independence both at the marker and observational level.  Tiled regression uses multiple and stepwise regression methods in predefined segments of the genome, defined by hotspot blocks, to identify independent sequence variants in a genome-wide context that are responsible for the variation or susceptibility in quantitative and qualitative traits, respectively.  Multiple regression method is used to test for associations on the sequence variants in each tile; stepwise regression is then used to select the significant independent sequence variants within each tile.  Higher order regressions are then used to identify significant variant across tiles, chromosomes and the entire genome.  One of the lessons learned at Genetic Analysis Workshop 17 (GAW 17) was that there was a substantial inflation of type I error when traditional statistical methods for GWAS were used to analyze quantitative traits and next generation sequence variants in a mini whole exome sequence data set.  It was clear that new methods and study designs (especially those incorporating information from families) will be required for the transition from the analysis of GWAS data to statistical genetic analysis of next generation sequence data, particularly that for targeted and whole genome sequence analysis (Wilson and Ziegler 2011, Hemmelmann, Daw and Wilson 2011).  These problems didnt exist to the same extent in GWAS;  correlations between markers were localized to linkage disequilibrium (LD) blocks, and variants with low minor allele frequency were routinely removed from the analysis.  This is not the case for next generation targeted or whole genome sequencing; and clearly a paradigm shift will be needed for the statistical analysis of next generation sequence data.  To address this issue, the tiled regression method was tested with simulated mini-exome sequence data as part of the GAW 17 and results are presented in detail in Sung et al. (2011).  The most striking finding from this analysis was that methods that use simple linear regression without considering correlations between markers in a genome-wide context have estimated type I error rates (false positive rates) that are inflated by as much as three orders of magnitude (up to 1000 times) higher than their expected type I error rates depending on the underlying genetic model.  Because the tiled regression method identifies only independent sequence variants, the type I error rate is stable regardless of the underlying genetic model.  Two other projects used the simulated mini-exome sequence data from Genetic Analysis Workshop 17 and the findings.  Simpson et al. (2011) evaluated intrafamilial tests of associations in order to compare the statistical properties of likelihood based and regression of offspring based (ROMP) methods.  In the samples considered, both methods were able to detect causal sequence variants with locus specific heritabilities greater than about 0.1, but neither method was able to detect causal variants with locus specific heritabilities near 0.  There was some inflation of the type I error rates for both methods.  Kim et al. (2011) evaluated machine learning methods to detect associations in the GAW 17 simulated data.  These methods did not provide any substantial advantage over more traditional methods, although interaction effects, the strength of the learning machine methods, were not included in the underlying simulation model.  In 2011 the tiled regression methodology was implemented in the Tiled Regression Analysis Package (TRAP), a software package written in the R programming language.  The package is freely available on the NHGRI website: http://research.nhgri.nih.gov/software/TRAP.  Simulation experiments to test the statistical properties of tiled regression  In a series of simulation experiments studying the statistical properties of tiled regression compared to those of simple linear regression, tiled regression had comparable power, a more conservative type I error and a lower FDR than corresponding results from simple linear regression of single markers in a GWAS setting.  Simulation experiments have also investigated penalized regression methods as an alternative to stepwise regression.  Stepwise regression outperformed penalized regression for when the causal variants are present in the genotyping data, but penalized regression methods outperformed stepwise methods when the causal variant were not among the variants genotyped.  Thus, penalized methods may be more appropriate for a GWAS, whereas stepwise methods may be the preferred approach for next generation whole genome data.  The use of generalized estimating equations as a method for including family information in a linear regression model has also been investigated and compared it to a variance component approach (VCA) (Suktitipat et al. 2012, in press).  Although the VCA makes complete use of phenotyping, genotyping and family relationships, the computational time for VCA in whole-genome data in families is considerable.  The power and type I error rate for a linear model with GEE clustering with a robust variance estimator, in clusters based on extended family structure (GEEExt) and clusters based on nuclear family structure split from the original extended family structure (GEESpl), was compared to that of VCA.  The type I error rate for GEEExt was marginally higher than the nominal rate when the MAF was < 0.1, and close to nominal rate when MAF  0.2.  All methods gave consistent effect estimates and had similar power.  The GEE extension to a linear model with a robust variance estimator was the computationally fastest and provided a reasonable alternative to the VCA for screening family data.  Collaborations  Familial Idiopathic Scoliosis  Several analyses focusing on candidate regions and phenotypic subsets in the Familial Idiopathic Scoliosis (FIS) project have been completed. These include:  1) Two candidate regions identified with linkage analysis on chromosome 1 (1p36 and 1q25-32) have been fine mapped and analyzed, corroborating the initial Miller et al 2005 linkage analysis, finding significant associations, and narrowing the size of the regions as part of Dana Behnemans recently completed Ph.D. project (manuscripts in preparation).  2) Candidate regions on 9q and 16p-16q, previously identified as linked to FIS in a study of 202 families Miller et al. 2005, were genotyped with a custom high-density map of SNPs in order to identify candidate genes and prioritize them for next generation sequence analysis.  Nominally significant linkage results were found for markers in both candidate regions.  Results from intra-familial tests of association and tiled regression corroborated the linkage findings and identified possible candidate genes suitable for follow-up with next generation sequencing in these same families (Miller et al. Human Hered 2012, in press).  Other large ongoing collaborations include:  1) Meta-analysis of smoking in African-Americans David et al. 2012 2) Clinical characterization of NF1 (Dr. Douglas Stewart, NIH/NCI) 3) The ClinSeq project (Les Biesecker, NIH/NHGRI) 4) The identification of genetic effects responsible for sagittal craniosynostosis with Dr. Simeon Boyd (aka Boyadjiev) at UC Davis (Justice et al. Nat Genet 2012, in press) 5) The GeneSTAR project (Drs. Diane and Lewis Becker, Johns Hopkins University School of Medicine) 6) Variation in metabolites in the Irish Trinity Student Study (Dr. Larry Brody, NIH/NHGRI) n/a",Genometric analysis of quantitative traits,8565534,ZIAHG000200,"['16p', '16q', '1p36', '1q25', 'Address', 'African American', 'Candidate Disease Gene', 'Case-Control Studies', 'Chromosomes', 'Chromosomes, Human, Pair 1', 'Clinical', 'Collaborations', 'Computer Simulation', 'Computer software', 'Craniosynostosis', 'Custom', 'DNA Markers', 'Data', 'Data Set', 'Dependency', 'Doctor of Philosophy', 'Economic Inflation', 'Educational workshop', 'Employee Strikes', 'Equation', 'Extended Family', 'Family', 'Family Relationship', 'Gene Frequency', 'Genetic', 'Genetic Heterogeneity', 'Genetic Models', 'Genets', 'Genome', 'Genotype', 'Goals', 'Heritability', 'Human', 'Idiopathic scoliosis', 'Individual', 'Learning', 'Linear Models', 'Linear Regressions', 'Link', 'Linkage Disequilibrium', 'Machine Learning', 'Manuscripts', 'Maps', 'Meta-Analysis', 'Methodology', 'Methods', 'Minor', 'Modeling', 'National Human Genome Research Institute', 'Nature', 'Nuclear Family', 'Phenotype', 'Population', 'Predisposition', 'Preparation', 'Programming Languages', 'Property', 'Quantitative Genetics', 'Regression Analysis', 'Research', 'Research Design', 'Sampling', 'Screening procedure', 'Sequence Analysis', 'Series', 'Simulate', 'Single Nucleotide Polymorphism', 'Single Nucleotide Polymorphism Map', 'Smoking', 'Statistical Methods', 'Statistical Study', 'Stratification', 'Structure', 'Students', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Variant', 'Work', 'Writing', 'base', 'density', 'exome', 'family structure', 'follow-up', 'genetic analysis', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'genome-wide', 'insight', 'medical schools', 'method development', 'models and simulation', 'next generation', 'offspring', 'population based', 'research study', 'simulation', 'statistics', 'trait', 'web site']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2012,1636850,0.037812830893456426
"Bioinformatics Approaches to Visual Disease Genetics     DESCRIPTION (provided by applicant): It is now recognized that many visual diseases are influenced by complex interactions between multiple different genetic variants. As a result, our ability to predict susceptibility to visual diseases will depend critically on the computational, mathematical and statistical modeling methods and software that are available for making sense of high-dimensional genetic data. We propose here a bioinformatics research project to develop network modeling approaches for identifying combinations of genetic biomarkers associated with visual disease endpoints. Our working hypothesis is that a systems-based bioinformatics approach using network modeling will play a very important role in confronting the complexity of the relationship between genomic variation and visual diseases. We will first develop and evaluate modeling methods to infer large-scale genetic interaction networks from genome-wide association studies (AIM 1). We will then apply the modeling methods developed in AIM 1 to the inference of genetic interaction networks from genome-wide association data in subjects with and without visual diseases (AIM 2). Next, we will utilize the inferred genetic interaction networks to guide the development of predictive genetic models of visual diseases (AIM 3). Finally, all network modeling methods will be released to the vision research community as part of a popular user-friendly, freely available and open-source software package (AIM 4). We anticipate that the network modeling methods and software developed and distributed as part of this project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for visual diseases.        PUBLIC HEALTH RELEVANCE: The network modeling methods and software developed and distributed as part of this bioinformatics research project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for common diseases such as glaucoma and age-related macular degeneration.                  The network modeling methods and software developed and distributed as part of this bioinformatics research project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for common diseases such as glaucoma and age-related macular degeneration.                ",Bioinformatics Approaches to Visual Disease Genetics,8264613,R01EY022300,"['Age related macular degeneration', 'Algorithms', 'Biochemical Pathway', 'Bioinformatics', 'Biological Markers', 'Clinical', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Disease', 'Entropy', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Structures', 'Genetic screening method', 'Genomics', 'Genotype', 'Glaucoma', 'Goals', 'Hereditary Disease', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Network-based', 'Ontology', 'Pathway Analysis', 'Phenotype', 'Play', 'Predisposition', 'Research Project Grants', 'Risk', 'Role', 'Simulate', 'Single Nucleotide Polymorphism', 'Statistical Models', 'System', 'Time', 'Variant', 'Vision research', 'Visual', 'Work', 'base', 'database of Genotypes and Phenotypes', 'genetic analysis', 'genetic variant', 'genome wide association study', 'mathematical model', 'network models', 'open source', 'predictive modeling', 'protein protein interaction', 'software development', 'tool', 'user-friendly']",NEI,DARTMOUTH COLLEGE,R01,2012,322000,-0.02765671608637906
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8328943,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome', 'genetic regulatory protein', 'genetic variant', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2012,461516,0.008010808593222854
"Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies    DESCRIPTION (provided by applicant): Common mental disorders such as Alzheimer's disease and schizophrenia are largely heritable with complex genetic underpinnings. Large-scale genome-wide association studies that contrast DNA sequence data from patients and controls have recently identified novel genetic risk variants for these disorders. Nevertheless, the processes through which genotype increases risk are yet to be fully characterized.  Neuroimaging offers a richer picture of the underlying disease processes than a clinical diagnosis. Thus the joint analysis of neuroimaging and genetics data promises to advance our understanding of these processes. Today, neuroimaging genetics studies however face important challenges that obstruct progress: small sample sizes, modest effect sizes, and the extreme dimensionality of the data limit statistical power and thus our ability to explore the complex and subtle associations between genes, neuroanatomy and clinical decline. Currently, the prevalent approach in neuroimaging genetics is to concentrate the analysis on a small number of anatomic regions of interest and/or candidate genes and often ignore a large portion of the data. The core goal of the proposed project is to develop computational tools that will take full advantage of the richness in the datasets and facilitate the exploration of the multifaceted associations between genotype, neuroimaging measurements and clinical phenotype. The proposed project will use advanced multivariate pattern analysis methods such as support vector machines to compute image-based and genetic scores that reflect pathology. We will validate the tools based on their association with classical biomarkers of disease. Finally, we will develop a model that uses both imaging and genotype data to predict future clinical outcome. We expect these tools will enable progress along three directions relevant to complex mental disorders, e.g. late-onset Alzheimer's disease (AD): (1) confirming and characterizing risk genes, (2) identifying disease-specific anatomical alterations in healthy individuals, and (3) early diagnosis and prognosis. The project will (1) use three already-collected large-scale datasets to apply the developed tools to AD, (2) build on cutting-edge image processing algorithms that we have been developing, and (3) allow the candidate to receive further training in neuroanatomy, mental disorders and genetics, forming the foundation for his future career as an independent researcher.       n/a",Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies,8308347,K25EB013649,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Anatomy', 'Biological Markers', 'Brain', 'Candidate Disease Gene', 'Clinical', 'Clinical Trials', 'Cognitive', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Dementia', 'Development', 'Disease', 'Early Diagnosis', 'Event', 'Exhibits', 'Face', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Research', 'Genetic Risk', 'Genotype', 'Goals', 'Hereditary Disease', 'Hippocampus (Brain)', 'Image', 'Individual', 'Joints', 'Late Onset Alzheimer Disease', 'Lead', 'Logistic Regressions', 'Machine Learning', 'Measurement', 'Mental disorders', 'Methods', 'Mining', 'Modeling', 'Motivation', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Probability', 'Process', 'Recruitment Activity', 'Research Personnel', 'Risk', 'Sample Size', 'Schizophrenia', 'Testing', 'Thick', 'Training', 'Variant', 'base', 'career', 'clinical Diagnosis', 'clinical phenotype', 'computerized tools', 'data modeling', 'disorder risk', 'entorhinal cortex', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'high risk', 'image processing', 'improved', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular pathology', 'neuroimaging', 'novel', 'outcome forecast', 'pre-clinical', 'programs', 'tool']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,K25,2012,175392,-0.03483764794465721
"Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning  Detecting Genome-Wide Epistasis with Efficient Bayesian Network Learning Epistasis is the interaction between two or more genes to affect phenotype. It is now widely accepted that epistasis plays an important role in susceptibility to many common diseases. The advent of high-throughput technologies has enabled genome-wide association studies (GWAS or GWA studies). It is compelling that we be able to detect epistasis using GWAS data. However, so far GWA studies have mainly focused on the association of a single gene or loci with a disease. The crucial challenge to analyzing epistasis using GWAS data is finding a way to efficiently handle high-dimensional data sets. The only possible solution is to design efficient algorithms that allow us to find the most relevant epistasic relationships without doing an exhaustive investigation. To the Principal Investigator's knowledge, no current method can do this. This career award will investigate this problem. The specific aims are as follows: (Aim 1) develop and evaluate efficient Bayesian network-based methods for learning candidate genes associated with diseases from GWAS sets. Such genes would provide candidates for follow-up biological studies, (Aim 2) implement the methods in a pilot GWAS system for use by researchers when conducting a GWAS, (Aim 3) develop simulated genome-wide data sets and evaluate the pilot system using these data sets, and (Aim 4) conduct GWA studies concerning breast cancer and lung cancer. Aim 1 will be addressed by developing a succinct Bayesian network model representing epistasis, efficient algorithms which are tailored to investigating such models, integration of the algorithms into methods for learning epistasis, and using simulated datasets to test the effectiveness of the methods and compare their performance to other methods. Aim 2 will be met by implementing the methods in a pilot GWAS system. Aim 3 will be satisfied by developing synthetic data sets similar to those found in GWA studies, and using them to evaluate the system. Aim 4 will be achieved by conducting GWA studies concerning breast and lung cancer. By conducting these studies, we can (1) substantiate previous results concerning the genetic basis of these diseases; (2) possibly obtain interesting new findings pertaining to these diseases. The main hypothesis is that the proposed method will be an advance over existing methods in that it will make it computationally feasible to learn epistatic relationships from genome-wide data and it will therefore yield better discovery performance than existing methods.  Learning gene-gene interactions from genome-wide association studies (GWAS) data is an important and challenging task in genetic epidemiology. This project will develop and evaluate a pilot GWAS system for performing this task. Advances obtained in analyzing GWAS data sets could enable us to learn the genetic basis of many diseases and thereby substantially improve the quality of personalized patient care.",Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning,8372706,R00LM010822,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Award', 'BRCA1 gene', 'BRCA2 gene', 'Biological', 'Biological Neural Networks', 'Cancer-Predisposing Gene', 'Candidate Disease Gene', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Effectiveness', 'Family history of', 'GAB2 gene', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Programming', 'Germ-Line Mutation', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Network-based', 'Patient Care', 'Performance', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Regression Analysis', 'Research', 'Research Personnel', 'Role', 'Simulate', 'Site', 'Solutions', 'Statistical Methods', 'System', 'Testing', 'Woman', 'Work', 'base', 'cancer cell', 'career', 'combinatorial', 'computer based statistical methods', 'data mining', 'design', 'follow-up', 'forest', 'gene interaction', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high throughput technology', 'improved', 'interest', 'malignant breast neoplasm', 'meetings', 'network models']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R00,2012,166150,0.017490379327295014
"Methods for high-resolution analysis of genetic effects on gene expression    DESCRIPTION (provided by applicant):    Summary Gene expression is a fundamental function of any cell. It is the main mechanism by which information is transmitted from the nucleus to the rest of the cell and eventually to other cells and the body of the organism. Genetic variation in components of the transcriptional machinery and signals that regulate gene function generates variation in transcriptional response and consequently variation in phenotypes. It has become apparent that many of the common genetic signals associated with disease are found away from the DNA sequence that encodes for protein sequence and is likely to be functioning in regulating gene expression. In this project we propose to develop methodologies that will explore the consequences of genetic variation in gene expression. There are three main goals of this project. First we will explore and develop methodologies to mine information from experiments that perform deep sequencing of the human transcriptome. The new sequencing technologies are providing us with unprecedented resolution into the transcriptome but are also raising challenges in the computational and biological models to use to interpret such large amounts of data. Secondly, we will use high-resolution genetic data to develop and use methodologies to dissect the fine structure of genetic variants that affect regulation of gene expression. Finally, we will implement and test models to infer the higher-order interactions of genome function so as to dig deeply into the biological consequences of genetic variants and how the signal is transmitted from the DNA sequence to higher levels of cell and body function. Our goals is to develop methodologies that will significantly improve our insight to the variability in human populations and assist in interpreting predisposition to genetic diseases.      PUBLIC HEALTH RELEVANCE:    Project narrative The proposed project aims at the development of statistical methods for the interpretation and study of the impact of genetic variants in cell function. Understanding the cellular effects of genetic variants provides a fundamental framework for the deep understanding of human genetic disease and increases the potential for the development of relevant treatments and drugs. It is the understanding of the basic molecular functions in health and disease that will provide the utmost resolution of information for the improvement of human health.           Project narrative The proposed project aims at the development of statistical methods for the interpretation and study of the impact of genetic variants in cell function. Understanding the cellular effects of genetic variants provides a fundamental framework for the deep understanding of human genetic disease and increases the potential for the development of relevant treatments and drugs. It is the understanding of the basic molecular functions in health and disease that will provide the utmost resolution of information for the improvement of human health.",Methods for high-resolution analysis of genetic effects on gene expression,8509240,R01MH090941,"['Accounting', 'Affect', 'Alleles', 'Alternative Splicing', 'Amino Acid Sequence', 'Biochemical', 'Biological', 'Biological Models', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Complex', 'Computer Simulation', 'DNA', 'DNA Resequencing', 'DNA Sequence', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Interphase Cell', 'Linkage Disequilibrium', 'Location', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Nucleotides', 'Organism', 'Pattern', 'Peptide Sequence Determination', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Property', 'RNA Sequences', 'Relative (related person)', 'Resolution', 'Sampling', 'Signal Transduction', 'Simulate', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Transcript', 'Variant', 'Work', 'base', 'cell type', 'density', 'gene function', 'genetic analysis', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'insight', 'network models', 'neuronal cell body', 'programs', 'protein protein interaction', 'public health relevance', 'reconstruction', 'research study', 'response', 'simulation', 'trait']",NIMH,UNIVERSITY OF GENEVA,R01,2012,215355,-0.011874696602513219
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8337800,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2012,2751015,0.0041650048410910795
"New Physical Methodologies for Genomic Analysis     DESCRIPTION (provided by applicant): Despite substantial efforts in developing sequencing technologies and computational software, spanning over 30 years, the full genome of any but the simplest organisms is still unable to automatically reconstructed. The length of the DNA sequences that can be 'read' by modern sequencing systems is substantially smaller than the length of most genomes (1000s of base-pairs versus millions to billions), making it virtually impossible to use the fragmented information generated by the shotgun sequencing process to reconstruct the long-range information linking together genomic segments belonging to a same chromosome. The main reason why genome assembly is difficult is genomic repeats - segments of DNA that occur in multiple identical or near-identical copies throughout a genome. Any repeats longer than the length of a sequencing read introduce ambiguity in the possible reconstructions of a genome - an exponential (in the number of repeats) number of different genomes can be constructed from the same set of reads, among which only one is the true reconstruction of the genome being assembled. Finding this one correct genome from among the many possible alternatives is impossible without the use of additional information, such as mate-pair information constraining the relative placement of pairs of shotgun reads along the genome. Mate-pair information is routinely generated in sequencing experiments and has been critical to scientists' ability to reconstruct genomes from shotgun data (e.g., mate-pair information was crucial to the success of the first prokaryotic genome project - Haemophilus influenza). Given these outstanding issues, a series of interlocking aims is proposed that center on enhanced optical and electronic detection of specially-decorated, genomic DNA molecules. The aims are designed for enabling new technologies that will provide sufficient physical map information to intimately mix with modern sequencing data for comprehensive assembly of complex genomes. These proposed advancements will be cradled within a new generation of nanofluidic devices engendering novel means for molecular control and detection. Such efforts will be directed by state-of-the art computer simulations that will model novel aspects of the new platforms for allowing rapid loops of design/implementation/testing. The main thrust of these technological developments will be carefully guided and serve a broad-based bioinformatics framework that will be developed for this work while laying the basis for highly integrated approaches to genome assembly and analysis.        PUBLIC HEALTH RELEVANCE: Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.              Development of new machines and software is proposed, which will rapidly analyze a person's genome and reveal new types of information that doctors will be able to use for treating patients. The machines that will be developed are actually very small devices that may one day be sufficiently miniaturized to fit in a person's hand.            ",New Physical Methodologies for Genomic Analysis,8373752,R01HG000225,"['Algorithms', 'Base Pairing', 'Beds', 'Bioinformatics', 'Characteristics', 'Chemistry', 'Chromosomes', 'Complement', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'DNA', 'DNA Sequence', 'DNA Structure', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Electronics', 'Engineering', 'Fluorochrome', 'Generations', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Graph', 'Haemophilus influenzae', 'Hand', 'Image', 'Image Analysis', 'Label', 'Length', 'Link', 'Maps', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Motion', 'Neighborhoods', 'Nucleotides', 'Optics', 'Organism', 'Partner in relationship', 'Patients', 'Persons', 'Polymerase', 'Process', 'Reading', 'Reagent', 'Relative (related person)', 'Scheme', 'Scientist', 'Series', 'Shotgun Sequencing', 'Shotguns', 'Single-Stranded DNA', 'Site', 'Stretching', 'Surface', 'Surgical Flaps', 'System', 'Techniques', 'Technology', 'Testing', 'Translations', 'Validation', 'Vent', 'Vision', 'Work', 'base', 'design', 'ds-DNA', 'engineering design', 'experience', 'genome-wide', 'heuristics', 'miniaturize', 'nanofluidic', 'new technology', 'novel', 'rapid detection', 'reconstruction', 'research study', 'restriction enzyme', 'scaffold', 'success']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,654177,0.03866334692360027
"EMR Phenotype and Community Engaged Genomic Associations    DESCRIPTION (provided by applicant): The electronic medical record (EMR) can be leveraged for high throughput phenotyping of large numbers of patients for genomics research. As part of eMERGE-l, we used EMR-based algorithms to enable genome- wide association studies (GWAS) of several primary and network-wide phenotypes. The present application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. The Mayo eMERGE-ll cohort (n=6916) includes the 3769 eMERGE-l patients and an additional 3147 individuals, the majority (90%) genotyped on the same lllumina 660W platform. We will work with other eMERGE-ll sites to expand and validate the library of electronic phenotyping algorithms to enable GWAS of multiple phenotypes of interest. A major focus of our application is to translate recent GWAS findings to clinical practice. Our specific aims are: Specific aim 1. Conduct EMR-based GWAS to identify common genetic variants that influence a) inter-individual variation in cardiorespiratory fitness and response to statin medications and b) susceptibility to venous thromboembolism and colon polyps. Specific aim 2. Quantify genetic risk of a common 'complex' disease - coronary heart disease (CHD) - and an adverse drug response - statin myopathy. We will develop risk communication tools that convey the clinical and genetic components of risk to both patients and care providers. Specific aim 3. Develop informatics approaches to incorporate genomic data into the EMR, including links to clinical decision support. Specific aim 4. Conduct a randomized-clinical trial to investigate how patients respond to genetically informed CHD-risk. We will re-consent 150 eMERGE-l patients without CHD, communicate the results via a genetic counselor, and discuss in detail the implications of the testing relevant to disease risk. The effectiveness of the communication and the patients' comprehension of risk, their hopes and concerns, and planned changes in lifestyle will be assessed by surveys and interviews after the patient-counselor encounter. As part of our ongoing efforts in community consultation, we will establish a community advisory group specific to this project.       RELEVANCE (See instructions): The proposed application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. We will develop tools to incorporate genomic information in the EMR. In addition, we will investigate clinical, translational, and ethical aspects of genetic testing for complex diseases and assess the response of patients to genetic testing.              n/a",EMR Phenotype and Community Engaged Genomic Associations,8319363,U01HG006379,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Bioethics', 'Cardiology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Colonic Polyps', 'Communication', 'Communication Tools', 'Communities', 'Complex', 'Comprehension', 'Computerized Medical Record', 'Consent', 'Coronary heart disease', 'Data', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Dose', 'Drops', 'Drug usage', 'Early Diagnosis', 'Effectiveness', 'Electronic library', 'Empirical Research', 'Epidemiologist', 'Ethical Issues', 'Ethics', 'Future', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Informatics', 'Instruction', 'Interview', 'Knowledge', 'Laboratories', 'Libraries', 'Life Style', 'Link', 'Medicine', 'Methods', 'Myopathy', 'Natural Language Processing', 'Patient Care', 'Patients', 'Perception', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Predisposition', 'Preventive', 'Principal Investigator', 'Procedures', 'Professional counselor', 'Provider', 'Public Health', 'Publishing', 'Randomized Clinical Trials', 'Research', 'Research Infrastructure', 'Risk', 'Risk Factors', 'Scientist', 'Screening procedure', 'Site', 'Staging', 'Surveys', 'Testing', 'Text', 'Thromboembolism', 'Translating', 'Variant', 'Venous', 'Work', 'adverse outcome', 'base', 'clinical practice', 'cohort', 'community consultation', 'cost', 'disorder risk', 'exome', 'experience', 'fitness', 'genetic risk assessment', 'genetic variant', 'genome wide association study', 'heart disease risk', 'interest', 'open source', 'point of care', 'repository', 'response', 'tool']",NHGRI,MAYO CLINIC ROCHESTER,U01,2012,773313,0.024116369211643972
"EMR Phenotype and Community Engaged Genomic Associations    DESCRIPTION (provided by applicant): The electronic medical record (EMR) can be leveraged for high throughput phenotyping of large numbers of patients for genomics research. As part of eMERGE-l, we used EMR-based algorithms to enable genome- wide association studies (GWAS) of several primary and network-wide phenotypes. The present application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. The Mayo eMERGE-ll cohort (n=6916) includes the 3769 eMERGE-l patients and an additional 3147 individuals, the majority (90%) genotyped on the same lllumina 660W platform. We will work with other eMERGE-ll sites to expand and validate the library of electronic phenotyping algorithms to enable GWAS of multiple phenotypes of interest. A major focus of our application is to translate recent GWAS findings to clinical practice. Our specific aims are: Specific aim 1. Conduct EMR-based GWAS to identify common genetic variants that influence a) inter-individual variation in cardiorespiratory fitness and response to statin medications and b) susceptibility to venous thromboembolism and colon polyps. Specific aim 2. Quantify genetic risk of a common 'complex' disease - coronary heart disease (CHD) - and an adverse drug response - statin myopathy. We will develop risk communication tools that convey the clinical and genetic components of risk to both patients and care providers. Specific aim 3. Develop informatics approaches to incorporate genomic data into the EMR, including links to clinical decision support. Specific aim 4. Conduct a randomized-clinical trial to investigate how patients respond to genetically informed CHD-risk. We will re-consent 150 eMERGE-l patients without CHD, communicate the results via a genetic counselor, and discuss in detail the implications of the testing relevant to disease risk. The effectiveness of the communication and the patients' comprehension of risk, their hopes and concerns, and planned changes in lifestyle will be assessed by surveys and interviews after the patient-counselor encounter. As part of our ongoing efforts in community consultation, we will establish a community advisory group specific to this project.       RELEVANCE (See instructions): The proposed application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. We will develop tools to incorporate genomic information in the EMR. In addition, we will investigate clinical, translational, and ethical aspects of genetic testing for complex diseases and assess the response of patients to genetic testing.              n/a",EMR Phenotype and Community Engaged Genomic Associations,8514888,U01HG006379,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Bioethics', 'Cardiology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Colonic Polyps', 'Communication', 'Communication Tools', 'Communities', 'Complex', 'Comprehension', 'Computerized Medical Record', 'Consent', 'Coronary heart disease', 'Data', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Dose', 'Drops', 'Drug usage', 'Early Diagnosis', 'Effectiveness', 'Electronic library', 'Empirical Research', 'Epidemiologist', 'Ethical Issues', 'Ethics', 'Future', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Informatics', 'Instruction', 'Interview', 'Knowledge', 'Laboratories', 'Libraries', 'Life Style', 'Link', 'Medicine', 'Methods', 'Myopathy', 'Natural Language Processing', 'Patient Care', 'Patients', 'Perception', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Predisposition', 'Preventive', 'Principal Investigator', 'Procedures', 'Professional counselor', 'Provider', 'Public Health', 'Publishing', 'Randomized Clinical Trials', 'Research', 'Research Infrastructure', 'Risk', 'Risk Factors', 'Scientist', 'Screening procedure', 'Site', 'Staging', 'Surveys', 'Testing', 'Text', 'Thromboembolism', 'Translating', 'Variant', 'Venous', 'Work', 'adverse outcome', 'base', 'clinical practice', 'cohort', 'community consultation', 'cost', 'disorder risk', 'exome', 'experience', 'fitness', 'genetic risk assessment', 'genetic variant', 'genome wide association study', 'heart disease risk', 'interest', 'open source', 'point of care', 'repository', 'response', 'tool']",NHGRI,MAYO CLINIC ROCHESTER,U01,2012,279834,0.024116369211643972
"From GWAS to PheWAS: Scanning the EMR phenome for gene-disease associations    DESCRIPTION (provided by applicant): Genomic medicine offers hope for improved diagnostic methods and for more effective, patient-specific therapies. Genome-wide associated studies (GWAS) elucidate genetic markers that improve understanding of risks and causes for many diseases, and may guide diagnosis and therapy on a patient-specific basis. This project will take another approach to identify gene-disease associations: perform ""reverse GWAS,"" or phenome- wide association study (PheWAS), to determine which phenotypes are associated with a given genotype. The project is enabled by a large DNA biobank coupled to a de- identified copy of the electronic medical record. This project has four specific aims. First, the project will develop and validate a standardized approach to extract disease phenotypes from EMR records, integrating national standard terminologies of clinical disorders and descriptors relating to treatment and diagnosis of each disease to create a sharable knowledge base. The project will use natural language processing, structured data queries, and heuristic and machine learning methods to accurately identify patients with each disease and corresponding controls. The second aim is to perform PheWAS analyses using existing genotype data. To validate the method, the project will use PheWAS to ""rediscover"" SNPs with known disease associations. The project will also investigate statistical methods for large-scale multiple hypothesis testing to discover novel phenotype associations. The third aim is to apply the PheWAS algorithms in four other sites with EMR-linked DNA biobanks and compare results. In the fourth aim, the project will validate novel phenotype-genotype associations discovered through PheWAS with new genotyping in a previously untested population. The tools generated from this project will not only make PheWAS possible, but will also broadly enable clinical research and subsequent genetic studies.           The promise of genomic medicine is to predict individuals' disease risk and treatment given their genetic information. This project will develop methods to identify diseases from electronic medical records and then find novel genetic associations from existing genomic data.",From GWAS to PheWAS: Scanning the EMR phenome for gene-disease associations,8042010,R01LM010685,"['Academic Medical Centers', 'Algorithms', 'Appointment', 'Blood specimen', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Treatment', 'Clinical Trials', 'Clinical and Translational Science Awards', 'Code', 'Computerized Medical Record', 'Coupled', 'DNA', 'DNA Databases', 'Data', 'Data Element', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Disease Association', 'Enrollment', 'Expert Systems', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Genotype', 'Goals', 'Hand', 'Individual', 'Institution', 'Investigation', 'Joints', 'Laboratories', 'Letters', 'Link', 'Machine Learning', 'Manuals', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Population', 'Positioning Attribute', 'Records', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Scanning', 'Secure', 'Single Nucleotide Polymorphism', 'Site', 'Statistical Methods', 'Structure', 'Syndrome', 'Techniques', 'Terminology', 'Testing', 'Text', 'Time', 'United States National Institutes of Health', 'Update', 'Validation', 'analytical method', 'base', 'biobank', 'biomedical informatics', 'case control', 'cohort', 'disease phenotype', 'disorder risk', 'experience', 'genetic association', 'genome-wide', 'heuristics', 'improved', 'knowledge base', 'novel', 'novel strategies', 'patient population', 'phenome', 'phenomics', 'research clinical testing', 'tool', 'treatment response']",NLM,VANDERBILT UNIVERSITY,R01,2011,336864,0.036214385338776044
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects has been continued in conjunction with Dr. Betty Doan. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We have created programs for calculating permutation p-values for the linkage results obtained when using propensity scores in LODPAL in the S.A.G.E. program package and are currently applying these methods to Dr. Bailey-Wilson's lung cancer data. Results will be presented at an upcoming international meeting.  We continue to explore the utility of various machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. We are continuing to pursue the use of machine learning methods in genomics studies, and have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). A paper presenting these results is in press (1). In addition, Dr. Bailey-Wilson has co-authored a review paper on machine learning methods that is in press (2). Dr. Bailey-Wilson is also first and corresponding author on a paper summarizing the findings of the GAW17 group on Regression and Data Mining Methods for Analyses of Multiple Rare Variants which is also in press (3).  We also have used the GAW17 simulated whole-exome sequence (WES) data to develop novel tools for analysis and interpretation of WES data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Two additional papers presenting these results are in press (4-5). Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.   Given the limitations of the GAW16 and GAW17 simulated datasets, we have started developing our own simulation programs to simulate genome-wide association data with realistice haplotype block structures that will be representative of (at least) European Caucasian and African-American populations. These simulations will allow us to test and compare methods across a wide array of biological models including complex trait models that include geneXgene and geneXenvironment interactions. n/a",Development of statistical genetics methodology,8349983,ZIAHG000153,"['African American', 'Biological Models', 'Caucasians', 'Caucasoid Race', 'Complex', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'European', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Haplotypes', 'International', 'Machine Learning', 'Malignant neoplasm of lung', 'Methodology', 'Methods', 'Modeling', 'Paper', 'Performance', 'Phenotype', 'Population', 'Publishing', 'Scheme', 'Sequence Analysis', 'Simulate', 'Statistical Methods', 'Structure', 'Testing', 'Variant', 'data mining', 'exome', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genome wide association study', 'improved', 'meetings', 'novel', 'programs', 'simulation', 'tool', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2011,195701,0.019938769240908052
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8107695,U01HG004695,"['Address', 'Algorithms', 'Area', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Hypersensitivity', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'RNA', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2011,108418,0.020214231990030935
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8107695,U01HG004695,"['Address', 'Algorithms', 'Area', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Hypersensitivity', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'RNA', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2011,1699793,0.020214231990030935
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics     DESCRIPTION (provided by applicant):  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. The driving force behind this initiative is the frequency of hearing impairment. As the most common sensory impairment, it is diagnosed in 1 of every 500 newborns and 50% of octogenarians (Morton Ann N Y Acad Sci 1991). With 57 genes implicated in nonsyndromic hearing loss (NSHL), it is also an extremely heterogeneous trait and presents a tremendous challenge to diagnosis.  Current strategies for genetic testing for deafness are inadequate. For most, only a minority of genes is included, with selection criteria typically reflecting: 1) high prevalence as a cause of deafness (i.e. GJB2); 2) association with another recognizable feature (i.e. SLC26A4 and enlarged vestibular aqueduct); or 3) a recognizable audioprofile (i.e. low frequency hearing loss as seen with WFS1) (Hilgert et al Mut Res 2009).  The recent advent of powerful DNA target enrichment and sequencing technologies, however, makes it possible to provide comprehensive genetic testing for deafness that is efficient and cost-effective. We have shown that it is possible to analyze all deafness genes simultaneously on a single platform (called OtoSCOPE) (Shearer et al PNAS 2010). Related to this endeavor, we have also validated AudioGene as a phenotypic tool that uses patient audiograms to predict the genetic cause of ADNSHL (Hildebrand et al Genet Med 2008; Hildebrand et al Laryngoscope 2009).  Building on these findings, in this proposal we will complete two specific aims.  Specific Aim 1: To provide comprehensive, high-throughput, low-cost DNA sequence generation and analysis for deafness genetic testing  Goal 1: Comprehensive, high-throughput, low-cost DNA sequence analysis for genetic testing for deafness is possible at sensitivities and specificities comparable to Sanger sequencing by using targeted sequence enrichment followed by massively parallel sequencing.  Specific Aim 2: To optimize both machine learning-based audioprofiling of audiometric data and phenotypic filtering of genotypic data by expanding and improving the platform we have developed called AudioGene  Goal 2: As a phenome tool, a machine-learning software system trained on an extensive set of audiometric data can be used to predict and to eliminate specific genes or gene variants as causes of deafness based on audiometric data.  Achieving these specific aims will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history, physical examination and audiological assessment.        PUBLIC HEALTH RELEVANCE:  In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.                   In this goal-driven proposal, submitted in response to Funding Opportunity Announcement (FOA) Number PAR-11-003, we will make comprehensive genetic testing for deafness available to clinicians for under $500 per person. Achieving this goal will change the clinical evaluation of deaf and hard-of-hearing persons by making genetic testing the most important diagnostic test after a history and physical exam.                ",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,8224101,R01DC012049,"['Audiometry', 'Bar Codes', 'Caring', 'Clinical', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Dideoxy Chain Termination DNA Sequencing', 'Family', 'Frequencies', 'Funding Opportunities', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genets', 'Goals', 'Hearing Impaired Persons', 'High Prevalence', 'Impairment', 'Laboratories', 'Laryngoscopes', 'Life', 'Link', 'Low Frequency Deafness', 'Machine Learning', 'Minority', 'Mutation', 'Newborn Infant', 'Octogenarian', 'Patients', 'Persons', 'Physical Examination', 'Recording of previous events', 'Resources', 'Sampling', 'Screening procedure', 'Selection Criteria', 'Sensitivity and Specificity', 'Sensory', 'Sequence Analysis', 'System', 'Technology', 'Training', 'Usher Syndrome', 'Variant', 'Vestibular Aqueduct', 'base', 'cost', 'cost effective', 'deafness', 'driving force', 'hearing impairment', 'improved', 'meetings', 'phenome', 'research clinical testing', 'response', 'software systems', 'tool', 'trait']",NIDCD,UNIVERSITY OF IOWA,R01,2011,608130,0.033227260113625055
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,8134360,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait', 'treatment strategy']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2011,342569,-0.0007904547136044258
"Information Explorer: a Suite of Tools for Cross-study Genetic Loci Discovery    DESCRIPTION (provided by applicant): Databases such as dbGaP represent extremely valuable resources of data that have been assembled across multiple cohorts. The increasing development of cost-effective high-throughput genotyping and sequencing technologies are resulting in vast amounts of genetic data. While such databases were formed in order to archive and distribute the results of previously performed genetic association analyses, an increasing number of studies have provided de-identified individual-level genotypic and phenotypic data that are made available to outside researchers who have obtained the appropriate authorization. While the amount of data made available has increased dramatically in recent years, relatively little has been done in order to facilitate phenotype harmonization across studies. Many genetic epidemiologic studies of cardiovascular disease have multiple variables related to any given phenotype, resulting from different definitions and multiple measurements or subsets of data. A researcher searching such databases for the availability of phenotype and genotype combinations is confronted with a veritable mountain of variables to sift through. This often requires visiting multiple websites to gain additional information about variables that are listed on databases, and examination of data distributions to assess similarities across cohorts. While the naming strategy for genetic variants is largely standardized across studies (e.g. ""rs"" numbers for single nucleotide polymorphisms or SNPs), this is often not the case for phenotype variables. For a given study, there are often numerous versions of phenotypic variables. Researchers currently have to analyze and compare increasingly larger numbers of variables that have varying degrees of documentation associated with them to obtain the desired information. This is a time-consuming process that may still miss the most appropriate variables. Moreover, every researcher that wants to compare the same datasets often needs to start from scratch since there are no tools to share the phenotype comparison results. The availability of informatic tools to make phenotype mapping more efficient and improve its accuracy, along with intuitive phenotype query tools, would provide a major resource for researchers utilizing these databases. The tools we are proposing would allow researchers to (1) Quickly obtain the information needed to assess whether a specific study will be useful for the hypothesis of interest; (2) Exclude variables that do not meet research criteria; (3) Ascertain which studies have combinations of phenotype and genetic information of interest; and (4) More easily expand research questions beyond the most basic main-effects to more complex analyses such as gene-by-environment interactions and multivariate tests incorporating multiple phenotypes. The increased utility will also enable larger meta-analyses to be performed, as researchers will be able to more quickly hone in on outcomes, exclusionary variables and covariates of interest, leading to increased statistical power to detect genetic associations.      PUBLIC HEALTH RELEVANCE: While the amount of genomic data (e.g., GWAS, sequencing, etc.) made available has increased dramatically in recent years, relatively little has been done in order to facilitate phenotype harmonization across studies. The tools we are proposing would allow researchers to quickly identify data sets of interest, expand research questions beyond the most basic main-effects to more complex analyses such as gene-by-environment interactions and multivariate test incorporating multiple phenotypes, and perform larger meta-analyses easily by honing in on outcomes, exclusionary variables and covariates of interest with increased statistical power to detect genetic associations.           While the amount of genomic data (e.g., GWAS, sequencing, etc.) made available has increased dramatically in recent years, relatively little has been done in order to facilitate phenotype harmonization across studies. The tools we are proposing would allow researchers to quickly identify data sets of interest, expand research questions beyond the most basic main-effects to more complex analyses such as gene-by-environment interactions and multivariate test incorporating multiple phenotypes, and perform larger meta-analyses easily by honing in on outcomes, exclusionary variables and covariates of interest with increased statistical power to detect genetic associations.         ",Information Explorer: a Suite of Tools for Cross-study Genetic Loci Discovery,8145063,UH2HL108780,"['Archives', 'Artificial Intelligence', 'Authorization documentation', 'Bioinformatics', 'Biological', 'Blood', 'Cardiovascular Diseases', 'Classification', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Documentation', 'Epidemiologic Studies', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Genotype', 'Heart', 'Hereditary Disease', 'Human', 'Individual', 'Informatics', 'Information Retrieval', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Names', 'Online Systems', 'Outcome', 'Performance', 'Phenotype', 'Postdoctoral Fellow', 'Process', 'Research', 'Research Personnel', 'Resources', 'Single Nucleotide Polymorphism', 'Sleep', 'Solid', 'Source', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Validation', 'Visit', 'Work', 'base', 'cohort', 'cost effective', 'data structure', 'database of Genotypes and Phenotypes', 'experience', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'graduate student', 'improved', 'interest', 'meetings', 'repository', 'scale up', 'software development', 'symposium', 'text searching', 'tool', 'trait', 'usability', 'web site']",NHLBI,UNIVERSITY OF SOUTHERN CALIFORNIA,UH2,2011,447457,0.02685480022176537
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,8035949,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'amplisome', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,321670,-0.013382918288155563
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,8133157,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2011,218724,0.009123670646845421
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,8306467,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Institutional Review Boards', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2011,13000,0.014974858428830057
"Genometric analysis of quantitative traits Methods Development  Because non-independence of marker data is particularly relevant in next generation sequencing data, most of the theoretical work during the past year has focused on the development, testing and implementation of Tiled regression, a linear regression based method for intra-familial tests of association that address non-independence both at the marker and observational level.  Tiled regression uses multiple and stepwise regression methods in predefined segments of the genome, defined by hotspot blocks, to identify independent sequence variants responsible for the variation or susceptibility in quantitative and qualitative traits, respectively.  Multiple, stepwise (and other) regression methods are used to test for associations on the sequence variants in each tile to select the independent markers within each tile.  Higher order regressions are then used to identify significant variant across tiles, chromosomes and the entire genome.  Quantitative and qualitative traits can be analyzed.  With this approach, it becomes practical to analyze hundreds of thousands or millions of markers and their significant gene x gene interaction terms.  This approach can substantially reduce the total number of tests to a number closer to the number of tiles rather than the number of markers.  Furthermore, the tiled approach can be incorporated into a linear regression framework that allows for non-independence between observations incorporating features from the Regression of Offspring on Mid-Parant (ROMP) and Generalized Estimating Equations approaches.    The tiled regression method was tested with simulated mini-exome sequence data as part of the Genetic Analysis Workshop 17 and results are presented in detail in Sung et al. BMC Proc, 2011.  The most striking finding from this analysis was that methods that use simple linear regression without considering correlations between markers have estimated type I error rates (false positive rates) that are inflated by as much as three orders of magnitude (up to 1000 times) higher than their expected type I error rates depending on the underlying genetic model.  The magnitude of the increase appears to be related to the correlations due to unknown causal variants that contribute to a quantitative trait.  This suggests that even with permutation tests, the type I error rate for the analysis of sequence data with GWAS methods may be substantially inflated if the marker-marker correlations are ignored, generating thousands of false positive results.  Because the tiled regression method identifies only independent sequence variants, the type I error rate is stable regardless of the underlying genetic model.  Permutation tests using the tiled regression method should yield appropriate type I error rates.  This approach has been applied to both SNP data from fine mapping SNP studies with the scoliosis data in collaboration with Dr. Nancy Miller (U of Colorado) two manuscripts submitted,2011, and two targeted candidate gene sequencing projects, an NF1 project in collaboration with Dr. Douglas Stewart and the ClinSeq project, in collaboration with Dr. Les Biesecker .  In 2011 the tiled regression methodology was implemented in TRAP, a software package written in the freely available R language.  The package is freely available on the NHGRI website: http://research.nhgri.nih.gov/software/TRAP.  Two other projects involved the simulated mini-exome sequence data from Genetic Analysis Workshop 17 and the findings are now in press.  As part of the first project Simpson et al, BMC Proc 2011 we evaluated intrafamilial tests of associations in order to compare the statistical properties of likelihood based and regression of offspring based (ROMP) methods.  In the samples considered, both methods were able to detect causal sequence variants with locus specific heritabilities greater than about 0.1, but neither method was able to detect causal variants with locus specific heritabilities near 0.  There was some inflation of the type I error rates for both methods.  In the second project Kim et al. BMC Proc 2011, we evaluated machine learning methods to detect associations in the GAW 17 simulated data.  These methods did not provide any substantial advantage over more traditional methods, although interaction effects, the strength of the learning machine methods, were not included in the underlying simulation model.   Collaborations  Familial Idiopathic Scoliosis  Several analyses focusing on candidate regions and phenotypic subsets have been completed and manuscripts have either been submitted or are in preparation. These included:  1) Statistical genetic analysis of two sets of families with familial idiopathic scoliosis with characteristics nearly identical to those of the sample analyzed in Miller et al. 2005.  Linkage analysis and tests of association were performed in two regions on chromosome 1, previously identified as primary candidate regions.  We have identified several regions of interest for subsequent nextgen sequencing Behnemann, doctoral thesis, anticipated 2011.  2) Targeted sequencing of the IRX gene family in families with kyphoscoliosis.  We have identified an association between kyphoscoliosis and a sequence variant in an upstream conserved region of one of the IRX genes.  Association analysis resulted in 12 SNPs with p-values < 0.025, of which 11 are  500 kb from IRX1, including the most significant SNP (p = 0.000382).  One of these SNPs is in a HCNR sharing 87% sequence identity with a HCNR upstream from IRX3 on 16q12 Justice et al. submitted.  3) Statistical genetic analysis of STRPs and SNPs on chromosomes 9 and 16.  Fine mapping on chromosomes 9 and 16 was performed to narrow previously identified candidate regions.  Linkage and association studies identified several highly significant regions that are candidates for next generation sequencing Miller et al., submitted.  4) A study based on the presence of males with severe scoliosis Miller et al., submitted.  The males with severe curve subset was comprised of 25 families (207 individuals) in which at least one male was diagnosed in adolescence with a &#8805;30 lateral curvature.  The genome-wide linkage analysis for the qualitative and quantitative traits resulted in significant p-values (2 adjacent markers with p-values < 0.01) on chromosomes 2, 16 and 22.  Significant SNPs lie primarily in the introns of the LARGE gene, integral to the development and maintenance of skeletal muscle, and SFI1, responsible for the integrity of the chromosomal centromere complex.   Other large ongoing collaborations include:  1) Clinical characterization of NF1 (Dr. Douglas Stewart, NIH/NCI)  2) the ClinSeq project (Les Biesecker, NIH/NHGRI)  3) the GeneSTAR project (Drs. Diane and Lewis Becker, Johns Hopkins University School of Medicine) Mathias et al., 2010  4) Variation in metabolites in the Irish (Dr. Larry Brody, NIH/NHGRI) n/a",Genometric analysis of quantitative traits,8349989,ZIAHG000200,"['16q12', 'Address', 'Adolescence', 'Candidate Disease Gene', 'Case-Control Studies', 'Centromere', 'Characteristics', 'Chromosomes', 'Chromosomes, Human, Pair 1', 'Chromosomes, Human, Pair 2', 'Chromosomes, Human, Pair 9', 'Clinical', 'Collaborations', 'Colorado', 'Complex', 'Computer Simulation', 'Computer software', 'DNA Markers', 'Data', 'Dependency', 'Development', 'Diagnosis', 'Economic Inflation', 'Educational workshop', 'Employee Strikes', 'Equation', 'Family', 'Gene Family', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Heterogeneity', 'Genetic Models', 'Genome', 'Goals', 'Heritability', 'Idiopathic scoliosis', 'Individual', 'Introns', 'Language', 'Lateral', 'Linear Regressions', 'Linkage Disequilibrium', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Maps', 'Methodology', 'Methods', 'National Human Genome Research Institute', 'Nature', 'Population', 'Predisposition', 'Preparation', 'Property', 'Quantitative Genetics', 'Research', 'Research Design', 'Sampling', 'Sequence Analysis', 'Simulate', 'Single Nucleotide Polymorphism', 'Single Nucleotide Polymorphism Map', 'Skeletal Muscle', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States National Institutes of Health', 'Universities', 'Variant', 'Work', 'Writing', 'base', 'density', 'exome', 'genetic analysis', 'genetic linkage analysis', 'genome wide association study', 'genome-wide linkage', 'insight', 'interest', 'male', 'medical schools', 'method development', 'models and simulation', 'next generation', 'offspring', 'population based', 'scoliosis', 'simulation', 'statistics', 'trait', 'web site']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2011,1705216,0.02690717672219234
"Developing Stats Methods to Detect Rare Genetics Variants in Human Pedigrees Next-generation sequencing technologies coupled with the efficient DNA capture methods provide exome sequencing approach to investigate the genetic basis of complex phenotypes. Unlike whole genome association studies (GWAS) which can only discover variation in DNA that is frequent in the population (great than 1%), exome sequencing is a great choice for scientists today who might be interested in looking for rare mutations. Furthermore, exome sequencing has the advantage of testing comprehensively the role of coding variation, both common and rare. It is anticipated that every gene may harbor functionally relevant variants.   Recently, a number of statistical methods become available for analyzing the contribution of rare variants to the development of complex traits. These methods include Combined Multivariate and Collapsing (CMC) Method, Multivariate test of collapsed sub-groups Hotelling T2 test, MANOVA, Fishers product method, Weighted Sum Method and Kernel-based adaptive test. While the merits of these methods have been evaluated extensively for population-based association studies, none of these methods in their current form can be used to analyze the pedigree based association analysis using exome sequencing data.   We will develop pedigree-based rare variants analysis approach by treating each affected relatives as dependent pairs and the dependency will be accounted for using correlation matrix. Under the null hypothesis of no association of a set of rare variants with the diseases, the new statistic we have developed is asymptotically distributed as a central distribution.  Further, we will use the estimated IBD based weights to account for the dependency of the related affected or unaffected pairs generated from same pedigrees. This method will be used to analyze approximately bipolar disorder pedigrees with exome data. Simulation studies will be used for determining power and type I errors. This method will be used to analyze approximately 100 bipolar disorder pedigrees with exome data as well as data sets with other mental disorders in the future. n/a",Developing Stats Methods to Detect Rare Genetics Variants in Human Pedigrees,8342188,ZIAMH002930,"['Accounting', 'Affect', 'Base Sequence', 'Bipolar Disorder', 'Code', 'Complex', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dependency', 'Development', 'Disease', 'Disease model', 'Family', 'Future', 'Genes', 'Genetic', 'Genomics', 'Human', 'Individual', 'Literature', 'Machine Learning', 'Mental disorders', 'Methods', 'Mutation', 'Phenotype', 'Population', 'Relative (related person)', 'Research Design', 'Role', 'Scientist', 'Statistical Methods', 'Sum', 'Technology', 'Testing', 'Variant', 'Weight', 'Work', 'base', 'design', 'exome', 'genetic linkage analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'interest', 'large scale simulation', 'next generation', 'novel', 'population based', 'simulation', 'statistics', 'tool', 'trait']",NIMH,NATIONAL INSTITUTE OF MENTAL HEALTH,ZIA,2011,176114,0.04510768184172135
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8321717,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,342218,-0.017254396197076586
"A Comprehensive catalog of human DNasel hypersensitive sites The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNasel hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNasel hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5). n/a",A Comprehensive catalog of human DNasel hypersensitive sites,8320051,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Insulator Elements', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Molecular', 'Noise', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Predictive Value', 'Preparation', 'Production', 'Public Domains', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'cost effective', 'density', 'design', 'digital', 'experience', 'functional genomics', 'genome-wide', 'high standard', 'high throughput screening', 'histone modification', 'human tissue', 'in vivo', 'insight', 'meetings', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2011,2615448,-0.017254396197076586
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant): Our group focuses on genetic variants that disrupt molecular functions that cause human disease. In this renewal R01 application, we propose to begin the process of realizing our long-term goals, and to expand our original scope of research to include the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation in noncoding regions. Additionally, we have formed collaborations with genetic data managers and will apply these methods to aid in their research and identify new testable hypotheses. We will do this in three aims. First, we will integrate predictions of protein-disease associations with mutation predictions to develop a new quantitative model of genotype and phenotype. Second, we will integrate each of these together to develop a systems level, molecular function genome annotator with functionality to import into the genome databases. Finally, we will continue to build new methods for characterization of mutations using sequence, function and structure and begin testing our published hypotheses. Each of these aims will include collaboration with the maintainers of genetic datasets to better understand their underlying molecular effects.           PrjctNrrative Tis cmetigrnwlR1aims t nerstn owgntic vritindat iscvrdi gnom sqecin  effortsdisrpts mlclr fnctinad te tsts wetertesemlclr fnctindisrptigvrintsar  mreliklytola to umn gneticdisaseusigbiiformtics.",Informatic profiling of clinically relevant mutation,8238173,R01LM009722,"['Affect', 'Algorithms', 'Amino Acid Substitution', 'Area', 'Bioinformatics', 'Biomedical Research', 'Classification', 'Code', 'Collaborations', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Disease Association', 'Disease model', 'Feedback', 'Focus Groups', 'Functional RNA', 'Funding', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Sequence Databases', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Hereditary Disease', 'Human', 'Human Genome', 'Individual', 'Informatics', 'Inherited', 'Internet', 'Laboratories', 'Leadership', 'Left', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Pharmacogenetics', 'Phenotype', 'Process', 'Proteins', 'Publishing', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Role', 'Science', 'Scientist', 'Staging', 'Structure', 'System', 'Testing', 'Transcript', 'Untranslated Regions', 'Variant', 'Work', 'base', 'cancer genome', 'career', 'clinically relevant', 'data management', 'disease phenotype', 'disease-causing mutation', 'exome', 'genetic regulatory protein', 'genetic variant', 'genome database', 'genome sequencing', 'human disease', 'improved', 'innovation', 'multidisciplinary', 'novel', 'novel strategies', 'protein structure function', 'software development', 'tool', 'user-friendly']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2011,500661,0.008010808593222854
"Statistical Methods for Correlated and High-Dimensional Biomedical Data We propose in the renewal of this MERIT award application to continue developing advanced statistical and computational methods for analysis of correlated and high-dimensional data, which arise frequently in health science research, especially in cancer research. Correlated data are often observed in observational studies and clinical trials, such as longitudinal studies and familial studies. High-dimensional data have emerged rapidly in recent years due to the advance of high-throughput 'omics technologies, e.g, in Genome- Wide Association Studies (GWAS), and genome-wide epigenetic (DNA methylation) studies. Massive next generation sequencing data are soon available. There is an urgent need to develop advanced stati stical and computational methods for analyzing such high throughput 'omics data in observational studies and clinical trials. We propose to develop statistical and computational methods for analysis of (1) genome-wide association studies; (2) sequencing data for studying rare variant effects; (3) genome-wide DNA methylation studies; (4) gene-gene and gene-environment interactions. We will develop methods for both case-control studies and cohort studies, such as longitudinal studies and survival studies. We will study the theoretical properties of the proposed methods and evaluate the finite s ample performance using simulation studies. We will develop efficient numerical algorithms and user-friendly statistical software, and disseminate these tools to health sciences researchers. In collaboration with biomedical investigators, we will apply the proposed models methods to data from several genome-wide epidemiological studies in cancer and other chronic diseases. RELEVANCE (See instructions):  Development of new statistical methods for analysis of correlated and high-dimensional data will provide  powerful analytic tools to advance 'omics research in observational studies and clinical trials and to help  understand the roles of genes, gene products, and the environment in causing human diseases.",Statistical Methods for Correlated and High-Dimensional Biomedical Data,8117858,R37CA076404,"['Advanced Development', 'Aging', 'Algorithms', 'Award', 'Biomedical Research', 'Case-Control Studies', 'Childhood', 'Chronic Disease', 'Clinical Treatment', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Computer software', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Development', 'Dimensions', 'Disease', 'Environment', 'Epidemiologic Studies', 'Epigenetic Process', 'Etiology', 'Explosion', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health Sciences', 'Human Genome', 'Instruction', 'Intervention', 'Investigation', 'Knowledge', 'Longitudinal Studies', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Measures', 'Messenger RNA', 'Methods', 'Modeling', 'Observational Study', 'Performance', 'Prevention strategy', 'Property', 'Proteins', 'Public Health Schools', 'Research', 'Research Personnel', 'Role', 'Scientist', 'Single Nucleotide Polymorphism', 'Statistical Computing', 'Statistical Methods', 'Techniques', 'Technology', 'Testing', 'Theoretical Studies', 'Variant', 'anticancer research', 'cancer risk', 'case control', 'computer science', 'computerized data processing', 'epigenomics', 'gene environment interaction', 'gene interaction', 'genome wide association study', 'genome-wide', 'health science research', 'high throughput analysis', 'human disease', 'malignant breast neoplasm', 'new technology', 'next generation', 'novel', 'programs', 'simulation', 'tool', 'user-friendly']",NCI,HARVARD SCHOOL OF PUBLIC HEALTH,R37,2011,308344,0.017291312179240306
"Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies    DESCRIPTION (provided by applicant): Common mental disorders such as Alzheimer's disease and schizophrenia are largely heritable with complex genetic underpinnings. Large-scale genome-wide association studies that contrast DNA sequence data from patients and controls have recently identified novel genetic risk variants for these disorders. Nevertheless, the processes through which genotype increases risk are yet to be fully characterized.  Neuroimaging offers a richer picture of the underlying disease processes than a clinical diagnosis. Thus the joint analysis of neuroimaging and genetics data promises to advance our understanding of these processes. Today, neuroimaging genetics studies however face important challenges that obstruct progress: small sample sizes, modest effect sizes, and the extreme dimensionality of the data limit statistical power and thus our ability to explore the complex and subtle associations between genes, neuroanatomy and clinical decline. Currently, the prevalent approach in neuroimaging genetics is to concentrate the analysis on a small number of anatomic regions of interest and/or candidate genes and often ignore a large portion of the data. The core goal of the proposed project is to develop computational tools that will take full advantage of the richness in the datasets and facilitate the exploration of the multifaceted associations between genotype, neuroimaging measurements and clinical phenotype. The proposed project will use advanced multivariate pattern analysis methods such as support vector machines to compute image-based and genetic scores that reflect pathology. We will validate the tools based on their association with classical biomarkers of disease. Finally, we will develop a model that uses both imaging and genotype data to predict future clinical outcome. We expect these tools will enable progress along three directions relevant to complex mental disorders, e.g. late-onset Alzheimer's disease (AD): (1) confirming and characterizing risk genes, (2) identifying disease-specific anatomical alterations in healthy individuals, and (3) early diagnosis and prognosis. The project will (1) use three already-collected large-scale datasets to apply the developed tools to AD, (2) build on cutting-edge image processing algorithms that we have been developing, and (3) allow the candidate to receive further training in neuroanatomy, mental disorders and genetics, forming the foundation for his future career as an independent researcher.      PUBLIC HEALTH RELEVANCE: Project Narrative/Relevance We will develop computational tools for analyzing complex associations between images, genotype and clinical phenotype. The tools will be user-friendly and freely available, and will potentially facilitate accurate early diagnosis and prognosis of mental disorders such as Alzheimer's.             n/a",Multivariate Pattern Analysis Methods for Neuroimaging Genetics Studies,8165447,K25EB013649,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Anatomy', 'Biological Markers', 'Brain', 'Candidate Disease Gene', 'Clinical', 'Clinical Trials', 'Cognitive', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Dementia', 'Development', 'Disease', 'Early Diagnosis', 'Event', 'Exhibits', 'Face', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Research', 'Genetic Risk', 'Genotype', 'Goals', 'Hereditary Disease', 'Hippocampus (Brain)', 'Image', 'Individual', 'Joints', 'Late Onset Alzheimer Disease', 'Lead', 'Logistic Regressions', 'Machine Learning', 'Measurement', 'Mental disorders', 'Methods', 'Mining', 'Modeling', 'Motivation', 'Neuroanatomy', 'Neurodegenerative Disorders', 'Outcome', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Probability', 'Process', 'Recruitment Activity', 'Research Personnel', 'Risk', 'Sample Size', 'Schizophrenia', 'Testing', 'Thick', 'Training', 'Variant', 'base', 'career', 'clinical Diagnosis', 'clinical phenotype', 'computerized tools', 'data modeling', 'disorder risk', 'entorhinal cortex', 'genetic risk factor', 'genetic variant', 'genome wide association study', 'high risk', 'image processing', 'improved', 'in vivo', 'interest', 'mild neurocognitive impairment', 'molecular pathology', 'neuroimaging', 'novel', 'outcome forecast', 'pre-clinical', 'programs', 'tool']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,K25,2011,175392,-0.03339431101612196
"Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning    DESCRIPTION (provided by applicant):       Epistasis is the interaction between two or more genes to affect phenotype. It is now widely accepted that epistasis plays an important role in susceptibility to many common diseases. The advent of high-throughput technologies has enabled genome-wide association studies (GWAS or GWA studies). It is compelling that we be able to detect epistasis using GWAS data. However, so far GWA studies have mainly focused on the association of a single gene or loci with a disease. The crucial challenge to analyzing epistasis using GWAS data is finding a way to efficiently handle high-dimensional data sets. The only possible solution is to design efficient algorithms that allow us to find the most relevant epistasic relationships without doing an exhaustive investigation. To the Principal Investigator's knowledge, no current method can do this.       This career award will investigate this problem. The specific aims are as follows: (Aim 1) develop and evaluate efficient Bayesian network-based methods for learning candidate genes associated with diseases from GWAS sets. Such genes would provide candidates for follow-up biological studies, (Aim 2) implement the methods in a pilot GWAS system for use by researchers when conducting a GWAS, (Aim 3) develop simulated genome-wide data sets and evaluate the pilot system using these data sets, and (Aim 4) conduct GWA studies concerning breast cancer and lung cancer.       Aim 1 will be addressed by developing a succinct Bayesian network model representing epistasis, efficient algorithms which are tailored to investigating such models, integration of the algorithms into methods for learning epistasis, and using simulated datasets to test the effectiveness of the methods and compare their performance to other methods. Aim 2 will be met by implementing the methods in a pilot GWAS system. Aim 3 will be satisfied by developing synthetic data sets similar to those found in GWA studies, and using them to evaluate the system. Aim 4 will be achieved by conducting GWA studies concerning breast and lung cancer. By conducting these studies, we can (1) substantiate previous results concerning the genetic basis of these diseases; (2) possibly obtain interesting new findings pertaining to these diseases.       The main hypothesis is that the proposed method will be an advance over existing methods in that it will make it computationally feasible to learn epistatic relationships from genome-wide data and it will therefore yield better discovery performance than existing methods.              Learning gene-gene interactions from genome-wide association studies (GWAS) data is an important and challenging task in genetic epidemiology. This project will develop and evaluate a pilot GWAS system for performing this task. Advances obtained in analyzing GWAS data sets could enable us to learn the genetic basis of many diseases and thereby substantially improve the quality of personalized patient care.",Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning,8145599,K99LM010822,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Award', 'BRCA1 gene', 'BRCA2 gene', 'Biological', 'Biological Neural Networks', 'Cancer-Predisposing Gene', 'Candidate Disease Gene', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Effectiveness', 'Family history of', 'GAB2 gene', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Programming', 'Germ-Line Mutation', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Network-based', 'Patient Care', 'Performance', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Regression Analysis', 'Research', 'Research Personnel', 'Role', 'Simulate', 'Site', 'Solutions', 'Statistical Methods', 'System', 'Testing', 'Woman', 'Work', 'base', 'cancer cell', 'career', 'combinatorial', 'computer based statistical methods', 'data mining', 'design', 'follow-up', 'forest', 'gene interaction', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high throughput technology', 'improved', 'interest', 'malignant breast neoplasm', 'meetings', 'network models']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2011,90000,0.012744923312194394
"Methods for high-resolution analysis of genetic effects on gene expression    DESCRIPTION (provided by applicant):    Summary Gene expression is a fundamental function of any cell. It is the main mechanism by which information is transmitted from the nucleus to the rest of the cell and eventually to other cells and the body of the organism. Genetic variation in components of the transcriptional machinery and signals that regulate gene function generates variation in transcriptional response and consequently variation in phenotypes. It has become apparent that many of the common genetic signals associated with disease are found away from the DNA sequence that encodes for protein sequence and is likely to be functioning in regulating gene expression. In this project we propose to develop methodologies that will explore the consequences of genetic variation in gene expression. There are three main goals of this project. First we will explore and develop methodologies to mine information from experiments that perform deep sequencing of the human transcriptome. The new sequencing technologies are providing us with unprecedented resolution into the transcriptome but are also raising challenges in the computational and biological models to use to interpret such large amounts of data. Secondly, we will use high-resolution genetic data to develop and use methodologies to dissect the fine structure of genetic variants that affect regulation of gene expression. Finally, we will implement and test models to infer the higher-order interactions of genome function so as to dig deeply into the biological consequences of genetic variants and how the signal is transmitted from the DNA sequence to higher levels of cell and body function. Our goals is to develop methodologies that will significantly improve our insight to the variability in human populations and assist in interpreting predisposition to genetic diseases.      PUBLIC HEALTH RELEVANCE:    Project narrative The proposed project aims at the development of statistical methods for the interpretation and study of the impact of genetic variants in cell function. Understanding the cellular effects of genetic variants provides a fundamental framework for the deep understanding of human genetic disease and increases the potential for the development of relevant treatments and drugs. It is the understanding of the basic molecular functions in health and disease that will provide the utmost resolution of information for the improvement of human health.           Project narrative The proposed project aims at the development of statistical methods for the interpretation and study of the impact of genetic variants in cell function. Understanding the cellular effects of genetic variants provides a fundamental framework for the deep understanding of human genetic disease and increases the potential for the development of relevant treatments and drugs. It is the understanding of the basic molecular functions in health and disease that will provide the utmost resolution of information for the improvement of human health.",Methods for high-resolution analysis of genetic effects on gene expression,8144831,R01MH090941,"['Accounting', 'Affect', 'Alleles', 'Alternative Splicing', 'Amino Acid Sequence', 'Biochemical', 'Biological', 'Biological Models', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Complex', 'Computer Simulation', 'DNA', 'DNA Resequencing', 'DNA Sequence', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Interphase Cell', 'Linkage Disequilibrium', 'Location', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Nucleotides', 'Organism', 'Pattern', 'Peptide Sequence Determination', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Property', 'RNA Sequences', 'Relative (related person)', 'Resolution', 'Sampling', 'Signal Transduction', 'Simulate', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Transcript', 'Variant', 'Work', 'base', 'cell type', 'density', 'gene function', 'genetic analysis', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'insight', 'network models', 'neuronal cell body', 'programs', 'protein protein interaction', 'public health relevance', 'reconstruction', 'research study', 'response', 'simulation', 'trait']",NIMH,UNIVERSITY OF GENEVA,R01,2011,315416,-0.011874696602513219
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.      PUBLIC HEALTH RELEVANCE:  Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,            Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8242999,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2011,2416667,0.004934595311732094
"EMR Phenotype and Community Engaged Genomic Associations    DESCRIPTION (provided by applicant): The electronic medical record (EMR) can be leveraged for high throughput phenotyping of large numbers of patients for genomics research. As part of eMERGE-l, we used EMR-based algorithms to enable genome- wide association studies (GWAS) of several primary and network-wide phenotypes. The present application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. The Mayo eMERGE-ll cohort (n=6916) includes the 3769 eMERGE-l patients and an additional 3147 individuals, the majority (90%) genotyped on the same lllumina 660W platform. We will work with other eMERGE-ll sites to expand and validate the library of electronic phenotyping algorithms to enable GWAS of multiple phenotypes of interest. A major focus of our application is to translate recent GWAS findings to clinical practice. Our specific aims are: Specific aim 1. Conduct EMR-based GWAS to identify common genetic variants that influence a) inter-individual variation in cardiorespiratory fitness and response to statin medications and b) susceptibility to venous thromboembolism and colon polyps. Specific aim 2. Quantify genetic risk of a common 'complex' disease - coronary heart disease (CHD) - and an adverse drug response - statin myopathy. We will develop risk communication tools that convey the clinical and genetic components of risk to both patients and care providers. Specific aim 3. Develop informatics approaches to incorporate genomic data into the EMR, including links to clinical decision support. Specific aim 4. Conduct a randomized-clinical trial to investigate how patients respond to genetically informed CHD-risk. We will re-consent 150 eMERGE-l patients without CHD, communicate the results via a genetic counselor, and discuss in detail the implications of the testing relevant to disease risk. The effectiveness of the communication and the patients' comprehension of risk, their hopes and concerns, and planned changes in lifestyle will be assessed by surveys and interviews after the patient-counselor encounter. As part of our ongoing efforts in community consultation, we will establish a community advisory group specific to this project.       RELEVANCE (See instructions): The proposed application will leverage the research infrastructure established in eMERGE-l to identify common genetic variants that influence medically important phenotypes. We will develop tools to incorporate genomic information in the EMR. In addition, we will investigate clinical, translational, and ethical aspects of genetic testing for complex diseases and assess the response of patients to genetic testing.              n/a",EMR Phenotype and Community Engaged Genomic Associations,8193561,U01HG006379,"['Address', 'Algorithms', 'Area', 'Atrial Fibrillation', 'Bioethics', 'Cardiology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Colonic Polyps', 'Communication', 'Communication Tools', 'Communities', 'Complex', 'Comprehension', 'Computerized Medical Record', 'Consent', 'Coronary heart disease', 'Data', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Dose', 'Drops', 'Drug usage', 'Early Diagnosis', 'Effectiveness', 'Electronic library', 'Empirical Research', 'Epidemiologist', 'Ethical Issues', 'Ethics', 'Future', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Individual', 'Informatics', 'Instruction', 'Interview', 'Knowledge', 'Laboratories', 'Libraries', 'Life Style', 'Link', 'Medicine', 'Methods', 'Myopathy', 'Natural Language Processing', 'Patient Care', 'Patients', 'Perception', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Predisposition', 'Preventive', 'Principal Investigator', 'Procedures', 'Professional counselor', 'Provider', 'Public Health', 'Publishing', 'Randomized Clinical Trials', 'Research', 'Research Infrastructure', 'Risk', 'Risk Factors', 'Scientist', 'Screening procedure', 'Site', 'Staging', 'Surveys', 'Testing', 'Text', 'Thromboembolism', 'Translating', 'Variant', 'Venous', 'Work', 'adverse outcome', 'base', 'clinical practice', 'cohort', 'community consultation', 'cost', 'disorder risk', 'exome', 'experience', 'fitness', 'genetic risk assessment', 'genetic variant', 'genome wide association study', 'heart disease risk', 'interest', 'open source', 'point of care', 'repository', 'response', 'tool']",NHGRI,MAYO CLINIC ROCHESTER,U01,2011,788498,0.024116369211643972
"Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform    DESCRIPTION (provided by applicant): DNAnexus proposes to develop a complete solution for the identification and stratification of personal genetic variation from ultra-high-throughput sequencing projects. The solution will be implemented as a Web 2.0 service and online browsing tool that will integrate public data sources such as the 1000 genomes project, comparative information, and the ENCODE II project data. Users will be able to browse and stratify the identified variation in the context of these genomic annotations, and according to the likely functional impact. In Phase I of our project, we will develop a basic browser for displaying sequence reads that are mapped to a reference genome with our state-of-the-art read mapper. The browser will support viewing mate paired reads as well as display of the variation between these reads and the reference genome. It will facilitate the algorithmic development that we will perform during Phase II, and it will be the foundation for the more sophisticated variation browser also proposed in Phase II. In Phase II, we will develop algorithms for detecting genomic variation, and a state-of-the-art browser for viewing variation in the context of existing genome annotations, functional genomic and comparative genomic data. Our algorithms for detecting variation will support all major types of genomic variation, including SNPs, microindels, larger insertions and deletions, duplications, copy number variations, inversions, and translocations. Our algorithms will be based on state-of-the-art statistical and machine learning methodology for human genome resequencing. The DNAnexus browser will have two components: a list browser that displays variation as a list filtered and stratified by criteria that a user chooses, and a powerful GUI whose navigation capabilities are inspired by modern online tools such as Google Maps.      PUBLIC HEALTH RELEVANCE: DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.           Project Narrative DNAnexus proposes to develop a complete solution for identifying and analyzing personal genetic variation for individuals whose genomes are sequenced using new sequencing technologies. Users will be able to browse an individual genome in the context of public data sources such as the 1000 genomes project, comparative information to other mammalian species, and functional data from the ENCODE II project.",Human Variation Detection and Visualization on the DNAnexus Web 2.0 platform,7909096,R43HG005794,"['Algorithms', 'Architecture', 'Arts', 'Code', 'Copy Number Polymorphism', 'DNA Resequencing', 'Data', 'Data Display', 'Data Sources', 'Data Storage and Retrieval', 'Detection', 'Development', 'Environment', 'Foundations', 'Genes', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Human Genome', 'Imagery', 'Individual', 'Internet', 'Machine Learning', 'Maps', 'Methodology', 'Partner in relationship', 'Phase', 'Point Mutation', 'Reading', 'Services', 'Solutions', 'Statistical Methods', 'Stratification', 'Technology', 'Variant', 'base', 'comparative', 'comparative genomics', 'cost', 'flexibility', 'functional genomics', 'genome sequencing', 'graphical user interface', 'insertion/deletion mutation', 'public health relevance', 'tool']",NHGRI,"DNANEXUS, INC.",R43,2010,74477,0.030501110494241455
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7913074,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,1248287,0.020214231990030935
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8121894,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,300000,0.020214231990030935
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8144973,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,113520,0.020214231990030935
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8147585,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,151816,0.020214231990030935
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7930715,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Other Genetics', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'flexibility', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'non-genetic', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2010,288566,0.036522040108408226
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7902231,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative genomics', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2010,346884,-0.0007904547136044258
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7795846,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,326175,-0.013382918288155563
"Computational Strategies for Quantitative Mapping of Genetic Interaction Networks    DESCRIPTION (provided by applicant): Recent studies suggest that many diseases, particularly those that commonly afflict our population, result from interactions among multiple alleles. In an attempt to understand these complex phenotypes, recent experimental efforts in model organisms have focused on measuring such interactions by engineering combinatorial genetic perturbations. Due to the enormous space of possible mutants, brute-force experimental investigation is simply not feasible, and thus, there is a critical need for computational strategies for intelligent exploration of genetic interaction networks. The specific objective of this application is to develop a computational framework for leveraging the existing genomic or proteomic data to enable intelligent direction of combinatorial perturbation studies. The rationale for the proposed research is that although current knowledge of genetic interactions is sparse, the integration of existing genomic and proteomic data can enable the inference of network models that suggest promising candidates for high-throughput interaction screens. Using such computational guidance should enable more efficient characterization of network structure, and ultimately, better understanding of how genes contribute to complex phenotypes.  Based on strong findings in preliminary studies, this objective will be accomplished through two specific aims: (1) development of critical normalization methods and quantitative models for colony array-based interaction assays, and (2) novel machine learning-based approaches for iterative model refinement and optimal interaction screen selection.  The proposed research is innovative because it would represent one of the first efforts to couple genomic data integration and network inference technology with a large-scale experimental effort, where several months of experimental investigation are based entirely on computational direction. Such an approach will yield insight into how combinatorial perturbations can be used to characterize global modularity and organization, and more generally, would serve as a prototype for hybrid computational-experimental strategies in other genomic contexts.      PUBLIC HEALTH RELEVANCE: Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.           Project Narrative: Computational Strategies for Mapping Genetic Interaction Networks Many common diseases result from interactions among multiple genes. One approach to studying multigenic interactions is to introduce combinations of mutations in model organisms and observe how they affect the cell. This project proposes to develop computational strategies to guide and interpret these combinatorial perturbation studies, which will ultimately help us better understand and treat multigenic diseases.",Computational Strategies for Quantitative Mapping of Genetic Interaction Networks,7887777,R01HG005084,"['Accounting', 'Affect', 'Alleles', 'Animal Model', 'Area', 'Attention', 'Biological', 'Biological Assay', 'Biological Process', 'Buffers', 'Cell physiology', 'Cells', 'Chad', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Coronary heart disease', 'Coupling', 'Data', 'Data Set', 'Development', 'Disease', 'Engineering', 'Evaluation', 'Feedback', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Gold', 'Growth', 'Hybrids', 'Imagery', 'Internet', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Mutation', 'Organism', 'Outcome', 'Phenotype', 'Plague', 'Population', 'Property', 'Proteins', 'Proteomics', 'Quantitative Genetics', 'Recommendation', 'Research', 'Resources', 'Sensitivity and Specificity', 'Structure', 'Study Section', 'Systems Biology', 'Technology', 'Training', 'Work', 'Yeasts', 'base', 'combinatorial', 'computer framework', 'data integration', 'disease phenotype', 'effective therapy', 'gene function', 'genetic variant', 'genome wide association study', 'high throughput technology', 'human disease', 'innovation', 'insight', 'lens', 'mutant', 'network models', 'novel', 'prototype', 'public health relevance', 'research study', 'yeast genetics']",NHGRI,UNIVERSITY OF MINNESOTA,R01,2010,273884,0.009123670646845421
"Multi-point and multi-locus analysis of genomic association data    DESCRIPTION (provided by applicant):       Genome-wide association studies (GWAS) provide a new and powerful approach to investigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learning approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases.            Principal Investigator/Program Director: Li, Jing Title: Multi-point and multi-locus analysis of genomic association data Abstract: Genome-wide association studies (GWAS) provide a new and powerful approach to inves- tigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learn- ing approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases. PHS 398 Page 1",Multi-point and multi-locus analysis of genomic association data,7897811,R01LM008991,"['Address', 'Advanced Development', 'Affect', 'Algorithms', 'Alleles', 'Architecture', 'Cataloging', 'Catalogs', 'Chromosomes', 'Classification', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Decision Trees', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Environment', 'Environmental Risk Factor', 'Etiology', 'Evaluation', 'Freedom', 'Frequencies', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Recombination', 'Genetic Risk', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Grouping', 'Haplotypes', 'Heart Diseases', 'Heterogeneity', 'Imagery', 'Inherited', 'Intelligence', 'Internet', 'Joints', 'Learning', 'Licensing', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Markov Chains', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Phenocopy', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Procedures', 'Rare Diseases', 'Research Project Grants', 'Risk', 'Role', 'Sampling', 'Scientist', 'Simulate', 'Single Nucleotide Polymorphism', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Trust', 'Uncertainty', 'Weight', 'Work', 'abstracting', 'base', 'case control', 'database of Genotypes and Phenotypes', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genome wide association study', 'genotyping technology', 'hydroxy-aluminum polymer', 'improved', 'markov model', 'neglect', 'novel', 'programs', 'research study', 'software systems', 'tool', 'trait']",NLM,CASE WESTERN RESERVE UNIVERSITY,R01,2010,930276,0.03348254625052932
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7893787,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2010,1512082,0.014974858428830057
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7893787,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2010,205892,0.014974858428830057
"Analysis Tool for Heritable and Envirnonmental Network Associations    DESCRIPTION (provided by applicant):       The efforts of the human genome project are beginning to provide important findings for human health. Technological advances in the laboratory, particularly in characterizing human genomic variation, have created new approaches for studying the human genome. However, current statistical and computational strategies are taking only partial advantage of this wealth of information. In the quest for disease susceptibility genes for common, complex disease, we are faced with many challenges. Selecting genetic, clinical, and environmental factors important for the trait of interest is increasingly more difficult as high throughput data generation technologies are developed. We know that genes do not act in isolation, thus numerous other factors are likely important in complex disease phenotypes. However, techniques for robust statistical modeling of important variables to predict clinical outcomes are limited in their capability for interaction effects. Ultimately, we want to know what factors are important to provide superior prevention, diagnosis, and treatment of human disease. Unfortunately, interpretation of statistical models in a meaningful way for biomedical research has been lacking due to the inherent difficulty in making such connections. Thus, a technology that embraces the complexity of human disease and integrates multiple data sources including biological knowledge from the public domain, through a powerful analytical framework is essential for dissecting the architecture of common diseases. ATHENA: the Analysis Tool for Heritable and Environmental Network Associations is a novel framework that incorporates variable selection, modeling, and interpretation to learn more about diseases of public health interest. As the field gains experience in analyzing large scale genomic data, it is crucial that we learn from each other and develop and codify the best strategies.            Many common, complex diseases are likely due to a combination of genetic and environmental risk factors. Out ability to extract all of the meaningful information from very large genomic and phenotypic datasets has been limited by our analytic strategies. The methodology described in this proposal is a powerful new approach to maximize the information learned from large datasets to improve prevention, diagnosis, and treatment of diseases of public health interest.",Analysis Tool for Heritable and Envirnonmental Network Associations,7860712,R01LM010040,"['Architecture', 'Arts', 'Base Pairing', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Biology', 'Biomedical Research', 'Candidate Disease Gene', 'Clinical', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Environment', 'Environmental Risk Factor', 'Evolution', 'Exhibits', 'Future', 'Generations', 'Genes', 'Genetic', 'Genetic Models', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genome', 'Human Genome Project', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Life', 'Machine Learning', 'Methodology', 'Modeling', 'Noise', 'Outcome', 'Prevention', 'Proteomics', 'Public Domains', 'Public Health', 'Research Personnel', 'Resources', 'Sampling', 'Signal Transduction', 'Simulate', 'Single Nucleotide Polymorphism', 'Solutions', 'Statistical Models', 'Susceptibility Gene', 'Techniques', 'Technology', 'Time', 'Variant', 'Vision', 'base', 'computerized tools', 'disease phenotype', 'disorder risk', 'experience', 'flexibility', 'follow-up', 'gene environment interaction', 'gene interaction', 'genetic analysis', 'genome wide association study', 'human disease', 'improved', 'interest', 'novel', 'novel strategies', 'simulation', 'success', 'tool', 'tool development', 'trait']",NLM,VANDERBILT UNIVERSITY,R01,2010,297123,0.018495441686446477
"VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES    DESCRIPTION (provided by applicant): Cardiovascular diseases (CVD) affect millions of people in US and across the world. There is strong evidence of a genetic component in cardiovascular diseases (CVD) and related traits. An emerging consensus is that both genes and environment and, perhaps more importantly, their interactions are responsible for this complex disease. As a result, many genetic epidemiological (GE) studies of CVD use a study design that tests hundreds of thousands of genetic predictors (e.g., single nucleotide polymorphism (SNP) markers) and hundreds of (related) disease phenotypes and environmental covariates. This has brought tremendous analytical challenges, particularly the high dimensionality of the data and the obscure interactions among the many variables. As a result, searching for CVD disease genes has become a task of selecting important variables from a vast number of SNPs and other predictor variables. Our real data analyses in several ongoing large scale CVD related studies motivated us to consider new methodological solutions to the variable selection problem. This application is developed upon these positive preliminary findings. Our main idea is to develop a strategy for selecting important predictors of CVD by integrating multiple sources of information via the method of statistical learning (i.e., optimizing the selection by repeated learning from examples). In this strategy, we will first develop a method for selecting significant SNPs in moderate-dimensional data (e.g., lower thousands of SNPs, in candidate genes studies) by an integrated classifier. The method will build upon existing techniques assessing information of SNPs in haplotype similarity, imputed functional potential, and gene-gene interactions. We then scale up the new method to the high-dimensional setting of genome-wide association studies (e.g., at least hundreds of thousands of SNPs), by dimension reduction that utilizes the local linkage-disequilibrium (LD) structure in SNPs and by combining latent factor analysis of correlated CVD traits and pathway-based analysis to account for gene-environment (GxE) interactions. A fast-search algorithm will also be developed based on an existing search heuristic that was successfully applied in high-dimensional data of gene expression and genomic sequence analysis. The new methods and algorithms will be coded into R programs and distributed as tool set for an association analysis pipeline. Evaluations of the new methods will be performed by intensive simulation studies and by applying to existing datasets in ongoing studies of CVD and related diseases. Results from evaluation studies, together with the ancillary databases generated by the study such as imputed functional scores of potential or known CVD SNPs will be distributed on a dedicated project website. By doing so, we believe that the utilities resulted from the proposed research will make a significant contribution to many ongoing genetic epidemiological studies of CVD and related traits.  PUBLIC HEALTH RELEVANCE: This project is aimed at timely development of computational tools for emerging large-scale genome-wide association studies of cardiovascular diseases (CVD) that affect millions of people in US and across the world. The new methods deal with the analytical challenges brought forth by the high dimensionality of the data and the obscure interactions among the many variables in these studies, and the tools will be applied to ongoing studies of CVD and related diseases. The results, together with the computer programs and ancillary databases will make a significant contribution to many ongoing and new genetic epidemiological studies of CVD and related diseases.             n/a",VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES,7895861,R01HL091028,"['Accounting', 'Affect', 'Algorithms', 'American', 'Area', 'Blood Vessels', 'Candidate Disease Gene', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosomes', 'Chronic Disease', 'Code', 'Collection', 'Complex', 'Consensus', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease Outcome', 'Environment', 'Epidemiologic Studies', 'Etiology', 'Evaluation', 'Evaluation Studies', 'Exclusion', 'Factor Analysis', 'Functional disorder', 'Gene Expression', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Haplotypes', 'Heart failure', 'Hypertension', 'Hypertrophy', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Left', 'Left Ventricular Hypertrophy', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Noise', 'Pathway interactions', 'Performance', 'Procedures', 'Process', 'Public Domains', 'Research', 'Research Design', 'Sea', 'Sequence Analysis', 'Single Nucleotide Polymorphism', 'Solutions', 'Source', 'Statistical Computing', 'Structure', 'Techniques', 'Testing', 'Variant', 'Ventricular', 'Weight', 'base', 'computer based statistical methods', 'computer program', 'computerized tools', 'disease phenotype', 'experience', 'gene interaction', 'genome wide association study', 'heuristics', 'hypertensive heart disease', 'improved', 'mortality', 'premature', 'prevent', 'programs', 'public health relevance', 'scale up', 'simulation', 'tool', 'trait', 'web site']",NHLBI,WASHINGTON UNIVERSITY,R01,2010,228000,0.009220585659351218
"Methods for high-resolution analysis of genetic effects on gene expression    DESCRIPTION (provided by applicant):    Summary Gene expression is a fundamental function of any cell. It is the main mechanism by which information is transmitted from the nucleus to the rest of the cell and eventually to other cells and the body of the organism. Genetic variation in components of the transcriptional machinery and signals that regulate gene function generates variation in transcriptional response and consequently variation in phenotypes. It has become apparent that many of the common genetic signals associated with disease are found away from the DNA sequence that encodes for protein sequence and is likely to be functioning in regulating gene expression. In this project we propose to develop methodologies that will explore the consequences of genetic variation in gene expression. There are three main goals of this project. First we will explore and develop methodologies to mine information from experiments that perform deep sequencing of the human transcriptome. The new sequencing technologies are providing us with unprecedented resolution into the transcriptome but are also raising challenges in the computational and biological models to use to interpret such large amounts of data. Secondly, we will use high-resolution genetic data to develop and use methodologies to dissect the fine structure of genetic variants that affect regulation of gene expression. Finally, we will implement and test models to infer the higher-order interactions of genome function so as to dig deeply into the biological consequences of genetic variants and how the signal is transmitted from the DNA sequence to higher levels of cell and body function. Our goals is to develop methodologies that will significantly improve our insight to the variability in human populations and assist in interpreting predisposition to genetic diseases.      PUBLIC HEALTH RELEVANCE:    Project narrative The proposed project aims at the development of statistical methods for the interpretation and study of the impact of genetic variants in cell function. Understanding the cellular effects of genetic variants provides a fundamental framework for the deep understanding of human genetic disease and increases the potential for the development of relevant treatments and drugs. It is the understanding of the basic molecular functions in health and disease that will provide the utmost resolution of information for the improvement of human health.           Project narrative The proposed project aims at the development of statistical methods for the interpretation and study of the impact of genetic variants in cell function. Understanding the cellular effects of genetic variants provides a fundamental framework for the deep understanding of human genetic disease and increases the potential for the development of relevant treatments and drugs. It is the understanding of the basic molecular functions in health and disease that will provide the utmost resolution of information for the improvement of human health.",Methods for high-resolution analysis of genetic effects on gene expression,7934780,R01MH090941,"['Accounting', 'Affect', 'Alleles', 'Alternative Splicing', 'Amino Acid Sequence', 'Biochemical', 'Biological', 'Biological Models', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Complex', 'DNA', 'DNA Resequencing', 'DNA Sequence', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Hereditary Disease', 'Human', 'Human Genetics', 'Interphase Cell', 'Linkage Disequilibrium', 'Location', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Nucleotides', 'Organism', 'Pattern', 'Peptide Sequence Determination', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Property', 'Proteins', 'RNA Sequences', 'Relative (related person)', 'Resolution', 'Sampling', 'Signal Transduction', 'Simulate', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Transcript', 'Variant', 'Work', 'base', 'cell type', 'density', 'gene function', 'genetic analysis', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'insight', 'network models', 'neuronal cell body', 'programs', 'protein protein interaction', 'public health relevance', 'reconstruction', 'research study', 'response', 'simulation', 'trait']",NIMH,UNIVERSITY OF GENEVA,R01,2010,332535,-0.011874696602513219
"Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning    DESCRIPTION (provided by applicant):       Epistasis is the interaction between two or more genes to affect phenotype. It is now widely accepted that epistasis plays an important role in susceptibility to many common diseases. The advent of high-throughput technologies has enabled genome-wide association studies (GWAS or GWA studies). It is compelling that we be able to detect epistasis using GWAS data. However, so far GWA studies have mainly focused on the association of a single gene or loci with a disease. The crucial challenge to analyzing epistasis using GWAS data is finding a way to efficiently handle high-dimensional data sets. The only possible solution is to design efficient algorithms that allow us to find the most relevant epistasic relationships without doing an exhaustive investigation. To the Principal Investigator's knowledge, no current method can do this.       This career award will investigate this problem. The specific aims are as follows: (Aim 1) develop and evaluate efficient Bayesian network-based methods for learning candidate genes associated with diseases from GWAS sets. Such genes would provide candidates for follow-up biological studies, (Aim 2) implement the methods in a pilot GWAS system for use by researchers when conducting a GWAS, (Aim 3) develop simulated genome-wide data sets and evaluate the pilot system using these data sets, and (Aim 4) conduct GWA studies concerning breast cancer and lung cancer.       Aim 1 will be addressed by developing a succinct Bayesian network model representing epistasis, efficient algorithms which are tailored to investigating such models, integration of the algorithms into methods for learning epistasis, and using simulated datasets to test the effectiveness of the methods and compare their performance to other methods. Aim 2 will be met by implementing the methods in a pilot GWAS system. Aim 3 will be satisfied by developing synthetic data sets similar to those found in GWA studies, and using them to evaluate the system. Aim 4 will be achieved by conducting GWA studies concerning breast and lung cancer. By conducting these studies, we can (1) substantiate previous results concerning the genetic basis of these diseases; (2) possibly obtain interesting new findings pertaining to these diseases.       The main hypothesis is that the proposed method will be an advance over existing methods in that it will make it computationally feasible to learn epistatic relationships from genome-wide data and it will therefore yield better discovery performance than existing methods.              Learning gene-gene interactions from genome-wide association studies (GWAS) data is an important and challenging task in genetic epidemiology. This project will develop and evaluate a pilot GWAS system for performing this task. Advances obtained in analyzing GWAS data sets could enable us to learn the genetic basis of many diseases and thereby substantially improve the quality of personalized patient care.",Detecting Genome Wide Epistasis with Efficient Bayesian Network Learning,7958949,K99LM010822,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Apolipoprotein E', 'Award', 'BRCA1 gene', 'BRCA2 gene', 'Biological', 'Biological Neural Networks', 'Breast', 'Cancer-Predisposing Gene', 'Candidate Disease Gene', 'Complex', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Effectiveness', 'Family history of', 'GAB2 gene', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Programming', 'Germ-Line Mutation', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Network-based', 'Patient Care', 'Performance', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Regression Analysis', 'Research', 'Research Personnel', 'Role', 'Simulate', 'Site', 'Solutions', 'Statistical Methods', 'System', 'Testing', 'Woman', 'Work', 'base', 'cancer cell', 'career', 'combinatorial', 'computer based statistical methods', 'data mining', 'design', 'follow-up', 'forest', 'gene interaction', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high throughput technology', 'improved', 'interest', 'malignant breast neoplasm', 'meetings', 'network models']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2010,90000,0.012744923312194394
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects has been continued in conjunction with Dr. Betty Doan. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We are currently applying it to Dr. Bailey-Wilson's lung cancer data.  We have previously developed sex-specific single-nucleotide polymorphism quality control filters for use with high density SNP array chip data to help control false positive rates due to poor data quality in genome-wide association studies. A paper presenting this method was published this year (2).  We continue to explore the utility of various machine learning methods in genome-wide association studies, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously used GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. A paper presenting these results was published this year (1). We are continuing to pursue the use of machine learning methods in genomics studies, and are currently evaluating the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17).   We also are using the GAW17 simulated whole-exome sequence (WES) data to develop novel tools for analysis and interpretation of WES data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Development of these analysis methods and tools are ongoing, driven by our own WES and targeted sequence data from multiple studies of complex traits.  Haplotype phase imputation is useful for most haplotype based association tests and for missing genotype imputation. However, phase imputation in extended pedigrees is not trivial. For large haplotype blocks, the number of possible diplotype configurations grows exponentially with the number of markers in the block. There are several haplotype phase estimation or reconstruction algorithms, and a few recent methods handle extended pedigree data. However, haplotypes with rare frequencies are often left out in reconstruction. In application, this can result in misclassification of imputed genotypes. These erroneous genotype assignments are considered particular to individuals, and are usually ignored. Based on population haplotype frequencies, we developed an efficient algorithm to impute phases (and therefore genotypes) for haplotype blocks of up to 8 SNPs, in trios as well as in extended pedigrees. To ensure no individual genotype assignment errors, we consider all possible haplotypes, even those with extremely rare frequencies. We are evaluating our phase imputation method using simulated data with masked genotypes within pedigrees. We are examining the misclassification proportions of imputed genotypes when rare haplotypes are left out, and comparing our methods with other methods: PHASE, HAPLORE, PedPhase, and PhyloPed. We will present this method and results at the upcoming 2010 meetings of the American Society of Human Genetics and the International Genetic Epidemiology Society. This study is ongoing. n/a",Development of statistical genetics methodology,8149420,ZIAHG000153,"['Development', 'Genetic', 'Methodology']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2010,171181,0.022087147877999216
"Machine Learning Analysis of Genetic Modulators of Vaccine Immune Response Abstract Machine Learning Analysis of Genetic Modulators of Vaccine Immune Response. This proposal describes the development of a machine-learning strategy to identify interacting susceptibility loci in polygenic biological endpoints, with a focus on smallpox and anthrax vaccine-related adverse events (AEs) and variation in serologic antibody response. The appearance of AEs following smallpox vaccination stems from excess stimulation of inflammatory pathways and is likely affected by multiple, interacting genetic factors. Some of these gene-gene interactions may be epistatic, having no distinct marginal effect for any single variant. Analytical approaches are needed for testing association in genome-wide data to account for conditional dependencies between genetic variants while still accounting for co-occurring variants with high marginal effects. We have introduced a machine-learning feature selection and optimization method called Evaporative Cooling (EC), which is based on information theory and the statistical thermodynamics of cooling a system of interacting particles by evaporation. The objective of the EC learner is the identification of susceptibility or protective genes in genome-wide DNA sequence data. This novel filter method, which includes no assumptions regarding gene interaction architecture or interaction order, has been shown to identify a spectrum of disease susceptibility models, including marginal main effects and pure interaction effects. Characterizing the genetic basis of multifactorial phenotypes in genome-wide sequence data is also computationally challenging due to the presence of a large number of noise variants, or variants that are irrelevant to the phenotype. Thus, the EC algorithm evaporates (i.e., removes) noise variants, leaving behind a minimal collection of variants enriched for relevance to the given phenotype. We propose to advance this method to characterize and interpret singe-gene, gene-gene and gene-environment interactions all of which may modulate complex phenotypes such as vaccine-associated AEs and human immune response. This strategy will be developed with the aid of artificial data, simulated under a variety of conditions observed in real data, and the strategy will be tested on single nucleotide polymorphism (SNP) and clinical data from volunteers from a NIAID/NIH-sponsored trial to evaluate the Aventis Pasteur Smallpox Vaccine and a Center for Disease Control sponsored trial to evaluate Anthrax Vaccine Adsorbed. Susceptibility to common complex disorders is likely due to a combination of gene-gene and gene-environment interactions as well as single-gene associations. In this proposal, we will develop a new bioinformatics strategy for identifying networks of single- nucleotide polymorphisms (SNPs) that influence susceptibility to complex disorders from genome-wide data. The proposed strategy will be developed to identify networks associated with adverse events and the human immune response following smallpox and anthrax vaccination.",Machine Learning Analysis of Genetic Modulators of Vaccine Immune Response,7919847,R56AI080932,"['Accounting', 'Adverse event', 'Affect', 'Algorithms', 'Anthrax Vaccines', 'Anthrax disease', 'Antibody Formation', 'Appearance', 'Architecture', 'Bioinformatics', 'Biological', 'Centers for Disease Control and Prevention (U.S.)', 'Classification', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computer software', 'Coupling', 'DNA Sequence', 'Data', 'Decision Trees', 'Dependency', 'Development', 'Disease', 'Disease susceptibility', 'Engineering', 'Gases', 'Gene Combinations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Models', 'Genetic Polymorphism', 'Goals', 'Heterogeneity', 'Human', 'Immune response', 'Immunity', 'Inflammatory', 'Information Theory', 'Learning', 'Left', 'Logistic Regressions', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Noise', 'Pathway interactions', 'Phenotype', 'Predisposition', 'Research', 'Sample Size', 'Serological', 'Simulate', 'Single Nucleotide Polymorphism', 'Smallpox', 'Smallpox Vaccine', 'Software Tools', 'Statistical Methods', 'Susceptibility Gene', 'System', 'Testing', 'Thermodynamics', 'Vaccination', 'Vaccines', 'Variant', 'abstracting', 'base', 'evaporation', 'forest', 'gene environment interaction', 'gene interaction', 'genetic analysis', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'novel', 'open source', 'particle', 'stem', 'user-friendly', 'volunteer']",NIAID,UNIVERSITY OF TULSA,R56,2009,346329,-0.008302120409531138
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects has been continued in conjunction with Dr. Betty Doan. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We are currently using computer simulation studies to examine factors that affect the performance of this method and are applying it to Dr. Bailey-Wilsons lung cancer data.   We are completed work on establishing a p-value threshold for genome wide association studies using the number of independent SNPs and blocks within the HapMap database, as well as the Affymetrix and Illumina GWAS panels. Since increased density reduces the number of independent tests, using corrections like Bonferroni are not accurate. Instead, we used HAPMAP data and the linkage disequilibrium structure of the genome to identify the true number of independent SNPs across the genome. This work was published this year (1), giving researchers in the field guidelines for appropriate significance thresholds in several ethnic groups plus algorithms for recomputing these thresholds for other ethnic groups and as newer versions of the HapMap are released.  We also explored the utility of various machine learning methods in genome-wide association studies, particularly with respect to power and detection of gene-gene and gene-environment interactions. We used GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. A paper presenting these results is in press. We are continuing to pursue the use of machine learning methods in genomics studies.  Many of these projects are ongoing. n/a",Development of statistical genetics methodology,7968868,ZIAHG000153,"['Affect', 'Algorithms', 'Computer Simulation', 'Computers', 'Data', 'Data Linkages', 'Databases', 'Detection', 'Development', 'Ethnic group', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Guidelines', 'Linkage Disequilibrium', 'Machine Learning', 'Malignant neoplasm of lung', 'Methodology', 'Methods', 'Modeling', 'Paper', 'Performance', 'Publishing', 'Research Personnel', 'Simulate', 'Statistical Methods', 'Structure', 'Testing', 'Work', 'density', 'gene environment interaction', 'genetic linkage analysis', 'genome wide association study', 'novel', 'trait']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2009,172609,0.013232247749986232
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7622614,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2009,1224323,0.020214231990030935
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7682282,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Other Genetics', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'flexibility', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'non-genetic', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2009,291480,0.036522040108408226
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7681225,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2009,351164,-0.0007904547136044258
"Algorithmic strategies for detecting structural variation in genomes    DESCRIPTION (provided by applicant): Fine-scale nucleotide changes, along with genetic recombination, are often cited as the major source of human genetic variation [1, 13, 14]. Less is known about larger scale (> 10kb) genomic structural variations. As genomic technologies improve, we are detecting structural variation in ever-increasing numbers, including genomic inversions [24, 48, 71, 65, 31]; insertion/deletion polymorphisms [12, 26, 42]; and, copy number polymorphisms [28, 59, 60]. These large variations can completely disrupt coding and regulatory sites and copy number of genes, and thereby have a huge impact on human phenotypes and disease susceptibility [23, 61]. Deleterious effects have indeed been observed in cancer and other diseases [70, 43]. Our understanding of the scale and impact of these variations can be enhanced by improving computational tools for mining the data from these technologies. Here, I propose the development of algorithms and computational tools to improve detection and resolution (location of breakpoints) of structural variation. Specifically, I will develop algorithms for (a) experimental design of sequencing projects for detecting and resolving structural variations; (b) fine-mapping of breakpoints using end sequence profiling, to detect gene-disruption and gene-fusions; (c) reconstructing tumor genome architectures; (d) detection of targeted genomic variations in a heterogeneous mix of normal versus mutated cells via multiplex PCR; and (e) detection of balanced structural variation in genotype data. The tools will be designed using techniques from statistical machine learning and combinatorial algorithms. Validation will be performed using known structural variations, simulation studies, and extensive experimental collaborations with technology developers and early technology adopters. All of the data, and software will be freely available for academic and non-commercial uses.      PUBLIC HEALTH RELEVANCE: The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and differentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogeneous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term effect on human health.           Project Narrative The proposed computational tools will be used to detect structural variations in human populations as a starting point for understanding their role in normal evolution and disease, specifically cancer. The architecture of tumor genomes will help reveal genes that are disrupted and di!erentially expressed in tumor cells. The targeted detection of genomic lesions in a heterogenous mix of mutated and wildtype cells, will find application as an early diagnostic for cancer. Thus, our computational methods will have an immediate and long term e!ect on human health.",Algorithmic strategies for detecting structural variation in genomes,7635337,R01HG004962,"['Algorithms', 'Architecture', 'Cancer Diagnostics', 'Cataloging', 'Catalogs', 'Cell Fraction', 'Cells', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computing Methodologies', 'Copy Number Polymorphism', 'DNA Sequence Rearrangement', 'DNA copy number', 'Data', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disease', 'Disease susceptibility', 'Emerging Technologies', 'Equilibrium', 'Error Sources', 'Event', 'Evolution', 'Experimental Designs', 'Frequencies', 'Gene Dosage', 'Gene Fusion', 'Genes', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genetics', 'Individual', 'Investigation', 'Length', 'Lesion', 'Location', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Microscope', 'Molecular', 'Mutate', 'Mutation', 'Nucleotides', 'Output', 'Phenotype', 'Population', 'Probability', 'Reading', 'Resolution', 'Role', 'Shotguns', 'Site', 'Software Tools', 'Solid', 'Source', 'Spliced Genes', 'Techniques', 'Technology', 'Tumor stage', 'Validation', 'Variant', 'base', 'combinatorial', 'computerized tools', 'cost', 'data mining', 'density', 'design', 'fusion gene', 'improved', 'insertion/deletion mutation', 'neoplastic cell', 'promoter', 'public health relevance', 'simulation', 'statistics', 'structural genomics', 'tool', 'tumor']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2009,330660,-0.013382918288155563
"Informatic profiling of clinically relevant mutation    DESCRIPTION (provided by applicant):       We are submitting this proposal pursuant to NOT-0D-09-058, NIH Announces the Availability of Recovery Act Funds for Competitive Revision Applications.       Our group focuses on understanding how amino acid substitutions disrupt molecular functions that cause human disease. In our currently funded R01, we are developing methods we call in silico functional profiling. This method works by learning residue-specific protein function and then estimates when it is disrupted. This research funds our efforts to characterize what the underlying molecular disruption a protein mutation is causing and thereby improve accuracy of these approaches. In this competitive revision application, we are proposing to expand our efforts to the challenge of understanding genetic disease mutations and polymorphisms that affect gene expression regulation or transcript splicing. Additionally, we have formed collaborations with genetic data managers and will apply all of our methods to aid in their research and identify new testable hypotheses. We will do this in three supplemental aims. First, we will evaluate genomic features for prediction of regulatory nucleotide substitutions and construct new methods to aid in their classification. Second, we will collaboratively work to develop machine learning methods for classification of nucleotide substitutions that disrupt transcript splicing. Finally, we will work to collaboratively annotate genetic data found in inherited disease, pharmacogenetics and somatic mutations in cancer. Together this Recovery Act proposal will fund two groups in bioinformatics and will support trainees, technical staff, and two faculty members.           7. Narrative In this research, we will identify genetic variants that are likely to disrupt genome function, mRNA transcript processing and protein function. We will develop new methods and databases that will hypothesize the underlying molecular mechanism of genetic disease and genetic phenotypes.",Informatic profiling of clinically relevant mutation,7809730,R01LM009722,"['Affect', 'American', 'Amino Acid Sequence', 'Amino Acid Substitution', 'Area', 'Binding Sites', 'Bioinformatics', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Computer Simulation', 'CpG Islands', 'DNA Resequencing', 'Data', 'Data Collection', 'Databases', 'Dideoxy Chain Termination DNA Sequencing', 'Disease', 'Economics', 'Elements', 'Epigenetic Process', 'Faculty', 'Focus Groups', 'Funding', 'Gene Expression Regulation', 'Gene Mutation', 'Generations', 'Genetic', 'Genetic Polymorphism', 'Genetic Predisposition to Disease', 'Genetic Variation', 'Genome', 'Genomics', 'Hereditary Disease', 'Indium', 'Informatics', 'Inherited', 'Laboratories', 'Laboratory Research', 'Learning', 'Letters', 'Machine Learning', 'Malignant Neoplasms', 'Messenger RNA', 'Methods', 'Missense Mutation', 'Modeling', 'Molecular', 'Mutation', 'Mutation Analysis', 'Nucleotides', 'Paper', 'Peptide Sequence Determination', 'Pharmacogenetics', 'Phenotype', 'Postdoctoral Fellow', 'Process', 'Protein Analysis', 'Proteins', 'RNA Splicing', 'Recovery', 'Research', 'Research Personnel', 'Research Priority', 'Scientist', 'Site', 'Somatic Mutation', 'Tertiary Protein Structure', 'Time', 'Training', 'Transcript', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical application', 'clinically relevant', 'data management', 'data mining', 'disease-causing mutation', 'genetic variant', 'human disease', 'improved', 'innovation', 'member', 'molecular phenotype', 'novel strategies', 'protein function', 'sound', 'tool', 'transcription factor']",NLM,BUCK INSTITUTE FOR RESEARCH ON AGING,R01,2009,145500,-0.015016538142653482
"Multi-point and multi-locus analysis of genomic association data    DESCRIPTION (provided by applicant):       Genome-wide association studies (GWAS) provide a new and powerful approach to investigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learning approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases.            Principal Investigator/Program Director: Li, Jing Title: Multi-point and multi-locus analysis of genomic association data Abstract: Genome-wide association studies (GWAS) provide a new and powerful approach to inves- tigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learn- ing approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases. PHS 398 Page 1",Multi-point and multi-locus analysis of genomic association data,7652746,R01LM008991,"['Address', 'Advanced Development', 'Affect', 'Algorithms', 'Alleles', 'Architecture', 'Cataloging', 'Catalogs', 'Chromosomes', 'Classification', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Decision Trees', 'Dependence', 'Development', 'Disease', 'Effectiveness', 'Environment', 'Environmental Risk Factor', 'Etiology', 'Evaluation', 'Freedom', 'Frequencies', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Recombination', 'Genetic Risk', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Grouping', 'Haplotypes', 'Heart Diseases', 'Heterogeneity', 'Imagery', 'Inherited', 'Intelligence', 'Internet', 'Joints', 'Learning', 'Licensing', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Markov Chains', 'Methods', 'Modeling', 'Modification', 'Mutation', 'Phenocopy', 'Phenotype', 'Play', 'Predisposition', 'Principal Investigator', 'Procedures', 'Rare Diseases', 'Research Project Grants', 'Risk', 'Role', 'Sampling', 'Scientist', 'Simulate', 'Single Nucleotide Polymorphism', 'Staging', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Trust', 'Uncertainty', 'Weight', 'Work', 'abstracting', 'base', 'case control', 'database of Genotypes and Phenotypes', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genome wide association study', 'genotyping technology', 'hydroxy-aluminum polymer', 'improved', 'markov model', 'neglect', 'novel', 'programs', 'research study', 'software systems', 'tool', 'trait']",NLM,CASE WESTERN RESERVE UNIVERSITY,R01,2009,951009,0.03348254625052932
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7671509,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2009,1455866,0.014974858428830057
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7671509,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2009,202086,0.014974858428830057
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7922465,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2009,415228,0.014974858428830057
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7911405,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'National Human Genome Research Institute', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'clinical care', 'clinical practice', 'data modeling', 'data sharing', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'patient population', 'phenome', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2009,229436,0.014974858428830057
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7788875,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Ontology', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'empowered', 'genome wide association study', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'histone modification', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'public health relevance', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2009,142123,-0.01571161586327459
"Analysis Tool for Heritable and Envirnonmental Network Associations    DESCRIPTION (provided by applicant):       The efforts of the human genome project are beginning to provide important findings for human health. Technological advances in the laboratory, particularly in characterizing human genomic variation, have created new approaches for studying the human genome. However, current statistical and computational strategies are taking only partial advantage of this wealth of information. In the quest for disease susceptibility genes for common, complex disease, we are faced with many challenges. Selecting genetic, clinical, and environmental factors important for the trait of interest is increasingly more difficult as high throughput data generation technologies are developed. We know that genes do not act in isolation, thus numerous other factors are likely important in complex disease phenotypes. However, techniques for robust statistical modeling of important variables to predict clinical outcomes are limited in their capability for interaction effects. Ultimately, we want to know what factors are important to provide superior prevention, diagnosis, and treatment of human disease. Unfortunately, interpretation of statistical models in a meaningful way for biomedical research has been lacking due to the inherent difficulty in making such connections. Thus, a technology that embraces the complexity of human disease and integrates multiple data sources including biological knowledge from the public domain, through a powerful analytical framework is essential for dissecting the architecture of common diseases. ATHENA: the Analysis Tool for Heritable and Environmental Network Associations is a novel framework that incorporates variable selection, modeling, and interpretation to learn more about diseases of public health interest. As the field gains experience in analyzing large scale genomic data, it is crucial that we learn from each other and develop and codify the best strategies.            Many common, complex diseases are likely due to a combination of genetic and environmental risk factors. Out ability to extract all of the meaningful information from very large genomic and phenotypic datasets has been limited by our analytic strategies. The methodology described in this proposal is a powerful new approach to maximize the information learned from large datasets to improve prevention, diagnosis, and treatment of diseases of public health interest.",Analysis Tool for Heritable and Envirnonmental Network Associations,7642231,R01LM010040,"['Architecture', 'Arts', 'Base Pairing', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Biology', 'Biomedical Research', 'Candidate Disease Gene', 'Clinical', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Diagnosis', 'Disease', 'Disease susceptibility', 'Environment', 'Environmental Risk Factor', 'Evolution', 'Exhibits', 'Future', 'Generations', 'Genes', 'Genetic', 'Genetic Models', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health', 'Human', 'Human Genome', 'Human Genome Project', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Life', 'Machine Learning', 'Methodology', 'Modeling', 'Noise', 'Outcome', 'Prevention', 'Proteomics', 'Public Domains', 'Public Health', 'Research Personnel', 'Resources', 'Sampling', 'Signal Transduction', 'Simulate', 'Single Nucleotide Polymorphism', 'Solutions', 'Statistical Models', 'Susceptibility Gene', 'Techniques', 'Technology', 'Time', 'Variant', 'Vision', 'base', 'computerized tools', 'disease phenotype', 'disorder risk', 'experience', 'flexibility', 'follow-up', 'gene environment interaction', 'gene interaction', 'genetic analysis', 'genome wide association study', 'human disease', 'improved', 'interest', 'novel', 'novel strategies', 'simulation', 'success', 'tool', 'tool development', 'trait']",NLM,VANDERBILT UNIVERSITY,R01,2009,922959,0.018495441686446477
"VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES    DESCRIPTION (provided by applicant): Cardiovascular diseases (CVD) affect millions of people in US and across the world. There is strong evidence of a genetic component in cardiovascular diseases (CVD) and related traits. An emerging consensus is that both genes and environment and, perhaps more importantly, their interactions are responsible for this complex disease. As a result, many genetic epidemiological (GE) studies of CVD use a study design that tests hundreds of thousands of genetic predictors (e.g., single nucleotide polymorphism (SNP) markers) and hundreds of (related) disease phenotypes and environmental covariates. This has brought tremendous analytical challenges, particularly the high dimensionality of the data and the obscure interactions among the many variables. As a result, searching for CVD disease genes has become a task of selecting important variables from a vast number of SNPs and other predictor variables. Our real data analyses in several ongoing large scale CVD related studies motivated us to consider new methodological solutions to the variable selection problem. This application is developed upon these positive preliminary findings. Our main idea is to develop a strategy for selecting important predictors of CVD by integrating multiple sources of information via the method of statistical learning (i.e., optimizing the selection by repeated learning from examples). In this strategy, we will first develop a method for selecting significant SNPs in moderate-dimensional data (e.g., lower thousands of SNPs, in candidate genes studies) by an integrated classifier. The method will build upon existing techniques assessing information of SNPs in haplotype similarity, imputed functional potential, and gene-gene interactions. We then scale up the new method to the high-dimensional setting of genome-wide association studies (e.g., at least hundreds of thousands of SNPs), by dimension reduction that utilizes the local linkage-disequilibrium (LD) structure in SNPs and by combining latent factor analysis of correlated CVD traits and pathway-based analysis to account for gene-environment (GxE) interactions. A fast-search algorithm will also be developed based on an existing search heuristic that was successfully applied in high-dimensional data of gene expression and genomic sequence analysis. The new methods and algorithms will be coded into R programs and distributed as tool set for an association analysis pipeline. Evaluations of the new methods will be performed by intensive simulation studies and by applying to existing datasets in ongoing studies of CVD and related diseases. Results from evaluation studies, together with the ancillary databases generated by the study such as imputed functional scores of potential or known CVD SNPs will be distributed on a dedicated project website. By doing so, we believe that the utilities resulted from the proposed research will make a significant contribution to many ongoing genetic epidemiological studies of CVD and related traits.  PUBLIC HEALTH RELEVANCE: This project is aimed at timely development of computational tools for emerging large-scale genome-wide association studies of cardiovascular diseases (CVD) that affect millions of people in US and across the world. The new methods deal with the analytical challenges brought forth by the high dimensionality of the data and the obscure interactions among the many variables in these studies, and the tools will be applied to ongoing studies of CVD and related diseases. The results, together with the computer programs and ancillary databases will make a significant contribution to many ongoing and new genetic epidemiological studies of CVD and related diseases.             n/a",VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES,7663792,R01HL091028,"['Accounting', 'Affect', 'Algorithms', 'American', 'Area', 'Blood Vessels', 'Candidate Disease Gene', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosomes', 'Chronic Disease', 'Code', 'Collection', 'Complex', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Developed Countries', 'Developing Countries', 'Development', 'Dimensions', 'Disease', 'Disease Outcome', 'Environment', 'Epidemiologic Studies', 'Etiology', 'Evaluation', 'Evaluation Studies', 'Exclusion', 'Factor Analysis', 'Functional disorder', 'Gene Expression', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Haplotypes', 'Heart failure', 'Hypertension', 'Hypertrophy', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Left', 'Left Ventricular Hypertrophy', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Noise', 'Pathway interactions', 'Performance', 'Procedures', 'Process', 'Public Domains', 'Research', 'Research Design', 'Sea', 'Sequence Analysis', 'Single Nucleotide Polymorphism', 'Solutions', 'Source', 'Statistical Computing', 'Structure', 'Techniques', 'Testing', 'Variant', 'Ventricular', 'Weight', 'base', 'computer based statistical methods', 'computer program', 'computerized tools', 'disease phenotype', 'experience', 'gene interaction', 'genome wide association study', 'heuristics', 'hypertensive heart disease', 'improved', 'mortality', 'premature', 'prevent', 'programs', 'public health relevance', 'scale up', 'simulation', 'tool', 'trait', 'web site']",NHLBI,WASHINGTON UNIVERSITY,R01,2009,228000,0.009220585659351218
"VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES    DESCRIPTION (provided by applicant): Cardiovascular diseases (CVD) affect millions of people in US and across the world. There is strong evidence of a genetic component in cardiovascular diseases (CVD) and related traits. An emerging consensus is that both genes and environment and, perhaps more importantly, their interactions are responsible for this complex disease. As a result, many genetic epidemiological (GE) studies of CVD use a study design that tests hundreds of thousands of genetic predictors (e.g., single nucleotide polymorphism (SNP) markers) and hundreds of (related) disease phenotypes and environmental covariates. This has brought tremendous analytical challenges, particularly the high dimensionality of the data and the obscure interactions among the many variables. As a result, searching for CVD disease genes has become a task of selecting important variables from a vast number of SNPs and other predictor variables. Our real data analyses in several ongoing large scale CVD related studies motivated us to consider new methodological solutions to the variable selection problem. This application is developed upon these positive preliminary findings. Our main idea is to develop a strategy for selecting important predictors of CVD by integrating multiple sources of information via the method of statistical learning (i.e., optimizing the selection by repeated learning from examples). In this strategy, we will first develop a method for selecting significant SNPs in moderate-dimensional data (e.g., lower thousands of SNPs, in candidate genes studies) by an integrated classifier. The method will build upon existing techniques assessing information of SNPs in haplotype similarity, imputed functional potential, and gene-gene interactions. We then scale up the new method to the high-dimensional setting of genome-wide association studies (e.g., at least hundreds of thousands of SNPs), by dimension reduction that utilizes the local linkage-disequilibrium (LD) structure in SNPs and by combining latent factor analysis of correlated CVD traits and pathway-based analysis to account for gene-environment (GxE) interactions. A fast-search algorithm will also be developed based on an existing search heuristic that was successfully applied in high-dimensional data of gene expression and genomic sequence analysis. The new methods and algorithms will be coded into R programs and distributed as tool set for an association analysis pipeline. Evaluations of the new methods will be performed by intensive simulation studies and by applying to existing datasets in ongoing studies of CVD and related diseases. Results from evaluation studies, together with the ancillary databases generated by the study such as imputed functional scores of potential or known CVD SNPs will be distributed on a dedicated project website. By doing so, we believe that the utilities resulted from the proposed research will make a significant contribution to many ongoing genetic epidemiological studies of CVD and related traits.  PUBLIC HEALTH RELEVANCE: This project is aimed at timely development of computational tools for emerging large-scale genome-wide association studies of cardiovascular diseases (CVD) that affect millions of people in US and across the world. The new methods deal with the analytical challenges brought forth by the high dimensionality of the data and the obscure interactions among the many variables in these studies, and the tools will be applied to ongoing studies of CVD and related diseases. The results, together with the computer programs and ancillary databases will make a significant contribution to many ongoing and new genetic epidemiological studies of CVD and related diseases.             n/a",VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES,7845764,R01HL091028,"['Accounting', 'Affect', 'Algorithms', 'American', 'Area', 'Blood Vessels', 'Candidate Disease Gene', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosomes', 'Chronic Disease', 'Code', 'Collection', 'Complex', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Developed Countries', 'Developing Countries', 'Development', 'Dimensions', 'Disease', 'Disease Outcome', 'Environment', 'Epidemiologic Studies', 'Etiology', 'Evaluation', 'Evaluation Studies', 'Exclusion', 'Factor Analysis', 'Functional disorder', 'Gene Expression', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Haplotypes', 'Heart failure', 'Hypertension', 'Hypertrophy', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Left', 'Left Ventricular Hypertrophy', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Noise', 'Pathway interactions', 'Performance', 'Procedures', 'Process', 'Public Domains', 'Research', 'Research Design', 'Sea', 'Sequence Analysis', 'Single Nucleotide Polymorphism', 'Solutions', 'Source', 'Statistical Computing', 'Structure', 'Techniques', 'Testing', 'Variant', 'Ventricular', 'Weight', 'base', 'computer based statistical methods', 'computer program', 'computerized tools', 'disease phenotype', 'experience', 'gene interaction', 'genome wide association study', 'heuristics', 'hypertensive heart disease', 'improved', 'mortality', 'premature', 'prevent', 'programs', 'public health relevance', 'scale up', 'simulation', 'tool', 'trait', 'web site']",NHLBI,WASHINGTON UNIVERSITY,R01,2009,229243,0.009220585659351218
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7499147,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Depth', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Numbers', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'foot', 'insight', 'member', 'novel', 'quality assurance', 'scale up', 'size', 'symposium', 'theories', 'tool']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2008,1200000,0.020214231990030935
"Development of statistical genetics methodology A major project of this section is the development of new statistical genetics methodology as prompted by the needs of our applied studies and the testing and comparison of novel and existing statistical methods.   The project to develop propensity scores in linkage analyses as a method for inclusion of covariate effects has been continued in conjunction with Dr. Betty Doan. This method appears promising in that it is generally more powerful than including the covariates directly into the model, and does not have strongly inflated Type I error rates. We are currently examining factors that affect the performance of this method and are applying it to Dr. Bailey-Wilsons lung cancer data.   We are currently working on establishing a p-value threshold for genome wide association studies using the number of independent SNPs and blocks within the HapMap database, as well as the Affymetrix and Illumina GWAS panels. Since increased density reduces the number of independent tests, using corrections like Bonferroni are not accurate. Instead, we are proposing to identify the true number of independent SNPs across the genome. A manuscript is under review and work is ongoing to refine and extend this method.  We also developed a perl program to count and visualize the number of extended tracts of homozygosity in dense SNP data. Excess homozgyosity could reflect inbreeding or possible regions of deletions, and visualizing these regions by case status will allow us to determine if these regions harbor potential deletion sites. This program is currently being tested by members of our Branch.  We developed a new approach to error detection and correction in microarray gene expression studies of families. A paper was published this year describing this method and its effect on the power of linkage studies that use the resulting phenotypic data.   We also examined the effects of intermarker linkage disequilibrium on linkage Type I error and power in varying types of family structures. We found that even small amounts of LD can inflate Type I error, that multigenerational pedigrees are less affected than are nuclear families and that missing parental genotypes exacerbates this effect. A paper presenting these results was published this year and we are developing optimal methods for removing intermarker LD while maximizing power and controlling Type I error.  We are exploring the utility of various machine learning methods in genome-wide association studies, particularly with respect to power and detection of gene-gene and gene-environment interactions.  Many of these projects are ongoing. n/a",Development of statistical genetics methodology,7734873,Z01HG000153,"['Affect', 'Count', 'Data', 'Databases', 'Detection', 'Development', 'Family Study', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genotype', 'Inbreeding', 'Linkage Disequilibrium', 'Machine Learning', 'Malignant neoplasm of lung', 'Manuscripts', 'Methodology', 'Methods', 'Modeling', 'Nuclear Family', 'Numbers', 'Paper', 'Performance', 'Publishing', 'Rate', 'Score', 'Site', 'Statistical Methods', 'Testing', 'Work', 'density', 'family structure', 'gene environment interaction', 'genetic linkage analysis', 'genetic pedigree', 'genome wide association study', 'member', 'novel', 'novel strategies', 'programs']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,Z01,2008,202443,-0.00184094731725124
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7488003,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Disease regression', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Numbers', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Rate', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2008,291480,0.036522040108408226
"What Made Us Human?    DESCRIPTION (provided by applicant): Comparative genomics promises to shed light on those genetic changes that gave rise to the modern human species. Mounting evidence suggests that the vast majority of functional differences between the human and chimpanzee genomes are in regions that do not code for proteins. Focusing on these non-coding regions, we will investigate lineage-specific evolution in the human genome. Our approach includes developing likelihood ratio tests for identifying changes in either the rate or the pattern of nucleotide substitution in a single lineage. These novel methods will be implemented in open source software that can be used to scan an entire genome. We will apply this evolutionary analysis to multiple sequence alignments of human and other vertebrates, including several closely related species (macaque, chimpanzee, Neanderthal), allowing us to identify recent changes in the human genome. In order to concentrate on functionally relevant changes, evolutionary testing will be limited to sets of candidate regions with specific known or predicted functions (e.g. regulatory regions, RNA genes). Predicted functional regions will be identified using machine learning classification techniques. These classifiers will employ measures of sequence conservation as well as the rapidly expanding collection of experimental and bioinformatic annotations of the human genome, including results of the ENCODE Project and other functional genomic studies. After identifying those regions that were most significantly altered in the human lineage, we will use this functional information to develop testable hypotheses about the effects of the observed changes. Experimental investigations of these genomic regions will lead to new understanding of the evolution of human biology and health.       PROJECT NARRATIVE: This project will vastly expand knowledge of biologically relevant features of the human genome that are unique to our species. Identification and characterization of the genetic changes leading to modern humans is of fundamental interest. These investigations also promise to contribute to our understanding of the causal mechanisms behind human diseases, leading to directed treatment and prevention strategies.          n/a",What Made Us Human?,7522602,R01GM082901,"['Affect', 'Amino Acids', 'Bioinformatics', 'Categories', 'Class', 'Classification', 'Code', 'Collaborations', 'Collection', 'Computer software', 'DNA', 'Data', 'Databases', 'Evolution', 'Functional RNA', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Investigation', 'Knowledge', 'Lead', 'Light', 'Macaca', 'Machine Learning', 'Mammals', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Nucleotides', 'Pan Genus', 'Pan troglodytes', 'Pattern', 'Prevention strategy', 'Process', 'Proteins', 'Public Domains', 'Rate', 'Relative (related person)', 'Ribonucleic Acid Regulatory Sequences', 'Scanning', 'Sequence Alignment', 'Site', 'Techniques', 'Testing', 'Vertebrates', 'base', 'comparative', 'experience', 'functional genomics', 'genome wide association study', 'human disease', 'insight', 'interest', 'novel', 'open source', 'simulation', 'trait']",NIGMS,J. DAVID GLADSTONE INSTITUTES,R01,2008,369424,-0.0007904547136044258
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7502672,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'concept', 'data modeling', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2008,1432331,0.014974858428830057
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7502672,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'concept', 'data modeling', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY,U01,2008,196200,0.014974858428830057
"Integrated Analysis of Genome-Wide Array Data    DESCRIPTION (provided by applicant): This project will develop an integrated desktop application to combine data from expression array, RNA transcript array, proteomics, SNP array (for polymorphism an analysis, as well as LOH and copy number determination), methylation array, histone modification array, promoter array, and microRNA array and metabolomics technologies. Current approaches to analysis of individual `omic' technologies suffer from problems of fragmentation, that present an incomplete view of the workings of the cell. However, effective integration into a single analytic platform is non-trivial. There is a need for a consistent approach, infrastructure, and interface between array types, to maximize ease of use, while recognizing and accommodating the specific computational and statistical requirements, and biological context, of each array. A central challenge is the need to create and work with lists of genomic regions of interest (GROIs) for each sample: we propose three novel approaches to aid in identification of GROIs. These lists must then be integrated with rectangular (sample by feature) data arrays to facilitate statistical analysis. Integration between array types occurs at the computational level, through a unified software package, statistically, through tools that seek statistical relationships between features from different arrays, biologically, through use of annotations (particularly gene ontology, protein- protein and protein-DNA interactions, and pathway membership) that document functional relationships between features, and through genomic interactions that suggest relationships between features that map to the same regions of the genome. The end product will support analysis of each platform separately, with a comprehensive suite of data management, statistical and heuristic analytic tools and the means to place findings of interest into a meaningful biological context through cross-reference to extensive biobases. Beyond that, a range of methods - statistical, biological and genomic - will be available to explore interactions and associations between platforms. PDF created with PDF Factory trial version www.pdffactory.com. PUBLIC HEALTH RELEVANCE: While the large-scale array technologies have provided an unprecedented capability to model cellular processes, both in normal functioning and disease states, this capability is utterly dependent on the availability of complex data management, computational, statistical and informatic software tools.  The utility of the next generation of arrays - which focus on critical regulation and control functions of the cell - will be stymied by an initial lack of suitable bioinformatic tools.  This proposal initiates an accelerated development of an integrated software package intended to empower biologists in the application and analysis of these powerful new technologies, with broadly reaching impact at all levels of biological and clinical research, and across every discipline.          n/a",Integrated Analysis of Genome-Wide Array Data,7538527,R43HG004677,"['Algorithms', 'Alternative Splicing', 'Binding', 'Bioinformatics', 'Biological', 'Biological Neural Networks', 'Bite', 'Cell physiology', 'Cells', 'Classification', 'Clinical Data', 'Clinical Research', 'Complex', 'Computer software', 'DNA copy number', 'DNA-Protein Interaction', 'Data', 'Data Linkages', 'Development', 'Discipline', 'Disease', 'Documentation', 'Evaluation', 'GDF15 gene', 'Gene Expression', 'Genes', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Heating', 'Histones', 'Imagery', 'Individual', 'Informatics', 'Internet', 'Joints', 'Link', 'Loss of Heterozygosity', 'Machine Learning', 'Maps', 'Methylation', 'MicroRNAs', 'Modeling', 'Modification', 'Numbers', 'Ontology', 'PLAB Protein', 'Pathway interactions', 'Phase', 'Polymorphism Analysis', 'Process', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'RNA', 'Range', 'Regulation', 'Research Infrastructure', 'Resources', 'Sampling', 'Software Tools', 'Sorting - Cell Movement', 'Statistical Methods', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Text', 'Transcript', 'Work', 'base', 'data management', 'genome-wide analysis', 'heuristics', 'high throughput technology', 'interest', 'metabolomics', 'new technology', 'next generation', 'novel', 'novel strategies', 'prognostic', 'promoter', 'tool', 'tool development']",NHGRI,EPICENTER SOFTWARE,R43,2008,157474,-0.01571161586327459
"VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES    DESCRIPTION (provided by applicant): Cardiovascular diseases (CVD) affect millions of people in US and across the world. There is strong evidence of a genetic component in cardiovascular diseases (CVD) and related traits. An emerging consensus is that both genes and environment and, perhaps more importantly, their interactions are responsible for this complex disease. As a result, many genetic epidemiological (GE) studies of CVD use a study design that tests hundreds of thousands of genetic predictors (e.g., single nucleotide polymorphism (SNP) markers) and hundreds of (related) disease phenotypes and environmental covariates. This has brought tremendous analytical challenges, particularly the high dimensionality of the data and the obscure interactions among the many variables. As a result, searching for CVD disease genes has become a task of selecting important variables from a vast number of SNPs and other predictor variables. Our real data analyses in several ongoing large scale CVD related studies motivated us to consider new methodological solutions to the variable selection problem. This application is developed upon these positive preliminary findings. Our main idea is to develop a strategy for selecting important predictors of CVD by integrating multiple sources of information via the method of statistical learning (i.e., optimizing the selection by repeated learning from examples). In this strategy, we will first develop a method for selecting significant SNPs in moderate-dimensional data (e.g., lower thousands of SNPs, in candidate genes studies) by an integrated classifier. The method will build upon existing techniques assessing information of SNPs in haplotype similarity, imputed functional potential, and gene-gene interactions. We then scale up the new method to the high-dimensional setting of genome-wide association studies (e.g., at least hundreds of thousands of SNPs), by dimension reduction that utilizes the local linkage-disequilibrium (LD) structure in SNPs and by combining latent factor analysis of correlated CVD traits and pathway-based analysis to account for gene-environment (GxE) interactions. A fast-search algorithm will also be developed based on an existing search heuristic that was successfully applied in high-dimensional data of gene expression and genomic sequence analysis. The new methods and algorithms will be coded into R programs and distributed as tool set for an association analysis pipeline. Evaluations of the new methods will be performed by intensive simulation studies and by applying to existing datasets in ongoing studies of CVD and related diseases. Results from evaluation studies, together with the ancillary databases generated by the study such as imputed functional scores of potential or known CVD SNPs will be distributed on a dedicated project website. By doing so, we believe that the utilities resulted from the proposed research will make a significant contribution to many ongoing genetic epidemiological studies of CVD and related traits.  PUBLIC HEALTH RELEVANCE: This project is aimed at timely development of computational tools for emerging large-scale genome-wide association studies of cardiovascular diseases (CVD) that affect millions of people in US and across the world. The new methods deal with the analytical challenges brought forth by the high dimensionality of the data and the obscure interactions among the many variables in these studies, and the tools will be applied to ongoing studies of CVD and related diseases. The results, together with the computer programs and ancillary databases will make a significant contribution to many ongoing and new genetic epidemiological studies of CVD and related diseases.             n/a",VARIABLE SELECTION IN GENETIC EPIDEMIOLOGICAL STUDIES OF CARDIOVASCULAR DISEASES,7528626,R01HL091028,"['Accounting', 'Affect', 'Algorithms', 'American', 'Area', 'Blood Vessels', 'Candidate Disease Gene', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosomes', 'Chronic Disease', 'Code', 'Collection', 'Complex', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Developed Countries', 'Developing Countries', 'Development', 'Dimensions', 'Disease', 'Disease Outcome', 'Environment', 'Epidemiologic Studies', 'Etiology', 'Evaluation', 'Evaluation Studies', 'Exclusion', 'Factor Analysis', 'Functional disorder', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Haplotypes', 'Heart failure', 'Hypertension', 'Hypertrophy', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Left', 'Left Ventricular Hypertrophy', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Noise', 'Numbers', 'Pathway interactions', 'Performance', 'Procedures', 'Process', 'Public Domains', 'Public Health', 'Research', 'Research Design', 'Score', 'Sea', 'Sequence Analysis', 'Single Nucleotide Polymorphism', 'Solutions', 'Source', 'Statistical Computing', 'Structure', 'Techniques', 'Testing', 'Variant', 'Weight', 'base', 'computer based statistical methods', 'computer program', 'computerized tools', 'disease phenotype', 'experience', 'gene interaction', 'genome wide association study', 'heuristics', 'hypertensive heart disease', 'improved', 'mortality', 'prevent', 'programs', 'scale up', 'simulation', 'tool', 'trait', 'ventricular hypertrophy']",NHLBI,WASHINGTON UNIVERSITY,R01,2008,228000,0.009220585659351218
"WormBase: a core data resource for C elegans and other nematodes    DESCRIPTION (provided by applicant):  Caenorhabditis elegans is a major model system for basic biological and biomedical research and the first animal for which there is a complete description of its genome, anatomy and development, and some information about each of its ~22,000 genes. Five years of funding is requested to maintain and expand WormBase, a Model Organism Database (MOD), with complete coverage of core genomic, genetic, anatomical and functional information about this and other nematodes. Such a database is necessary to allow the entire biomedical research community to make full use of nematode genomic sequences. The two top priorities will be intensive data curation and user interface improvement. WormBase will include up-to-date annotation of the genomic data, the current genetic and physical maps and many experimental data such as genome-scale datasets connected to the function and interactions of cells and genes, as well as development, physiology and behavior. Direct access to the sources of biological material, such as the strain collection of the Caenorhabditis Genetics Center and direct links to data sets maintained by others will be provided. Data will be recovered from the existing resources, from direct contribution of the individual laboratories, and from the literature. While WormBase will act as a central forum through which every laboratory will be able to contribute constructively to the global effort to fully comprehend this metazoan organism, WormBase professional curators will ensure detailed attribution of data sources and check consistency and integrity. To facilitate communication, WormBase will use technology, terminology and style concordant with other databases wherever possible. WormBase will maintain ontologies for nematode anatomy and phenotypes. WormBase will be Web-based and easy to use. Multiple relational databases will be used for data management; the object-based Acedb database system will be used for integration, and this integrated database plus ""slave"" relational databases will be used to drive the website. Coordination of the project and the main curation site will be at Caltech under the supervision of a C. elegans biologist. Curation and annotation of genomic sequence will take place at the centers - the Sanger Institute and Washington University - that generated the entire genome sequence. Oxford University will maintain genetic nomenclature.  Nematodes (roundworms) are major parasites of humans, livestock and crops, and extension of WormBase to broader coverage of nematode genomics will facilitate research into the diagnosis and treatment of nematode-based disease. Studies of C. elegans have informed us of basic principles of normal development and the molecular basis of aging, cancer, nicotine addiction, as well as a variety of fundamental biological processes such as cell migration, cell differentiation and cell death.              n/a",WormBase: a core data resource for C elegans and other nematodes,7502984,P41HG002223,"['Ablation', 'Age', 'Agriculture', 'Alleles', 'Anatomy', 'Animals', 'Antibodies', 'Architecture', 'Base Sequence', 'Behavior', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biomedical Research', 'Caenorhabditis', 'Caenorhabditis elegans', 'Cell Communication', 'Cell Death', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Chromosome Mapping', 'Code', 'Collection', 'Communication', 'Communities', 'Comparative Anatomy', 'Compatible', 'DNA Sequence', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Ensure', 'Expressed Sequence Tags', 'Funding', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Processes', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Institutes', 'Internet', 'Knock-out', 'Knowledge', 'Laboratories', 'Link', 'Literature', 'Livestock', 'Longevity', 'Malignant Neoplasms', 'Maps', 'Medical', 'Metabolic', 'Methods', 'Molecular', 'Molecular Genetics', 'Mutation', 'Names', 'Natural Language Processing', 'Nature', 'Nematoda', 'Nicotine Dependence', 'Nomenclature', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Parasites', 'Parasitic nematode', 'Pathway interactions', 'Phenotype', 'Physical Chromosome Mapping', 'Physiology', 'Pliability', 'Process', 'Proteins', 'Proteomics', 'RNA Interference', 'Reagent', 'Regulation', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Secure', 'Site', 'Slave', 'Source', 'Subcellular Anatomy', 'Supervision', 'System', 'Techniques', 'Technology', 'Terminology', 'Tertiary Protein Structure', 'Transcript', 'Transgenes', 'Transgenic Organisms', 'Universities', 'Variant', 'Washington', 'Yeasts', 'base', 'cell motility', 'chromatin immunoprecipitation', 'comparative', 'comparative genomic hybridization', 'data integration', 'data management', 'data modeling', 'design', 'experience', 'functional genomics', 'gene function', 'genetic analysis', 'genome sequencing', 'improved', 'interoperability', 'member', 'migration', 'model organisms databases', 'programs', 'research study', 'small molecule', 'tool', 'transcription factor', 'usability', 'web interface', 'yeast two hybrid system']",NHGRI,CALIFORNIA INSTITUTE OF TECHNOLOGY,P41,2008,2750000,-0.00944053124389365
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7292731,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Disease regression', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Numbers', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Rate', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2007,297126,0.036522040108408226
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7427367,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'concept', 'data modeling', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY MED CTR,U01,2007,1463449,0.014974858428830057
"Vanderbilt Genome-Electronic Records Project    DESCRIPTION (provided by applicant):  VGER: The Vanderbilt Genome-Electronic Record project An important potential enabling resource for Personalized Medicine is the combination of a DNA repository with Electronic Medical Record (EMR) systems sufficiently robust to provide excellence in clinical care and to serve as resources for analysis of disease susceptibility and therapeutic outcomes across patient populations. The Vanderbilt EMR is a state of the art clinical and research tool (that includes >1.4 million records), and is associated with a DNA repository which has been in development for over 3 years; these are the key components of VGER, the Vanderbilt Genome-Electronic Records project proposed here. The VGER model acquires DNA from discarded blood samples collected from routine patient care, and can link these to de-identified data extracted and readily updated from the EMR. The phenotype we will analyze here is the QRS duration on the electrocardiogram, since slow conduction (indicated by longer QRS duration) is a marker of arrhythmia susceptibility. This will not only exploit the power of Genome-Wide Association (GWA) approaches to generate new biologic knowledge that impacts an area of public health concern, but also provides a platform for the development of tools, such as Natural Language Processing approaches, to optimally mine EMRs. This project brings together a team of investigators with nationally recognized records of accomplishment in genome science, medical ethics, bioinformatics, de-identification science, and translational and cardiovascular medicine to address four Specific Aims: (1) perform a GWA comparing samples from subjects with QRS durations at the extremes of the normal range, and validate by genotyping high likelihood associations in prospectively ascertained clinical trial sets for QRS duration and for arrhythmia susceptibility; (2) evaluate the validity and utility of structured and unstructured components of EMR data for genome-phenome correlations; (3) assess the ethical, scientific, and societal advantages and disadvantages of the VGER model, and determine best practices for oversight, community involvement, and communication as the resource grows; and (4) develop and evaluate formal privacy protection models for data derived from databanks and EMRs, establishing data sharing and integration practices. We also include here a proposal to develop the Administrative Coordinating Center whose mission will be to facilitate communication and collaboration among nodes in this network, the NHGRI, and external advisors. We subscribe to a vision of Personalized Medicine in which genomic and other patient-specific information drives personalized, predictive, preemptive, and participatory health care, and VGER represents an important step in that direction.           n/a",Vanderbilt Genome-Electronic Records Project,7427367,U01HG004603,"['Address', 'Area', 'Arrhythmia', 'Arts', 'Bioinformatics', 'Blood specimen', 'Cardiac', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Commit', 'Communication', 'Communities', 'Computerized Medical Record', 'DNA', 'Data', 'Databases', 'Development', 'Disadvantaged', 'Disease', 'Disease susceptibility', 'EKG QRS Complex', 'Electrocardiogram', 'Electronics', 'Ethics', 'Genome', 'Genomics', 'Genotype', 'Healthcare', 'Heart Diseases', 'Institution', 'Knowledge', 'Lead', 'Legal', 'Link', 'Measures', 'Medical Ethics', 'Medicine', 'Methods', 'Mining', 'Mission', 'Modeling', 'Natural Language Processing', 'Normal Range', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Population', 'Predisposition', 'Privacy', 'Public Health', 'Records', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Structure', 'System', 'Testing', 'Therapeutic', 'Translational Research', 'Update', 'Validation', 'Variant', 'Vision', 'concept', 'data modeling', 'egg', 'endophenotype', 'genome wide association study', 'heart rhythm', 'indexing', 'repository', 'tool', 'tool development']",NHGRI,VANDERBILT UNIVERSITY MED CTR,U01,2007,125000,0.014974858428830057
"A Comprehensive catalog of human DNasel hypersensitive sites    DESCRIPTION (provided by applicant):   The overall aim of this proposal is to establish a comprehensive, high-quality catalogue of human DNaseI hypersensitive sites (DHSs) spanning all major tissue lineages. We plan to map DNaseI hypersensitive sites at physiological resolution across the genome with high sensitivity and specificity. The major focus of our production effort will be on data quality, a strategy that served the Human Genome Project well. Accordingly, samples will be rigorously screened in a pipeline fashion, with only a select set advancing to whole-genome data collection (Specific Aim 1). To ensure the broadest possible coverage of both unique and non-unique genomic territories, a synergistic combination of three technologies (DNase-array, digital mapping of DNAasel cleave site sequences, and Quantitative Chromatin Profiling) will be applied (Specific Aim 2). This combination will enable mapping of >95% of the DHSs in the genome of each cell type. Independent validation provides the ultimate quality standard. We therefore plan to validate the DHS catalogue in a statistically rigorous fashion using hypersensitivity Southerns, a well-established, gold standard assay (Specific Aim 3). Since DNAasel hypersensitive sites are generic markers of a broad spectrum of human cis-regulatory sequences, the utility of the catalogue will be greatly enhanced by the classification of DHSs into major functional categories including promoters, distal elements (enhancers, LCRs), and insulators (Specific Aim 4). Validation of DHS functional classes will be accomplished using well-tested cell and transgenic assays of biological function (Specific Aim 5).           n/a",A Comprehensive catalog of human DNasel hypersensitive sites,7410206,U54HG004592,"['Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biological Testing', 'Biology', 'Boundary Elements', 'Cataloging', 'Catalogs', 'Categories', 'Cell Nucleus', 'Cells', 'Chromatin', 'Class', 'Classification', 'Cleaved cell', 'Communities', 'Custom', 'Data', 'Data Collection', 'Data Quality', 'Deoxyribonuclease I', 'Deoxyribonucleases', 'Detection', 'Digestion', 'Distal', 'Distal Enhancer Elements', 'Elements', 'Employee Strikes', 'Enhancers', 'Ensure', 'Environment', 'Exhibits', 'Generations', 'Generic Drugs', 'Genes', 'Genome', 'Genomics', 'Goals', 'Gold', 'Histones', 'Human', 'Human Genome', 'Human Genome Project', 'Hypersensitivity', 'Individual', 'Informatics', 'Laboratories', 'Locales', 'Locus Control Region', 'Machine Learning', 'Maps', 'Methods', 'Metric', 'Modification', 'Molecular', 'Noise', 'Numbers', 'Physiological', 'Pilot Projects', 'Plague', 'Positioning Attribute', 'Preparation', 'Production', 'Public Domains', 'Range', 'Rate', 'Regulation', 'Research Infrastructure', 'Resolution', 'Sample Size', 'Sampling', 'Score', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Staging', 'Standards of Weights and Measures', 'Surveys', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Transgenic Mice', 'Transgenic Organisms', 'Validation', 'base', 'cell type', 'cost', 'density', 'design', 'digital', 'experience', 'functional genomics', 'high throughput screening', 'human tissue', 'in vivo', 'insight', 'promoter']",NHGRI,UNIVERSITY OF WASHINGTON,U54,2007,3114596,-0.01642171452607187
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7146455,R01HG003618,"['clinical research', 'genes', 'genetics', 'human', 'model']",NHGRI,EMORY UNIVERSITY,R01,2006,306000,0.036522040108408226
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,7120160,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2006,414036,-0.0005768722488898925
"Shifting Conceptions of Human Identity DESCRIPTION (provided by applicant):  . One of the most important questions raised by the ongoing achievements of the Human Genome Project is how this new biological knowledge - and the powers it confers - will affect our identity and self-understanding as human beings. This book project focuses on one key aspect of this complex issue: exploring the extent to which human identity can be reconciled with deliberate design or partial redesign. The author proposes to shed new light on this question by comparing the debates surrounding two areas of scientific innovation that are not normally associated with each other, but that are in fact deeply related: the enterprise of human genetic intervention and the enterprise of building intelligent machines. Both these enterprises entail ""pushing the limits"" of traditional concepts of what it means to be human; and both ultimately confront their makers with the same core ""family"" of questions: What are the defining features of human personhood? To what extent can those features be modified or extended, before human personhood begins to break down? Can some (or all) of those features find embodiment in an entity other than a human being? These kinds of questions are no longer the sole province of science fiction writers, but have been taken up with increasing seriousness by mainstream scientists and technologists, as well as by a wide array of ""science watchers"" in academia, legislative circles, and the news media.   . Through documentary research and interviews, this project aims to deepen our understanding of the history and sociology of the debates surrounding these powerful new technologies, electro-mechanical and biological, that are perceived as destabilizing human identity. The intended audience for the book is a broad one: scientists and technological practitioners interested in the social and cultural reception of their research; legislators and other policymakers with a stake in the governance of science; general educated readers who are concerned about the role of science and technology in shaping our collective future. n/a",Shifting Conceptions of Human Identity,6915830,R03HG003298,"['adult human (21+)', 'artificial intelligence', 'behavioral /social science research tag', 'biotechnology', 'books', 'clinical research', 'ethics', 'genetic manipulation', 'history of life science', 'human subject', 'identity', 'interview', 'robotics', 'self concept', 'sociology /anthropology']",NHGRI,VANDERBILT UNIVERSITY,R03,2005,75833,-0.00012038309561105854
"BioHDF - Open Binary File Standards for Bioinformatics DESCRIPTION (provided by applicant):  Geospiza Inc. and the National Center for Supercomputing Applications (NCSA) are creating a standards based software framework around NCSA's Heirarchical Data Format (HDF5). The envisioned framework will integrate algorithms important in DNA and protein sequence analysis to create scalable high throughput software systems which will be accessed using new graphical user interfaces (GUIs) to provide researchers with new views of their data to finish sequencing projects in large-scale genome sequencing, microbial genome sequencing, viral epidemiology, polymorphism detection, phylogenetic analysis, multi-locus sequence typing, confirmatory sequencing, and EST analysis.    In our vision, algorithms will be either integrated into the system to directly read and write from HDF5 project files, or they will communicate with project files via filter programs that produce standardized XML formatted data. Through this model, a scalable solution will support different applications of DNA sequencing, fulfilling the many needs and requirements expressed by the medical research community now and into the future. As the first step in this process we will, define requirements for editing and versioning data in DNA sequencing, research and propose data models for the computational phases of DNA sequencing and annotating DNA sequence data using existing standards, create a prototype application for DNA sequencing based SNP discovery, and engage the bioinformatics community for BioHDF adoption.       In the past ten years the cost of sequencing DNA has dropped over 1000 fold and the amount of raw sequence data, entering our national repositories is doubling every 12 months. DNA sequencing is fundamental to biological research activities such as genomics, systems biology, and clinical medicine. Proposals are being sought to decrease sequencing costs by two orders of magnitude through technology refinements with an ultimate vision of developing technology to sequence human genome equivalents for $1000 each. The amount of data that will be produced through these endeavors is unimaginable. However, the $1,000 genome will not advance medical research unless we integrate all phases of the DNA sequencing process and treat the creation, management, finishing, analysis, and sharing of the data as common goals. n/a",BioHDF - Open Binary File Standards for Bioinformatics,6992995,R41HG003792,"['DNA', 'artificial intelligence', 'bioengineering /biomedical engineering', 'bioinformatics', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'functional /structural genomics', 'genetic mapping', 'genetic polymorphism', 'mathematics', 'molecular biology information system', 'nucleic acid sequence', 'single nucleotide polymorphism', 'virus genetics']",NHGRI,"GEOSPIZA, INC.",R41,2005,142775,0.01033913395573646
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,6952028,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2005,412000,-0.0005768722488898925
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6912979,R44HG002244,"['artificial intelligence', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'data management', 'genotype', 'informatics', 'mathematical model', 'nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2004,191986,0.014805347626092915
"Detecting relations among heterogeneous genomic datasets    DESCRIPTION (provided by applicant): During the past decade, the new focus on genomics has highlighted a particular challenge: to integrate the different views of the genome that are provided by various types of experimental data. The long-term objective of this work is to provide a coherent computational framework for integrating and drawing inferences from a collection of genome-wide measurements. Hence, the proposed research plan develops algorithms and computational tools for learning from heterogeneous data sets. We focus on the analysis of the yeast genome because so many genome-wide data sets are currently available; however, the tools we develop will be applicable to any genome. We approach this task using two recent trends from the field of machine learning: kernel algorithms that represent data via specialized similarity functions, and transductive algorithms that exploit the availability of unlabeled test data during the training phase of the algorithm. We apply focus on two tasks: (1) classifying groups of genes that are of interest to our collaborators, including components of the spindle pole body, cell cycle regulated genes, and genes involved in meiosis and sporulation, splicing, alcohol metabolism, etc., and (2) prediction of protein-protein interactions. These two specific aims are not only important scientific tasks, but also represent typical challenges that future genomic studies will face. Accomplishing these aims requires the integration of many heterogeneous sources of data, the prediction of multiple properties of genes and proteins, the explicit introduction of domain knowledge, the automatic introduction of knowledge from side information, scalability to large data sizes, and tolerance of large levels of noise.         n/a",Detecting relations among heterogeneous genomic datasets,6737944,R33HG003070,"['cell cycle', 'computer system design /evaluation', 'data collection', 'genome', 'informatics', 'meiosis', 'metabolism', 'protein protein interaction']",NHGRI,UNIVERSITY OF WASHINGTON,R33,2004,400000,-0.0005768722488898925
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6622259,R44HG002244,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' genotype', ' informatics', ' mathematical model', ' nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2003,560392,0.014805347626092915
"Second Generation DNA Sequence Management Tools   DESCRIPTION (provided by applicant): The human genome project spurred the            development of high throughput technologies, especially in the area of DNA           sequencing. Not only has this effort produced a draft of the human genome, it's      catalyzed development of an entire industry based on DNA sequencing and              genomics. Since these technologies produce enormous amounts of data they depend      on bioinformatics programs for data management. Phrap, Cross_Match,                  RepeatMasker and Consed are four programs that played an integral role in the        human genome project and became accepted as standard. However, as the                technology for sequencing has evolved, so too, have the applications. These new      applications include sequencing additional genomes, EST cluster analysis, and        genotyping and they have highlighted the need to update standard bioinformatics      programs to meet the current needs of a broader community. In this project we        will re-engineer Phrap, Cross_Match and Repeat Masker to improve performance by      optimizing these algorithms and developing a hierarchical data file to store         and manipulate assembled sequence data. Phrap and Cross_Match will also be           modified to use XML-formatted data allowing users to apply constraints to            sequence assembly. Lastly, we will develop a new program to review, edit, and        manipulate sequences, thus giving users unprecedented control over their data.      PROPOSED COMMERCIAL APPLICATION:                                                                                     Phrap is widely used in industry and academia for applications involving DNA sequences.  There are over 100 commercial sites that would benefit from new versions of Phrap that support incremental assemblies and utilize computer resources better.  An API for Phrap will encourage application development creating additional commercialization possibilities for algorithm and application developers. n/a",Second Generation DNA Sequence Management Tools,6444292,R44HG002244,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' genotype', ' informatics', ' mathematical model', ' nucleic acid sequence']",NHGRI,"GEOSPIZA, INC.",R44,2002,531259,0.014805347626092915
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,6180774,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2000,283617,0.01519261006761807
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,9976348,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2020,529154,0.008123747703706769
"Development of a joint machine learning/de novo assembly system for resolving viral quasispecies PROJECT SUMMARY Viral hepatitis from hepatitis B (HBV) establishes chronic infections in >250M people worldwide; chronicity is on the rise, and approximately one-third of the world’s population (2 billion) has serologic evidence of exposure. HBV coinfection with HCV and HIV is a hidden consequence of the substance use disorder epidemic. Viral populations have extremely high sequence diversity and rapidly evolve, which explains the vaccine failure rates and viral resistance to existing therapies and makes discovering lasting therapies extremely challenging. Next Generation Sequencing (NGS) is the method of choice to assess the intra-host virus population, termed a “quasispecies”. While a large set of short DNA sequencing reads are acquired that represent the virions in the quasispecies, computational technologies are limited in their analysis capabilities, resulting in particularly low resolution of complex HBV genomic structures. Another challenge is assembling NGS reads representing short fragment of the host genome into full strains (haplotypes) without knowledge of their true occurrence in the samples. To meet these challenges, GATACA is developing pathogen-specific bioinformatics software, GAT-ML (GATACA Assembly Tool – machine learning [ML]) to support treatment discovery and improve infection control. Its specifically designed algorithm utilizes novel ML methodologies adapted and modified for assisting genome assembly that will allow GAT-ML to reconstruct complete viral haplotypes and populations by learning the ‘language’ of the sequences. Tailored initially for HBV samples, GAT and its new ML system will be integrated for feasibility testing in this Phase I with the following Specific Aims: 1. Specific Aim 1. Build a joint learning system. Train and test natural language processing (NLP) methods on HBV genetic variation. 2. Specific Aim 2. Implement and test the machine learning methods in GAT (GAT-ML). We anticipate a working tool for characterizing HBV haplotypes, validated with multi-sourced datasets, and extensive testing and benchmarking of offline and integrated methods. The proposed project will develop and increase the capabilities of our novel computational tool, GAT, to help researchers identify the full spectrum of genetic features of a viral population—such as emergence and persistence of resistance or baseline polymorphisms regardless of their frequencies—and translate these findings to the development of new or improved antiviral drugs and other applications requiring high analytic sensitivity. GAT will particularly benefit researchers working in preclinical stages of drug development who require rapid, sensitive, and reliable results to inform decisions about which targets to advance to clinical trial testing.",Development of a joint machine learning/de novo assembly system for resolving viral quasispecies,10011686,R43AI152894,"['Adoption', 'Algorithm Design', 'Algorithms', 'Antiviral Agents', 'Benchmarking', 'Bioinformatics', 'Chronic', 'Chronic Hepatitis', 'Classification', 'Clinical Trials', 'Complex', 'Computer software', 'DNA Structure', 'DNA sequencing', 'Data', 'Data Set', 'Development', 'Dimensions', 'Epidemic', 'Failure', 'Frequencies', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'HIV', 'HIV/HCV', 'Haplotypes', 'Healthcare', 'Hepatitis B', 'Hepatitis B Virus', 'Infection Control', 'Joints', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Link', 'Liver diseases', 'Machine Learning', 'Metagenomics', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Natural Language Processing', 'Outcome', 'Pattern', 'Performance', 'Phase', 'Population', 'Population Analysis', 'Privatization', 'Research Personnel', 'Resistance', 'Resolution', 'Sampling', 'Semantics', 'Serological', 'Serotyping', 'Source', 'Speed', 'Substance Use Disorder', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Trust', 'Vaccines', 'Validation', 'Variant', 'Viral', 'Viral hepatitis', 'Virion', 'Virus', 'base', 'chronic infection', 'co-infection', 'commercialization', 'computerized tools', 'contig', 'design', 'drug development', 'improved', 'insertion/deletion mutation', 'machine learning algorithm', 'machine learning method', 'multiple data sources', 'neural network', 'next generation sequencing', 'novel', 'pathogen', 'pre-clinical', 'structural genomics', 'syntax', 'tool', 'viral resistance']",NIAID,"GATACA, LLC",R43,2020,267225,0.01594352632793696
"Genetic determinants of 4D genome folding in human cardiac development PROJECT SUMMARY A major unanswered question is how chromatin topology coordinates human development and cellular differentiation, and how genome folding is differentially regulated in human disease. It is thought that three- dimensional (3D) chromatin organization is driven by transcriptional regulators, but fundamental mechanisms of this regulation as it relates to disease-relevant human cells have not been well explored. We propose to elucidate the temporally dynamic 3D nucleome (4DN) that underlies human cardiac differentiation, its molecular underpinnings, and the impact of mutations that underly defective 4DN organization in human congenital heart disease (CHD). CHDs are the most common birth defect and arise from abnormal heart development. The genetic basis of CHD is largely mutations in genes encoding chromatin modifiers (e.g. WDR5, KMT2D) and transcription factors (TFs, e.g. TBX5, GATA4), many of which also cause adult-onset arrhythmias. The impact of CHD mutations on the 4DN has not been explored. We hypothesize that 3D genome folding is highly regulated during cardiac differentiation and is impacted by disease-causing mutations in transcriptional regulators and non-coding elements. We will use iPS cell models and machine learning to elucidate dynamic 3D chromatin organization in human cardiomyocytes and endothelial cells during normal and diseased cardiac differentiation. We propose 3 specific aims: Aim 1: Establish a kilobase-scale 4D map of genome folding in human cardiomyocytes (CM) and endothelial cell (EC) differentiation. We will use directed differentiation of human iPS cells towards the two major cell types of the developing heart: CMs and ECs, and using microC across a fine time course of differentiation we will define at kilobase scale the 3D organization of the genome, capturing the states of developmental intermediates and the final differentiated cells. This aim will generate an essential integrated 4DN template for discovery in cardiac differentiation. In Aim 2: we will Determine the regulatory and disease-related basis for cardiac 3D chromatin organization. We will perform microC in iPS cell lines with CHD-associated mutations in transcriptional regulators, differentiated into CMs and ECs. These findings will establish the degree to which CHD is caused by abnormal genome folding and chromatin states, with important relevance to other human cardiovascular diseases. Finally, Aim 3 will address High-throughput screening of millions of CHD and synthetic non- coding mutations with a deep-learning model of dynamic genome folding. We will build a deep-learning model predicting 3D chromatin contact frequencies across cardiac differentiation at kilobase-resolution. By introducing thousands of CHD patient deletions and other non-coding mutations in silico, we will prioritize variants likely to interact with transcriptional regulators to cause disease through disrupted genome folding. Several candidates will be validated in engineered iPS cells differentiated into CMs and ECs. These results will provide a novel platform for computational discovery of disease variant impact across diverse human diseases PROJECT NARRATIVE Congenital heart defects are present in 1-2 out of 100 births, and are caused by mutations in genes that may control the 3-dimensional organization of chromosomes. We will use human cellular models and Artificial Intelligence to understand how chromosome organization is controlled during heart development and altered by disease processes. This will reveal fundamental concepts of gene regulation and may lead to a better understanding congenital heart defects towards improving diagnosis and treatment.",Genetic determinants of 4D genome folding in human cardiac development,10118056,U01HL157989,"['3-Dimensional', 'ATAC-seq', 'Address', 'Adult', 'Architecture', 'Arrhythmia', 'Artificial Intelligence', 'Birth', 'CCCTC-binding factor', 'Cardiac', 'Cardiac Myocytes', 'Cardiac development', 'Cardiovascular Diseases', 'Cell Differentiation process', 'Cell Line', 'Cell model', 'Cells', 'ChIP-seq', 'Child', 'Chromatin', 'Chromatin Remodeling Factor', 'Chromosome Structures', 'Code', 'Complement', 'Complex', 'Congenital Abnormality', 'Congenital Heart Defects', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Endothelial Cells', 'Engineering', 'Enhancers', 'Family', 'Frequencies', 'GATA4 gene', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Transcription', 'Genome', 'Genomics', 'Heart', 'Heart Abnormalities', 'Heart Diseases', 'Histones', 'Human', 'Human Biology', 'Human Development', 'Lead', 'Machine Learning', 'Maps', 'Measures', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Patients', 'Phenotype', 'Process', 'Proteins', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Resolution', 'SMARCA2 gene', 'Structure', 'Time', 'Untranslated RNA', 'Variant', 'Work', 'cardiogenesis', 'cell type', 'cohesin', 'computational platform', 'congenital heart disorder', 'deep learning', 'disease-causing mutation', 'high throughput screening', 'histone modification', 'human disease', 'human model', 'human pluripotent stem cell', 'improved', 'in silico', 'machine learning method', 'novel', 'predictive modeling', 'promoter', 'stem cell differentiation', 'stem cell model', 'transcription factor']",NHLBI,J. DAVID GLADSTONE INSTITUTES,U01,2020,742240,-0.02407864871920406
"The interaction of myosin and the thin filament: how mutations cause allosteric dysfunction and their connection to genetic cardiomyopathy Project Summary: The long-term goal of this research program is to develop a rigorously experimentally validated all-atom computational model of the cardiac thin filament (CTF) bound to myosin S1 which provides a unique and accessible platform to identify novel, high resolution disease mechanisms linked to Hypertrophic Cardiomyopathy (HCM). In the prior funding period, we refined and extended our existing CTF computational model and successfully employed it to identify unique and clinically relevant allosteric disease mechanisms including HCM mutation-induced changes in myofilament Ca2+ kinetics, mutation-specific molecular causes of differential cardiac remodeling and disease progression. This included an in vivo validation via the development of a novel transgenic mouse model of cTnT-linked dilated cardiomyopathy and a predictive algorithm to determine the pathogenicity of cTnT mutations that out-performed existing computational approaches in a preliminary test. The key to these advances has been the ability of the current model to precisely identify and locate allosteric changes caused by mutations throughout all components of the CTF followed by closely coupled experimental validation and eventual in vivo model correlation. We now propose to significantly expand the biological complexity of the model to include myosin S1, the molecular motor that drives contraction and the second most common genetic cause of HCM. This important and challenging advance will facilitate a deeper understanding of disease pathogenesis by, for the first time, incorporating the role of molecular allosteric mechanisms between myosin S1 and thin filament. This new computational – experimental platform will be used for both mechanistic insight (for example used for the identification of novel myofilament disease targets,) and the development of a comprehensive deep-learning predictive algorithm to assign pathogenicity to both myosin and thin filament HCM mutations. The latter represents the first use of high-resolution structure, dynamics and function to predict HCM disease allele pathogenicity, a central challenge in the clinical management of these complex patients. Both the training and testing components of the deep learning development will utilize data from the highly annotated and curated SHaRe HCM registry thus greatly improving translational power. Two Specific Aims will be pursued: Aim 1 will utilize state of the art rare event simulation methods developed in one of our groups and refinement of existing unstructured domains of the CTF via FRET to establish the new model. Aim 2 will employ an extensive program of computational analysis and subsequent in vitro validation using pathogenic, variants of unknown significance and non- pathogenic HCM alleles derived from SHaRe to provide inputs to the machine learning environment for algorithm development. Novel disease mechanisms for myosin and thin filament HCM that include crosstalk between the two components will also be explored. Elucidation of these mechanisms can be the basis for robust molecular approaches to disease. Precision medicine and “molecular” medicine are concepts that aim to employ a patient’s genetic structure to discern the best medical treatments for disease. Hypertrophic cardiomyopathy is a genetic disease that afflicts 1/500 people. This application translates our knowledge of the molecular level effects of cardiac tissue mutation to disease and will aim to lead to eventual treatment.",The interaction of myosin and the thin filament: how mutations cause allosteric dysfunction and their connection to genetic cardiomyopathy,10071638,R01HL107046,"['Address', 'Alleles', 'Anisotropy', 'Artificial Intelligence', 'Biological', 'Biological Assay', 'Biology', 'Biophysics', 'Breath Tests', 'C-terminal', 'Cardiac', 'Chemistry', 'Clinical Management', 'Complex', 'Computer Analysis', 'Computer Models', 'Contracts', 'Coupled', 'Data', 'Data Set', 'Descriptor', 'Development', 'Differential Scanning Calorimetry', 'Dilated Cardiomyopathy', 'Disease', 'Disease Progression', 'Distant', 'Engineering', 'Enzymes', 'Event', 'Fluorescence Anisotropy', 'Fluorescence Resonance Energy Transfer', 'Functional disorder', 'Funding', 'Generations', 'Genetic', 'Genetic Diseases', 'Genetic Structures', 'Goals', 'Grant', 'Hand', 'Human', 'Hypertrophic Cardiomyopathy', 'In Vitro', 'Individual', 'Induced Mutation', 'Kinetics', 'Knowledge', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Microfilaments', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Medicine', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'Pathogenesis', 'Pathogenicity', 'Patients', 'Perception', 'Physiological', 'Play', 'Protein Conformation', 'Protein Dynamics', 'Proteins', 'Registries', 'Research', 'Resolution', 'Resources', 'Role', 'Sampling', 'Sarcomeres', 'Site', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick Filament', 'Thin Filament', 'Thinness', 'Time', 'Tissues', 'Training', 'Transgenic Mice', 'Translating', 'Validation', 'Variant', 'Work', 'algorithm development', 'automated analysis', 'base', 'cell motility', 'clinically relevant', 'deep learning', 'educational atmosphere', 'experimental study', 'improved', 'in vivo', 'in vivo Model', 'inherited cardiomyopathy', 'insight', 'machine learning algorithm', 'mouse model', 'neural network', 'next generation', 'novel', 'phosphorescence', 'precision medicine', 'prediction algorithm', 'programs', 'quantum chemistry', 'response', 'simulation', 'stopped-flow fluorescence', 'success', 'variant of unknown significance']",NHLBI,UNIVERSITY OF ARIZONA,R01,2020,585711,0.009801039681476583
"Computational Methods for Next-Generation GWAS Project Summary/Abstract  Predicting phenotypes from DNA sequence variation is a major goal for genetics with potential applications in evolutionary biology, crop breeding, and public health. A central challenge in this task is separating genetic and environmental effects on phenotypes. In natural populations breeding structure is often correlated with the environment across space such that different subpopulations experience different environments. For genome-wide association studies (GWAS) this creates a problem: genetic and environmental effects can be confounded by population structure, leading to inflated test statistics and low predictive power across populations (Bulik-Sullivan et al. 2015, Mathieson and Mcvean, 2012). Understanding when association studies are biased by population stratification and creating better methods to correct for it are thus important challenges for population genetics over the next decade.  To identify conditions under which existing methods of population stratification correction are subject to bias and develop robust new alternatives suitable for use with the continental-scale genomic datasets that are now routinely available for humans, we propose to use simulations and machine learning to separate the signals of fine-scale ancestry from polygenic phenotype association. In our first aim we will develop simulations of polygenic phenotype evolution in continuous space and use the output to evaluate existing methods of stratification control including linear mixed models, PC correction, and LD score regression. In this aim we will seek to identify the regions of parameter space – i.e. the strength of isolation by distance and the spatial distribution of environmental variation – in which existing methods can be expected to produce reliable effect size estimates, and establish guidelines for applications of GWAS to structured populations.  We will then train machine learning algorithms on real genotype data from humans and mosquitoes to describe continuous structure in large spatial samples using a variational autoencoder, a dimensionality reduction technique based on deep neural networks that can take advantage of both allele frequency and haplotype-based measures of differentiation in a single analysis and thus offer improved control of stratification inflation in GWAS relative to the now standard PCA regression approach. Last we will apply deep learning techniques to the problem of linking phenotypes and genotypes in structured samples by training neural networks on simulated phenotypes and empirical genetic data. By training our networks on empirical genetic data and incorporating contextual information about surrounding haplotype structure into the model, our networks should learn to discriminate causal associations from false positives created by population structure in the sample cohort, which will improve performance when attempting to identify associations with the real phenotype. These methods will be applied to existing genomic datasets of height in humans, tested against the current state-of-the-art approaches, and packaged as scalable software for the broader scientific community. Project Narrative Separating the signals of polygenic trait association and population structure has emerged as a major challenge for the interpretation of genome-wide association studies (GWAS). We propose to develop new simulations of populations evolving in continuous space that will allow us to rigorously benchmark existing methods of stratification control in GWAS while fully controlling the underlying demographic and selective process. We will then apply deep learning techniques to develop (1) a new method of dimensionality reduction to test as a covariate for ancestry in GWAS, and (2) a neural network that identifies genotype-phenotype connections while controlling for population structure in the sample cohort.",Computational Methods for Next-Generation GWAS,9910009,F32GM136123,"['Agriculture', 'Benchmarking', 'Biology', 'Breeding', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Culicidae', 'DNA Sequence', 'Data', 'Dimensions', 'Environment', 'Evolution', 'Gene Frequency', 'Genetic', 'Genotype', 'Geographic Locations', 'Goals', 'Guidelines', 'Haplotypes', 'Health', 'Heart Diseases', 'Height', 'Human', 'Image', 'Learning', 'Linear Models', 'Linear Regressions', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oligogenic Traits', 'Output', 'Performance', 'Phenotype', 'Polygenic Traits', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Positioning Attribute', 'Process', 'Public Health', 'Running', 'Sampling', 'Signal Transduction', 'Spatial Distribution', 'Stratification', 'Structure', 'Sum', 'Techniques', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'Variant', 'autoencoder', 'base', 'biobank', 'cohort', 'deep learning', 'deep neural network', 'diverse data', 'experience', 'genome wide association study', 'genome-wide', 'genomic data', 'human data', 'image reconstruction', 'improved', 'large scale simulation', 'learning strategy', 'machine learning algorithm', 'neural network', 'next generation', 'polygenic risk score', 'population stratification', 'simulation', 'statistics', 'supervised learning', 'tool', 'trait']",NIGMS,UNIVERSITY OF OREGON,F32,2020,19290,0.022269262008820873
"Center for Critical Assessment of Genome Interpretation Genomic data hold the promise of revolutionizing our understanding and treatment of human disease. Multiple barriers stand between the acquisition of the data and realizing these and other benefits. Rapid accumulation of genomic data far exceeds our capacity to reliably interpret genomic variation. New developments in artificial intelligence and machine learning, combined with increased computing power and domain knowledge, provide hope for the deployment of enhanced computational tools in both basic research and clinical practice. Use of these methods critically depends upon reliable characterization of their performance.  The Center for Critical Assessment of Genome Interpretation (C-CAGI) will address these needs, through objective evaluation of the state of the art in relating human genetic variation and health. CAGI has had five editions since 2010 with 50 challenges posed to the community taken on by hundreds of predictors, leading to scores of publications about prediction methods and their assessment. We propose for C-CAGI to continue to advance the field of variant interpretation through the following Specific Aims: 1. Develop community experiments to evaluate the quality of computational methods for interpreting genomic variation data. C-CAGI will conduct community experiments in which participants make bona fide blinded predictions of disease related phenotypes on the basis of genomic data. We will engage a diverse predictor community to spur innovation. The CAGI Ethics Forum will vet studies to ensure that privacy and sharing maintain the highest standards and will educate the community. 2. Assess the quality of current computational methods for interpreting genomic variation data; highlight innovations and progress at interactive conferences. Predictions will be evaluated by independent assessors, who will be supported by new assessment approaches from C-CAGI. Results will be presented at CAGI experiment conferences with deep technical engagement, which will be interleaved with reflective CAGIâ meetings that create an environment for a comprehensive evaluation of the field, facilitating identification of major bottlenecks and problems faced by the current genome interpretation approaches. 3. Broadly disseminate the results and conclusions from the CAGI experiments and analysis. C-CAGI will outreach to the broader scientific and clinical community through its publications, and the creation of a calibrated reference integrated into the most common workflows for ready adoption. CAGI will also be represented at international meetings with presentations and workshops. 4. Operate effectively and responsively. C-CAGI will operate efficiently as it closely interacts with hundreds of participants. CAGI will build upon a robust information infrastructure that securely facilitates data dissemination, prediction submission, and assessment. Genomic variation is responsible for numerous rare diseases, for propensity for many common traits and diseases, for drug response, and is a key characteristic of cancer evolution. At present, our ability to characterize genetic differences far exceeds our capacity to interpret them either for basic research understanding or for clinical application. The Center for Critical Assessment of Genome Interpretation, operating on robust ethical foundations, will provide an evaluation of the current state of the art and help promote progress in understanding the impact of genomic variation.",Center for Critical Assessment of Genome Interpretation,9937546,U24HG007346,"['Address', 'Adoption', 'Affect', 'Amino Acid Sequence', 'Artificial Intelligence', 'Basic Science', 'Blinded', 'Characteristics', 'Clinical', 'Communities', 'Computing Methodologies', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Ensure', 'Environment', 'Ethics', 'Evaluation', 'Evolution', 'Foundations', 'Genetic', 'Genetic Variation', 'Genome', 'Health', 'Human Genetics', 'Infrastructure', 'International', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Nucleotides', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Privacy', 'Provider', 'Publications', 'RNA Splicing', 'Rare Diseases', 'Secure', 'Structure', 'Trust', 'Variant', 'Work', 'base', 'clinical application', 'clinical practice', 'computerized tools', 'data acquisition', 'data dissemination', 'exome', 'experimental study', 'genetic information', 'genetic variant', 'genomic data', 'genomic variation', 'high standard', 'human disease', 'innovation', 'meetings', 'multiple omics', 'operation', 'outreach', 'response', 'symposium', 'trait', 'whole genome']",NHGRI,UNIVERSITY OF CALIFORNIA BERKELEY,U24,2020,314933,0.026096731669895252
"Center for Critical Assessment of Genome Interpretation Genomic data hold the promise of revolutionizing our understanding and treatment of human disease. Multiple barriers stand between the acquisition of the data and realizing these and other benefits. Rapid accumulation of genomic data far exceeds our capacity to reliably interpret genomic variation. New developments in artificial intelligence and machine learning, combined with increased computing power and domain knowledge, provide hope for the deployment of enhanced computational tools in both basic research and clinical practice. Use of these methods critically depends upon reliable characterization of their performance.  The Center for Critical Assessment of Genome Interpretation (C-CAGI) will address these needs, through objective evaluation of the state of the art in relating human genetic variation and health. CAGI has had five editions since 2010 with 50 challenges posed to the community taken on by hundreds of predictors, leading to scores of publications about prediction methods and their assessment. We propose for C-CAGI to continue to advance the field of variant interpretation through the following Specific Aims: 1. Develop community experiments to evaluate the quality of computational methods for interpreting genomic variation data. C-CAGI will conduct community experiments in which participants make bona fide blinded predictions of disease related phenotypes on the basis of genomic data. We will engage a diverse predictor community to spur innovation. The CAGI Ethics Forum will vet studies to ensure that privacy and sharing maintain the highest standards and will educate the community. 2. Assess the quality of current computational methods for interpreting genomic variation data; highlight innovations and progress at interactive conferences. Predictions will be evaluated by independent assessors, who will be supported by new assessment approaches from C-CAGI. Results will be presented at CAGI experiment conferences with deep technical engagement, which will be interleaved with reflective CAGIâ meetings that create an environment for a comprehensive evaluation of the field, facilitating identification of major bottlenecks and problems faced by the current genome interpretation approaches. 3. Broadly disseminate the results and conclusions from the CAGI experiments and analysis. C-CAGI will outreach to the broader scientific and clinical community through its publications, and the creation of a calibrated reference integrated into the most common workflows for ready adoption. CAGI will also be represented at international meetings with presentations and workshops. 4. Operate effectively and responsively. C-CAGI will operate efficiently as it closely interacts with hundreds of participants. CAGI will build upon a robust information infrastructure that securely facilitates data dissemination, prediction submission, and assessment. Genomic variation is responsible for numerous rare diseases, for propensity for many common traits and diseases, for drug response, and is a key characteristic of cancer evolution. At present, our ability to characterize genetic differences far exceeds our capacity to interpret them either for basic research understanding or for clinical application. The Center for Critical Assessment of Genome Interpretation, operating on robust ethical foundations, will provide an evaluation of the current state of the art and help promote progress in understanding the impact of genomic variation.",Center for Critical Assessment of Genome Interpretation,9937546,U24HG007346,"['Address', 'Adoption', 'Affect', 'Amino Acid Sequence', 'Artificial Intelligence', 'Basic Science', 'Blinded', 'Characteristics', 'Clinical', 'Communities', 'Computing Methodologies', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Ensure', 'Environment', 'Ethics', 'Evaluation', 'Evolution', 'Foundations', 'Genetic', 'Genetic Variation', 'Genome', 'Health', 'Human Genetics', 'Infrastructure', 'International', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Nucleotides', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Privacy', 'Provider', 'Publications', 'RNA Splicing', 'Rare Diseases', 'Secure', 'Structure', 'Trust', 'Variant', 'Work', 'base', 'clinical application', 'clinical practice', 'computerized tools', 'data acquisition', 'data dissemination', 'exome', 'experimental study', 'genetic information', 'genetic variant', 'genomic data', 'genomic variation', 'high standard', 'human disease', 'innovation', 'meetings', 'multiple omics', 'operation', 'outreach', 'response', 'symposium', 'trait', 'whole genome']",NHGRI,UNIVERSITY OF CALIFORNIA BERKELEY,U24,2020,478516,0.026096731669895252
"A Multivariate Mediation and Deep Learning Framework for Genome-Connectome -Substance Use Research Substance use and addiction are complex biopsychosocial disorders influenced by both genetic and environmental factors. A key challenge in addiction genetics research is to understand how multiple genetic variants interactively influence addiction traits through impacting the central nervous system. To address this challenge, we propose a large-scale mediation analysis framework to identify addiction-related gene-brain circuitry pathways, using nicotine addiction as the targeted disorder, although the platform will be readily applicable for other addiction-related disorders and phenotypes. We will fully leverage the complex and interactive interdependent relationships between the imaging-genetics data and perform multivariate statistical inference with simultaneously increased statistical power and reduce false positive rates. The results will precisely identify multiple sets of genetic variants that interactively alter brain functional and structural circuitries, and then influence nicotine addiction. We will further supplement the mediation results with deep learning algorithms to study how genetic variants non-linearly and interactively coordinate to influence nicotine addiction and explain the phenotypic variance. Novel network topology based convolutional and pooling functions will be developed to achieve optimal prediction accuracy of addiction traits using genome-connectome pathways. All models and findings will be carefully validated through multiple independent large-sample data sets of imaging-genetics studies for nicotine addiction for ensuring the replicability and reliability of our findings derived from this framework. We plan to produce a freely available and user-friendly software incorporating the mediation analysis framework and deep learning algorithms enabling the complex whole genome - connectome analysis for addiction genetics research. Nicotine addiction is a worldwide public health priority and imposing health and economic burden on millions of individuals and families. This proposal seeks to identify how multiple genetic variants interactively influence the nicotine addiction through impacting brain circuitries. The improved understanding of genome-connectome pathways of addiction could lead to more effective treatment and prevention.",A Multivariate Mediation and Deep Learning Framework for Genome-Connectome -Substance Use Research,9983690,DP1DA048968,"['Address', 'Alcohol or Other Drugs use', 'Brain', 'Complex', 'Data', 'Data Set', 'Disease', 'Economic Burden', 'Ensure', 'Environmental Risk Factor', 'Family', 'Genes', 'Genetic', 'Genetic Research', 'Genetic study', 'Genome', 'Individual', 'Lead', 'Mediation', 'Modeling', 'Neuraxis', 'Nicotine Dependence', 'Pathway interactions', 'Phenotype', 'Prevention', 'Research', 'Sampling', 'Structure', 'Substance Addiction', 'addiction', 'base', 'biopsychosocial', 'brain circuitry', 'connectome', 'deep learning', 'deep learning algorithm', 'effective therapy', 'genetic variant', 'health economics', 'imaging genetics', 'improved', 'nicotine use', 'novel', 'public health priorities', 'trait', 'user friendly software', 'whole genome']",NIDA,UNIVERSITY OF MARYLAND BALTIMORE,DP1,2020,463500,0.03556073352943952
"A novel human T-cell platform to define biological effects of genome editing PROJECT SUMMARY Genome editing technologies have extraordinary potential as new genomic medicines that address underlying genetic causes of human disease; however, it remains challenging to predict their long-term safety, because we do not know the consequences of potential side effects of genome editing such as off-target mutations or immunogenicity. Our long-term goal is to understand and predict such unintended biological effects to advance the development of safe and effective therapies. T-cells are an ideal cellular model because: 1) they are highly relevant as the most widely used cells for development of therapeutic genome editing strategies (such as cell-based treatments for HIV and cancer) and 2) mature T-cells encode a diverse T-cell receptor repertoire that can be exploited as built-in cellular barcodes for quantifying clonal expansion or depletion in response to specific treatments. We, therefore, propose the following specific aims: 1) to predict which unintended editing sites have biological effects on human T-cells by integrating large-scale genome-wide activity and epigenomic profiles with state-of-the-art deep learning models and 2) to develop a human primary T-cell platform to detect functional effects of genome editing by measuring clonal representation, off-target mutation frequencies, immunogenicity, or gene expression. If successful, our experimental and predictive framework will profoundly increase confidence in the safety of the next generation of promising genome editing therapies. PROJECT NARRATIVE Genome editing technologies have extraordinary potential as the basis of new genomic medicines that address the underlying genetic causes of human disease; however, it is challenging to predict their long-term safety, because we do not know the consequences of potential unintended side effects of genome editing such as off-target mutations or immunogenicity. To define the biological effects of genome editing strategies, we will develop a human primary T-cell platform to sensitively detect functional effects coupled with an empirically-trained artificial intelligence models to predict them. Together, our platform will significantly improve confidence in safety assessments of promising genome editing therapeutics.",A novel human T-cell platform to define biological effects of genome editing,10016298,U01AI157189,"['Address', 'Advanced Development', 'Adverse effects', 'Affect', 'Artificial Intelligence', 'Bar Codes', 'Benign', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Cell model', 'Cell physiology', 'Cells', 'Chromatin', 'Clonal Expansion', 'Complex', 'Coupled', 'DNA Methylation', 'Detection', 'Engineering', 'Epitopes', 'Frequencies', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Transcription', 'Genetic Variation', 'Genomic medicine', 'Genomics', 'Goals', 'HIV', 'Human', 'Human Genetics', 'Human Genome', 'Immunologic Deficiency Syndromes', 'In Vitro', 'Inherited', 'Malignant Neoplasms', 'Maps', 'Mature T-Lymphocyte', 'Measures', 'Methods', 'Modeling', 'Mutation', 'Oncogenic', 'Organizational Change', 'Outcome', 'Peptide Library', 'Peripheral Blood Mononuclear Cell', 'Phenotype', 'Population', 'Proto-Oncogenes', 'Regulatory Element', 'Retroviral Vector', 'Ribonucleoproteins', 'Safety', 'Site', 'Site-Directed Mutagenesis', 'Standardization', 'Streptococcus pyogenes', 'T cell response', 'T-Cell Proliferation', 'T-Cell Receptor', 'T-Lymphocyte', 'T-cell receptor repertoire', 'Technology', 'Testing', 'Therapeutic', 'Training', 'Variant', 'adaptive immune response', 'adverse outcome', 'base', 'comparative genomics', 'cytokine', 'deep learning', 'effective therapy', 'epigenomics', 'functional genomics', 'gene therapy', 'genome editing', 'genome-wide', 'genotoxicity', 'histone modification', 'human disease', 'immunogenic', 'immunogenicity', 'improved', 'in vivo', 'machine learning method', 'next generation', 'novel', 'novel therapeutics', 'off-target mutation', 'off-target site', 'response', 'safety assessment', 'safety testing', 'side effect', 'therapeutic development', 'therapeutic gene', 'therapeutic genome editing', 'transcriptome sequencing']",NIAID,ST. JUDE CHILDREN'S RESEARCH HOSPITAL,U01,2020,610710,0.0011613476878709094
"A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning SUMMARY Adaptive evolution (AE) is both a “force of good” as it can help to optimize biological processes in industry, but it is also a “force of frustration” when infectious diseases exploit AE to escape the host immune system or become resistant to drugs. It has long been assumed close to impossible to make predictions on AE due to the presumed predominating influences of random forces and events. However, the observation that evolutionary repeatability across traits and species is far more common than previously thought, suggests that AE, with the right data and approach, may become (partially) predictable. Indeed, we found through experiments with the bacterial pathogen Streptococcus pneumoniae on its response to antibiotics and the emergence of antimicrobial resistance, that in order to make AE predictable a detailed understanding of at least two aspects of the bacterial system are required: 1.) the genetic constraints of the system (i.e. the architecture of the organismal network); and 2.) where and how in the system stress is experienced and processed. We showed that by mapping out ~25% of the bacterium's network, determining phenotypic and transcriptional antibiotic responses, applying network analyses to capture and quantify the responses in a network context, and exploiting experimental evolution to pin-point adaptive mutations in the genome it becomes possible, by means of machine learning, to uncover hidden patterns in the data that make AE predictions feasible. This means that the network in interaction with the environment shapes the adaptive landscape, it limits available solutions and makes some solutions more likely than others, thereby driving repeatability and enabling predictability. In this proposal we build on these exciting developments with the goal to map out the constraints of S. pneumoniae's entire network and develop a machine learning model that can forecast adaptive evolution a priori, and on a genome-wide scale. To accomplish this, we combine in aim 1 parts of Tn-Seq, dTn-Seq and Drop-Seq to finalize a new tool Tn-Seq^2 (Tn-Seq squared) that is able to map genetic-interactions in high-throughput and genome-wide. We use Tn-Seq^2 to reconstruct the first genome-wide genetic interaction network for S. pneumoniae in the presence of 20 antibiotics. In aim 2 we create 85 HA-tagged Transcription factor induction (TFI) strains and: a) Determine with ChIP-Seq the DNA-binding sites for all 85 TFs in S. pneumoniae; b) By overexpressing each TFI strain followed by RNA- Seq we determine each TFs regulatory signature; c) Use a Transcriptional Regulator Induced Phenotype screen in the presence of 20 antibiotics to untangle environment specific links between genetic and transcriptional perturbations and their phenotypic outcomes. Lastly, in aim 3, we train and test a variety of machine learning approaches to design an optimal model that predicts which genes in the genome are most likely to adapt in the presence of a specific antibiotic. The development of this predictive AE model, will not only be useful in predicting the emergence of antibiotic resistance, but the strategy should be valuable for most any biological field for which adaptive changes are important, ranging from biological engineering to cancer. NARRATIVE Adaptive evolution (AE) is the driving force behind the emergence of antibiotic resistance and if it were possible to predict AE before it happens, it could help in preventing resistance. Here we use cutting-edge existing and newly designed genomics tools and analytical approaches to develop a machine learning model that can predict AE a priori, and on a genome-wide scale.",A priori adaptive evolution predictions for antibiotic resistance through genome-wide network analyses and machine learning,10049219,R01AI148470,"['Achievement', 'Affect', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Automobile Driving', 'Bacteria', 'Binding Sites', 'Biological', 'Biological Process', 'Biomass', 'ChIP-seq', 'Communicable Diseases', 'Complex', 'DNA Binding', 'Data', 'Development', 'Drug resistance', 'Engineering', 'Ensure', 'Environment', 'Escherichia coli', 'Event', 'Evolution', 'Exposure to', 'Fermentation', 'Frustration', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Immune system', 'Immunotherapeutic agent', 'Industry', 'Life', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Microfluidics', 'Modeling', 'Mutation', 'Organism', 'Outcome', 'Pathway Analysis', 'Pattern', 'Phenotype', 'Photosynthesis', 'Planet Earth', 'Process', 'Resistance', 'Shapes', 'Streptococcus pneumoniae', 'Stress', 'System', 'Testing', 'Time', 'Training', 'Yeasts', 'design', 'driving force', 'droplet sequencing', 'emerging antibiotic resistance', 'emerging antimicrobial resistance', 'experience', 'experimental study', 'genetic architecture', 'genome-wide', 'genomic tools', 'network architecture', 'novel', 'overexpression', 'pathogenic bacteria', 'predictive modeling', 'prevent', 'process optimization', 'programs', 'response', 'tool', 'trait', 'transcription factor', 'transcriptome', 'transcriptome sequencing', 'transposon sequencing']",NIAID,BOSTON COLLEGE,R01,2020,391250,-0.010635120352659696
"Scalable detection and interpretation of structural variation in human genomes PROJECT SUMMARY Structural variation (SV), is a diverse class of genome variation that includes copy number variants (CNVs) such as deletions and duplications, as well as balanced rearrangements, such as inversions and reciprocal translocations. A typical human genome harbors >4,000 SVs larger than 300bp and their large size increases the potential to delete or duplicate genes, disrupt chromatin structure, and alter expression. Despite their prevalence and potential for phenotypic consequence, SVs remain notoriously difficult to detect and genotype with high accuracy. Much of this difficulty is driven by the fact DNA sequence alignment “signals” indicating SVs are far more complex than for single-nucleotide and insertion deletion variants. Unlike SNP alignments that vary only in allele state, alignments supporting SVs vary in state (supports an alternate structure or not) alignment location, and type. Consequently, the accuracy of SV discovery is much lower than that of SNPs and INDELs. Furthermore, SV pipelines scale poorly and are difficult to run. These challenges are a barrier for single genome analysis and studies of families must invest substantial effort into eliminating a sea of false positives. These problems become exponentially more acute for large-scale sequencing efforts such as TOPmed, the Centers for Common Disease Genetics, and the All of Us program. Software efficiency is key to scalability for such projects. However, of equal importance is comprehensive, accurate discovery.  Building upon more than a decade of software development experience and analyzing SV in diverse disease contexts, we have invested significant effort into understanding the causes of the insufficient accuracy for SV discovery. These efforts, together with our research and development experience in this area, give us unique insight into improving the accuracy and scalability of SV discovery. Our goal is to narrow the accuracy gap between SNP/INDEL variation and structural variation discovery. These developments will empower studies of human genomes in diverse contexts and will therefore have broad impact. Our goals are to: 1. Develop a deep learning model to correct systematic variation in sequence depth. This new machine  learning model will correct systematic biases in DNA sequence depth and dramatically improve the  discovery of deletions and duplications. 2. Improve the speed, scalability, and accuracy of SV detection and genotyping. Using new algorithms,  we will bring the accuracy of SV detection much closer to that of SNP and INDEL discovery and allow  accurate SV discovery to be deployed at scale. 3. Create a map of genomic constraint for SV from population-scale genome analysis. We will deploy  our new methods to detect and genotype structural variation among tens of thousands of human genomes.  The resulting SV map will empower the creation of a model of genomic constraint for SV and enable new  software to predict deleterious SVs, especially in the noncoding genome. PROJECT NARRATIVE Single-nucleotide DNA changes paint an incomplete picture of a human’s genome. A more complete picture must include a genome's structural variation (SV), an important class of genome variation that includes copy number variants (CNVs) such as deletions and duplications. However, existing methods have poor accuracy. As the genetics community transitions to large-scale genome sequencing studies, there is an acute need for improved SV discovery methods. This proposal introduces a series of algorithmic and software innovations that will empower SV discovery, genotyping, and interpretation in large-scale human disease studies.",Scalable detection and interpretation of structural variation in human genomes,9973582,R01HG010757,"['Acute', 'Affect', 'Algorithmic Software', 'Algorithms', 'All of Us Research Program', 'Alleles', 'Area', 'Automobile Driving', 'Biological Assay', 'Chromatin Structure', 'Chromosome Structures', 'Clip', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer software', 'Copy Number Polymorphism', 'DNA', 'DNA Sequence', 'Data', 'Data Reporting', 'Detection', 'Development', 'Disease', 'Environment', 'Error Sources', 'Exhibits', 'Family Study', 'Funding', 'Future', 'Gene Duplication', 'Gene Expression', 'Gene Fusion', 'Gene Structure', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Individual', 'Laboratories', 'Large-Scale Sequencing', 'Location', 'Machine Learning', 'Maps', 'Methods', 'Modeling', 'Noise', 'Nucleotides', 'Paint', 'Pathogenicity', 'Performance', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Process', 'Reciprocal Translocation', 'Research', 'Running', 'Sampling', 'Sea', 'Sensitivity and Specificity', 'Sequence Alignment', 'Series', 'Signal Transduction', 'Software Tools', 'Source', 'Speed', 'Structure', 'Systematic Bias', 'Techniques', 'Technology', 'Training', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'algorithm development', 'base', 'convolutional neural network', 'deep learning', 'developmental disease', 'dosage', 'exome', 'experience', 'genome analysis', 'genome sequencing', 'genome-wide', 'human disease', 'improved', 'innovation', 'insertion/deletion mutation', 'insight', 'large datasets', 'method development', 'nanopore', 'novel', 'prevent', 'research and development', 'software development', 'success', 'tool', 'variant detection', 'whole genome']",NHGRI,UNIVERSITY OF UTAH,R01,2020,692048,0.031908742065571274
"Mobile Genetic Elements and Clinical Outcomes in Staphylococcus aureus Bacteremia Project Summary Antimicrobial resistance (AMR) and its impact on health has been recognized as one of the most serious public health threats facing society. Significantly, the vast majority of acquired AMR genes are carried on mobile genetic elements (MGEs), which include plasmids, insertion sequences, and transposons. One of the most important hospital and community-associated pathogens harboring resistance genes is Staphylococcus aureus, which causes more than 80,000 infections and 11,000 deaths each year in the United States. S. aureus readily acquire MGEs, which encompass more than 20% of the genome for most strains, and these elements have been central to the establishment and broad spread of resistance to antibiotics such as oxacillin and vancomycin. Additionally, S. aureus is capable of causing a wide range of infections, including bacteremia, with a mortality rate up to 30%. Utilizing an unparalleled collection of S. aureus strains from a cohort of patients in Central and South America with bacteremia, I seek to develop a framework for the identification and comparison of circulating MGEs through the use of bacterial phylogenetics, clinical epidemiology, and machine learning. This dataset will serve as the foundation for my training to become an independent scientist. To begin interrogating this exceptional strain collection, we have generated Illumina short-read whole genome sequencing data on 1,087 S. aureus bacteremia isolates to identify MGEs, and will leverage novel ultra-long read sequencing methodologies to fully characterize the position and variations of these elements. The three aims within this proposal are designed to elucidate the role of MGEs in driving the genetic diversification of endemic S. aureus clades, and identify if they serve as adaptation hotspots when put under selective pressure from the host immune system or antibiotics. First, I will characterize the repertoire of MGEs within this large cohort of isolates and apply gene-order and Bayesian time-measured phylogenetics to identify the predominant MGEs within each clade and how frequently they are acquired and lost. Second, I will assess the MGE diversity within isolates collected serially from the same individual. I hypothesize these MGEs will be the primary variation points and will be more important than single nucleotide polymorphisms (SNPs) to the adaptation to selective pressures such as antibiotics. Third, I will identify the clinical (age, BMI, and present comorbidities) and genomic (SNPs, MGEs, and genes) features that are predictive of the 30-day mortality in the predominant clades of S. aureus within our dataset. I theorize these genetic and clinical signatures will be different for each clade as they possess different repertoires of MGEs. The Center for Antimicrobial Resistance and Microbial Genomics in The University of Texas Health Sciences Center at Houston has a firm commitment to understanding and reducing AMR and AMR infections. This provides an exceptional environment to conduct my research elucidating the role of MGEs in the clinical outcomes of S. aureus bacteremia, and to develop as an investigator and participate in the training offered to make the transition to independence. Project Narrative Antimicrobial resistance (AMR) and its impact on health has been recognized as one of the most serious global public health threats facing our society. This proposal aims to clarify the role mobile genetic elements play in transmitting antimicrobial resistance and driving genetic diversity within endemic Staphylococcus aureus lineages causing bacteremia. Additionally, this research will provide the platform for the career development of a young scientist focused on bacterial phylogenetics, clinical epidemiology, and machine learning methods to tackle the dire consequences of AMR.",Mobile Genetic Elements and Clinical Outcomes in Staphylococcus aureus Bacteremia,10055522,K01AI148593,"['Age', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Automobile Driving', 'Bacteremia', 'Bacterial Genome', 'Bypass', 'Carbon', 'Centers for Disease Control and Prevention (U.S.)', 'Central America', 'Cessation of life', 'Clinical', 'Clonal Expansion', 'Collection', 'Communities', 'Complex', 'DNA Insertion Elements', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Elements', 'Endocarditis', 'Environment', 'Evolution', 'Foundations', 'Gene Order', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Geographic Locations', 'Geography', 'Health', 'Health Sciences', 'Horizontal Gene Transfer', 'Hospitals', 'Immune', 'Immune system', 'Individual', 'Infection', 'Laboratories', 'Light', 'Machine Learning', 'Measures', 'Methodology', 'Microbial Biofilms', 'Mobile Genetic Elements', 'Molecular Genetics', 'Outcome', 'Oxacillin', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Phylogenetic Analysis', 'Phylogeny', 'Plasmids', 'Play', 'Population', 'Positioning Attribute', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Resistance to infection', 'Role', 'Sampling', 'Science', 'Scientist', 'Sepsis', 'Single Nucleotide Polymorphism', 'Site', 'Skin Tissue', 'Societies', 'Soft Tissue Infections', 'South America', 'Staphylococcus aureus', 'Technology', 'Texas', 'Time', 'Training', 'Treatment Failure', 'United Nations', 'United States', 'United States National Institutes of Health', 'Universities', 'Vancomycin', 'Variant', 'Virulence', 'Virulence Factors', 'Work', 'beta-Lactams', 'career development', 'clinical epidemiology', 'clinically relevant', 'cohort', 'common treatment', 'comorbidity', 'design', 'fitness', 'genetic signature', 'genome sequencing', 'human pathogen', 'insight', 'machine learning method', 'methicillin resistant Staphylococcus aureus', 'microbial genomics', 'mortality', 'nanopore', 'novel', 'pathogen', 'predictive signature', 'pressure', 'random forest', 'reconstruction', 'resistance gene', 'tool', 'transmission process', 'whole genome']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,K01,2020,129870,0.0033453503049029575
"Inferring selection from human population genomic data Project Summary/Abstract Identifying genomic regions responsible for recent adaptation is a major challenge in population genetics. Particularly in humans, the task of confidently detecting the action of recent adaptive natural selection (or positive selection) has proved troublesome. Indeed there is considerable controversy over whether recent positive selection has a substantial impact on human genetic variation. The work proposed here will address this problem by creating a more complete map of positive selection across many human populations, identifying selection on de novo mutations as well as selection on previously standing variation.  Specifically, the proposed research seeks to construct a scan for positives election that is more robust and accurate than any currently existing methods (Aim 1). This tool will utilize supervised machine learning techniques allowing it combine information from a number of existing tests for natural selection, and will be tested extensively on a large suite of population genetic simulations presenting a wide range of potentially confounding scenarios. This tool will then be released to the public. Next, it will be applied to 26 human populations in which a large sample of genomes have been sequenced by the 1000 Genomes Project (Aim 2), revealing similarities and differences in the tempo, mode, and targets of adaptive evolution across human populations. Finally, because selection on both beneficial and deleterious mutations skews genetic variation, our method will be used to identify regions of the genome least affected by natural selection, which will in turn be used to produce more accurate inferences of human demographic histories (Aim 3).  The mentored phase of this work will be performed within the Department of Genetics at Rutgers University. This is an intellectually stimulating environment with numerous journal clubs, an excellent seminar series, and several other research groups using computational techniques. The project will be performed under the stewardship of Dr. Andrew Kern, from whom the candidate will also receive training in machine learning and population genetics. Dr. Schrider will also receive training in population genetics and guidance from Dr. Jody Hey (Co-mentor) at nearby Temple University. This training will help Dr. Schrider acquire skills that will aid not only in the completion of the proposed work but also his transition to principle investigator of an internationally recognized independent research program studying the evolutionary forces driving patterns of human genetic variation. Project Narrative Detecting genes underpinning recent human adaptation remains a major challenge, and such genes are often associated with human disease. The work proposed here seeks to use supervised machine learning techniques to detect genomic regions responsible for recent adaptation across 26 different human populations. This work will also clarify human population size and migration histories, information that has implications for the prevalence of disease-causing mutations and efforts to identify them.",Inferring selection from human population genomic data,9868315,R00HG008696,"['Address', 'Affect', 'Africa South of the Sahara', 'Computational Technique', 'Data', 'Environment', 'Evolution', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Goals', 'Homo sapiens', 'Human', 'Human Genetics', 'Human Genome', 'International', 'Journals', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Mutation', 'Natural Selections', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Population Genetics', 'Population Sizes', 'Prevalence', 'Recording of previous events', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Series', 'Site', 'Techniques', 'Testing', 'Training', 'Universities', 'Variant', 'Work', 'base', 'de novo mutation', 'disease-causing mutation', 'driving force', 'fitness', 'genomic data', 'human disease', 'human population genetics', 'machine learning method', 'population migration', 'pressure', 'programs', 'sample fixation', 'simulation', 'skills', 'statistics', 'supervised learning', 'tool']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R00,2020,237600,0.01469674188159728
"Development of statistical genetics methodology We continue to develop machine learning methods in genome-wide association studies and in analyses of whole-exome sequence data, and to explore their utility, particularly with respect to power and detection of gene-gene and gene-environment interactions. We previously published a study using GWAS genotype data from the Framingham Heart Study data repository with computer simulated trait data, thus allowing us to show that these methods may be able to detect interaction effects in suitably-powered studies. In the past, we have evaluated the power of several of these methods in whole-exome sequence data from the 1000 Genomes Project using computer simulated phenotypes as part of Genetic Analysis Workshop 17 (GAW17). We published several papers concerning data mining in the GAW17 data in late 2011. We have published a paper showing that our novel recurrency method in Random Forests seems to better differentiate between variables of high importance vs. low importance than other current methods. We have also used this recurrency approach to detect low quality SNVs in whole exome and whole genome sequence data and applied this method to GAW19 data. Ongoing studies have also shown that this method can detect epistatic interactions in the absence of main effects in simulated genetic data, with these results presented at several scientific meetings. We have further developed and tested a limited permutation method that allows estimation of false positive rates in conjunction with our recurrency approach. Simulations further suggest that our new recurrency method is powerful in multiple situations and controls false positives and that it allows the detection of epistatic interactions in a more powerful fashion than is possible with parametric methods when there are no main effects. We have developed and released a software package, r2VIM, which is available on Dr. Bailey-Wilsons website for broad access and have published three papers describing this method. We are currently developing The Machine Suite which will be an extension of r2VIM. In this reporting period we have  further improved control of false positive rates while retaining excellent power, adding multistep, weighted approaches that we are calling weighted replanting to increase power when number of features is very large and there are only interaction effects on risk of disease or when such interactions exist in the presence of large numbers of other additive polygenic risk variants. Simulations confirm this excellent power and false positive control under a wide variety of realistic genome-wide scenarios.  A manuscript presenting this new method, r2VIM-W, is in preparation and results will be presented at upcoming scientific meetings. We have also been developing and testing a new approach, InteractionDetector, for specifically identifying which selected features are actually interacting with each other as opposed to acting independently. This work will continue in the next fiscal year and we plan applications to several of our datasets. We are also working on  our ongoing development of the Machine Suite which will include open source software for r2VIM-W, InteractionDetector and OptimalCrowd which will be our implementation of Dr. James Malleys published methodology, since freely available software for this method does not exist at present. These software packages will all be shared on Dr. Bailey-Wilsons NHGRI website and possibly also on github and cran. The massive number of simulations for this project relied heavily on the Biowulf computational resource at NIH.  We have also been developing a novel method to analyze matched case-control, or case-parent trio data using Random Forests. By combining results from a large number of classification trees, we have a flexible solution to analyze matched datasets and a paper was published (Li et al., 2015) presenting some of this work along with an applied analysis of oral cleft GWAS data. Work to efficiently implement this method for large-scale genomic data is ongoing and additional manuscripts are in development.  We have developed novel tools for analysis and interpretation of whole exome sequence (WES) and whole genome sequence (WGS) data, including strategies for combining linkage and sequence results, various schemes of collapsing rare variants in genes and gene networks to improve the power of sequence analysis, and methods for integrating sequence analyses with existing genomics databases. Development of these analysis methods and tools are ongoing, driven by our own WES and WGS sequence data from multiple studies of complex traits.  We have recently updated our sequence data quality assurance pipeline and scripts to automate two-point linkage analysis (parametric and non-parametric) of whole exome and whole genome sequence data. We have worked on optimizing methods for performing multipoint analyses using extremely dense WES, WGS and exome chip data sets. Also this year, we made many improvements to our pipelines for application of family-based methods for improved quality control in whole genome sequence data. Our WGS pipeline has been presented at several scientific meetings this past year.   In collaboration with Dr. Ruzong Fan (s Guest Researcher who is a Professor at Georgetown University) and Dr. Chi-Yang Chiu (a Guest Researcher who is a faculty member at University of Tennessee Health Sciences Center), we have contributed to the development of new generalized functional linear models for gene-based tests of both quantitative and qualitative traits as well as mixed effects models. These new methods have been shown to be more powerful than other gene-based tests while retaining good control of false positive rates. We have published multiple papers in this area in previous years. In this reporting period, we have utilized gene-based association analysis to develop and test a new method for association analysis of survival traits using functional regression based mixed effect cos models for use in family data. This work, along with the extensive simulation studies showing its good power and false positive control was published in this reporting period  (1). The massive number of simulations for this project relied heavily on the Biowulf computational resource at NIH.  We began a new collaboration with Dr. Kathleen Vazzana and Laura Lewandowski at NIAMS, who had performed TDT analysis using whole exome sequence data on a moderately sized sample of parent-parent-affected child trios for lupus.  This study used both single variant and gene-based association tests. We developed a permutation-based approach to determine the significance of the results of these analyses, using 10,000 permuted data replicates that we then analyzed in the same manner as the original TDT analyses.  We used the p-values from the permuted datasets (under the null hypothesis of no association) to determine new significance thresholds for the applied analyses and to evaluate the empirical significance of the most significant results.  This is being done separately for the single variant and gene-based tests. A manuscript will be prepared to present this work in the next reporting period. n/a",Development of statistical genetics methodology,10267086,ZIAHG000153,"['Affect', 'Area', 'Child', 'Collaborations', 'Complex', 'Computer software', 'Computers', 'DNA Sequence Analysis', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Educational workshop', 'Faculty', 'Family', 'Framingham Heart Study', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Health Sciences', 'Linear Models', 'Lupus', 'Manuscripts', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Paper', 'Parents', 'Performance', 'Phenotype', 'Preparation', 'Publishing', 'Quality Control', 'Recurrence', 'Reporting', 'Research Personnel', 'Sample Size', 'Scheme', 'Sequence Analysis', 'Statistical Methods', 'Survival Analysis', 'Tennessee', 'Testing', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Work', 'Yang', 'base', 'case control', 'classification trees', 'computing resources', 'data mining', 'data quality', 'data warehouse', 'disorder risk', 'exome', 'flexibility', 'gene environment interaction', 'genetic analysis', 'genetic linkage analysis', 'genetic testing', 'genome wide association study', 'genome-wide', 'genomic data', 'improved', 'machine learning method', 'meetings', 'member', 'novel', 'novel strategies', 'open source', 'oral cleft', 'professor', 'quality assurance', 'random forest', 'rare variant', 'risk variant', 'simulation', 'tool', 'trait', 'web site', 'whole genome']",NHGRI,NATIONAL HUMAN GENOME RESEARCH INSTITUTE,ZIA,2020,202397,0.016836016005832805
"Advancing Multi-Omics and Electronic Health Records Computational Methodologies PROJECT SUMMARY  Phenomic advances from large-scale electronic health records (EHR) linked to DNA biobanks have pioneered an efficient approach to genetic discovery that has transformed human genetic studies, with the enormous potential to provide constraints on relevant biological mechanisms on a wide spectrum of human phenotypes. Nevertheless, our understanding of the downstream molecular consequences of genetic associations remains limited and impedes our ability to develop novel therapeutic strategies for complex diseases. Given their enormous discovery potential for human genomics and precision medicine, genetic analyses in diverse populations offer unprecedented opportunities to identify causal genetic mechanisms underlying human trait variation.  This research proposal aims to address these convergent developments and critical gaps and to exert a powerful influence on efforts to expand our understanding of disease mechanisms and therapeutic possibilities. Here we hypothesize that a comprehensive multi- omic, phenomic, and trans-ethnic computational methodology will provide a robust and rigorous framework. This proposal thus has the following aims: AIM 1: Develop a regularized regression based methodology and a deep learning framework to improve characterization of the genetic architecture of gene expression and to build robust prediction models, extending a Transcriptome-Wide Association Study (TWAS) methodology (called PrediXcan) that we developed. AIM 2: Develop statistical causal modeling of trait-associated genetic variation through a convergent TWAS and Mendelian Randomization approach and apply it to thousands of human traits with available GWAS and EHR data. AIM 3: Develop analytic approaches and software tools to further genetic analyses in admixed and multi-ethnic populations and to lay the groundwork for trans-ethnic multi-omic methodologies, using EHR data (e.g., BioVU, UK Biobank, All of Us). PUBLIC HEALTH RELEVANCE We will develop a comprehensive multi-omic, phenomic, and trans-ethnic computational methodology that bridges the gap between Genetic Epidemiology and Functional Genomics. This research provides a rigorous framework for investigating relevant mechanisms underlying complex traits, including disease risk and quantitative traits. We will leverage and integrate high- dimensional molecular data, electronic health records, and genetic studies in diverse populations.",Advancing Multi-Omics and Electronic Health Records Computational Methodologies,9979509,R01HG011138,"['Address', 'Algorithms', 'All of Us Research Program', 'Alleles', 'Biological', 'Catalogs', 'Chromatin', 'Complex', 'Computing Methodologies', 'DNA', 'Data', 'Data Set', 'Development', 'Discipline', 'Disease', 'Electronic Health Record', 'Estrogen receptor positive', 'Expression Profiling', 'Gene Expression', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genomic medicine', 'Genomics', 'Heterogeneity', 'Human', 'Human Genetics', 'Image', 'Link', 'Machine Learning', 'Methodological Studies', 'Methodology', 'Methylation', 'Modeling', 'Molecular', 'Molecular Analysis', 'Nature', 'Performance', 'Phenotype', 'Population', 'Population Heterogeneity', 'RNA', 'Randomized', 'Regulation', 'Regulatory Element', 'Research', 'Research Proposals', 'Resources', 'Robotics', 'Single Nucleotide Polymorphism', 'Software Tools', 'Therapeutic', 'Tissues', 'Training', 'Translational Research', 'Underrepresented Populations', 'Variant', 'base', 'biobank', 'causal model', 'cell type', 'comorbidity', 'computerized tools', 'data warehouse', 'deep learning', 'disorder risk', 'functional genomics', 'genetic analysis', 'genetic architecture', 'genetic association', 'genetic epidemiology', 'genetic variant', 'genome wide association study', 'genomic data', 'high dimensionality', 'histone modification', 'human genomics', 'improved', 'multiple omics', 'novel therapeutics', 'phenome', 'phenomics', 'pleiotropism', 'precision medicine', 'predictive modeling', 'protein metabolite', 'public health relevance', 'recruit', 'repository', 'response', 'trait', 'transcriptome']",NHGRI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,330670,0.028635763879091725
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9925808,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'ClinVar', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data standards', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'patient health information', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,399965,0.00815219951469505
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,9925808,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'ClinVar', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data standards', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'patient health information', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,400000,0.00815219951469505
"Identification of Transposable Element Insertions in the Kids First Data Project Summary Insertion of transposable elements (TEs, sometimes referred to as “jumping genes”) into the human genome can be pathogenic. Our aim in this project is to use sophisticated computational approaches to characterize TE insertions in the whole-genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program and identify any insertional mutations that may disrupt gene function. The large scale of the Kids First program provides an unprecedented opportunity to investigate the role of TE insertions in childhood cancers and structural birth defects, as well as to create a resource of reference TE maps that will be important for all other TE studies. We will first modify our existing algorithm called xTEA for the trio design of the Kids First studies and increase the accuracy and efficiency of the algorithm. Then, we will apply it to the thousands of trios that have been profiled in the Kids First program, using a pipeline optimized for the cloud environment. The resulting set of TE insertions (especially L1, Alu, SVA, and HERV insertions) will be curated with all relevant features and be made into a database for the community. We will also apply machine learning methods to improve the calls once a sufficient amount of training data have been obtained. To investigate the potential pathogenicity of the mutation, we will first focus on insertions within genes, but we will also explore those in regulatory elements inferred from epigenetic profiling data. PROJECT NARRATIVE Transposable elements, or “jumping genes”, are genetic elements that can alter the DNA of an individual. We aim to utilize a computational method to identify such elements in the genome sequencing data generated in the Gabriella Miller Kids First Pediatric Research Program. Our analysis will identify transposable elements that may be causal for a disease phenotype.",Identification of Transposable Element Insertions in the Kids First Data,9957262,R03CA249364,"['Algorithms', 'Communities', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Insertion Elements', 'DNA Transposable Elements', 'Data', 'Data Set', 'Databases', 'Disease', 'Elements', 'Endogenous Retroviruses', 'Environment', 'Gene Frequency', 'Genes', 'Genetic Diseases', 'Genome', 'Genomics', 'Genotype', 'Human Genome', 'Individual', 'Inherited', 'Insertion Mutation', 'Jumping Genes', 'Length', 'Location', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Maps', 'Mendelian disorder', 'Methods', 'Modeling', 'Mutation', 'Neurons', 'Output', 'Parents', 'Paste substance', 'Pathogenicity', 'Pediatric Research', 'Play', 'Population', 'Regulatory Element', 'Reporting', 'Resources', 'Retrotransposon', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Site', 'Source', 'Speed', 'Structural Congenital Anomalies', 'Training', 'base', 'cloud based', 'cohort', 'design', 'disease phenotype', 'epigenetic profiling', 'gene function', 'genetic element', 'genome sequencing', 'improved', 'machine learning method', 'proband', 'programs', 'transcriptome sequencing', 'whole genome']",NCI,HARVARD MEDICAL SCHOOL,R03,2020,169041,-0.03011462987040554
"Advancing evolutionary genetic inference in humans and other taxa Project Summary/Abstract Background: A major challenge in evolutionary genomics is to characterize the forces shaping present-day patterns of genetic variation. For instance, the extent and manner in which natural selection affects genetic diversity remains highly controversial. Researchers have largely addressed this problem by developing statistical tests or summaries of genome sequence variation that provide insights into the evolutionary forces at play. However, because such approaches typically rely on a single univariate summary of the data, valuable discriminatory information present in the original dataset is lost. A more fruitful strategy would thus be to use multidimensional summaries of genomic data (e.g. a large vector of summary statistics) or even the totality of the input data (e.g. a matrix-representation of a sequence alignment) to make more accurate inferences. An even more powerful approach is to utilize data sets in which the same population is sampled at multiple time points, allowing one to observe evolutionary dynamics in action. Although such genomic time-series data are becoming more prevalent, the development of appropriate computational methodologies has lagged behind the proliferation of such data. Proposal: The Schrider Lab seeks to develop and apply powerful machine learning methods for evolutionary inference. Our work over the next five years will yield powerful software tools leveraging novel representations of genomic datasets, including time-series data. These efforts will dramatically improve researchers' ability to make accurate evolutionary inferences from both population genomic and phylogenetic data. Indeed, preliminary results demonstrate that our methods vastly outperform current approaches in evolutionary genetics. More importantly, we will use these tools to answer pressing evolutionary questions. In particular, our use of time-series data will reveal loci responsible for recent adaptation with much greater confidence than currently possible. Our efforts will help to resolve the controversy over the role of adaptation in shaping patterns of diversity across the human genome. This research has important implications for public health as well, as genes underlying recent adaptations are enriched for disease-associations. Moreover, we are constructing a time-series dataset in the mosquito vector species Aedes aegypti and Aedes albopictus. We will interrogate these data for evidence of recent and ongoing adaptation—this work will reveal loci responsible for the evolution of resistance to insecticides and other control efforts. Encouraging preliminary data also suggest that our work in phylogenetics will substantially improve inferential power in this important research area. More broadly, the success of the novel approaches described in this proposal has the potential to transform the methodological landscape of evolutionary genomic data analysis. Project Narrative The work proposed here seeks to develop and apply powerful machine-learning based software tools for evolutionary genetic inference in humans, mosquito vectors, and other species. Such efforts have important health implications, as they can identify genes involved in adaptation, which in humans are often associated with disease and in mosquitos are often associated with resistance to insecticides and other control efforts.",Advancing evolutionary genetic inference in humans and other taxa,10028474,R35GM138286,"['Address', 'Aedes', 'Affect', 'Area', 'Computing Methodologies', 'Culicidae', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Health', 'Human', 'Human Genome', 'Insecticides', 'Machine Learning', 'Methodology', 'Methods', 'Natural Selections', 'Pattern', 'Phylogenetic Analysis', 'Play', 'Population', 'Public Health', 'Research', 'Research Personnel', 'Resistance', 'Role', 'Sampling', 'Sequence Alignment', 'Series', 'Shapes', 'Software Tools', 'Testing', 'Time', 'Variant', 'Work', 'base', 'genomic data', 'improved', 'insight', 'machine learning method', 'novel', 'novel strategies', 'statistics', 'success', 'time use', 'tool', 'vector', 'vector mosquito']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2020,382894,0.028683102109049174
"Clinical Research Education in Genome Science (CREiGS) Project Summary/Abstract  The sensitivity and availability of omic technologies have enabled the genomic, transcriptomic and proteomic characterization of disease phenotypes, at the tissue and even the single cell level. This has allowed development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. Patients of providers who have participated in these educational initiatives also benefit as it allows for more rapid integration of genomic study findings into the clinical care setting. Thus, in response to PAR-19-185, we propose to develop and implement the Clinical Research Education in Genome Science (CREiGS) program that will not only focus on the analysis of genomic data, but also on gene-expression data, the integration of these two data types, as well as introductory theory and application of statistical and machine learning methods. Specifically we propose to accomplish the following specific aims: 1. Develop and successfully implement the online and in-person phases of CREiGS to increase the methodologic ingenuity by which researchers tackle important genomics-related clinical problems. 2. Establish a Diversity Recruitment External Advisory Board to ensure that the most effective strategies are employed to recruit URM doctoral students, postdoctoral fellows, and faculty from academic institutions nationwide into CREiGS. 3. Enhance the dissemination phase of CREiGS by packaging and uploading the asynchronous lectures and the online critical thinking/problem solving assessments with solutions for publicly available, online teaching resources. 4. Implement effective methods to evaluate the efficacy of CREiGS by examining:1) the participants' grasp of the CREiGS core competencies, 2) the clarity and quality of the curriculum, 3) program logistics and operation, and 4) the participants' short-term and long-term success attributed to participation in CREiGS. In summary, we posit that CREiGS will provide participants with a solid foundation in genomics science to answer complex, clinical questions. We believe that CREiGS supports the mission of the NHGRI by providing researchers with rigorous training to “accelerate medical breakthroughs that improve human health.” Project Narrative The sensitivity and availability of omic technologies have allowed for the development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. The overall goal of the Clinical Research Education in Genome Science program is to increase the methodologic ingenuity of students, postdoctoral fellows, and faculty from academic institutions nationwide through a solid foundation in genomics science to answer complex, clinical research questions and improve patient care.",Clinical Research Education in Genome Science (CREiGS),9934567,R25HG011021,"['Area', 'Biomedical Research', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Critical Thinking', 'Data', 'Data Analyses', 'Development', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genetic', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Hour', 'Human', 'Hybrids', 'Institution', 'Knowledge', 'Logistics', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Human Genome Research Institute', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Play', 'Postdoctoral Fellow', 'Problem Solving', 'Proteomics', 'Provider', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Role', 'Single Nucleotide Polymorphism', 'Solid', 'Statistical Methods', 'Students', 'Technology', 'Tissues', 'Training', 'Translational Research', 'Treatment outcome', 'Underrepresented Minority', 'Underserved Population', 'Update', 'cancer therapy', 'clinical care', 'clinical efficacy', 'computerized tools', 'data integration', 'data management', 'disease phenotype', 'disorder subtype', 'doctoral student', 'education research', 'genetic analysis', 'genome sciences', 'genomic data', 'grasp', 'health disparity', 'improved', 'individual patient', 'innovation', 'lectures', 'machine learning method', 'operation', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'response', 'statistical and machine learning', 'success', 'theories', 'therapy development', 'tool', 'transcriptomics', 'treatment optimization', 'virtual']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R25,2020,161662,-0.029469183676218386
"Integrated Clinical and Transcriptomic Profiling to Characterize Disease Phenotype PROJECT SUMMARY Exome and whole-genome sequencing are becoming increasingly routine approaches in cancer[1], common disease[2]and rare disease diagnosis.[3] Despite their success, our ability to fully interpret the clinical relevance of personal genome variation remains a significant gap[4-6]. Considering this, the most crucial need is more genotype-phenotype data that link genetic variation with disease causation. The objective of this proposal is to improve the clinical interpretation of genetic variation; in particular, by developing integrative approaches that predict the effect of genetic variation on clinical phenotype. This proposal addresses the hypothesis, supported by preliminary data, that combining patient transcriptomic data with genotypic and clinical data (as opposed to each alone) offers a better mechanistic understanding of disease natural history, from initial presentation to progression. The specific aims are designed such that each independently add substantial functional genomic information, over and above previously available patient genetic data, to further resolve the clinical phenotype. Aim 1 establishes a comprehensive and widely-shared dataset of patient transcriptomic (and genetic) variation across multiple cancer, cardiovascular and thrombosis/bleeding phenotypes, in patients with somatically-acquired myeloproliferative neoplasms (MPN) and select other rare heritable blood diseases (HBD). Aim 2 methodically determines differential RNA expression and processing between clinically-relevant subgroups of MPN and HBD patients. Aim 3 brings these elements together – and applies two integrative Bayesian and machine learning approaches, RIVER[24] (RNA-informed variant effect on regulation) and LASSO[25] (Least Absolute Shrinkage and Selection Operator), to resolve the functional and clinical relevance of rare variants; and identify signatures most predictive of disease risk or progression. Completion of these aims will contribute new scientific knowledge on how integrating transcriptomic data improves clinical genomic analyses in other genetic (and rare) diseases. In addition, this project will enable the Principal Investigator to develop expertise in the informatics and data science aspects of genomic medicine that complement her current background in biophysics, biochemistry and translational hematology. Combined with additional informatics training at Stanford University through coursework, seminars, one-on-one advising from project mentors, and interactions with the wider statistics, bioinformatics and genomics communities, this project will prepare the Principal Investigator to launch an independent academic career in genomic medicine. PROJECT NARRATIVE Accurate clinical interpretation of genetic variation in personal genome data is an essential component of personalized medicine approaches and the precise genetic diagnosis toward achieving improved public health. This project will integrate genetic and clinical modifiers with functional genomic information (RNA sequencing) from adequately-powered, disease-relevant cells; and provide direct insight into transcriptional perturbations caused by genetic variation.",Integrated Clinical and Transcriptomic Profiling to Characterize Disease Phenotype,9948713,K08HG010061,"['Address', 'Adult', 'Age Factors', 'Alleles', 'Alternative Splicing', 'Bayesian Modeling', 'Bayesian learning', 'Biochemistry', 'Bioinformatics', 'Biological Markers', 'Biophysics', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood specimen', 'Body mass index', 'Cardiovascular system', 'Cells', 'Clinical', 'Clinical Data', 'Communities', 'Complement', 'DNA Sequence', 'Data', 'Data Science', 'Data Set', 'Databases', 'Demographic Factors', 'Disease', 'Disease Progression', 'Disease stratification', 'Elements', 'Etiology', 'Evaluation', 'Foundations', 'Functional disorder', 'Future', 'Gender', 'Gene Expression', 'Gene Expression Profiling', 'Gene Fusion', 'Genetic', 'Genetic Heterogeneity', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Hematological Disease', 'Hematology', 'Hemorrhage', 'Heritability', 'Informatics', 'Investigation', 'Knowledge', 'Laboratories', 'Lasso', 'Lead', 'Link', 'Malignant Neoplasms', 'Medical Genetics', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Myeloproliferative disease', 'Other Genetics', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Principal Investigator', 'Process', 'Protein Isoforms', 'Public Health', 'RNA', 'RNA Processing', 'Rare Diseases', 'Reference Standards', 'Regulation', 'Research Training', 'Resources', 'Rivers', 'Sampling', 'Severities', 'Subgroup', 'System', 'Thrombosis', 'Tissue-Specific Gene Expression', 'Training', 'Universities', 'Untranslated RNA', 'Validation', 'Variant', 'Whole Blood', 'base', 'biobank', 'career', 'clinical phenotype', 'clinically relevant', 'cohort', 'data integration', 'design', 'disease diagnosis', 'disease natural history', 'disease phenotype', 'disorder risk', 'driver mutation', 'exome', 'experience', 'functional genomics', 'genetic disorder diagnosis', 'genetic variant', 'genome sequencing', 'genomic data', 'improved', 'informatics training', 'insight', 'knowledge base', 'multidisciplinary', 'novel', 'patient stratification', 'personalized medicine', 'phenotypic data', 'prediction algorithm', 'prospective', 'rare cancer', 'rare variant', 'regression algorithm', 'statistics', 'success', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'variant of unknown significance', 'whole genome']",NHGRI,STANFORD UNIVERSITY,K08,2020,190941,0.029221089307737595
"Center for Undiagnosed Diseases at Stanford Abstract The Undiagnosed Diseases Network (UDN) has increased access for patients with undiagnosed diseases to the nation’s leading clinicians and scientists. Phase II of the Network will facilitate the transition of UDN efforts toward sustainability, through the expansion of clinical sites, refinement of methods, and integration with regular clinical practice. Here, we propose a program of study that will (1) facilitate timely, accurate diagnosis of patients with undiagnosed diseases; (2) improve diagnostic rates through novel approaches to data analysis and integration; and (3) explore underlying mechanisms of disease to accelerate therapeutic drug discovery. In Aim 1, we propose to evaluate patients referred to the UDN through a protocol that includes pre-visit chart review and genetic counseling followed by an individualized visit during which standardized phenotypic and environmental data are collected. Biosamples facilitate genomic, multi-omic, and cellular evaluation of disease. Expansion of fibroblasts and, in selected cases, generation of induced Pluripotent Stem Cell (iPSC) lines facilitates scientific investigation of the underlying diseases. We will expand our program of patient outreach, particularly to under-served populations. We will extend our UDN-based genomic medicine educational program both in scope and by broadening its eligibility. In Aim 2, we propose to develop and implement novel methods in areas of high potential to increase diagnostic yield. This includes algorithms for the detection of small genomic insertions and deletions as well as large scale structural variation. We will develop alignment algorithms using graph reference genomes and promote the use of long-read sequencing technologies. We will apply machine learning to the systematic integration of RNA sequencing, metabolomic, and phenotypic data with the electronic medical record and the entire medical literature to improve diagnostic yield. In Aim 3, we propose to facilitate diagnosis through enhanced cellular and model organisms phenotyping. We will implement immunomic and metagenomic approaches such as T cell, B cell and unknown organism sequencing for undiagnosed cases. We will utilize methods for moderate- and high-throughput phenotyping of iPS-derived cells and promote novel drug discovery via high throughput drug screening both with FDA- approved drugs and large scale small molecule libraries. Beyond Phase II, Stanford Medicine has made a strong commitment to the continuation of the Center for Undiagnosed Diseases at Stanford through a multi- million dollar institutional commitment. In summary, we aim to build on the success of Phase I of the UDN by streamlining processes, maximizing collaboration and outreach, optimizing computational algorithms, extending scientific investigation towards therapeutic discovery, and promoting engagement of hospital leaders, clinicians, scientists, policy-makers, and philanthropists to ensure this national resource is sustained long beyond the duration of this award. Narrative We will refine the operations of the Center for Undiagnosed Diseases at Stanford in coordination with other Phase II sites of the Undiagnosed Diseases Network to diagnose the undiagnosed and facilitate a transition to sustainability. Our Center will bring Stanford’s long history in technology development, genomic data analysis, stem cell biology, and translational science to the team-based diagnosis and care of patients with undiagnosed disease. We will refine existing procedures to further optimize the diagnostic process and integrate care of the undiagnosed into clinical practice while preserving the scientific mission of the Undiagnosed Diseases Network.",Center for Undiagnosed Diseases at Stanford,10124880,U01HG010218,"['Algorithms', 'Animal Model', 'Area', 'Award', 'B-Lymphocytes', 'Biological Assay', 'Caring', 'Cell Line', 'Cell model', 'Cells', 'Child Health', 'Collaborations', 'Committee Membership', 'Computational algorithm', 'Computerized Medical Record', 'Consent', 'Country', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Education', 'Eligibility Determination', 'Ensure', 'Evaluation', 'FDA approved', 'Family', 'Fibroblasts', 'Gene Silencing', 'Generations', 'Genetic Counseling', 'Genomic medicine', 'Genomics', 'Goals', 'Graph', 'Healthcare', 'Hospitals', 'Human', 'International', 'Investigation', 'Investments', 'Leadership', 'Libraries', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Metagenomics', 'Methods', 'Mission', 'Modeling', 'Multiomic Data', 'Network-based', 'Ontology', 'Organism', 'Organoids', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Policy Maker', 'Principal Investigator', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Recording of previous events', 'Research', 'Resources', 'Robotics', 'Role', 'Scientist', 'Site', 'Standardization', 'Structure', 'System', 'T-Lymphocyte', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underserved Population', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visit', 'accurate diagnosis', 'base', 'clinical practice', 'clinical research site', 'cohort', 'data integration', 'deep learning', 'drug discovery', 'experience', 'follow-up', 'genome-wide', 'genomic data', 'high-throughput drug screening', 'improved', 'induced pluripotent stem cell', 'innovation', 'insertion/deletion mutation', 'meetings', 'metabolomics', 'multiple omics', 'next generation', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'outreach', 'patient outreach', 'phenotypic data', 'preservation', 'programs', 'reference genome', 'relating to nervous system', 'research clinical testing', 'sample collection', 'screening', 'small molecule libraries', 'socioeconomics', 'stem cell biology', 'success', 'support network', 'technology development', 'tool', 'transcriptome sequencing', 'variant detection', 'virtual screening']",NHGRI,STANFORD UNIVERSITY,U01,2020,50000,-0.0023351266999561723
"Center for Undiagnosed Diseases at Stanford Abstract The Undiagnosed Diseases Network (UDN) has increased access for patients with undiagnosed diseases to the nation’s leading clinicians and scientists. Phase II of the Network will facilitate the transition of UDN efforts toward sustainability, through the expansion of clinical sites, refinement of methods, and integration with regular clinical practice. Here, we propose a program of study that will (1) facilitate timely, accurate diagnosis of patients with undiagnosed diseases; (2) improve diagnostic rates through novel approaches to data analysis and integration; and (3) explore underlying mechanisms of disease to accelerate therapeutic drug discovery. In Aim 1, we propose to evaluate patients referred to the UDN through a protocol that includes pre-visit chart review and genetic counseling followed by an individualized visit during which standardized phenotypic and environmental data are collected. Biosamples facilitate genomic, multi-omic, and cellular evaluation of disease. Expansion of fibroblasts and, in selected cases, generation of induced Pluripotent Stem Cell (iPSC) lines facilitates scientific investigation of the underlying diseases. We will expand our program of patient outreach, particularly to under-served populations. We will extend our UDN-based genomic medicine educational program both in scope and by broadening its eligibility. In Aim 2, we propose to develop and implement novel methods in areas of high potential to increase diagnostic yield. This includes algorithms for the detection of small genomic insertions and deletions as well as large scale structural variation. We will develop alignment algorithms using graph reference genomes and promote the use of long-read sequencing technologies. We will apply machine learning to the systematic integration of RNA sequencing, metabolomic, and phenotypic data with the electronic medical record and the entire medical literature to improve diagnostic yield. In Aim 3, we propose to facilitate diagnosis through enhanced cellular and model organisms phenotyping. We will implement immunomic and metagenomic approaches such as T cell, B cell and unknown organism sequencing for undiagnosed cases. We will utilize methods for moderate- and high-throughput phenotyping of iPS-derived cells and promote novel drug discovery via high throughput drug screening both with FDA- approved drugs and large scale small molecule libraries. Beyond Phase II, Stanford Medicine has made a strong commitment to the continuation of the Center for Undiagnosed Diseases at Stanford through a multi- million dollar institutional commitment. In summary, we aim to build on the success of Phase I of the UDN by streamlining processes, maximizing collaboration and outreach, optimizing computational algorithms, extending scientific investigation towards therapeutic discovery, and promoting engagement of hospital leaders, clinicians, scientists, policy-makers, and philanthropists to ensure this national resource is sustained long beyond the duration of this award. Narrative We will refine the operations of the Center for Undiagnosed Diseases at Stanford in coordination with other Phase II sites of the Undiagnosed Diseases Network to diagnose the undiagnosed and facilitate a transition to sustainability. Our Center will bring Stanford’s long history in technology development, genomic data analysis, stem cell biology, and translational science to the team-based diagnosis and care of patients with undiagnosed disease. We will refine existing procedures to further optimize the diagnostic process and integrate care of the undiagnosed into clinical practice while preserving the scientific mission of the Undiagnosed Diseases Network.",Center for Undiagnosed Diseases at Stanford,9980967,U01HG010218,"['Algorithms', 'Animal Model', 'Area', 'Award', 'B-Lymphocytes', 'Biological Assay', 'Caring', 'Cell Line', 'Cell model', 'Cells', 'Child Health', 'Collaborations', 'Committee Membership', 'Computational algorithm', 'Computerized Medical Record', 'Consent', 'Country', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Education', 'Eligibility Determination', 'Ensure', 'Evaluation', 'FDA approved', 'Family', 'Fibroblasts', 'Gene Silencing', 'Generations', 'Genetic Counseling', 'Genomic medicine', 'Genomics', 'Goals', 'Graph', 'Healthcare', 'Hospitals', 'Human', 'International', 'Investigation', 'Investments', 'Leadership', 'Libraries', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Metagenomics', 'Methods', 'Mission', 'Modeling', 'Multiomic Data', 'Network-based', 'Ontology', 'Organism', 'Organoids', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Policy Maker', 'Principal Investigator', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Recording of previous events', 'Research', 'Resources', 'Robotics', 'Role', 'Scientist', 'Site', 'Standardization', 'Structure', 'System', 'T-Lymphocyte', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underserved Population', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visit', 'accurate diagnosis', 'base', 'clinical practice', 'clinical research site', 'cohort', 'data integration', 'deep learning', 'drug discovery', 'experience', 'follow-up', 'genome-wide', 'genomic data', 'high-throughput drug screening', 'improved', 'induced pluripotent stem cell', 'innovation', 'insertion/deletion mutation', 'meetings', 'metabolomics', 'multiple omics', 'next generation', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'outreach', 'patient outreach', 'phenotypic data', 'preservation', 'programs', 'reference genome', 'relating to nervous system', 'research clinical testing', 'sample collection', 'screening', 'small molecule libraries', 'socioeconomics', 'stem cell biology', 'success', 'support network', 'technology development', 'tool', 'transcriptome sequencing', 'variant detection', 'virtual screening']",NHGRI,STANFORD UNIVERSITY,U01,2020,1100000,-0.0023351266999561723
"What comes next? Engaging stakeholders in governance of participant data and relationships during the sunset of large genomic medicine research initiatives Abstract The Undiagnosed Diseases Network (UDN) has increased access for patients with undiagnosed diseases to the nation’s leading clinicians and scientists. Phase II of the Network will facilitate the transition of UDN efforts toward sustainability, through the expansion of clinical sites, refinement of methods, and integration with regular clinical practice. Here, we propose a program of study that will (1) facilitate timely, accurate diagnosis of patients with undiagnosed diseases; (2) improve diagnostic rates through novel approaches to data analysis and integration; and (3) explore underlying mechanisms of disease to accelerate therapeutic drug discovery. In Aim 1, we propose to evaluate patients referred to the UDN through a protocol that includes pre-visit chart review and genetic counseling followed by an individualized visit during which standardized phenotypic and environmental data are collected. Biosamples facilitate genomic, multi-omic, and cellular evaluation of disease. Expansion of fibroblasts and, in selected cases, generation of induced Pluripotent Stem Cell (iPSC) lines facilitates scientific investigation of the underlying diseases. We will expand our program of patient outreach, particularly to under-served populations. We will extend our UDN-based genomic medicine educational program both in scope and by broadening its eligibility. In Aim 2, we propose to develop and implement novel methods in areas of high potential to increase diagnostic yield. This includes algorithms for the detection of small genomic insertions and deletions as well as large scale structural variation. We will develop alignment algorithms using graph reference genomes and promote the use of long-read sequencing technologies. We will apply machine learning to the systematic integration of RNA sequencing, metabolomic, and phenotypic data with the electronic medical record and the entire medical literature to improve diagnostic yield. In Aim 3, we propose to facilitate diagnosis through enhanced cellular and model organisms phenotyping. We will implement immunomic and metagenomic approaches such as T cell, B cell and unknown organism sequencing for undiagnosed cases. We will utilize methods for moderate- and high-throughput phenotyping of iPS-derived cells and promote novel drug discovery via high throughput drug screening both with FDA- approved drugs and large scale small molecule libraries. Beyond Phase II, Stanford Medicine has made a strong commitment to the continuation of the Center for Undiagnosed Diseases at Stanford through a multi- million dollar institutional commitment. In summary, we aim to build on the success of Phase I of the UDN by streamlining processes, maximizing collaboration and outreach, optimizing computational algorithms, extending scientific investigation towards therapeutic discovery, and promoting engagement of hospital leaders, clinicians, scientists, policy-makers, and philanthropists to ensure this national resource is sustained long beyond the duration of this award. Narrative We will refine the operations of the Center for Undiagnosed Diseases at Stanford in coordination with other Phase II sites of the Undiagnosed Diseases Network to diagnose the undiagnosed and facilitate a transition to sustainability. Our Center will bring Stanford’s long history in technology development, genomic data analysis, stem cell biology, and translational science to the team-based diagnosis and care of patients with undiagnosed disease. We will refine existing procedures to further optimize the diagnostic process and integrate care of the undiagnosed into clinical practice while preserving the scientific mission of the Undiagnosed Diseases Network.",What comes next? Engaging stakeholders in governance of participant data and relationships during the sunset of large genomic medicine research initiatives,10162151,U01HG010218,"['Algorithms', 'Animal Model', 'Area', 'Award', 'B-Lymphocytes', 'Biological Assay', 'Caring', 'Cell Line', 'Cell model', 'Cells', 'Child Health', 'Collaborations', 'Committee Membership', 'Computational algorithm', 'Computerized Medical Record', 'Consent', 'Country', 'Data', 'Data Analyses', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Education', 'Eligibility Determination', 'Ensure', 'Evaluation', 'FDA approved', 'Family', 'Fibroblasts', 'Gene Silencing', 'Generations', 'Genetic Counseling', 'Genomic medicine', 'Genomics', 'Goals', 'Graph', 'Healthcare', 'Hospitals', 'Human', 'International', 'Investigation', 'Investments', 'Leadership', 'Libraries', 'Literature', 'Machine Learning', 'Medical', 'Medicine', 'Metagenomics', 'Methods', 'Mission', 'Modeling', 'Multiomic Data', 'Network-based', 'Ontology', 'Organism', 'Organoids', 'Participant', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physicians', 'Play', 'Policy Maker', 'Principal Investigator', 'Procedures', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Recording of previous events', 'Research', 'Resources', 'Robotics', 'Role', 'Scientist', 'Site', 'Standardization', 'Structure', 'System', 'T-Lymphocyte', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underserved Population', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visit', 'accurate diagnosis', 'base', 'clinical practice', 'clinical research site', 'cohort', 'data integration', 'deep learning', 'drug discovery', 'experience', 'follow-up', 'genome-wide', 'genomic data', 'high-throughput drug screening', 'improved', 'induced pluripotent stem cell', 'innovation', 'insertion/deletion mutation', 'meetings', 'metabolomics', 'multiple omics', 'next generation', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'outreach', 'patient outreach', 'phenotypic data', 'preservation', 'programs', 'reference genome', 'relating to nervous system', 'research clinical testing', 'sample collection', 'screening', 'small molecule libraries', 'socioeconomics', 'stem cell biology', 'success', 'support network', 'technology development', 'tool', 'transcriptome sequencing', 'variant detection', 'virtual screening']",NHGRI,STANFORD UNIVERSITY,U01,2020,100000,0.00013416423363736947
"Visualization, modeling and validation of chromatin interaction data The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Several recent high- throughput technologies based on Chromatin Conformation Capture (3C) have emerged (such as 4C, 5C, Hi-C and ChIA-PET) and given us an unprecedented opportunity to study the higher-order genome organization. Among them, Hi-C technology is of particular interest due to its unbiased genome-wide coverage that can measure chromatin interaction intensities between any two given genomic loci. However, Hi-C data analysis and interpretation are still in the early stages. One of the main challenges is how to efficiently visualize chromatin interaction data, so that the scientific community to visualize and use it for their own research. In addition, due to the complex experimental procedure and high sequencing cost, Hi-C has only been performed in a limited number of cell/tissue types. Finally, the underlying mechanism of chromatin interactions remains largely unclear. Therefore, the PI will propose the following aims: Aim 1. Build an interactive and customizable 3D genome browser. We will build an interactive and customizable 3D browser, which allows users to navigate Hi-C data and other high-throughput chromatin organization data, including ChIA-PET and Capture Hi-C. We have built a prototype of the 3D genome browser (www.3dgenome.org). Our browser will allow users to conveniently browse chromatin interaction data with other data types (such as ChIP-Seq and RNA-Seq) from the genomic region in the same window simultaneously. Our system will also empower the users to create their own session and query their own Hi-C and other epigenomic data. Aim 2. Impute chromatin interaction using other genomic/epigenomic information. We will predict Hi-C interaction frequencies using other available genomic and epigenomic data in the same cell type, such as ChIP-Seq data for histone modifications and transcription factors. We will build our prediction model and then systematically impute Hi-C interaction matrices for all 127 cell types whose epigenomes are available thanks to recent effort by the ENCODE and Roadmap Epigenome projects. Aim 3. Perform validation experiments for computational method in aim 1 and 2. We will perform 20 3C experiments in hESC and GM cell lines, coupled with genome engineering by CRISPR/Cas9, to evaluate Hi-C prediction method in aim 2. The three dimensional (3D) organization of mammalian genomes is tightly linked to gene regulation, as it can reveal the physical interactions between distal regulatory elements and their target genes. Although several recent high-throughput technologies including Hi-C have emerged and given us an unprecedented opportunity to study 3D chromatin interaction in high resolution, its analysis and interpretation are still in the early stages. Here we propose to develop a suite of statistical modeling and computational methods to model and validate chromatin interaction using other genomic/epigenomics data, and build an interactive and customizable 3D genome browser.","Visualization, modeling and validation of chromatin interaction data",9840492,R01HG009906,"['3-Dimensional', 'Address', 'CRISPR/Cas technology', 'Cell Line', 'Cell physiology', 'Cells', 'ChIP-seq', 'Chromatin', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Chromatin Remodeling Factor', 'Chromosome Territory', 'Communities', 'Complex', 'Computer Models', 'Computing Methodologies', 'Country', 'Coupled', 'Data', 'Data Analyses', 'Distal', 'Elements', 'Environment', 'Event', 'Frequencies', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genome engineering', 'Genomic Segment', 'Genomics', 'Intuition', 'Knock-out', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Molecular', 'Procedures', 'Regulator Genes', 'Regulatory Element', 'Research', 'Resolution', 'Statistical Models', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Validation', 'Visit', 'Visualization', 'base', 'cell type', 'chromosome conformation capture', 'convolutional neural network', 'cost', 'epigenome', 'epigenomics', 'experimental study', 'genome annotation', 'genome browser', 'genome-wide', 'genomic locus', 'high throughput technology', 'histone modification', 'human embryonic stem cell', 'interest', 'mammalian genome', 'performance tests', 'predictive modeling', 'prototype', 'random forest', 'repository', 'transcription factor', 'transcriptome sequencing', 'web site']",NHGRI,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,395000,-0.03193962199793852
"Computational modeling of spatial genome organization and gene regulation PROJECT SUMMARY/ABSTRACT The three-dimensional (3D) organization of the genome plays an essential role in genome stability, gene regulation, and many diseases, including cancer. The recent development of high-throughput chromatin conformation capture (Hi-C) and its variants provide an unprecedented opportunity to investigate higher-order chromatin organization. Despite the rapidly accumulating resources for investigating 3D genome organization, our understanding of the regulatory mechanisms and functions of the genome organization remain largely incomplete. Hi-C analyses and 3D genome research are still in their early stage and face several challenges. First, high-resolution chromatin contact maps require extremely deep sequencing and hence have been achieved only for a few cell lines. Second, it is computationally challenging to complement 3D genome structure with one-dimensional (1D) genomic and epigenomic features. Third, recent studies have just begun to infer associations between chromatin interactions and genetic variants and to identify potential target genes of those variants at the genome-wide scale. Given these challenges and my unique multi-disciplinary training, my long-term research goal is to develop innovative computational and statistical methods to uncover the interplay between 3D genome structure and function. Speciﬁcally, in the next ﬁve years, I will i) develop computational approaches to enhance the resolution of existing Hi-C data and investigate ﬁne-scale 3D genome architecture as well as its spatiotemporal dynamics and ii) build scalable and interpretable machine learning models that leverage 1D epigenomic data to predict cell type-speciﬁc 3D chromatin interactions and gene expression and elucidate the function of 3D genome organization in gene regulation and human diseases. The completion of the proposed work will deepen our knowledge of 3D genome architecture as well as its functions in gene regulation and disease. PROJECT NARRATIVE The overarching mission of my research is to understand the interplay between genome architecture and gene regulation. Recent development of high-throughput chromatin conformation capture techniques has allowed us to look beyond the nucleotide sequence of DNA and investigate the principles of higher-order chromatin organization. I will develop innovative computational and statistical strategies to investigate 3D genome organization at an unprecedented scale, thereby elucidating the impacts of genome organization on gene regulation and disease.",Computational modeling of spatial genome organization and gene regulation,9999005,R35GM133678,"['3-Dimensional', 'Architecture', 'Base Sequence', 'Cell Line', 'Chromatin', 'Complement 3d', 'Computer Models', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Development', 'Dimensions', 'Disease', 'Face', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genome', 'Genome Stability', 'Genomics', 'Goals', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mission', 'Modeling', 'Play', 'Research', 'Resolution', 'Resources', 'Role', 'Statistical Methods', 'Structure', 'Techniques', 'Training', 'Variant', 'Work', 'cell type', 'chromosome conformation capture', 'deep sequencing', 'epigenomics', 'genetic variant', 'genome-wide', 'human disease', 'innovation', 'multidisciplinary', 'spatiotemporal']",NIGMS,UNIVERSITY OF CALIFORNIA RIVERSIDE,R35,2020,378309,-0.03213831793251803
"Leveraging Common Fund data for feature selection in Kids First studies. Project Abstract This project will pilot a process for identifying multi-variant interactions contributing structural birth defect and childhood cancer disorders. This study will focus on analysis of oral-facial clefts, congenital diaphragmatic hernia, and congenital heart defects from whole-genome sequencing (WGS) data from family cohorts taken from Gabriella Miller Kids First Pediatric Research Project (KF).  Typically, tests to link disorders to genome-wide complex multivariate associations are computationally prohibitive. Thus, a first step to making such analyses more reasonable is to limit the number of variables (genes, variants) being tested together. We can reduce the number of possible tests by restricting what data should be tested. This study will seek to reduce the data for testing by utilizing biological knowledge from other two Common Fund datasets: the Knockout Mouse Phenotyping Program (KOMP2), and the Genotype-Tissue Expression (GTEx) project. KOMP2 has generated extensive information on mouse knockout developmental phenotypes relevant for matching gene and phenotypes in KF WGS studies. GTEx can be merged with KF loci and relevant tissue-to-phenotype relationships. Thus, using features from other Common Fund data and annotations, we can generate selected subsets of KF variants and genes as feature-reduced KF data.  A comprehensive machine learning (ML) analysis pipeline will then be utilized for the identification of candidate risk factors and characterization of complex patterns of association between these feature-reduced KF data. In addition to performing the more traditional univariate association analyses of genotype vs. phenotype, this pipeline will also identify complex associations including (1) context-dependent genetic effects resulting from non-additive multi-variant interactions, i.e. epistasis, and (2) subgroup-specific associations, i.e. by phenotype and genotypic heterogeneity, where different etiological paths lead to the same/similar phenotypes in the selected KF subject group. This pipeline will include feature selection, modeling, and interpretation of multi-variant interactions.  The outcomes of this study will include (1) pipelines for integrating Common Fund data into Kids First datasets, (2) integrated KF-KOMP2-GTEx datasets including cross-species integration, (3) ML pipelines for multi-variant interaction analyses of phenotype vs genotype in selected, reduced-feature KF data, and (4) results from the aforementioned pipelines for multi-variant interactions for later hypothesis testing. Project Abstract This project will pilot a process for identifying interactions between genetic variants that contribute to structural birth defect and childhood cancer disorders by combining data from the Gabriella Miller Kids First Pediatric Research Project with biological knowledge from other two Common Fund datasets: the Knockout Mouse Phenotyping Program (KOMP2), and the Genotype-Tissue Expression (GTEx) project. By selective use of this merged data within machine-learning pipelines, we will produce novel genetic analysis methods for studying complex variant interactions that may contribute to these childhood disorders.",Leveraging Common Fund data for feature selection in Kids First studies.,10112014,R03OD030600,"['Agreement', 'Anatomy', 'Biological', 'Biology', 'Child', 'Childhood', 'Cohort Studies', 'Complex', 'Congenital Heart Defects', 'Congenital diaphragmatic hernia', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Targeting', 'Etiology', 'Face', 'Family', 'Funding', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genotype', 'Genotype-Tissue Expression Project', 'Goals', 'Grant', 'Graph', 'Heart', 'Heart Abnormalities', 'Heterogeneity', 'Individual', 'Knock-out', 'Knockout Mice', 'Knowledge', 'Lead', 'Link', 'Machine Learning', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Metadata', 'Methods', 'Modeling', 'Mus', 'Ontology', 'Oral', 'Outcome Study', 'Pathway interactions', 'Pattern', 'Pediatric Research', 'Performance', 'Phenotype', 'Population', 'Process', 'Quantitative Trait Loci', 'Randomized', 'Recovery', 'Research Personnel', 'Research Project Grants', 'Risk', 'Risk Factors', 'Services', 'Source', 'Structural Congenital Anomalies', 'Subgroup', 'Testing', 'Time', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Work', 'analysis pipeline', 'analytical method', 'base', 'candidate identification', 'cohort', 'complex data ', 'data integration', 'data resource', 'database of Genotypes and Phenotypes', 'feature selection', 'gene interaction', 'genetic analysis', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'genomic locus', 'insight', 'interest', 'knockout gene', 'large scale data', 'novel', 'performance tests', 'phenotypic data', 'programs', 'rare variant', 'statistical and machine learning', 'whole genome']",OD,CHILDREN'S HOSP OF PHILADELPHIA,R03,2020,363306,0.016291417066821606
"Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease Project Summary Over the past decade, it has become clear that mixture between diverged populations (admixture) has been a recurrent feature in human evolution. It has also become evident that a detailed understanding of admixture is essential for effective disease gene mapping as well as evolutionary inference. Nevertheless, adequate analytical tools to dissect admixture and its impact on phenotype are lacking. As a result, disease gene mapping or evolutionary studies have either excluded admixed populations or relied on simplified models at the risk of inaccurate inferences. This proposal proposes to develop computational methods to infer the genomic structure and history of admixed populations across a range of evolutionary time scales and to leverage this structure to obtain a comprehensive understanding of the genetic architecture and evolution of complex phenotypes. The proposed methods will integrate powerful sources of information from ancient DNA with genomes from present-day human populations. These methods will enable populations with a history of admixture to be studied just as effectively as homogeneous populations. The first step in obtaining a thorough understanding of admixture is a principled and scalable statistical framework to infer fine-scale genomic structure (local ancestry) and evolutionary relationships. This proposal leverages recent advances in statistical machine learning to develop effective tools for the increasingly common and challenging problem of local ancestry inference where reference genomes for ancestral populations are unavailable (de-novo local ancestry). Further, the proposal intends to develop models to infer complex evolutionary histories as well as realistic mating patterns in admixed populations. These inferences will form the starting point to systematically understand how admixture has shaped phenotypes. For example, it is becoming clear that admixture between modern humans and archaic humans (Neanderthals and Denisovans) could have had a major impact on human phenotypes. This question will be explored by applying novel statistical methods to large genetic datasets with phenotypic measurements to assess the adaptive as well as phenotypic impact of Neanderthal alleles. Finally, large collections of genomes from extinct populations that are now becoming available due to advances in ancient DNA technologies can lead to vastly more powerful methods for evolutionary inference that overcome the limitation of methods that rely only on extant genomes. Statistical models that use ancient genome time-series to efficiently infer admixture histories, local ancestry and selection will be developed. Project Narrative Although mixture events between human populations (admixture) are now known to have been common throughout human history and are likely to have had a major impact on human phenotypes, we lack adequate methods to study these processes. Our work will lead to a suite of powerful tools to understand the history of admixture, the impact of admixture on fine-scale genomic structure and function. Our work not only lead to new insights into the genetic basis and evolution of complex phenotypes but will ensure that major population groups, many of whom descend from admixture events or from ancestral groups distinct from those of Europeans, can benefit from the advances in genomics.",Statistical Models for Dissecting Human Population Admixture and its Role in Evolution and Disease,9990809,R35GM125055,"['Admixture', 'Alleles', 'Chromosome Mapping', 'Collection', 'Complex', 'Computing Methodologies', 'DNA', 'Data Set', 'Disease', 'Ensure', 'European', 'Event', 'Evolution', 'Genetic', 'Genome', 'Genomics', 'Human', 'Lead', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Partner in relationship', 'Pattern', 'Phenotype', 'Population', 'Population Group', 'Process', 'Recording of previous events', 'Recurrence', 'Risk', 'Role', 'Series', 'Source', 'Statistical Methods', 'Statistical Models', 'Structure', 'Technology', 'Time', 'Work', 'analytical tool', 'genetic architecture', 'genetic evolution', 'insight', 'novel', 'reference genome', 'statistical and machine learning', 'structural genomics', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2020,332952,0.03276441067871565
"Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease ABSTRACT Rapid progress in biomedical informatics has generated massive high-dimensional data sets (“big data”), ranging from clinical information and medical imaging to genomic sequence data. The scale and complexity of these data sets hold great promise, yet present substantial challenges. To fully exploit the potential informativeness of big data, there is an urgent need to find effective ways to integrate diverse data from different levels of informatics technologies. Existing approaches and methods for data integration to date have several important limitations. In this project, we propose novel statistical methods and strategies to integrate neuroimaging, multi-omics, and clinical/behavioral data sets. To increase power for association analysis compared to existing methods, we propose a novel multi-phenotype multi-variant association method that can evaluate the cumulative effect of common and rare variants in genes or regions of interest, incorporate prior biological knowledge on the multiple phenotype structure, identify associated phenotypes among multiple phenotypes, and be computationally efficient for high-dimensional phenotypes. To improve the prediction of clinical outcomes, we propose a novel machine learning strategy that can integrate multimodal neuroimaging and multi-omics data into a mathematical model and can incorporate prior biological knowledge to identify genomic interactions associated with clinical outcomes. The ongoing Alzheimer's Disease Neuroimaging Initiative (ADNI) and Indiana Memory and Aging Study (IMAS) projects as a test bed provide a unique opportunity to evaluate/validate the proposed methods. Specific Aims: Aim 1: to develop powerful statistical methods for multivariate tests of associations between multiple phenotypes and a single genetic variant or set of variants (common and rare) in regions of interest, and to develop methods for mediation analysis to integrate neuroimaging, genetic, and clinical data to test for direct and indirect genetic effects mediated through neuroimaging phenotypes on clinical outcomes; Aim 2: to develop a novel multivariate model that combines multi-omics and neuroimaging data using a machine learning strategy to predict individuals with disease or those at high-risk for developing disease, and to develop a novel multivariate model incorporating prior biological knowledge to identify genomic interactions associated with clinical outcomes; Aim 3: to evaluate and validate the proposed methods using real data from the ADNI and IMAS cohorts; and Aim 4: to disseminate and support publicly available user-friendly software that efficiently implements the proposed methods. RELEVANCE TO PUBLIC HEALTH: Alzheimer's disease (AD) as an exemplar is an increasingly common progressive neurodegenerative condition with no validated disease modifying treatment. The proposed multivariate methods are likely to help identify novel diagnostic biomarkers and therapeutic targets for AD. Identifying new susceptibility loci/biomarkers for AD has important implications for gaining greater insight into the molecular mechanisms underlying AD. NARRATIVE In this project, we propose novel statistical methods and strategies to integrate high-dimensional neuroimaging, multi-omics, and clinical/behavioral data sets, which aim to increase detection power for association analysis and improve the prediction of clinical outcomes. The development of an advanced integrative analysis platform will provide more comprehensive and integrated approaches to answering complex biological questions. The proposed multivariate analysis methods have a high potential impact on and important implications for gaining greater insight into the molecular mechanisms underlying complex diseases, as well as helping the development of earlier diagnostic tests and novel therapeutic targets.","Integrating Neuroimaging, Multi-omics, and Clinical Data in Complex Disease",9916801,R01LM012535,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Beds', 'Behavioral', 'Big Data', 'Biological', 'Brain', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Complex', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Progression', 'Evaluation', 'Genes', 'Genetic', 'Genetic Variation', 'Genomics', 'Genotype', 'Health', 'Heterogeneity', 'Indiana', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mediating', 'Mediation', 'Medical Imaging', 'Memory', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Multivariate Analysis', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Phenotype', 'Positron-Emission Tomography', 'Proteomics', 'Public Health', 'Science', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Technology', 'Testing', 'Time', 'Validation', 'Variant', 'base', 'biomedical informatics', 'cohort', 'data integration', 'diagnostic biomarker', 'disease classification', 'diverse data', 'endophenotype', 'epigenomics', 'genetic association', 'genetic variant', 'high dimensionality', 'high risk', 'improved', 'insight', 'interest', 'learning strategy', 'mathematical model', 'metabolomics', 'multidimensional data', 'multimodality', 'multiple omics', 'neuroimaging', 'new therapeutic target', 'novel', 'novel diagnostics', 'predict clinical outcome', 'rare variant', 'risk variant', 'therapeutic target', 'transcriptomics', 'user friendly software']",NLM,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2020,341471,-0.04323949771189575
"Advanced computational methods in analyzing high-throughput sequencing data Sequencing technologies have become an essential tool to the study of human evolution, to the understanding of the genetic bases of diseases and to the clinical detection and treatment of genetic disorders. Computational algorithms are indispensible to the analysis of large-scale sequencing data and have received broad attention. However, developed several years ago, many mainstream software packages for sequence alignment, assembly and variant calling have gradually lagged behind the rapid development of sequencing technologies. They are unable to process the latest long reads or assembled contigs, and will be outpaced by upcoming technologies in terms of throughput. The development of advanced algorithms is critical to the applications of sequencing technologies in the near future. This project will address this pressing need with four proposals: (1) developing a fast and accurate aligner that accelerates short-read alignment and can map megabase-long assemblies against large sequence collections of over 100 gigabases in size; (2) developing an integrated caller for small sequence variations that is faster to run, more sensitive to moderately longer insertions and more accessible to biologists without extended expertise in bioinformatics; (3) developing a generic variant filtering tool that uses a novel deep learning model to achieve human-level accuracy on identifying false positive calls; (4) developing a new de novo assembler that works with the latest nanopore reads of ~100 kilobases in length and may achieve good contiguity at low coverage. Upon completion, the proposed studies will dramatically reduce the computational cost of data processing in most research labs and commercial entities, and will enable the applications of long reads in genome assembly, in the study of structural variations and in cancer researches. Computational algorithms are essential to the analysis of high-throughput sequencing data produced for the detection, prevention and treatment of cancers and genetic disorders. The proposed studies aim to address new challenges arising from the latest sequencing data and to develop faster and more accurate solutions to existing applications. The success of this proposal is likely to unlock the full power of recent sequencing technologies in disease studies and will dramatically reduce the cost of data analyses.",Advanced computational methods in analyzing high-throughput sequencing data,9870944,R01HG010040,"['Address', 'Advanced Development', 'Algorithms', 'Attention', 'Bioinformatics', 'Biological', 'Characteristics', 'Chromosomes', 'Clinical', 'Clinical Data', 'Collection', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Dependence', 'Detection', 'Development', 'Dimensions', 'Disease', 'Evolution', 'Future', 'Generations', 'Genetic', 'Genetic Diseases', 'Genome', 'High-Throughput Nucleotide Sequencing', 'Hour', 'Human', 'Large-Scale Sequencing', 'Length', 'Mainstreaming', 'Maps', 'Medical Genetics', 'Modeling', 'Modernization', 'Performance', 'Population Genetics', 'Prevention', 'Process', 'Production', 'Research', 'Research Personnel', 'Running', 'Seeds', 'Sequence Alignment', 'Sequence Analysis', 'Site', 'Speed', 'Stress', 'Structure', 'Technology', 'Text', 'Time', 'Variant', 'Work', 'anticancer research', 'base', 'bioinformatics tool', 'cancer therapy', 'computerized data processing', 'contig', 'convolutional neural network', 'cost', 'deep learning', 'deep sequencing', 'design', 'experimental study', 'genome analysis', 'high throughput analysis', 'improved', 'indexing', 'light weight', 'mammalian genome', 'nanopore', 'novel', 'open source', 'preservation', 'programs', 'success', 'tool', 'user-friendly', 'whole genome']",NHGRI,DANA-FARBER CANCER INST,R01,2020,397125,0.029888191579696397
"The fitness effects of de novo structural variants PROJECT SUMMARY/ABSTRACT This proposal for the NIH Pathway to Independence Award (K99/R00) focuses on the training of Dr. PingHsun Hsieh to become an independent investigator of large-scale genomics and human population genetics. Dr. Hsieh is a population geneticist by training, and the proposed studies will advance his training into long-read- based sequencing technologies and novel machine-learning approaches to study the fitness consequences of new mutations, with a focus on structural variants (SVs), in humans and nonhuman primates. Another essential piece will be the development of resources on which types of new SVs are most likely to be pathogenic and hence most worth further effort by medical researchers. The methods developed in this work will enable other researchers to do more hypothesis-free analysis of SVs in disease etiology. Specifically, the training program will center on the study of the distribution of fitness effects of new SVs in human and nonhuman primates using high-quality SV calls and genotypes from several large-scale long- and short-read sequencing projects. The mentored work will take place under the supervision of the primary mentor, Dr. Evan Eichler, and the co-mentor, Dr. Sharon Browning, both at the University of Washington (UW). The mentor and co-mentor are well-established experts in the characterization of genomic variations using high-throughput technologies and the development of stochastic modeling methods for large-scale genetic data, respectively. Dr. Hsieh will also gain advice from a formal advisory committee as well as through activities arranged by the Department of Genome Sciences (GS), which is an optimal place for the mentored training providing the candidate with access to outstanding scientists in areas including genetics of model organisms, disease, population genetics, and the development of high-throughput genomic technologies. While found in nature and yet generally deemed to be deleterious given their size, SVs can be beneficial, and thus, the distribution of fitness effects (DFE) of new SVs (i.e., the relative frequencies of beneficial, neutral, and deleterious SVs) remains elusive. In the proposed studies, we will infer the DFE of new SVs and other variants to assess their relative importance in nature, which in turn helps prioritize variants (e.g., SVs vs. single- nucleotide variants [SNVs]) in medical genetics. Specifically, in the K99/R00 phases we will (1) infer the DFE of new SVs and SNVs using a diverse panel of ~100 long-read and ~4,000 short-read high-coverage human and nonhuman primate genomes; (2) compare the DFE of new mutations among primates using contemporary and ancient DNA genomes; and (3) study the fitness effects and selective constraints on diseases in different mutation categories in large cohorts of >20,000 genomes. The skills learned in this proposal are on the cutting-edge and are tailored for the candidate to amass a great amount of knowledge in new areas of genomics, which will be applicable to many organisms and diseases and critical to the candidate’s future independent laboratory. NARRATIVE Understanding the relative abundance of beneficial, neutral, and deleterious mutations in different variant categories (e.g., genic vs. intergenic) provides useful guidance and resources for biomedical researchers to prioritize disease-causing mutations and strategize their efforts. To date, however, little effort has been made to study the full spectrum of fitness effects of new structural variants – an important but largely underappreciated genomic variation. The work proposed here seeks to leverage long-read sequencing technologies and develop novel machine-learning approaches to quantify the fitness effects of new mutation, with a focus on structural variants, and subsequently delineate the relative importance among different types of mutations in genetic diseases.",The fitness effects of de novo structural variants,9950314,K99HG011041,"['Advisory Committees', 'Affect', 'Animal Model', 'Area', 'Award', 'Base Pairing', 'Benchmarking', 'Categories', 'Communities', 'Complex', 'Copy Number Polymorphism', 'DNA', 'DNA Sequence', 'Data', 'Demography', 'Development', 'Diploidy', 'Disease', 'Etiology', 'Evolution', 'Frequencies', 'Future', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Models', 'Genetic Polymorphism', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Individual', 'Instruction', 'Knowledge', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Genetics', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Mutation', 'Natural Selections', 'Nature', 'Organism', 'Outcome', 'Parents', 'Pathogenicity', 'Pathway interactions', 'Phase', 'Phylogenetic Analysis', 'Population', 'Population Genetics', 'Primates', 'Public Health', 'Quantitative Trait Loci', 'Recurrence', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Sample Size', 'Sampling', 'Scientist', 'Shapes', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Structure', 'Supervision', 'Technology', 'Testing', 'Time', 'Training', 'Training Programs', 'Uncertainty', 'United States National Institutes of Health', 'Universities', 'Variant', 'Washington', 'Work', 'autism spectrum disorder', 'base', 'biological systems', 'biomedical resource', 'career', 'cohort', 'disease-causing mutation', 'expectation', 'fitness', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic locus', 'genomic variation', 'high throughput technology', 'human population genetics', 'improved', 'machine learning method', 'nonhuman primate', 'novel', 'pressure', 'simulation', 'skills', 'technology development', 'trait']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2020,132244,0.004241468448406659
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efficiently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be infinitely replicated. Their combination, the multiparental genetic reference population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, flies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions considered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and find variance-controlling genes; and more rigorous and expansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered include: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only fill significant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9893003,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'causal variant', 'computerized tools', 'design', 'fly', 'human disease', 'human model', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2020,336445,0.03084403533211053
"Uncovering the Human Secretome PROJECT SUMMARY / ABSTRACT Peptide hormones regulate embryonic development and most physiological processes by acting as endocrine or paracrine signals. They are also a rich source of relatively safe medicines to treat both common and rare diseases. Yet finding peptide-coding genes below ~300 base pairs is inherently difficult because they lie within the noise of the genome. Recent multidisciplinary, proteophylogenomic studies in lower species, such as yeast and flies, have uncovered hundreds of new small protein-coding genes called “smORFs”. In humans, recent work on the mitochondrial genome has also uncovered dozens of small peptide hormone genes called MDPs. Based on these and other studies, it is estimated that about 5% of proteins in the human nuclear genome have not yet been discovered, particularly those that encode small peptides below 100 amino acids. It is a well documented but rarely challenged practice to discard large quantities of sequencing and proteomic data because they do not match the annotated human genome. My overarching goal is to discover the human “secretome” and make practical use of it to improve the human condition. Over the past few years, we have developed a unique pipeline of technologies that combines breakthroughs in math, computer hardware and software, proteomics, mass spectrometry, and HTS screening, each of which has been optimized and integrated. Our GeneFinder software modules, based on machine-learning, can process data 100 times faster than traditional methods and rapidly validate small human genes using public and in-house generated databases of genetic and proteomic data. Using the prototype version of the platform that finds conservation between humans, chimp, and macaque, we have discovered thousands of putative peptide-coding genes and validated hundreds of them. We aim to (1) further improve the algorithm to increase its speed and accuracy, (2) improve the genome annotation for thousands of small novel genes, (3) determine their expression profiles in normal and diseased tissues, (4) explore their genetic association with disease loci, and (5) screen the first secretomic library to find hormones with novel biological and therapeutically relevant activities. The data, the software package, and libraries will be made available to the research community. In doing so, we will shed light on the dark matter of the human genome, the parts with the greatest therapeutic potential, thereby helping to steer and accelerate the pace of research and drug development for generations to come. PROJECT NARRATIVE There has been a rapid expansion in the use of peptide hormones as drugs over the last decade, yet new research indicates that more than 90% of all hormones in the body (encoded by an additional 5% of the human genome) remain to be discovered. As a result, terabytes of data are discarded each week and innumerable opportunities for biological discovery are missed because, according to our findings, the majority of genes below ~300 base pairs are missing from the annotated human genome. We propose an integrated, multi- disciplinary approach to find, validate and characterize an estimated 4000-5000 new peptide-coding genes using a pioneering technology platform that combines breakthroughs in math, custom-built computer hardware and software, and wet-lab approaches, providing a far more complete roadmap for biology and medicine in the 21st century.",Uncovering the Human Secretome,9928344,DP1AG058605,"['Algorithms', 'Amino Acids', 'Base Pairing', 'Biological', 'Biological Response Modifier Therapy', 'Biology', 'Code', 'Communities', 'Computer Hardware', 'Computer software', 'Custom', 'Data', 'Disease', 'Embryonic Development', 'Endocrine', 'Expression Profiling', 'Generations', 'Genes', 'Genetic Databases', 'Genome', 'Goals', 'Hormones', 'Human', 'Human Genome', 'Libraries', 'Light', 'Macaca', 'Machine Learning', 'Mass Spectrum Analysis', 'Mathematics', 'Medicine', 'Methods', 'Noise', 'Nuclear', 'Pan Genus', 'Paracrine Communication', 'Peptides', 'Pharmaceutical Preparations', 'Physiological Processes', 'Process', 'Proteins', 'Proteomics', 'Rare Diseases', 'Research', 'Source', 'Speed', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Work', 'Yeasts', 'base', 'dark matter', 'drug development', 'fly', 'genetic association', 'genome annotation', 'improved', 'interdisciplinary approach', 'mitochondrial genome', 'multidisciplinary', 'novel', 'peptide hormone', 'prototype', 'research and development', 'screening', 'terabyte']",NIA,HARVARD MEDICAL SCHOOL,DP1,2020,1186500,0.0094728034843306
"Advanced algorithms to infer and analyze 3D genome structures Project Summary For the past decade, the population-cell Hi-C technique has significantly improved our ability to discover genome-wide DNA proximities. However, because population Hi-C is based on a pool of cells, it will not help us reveal each single cell's 3D genome structure or understand cell-to-cell variability in terms of 3D genome structure and gene regulation. It is also difficult to achieve a high resolution, such as 1 Kbp, with population Hi- C; therefore, when finding and analyzing the spatial interactions for the promoter or enhancer regions typically associated with biologically-important regulatory elements, population Hi-C data's resolution is too low to be useful. Moreover, while we know that the CTCF-cohesin complex plays a key role in the formation of genome 3D structures, the question is whether long non-coding RNAs (lncRNAs) are involved in the process since lncRNAs have been found to recruit proteins needed for chromatin remodeling, and our preliminary research has found that lncRNA LINC00346 directly interacts with CTCF. Finally, while members of the bioinformatics community, including the PI, have developed many algorithms to reconstruct 3D genome structures based on population Hi-C data, important questions still must be answered regarding how 3D genome structures are involved in gene regulation and whether there are relationships between 3D genome structures and genetic and epigenetic features. The PI proposes to conduct leading research to overcome these challenges and address these questions. During the next five years, the PI will develop algorithms to reconstruct the 3D whole- genome structures for single cells and analyze cell-to-cell variabilities in terms of 3D genome structure and gene regulation. The PI will develop a deep learning algorithm to enhance the resolution of population Hi-C data to that of Capture Hi-C data (1 Kbp) so that we can make good use of the large amount of Hi-C data accumulated in the past decade. An online database will be built to allow the community to access both population and single-cell 3D genome structures in an integrated way. The PI will work with a cancer biologist to discover any lncRNAs that function as a scaffold to fine-tune the CTCF-cohesin protein complex, as well as two neuron scientists to develop a more complete understanding of gene regulation while considering 3D genome and other genetic and epigenetic features. Given the PI's track record and productivity, having three computational goals and two collaborative goals is not only feasible but computationally and biologically rewarding. In five years, once the proposed studies are accomplished, the PI should have established a uniquely independent place in the field of 3D genome, maintaining leading positions in inferring single-cell 3D genome structures, enhancing Hi-C data resolution, and building 3D genome databases, while establishing similar positions in reconstructing high-resolution 3D genome structures, finding lncRNAs' roles in the formation of genome structures, and understanding how 3D genome structures are involved in gene regulation. Project Narrative The three-dimensional (3D) structure of genome is critically important for gene regulation; and the abnormal 3D genome structures are often associated with diseases such as cancer. This proposal aims to reconstruct and analyze the 3D genome structures of thousands of individual cells, study how 3D genome structures participate in gene regulation, determine whether long noncoding RNAs (lncRNAs) are involved in the formation of genome structures, and build an online knowledge base integrating 3D genome structures with other biological information.",Advanced algorithms to infer and analyze 3D genome structures,10027542,R35GM137974,"['3-Dimensional', 'Address', 'Algorithms', 'Bioinformatics', 'Biological', 'Cells', 'Communities', 'Complex', 'DNA', 'Data', 'Databases', 'Disease', 'Enhancers', 'Epigenetic Process', 'Gene Expression Regulation', 'Genetic', 'Genome', 'Goals', 'Individual', 'Malignant Neoplasms', 'Neurons', 'Other Genetics', 'Play', 'Population', 'Positioning Attribute', 'Process', 'Productivity', 'Proteins', 'Regulatory Element', 'Research', 'Resolution', 'Rewards', 'Role', 'Scientist', 'Structure', 'Techniques', 'Untranslated RNA', 'Work', 'base', 'chromatin remodeling', 'cohesin', 'deep learning algorithm', 'genome database', 'genome-wide', 'improved', 'knowledge base', 'member', 'promoter', 'protein complex', 'recruit', 'scaffold', 'three dimensional structure', 'whole genome']",NIGMS,UNIVERSITY OF MIAMI CORAL GABLES,R35,2020,354694,-0.023161995229376273
"Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation To be fully understood, the human genome must be considered in the context of evolution. The activities that have dominated human genomics for three decades — such as genome sequencing and annotation, interrogation with high-throughput biochemical assays, and the identification of associations between genetic variants and diseases — have been enormously informative, but these descriptive studies must eventually be understood within the theoretical framework of evolutionary genetics. We must continue to press forward from the what? to the why? and how? of human genetics.  The goal of my laboratory is to interpret high-throughput genomic data from an evolutionary perspective. Drawing from ideas and techniques in molecular evolution, population genetics, statistics, and computer science, we aim both to understand the evolutionary forces that have shaped human genomes, and to use evolution to shed light on the phenotypic importance of particular sequences. Our recent activities have focused in three major areas: (1)  reconstruction  of  features  of  human  evolution  based  on  genome  sequences;  (2)  prediction  of  the  fitness consequences  of  human  mutations;  and  (3)  the  study  of  transcriptional  regulation  and  its  evolution  in primates.   We have reported major findings in each of these areas, including the existence of gene flow from early modern humans to Eastern Neandertals, a map of fitness consequences for mutations across the human genome, and an analysis showing that the architecture of transcription initiation is highly similar at enhancers and promoters in the human genome.  Here we propose to extend our research substantially in each of these areas, working together with a broad range  of  experimental  and  theoretical  collaborators.    Our  new  goals  include  the  development  of  improved methods for reconstructing human demography, with a focus on ancient gene flow; extensions of our ancestral recombination graph (ARG) sampling methods to accommodate much larger samples sizes, with applications in association mapping and the detection of natural selection; two complementary machine-learning approaches for  improving  the  prediction  of  fitness  consequences  from  sequence  data;  an  experimental  collaboration  to leverage CRISPR-Cas9 screens in characterizing noncoding mutations; a multi-pronged study of the sequence determinants of RNA stability and their implications for the evolution of transcription units; and development of a new probabilistic model for turnover of regulatory elements.  Together, these projects will address a wide variety of fundamental questions about the function and evolution of sequences in the human genome. Vast quantities of genomic data are now available to describe patterns of genetic variation within  human populations and across species, and various measures of biochemical activity along the human  genome. These data need to be interpreted in light of the fundamental forces of mutation,  recombination, natural selection, and genetic drift that have shaped genetic variation. This  proposal describes a series of projects that make use of new computational, statistical, and  theoretical methods to address fundamental questions in human evolutionary genetics, including how  humans arose   from our archaic hominin and ape cousins, how human populations diverged from one  another, how new mutations influence human health and fitness, and how regulatory sequences  contribute to unique aspects of human biology.","Evolutionary Human Genomics: Demography, Natural Selection, and Transcriptional Regulation",9876220,R35GM127070,"['Address', 'Architecture', 'Area', 'Biochemical', 'Biological Assay', 'CRISPR screen', 'Collaborations', 'Data', 'Demography', 'Detection', 'Development', 'Enhancers', 'Evolution', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Drift', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Goals', 'Graph', 'Health', 'Human', 'Human Biology', 'Human Genetics', 'Human Genome', 'Laboratories', 'Light', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modernization', 'Molecular Evolution', 'Mutation', 'Natural Selections', 'Pattern', 'Phenotype', 'Pongidae', 'Population', 'Population Genetics', 'Primates', 'RNA Stability', 'Regulatory Element', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Series', 'Statistical Models', 'Techniques', 'Transcription Initiation', 'Transcriptional Regulation', 'Untranslated RNA', 'base', 'computer science', 'fitness', 'genetic variant', 'genome analysis', 'genome annotation', 'genome sequencing', 'genomic data', 'human genomics', 'improved', 'promoter', 'reconstruction', 'statistics']",NIGMS,COLD SPRING HARBOR LABORATORY,R35,2020,479215,-0.013154856128190033
"A database for high-resolution chromatin contact maps and human genetic variants Abstract After the completion of the Human Genome Project, several landmarking consortia have accumulated large amounts of genomic data towards understanding the functions of human genome. The ENCODE project has annotated genome-wide regulatory elements. The Roadmap Epigenomic project has characterized tissue-speciﬁc variation in epigenetic state. The NIH Common Fund GTEx project has delineated tissue-speciﬁc gene expression and transcription regulation. The NIH Common Fund 4D Nucleome (4DN) project has revealed dynamic 3D chromatin organization in many cell and tissue types. Each of the aforementioned consortia has generated thousands or even tens of thousands of datasets, and provided different insights regarding human genome at an unprecedent scale and depth. However, the datasets generated from these consortia are isolated in terms of cell types and tissue types covered, how the data are stored, and the resolution of the genomic data. These gaps bring realistic data analysis challenges to biomedical researchers when they use these public datasets jointly in their research — they need to go through different data portals with heterogeneous processing pipelines, different data formats, and unmatched resolutions. We aim to develop the most cutting-edge deep learning approaches to impute high-resolution chromatin contact maps, and integrate the high-resolution chromatin contact maps with transcriptional data available from GTEx project and epigenomic data from ENCODE/Roadmap. We plan to share the integrated data on a public web server with a multi-panel interactive visualization genome browser. The integrated data will provide an important resource for understanding of tissue-speciﬁc genetic variation in the light of the spatial organization of these genomic and epigenomic elements and their functional implications. Project Narrative The goal of this project is to develop novel computational methods to integrate 4DN datasets with GTEx datasets and ENCODE/Roadmap datasets. The integrated datasets will be critical resource to unveil the mechanisms of the genetic variants identiﬁed in genome-wide association studies. The new knowledge gained here could help us understand the genetic basis of many human diseases.",A database for high-resolution chromatin contact maps and human genetic variants,10109293,R03OD030599,"['3-Dimensional', 'Address', 'Area', 'Base Pairing', 'Cells', 'Chromatin', 'Chromatin Structure', 'Communities', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Elements', 'Epigenetic Process', 'Funding', 'Gene Expression Regulation', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Internet', 'Knowledge', 'Maps', 'Molecular', 'Nucleosomes', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Technology', 'Tissue-Specific Gene Expression', 'Tissues', 'Transcriptional Regulation', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'cell type', 'data format', 'data integration', 'data portal', 'data resource', 'data visualization', 'deep learning', 'epigenomics', 'expectation', 'genetic variant', 'genome annotation', 'genome browser', 'genome sciences', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'insight', 'interest', 'next generation sequencing', 'novel', 'open data', 'web server']",OD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R03,2020,265495,-0.027316349528462885
"Novel statistical methods and tools to integrate multiple endophenotypes and functional annotation data to study the roles of rare variants in complex human diseases using sequencing data Project Summary In the past fifteen years, great efforts have been made to understand the genetic architecture of complex human diseases through genome-wide association studies. Although many genome-wide significant variants have been identified, the heritability or variance explained by these variants remains very small, suggesting substantial missing heritability that may yet be explained by common genetic variants with smaller effect sizes and/or rare and low frequency variants, which calls for the development and application of novel statistical methods to whole genome/exome sequencing data collected from deeply phenotyped cohorts. In this project, we will develop methods that leverage multiple correlated endophenotypes and further integrate functional annotation data to identify novel rare variants for complex traits. We will develop a set of new computational and analytical tools that are practically useful and broadly applicable to general sequencing studies, and the applications of our methods will likely identity novel rare variant associations and shed new lights on the genetics of cardiometabolic diseases. In Aim 1, we propose to develop novel statistical methods to integrate multiple endophenotypes to study the impact of rare variants on complex human diseases. Our methods will fill in the gap between the current practice of association studies and the practical needs of integrating endophenotypes for improved understanding and diagnosis of clinical outcomes. In Aim 2, we will extend the methods to meta-analyses across studies. In Aim 3, we will develop a novel kernel machine learning approach to integrating various functional information to annotate the whole genome region, and further integrate them to develop a dynamic whole-genome scan test to detect rare variant associations with multiple endophenotypes. We will leverage the NHLBI TOPMed whole genome sequencing (WGS) data and the UK Biobank whole exome sequencing (WES) data, and integrate the functional annotation data to identify and dissect the role of rare variants on the cardiometabolic traits (Aim 4). Our proposed work is cost-effective as it leverages the existing WGS/WES samples and functional annotation data while providing methods and tools that are broadly applicable to other studies, and builds on a strong team of scientists with proven track record in statistical genetics, large-scale genetic studies, and cardiometabolic traits. We expect our methods will lead to the discoveries of many more rare and low frequency variants for these traits. These results will offer new insights to help design more effective treatment and prevention strategies. All our proposed methods will be disseminated to the public through well-tested and publicly available software (Aim 5). Project Narrative We will develop statistical methods and computational software to analyze whole genome/exome sequencing data by integrating multiple phenotypes and functional annotations to identify novel genes associated with cardiometabolic diseases and allow researchers to better disentangle the impacts of rare variants on these complex human diseases. It will also facilitate the translation of basic research findings into clinical studies.",Novel statistical methods and tools to integrate multiple endophenotypes and functional annotation data to study the roles of rare variants in complex human diseases using sequencing data,9972090,R01GM134005,"['Address', 'Basic Science', 'Biological', 'Cardiovascular Diseases', 'Clinical Research', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Estrogen receptor positive', 'Frequencies', 'Genes', 'Genetic', 'Genetic study', 'Genome Scan', 'Heritability', 'Human', 'Knowledge', 'Large-Scale Sequencing', 'Machine Learning', 'Measures', 'Meta-Analysis', 'Metabolic Diseases', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Outcome', 'Phenotype', 'Play', 'Prevention strategy', 'Public Health', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Software Tools', 'Source', 'Statistical Methods', 'Statistical Models', 'Testing', 'Time', 'Trans-Omics for Precision Medicine', 'Translations', 'Variant', 'Work', 'analytical tool', 'base', 'biobank', 'cardiometabolism', 'clinical Diagnosis', 'cohort', 'computerized tools', 'cost effective', 'design', 'disease diagnosis', 'effective therapy', 'endophenotype', 'exome sequencing', 'experience', 'genetic architecture', 'genetic variant', 'genome sequencing', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'novel', 'programs', 'rare variant', 'tool', 'trait', 'treatment strategy', 'web site', 'whole genome']",NIGMS,YALE UNIVERSITY,R01,2020,328257,0.05818739153543492
"Optimizing Genetic Testing for Deafness for Clinical Diagnostics Project Summary  Hearing loss is the most common sensory deficit in humans. It is diagnosed in 1 in 500 newborns and affects half of all octogenarians. Although causality is multifactorial, in developed countries a large fraction of hearing loss is genetic and non-syndromic, i.e. not associated with other phenotypes.  During the prior granting period, we implemented and integrated comprehensive genetic testing as a cornerstone in the evaluation of the deaf and hard-of-hearing person. The American College of Medical Genetics has recognized the merit of this approach, and in 2014 included comprehensive genetic testing for the evaluation of deafness in their newest treatment guidelines. In the largest study to date to corroborate this decision, we found an underlying genetic cause for hearing loss in 440 (39%) of 1119 sequentially accrued patients chosen without exclusion criteria. Pathogenic variants were present in 49 genes and included missense variants (49%), copy number changes (18%), indels (18%), nonsense variants (8%), splice-site alterations (6%) and promoter variants (<1%), making comprehensive genetic testing the single best test to order in the diagnosis of hearing loss after an audiogram.  In this competitive renewal, we will build on these accomplishments by completing the following aims: • Specific Aim 1: To optimize phenotype-genotype integration in the analysis of hereditary hearing loss  by refining the use of hierarchical surface clustering and audioprofile surface analysis to determine  which types of genetic hearing loss are associated with clinically meaningful sub-clusters • Specific Aim 2: To validate and integrate physics-based protein modeling as a tool within the Deafness  Variation Database to predict variant effect and the molecular and patient phenotype • Specific Aim 3: To identify genetic modifiers of specific deafness-causing genes predicted by  hierarchical surface clustering and validated by physics-based potential free-energy modeling  The successful completion of this grant will improve the clinical care of persons with hearing loss by enhancing phenome-genome integration and by making variant interpretation more robust. Knowledge gained from this proposal will also lay the foundation for refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex phenotypes such as noise- induced and age-related hearing loss. This competitive renewal addresses the increasingly daunting challenge of variant interpretation. We will seamlessly integrate AudioGene into the OtoSCOPE® pipeline, explore hierarchical surfaces clustering at all loci, enhance the utility of the Deafness Variation Database by adding physics-based potential free-energy modeling, and using these tools, identify genetic modifiers of select types of genetic hearing loss. The completion of these aims will lay the foundation for more refined studies focused on the identification of genetic modifiers – both positive and negative – associated with complex hearing loss phenotypes including noise-induced and age-related hearing loss.",Optimizing Genetic Testing for Deafness for Clinical Diagnostics,9820729,R01DC012049,"['Address', 'Adoption', 'Affect', 'Algorithms', 'American', 'Area', 'Auditory Threshold', 'Biology', 'Case Study', 'Classification', 'Clinical', 'Clinical Trials', 'Cochlear implant procedure', 'Communities', 'Complex', 'Cystic Fibrosis', 'Data', 'Databases', 'Decision Making', 'Decision Trees', 'Developed Countries', 'Diagnosis', 'Diagnostic', 'Duchenne muscular dystrophy', 'Enrollment', 'Etiology', 'Evaluation', 'Exclusion Criteria', 'Foundations', 'Free Energy', 'Genes', 'Genetic', 'Genetic Diseases', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Guidelines', 'Health Personnel', 'Healthcare', 'Hearing', 'Hearing Tests', 'Heritability', 'Human', 'Infrastructure', 'Knowledge', 'Machine Learning', 'Massive Parallel Sequencing', 'Medical Genetics', 'Methods', 'Modeling', 'Molecular', 'Newborn Infant', 'Noise', 'Octogenarian', 'Otoscopes', 'Pathogenicity', 'Patients', 'Persons', 'Phenotype', 'Physics', 'Presbycusis', 'Proteins', 'RNA Splicing', 'Reporting', 'Research', 'Scientist', 'Sensory', 'Site', 'Surface', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Treatment Efficacy', 'Variant', 'base', 'clinical care', 'clinical decision-making', 'clinical diagnostics', 'clinical implementation', 'clinical phenotype', 'clinically significant', 'cohort', 'deaf', 'deafness', 'design', 'evaluation/testing', 'falls', 'gene therapy', 'genetic disorder diagnosis', 'genetic testing', 'hard of hearing', 'hearing impairment', 'hearing loss phenotype', 'hearing preservation', 'hereditary hearing loss', 'improved', 'in silico', 'insertion/deletion mutation', 'medical schools', 'novel', 'phenome', 'precision genetics', 'prognostic', 'promoter', 'research clinical testing', 'software systems', 'support vector machine', 'tool', 'treatment guidelines']",NIDCD,UNIVERSITY OF IOWA,R01,2020,508845,0.041186791525711405
"Comprehensive Characterization of Missense Mutants in Factor IX SUMMARY Deficiencies in coagulation factor IX (FIX) cause the bleeding disorder hemophilia B, while high levels of FIX pose a risk for thrombosis. Thus, genetic variation in the F9 gene encoding FIX can impact bleeding by decreasing FIX expression or activity, or can impact thrombosis by increasing FIX expression or activity. However, when a new DNA variant is discovered in the F9 gene, we typically lack the evidence needed to confidently determine if the variant alters the function of the encoded FIX protein and, if so, how severely. For example, in the national hemophilia genotyping project MyLifeOurFuture, the majority of F9 missense variants (i.e. DNA changes predicted to change a FIX amino acid) discovered in patients with hemophilia B had insufficient evidence to be classified as pathogenic. Functional studies, where a FIX variant’s stability, activity or other properties are evaluated in vitro, can provide strong evidence to inform interpretation of F9 variants. However, traditional functional studies are time- and resource-intensive, so testing the hundreds of F9 variant we have observed so far would be impractical. Evaluating the thousands of possible FIX missense variants we could observe as more individuals are sequenced would be impossible. Instead, we propose a new approach to express and characterize nearly every possible missense variant in the FIX protein to advance our understanding of FIX biology, improve the interpretation of genetic variation in the F9 gene, and advance hemophilia care and treatments. To accomplish this goal, we will employ deep mutational scanning, a method we developed for measuring the effects of massive numbers of missense variants of a protein simultaneously. Here, we will display a library of nearly all possible FIX missense variants tethered to the surface of cultured human cells. We propose to exploit this FIX surface display library in two aims: 1) Quantifying the effect of nearly every possible F9 missense variant on FIX expression and secretion, and 2) Quantifying the effect of nearly every possible F9 missense variant on specific FIX functions including Gla-domain gamma-carboxylation and activation of FIX by factor XIa (FXIa). These aims will reveal how nearly all possible missense variants in FIX impact expression, secretion, gamma- carboxylation, and activation by FXIa. In aim 3, we will use these large-scale functional data to dissect the mechanism by which F9 pathogenic variants disrupt FIX function. We will also use machine learning, leveraging the functional data along with other features to predict pathogenicity for each missense variant in FIX. Taken together, the functional data we generate, the analyses we propose, and tools we build will transform the characterization of F9 variants. They will also serve as a resource to better understand FIX biology, improve the clinical translation of F9 genetic information, and inform new treatments. NARRATIVE DNA changes that affect the F9 gene that makes coagulation factor IX (FIX) can reduce FIX levels and cause the bleeding disorder hemophilia B, or increase the amount of active FIX and increase the risk of thrombosis. Although hundreds of variants have been detected in the F9 gene, there is often insufficient information to know how any one specific change will affect the protein, if that change will cause disease, or how severe disease will likely be. We will use new technologies to study the consequences of every possible amino acide change in FIX, with the goal of developing the information needed to understand the significance of new genetic changes as they are discovered in the future and to improve the care and treatment of patients.",Comprehensive Characterization of Missense Mutants in Factor IX,9946710,R01HL152066,"['Affect', 'Amino Acids', 'Antibodies', 'Binding', 'Biological Assay', 'Biology', 'Blood Coagulation Disorders', 'Caring', 'Cell surface', 'Cells', 'Clinic', 'Coagulation Process', 'Comprehension', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Development', 'Disease', 'F9 gene', 'Factor Analysis', 'Factor IX', 'Factor XIa', 'Fluorescence', 'Fluorescent Antibody Technique', 'Future', 'Genetic Variation', 'Genetic study', 'Genotype', 'Goals', 'Hemophilia A', 'Hemophilia B', 'Hemorrhage', 'Hemostatic function', 'High-Throughput DNA Sequencing', 'Human', 'In Vitro', 'Individual', 'Label', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Mutation', 'Pathogenicity', 'Patients', 'Peptides', 'Production', 'Property', 'Proteins', 'Research', 'Resources', 'Risk', 'Sorting - Cell Movement', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Thrombosis', 'Time', 'Translating', 'Validation', 'Variant', 'Work', 'base', 'carboxylation', 'clinical translation', 'experimental study', 'gain of function', 'genetic information', 'genetic variant', 'improved', 'mutant', 'mutation screening', 'new technology', 'novel strategies', 'novel therapeutics', 'predictive modeling', 'tool']",NHLBI,BLOODWORKS,R01,2020,418577,-0.013255290242785689
"Epilepsy Multiplatform Variant Prediction (EpiMVP) The advent of next generation DNA sequencing has revolutionized gene discovery in human diseases, including epilepsy. Hundreds of genes have been implicated in epilepsy in the last decade, revealing the diversity of biological mechanisms that can go awry in this disorder. However, the rate at which we are identifying new genes involved in epilepsy is now outpacing our ability to study disease mechanisms. Moreover, clinical gene panel or exome sequencing has become standard practice for patients with early-onset, familial, and refractory epilepsies. This rapid assimilation of genetic testing into clinical care has led to a surge in the number of genetic variants of uncertain significance (VUS), particularly the occurrence of missense VUS. These VUS are assigned to an indeterminate spectrum between pathogenic and benign, which complicate interpretation for genetic counselors, clinicians, patients and families, as well as assessment of the need for further testing. Here we propose a Center without Walls, entitled Epilepsy Multiplatform Variant Prediction (EpiMVP), spanning 5 institutions and incorporating expertise from geneticists, clinicians, computational biologists, neuroscientists, stem cell biologists, pharmacologists and electrophysiologists who have a proven track record of collaborative publications and grants, as well as stature as leaders of national and international epilepsy organizations. EpiMVP will develop a modular, highly integrated platform approach to accelerate determination of the functional, pharmacological, neuronal network and whole animal consequences of genetic variants implicated in a range of clinical epilepsy types. We will study non-ion-channel, non-receptor genes commonly implicated in epilepsy, and that are involved in diverse biological processes. Our ultimate goals are to devise an effective experimental platform for testing the pathogenicity of VUS in genes implicated in epilepsy and to generate a computational model (EpiPred) that predicts the likelihood that a variant is pathogenic or benign. This work is crucial in the pursuit of novel therapeutics and the promise of personalized medicine. The overall milestones of the Center are: 1. Evaluate genes associated with epilepsy and select candidates for analysis, model data for, and analyze all project data for development of EpiPred an iterative machine learning model to classify variants in genes implicated in epilepsy. 2. Test selected VUS using medium throughput, in vitro approaches. 3. Test selected VUS in human cortical neurons or human brain organoids using induced pluripotent stem cell approaches. 4. Test selected VUS in pre-clinical, in vivo models. The expected outcomes are: 1. Provide a freely available prediction tool for clinicians to differentiate between pathogenic and benign variants for genes implicated in epilepsy; 2. Provide experimental models to study the functional consequences of specific variants; 3. Provide a reclassification of VUS in ClinVar/ClinGen and to develop new guidelines for incorporating functional readouts into the ACMG criteria; 4. Inform the future development of novel therapeutics to treat epilepsy. Here, we propose a Center without Walls, entitled Epilepsy Multiplatform Variant Prediction (EpiMVP), spanning five institutions and incorporating expertise from geneticists, clinicians, computational biologists, neuroscientists, stem cell biologists, pharmacologists and electrophysiologists who have a proven track record of collaborative publications and grants, as well as stature as leaders of national and international epilepsy organizations. EpiMVP will develop a modular, highly integrated platform approach to accelerate determination of the functional, pharmacological, neuronal network and whole animal consequences of genetic variants among a range of clinical epilepsy types. Our ultimate goal is to devise an effective platform for testing the pathogenicity of variants of uncertain significance in non-ion channel, non-receptor genes implicated in epilepsy and for identifying potential targets for future intervention.",Epilepsy Multiplatform Variant Prediction (EpiMVP),10003679,U54NS117170,"['Animals', 'Assimilations', 'Benign', 'Biodiversity', 'Biological', 'Biological Process', 'Brain', 'Cell Line', 'Cells', 'ClinVar', 'Clinical', 'Communication', 'Communities', 'Computer Models', 'DNA sequencing', 'Data', 'Data Analyses', 'Development', 'Disease', 'Epilepsy', 'Experimental Models', 'Family', 'Future', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Human', 'In Vitro', 'Institution', 'International', 'Intervention', 'Intractable Epilepsy', 'Ion Channel', 'Ligands', 'Machine Learning', 'Modeling', 'Molecular Biology', 'Needs Assessment', 'Neurons', 'Organoids', 'Outcome', 'Pathogenicity', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmacology', 'Pre-Clinical Model', 'Proteins', 'Publications', 'Services', 'System', 'Testing', 'Variant', 'Work', 'candidate selection', 'clinical care', 'data modeling', 'disease mechanisms study', 'early onset', 'exome sequencing', 'gene discovery', 'gene panel', 'genetic counselor', 'genetic testing', 'genetic variant', 'human disease', 'human pluripotent stem cell', 'in vivo Model', 'induced pluripotent stem cell', 'innovation', 'new therapeutic target', 'next generation', 'novel strategies', 'novel therapeutics', 'personalized medicine', 'pre-clinical', 'receptor', 'stem cells', 'tool', 'variant of unknown significance']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,U54,2020,2413012,0.004642204738822924
"Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases ﻿    DESCRIPTION (provided by applicant): The NHGRI Genome Sequencing Program (GSP) will identify genomic variants relevant to health and disease by genome sequencing over 225,000 participants across a multitude of diseases. The GSP will also serve as a pilot for the Precision Medicine Initiative that aims to enroll and sequence more than a million people representative of U.S. ethnic diversity. Here, we propose a GSP analysis center focused on Multi- and Trans- ethnic Mapping of Mendelian and Complex Diseases. There is a growing recognition of the substantial scientific advantages, as well as public health importance, of conducting biomedical research across ethnically diverse cohorts. We propose to develop scalable methods that incorporate ancestry to optimize medical genomic study design and improve power for uncovering the role of common and rare variants in disease. Achieving this goal requires expertise across diverse domains of knowledge including: medical and population genomics, algorithm development for complex disease mapping, and expertise in management of large-scale databases. Here, we have assembled a world-class team of medical and population geneticists, computer scientists, statisticians and clinicians, with leading expertise in the development of novel and scalable strategies for characterizing sequence variants and their role in disease. Importantly, our group has been at the forefront of development of resources, study designs and methods to enable genomic research in U.S. minority populations. Our project has three main objectives. First, we will develop an Automated Scalable Ancestry Pipeline (ASAP) for common disease mapping in diverse populations. ASAP will improve the computational efficiency of existing state-of-the-art methods for ancestry inference and develop important extensions to linear mixed models (LMMs) and other mapping strategies leveraging local and global ancestry. We will also develop methods to refine phenotypes and identify common controls for disease studies and define endpoints. Secondly, we will develop tools and resources for trans- and multi-population rare variant discovery that incorporate patterns of local and sub-continental ancestry. We will also develop machine-learning tools for variant annotation that leverage ancestral information, patterns of sequence evolution, and protein structure in a unified framework. Furthermore, we will incorporate population-specific patterns of cellular phenotypes to improve functional prediction algorithms for non-coding and coding variants. Lastly, we will disseminate our results through web-based resource that empower the biomedical research community. We will augment existing resources including ClinGen by annotating and characterizing pathogenic variants across diverse populations. We will develop a secure web-server that allows sharing of summary statistics and analysis pipelines to enable discovery, fine-mapping and functional prediction of genetic variants. Our team has ample experience with NIH-funded consortia and is dedicated to meeting the overall GSP project goals through collaborative work with NHGRI leadership and other funded investigators. PUBLIC HEALTH RELEVANCE The goal of our project is to accelerate the discovery of DNA variation relevant to health and disease by analyzing data from over 225,000 ethnically and racially diverse patients that will undergo genome sequencing. Of particular importance is ensuring we have powerful statistical methods for analyzing data from underserved groups including U.S. minority populations. Achieving this goal requires expertise across many domains of knowledge including: medical and population genomics, algorithm development for disease mapping, and expertise in large-scale databases.",Center for Multi- and Trans-ethnic Mapping of Mendelian and Complex Diseases,10126204,U01HG009080,"['Architecture', 'Biomedical Research', 'Chronic Disease', 'Clinical', 'Code', 'Communities', 'Complex', 'Computers', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Enrollment', 'Ensure', 'Evolution', 'Funding', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Health', 'Human Genome', 'Investigation', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Methylation', 'Minority', 'Modeling', 'Molecular Conformation', 'National Human Genome Research Institute', 'Participant', 'Pathogenicity', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Population Heterogeneity', 'Precision Medicine Initiative', 'Privatization', 'Protocols documentation', 'Public Health', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Resource Development', 'Resources', 'Role', 'Scientist', 'Secure', 'Shoulder', 'Statistical Methods', 'Target Populations', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Untranslated RNA', 'Variant', 'Work', 'algorithm development', 'analysis pipeline', 'cohort', 'disorder control', 'ethnic diversity', 'experience', 'genetic variant', 'genome sequencing', 'genomic tools', 'improved', 'innovation', 'large-scale database', 'meetings', 'novel', 'online resource', 'patient privacy', 'phenome', 'prediction algorithm', 'predictive modeling', 'preservation', 'programs', 'protective allele', 'protein structure', 'public health relevance', 'racial diversity', 'rare variant', 'risk variant', 'simulation', 'statistics', 'tool', 'tool development', 'web server', 'web-based tool']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,U01,2020,962530,0.05805977600330793
"Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations PROJECT SUMMARY/ABSTRACT  Myosins are a diverse and ubiquitous class of molecular motors that are responsible for generating much of the macroscopic force in the human body. The human genome encodes 38 different isoforms of myosin, and members of this group act as force sensors or generators for a diverse set of processes throughout the body. To serve this wide array of functions, each myosin isoform has been biophysically tuned for its physiological role. In fact, the tuning is so precise that missense variants in one myosin isoform, !-cardiac myosin, can cause a congenital cardiomyopathy that is the leading cause of sudden cardiac death in people under 30. And yet, it is unknown how particular variants cause disease, or how to infer the pathogenic potential for novel mutations.  Large differences in functional properties between myosin isoforms are not the result of large differences in coding sequence or overall topology. Neither foreknowledge of phylogeny nor crystal structure is sufﬁcient to predict an isoform's biophysical properties. Furthermore, mutations causing disease frequently occur in regions of the protein far from the site of their deleterious effects. Poor understanding of the biophysical regulation of motor function has hampered the development of pharmaceuticals and the interpretation of human genomic data.  My goal is to establish a mechanistic understanding of myosin motors that is capable of predicting if and how sequence variation changes biophysical properties and can cause cardiac disease. Since myosin kinetics are not apparent from sequence or overall structure, they must be determined by other factors. I hypothesize that kinetic differences result from differences in the allosteric networks in these proteins. Allosteric network in this context refers to the coordinated conformational ﬂuctuations that give protein regulation the appearance of action at a distance. To test this hypothesis, we will use our unique combination of enormous computational power for molecular simulation and cutting-edge machine learning tools for analyzing protein allostery.  Aim 1 is to identify the biophysical determinants of myosin isoforms' differing speeds. To test our hypothesis that allosteric networks are responsible for modulating dynamics, I will use molecular simulations of different myosin isoforms and compare their allosteric networks with biochemical data about their properties. Aim 1 directly addresses outstanding questions about normal molecular-biological function of the heart, putting it in line with NHLBI overarching objective #1.  Aim 2 is to determine the difference, at atomic resolution, between healthy and diseased !-cardiac myosin. I hypothesize that the pathogenicity of variants with an unknown molecular etiology is a consequence of allosteric disruption, and will use our computational tools to test this hypothesis by simulating a set of known-pathogenic variants. This aim uses techniques from data science to understand the genetic determinants of health, and will apply equally well to rare alleles in under-represented groups as to majority groups. It is directly addresses NHLBI overarching objectives #3, #4, and #7. PROJECT NARRATIVE  Myosins are a closely-related group of molecules that are responsible for generating much of the force in the human body, including the heartbeat, the movement of limbs, and driving food through the stomach and intestines. Small changes to the myosin genes can have large effects: in healthy people, these give rise to different myosins that perform different functions, and mutations in some myosin genes can give rise to diseases that cause of sudden cardiac death. This proposal aims to learn, at the level of atoms and interatomic bonds, why and how these subtle changes to the myosin gene can create such large effects in the protein's function.",Physics-based precision medicine: computationally phenotyping myosin isoforms and cardiomyopathy mutations,9881184,F30HL146052,"['Actins', 'Address', 'Affinity', 'Appearance', 'Automobile Driving', 'Behavior', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Process', 'Biophysics', 'Cardiac Myosins', 'Cardiomyopathies', 'Catalysis', 'Chemistry', 'Clinical', 'Code', 'Congenital cardiomyopathy', 'Crystallization', 'Data', 'Data Science', 'Development', 'Disease', 'Drug Binding Site', 'Etiology', 'Food', 'Genes', 'Genetic Determinism', 'Genetic Variation', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Genome', 'Human body', 'Intestines', 'Kinetics', 'Learning', 'Machine Learning', 'Measures', 'Membrane Proteins', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Molecular Motors', 'Motor', 'Mutation', 'Myosin ATPase', 'National Heart, Lung, and Blood Institute', 'Pathogenicity', 'Patient risk', 'Pharmacologic Substance', 'Phenotype', 'Phylogeny', 'Physics', 'Physiological', 'Process', 'Property', 'Protein Analysis', 'Protein Isoforms', 'Protein Region', 'Proteins', 'Regulation', 'Relaxation', 'Resolution', 'Risk stratification', 'Role', 'Signal Transduction', 'Site', 'Solvents', 'Speed', 'Stomach', 'Structure', 'Surface', 'Techniques', 'Testing', 'Time', 'Underrepresented Groups', 'Variant', 'base', 'biophysical properties', 'computerized tools', 'disease-causing mutation', 'force sensor', 'genomic data', 'heart function', 'improved', 'insight', 'limb movement', 'member', 'millisecond', 'molecular dynamics', 'novel', 'precision medicine', 'protein function', 'prototype', 'rare variant', 'rat Ran 2 protein', 'simulation', 'sudden cardiac death', 'tool', 'whole genome']",NHLBI,WASHINGTON UNIVERSITY,F30,2020,48719,-0.023912798793311093
"Discovering Novel Structural Genomic Rearrangements Using Deep Neural Networks Abstract Accurately detecting structural variation in the genome is a challenging task. Many approaches have been developed over the last few decades, yet it is estimated that tens of thousands of variants are still being missed in a given sample. Many of these variants are missed due to the limitations of using short-read sequencing to identify large variants. Although many of these missed variants are located within complex regions of the genome, it has been shown that some still have clinical relevance making their discovery important. New platforms have been developed for sequencing the genome using long-reads and show promise for overcoming many of these limitations creating the ability to identify the full spectrum of simple and complex structural variants. Because this technology is relatively young, new computational approaches to support the analysis of long-read sequencing data can aid in the discovery of these variants which are still being missed. In addition to detecting novel variation in samples with long-read sequencing data, computational approaches can be developed to leverage these novel variant calls to reanalyze the hundreds of thousands of short-read datasets currently available. In this proposal, we plan to develop new computational approaches to identify novel structural variation in the genome. In Aim 1, we will apply a recurrence approach to analyze long read sequencing datasets utilizing deep neural networks. In Aim 2, we will develop a tool to derive profiles of structural variants predicted in long- reads which can be used to identify and genotype structural variants calls in short read data-sets. Together, these approaches will allow researchers to accurately characterize structural variation in both long and short- read datasets. Narrative Structural variation has been implicated in numerous human diseases but there are still tens of thousands of variants being overlooked in the genome. The proposed research aims to detect novel variation by developing new computational tools to analyze data generated by state-of-the-art sequencing methods. These tools will aid in the discovery of variants associated with human health.",Discovering Novel Structural Genomic Rearrangements Using Deep Neural Networks,9911983,F31HG010569,"['Affect', 'Algorithms', 'Benchmarking', 'Biological Sciences', 'Categories', 'Complex', 'Computing Methodologies', 'DNA', 'DNA Resequencing', 'DNA Sequence Rearrangement', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Future', 'Genome', 'Genotype', 'Haplotypes', 'Health', 'Human', 'Human Genome', 'Image', 'Image Analysis', 'Label', 'Methods', 'Molecular', 'Molecular Computations', 'Pattern', 'Process', 'Recurrence', 'Repetitive Sequence', 'Research', 'Research Personnel', 'Sampling', 'Structure', 'Techniques', 'Technology', 'Training', 'Validation', 'Variant', 'base', 'clinically relevant', 'comparative', 'computerized tools', 'cost', 'deep learning', 'deep neural network', 'design', 'genome sequencing', 'human disease', 'insertion/deletion mutation', 'new technology', 'novel', 'reference genome', 'structural genomics', 'tool', 'variant detection']",NHGRI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,F31,2020,37657,0.036809251200961686
"Statistical genetics of aging-related genomic and phenotypic change To help to analyze and understand aging-related ""complex"" traits that are affected by many genes and environmental factors, we have followed the path of developing statistical algorithms for the analyses of genome-wide genotyping and high-throughput sequencing studies. Our proposed new computational tools provide means to analyze additional types of data e.g., to identify mitochondrial DNA (mtDNA) variants and to estimate mtDNA copy number efficiently from whole-genome sequences. For experimental tests of the algorithms, we are capitalizing on the special advantages of the InCHIANTI project (see Annual Report AG001050) and SardiNIA project (see Annual Report AG000675) to help in the assembly of mitochondrial sequence data and multiple phenotypic data in the two Italian cohorts.   In order to conduct analyses on large-scale consortium data to study mtDNA variation and copy number, we have developed two computational programs, providing a general solution for the analysis of mtDNA dynamics based on whole-genome sequencing studies. One program (mitoCaller) is designed specifically to identify mtDNA variants; the other (mitoCalc) infers mtDNA copy number in a cell directly from genome sequences. Applying the programs to leukocyte sequences of 2,000 SardiNIA participants and 1,000 InCHIANTI participants, we have shown that heteroplasmies (mtDNA variants with more than one allele at a site) increase with age, and that copy number is relatively highly heritable and is correlated with metabolic traits, particularly central fat levels. In more recent work, we have increased the speed of mitoCalc 100-fold (fastMitoCalc). The new program is being applied to white cells of 65,000 deeply sequenced individuals (TOPMed program, NHLBI), for GWAS on copy number.   With our expertise in studying mtDNA variation, we have an ongoing collaborative effort to study a special structural feature of DNA, G-quadruplex (G4) structures, as potential DNA roadblocks that perturb mitochondrial replication machinery. We used computational analyses of 3,000 individual genomes from two Italian cohorts to demonstrate an association between G4s and mtDNA variation. Using the software G4Hunter to predict G4-forming regions in mtDNA, we found statistically significant enrichment of mutations in stable G4 regions, with preferential occurrence of variants in the loop segments of G4 structures. Biochemical studies demonstrated a potent block of human mitochondrial replicative polymerase in DNA synthesis by G4 structure, which could be overcome by the G4-resolving helicase Pif1. Altogether, the computational and biochemical approaches indicate that mtDNA point mutations are enriched at stable G4 structures, consistent with replisome stalling at G-quadruplexes and reliance on error-prone DNA synthesis.  Expanding our other focus on the mtDNA copy number (mtDNAcn) analysis, we are setting out to examine the association between mtDNAcn and personality in participants of the Baltimore Longitudinal Study of Aging (BLSA). We assess the big five personality traits and facets using the Revised NEO Personality Inventory (NEO-PI-R) and estimate mtDNAcn efficiently from whole-genome DNA sequences. Our preliminary analyses show that mtDNAcn is significantly associated with specific domains of the personality inventory. We are currently performing mediation analysis to study the potential impact of mtDNAcn on the relationship between certain personality traits and mortality.  In another study, we have created a program that uses machine learning methods to measure effective rates of aging for individuals. We assess the extent to which an individual's physiological age could be determined as a composite score inferred from a broad range of biochemical and physiological traits from the SardiNIA and InCHIANTI longitudinal studies of aging. Physiological age inferred from our framework was highly correlated with chronological age (R2>0.8). We then defined a physiological aging rate (PAR) for each subject, a continuous trait measured as the ratio of the subjects predicted physiological age to his/her chronological age. We found that PARs were reproducible across follow-up studies, heritable (h20.3), and predictive of lifespan and mortality. Genome-wide association studies (GWAS) on the PARs identified both previously established age-associated loci and several new genetic associations. Our findings support a whole-body, pathology-independent aging effect that can be summarized by the physiological aging rate and our method can be used to evaluate the efficacy of treatments that target aging-related processes and disease. n/a",Statistical genetics of aging-related genomic and phenotypic change,10259330,ZIAAG000693,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Algorithms', 'Alleles', 'Ally', 'Annual Reports', 'Baltimore', 'Biochemical', 'Case-Control Studies', 'Cells', 'Chronology', 'Complex', 'Computer Analysis', 'Computer software', 'DNA', 'DNA Sequence', 'DNA biosynthesis', 'DNA copy number', 'Data', 'Disease', 'Environmental Risk Factor', 'Fatty acid glycerol esters', 'Follow-Up Studies', 'G-Quartets', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Heritability', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Leukocytes', 'Longevity', 'Longitudinal Studies', 'Measures', 'Mediation', 'Metabolic', 'Methods', 'Mitochondria', 'Mitochondrial DNA', 'Mutation', 'National Heart, Lung, and Blood Institute', 'Nuclear', 'Participant', 'Pathology', 'Personality', 'Personality Traits', 'Personality inventories', 'Phenotype', 'Physiological', 'Point Mutation', 'Polymerase', 'Population Control', 'Process', 'Reproducibility', 'Risk', 'Sardinia', 'Sequence Deletion', 'Single Nucleotide Polymorphism', 'Site', 'Speed', 'Statistical Algorithm', 'Structure', 'Testing', 'Trans-Omics for Precision Medicine', 'Treatment Efficacy', 'Variant', 'Work', 'age effect', 'base', 'cohort', 'computerized tools', 'design', 'genetic analysis', 'genetic association', 'genome sequencing', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'helicase', 'machine learning method', 'mortality', 'phenotypic data', 'programs', 'trait', 'whole genome']",NIA,NATIONAL INSTITUTE ON AGING,ZIA,2020,1547874,0.023374963879791363
"Central Sequencing Initiative Summary of ongoing projects organized by topic:   I. CLINICAL DIAGNOSTICS AND CONSULTATION  A. CLIA reports in CRIS. A central deliverable for our initiative is the clinical analysis and CLIA reporting into the CC medical record. This has been completed for approximately 600 patients since January 2019 and is a major accomplishment.  B. Operational development and refinement. Given the scale of our initiative, we dedicate significant attention to optimizing the efficiency of our workflow and anticipating potential disruptions related to policy adjustment or special circumstances. Specifically, this year we have increased automation of data entry into reporting and tracking processes, developed a new rapid turnaround time workflow for rare cases with high clinical urgency, and developed new CRIMSON workflows related to the new requirement for each patient to have a documented patient visit plan from a physician specifying sequencing prior to order activation.  C. Integration of medical geneticist in suite of consultation offerings. Recognizing room for improvement in our clinical consultation service for complex cases, we've started collaborating with a NIAID-NIAMS medical geneticist and are working concurrently with the NHGRI genetics consult service so we can continue to provide educational opportunities to genetics fellows. This has proven to be a clinically valuable service in multiple cases with complex clinical presentations or clinically significant molecular diagnoses outside the immune system.  D. Reanalysis. Clinical reanalysis of exome data is known to be an important source of new diagnoses over time. We are implementing a limited re-analysis workflow to be alerted to recent publications on variants in our database, which in rare cases provides sufficient evidence to merit a new molecular diagnosis.   E. Childrens collaboration. The CSI works with Gigi Notarangelo to recruit young patients from Children National Health System (site-PI: Mike Keller). The CSI protocol is the first protocol to be formally submitted under the new reliance agreement, paving the way for future studies and opening up a referral source of very young research participants who cannot typically be seen at the CC.   II. DISCOVERY  A. New gene disease discovery. The CSI is contributing to at least three ongoing projects with DIR investigators characterizing new gene-disease relationships. There is a significant opportunity to further exploit this data for discovery.  B. Collaboration with NHGRI on UTR and mosaic variants.  We have an ongoing collaboration with NHGRI to evaluate and develop more effective approaches for detection of clinically relevant variants in the untranslated regions of genes and clinically relevant mosaic variation.  C. Collaboration with multiple groups on computable phenotypic data. The CSI has built a highly valuable dataset of genomic data associated with detailed clinical records, manually coded with relevant phenotypic terms.  The integration of computable phenotypic and laboratory data into genomics is an area of great interest across the field.  We are working with NLM for more efficient text mining approaches, the NIAID epidemiological unit on phenotypic modeling for machine learning in large datasets from other health centers, and other extramural collaborators on tailoring phenotypic data analysis approaches for Mendelian disorders of the immune system.  D. Collaboration with The Genotype Ascertainment Cohort (TGAC), hosted by NHGRI. The CSI seeks to model genomic data sharing approaches that optimize both patient confidentiality and research productivity. In addition to the required deposition into dbGAP, CSI contributes data to TGAC. Exome and genome data from patients in contributing cohorts, including CSI, are available to view in aggregate by DIR researchers. This project is designed to enable further study of individuals via genomic ascertainment without prior knowledge of phenotype.  CSI staff has also participated in the review board for patient access requests.   III. SOCIAL AND BEHAVIORAL RESEARCH, POLICY  A. Negative results comprehension. The CSI is studying patient perceptions and understanding of the inconclusive negative exome results released in the medical record without specific counseling. The objective of this substudy is to use survey and interview data to better understand how well patients understand their negative exome sequencing results and to identify patient characteristics associated with poor understanding. Modification of our policy or specific educational interventions may follow if needed.  B. Secondary findings follow up collaboration. The CSI is collaboratively studying the clinical follow up of secondary findings with researchers at NHGRI.  There is some evidence that a minority of participants do not seek recommended follow up care for the potentially life threatening disorders which are returned on CSI as secondary findings.  The objective of this substudy is to better understand patient cognitive, emotional, and behavioral reactions to receiving a secondary finding, over time, including the motivators and barriers to clinical follow up.  C. Participating in facilitated discussions about policies on genetic research in humans at NIAID DIR. These discussions covered issues about quality of data, quality of analysis, and return of results, primarily focusing on the latter. n/a",Central Sequencing Initiative,10274166,ZICAI001244,"['Address', 'Agreement', 'Area', 'Attention', 'Automation', 'Behavioral', 'Behavioral Research', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Complex', 'Comprehension', 'Confidentiality of Patient Information', 'Consent', 'Consult', 'Consultations', 'Counseling', 'Data', 'Data Analyses', 'Data Discovery', 'Databases', 'Deposition', 'Detection', 'Development', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Education', 'Educational Intervention', 'Emotional', 'Enrollment', 'Epidemiology', 'Evaluation', 'Extramural Activities', 'Feedback', 'Future', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Research', 'Genome', 'Genomics', 'Genotype', 'Health', 'Health system', 'Human', 'Immune System Diseases', 'Immune system', 'Individual', 'Infrastructure', 'Institutes', 'Interview', 'Knowledge', 'Laboratories', 'Language', 'Life', 'Machine Learning', 'Manuals', 'Medical', 'Medical Records', 'Medicine', 'Mendelian disorder', 'Minority', 'Mission', 'Modeling', 'Modification', 'Molecular', 'Molecular Diagnosis', 'Mosaicism', 'National Human Genome Research Institute', 'National Institute of Allergy and Infectious Disease', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Participant', 'Patients', 'Perception', 'Phenotype', 'Physicians', 'Policies', 'Process', 'Productivity', 'Protocols documentation', 'Publications', 'Reaction', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Robotics', 'Rotation', 'SNP array', 'Secure', 'Services', 'Site', 'Source', 'Specific qualifier value', 'Students', 'Surveys', 'Testing', 'Time', 'United States National Institutes of Health', 'Untranslated Regions', 'Variant', 'Visit', 'Work', 'clinical care', 'clinical center', 'clinical diagnostics', 'clinically relevant', 'clinically significant', 'cohort', 'computable phenotypes', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'exome', 'exome sequencing', 'follow-up', 'genetic counselor', 'genomic data', 'interest', 'large datasets', 'lectures', 'meetings', 'pediatric patients', 'phenotypic data', 'recruit', 'sample collection', 'social', 'text searching']",NIAID,NATIONAL INSTITUTE OF ALLERGY AND INFECTIOUS DISEASES,ZIC,2020,2768476,0.01852857429826889
"Single cell atlas as a roadmap for interpreting human genetic variation in complex disease Project Summary Genome wide association studies (GWAS) have successfully identified thousands of loci likely affecting human health. To translate these findings into therapeutic targets and disease treatments, we need to understand the cellular context and underlying biological mechanisms through which each disease associated variant disrupts function. Large scale, information rich datasets are being generated across multiple modalities including transcriptomics from single cell RNA-seq studies, traits and phenotypes from the UK Biobank and germline genetic variation from exome sequencing studies. Here, we propose to develop methods to integrate these amazing resources towards understanding the identifying biological and cellular mechanisms that are leading to disease. The objectives will be accomplished with the following specific aims: 1) Integrate population scale biological datasets including UK Biobank and single cell transcriptomics data to construct gene modules with the goal to recapitulate biological pathways. 2) Develop a statistical framework to measure mutational burden across each of the cell type specific gene modules. Together, this research proposal will increase the power in interpreting human genetic variation and help better understand the mechanism through which they act. These methods are being developed around an IBD dataset and will derive substantial molecular information about the mechanisms driving IBD. The lessons and methodological advances from this work will be directly applicable in many complex disease contexts. Project Narrative Genome wide association studies are highly successful identifying thousands of disease-associated loci but fall short at 1) pinpointing the biological mechanisms through which the variants effect disease and 2) capturing the effects of rare variants which may be having larger effect on disease outcomes. This research proposal details plans to integrate high-throughput single cell transcriptomics, population scale biobank datasets and exome sequencing from large disease cohorts to learn a prior on which genes are likely working together in which cell types and consequently improve the statistical power in interpreting rare human genetic variation. Our work will create foundational methods that can be applied broadly across many disease contexts.",Single cell atlas as a roadmap for interpreting human genetic variation in complex disease,10068981,F32HG011434,"['Affect', 'Amaze', 'Area', 'Asthma', 'Atlases', 'Automobile Driving', 'Biological', 'Cell physiology', 'Cells', 'Colon', 'Complex', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Outcome', 'Disease model', 'Foundations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Grouping', 'Health', 'Human', 'Human Genetics', 'Individual', 'Inflammation', 'Inflammatory Bowel Diseases', 'Learning', 'Link', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Modality', 'Molecular', 'Mutation', 'Non-Insulin-Dependent Diabetes Mellitus', 'Organ', 'Participant', 'Pathway interactions', 'Patient Care', 'Pattern', 'Phenotype', 'Physiology', 'Population', 'Research Proposals', 'Resources', 'Schizophrenia', 'Signal Pathway', 'Signal Transduction', 'Therapeutic', 'Thinking', 'Tissues', 'Translating', 'Variant', 'Work', 'biobank', 'burden of illness', 'causal variant', 'cell type', 'cohort', 'design', 'disease phenotype', 'disorder risk', 'endoplasmic reticulum stress', 'exome', 'exome sequencing', 'falls', 'genome wide association study', 'genomic locus', 'heterogenous data', 'improved', 'machine learning method', 'personalized medicine', 'phenotypic data', 'rare variant', 'response', 'single cell analysis', 'single cell mRNA sequencing', 'single-cell RNA sequencing', 'statistical and machine learning', 'therapeutic target', 'trait', 'transcriptomics', 'unsupervised learning']",NHGRI,"BROAD INSTITUTE, INC.",F32,2020,64926,-0.007576383464770685
"Unravelling genetic basis of comorbidity using EHR-linked biobank data Rapid progress in translational bioinformatics and clinical informatics for precision medicine has  provided many computing and informatics methodologies to provide better prediction, diagnosis and  treatment strategy as a clinical utility. In particular, high dimensional and large-scale  biomedical data sets, ranging from clinical data to ‘omics data, provide an unprecedented  opportunity for translating the newly found knowledge from biomedical big data analytics to  support clinical decisions. The complexity and scale of these big data sets hold great  promise, yet present substantial challenges. As one of important concerns for clinicians,  comorbidity is a well- documented phenomenon in medicine in which one or more medical conditions  exist and potentially interact with one another, thereby influencing the primary clinical  condition. Several studies show variability in the number of comorbid conditions that can  exist at one time, and patterns of disease presentation differ from one chronic condition to  another. Thus, there is a clear need to improve care for individuals with multiple  comorbidities, but doing so requires a much more detailed understanding of the trends of disease  associations than we currently possess. Previous studies have primarily focused on a  handful of specific comorbidities; investigating the underlying causes of broad disease  comorbidity across the human diseasome has been challenging. Fortunately, in the past  decade, comprehensive collections of disease diagnosis data have become available, primarily  in the form of data from electronic health records (EHRs). Retrospectively, we can use a patient’s  health history to identify comorbidities and apply a data-driven approach to studying disease  comorbidity patterns that considers all possible disease comorbidities. In particular, developing  computing and modeling of large-scale data that integrates newly defined comorbidity patterns with  genomics will hold great potential for uncovering molecular mechanisms of disease. Primarily, we  will elucidate the underlying genetic and non-genetic factors that influence disease comorbidity.  We will apply two orthogonal approaches to identify comorbidities: 1) deriving from disease  co-occurrence using EHR data alone, and 2) deriving from pleiotropic genetic associations using the  EHR-linked biobank dataset. Network-based approaches have the potential to uncover unexpected  relationships between diseases. One of the most significant advantages of our proposal is the  linking of a single-source EHR to genomic data; this provides the opportunity to  revisit individual-level genotype and phenotype data for the design of more targeted  studies and to ask more specific questions. Additionally, our results can be used to develop  a novel comorbidity risk score that combines both clinical data and genetic effects, which might  constitute a new tool for clinical prevention and monitoring. These goals are very much in keeping  with today’s climate of precision medicine, where treatment and prevention are ideally designed to  consider an individual patient’s variability in genetics, lifestyle, and environmental exposures. There is a clear need to improve care for individuals with multiple comorbidities, but this  requires a much more detailed understanding of the trends of disease associations than we  currently possess. An EHR-linked biobank data provides a unique opportunity to investigate  cross-phenotypes associations, and it might broaden the understanding of genetic architecture  that exists between diagnoses, genes, and pleiotropy. In this proposal, we will construct a  disease comorbidity map of 2.1 million patients using longitudinal EHRs in Penn Medicine (Aim 1),  construct a disease-gene map derived from phenome-wide association study using Penn Medicine  Biobank Participants (Aim 2), and develop a novel scoring system using graph-based  machine learning and predict comorbidity risk scores (CRS) for a given disease (Aim 3).",Unravelling genetic basis of comorbidity using EHR-linked biobank data,10034691,R01GM138597,"['Algorithms', 'Big Data', 'Big Data Methods', 'Bioinformatics', 'Caring', 'Chronic', 'Climate', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Collection', 'Communities', 'Complex', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environmental Exposure', 'Etiology', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Graph', 'Health', 'Human', 'Individual', 'Informatics', 'International Classification of Disease Codes', 'Knowledge', 'Life Style', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Genetics', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Network-based', 'Participant', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Prevention', 'Recording of previous events', 'Research', 'Research Personnel', 'Risk', 'Scoring Method', 'Source', 'System', 'Time', 'Translating', 'Variant', 'Veterans', 'base', 'big biomedical data', 'biobank', 'clinical decision support', 'cohort', 'comorbidity', 'design', 'disease diagnosis', 'electronic data', 'genetic architecture', 'genetic association', 'genetic information', 'genetic variant', 'genomic data', 'high dimensionality', 'human disease', 'improved', 'individual patient', 'interactive tool', 'large scale data', 'non-genetic', 'novel', 'patient variability', 'phenome', 'phenotypic data', 'pleiotropism', 'precision medicine', 'programs', 'rare variant', 'supervised learning', 'tool', 'treatment strategy', 'trend']",NIGMS,UNIVERSITY OF PENNSYLVANIA,R01,2020,486125,-0.005752558810104617
"A Proteogenomic Search Engine for Direct Mass Spectrometric Identification of Variant Proteins Using Genomic Data Project Summary / Abstract Mass spectrometry-based proteomics, used in conjunction with genomics, has been called proteogenomics. Recent exponential increases in variant identification by next-generation sequencing (NGS) is redefining the concept of the human genome/proteome. Our project is the commercialization of a first-to-market proteomic database search engine for mass spectrometry capable of directly reading NGS data for the identification of mutilations from individual samples or from curated resources. Such an offering has the potential to bring together these two fields, enabling validation of mutations at the protein-level. Mutated proteins have been shown to make ideal targets for drug therapies and diagnostics in cancer. Our software will provide an intuitive user experience, approachable by scientists who may not be expert both proteomic and genomic data analysis. Since the search engine is guided by prior knowledge, performance exceeds current practice. The software will come complete with a full array of post-processing validation, and visualization tools. Project Narrative The detection of protein variants, which differ from those predicted from the reference human genome sequence, can make ideal candidates for the development of targeted treatments and diagnostics for many clinical conditions such as cancer. This project proposes the development a first-of-its-kind “proteogenomics” search engine for the identification of protein variants by mass spectrometry, making direct use of genomic data and ever-growing public and private databases of genetic variation.",A Proteogenomic Search Engine for Direct Mass Spectrometric Identification of Variant Proteins Using Genomic Data,10082114,R44CA217432,"['Agreement', 'Cancer Vaccines', 'Clinical', 'Communities', 'Complement', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Databases', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Environment', 'Future', 'Gefitinib', 'Genetic Databases', 'Genetic Diseases', 'Genetic Variation', 'Genomics', 'Goals', 'Guidelines', 'Heterozygote', 'Human Genome', 'Individual', 'Informatics', 'Intuition', 'Ions', 'Isomerism', 'Knowledge', 'Licensing', 'Malignant Neoplasms', 'Marketing', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Modification', 'Monitor', 'Mutate', 'Mutation', 'Mutation Detection', 'Pathway interactions', 'Peptides', 'Performance', 'Phase', 'Post Translational Modification Analysis', 'Privatization', 'Probability', 'Protein Databases', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Readability', 'Reading', 'Research', 'Resolution', 'Resources', 'Risk', 'Running', 'Sales', 'Sampling', 'Scientist', 'Services', 'Small Business Innovation Research Grant', 'Testing', 'Transcript', 'Validation', 'Variant', 'Visualization', 'Visualization software', 'Work', 'base', 'commercialization', 'cost', 'experience', 'genomic data', 'graphical user interface', 'human reference genome', 'improved', 'next generation sequencing', 'open source', 'protein expression', 'proteogenomics', 'prototype', 'repository', 'scaffold', 'search engine', 'support vector machine', 'targeted treatment', 'tool', 'transcriptome sequencing']",NCI,"SPECTRAGEN INFORMATICS, LLC",R44,2020,529294,-0.028965596329133318
"Genetic Privacy and Identity in Community Settings - GetPreCiSe Genetic Privacy and Identity in Community Settings (GetPreCiSe), is an NHGRI Center of Excellence in ELSI Research (CEER) that, in its first four years, established an environment for multi-disciplinary study that produced innovative ways of studying genetic privacy and identity. Specifically, the center 1) parsed the concept of genetic privacy into its often conflated constituent components, including: the “right to be let alone,” control and governance of data, and concerns about downstream uses of data; 2) documented and critically assessed the privacy practices of direct to consumer genetic testing (DTC-GT) companies; 3) examined how and why people trade off personal privacy for other social goods and services; 4) used new techniques to explore how film, television, and social media reflect and affect public perceptions of genetic privacy; and 5) refined understanding of the risk that people will be re-identified from their genomic information. During this time, many developments raised new issues of privacy and identity for genetics. First is the growth of DTC-GT, which generates genetic information used to trace ancestry, acquire health information, find relatives, uncover parentage, and pursue law enforcement investigations, among other activities. Second, laws and regulations governing data privacy and security, particularly with respect to genomics, are changing rapidly in the U.S. and abroad. These often conflict and present new challenges as genomic data move across state and international borders. Third, the creation of ever larger cohorts, such as the NIH’s All of Us Research Program, raises further dilemmas because some or all of the genomic and other data participants provide will be made available to investigators working in a variety of settings and subject to different regulatory regimes. Moreover, participants in these studies may receive research results, which could be deposited in their electronic health records, making this data subject to clinical regulation and compelling action by clinical providers who may not have the knowledge or infrastructure to respond. Thus, as our understanding of genomics increases, so, too, do its multifarious roles and implications for individuals, families, and society evolve. Given the evolving landscape, in its next four years GetPreCiSe will address three complementary specific aims: 1) Apply multimodal methods to characterize how social practices affect, and are affected by, evolving notions of genetic privacy and identity and increased availability of data, 2) Characterize how emerging legal and regulatory frameworks influence genomic privacy and identity in the US and abroad, and 3) Engineer and evaluate new technologies and quantitative frameworks that have potential to intrude on, but also protect, genetic privacy and identity. Recognizing that genetic data processing opportunities and threats are evolving, GetPreCiSe is designed to be a multi-disciplinary center, focused on training the next generation of ELSI researchers, with sufficient agility to respond to emerging issues. We anticipate these aims will need to be refined, and possibly pivoted, over the next four years and so stand ready to seed new investigations into emerging issues and compose new teams for investigation as needed. The incorporation of genetics and genomics into medical care and the public domain raises new challenges for how we understand privacy and identity, concepts that have long been closely linked in American discourse. The Genetic Privacy and Identity in Community Settings (GetPreCiSe), an NHGRI Center of Excellence in Ethical, Legal, and Social Implications Research (CEER) will 1) characterize how social practices and genetic data access affect notions of genetic privacy and identity, 2) assess the impact of emerging laws and regulatory frameworks in the US and abroad, and 3) gauge how new technologies compromise but also uphold protections.",Genetic Privacy and Identity in Community Settings - GetPreCiSe,9982627,RM1HG009034,"['Address', 'Advertising', 'Affect', 'Age', 'All of Us Research Program', 'American', 'Area', 'Artificial Intelligence', 'Arts', 'Behavior', 'Big Data', 'CCL4 gene', 'California', 'Caring', 'Clinical', 'Clinical Research', 'Communities', 'Conceptions', 'Conflict (Psychology)', 'Data', 'Data Collection', 'Data Protection', 'Data Security', 'Deposition', 'Development', 'Electronic Health Record', 'Engineering', 'Environment', 'European Union', 'Family', 'Film', 'Gender', 'Genetic', 'Genetic Identity', 'Genetic Models', 'Genetic Privacy', 'Genetic study', 'Genomics', 'Growth', 'Health', 'Imagination', 'Individual', 'Infrastructure', 'International', 'Internet', 'Investigation', 'Knowledge', 'Law Enforcement', 'Laws', 'Legal', 'Link', 'Literature', 'Medical', 'Methods', 'Modeling', 'National Human Genome Research Institute', 'Newspapers', 'Participant', 'Perception', 'Policies', 'Privacy', 'Provider', 'Public Domains', 'Publications', 'Race', 'Radio', 'Regulation', 'Research', 'Research Personnel', 'Risk', 'Role', 'Seeds', 'Services', 'Social Network', 'Social Sciences', 'Societies', 'Technology', 'Television', 'Testing', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Use of New Techniques', 'Visual', 'Work', 'base', 'behavior influence', 'behavioral economics', 'blockchain', 'cohort', 'community setting', 'computerized data processing', 'data access', 'data privacy', 'data sharing', 'design', 'ethical legal social implication', 'genetic information', 'genetic testing', 'genomic data', 'innovation', 'insight', 'interest', 'legal implication', 'minimal risk', 'multidisciplinary', 'multimodality', 'new technology', 'news', 'next generation', 'sex', 'social', 'social media']",NHGRI,VANDERBILT UNIVERSITY MEDICAL CENTER,RM1,2020,1112351,0.011013942555858115
"Investigating the clinical ontologies of loss-of-function and gain-of-function human gene variants PROJECT SUMMARY/ABSTRACT This proposal is for an MD/PhD student’s individual pre-doctoral fellowship application. Joseph Park, the applicant under consideration, proposes a research training plan with the long-term goal of developing into an independent physician-scientist studying the genetic mechanisms underlying cardiometabolic and other complex diseases using computational, experimental, and translational approaches. Genome-wide association studies (GWAS) have successfully described the roles of common genetic variation on human diseases by analyzing large populations with shared disease traits, but the clinical ontologies of numerous genes remain incompletely described through these phenotype-based methodologies. Additionally, a fundamental problem of genetic association studies remains to be the difficulty of describing the functional consequences of disease- associated variants to their respective gene products (i.e. loss- vs. gain-of-function). The Penn Medicine Biobank, a healthcare system-based database of genotype, whole-exome sequencing, and electronic health record (EHR) data, allows for an unbiased, genotype-first approach to describing the relationships between dysfunctional genes and human disease traits captured in the clinical setting through phenome-wide association studies (PheWAS). Through gene-burden PheWAS tests, the proposed study aims to characterize the clinical manifestations of disease caused by rare, loss-of-function mutations in each gene on a genome- wide scale. Our analyses will enable clinicians to more effectively identify genetic diseases among their patients in the clinical setting. Furthermore, in addition to our interrogation of loss-of-function mutations, our proposed project has the potential to define the roles of known gain-of-function mutations in human disease and identify novel gain-of-function variants relevant to disease, offering a direction for investigators to design follow-up experimental studies in the basic sciences as well as a platform promoting more efficient therapeutic discoveries. And importantly, while conducting the proposed study, Joseph will receive rigorous training in computational biology and statistical genetics during the funding period, promoting his maturation into a successful, independent physician-scientist thoroughly prepared for a clinical career involving the analysis of “omics” and “big data”. These goals will be accomplished through the extensive fellowship training plan jointly developed by him and his sponsor, Daniel Rader. Through the mentorship of numerous senior investigators, regular attendance at seminars, conferences, and other opportunities for presentation and interaction with renowned scientists at the University of Pennsylvania, and the collaborative research environment that the Rader laboratory and its physically surrounding organizations promote, Joseph is well-equipped to achieve his career goals through his guaranteed development during the proposed training. PROJECT NARRATIVE Genome-wide association studies (GWAS) have successfully described the roles of many human genes by analyzing large populations with shared traits, but these phenotype-based methodologies have incompletely described the clinical implications of numerous genes. I propose to address this knowledge gap by taking an unbiased, genotype-first approach to describing the relationships between dysfunctional genes and human disease traits through gene-burden phenome-wide association studies (PheWAS), essentially intersecting data from our healthcare system-based biobank database comprised of genotype data, whole-exome sequencing, and electronic health records (EHR). In addition to capturing the disease implications of rare, loss-of-function mutations on a genome-wide scale, my proposed project has the potential to define the roles of known and novel gain-of-function mutations in human disease, offering a direction for follow-up functional studies as well as a platform for more efficient therapeutic discoveries.",Investigating the clinical ontologies of loss-of-function and gain-of-function human gene variants,9916631,F30HG010442,"['Address', 'African American', 'Animal Model', 'Authorization documentation', 'Basic Science', 'Big Data', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computational Biology', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Electronic Health Record', 'Environment', 'Fellowship', 'Frequencies', 'Funding', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genotype', 'Goals', 'Grant', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Laboratories', 'Literature', 'Measurement', 'Medicine', 'Mentorship', 'Methodology', 'Methods', 'Mutation', 'Natural Language Processing', 'Ontology', 'Participant', 'Patients', 'Pennsylvania', 'Phenotype', 'Physicians', 'Play', 'Population', 'Population Analysis', 'Privatization', 'Recontacts', 'Records', 'Regression Analysis', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Scientist', 'Serum', 'Structure', 'Suggestion', 'Testing', 'Therapeutic', 'Tissue Model', 'Training', 'Universities', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'cardiometabolism', 'career', 'design', 'disease phenotype', 'doctoral student', 'exome sequencing', 'experimental study', 'follow-up', 'gain of function', 'gain of function mutation', 'gene discovery', 'gene product', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'human disease', 'human tissue', 'loss of function', 'loss of function mutation', 'medical schools', 'novel', 'phenome', 'pre-doctoral', 'precision medicine', 'programs', 'quantitative imaging', 'rare variant', 'recruit', 'symposium', 'text searching', 'tool', 'trait', 'translational approach']",NHGRI,UNIVERSITY OF PENNSYLVANIA,F30,2020,50520,0.018877154382286772
"Computational Methods for Next-Generation Comparative Genomics PROJECT SUMMARY Recent advances in regulatory genomics, especially 3D genome organization in cell nucleus, suggest that existing methods for cross-species comparisons are limited in their ability to fully understand the evolution of non-coding genome function. In particular, it is known that genomes are compartmentalized to distinct compartments in the nucleus such as nuclear lamina and nuclear speckles. Such nuclear compartmentalization is an essential feature of higher-order genome organization and is linked to various important genome functions such as DNA replication timing and transcription. Unfortunately, to date no study exists that directly compares nuclear compartmentalization between human and other mammals. In addition, there are no computational models available that consider the continuous nature of multiple features of nuclear compartmentalization and function, which is critical to integrate genome-wide functional genomic data and datasets that measure cytological distance to multiple compartments across species. In this project, we will develop novel algorithms and generate new datasets to directly address two key questions: (1) How to identify the evolutionary patterns of nuclear compartmentalization? (2) What types of sequence evolution may drive spatial localization changes across species? The proposed project represents the first endeavor in comparative genomics for nuclear compartmentalization. Our Specific Aims are: (1) Developing new probabilistic models for identifying evolutionary patterns of nuclear compartmentalization. (2) Identifying genome-wide evolutionary patterns of nuclear compartmentalization in primate species based on TSA-seq and Repli-seq. (3) Developing new algorithms to connect sequence features to nuclear compartmentalization through cross-species comparisons. Successful completion of these aims will result in novel computational tools and new datasets that will be highly valuable for the comparative genomics community. Integrating the new computational tools and unique datasets will provide invaluable insights into the relationship between sequence evolution and changes in nuclear genome organization in mammalian species. Therefore, the proposed research is expected to advance comparative genomics to a new frontier and provide new perspectives for studying human genome function PROJECT NARRATIVE The proposed research is relevant to public health because the outcome of the project is expected to enhance the analyses of nuclear genome organizations across primate species to better understand genome function and human biology. Thus, the proposed research is relevant to NIH’s mission that seeks to obtain fundamental knowledge that will help to improve human health.",Computational Methods for Next-Generation Comparative Genomics,9959498,R01HG007352,"['3-Dimensional', 'Address', 'Algorithms', 'CRISPR/Cas technology', 'Cell Nucleus', 'Cells', 'Communities', 'Complement', 'Computer Models', 'Computing Methodologies', 'Crete', 'Cytology', 'DNA Insertion Elements', 'DNA Replication Timing', 'Data Set', 'Development', 'Disease', 'Evolution', 'Genetic Transcription', 'Genome', 'Genomics', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Knowledge', 'Lamin Type B', 'Link', 'Machine Learning', 'Mammals', 'Maps', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular Profiling', 'Nature', 'Nuclear', 'Nuclear Lamina', 'Outcome', 'Pattern', 'Phenotype', 'Primates', 'Psyche structure', 'Public Health', 'Research', 'Signal Transduction', 'Statistical Models', 'Techniques', 'Time', 'Translating', 'United States National Institutes of Health', 'Untranslated RNA', 'Visualization', 'base', 'comparative genomics', 'computerized tools', 'frontier', 'functional genomics', 'genetic variant', 'genome-wide', 'genomic data', 'genomic locus', 'improved', 'insight', 'mental function', 'next generation', 'novel', 'predictive modeling']",NHGRI,CARNEGIE-MELLON UNIVERSITY,R01,2020,360268,-0.011948245291722058
"Automated, high-throughput identification of genetic structural variants for gene editing and undiagnosed genetic diseases screening ABSTRACT A simple method to comprehensively discover, characterize and identify structural variants arising from normal metabolic processes, as well as cell manipulations, would have great utility for gene editing, oncology, and rare disease research, among other applications. De Novo Directional Genomic Hybridization (dGH™) has been developed to efficiently screen thousands of cells for the presence of simple, complex, and heterogenous structural variants. In this project, Automated, High-Throughput Identification of Genetic Structural Variants for Gene Editing and Undiagnosed Genetic Diseases Screening, we propose K-Band™ dGH, an expanded dGH method. K-Band dGH is an in-situ hybridization method that utilizes high-density chromatid paints with bands of distinct spectra. A normal chromosome has a definitive pattern of bands, spectra and probe density. Structural variants are detected and identified via changes to the signal pattern. The proposed K-Band™ dGH method will provide the means for de novo discovery of balanced allelic translocations involving breakpoints at the same loci, inversions, and sister chromatid recombination and exchange events that are invisible to existing methods such as sequencing and aCGH. K-Band dGH will additionally characterize deletions, duplications, translocations, aneuploidy, polyploidy and more complex rearrangements. Structural variations cause a wide range of disorders, from rare diseases to cancers, and can be precise and definitive biomarkers. Also, because variations arise from the mis-repair of DNA double-strand breaks, unintended structural damage is an inevitable and potentially high-risk byproduct of genome editing. The potential of genome editing approaches such as CRISPR-Cas9 in the treatment of diseases is widely recognized and the realization of the promise of such therapeutic approaches will rely on accurate confirmation of the presence and absence of potentially risky structural variants. For these reasons, comprehensive detection and characterization of structural variations is a necessary step toward understanding, diagnosing and ultimately precisely treating genetic diseases. From a homogeneous or heterogenous population of cells, and in a single experiment, K-Band dGH will identify cells with a structurally normal phenotype, detect all classes of structural variants, and locate the breakpoints of all simple and complex structural variants in each cell. With a limit of detection below 5Kb, K-Band dGH is an ideal method for determining the outcomes of gene editing, discovering the causes of undiagnosed rare diseases, profiling genomic structural instability and variability, and discovering and validating previously unknown structural genetic drivers of disease. PROJECT NARRATIVE Modern genomics, driven by the demands of personalized medicine, needs higher throughput, higher integrity, and improved resolution to enable the discovery of new disease drivers and in the development of safer gene therapies. Rapid, accurate, efficient characterization of structural variants and their associated risks is critical to the discovery of potential therapeutic avenues for undiagnosed and rare diseases, and to the development of engineered cellular therapies, including stem cells, CAR-T and other gene therapies leveraging gene-editing tools such as CRISPR. K-Band™ dGH, proposed in Automated, High-Throughput Identification of Genetic Structural Variants for Gene Editing and Undiagnosed Genetic Diseases Screening, will enable single-cell, single-experiment identification of clinically important structural variants that cannot be discovered or identified by NGS or other available methods with broad applicability in genome engineering R&D, target discovery and personalized therapy development.","Automated, high-throughput identification of genetic structural variants for gene editing and undiagnosed genetic diseases screening",10080433,R44HG011442,"['Algorithms', 'Alleles', 'Aneuploidy', 'Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'Biological Markers', 'Biomedical Research', 'CRISPR screen', 'CRISPR therapeutics', 'CRISPR/Cas technology', 'Cell Line', 'Cell Therapy', 'Cells', 'Chromatids', 'Chromosomal Rearrangement', 'Chromosome Structures', 'Chromosomes', 'Clinical', 'Clinical assessments', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Color', 'Complex', 'DNA', 'DNA Double Strand Break', 'DNA Repair', 'DNA Sequence', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Double Strand Break Repair', 'Event', 'Exposure to', 'Fingerprint', 'Funding', 'Genes', 'Genetic Diseases', 'Genetic Recombination', 'Genetic Structures', 'Genome engineering', 'Genomic Hybridizations', 'Genomics', 'Goals', 'Government', 'Human', 'Image', 'Image Analysis', 'In Situ Hybridization', 'Individual', 'Knowledge', 'Location', 'Malignant Neoplasms', 'Maps', 'Marketing', 'Measurement', 'Measures', 'Medical', 'Metabolism', 'Methods', 'Modernization', 'Oncology', 'Outcome', 'Paint', 'Pattern', 'Pattern Recognition', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Polyploidy', 'Population', 'Prevalence', 'Radiation', 'Rare Diseases', 'Reciprocal Translocation', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Sampling', 'Signal Transduction', 'Sister Chromatid', 'Small Business Innovation Research Grant', 'Solid', 'Structure', 'System', 'Technology', 'Testing', 'Therapeutic', 'Validation', 'Variant', 'Work', 'automated image analysis', 'base', 'cellular engineering', 'clinically relevant', 'commercial application', 'comparative genomic hybridization', 'density', 'experimental study', 'fluorophore', 'gene therapy', 'genetic variant', 'genome editing', 'genomic profiles', 'genotoxicity', 'high risk', 'improved', 'intelligent algorithm', 'new therapeutic target', 'personalized medicine', 'reconstruction', 'research and development', 'screening', 'stem cells', 'structural genomics', 'technological innovation', 'therapeutic gene', 'therapeutic target', 'therapy development', 'tool', 'whole genome']",NHGRI,"KROMATID, INC.",R44,2020,1088162,0.013444718318065579
"Functional Annotation of Natural and Disease Variants in Tryosine Kinases ﻿    DESCRIPTION (provided by applicant): Protein tyrosine kinases are dynamic molecular switches that toggle between a catalytically ""on"" and ""off"" state to turn on and off signals responsible for cell growth and survival. While the tyrosine kinase switch is tightly regulated by  diverse array of structural mechanisms in normal states, in many disease states, the switch is permanently turned on or off due, in part, to mutations in the tyrosine kinase domain. Although genome sequencing studies have revealed the mutational patterns of tyrosine kinases from many different disease types, understanding the structural and functional impact of these mutations is a challenge because many recurrent mutations occur far from the active site (distal mutations) and the residue networks that contribute to the complex modes of tyrosine kinase allosteric regulation are not fully understood. Our long term goal is to understand the relationships connecting sequence, structure, function, regulation and disease in protein kinases using a combination of computational and experimental approaches. Our objective in this proposal, which is the next logical step toward attainment of our long-term goal, is to delineate the residue interaction networks that contribute to the unique modes of allosteric regulation in tyrosine kinases, and to develop a computational framework for predicting mutation impact using the evolutionary and allosteric properties encoded in three dimensional structures. The central hypothesis is that distal mutations alter evolutionarily conserved allosteric networks in tyrosine kinases, and delineating the allosteric networks unique to tyrosine kinases will provide context for predicting and testing disease mutation impact. The specific aims are: * To identify and characterize natural sequence and structural variants associated with tight  allosteric control of tyrosine kinase activity * To develop a computational framework for predicting mutation impact on kinase activation and to  experimentally validate computational predictions using selected receptor tyrosine kinases as  model systems Successful completion of these aims is expected to reveal novel activating mutations in putative allosteric sites in the tyrosine kinase domain, and pinpoint key residues and interactions for functional studies. These outcomes, in turn, are expected to have major biomedical impact by accelerating the functional characterization of the mutated tyrosine kinome, which is emerging as a major target for personalized medicine. Finally, by providing detailed mechanistic annotation of mutations identified in genome sequencing studies, this proposal will address a fundamental NIH roadmap problem in translational medicine of converting genomic discoveries into therapeutic strategies. PUBLIC HEALTH RELEVANCE: Protein tyrosine kinases are a biomedically important class of proteins that are abnormally regulated in many human diseases including cancer, diabetes, and inflammatory disorders, to name but a few. They have been the focus of many drug discovery efforts and genome sequencing studies because of the therapeutic potential of targeting mutated tyrosine kinases for personalized therapy. By providing functional annotation of natural and disease mutations in tyrosine kinases, the proposed studies will accelerate the targeting of mutated tyrosine kinases for drug discovery and personalized therapy.",Functional Annotation of Natural and Disease Variants in Tryosine Kinases,10145865,R01GM114409,"['Active Sites', 'Address', 'Allosteric Regulation', 'Allosteric Site', 'Antineoplastic Agents', 'Binding', 'Biological Assay', 'Biological Models', 'Cell Survival', 'Communities', 'Complex', 'Diabetes Mellitus', 'Disease', 'Distal', 'Drug Binding Site', 'Drug resistance', 'Foundations', 'Genes', 'Genomics', 'Goals', 'Human Genome', 'In Vitro', 'Inflammatory', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Names', 'Ontology', 'Organism', 'Outcome', 'Pathogenicity', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Property', 'Protein Kinase', 'Protein Tyrosine Kinase', 'Protein-Serine-Threonine Kinases', 'Proteins', 'Publishing', 'Receptor Protein-Tyrosine Kinases', 'Recurrence', 'Regulation', 'Signal Transduction', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Tyrosine', 'Tyrosine Kinase Domain', 'United States National Institutes of Health', 'Variant', 'base', 'cell growth', 'computer framework', 'drug discovery', 'genome sequencing', 'human disease', 'improved', 'insight', 'learning classifier', 'molecular dynamics', 'mutant', 'nonsynonymous mutation', 'novel', 'personalized medicine', 'predictive test', 'public health relevance', 'three dimensional structure', 'translational medicine']",NIGMS,UNIVERSITY OF GEORGIA,R01,2020,9815,-0.01868828976759812
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,10260680,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,177000,0.0037676289542466195
"Biomedical Computing and Informatics Strategies for Infectious Disease Research ﻿    DESCRIPTION (provided by applicant): An important goal of infectious disease research is to develop genetic predictors of susceptibility. Our success in this endeavor will depend critically on the informatics methods and software that are available for making sense of high-dimensional genetic and genomic data. The goal of this research program is to develop, evaluate, distribute and support new and novel biomedical computing algorithms and open-source software for identifying combinations of genetic predictors of clinically important infectious disease outcomes. This application will target the growing body of rare genetic variants identified by high-throughput DNA sequencing. Our clinical application will focus on the prediction of antiretroviral response in clinical trials for HIV/AIDS. We propose here a highly innovative Hierarchical Rare Variant Collapsing Machine (HRVCM) algorithm for identifying and collapsing combinations of rare variants across gene regions (AIM 1). We will then integrate these new collapsed HRVCM variables into our popular Multifactor Dimensionality Reduction (MDR) method that will assess them in combination with common single-nucleotide polymorphisms (SNPs) from genome-wide association studies or GWAS (AIM 2). Our novel HRVCM-MDR approach will, for the first time, make it possible to assess non-additive interactions among sets of rare and common variants simultaneously in genetic studies of infectious diseases. We will apply these new and novel methods to approximately 13 million rare and common variants from nearly 3000 subjects that participated in an AIDS Clinical Trials Group (ACTG) study to evaluate risk for virologic failure with efavirenz-containing antiretroviral therapy (ART) regimens (AIM 3). Finally, we will release all methods as open source to the biomedical research community through our freely available MDR software package (AIM 4). PUBLIC HEALTH RELEVANCE: The overall goal of this application is to develop innovative new computational methods for the genetic analysis of infectious diseases. We will focus on the development of methods that are able to detect synergistic effects of multiple genetic variants regardless of whether they are rare of common in human populations. We will apply these methods to the study of HIV/AIDS vaccination response.",Biomedical Computing and Informatics Strategies for Infectious Disease Research,9869806,R01AI116794,"['AIDS clinical trial group', 'AIDS/HIV problem', 'Algorithmic Analysis', 'Algorithms', 'Anti-Retroviral Agents', 'Bioinformatics', 'Biomedical Computing', 'Biomedical Research', 'Clinical Trials', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Dimensions', 'Disease Outcome', 'Disease susceptibility', 'Failure', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Variation', 'Genetic study', 'Genome', 'Genomic Segment', 'Goals', 'Graph', 'High-Throughput DNA Sequencing', 'Human', 'Infectious Diseases Research', 'Informatics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Population', 'Predisposition', 'Regimen', 'Research', 'Risk', 'Single Nucleotide Polymorphism', 'Statistical Data Interpretation', 'Time', 'Vaccination', 'Variant', 'antiretroviral therapy', 'base', 'biomedical informatics', 'clinical application', 'clinical predictors', 'design', 'efavirenz', 'gene interaction', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic data', 'high dimensionality', 'innovation', 'method development', 'novel', 'open source', 'programs', 'public health relevance', 'rare variant', 'response', 'simulation', 'success', 'virology']",NIAID,UNIVERSITY OF PENNSYLVANIA,R01,2020,463248,0.05388442562430904
"A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions PROJECT SUMMARY Cancer genomes typically harbor a substantial number of somatic mutations. Relatively few driver mutations actually alter the function of proteins in tumor cells, whereas most mutations are considered to be functionally neutral passenger mutations. Over the past decade, the search for cancer driver mutations has focused on coding regions and several mutational significance algorithms have been developed for coding mutations. The contribution of mutations in noncoding regulatory regions to tumor formation largely remains unknown and current mutational significance algorithms are not designed to detect driver mutations in noncoding regions, due to biological differences between coding and noncoding mutations. The emerging availability of large whole- genome sequencing datasets (e.g. PCAWG and HMF datasets) creates an ample opportunity to develop new mutational significance algorithms that are particularly designed for the interpretation of noncoding regions. Recently, we have developed a new statistical approach that identifies driver mutations in coding regions based on the nucleotide context. Critically, consideration of the nucleotide context around mutations does not require prior knowledge for functional consequences associated with these mutations. Hence, we hypothesize that generalizing our nucleotide context model to noncoding regions will uncover novel noncoding driver mutations that cannot be detected using the mutational significance approaches currently available. For this purpose, we will develop a statistical framework that incorporates the biological differences between coding and noncoding mutations and that is specifically designed to detect driver mutations in noncoding regions. Specifically, we will consider the context-dependent distribution of passenger mutations, modeling of the background mutation rate, accurately partition the background mutation rate, model the sequence composition of the reference genome, and account for coverage fluctuation. We will then combine these statistical components by computing an independent product of their underlying probabilities. We will derive a significance p-value using a Monte-Carlo simulation approach, and use FDR for multiple hypothesis test correction. This strategy will allow us to accurately estimate the significance of somatic mutations in noncoding genomic regions. We will next apply this statistical framework to whole-genome sequencing data of 5,523 tumor patients, thereby deriving a comprehensive list of candidate driver mutations in noncoding regions. Finally, we will investigate whether noncoding mutations are overrepresented in transcription factor binding sites, regulate gene expression levels, induce alternative splicing, or affect epigenomic states. Upon the completion of this project, we will have developed and applied a statistical framework for discovery of significant somatic mutations in noncoding regions, and defined the mutational landscape of the non-coding cancer genome. All aspects of the methods developed and applied in this project will be made open source and developed in an online platform. PROJECT NARRATIVE While coding cancer driver mutations have been characterized in detail over the past decade, the contribution of noncoding mutations to tumor formation remains - apart from few examples (e.g. mutations in TERT promoters) - largely unknown. Recently, large-scale whole-genome sequencing datasets have been made available, but a major bottleneck for the biological and clinical interpretation of these cancer whole-genome cohorts is the lack of statistical models that identify driver mutations in noncoding regions. We developed a new statistical approach that characterizes driver mutations based on their surrounding nucleotide context in coding regions, and herein we propose a concrete plan to generalize our computational model to noncoding regions, apply our model to aggregated whole-genome sequencing data of 5,523 tumor patients (PCAWG, HMF datasets), and define the noncoding driver and passenger mutational landscape for biological discovery and focused clinical application.",A statistical framework to systematically characterize cancer driver mutations in noncoding genomic regions,9957082,R21CA242861,"['Address', 'Affect', 'Algorithms', 'Alternative Splicing', 'Attention', 'Binding Sites', 'Biological', 'Biological Process', 'Biology', 'Clinical', 'Code', 'Communities', 'Computational Biology', 'Computer Models', 'Data', 'Data Set', 'Development', 'Gene Expression', 'Gene Expression Regulation', 'Genomic Segment', 'Immunotherapy', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Mediating', 'Methods', 'Microsatellite Instability', 'Modeling', 'Monte Carlo Method', 'Mutation', 'Nucleic Acid Regulatory Sequences', 'Nucleotides', 'Outcome', 'Patients', 'Pattern', 'Play', 'Positioning Attribute', 'Probability', 'Process', 'Role', 'Somatic Mutation', 'Statistical Models', 'Stratification', 'Testing', 'The Cancer Genome Atlas', 'Untranslated RNA', 'base', 'cancer genome', 'cancer immunotherapy', 'checkpoint therapy', 'clinical application', 'clinical effect', 'cohort', 'design', 'driver mutation', 'epigenomics', 'exome sequencing', 'genome sequencing', 'genome-wide', 'immune checkpoint blockade', 'immunogenicity', 'large datasets', 'malignant breast neoplasm', 'melanoma', 'mutant', 'neoantigens', 'neoplastic cell', 'novel', 'open source', 'predicting response', 'promoter', 'protein function', 'reference genome', 'response', 'targeted treatment', 'transcription factor', 'tumor', 'whole genome']",NCI,DANA-FARBER CANCER INST,R21,2020,193576,0.0037676289542466195
"Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation Project Summary/Abstract: With the surge of large genomics data, there is an immense increase in the breadth and depth of different omics datasets and an increasing importance in the topic of privacy of individuals in genomic data science. Detailed genetic and environmental characterization of diseases and conditions relies on the large-scale mining of functional genomics data; hence, there is great desire to share data as broadly as possible. However, there is a scarcity of privacy studies focused on such data. A key first step in reducing private information leakage is to measure the amount of information leakage in functional genomics data, particularly in different data file types. To this end, we propose to to derive information-theoretic measures for private information leakage in different data types from functional genomics data. We will also develop various file formats to reduce this leakage during sharing. We will approach the privacy analysis under three aims. First, we will develop statistical metrics that can be used to quantify the sensitive information leakage from raw reads. We will systematically analyze how linking attacks can be instantiated using various genotyping methods such as single nucleotide variant and structural variant calling from raw reads, signal profiles, Hi-C interaction matrices, and gene expression matrices. Second, we will study different algorithms to implement privacy-preserving transformations to the functional genomics data in various forms. Particularly, we will create privacy-preserving file formats for raw sequence alignment maps, signal track files, three-dimensional interaction matrices, and gene expression quantification matrices that contain information from multiple individuals. This will allow us to study the sources of sensitive information leakages other than raw reads, for example signal profiles, splicing and isoform transcription, and abnormal three-dimensional genomic interactions. Third, we will investigate the reads that can be mapped to the microbiome in the raw human functional genomics datasets. We will use inferred microbial information to characterize private information about individuals, and then combine the microbial information with the information from human mapped reads to increase the re-identification accuracy in the linking attacks described in the second aim. We will use the tools to quantify the sensitive information and privacy-preserving file formats in the available datasets from large sequencing projects, such as the ENCODE, The Cancer Genome Atlas, 1,000 Genomes, gEUVADIS, and Genotype-Tissue Expression projects. Project Narrative: Sharing large-scale functional genomics data is critical for scientific discovery, but comes with important privacy concerns related to the possible misuse of such data. This proposal will quantify and manage the rieslkasted to releasing functional genomics datasets, based on integrating inferred genotypes from the raw sequence files, signal tracks, and microbiome mapped sequences. Finally, we will develop file formats, statistical methodologies, and related software for anonymization of functional genomics data that enable open sharing.",Enhancing open data sharing for functional genomics experiments: Measures to quantify genomic information leakage and file formats for privacy preservation,9970939,R01HG010749,"['3-Dimensional', 'Address', 'Algorithms', 'Assessment tool', 'Biology', 'ChIP-seq', 'Code', 'Computer software', 'Consent', 'DNA sequencing', 'Data', 'Data Files', 'Data Science', 'Data Set', 'Databases', 'Diet', 'Disease', 'Environment', 'Equilibrium', 'Extravasation', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Glean', 'Human', 'Individual', 'Institutes', 'Laws', 'Learning', 'Letters', 'Life Style', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Mining', 'Motivation', 'Participant', 'Patients', 'Phenotype', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Protein Isoforms', 'Protocols documentation', 'Provider', 'Pythons', 'Quantitative Trait Loci', 'RNA Splicing', 'Research Personnel', 'Risk', 'Risk Assessment', 'Sampling', 'Sequence Alignment', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Smoker', 'Source', 'Structure', 'Techniques', 'The Cancer Genome Atlas', 'Tissues', 'Variant', 'base', 'clinically relevant', 'computerized data processing', 'data mining', 'data sharing', 'experimental study', 'file format', 'functional genomics', 'genome sequencing', 'genomic data', 'human tissue', 'interest', 'large datasets', 'microbial', 'microbiome', 'open data', 'privacy preservation', 'social', 'tool', 'transcriptome sequencing']",NHGRI,YALE UNIVERSITY,R01,2020,523409,-0.00543839531210512
"Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases ﻿    DESCRIPTION (provided by applicant) Over the past 10 years human genetics studies made unprecedented numbers of discoveries relating genome variation to common diseases. While it is unquestionably true that we have learned substantially from the discoveries made to date, we must also acknowledge that with respect to the identification and characterization of the genome variation affecting risk of common human diseases - those accounting for the overwhelming majority of public health care expenditures - our discoveries have not generated nearly the knowledge of disease etiology that we would have expected given the sheer number of these discoveries. The combination of these observations coupled with the dramatic reduction in the cost of sequencing is driving the case for moving to whole genome sequencing studies for common disease. We have focused our application on three critical challenges for methods development and analysis of whole genome sequence data. While there has been substantial progress in methods development for analysis of exome sequencing, with gene-based tests that are relatively robust to the direction of effects of rare coding variants as well as the proportionof the gene's rare variants contributing to phenotype, it is clear that methods integrating the analysis of common and rare variation as well as functional genomics data will be essential for appropriate analysis of whole genome sequence data. Thus, we propose in Specific Aim 1 to develop novel methods, software and analysis pipelines for integrated analysis of common and rare variants for the analysis of whole genome sequence on 50,000- 100,000 individuals for any given common disease, and in Specific Aim 2 to develop and apply novel approaches for prioritizing results from these large-scale sequencing studies using BioVU, the 200,000 member biobank at Vanderbilt that is associated with 30 years of high quality electronic health records, and in Specific Aim 3 to develop queriable results databases and a comprehensive web portal to serve results of our studies on the sequence data for both the internal sequencing community and for the broader scientific community. PUBLIC HEALTH RELEVANCE Large-scale whole genome sequencing studies are being carried out to understand the genetic architecture of human complex diseases. It remains challenging to decipher the genetic mechanisms of disease etiology. In this application we aim to develop a suite of statistical and computational methods to identify genes and variants associated with complex disease and use BioVU, a DNA BioBank linked to electronic health records, to validate and investigate genetic architecture of multiple complex diseases.","Analysis, Validation and Resource Creation for Genome Sequencing of Complex Diseases",10116927,U01HG009086,"['Accounting', 'Affect', 'Automobile Driving', 'Code', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Etiology', 'Face', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic study', 'Genome', 'Government', 'Health Expenditures', 'Human', 'Human Genetics', 'Individual', 'Knowledge', 'Large-Scale Sequencing', 'Link', 'Machine Learning', 'Methods', 'National Human Genome Research Institute', 'Phenotype', 'Policies', 'Public Health', 'Regulator Genes', 'Reporting', 'Research', 'Resources', 'Risk', 'Science', 'Statistical Methods', 'Statistical Models', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Validation', 'Variant', 'analysis pipeline', 'base', 'biobank', 'cost', 'design', 'disease phenotype', 'exome', 'exome sequencing', 'expectation', 'experience', 'experimental study', 'functional genomics', 'genetic architecture', 'genetic testing', 'genetic variant', 'genome sciences', 'genome sequencing', 'genome wide association study', 'genomic data', 'human disease', 'human genomics', 'improved', 'insight', 'member', 'method development', 'novel', 'novel strategies', 'personalized medicine', 'pleiotropism', 'public health relevance', 'rare variant', 'success', 'web portal', 'whole genome']",NHGRI,VANDERBILT UNIVERSITY,U01,2020,864183,0.06065930035622768
"Novel Statistical methods for DNA Sequencing Data, and applications to Autism. Summary One of the major problems in human genetics is understanding the genetic causes underlying complex phenotypes, including neuropsychiatric traits such as autism spectrum disorders and schizophrenia. Despite tremendous work over the past few decades, the underlying biological mechanisms are poorly understood in most cases. Recent advances in high-throughput, massively parallel genomic technologies have revolutionized the field of human genetics and promise to lead to important scientific advances. Despite this progress in data generation, it remains very challenging to analyze and interpret these data. The main focus of this proposal is the development of powerful statistical methods for the integration of whole-genome sequencing data with rich functional genomics data with the goal to improve the discovery of genes involved in autism spectrum disorders. We propose to integrate data from many different sources, including epigenetic data from projects such as ENCODE, Roadmap, and PsychENCODE, eQTL data from the GTEx, PsychENCODE and CommonMind consortia, data from large scale databases of genetic variation such as ExAC and gnomAD, in order to predict functional effects of genetic variants in non-coding genetic regions in a tissue and cell type specific manner, and generate functional maps across large number of tissues and cell types in the human body that we can then use to identify novel associations with autism in whole-genome sequencing studies. The proposed functional predictions and functional maps will be broadly available in the popular ANNOVAR database. We further propose to use these functional predictions in the analysis of almost 20,000 whole genomes from three large whole genome sequencing studies for autism. We believe that the proposed research is very timely and has the potential to substantially improve the analysis of non-coding genetic variation, and hence provide new insights into the biological mechanisms underlying risk to autism, and more broadly to other neuropsychiatric diseases. Narrative Autism Spectrum Disorders are common diseases with major impact on public health. Although coding variation has been extensively studied for its role in affecting risk to autism, the analysis of non-coding variation poses tremendous challenges. The proposed statistical methods and their applications to nearly 20,000 whole genomes from three large autism whole genome sequencing studies will improve our understanding of the biological mechanisms involved in autism with important implications for disease treatment strategies.","Novel Statistical methods for DNA Sequencing Data, and applications to Autism.",9923466,R01MH095797,"['Affect', 'Anterior', 'Biochemical', 'Biological', 'Biological Assay', 'Brain region', 'Chromatin', 'Code', 'Collection', 'Complex', 'Computer software', 'Computing Methodologies', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Encyclopedia of DNA Elements', 'Epigenetic Process', 'Generations', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human Genetics', 'Human body', 'Individual', 'International', 'Lead', 'Maps', 'Measures', 'Methods', 'Molecular', 'Phenotype', 'Prefrontal Cortex', 'Public Health', 'Research', 'Risk', 'Role', 'Schizophrenia', 'Scientific Advances and Accomplishments', 'Source', 'Statistical Methods', 'Technology', 'Time', 'Tissues', 'Untranslated RNA', 'Variant', 'Work', 'autism spectrum disorder', 'cell type', 'cingulate cortex', 'data integration', 'design', 'epigenomics', 'exome', 'frontal lobe', 'functional genomics', 'gene discovery', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'histone modification', 'improved', 'insight', 'large scale data', 'large-scale database', 'neuropsychiatric disorder', 'neuropsychiatry', 'novel', 'software development', 'supervised learning', 'tool', 'trait', 'treatment strategy', 'whole genome']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2020,446831,0.029614080757234557
"Statistical Methods in Trans-Omics Chronic Disease Research Project Summary The broad, long-term objectives of this research are the development of novel and high-impact statistical methods for medical studies of chronic diseases, with a focus on trans-omics precision medicine research. The speciﬁc aims of this competing renewal application include: (1) derivation of efﬁcient and robust statistics for integrative association analysis of multiple omics platforms (DNA sequences, RNA expressions, methylation proﬁles, protein expressions, metabolomics proﬁles, etc.) with arbitrary patterns of missing data and with detection limits for quantitative measurements; (2) exploration of statistical learning approaches for handling multiple types of high- dimensional omics variables with structural associations and with substantial missing data; and (3) construction of a multivariate regression model of the effects of somatic mutations on gene expressions in cancer tumors for discovery of subject-speciﬁc driver mutations, leveraging gene interaction network information and accounting for inter-tumor heterogeneity in mutational effects. All these aims have been motivated by the investigators' applied research experience in trans-omics studies of cancer and cardiovascular diseases. The proposed solutions are based on likelihood and other sound statistical principles. The theoretical properties of the new statistical methods will be rigorously investigated through innovative use of advanced mathematical arguments. Computationally efﬁcient and numerically stable algorithms will be developed to implement the inference procedures. The new methods will be evaluated extensively with simulation studies that mimic real data and applied to several ongoing trans-omics precision medicine projects, most of which are carried out at the University of North Carolina at Chapel Hill. Their scientiﬁc merit and computational feasibility are demonstrated by preliminary simulation results and real examples. Efﬁcient, reliable, and user-friendly open-source software with detailed documentation will be produced and disseminated to the broad scientiﬁc community. The proposed work will advance the ﬁeld of statistical genomics and facilitate trans-omics precision medicine studies of chronic diseases. Project Narrative The proposed research intends to develop novel and high-impact statistical methods for integrative analysis of trans-omics data from ongoing precision medicine studies of chronic diseases. The goal is to facilitate the creation of a new era of medicine in which each patient receives individualized care that matches their genetic code.",Statistical Methods in Trans-Omics Chronic Disease Research,9855035,R01HG009974,"['Accounting', 'Address', 'Algorithms', 'Applied Research', 'Biological', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Communities', 'Complex', 'Computer software', 'DNA Sequence', 'Data', 'Data Set', 'Derivation procedure', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Documentation', 'Equation', 'Formulation', 'Gene Expression', 'Genes', 'Genetic Code', 'Genetic Transcription', 'Genomics', 'Goals', 'Grant', 'Information Networks', 'Institution', 'Inter-tumoral heterogeneity', 'Joints', 'Knowledge', 'Malignant Neoplasms', 'Mathematics', 'Measurement', 'Medical', 'Medicine', 'Mental disorders', 'Methods', 'Methylation', 'Modeling', 'Modernization', 'Molecular', 'Molecular Abnormality', 'Molecular Profiling', 'Mutation', 'Mutation Analysis', 'National Human Genome Research Institute', 'North Carolina', 'Patients', 'Pattern', 'Precision Medicine Initiative', 'Prevention', 'Procedures', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Resources', 'Somatic Mutation', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Tail', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Trans-Omics for Precision Medicine', 'United States', 'United States National Institutes of Health', 'Universities', 'Work', 'base', 'disease phenotype', 'driver mutation', 'experience', 'gene interaction', 'genome sequencing', 'high dimensionality', 'innovation', 'machine learning method', 'metabolomics', 'multidimensional data', 'multiple omics', 'novel', 'open source', 'outcome prediction', 'personalized care', 'precision medicine', 'programs', 'protein expression', 'research and development', 'semiparametric', 'simulation', 'sound', 'statistical learning', 'statistics', 'theories', 'tool', 'tumor', 'tumor heterogeneity', 'user-friendly']",NHGRI,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,305167,0.010289206738990645
"Modulation of Lung Disease by Genetic/Epigenetic Profiling Project Summary/Abstract Therapeutic management of lung disorders hallmarked by the loss-of-function of the Cystic Fibrosis (CF) Transmembrane conductance Regulator (CFTR) leading to CF are challenged by genetic and epigenetic diversity found in the CF population. Given the Precision Medicine Initiative (All of Us for You (https://allofus.nih.gov/) and the large amount of genomic and phenomic diversity found in patients, it is now generally recognized that we must find new approaches to address the complexity in CF presentation in the clinic. This will require an understanding of fundamental principles dictating disease onset at birth, defined by familial genetic variation, and its progression, influenced by epigenetic programs, both unique to the individual. This proposal is about understanding the role of genetic and epigenetic diversity in CF in response to Histone DeACetylase (HDAC) activity. We have shown these relationships to be responsive to the activity of HDACs, proteins that manage the acetylation/deacetylation balance of the genome and the proteome (the epigenome) to integrate the complex functions linking the genome to the proteome and phenome. Based on the premise that the genome and epigenome are sensitive to manipulation(s) that will favor increased functionality of the CFTR variant fold, the objective of this proposal is to mechanistically define the impact of HDAC modulation on CFTR function observed at the bench and the bedside. We hypothesize that CF can be best understood based on the rationale that disease can be defined by the collective of variation found in the CF population that alters CFTR sequence-to-function-to-structure relationships in the individual as now described using Variation Spatial Profiling (VSP) and the new principle of Spatial CoVariance (SCV) (Wang and Balch, 2018, In press). It is the objective of this proposal to apply VSP/SCV to analysis of the role of the epigenome in CF. Key goals to be achieved in this proposal are to 1) define molecular, cellular and physiological states that 2) describe the role of genetic/epigenetic/proteomic diversity in the CF population to 3) provide a sequence-to-function-to-structure characterization of disease in the individual. Aim 1 will explore the impact of HDAC inhibitors (HDACi) to define, from a biochemical/genetic diversity perspective, how variation across the entire CF population will respond to rebalancing of acetylation/deacetylation dynamics. Aim 2 will focus on the role of HDAC7 in the management of CF genetic diversity using molecular, biochemical and cellular approaches. Aim 3 will analyze the role of select HDAC7-sensitive CFTR interactors to address their role in the management of CF variation from an epigenetic perspective. We hypothesize that the completion of these Aims will describe relationships in the population that define the epigenome-linked genome features that impact progression of CF in the individual. Our integrated genome/epigenome/proteome platform will advance our understanding of the contribution of genetic diversity in the progression and management of CF as a complex disease. Project Narrative CF is a complex loss-of-function disease caused by genetic and epigenetic variation in the Cystic Fibrosis Transmembrane conductance Regulator (CFTR). We will focus on understanding spatial relationships defined by genetic diversity across the CF population that are sensitive to Histone DeACetylase (HDAC) activity to understand the role of the acetylation/deacetylation balance in facilitating function in the individual. We will use a combination of genomic/epigenomic/proteomic approaches based on the principles of Variation Spatial Profiling (VSP) and Spatial CoVariance (SCV) to dissect the role of HDAC in integrated pathways that affect CFTR variant synthesis, folding, trafficking and stability/function at the cell surface that may be responsive to chemical and/or biological manipulation of the epigenome.",Modulation of Lung Disease by Genetic/Epigenetic Profiling,9928091,R01HL095524,"['Acetylation', 'Address', 'Affect', 'Amino Acids', 'Automobile Driving', 'Biochemical', 'Biochemical Genetics', 'Biological', 'Biology', 'Birth', 'Cell Death', 'Cell surface', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Collection', 'Complex', 'Cystic Fibrosis', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'Deacetylation', 'Disease', 'Disease Progression', 'Environment', 'Epigenetic Process', 'Equilibrium', 'Fibrosis', 'Funding', 'Gaussian model', 'Genetic', 'Genetic Diseases', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'HDAC7 histone deacetylase', 'Health', 'Histone Deacetylase', 'Histone Deacetylase Inhibitor', 'Human', 'Immune', 'Individual', 'Inflammatory Response', 'Lead', 'Link', 'Lung diseases', 'Machine Learning', 'Membrane', 'Mendelian disorder', 'Modification', 'Molecular', 'Mucous body substance', 'Onset of illness', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Physiological', 'Physiology', 'Population', 'Precision Medicine Initiative', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Publications', 'Role', 'Structure', 'System', 'Therapeutic', 'Tissues', 'Variant', 'base', 'bench to bedside', 'cystic fibrosis patients', 'epigenetic profiling', 'epigenetic variation', 'epigenome', 'epigenomics', 'genomic platform', 'healthspan', 'insight', 'loss of function', 'novel strategies', 'phenome', 'phenomics', 'programs', 'response', 'spatial relationship', 'success', 'trafficking', 'transcription factor']",NHLBI,SCRIPPS RESEARCH INSTITUTE,R01,2020,483750,0.023575375927765752
"Systems Biology Analysis of Cardiac Electrical Activity and Arrhythmias. Cardiac arrhythmias are a leading cause of morbidity and mortality in the United States. Abnormalities in heart rate, cardiac conduction (PR and QRS) and repolarization (QT) measured on the ECG predispose to the clinically important cardiac arrhythmias of atrial fibrillation (AF) and ventricular fibrillation (VF) / sudden cardiac death (SCD). We examine the genomic basis of these ECG endophenotypes in order to deconstruct arrhythmias into more proximate traits and discrete components, allowing us to better understand underlying mechanisms, provide insight into arrhythmia generation, and help target development of novel therapies.  The molecular architecture of cardiac electrical activity and arrhythmias is not fully understood, but likely involves genomic, epigenomic, and environmental influences. Over the past 10 years, we have identified numerous common loci associated with cardiac electrical activity and arrhythmias, yet these common variants account for only a portion of the heritability of electrophysiologic and arrhythmic phenotypes. The agnostic examination of genotype-phenotype associations employed in genome- wide association studies (GWAS) does not incorporate knowledge of functional genomic regions or important biologic relationships. Additionally, we currently lack an understanding of the molecular mechanisms connecting mostly intergenic and intronic GWAS signals to phenotype. We therefore hypothesize that a systems biology approach integrating genetic sequence variation with omic data (epigenomic, transcriptomic, and proteomic data) will uncover novel associations and elucidate biologic mechanisms associated with arrhythmia-related phenotypes. We further hypothesize that examining the simultaneous association between sequence variation and multiple cardiac electrophysiologic phenotypes will help uncover additional novel mechanisms associated with cardiac electrical activity and arrhythmias.  TOPMed's combination of rich phenotype data, with whole genome sequence (WGS), epigenomic, transcriptomic, and proteomic data, provides a unique opportunity to more comprehensively explore these hypotheses. We leverage sequence, omic, and phenotype data from multiple cohort studies to efficiently and cost-effectively examine and dissect association of omic factors with cardiac electrophysiology and arrhythmia risk. Our application is an ambitious yet eminently feasible effort that integrates clinical, genetic, and systems biology expertise. We aim to discover associations using omics data (Aims 1 and 2) and elucidate specific genes and biologic pathways underlying these associations (Aims 3 and 4). Our ultimate goal is to identify pathways, genes, and genetic variation that are clinically relevant, and therefore potentially the target of new therapies, diagnostics, or risk predictions. Narrative Cardiac arrhythmias are a major cause of morbidity and mortality in the United States. This proposal aims to use genomic, epigenomic, transcriptomic, and proteomic data, combined with complex systems biology and pleiotropic analyses, to better understand the underlying pathways and genes involved in normal electrophysiology and arrhythmia formation. The identification of biologic factors that influence cardiac electrical activity and arrhythmias will provide insight into the mechanisms of arrhythmia generation, and perhaps identify better targets for drug development and prevention.",Systems Biology Analysis of Cardiac Electrical Activity and Arrhythmias.,9921462,R01HL141989,"['Address', 'Affect', 'Architecture', 'Arrhythmia', 'Atrial Fibrillation', 'Bayesian Modeling', 'Biological', 'Biological Factors', 'Biological Process', 'Cardiac', 'Cardiac Electrophysiologic Techniques', 'Clinical', 'Cohort Studies', 'Complex', 'Data', 'Development', 'Diagnostic', 'Drug Targeting', 'Electrocardiogram', 'Electrophysiology (science)', 'Gene Expression Regulation', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genomic Segment', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Goals', 'Grouping', 'Heart', 'Heart Rate', 'Heritability', 'Knowledge', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Medical Genetics', 'Methods', 'Methylation', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'Multiomic Data', 'Pathway interactions', 'Pattern', 'Phenotype', 'Population', 'Prevention', 'Proteins', 'Proteomics', 'Regulator Genes', 'Risk', 'Signal Transduction', 'Site', 'Systems Biology', 'Testing', 'Trans-Omics for Precision Medicine', 'United States', 'Variant', 'Ventricular Fibrillation', 'base', 'causal variant', 'clinical phenotype', 'clinically relevant', 'cost', 'drug development', 'endophenotype', 'epigenomics', 'functional genomics', 'genome wide association study', 'heart electrical activity', 'insight', 'mortality', 'new therapeutic target', 'novel', 'novel therapeutics', 'phenotypic data', 'pleiotropism', 'rare variant', 'sudden cardiac death', 'trait', 'transcriptomics', 'whole genome']",NHLBI,UNIVERSITY OF WASHINGTON,R01,2020,476969,0.013407060751618214
"Enhancing molecular diagnosis in children with multiple congenital anomalies using clinically focused splicing prediction algorithms The training included in this career development award promotes the applicant's development as a physician-scientist during his the PhD phase of his MD/PhD training in transdisciplinary computational genomics. The applicant has previously completed a Master's Degree in Mathematics, and has had extensive instruction in general computational biology. This unique melding of high-level computational expertise and interest in applied genomics has led to the development of this innovative project. He is now being co-mentored by Drs. Barash and Bhoj to gain complementary practical training in predictive algorithm development and molecular genetics. In both his clinical and research interests he is dedicated to improving the rate of molecular diagnosis for children with rare Mendelian disorders. His short-term goals include developing and refining his skills in RNA splicing prediction and human genetic variation analysis in exome and genome data. In addition, he will gain new insight into experimental design, data interpretation, and scientific communication skills to ensure his successful post-doctoral transition. His co-mentors for the proposal are Drs. Yoseph Barash and Elizabeth Bhoj, international leaders in computational genomics and molecular genetics. In addition he will be supported by outstanding resources of the MSTP at Penn, which has an extensive proven track record of successful previous awardees.  The applicant has been pursuing work in creating an improved computational pipeline for the analysis of variants from exome and genome data. Specifically he is capturing the intronic and synonymous variants that are generally removed from the analysis pipeline because of the difficulty in determining the pathogenicity of such variants. As there are many intronic and synonymous variants that are known to cause Mendelain disorders, this clearly leads to missed diagnoses. In Aim 1 he will generate an interpretable algorithm for prioritizing general splicing variants that guides functional validation. In Aim 2 he will identify novel variants and genes for mechanistic evaluation in the pathogenesis of congenital anomalies. This algorithm will be generally applicable, significantly enhancing our ability to provide molecular diagnoses for all patients with suspected Mendelian disorders. In addition, this proposal will allow the candidate to gain experience, knowledge, and new skills to successfully lay the foundation as a physician-scientist in computational genomics. Many children who are born with multiple medical issues have a genetic cause for their differences, but even the best tests cannot identify the genetic cause. This project will develop new computer technology to do a more complete analysis of their genetic testing information to help diagnose more of these children.",Enhancing molecular diagnosis in children with multiple congenital anomalies using clinically focused splicing prediction algorithms,9907858,F30HD098803,"['Address', 'Algorithms', 'Alternative Splicing', 'Benchmarking', 'Cells', 'Child', 'Childhood', 'ClinVar', 'Clinical', 'Clinical Research', 'Code', 'Communication', 'Computational Biology', 'Computational Molecular Biology', 'Computers', 'Critical Thinking', 'Data', 'Data Analyses', 'Data Set', 'Defect', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Ensure', 'Evaluation', 'Excision', 'Exhibits', 'Exons', 'Experimental Designs', 'Foundations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Human', 'Human Genetics', 'Instruction', 'International', 'Introns', 'K-Series Research Career Programs', 'Knowledge', 'Libraries', 'Manuals', 'Master&apos', 's Degree', 'Mathematics', 'Medical', 'Mendelian disorder', 'Mentors', 'Mentorship', 'Messenger RNA', 'Modeling', 'Molecular Diagnosis', 'Molecular Genetics', 'Normal tissue morphology', 'Pathogenesis', 'Pathogenicity', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Physicians', 'Postdoctoral Fellow', 'Protein Isoforms', 'RNA Splicing', 'Regulation', 'Resources', 'Reverse Transcriptase Polymerase Chain Reaction', 'Scientist', 'Site', 'Syndrome', 'Technology', 'Testing', 'Tissues', 'Training', 'Untranslated RNA', 'Validation', 'Variant', 'Work', 'algorithm development', 'analysis pipeline', 'career', 'causal variant', 'clinical application', 'cohort', 'computational pipelines', 'congenital anomaly', 'deep learning', 'exome', 'exome sequencing', 'experience', 'genetic testing', 'genetic variant', 'improved', 'innovation', 'insight', 'interest', 'novel', 'prediction algorithm', 'reference genome', 'skills', 'standard of care', 'transcriptome sequencing']",NICHD,UNIVERSITY OF PENNSYLVANIA,F30,2020,50520,0.03160683534943365
"Integrate gene expression data to characterize the contribution of rare genetic risk factors to structural birth defects Project Summary  We aim to maximize discovery of new risk genes and elucidate the genetic architecture of structural birth defects. To achieve that, we propose cross-disease genetic analysis of both protein-coding and noncoding variants and integration of gene expression data to prioritize candidate risk genes.  Better understanding of the genetic basis of structural birth defects will lead to new insights into human developmental biology and will provide targets for medical intervention and treatment. Recent large-scale genome and exome sequencing studies of birth defects have identified new risk genes, especially through the analysis of de novo variants in protein coding regions. However, we are still far from complete understanding of the genetic causes of birth defects. Estimates are that there are 400- 800 risk genes of large effect size for birth defects such as congenital heart disease, and the vast majority of these genes are unknown. This is primarily due to the lack of statistical power. While increasing sample size is essential and is part of the core deliverables of the Gabriella Miller Kids First (GMKF) programs, we also need to develop and apply new analytical methods that improve power and maximize the utility of the available genetic data by using other types of data and biological knowledge. In addition, in most prior studies, the analysis of rare genetic variation has been focused on small variants in the coding regions or large copy number variants (CNV). The data and methods to interrogate the contribution of rare noncoding variants is rudimentary, limiting our understanding of genetic architecture of these diseases. In this study, we propose two aims to address these questions by leverage GMKF cross-disease whole genome sequencing data sets: Specific Aim 1. Elucidate genetic architecture by cross-disease analysis of rare coding and non-coding variants. Specific Aim 2. Integrate gene expression with genome sequencing data to improve discovery and biological interpretation of risk genes of structural birth defects.  The proposed study will maximize the genetic discovery potential of the GMKF WGS data sets for birth defects and improve our understanding of the pleiotropic effects and tissue specificity of risk genes and variants. The analytical approaches developed in this study will be applicable to genetic data of birth defects and developmental disorders from future GMKF cohorts and other programs. Project Narrative We propose to analyze whole genome sequencing data from the Gabriella Miller Kids First cohorts using new computational approaches that maximize the risk gene discovery and improve interpretation of candidate genes. Our research will enhance the utility of Kids First program generated data and improve our understanding of the genetics of birth defects.",Integrate gene expression data to characterize the contribution of rare genetic risk factors to structural birth defects,9882319,R03HL147197,"['Address', 'Award', 'Biological', 'Candidate Disease Gene', 'Code', 'Collaborations', 'Computing Methodologies', 'Congenital Abnormality', 'Congenital diaphragmatic hernia', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Developmental Biology', 'Disease', 'Ensure', 'Esophagus', 'Funding', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Diseases', 'Genetic Risk', 'Genetic Transcription', 'Genetic Variation', 'Human', 'Human Development', 'Intervention', 'Knowledge', 'Malignant Neoplasms', 'Medical', 'Methods', 'Molecular', 'Multiple Birth Offspring', 'Neurodevelopmental Disorder', 'Open Reading Frames', 'Organ', 'Pathway interactions', 'Pattern', 'Proteins', 'Research', 'Role', 'Sample Size', 'Specificity', 'Structural Congenital Anomalies', 'Tissues', 'Untranslated RNA', 'Variant', 'analytical method', 'autism spectrum disorder', 'base', 'bioinformatics pipeline', 'body system', 'brain cell', 'cell type', 'cohort', 'congenital heart disorder', 'de novo mutation', 'developmental disease', 'dosage', 'exome', 'exome sequencing', 'functional genomics', 'gene discovery', 'genetic analysis', 'genetic architecture', 'genetic risk factor', 'genetic variant', 'genome sequencing', 'genome-wide', 'genomic data', 'improved', 'insight', 'interest', 'machine learning method', 'novel', 'pleiotropism', 'programs', 'rare variant', 'risk variant', 'single-cell RNA sequencing', 'whole genome']",NHLBI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2020,157441,0.014531710450492646
"Privacy-preserving genomic medicine at scale 1 Project Summary  2  3 High-throughput sequencing, biomedical imaging, and electronic health record technologies are 4 generating health-related datasets of unprecedented scale. Integrative analysis of these  5 resources promises to reveal new biology and drive personal and precision medicine. Yet, the  6 sensitive nature of these data often requires that they be kept in isolated silos, limiting their 7 usefulness to science. The goal of this project is to develop innovative privacy-preserving  8 algorithms to enable data sharing and drive genomic medicine. Crucially, we will draw upon our  9 past success in secure genome analysis and algorithmic expertise in computational biology to 10 address the imminent need to perform complex integrative analyses securely and at scale. 11 Current privacy-preserving tools are prohibitively too costly to perform the complex 12 calculations required in genomic analysis. We previously leveraged the highly structured nature 13 of biological data and novel optimization strategies to implement efficient pipelines for secure 14 genome-wide association studies (GWAS) and drug interaction predictions which scaled to 15 millions of samples. In this project, we will further exploit the unique properties of biomedical data 16 to: (i) develop secure integrative analysis methods for genomic medicine; (ii) develop an easy-to- 17 use programming environment with advanced automated optimizations to facilitate the adoption 18 of privacy-preserving analyses; and (iii) promote the use of our privacy techniques to gain novel 19 biological insights through large-scale collaborative genetic studies of multi-ethnic cohorts. 20 With co-I’s Amarasinghe (MIT) and Cho (Broad Institute), we aim to apply these tools to 21 realize the first multi-institution, multi-national secure genetic studies with our partners at the 22 Swiss Personalized Health Network, UK Biobank, Finnish FinnGen, All of Us, NIH NCBI, Broad 23 and Barcelona Supercomputing Center (Letters of Support). We will also use our privacy- 24 preserving approaches to study genomic origins of polygenic traits for disease as well as 25 neuroimaging and other clinical phenotypes. We will continue to actively integrate our methods 26 into community standards (MPEG-G, GA4GH). 27 Successful completion of these aims will result in computational methods and open-source, 28 easy-to-use, production-grade implementations that open the door to secure integration and 29 analysis of massive sets of sensitive genomic and clinical data. With input from our collaborations, 30 we will build these tools and apply them to better understand the molecular causes of human 31 health and its translation to the clinic. Project Narrative Combining genomic and health-related data from millions of patients will empower the development of clinically relevant measures of human health and disease risks. However, this task requires securely sharing sensitive data at an immense scale beyond what existing cryptographic platforms can achieve. Here we develop novel computational methods to enable biomedical data integration, analysis, and interpretation in a privacy-preserving and highly scalable manner.",Privacy-preserving genomic medicine at scale,9998648,R01HG010959,"['Address', 'Adoption', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biological', 'Biology', 'Clinic', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Complex Analysis', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Consumption', 'Data', 'Data Analyses', 'Data Pooling', 'Data Security', 'Data Set', 'Disease', 'Drug Interactions', 'Electronic Health Record', 'Engineering', 'Environment', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Institutes', 'Institution', 'Knowledge', 'Letters', 'Machine Learning', 'Mainstreaming', 'Measures', 'Medical Imaging', 'Medical Records', 'Medicine', 'Methods', 'Modernization', 'Molecular', 'Nature', 'Patients', 'Performance', 'Pharmacology', 'Polygenic Traits', 'Privacy', 'Process', 'Production', 'Property', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Science', 'Secure', 'Security', 'Software Engineering', 'Software Tools', 'Standardization', 'Stream', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Time', 'Translations', 'United States National Institutes of Health', 'Work', 'analysis pipeline', 'base', 'biobank', 'bioimaging', 'clinical development', 'clinical phenotype', 'clinically relevant', 'cohort', 'computer framework', 'cost', 'cryptography', 'data analysis pipeline', 'data integration', 'data sharing', 'data warehouse', 'disorder risk', 'epidemiology study', 'experimental study', 'genome analysis', 'genome wide association study', 'genomic data', 'health data', 'innovation', 'insight', 'monomethoxypolyethylene glycol', 'neuroimaging', 'novel', 'open source', 'polygenic risk score', 'precision medicine', 'preservation', 'privacy preservation', 'statistics', 'success', 'task analysis', 'theories', 'tool']",NHGRI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,636185,0.00847308583323075
"Comprehensive Characterization of Adaptive Regulatory Variation Linked to Human Disease Project Summary/ Abstract  Over the past decade there has been a rapid expansion of genome-wide association studies (GWAS), as well as the development of large-scale consortia like the UKBioBank and the All of Us project. While the number of genetic associations to human traits and disease is soaring, tools to characterize and interpret these variants are lacking. One challenge to realizing the potential of genomics is that over 99% of human genetic variation is non-coding, regulatory sequences. However, ‘regulatory grammar’ – the complex pattern of sequences that interact with transcription factors to control gene expression, is poorly understood. A repertoire of well-characterized causal variants is needed to build generalizable models with which to unlock insights into the genetic basis of human health and history.  Natural selection is a powerful driver of human genetic variation. As our species has encountered new climates, dramatic alterations in diet, and novel pathogens, these selective pressures have left hundreds of signatures of adaptation in our genomes, reflected in our species’ diversity of disease risk and morphology. For selection to have acted positively on them, these adaptive alleles must exhibit relatively strong phenotypic effects, and they continue to contribute to modern traits and disease (e.g. height or sickle cell anemia). Salient examples of human adaptation include immunity, metabolism, and morphology, all of which have extensive, unresolved GWAS signals. This renders the lens of recent evolution a powerful, but underutilized, tool for identifying alleles that contribute to phenotypic variation in modern association studies.  This proposal aims to expand the repertoire of well-characterized GWAS signals, by A) using evolution to prioritize adaptive variants, and B) applying novel, high-throughput experimental and computational tools to comprehensively decipher the functions of regulatory variants. These approaches will identify much needed causal variants, devise paradigms for their study, and inform future predictive models to characterize them. During the mentored phase of the K99, I will first develop methods to colocalize signals of selection and GWAS, and then use Variant Effect Predictions (VEP) to predict their function. I will then employ high-through methods such as a the massively parallel reporter assay and CRISPR non-coding screen to functionally characterize them directly. From the adaptive GWAS alleles our screens identify, we will make in-vivo system to more deeply characterize them during the Independent R00 phase. During this time I will deploy a variety of genomic tools such as ChIP, ChIA-PET, and RNA-seq to understand the adaptive variants’ molecular etiology. I will use the empirical data fro these studies, and the MPRA/HCR-FlowFISH screens to build more accurate VEP models. ! Project Narrative While thousands of genomic regions have been linked to human evolution and diseases, many of the genetic variants responsible are non-coding and thus difficult to interpret. I propose to identify adaptive human alleles underlying genome wide association studies and comprehensively characterize them using novel computational and experimental tools. I will then make in-vivo models of these to test their function and effects on fitness, improving future predictions of how genetic variants impact human evolution and health.",Comprehensive Characterization of Adaptive Regulatory Variation Linked to Human Disease,10005404,K99HG010669,"['African', 'Alleles', 'Biological Assay', 'CCRL2 gene', 'CRISPR interference', 'CRISPR screen', 'CRISPR/Cas technology', 'Cell Line', 'Cell model', 'Cells', 'Chromatin Interaction Analysis by Paired-End Tag Sequencing', 'Climate', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Computer Models', 'Data', 'Databases', 'Deoxyribonucleases', 'Development', 'Diet', 'Disease', 'Epigenetic Process', 'Etiology', 'Evolution', 'Exhibits', 'Future', 'Gene Expression', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomic Segment', 'Genomics', 'Health', 'Height', 'Histones', 'Human', 'Human Genetics', 'Immunity', 'Lassa Fever', 'Left', 'Link', 'Linkage Disequilibrium', 'Machine Learning', 'Measures', 'Mentors', 'Metabolism', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Morphology', 'National Human Genome Research Institute', 'Natural Selections', 'Neural Network Simulation', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Preparation', 'Recording of previous events', 'Regulatory Element', 'Reporter', 'Reporting', 'Research', 'Scanning', 'Sickle Cell Anemia', 'Signal Transduction', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Untranslated RNA', 'Variant', 'biobank', 'causal variant', 'cell type', 'computerized tools', 'disorder risk', 'fitness', 'genetic association', 'genetic variant', 'genome editing', 'genome wide association study', 'genomic tools', 'human disease', 'improved', 'in vivo', 'in vivo Model', 'insight', 'lens', 'mouse model', 'novel', 'pathogen', 'predictive modeling', 'pressure', 'tool', 'trait', 'transcription factor', 'transcriptome sequencing']",NHGRI,"BROAD INSTITUTE, INC.",K99,2020,125378,-0.02530886329388672
"IBD Gene Mapping by Clinical and Population Subset PROJECT SUMMARY Inflammatory bowel disease (IBD), Crohn's disease (CD) and ulcerative colitis (UC) are complex genetic disorders of the gastrointestinal tract, and a major health burden to patients and society. Tremendous progress has been made in dissecting IBD genetic etiology with identification of over 200 IBD loci by genome wide association studies (GWAS) but mainly limited to persons of European ancestry. The IBD Genetics Consortium (IBDGC) was established to facilitate multicenter collaborative studies of 6 Genetics Research Centers (GRCs) organized with a Data Coordinating Center (DCC). Our GRC at Johns Hopkins (JHGRC) has contributed to all IBDGC studies, meeting recruitment objectives and taking roles in IBDGC leadership positions. Our particular focus is on African American (AA) IBD genetics. We performed the first large-scale evaluation of European loci in the AA population, replicating several genes, but also finding unique African-ancestral variants within these loci, as well as identified multiple admixture significant loci. We also published the first AA IBD genome-wide association study (GWAS), a collaborative effort that identified two African-specific gene loci, and replicated multiple additional European loci. We have also explored why some loci with proven risk variants in Europeans and other populations only cause disease in one ancestral population but not others. More research in AA IBD is needed to understand the etiology of IBD in this ancestrally distinct, major American population. In this application we will re-evaluate the AA GWAS by better imputation, evaluate whole genome sequencing data to test low frequency and rare variants, and perform an evaluation for chromosome X variants. We will recruit a large number of AA IBD patients through our own and multiple Satellite Recruitment Centers to power a second AA IBD GWAS, both UC and CD, and meta-analyze with the first to identify more novel loci, identify more African specific risk variants, and replicate known loci for this population and replicate our admixture loci. We will also incorporate diverse data sources to incorporate into our GWAS analyses including RNA-Seq currently being generated on lymophoblastoid cell lines from AA CD cases and controls, and RNA-Seq that we will generate in colonic biopsies from UC cases and controls. We will evaluate chromatin differences and expression of genes in cell types relevant to IBD from European, AA and East Asian ancestries in an effort to better understand locus heterogeneity by ancestry. We will continue to participate in all IBDGC activities to maximize the Impact of IBD genetics research by this cooperative funding mechanism. According to the Center for Disease Control and Prevention, an estimated 1.4 million Americans suffer from Inflammatory Bowel Disease (IBD), a chronic debilitating disorder with no cure that includes Crohn's disease and ulcerative colitis. IBD ranks in the top 5 in prevalence for gastrointestinal disorders and represents a significant financial burden to society requiring a lifetime of medical care. This proposed research aims to determine the genetic variations that cause IBD which will aid in developing preventive measures, improving the quality of care with better treatments and educating patients through genetic counseling.",IBD Gene Mapping by Clinical and Population Subset,10001511,U01DK062431,"['ATAC-seq', 'Admixture', 'African', 'African American', 'Algorithms', 'American', 'Asians', 'Biopsy', 'Caring', 'Cell Line', 'Centers for Disease Control and Prevention (U.S.)', 'Charge', 'Chromatin', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Coculture Techniques', 'Cohort Studies', 'Collaborations', 'Complex', 'Crohn&apos', 's disease', 'DNA', 'Data', 'Data Coordinating Center', 'Data Sources', 'Databases', 'Digestive System Disorders', 'Disease', 'Effectiveness', 'Enhancers', 'Epithelial', 'Epithelium', 'Ethnic Origin', 'Etiology', 'European', 'Evaluation', 'Financial Hardship', 'Fostering', 'Frequencies', 'Funding', 'Funding Mechanisms', 'Future', 'Gastrointestinal Diseases', 'Gene Expression', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic Counseling', 'Genetic Diseases', 'Genetic Predisposition to Disease', 'Genetic Research', 'Genetic Variation', 'Genotype', 'Goals', 'Health', 'Heterogeneity', 'Hispanics', 'Human Characteristics', 'Individual', 'Inflammatory Bowel Diseases', 'Investigation', 'Lead', 'Leadership', 'Linkage Disequilibrium', 'Machine Learning', 'Medical', 'Modeling', 'Nature', 'Other Genetics', 'Pathway Analysis', 'Patients', 'Pattern', 'Persons', 'Phase', 'Phenotype', 'Point Mutation', 'Population', 'Population Genetics', 'Positioning Attribute', 'Prevalence', 'Preventive measure', 'Publications', 'Publishing', 'Quality of Care', 'Research', 'Resources', 'Role', 'Sampling', 'Societies', 'Source', 'Testing', 'Ulcerative Colitis', 'Universities', 'Update', 'Variant', 'Work', 'X Chromosome', 'base', 'case control', 'cell type', 'differential expression', 'diverse data', 'experience', 'genetic association', 'genome sequencing', 'genome wide association study', 'genomic locus', 'improved', 'insight', 'interest', 'macrophage', 'meetings', 'novel', 'novel strategies', 'racial disparity', 'rare variant', 'recruit', 'risk variant', 'sex', 'study population', 'transcriptome sequencing', 'two-dimensional', 'whole genome']",NIDDK,RBHS-ROBERT WOOD JOHNSON MEDICAL SCHOOL,U01,2020,451377,0.025295219552930272
