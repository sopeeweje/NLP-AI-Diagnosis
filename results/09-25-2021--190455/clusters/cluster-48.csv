text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction Project Summary/Abstract Electronic Health Records (EHRs) contain significant information that can benefit many downstream uses. However, most of this information is in unstructured narrative form and is inaccessible to computerized methods that rely on structured representations for exploring, retrieving, and presenting the information. Natural language processing (NLP) and information extraction (IE) open this trove of information to studies that would otherwise be without. Over the past decades, many IE systems have been developed. These systems have typically focused on one task at a time. In addition, most have studied only specific types of records, e.g., discharge summaries, and addressed their task on data from a single institution. Performances achieved by the state-of-the-art IE systems developed under these conditions ranged from 44% F-measure to 99% F-measure. This observed variation can be attributed to the nature of the tasks: some target entities like dates tend to be better represented in the data and also more rigidly stick to known patterns of expression as opposed to reasons for medication administration which are relatively sparse in the data and can show wider linguistic diversity. However, this may not be the only reason: the data used can also explain the performance variation. Narratives of EHRs vary in their style, format, and content going from one department to another, from one hospital to another. Even the same record type in two different hospitals can be very different in narrative style and pose different challenges for IE. Understanding IE performance therefore requires studies of multiple tasks on multiple record types that come from multiple institutions. One major bottleneck for evaluation of IE systems on such a large scale is annotation. The same bottleneck also limits system development. This proposal aims to address this bottleneck for both evaluation and development. It first generates a multi-institution corpus consisting of multiple record types from five institutions. It studies four different IE tasks that broadly represent IE in clinical records and can inform the field of IE as a whole: de-identification, clinical concept extraction, medication extraction, and adverse drug event extraction. Within the context of these IE tasks, the proposal then puts forward methods that learn from unlabeled or pseudo data that can help alleviate reliance on annotated data for development. It evaluates these methods both for performance and generalizability on multiple types of records from multiple institutions. As a result of these activities, this proposal generates de-identified data, annotations, methods, software, and machine learning models which it then makes available to the research community. Project Narrative Information extraction (IE) systems, i.e., natural language processing (NLP) systems that enable creation of accurate semantic representations of narratives, rely heavily on the availability of gold standard annotated corpora and vary significantly in their performance from task to task, and from data set to data set. We propose methods that augment gold standard data with unlabeled data that are more easily available, and pseudo data which can be derived from gold standard data. We study IE within the context of four tasks and evaluate IE systems enhanced with unlabeled and pseudo data for generalizability on a heterogeneous data set consisting of multiple record types from five institutions.",Leveraging Unlabeled and Pseudo Data for Clinical Information Extraction,9813134,R15LM013209,"['Accident and Emergency department', 'Address', 'Adverse drug event', 'Affect', 'Clinic', 'Clinical', 'Clinical Data', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Discipline of Nursing', 'Electronic Health Record', 'Engineering', 'Evaluation', 'Frequencies', 'Gold', 'Growth', 'Healthcare', 'Hospitals', 'Institution', 'Israel', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Location', 'Machine Learning', 'Measures', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nature', 'Outcome', 'Pattern', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Plant Roots', 'Procedures', 'Psychiatry', 'Publications', 'Records', 'Reporting', 'Research', 'Resources', 'Route', 'Sampling', 'Semantics', 'Signs and Symptoms', 'Social Work', 'Structure', 'Supervision', 'System', 'Systems Development', 'Task Performances', 'Telephone', 'Test Result', 'Testing', 'Text', 'Thinness', 'Time', 'Training', 'Universities', 'Variant', 'Virginia', 'Washington', 'computerized', 'deep learning', 'dosage', 'field study', 'improved', 'learning strategy', 'medication administration', 'novel', 'open source', 'response', 'supervised learning', 'tool']",NLM,GEORGE MASON UNIVERSITY,R15,2019,414798,-0.015467104149353168
"Improving Specialty Care Delivery in the Safety Net with Natural Language Processing Project Summary  Safety net providers treat a substantial share of socioeconomically vulnerable patients in their communities, but struggle to provide timely access to high quality specialty care for their patients. Delayed access to specialty care is associated with worse health outcomes and potentially contributes to health disparities across socioeconomic groups. Given their limited resources, safety net providers must seek creative approaches to improve specialty access. However, to choose what programs to implement, safety net providers need to understand the specialty care needs of their populations. Fortunately, the adoption of eConsult systems by safety net providers across the US provides a valuable opportunity to systematically measure patterns of specialty care referrals for minority, underserved populations.  In this project, we propose using state-of-the-art methods in machine learning and natural language processing (NLP) to help safety net providers extract actionable, population wide data from their electronic consultation systems. We will do this in partnership with three of the most prominent safety net health systems in the US in Los Angeles, San Francisco and New York City. Using specialty request databases from our collaborators, we will build NLP systems to automatically classify specialty requests along two dimensions: the “clinical issue” motivating the request (e.g., chest pain), and the “question type” (e.g., request for a procedure, help with medication management). This automated classification of electronic specialty requests can enable identification of promising targets for interventions to improve specialty access and quality of care.  After developing these NLP systems, we will analyze >1 million specialty requests to describe trends in how safety net patients are referred to specialists and examine variation in referral patterns by clinic and individual provider. The goal is to identify the most impactful opportunities to improve specialty access and quality. For example, a high rate of referrals for esophageal reflux, which most PCPs can treat on their own with specialist guidance, could lead to new treatment algorithms, potentially reducing the need for these requests and improving access for other patients.  This proposal is a “high-risk high-reward” project that creates new research tools to identify and evaluate data-driven interventions to improve specialty care delivery for underserved populations. Project Narrative Access to timely, high-quality specialty care is a fundamental component of a well-functioning health system, yet safety net health care providers face persistent challenges delivering such care. Quality improvement efforts to improve specialty access have been thwarted in part because safety net providers lack the data to understand a basic question – why patients are referred for specialty care. Taking advantage of the growing use of electronic specialty referral systems by safety net providers, we propose using natural language processing to conduct automated analysis and classification of specialty requests in safety net populations, which will enable the design of targeted interventions to improve specialty care access and delivery.",Improving Specialty Care Delivery in the Safety Net with Natural Language Processing,9789060,R21MD012693,"['Acute', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Chest Pain', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Communities', 'Consultations', 'County', 'Data', 'Data Set', 'Databases', 'Education', 'Epidemiology', 'Face', 'Federally Qualified Health Center', 'Gastroesophageal reflux disease', 'Goals', 'Health', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Heart failure', 'Hospitals', 'Improve Access', 'Individual', 'Intervention', 'Lead', 'Los Angeles', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Education', 'Medical center', 'Medication Management', 'Methods', 'Minority', 'Morbidity - disease rate', 'Natural Language Processing', 'New York City', 'Online Systems', 'Ophthalmology', 'Outcome', 'Patients', 'Pattern', 'Play', 'Population', 'Primary Care Physician', 'Procedures', 'Provider', 'Public Hospitals', 'Quality of Care', 'Research', 'Resources', 'Retinal Diseases', 'Role', 'San Francisco', 'Specialist', 'System', 'Taxonomy', 'Telemedicine', 'Text', 'Time', 'Transplantation', 'Triage', 'Underserved Population', 'Variant', 'Visit', 'automated analysis', 'care delivery', 'design', 'diabetic', 'disease classification', 'ethnic minority population', 'follow-up', 'health disparity', 'high reward', 'high risk', 'improved', 'medical specialties', 'medically underserved', 'minority communities', 'mortality', 'performance tests', 'programs', 'racial and ethnic', 'safety net', 'screening', 'socioeconomic disadvantage', 'socioeconomics', 'tool', 'trend', 'two-dimensional']",NIMHD,BOSTON CHILDREN'S HOSPITAL,R21,2019,94263,0.013190330471263334
"Ethical Considerations for Language Modeling within Brain-Computer Interfaces Project Summary Machine learning (ML) and Natural Language Processing (NLP) have the potential to transform communication for patients with neurodegenerative disease through personalized and real-time augmentative and alternative communication (AAC) devices. Individuals with severe communication impairments who can no longer control their daily conversations or participate in previous life roles want AAC devices. And they want them to work – to be reliable, effective, and fast. ML and NLP are emerging as promising tools to bridge current technology and next generation devices for individuals with the most severe speech and physical impairments, like the RSVP Keyboard™, a brain-computer interface (BCI) being developed by the parent grant. BCI systems for communication are referred to as AAC-BCIs. NLP efforts to combine large public data sets with private data sets, such as personal email messages, promise to give individuals with communication impairments their own personalized language models, models that are sufficiently robust to get closer to real-time communication. The focus on getting AAC-BCIs to work with machine learning, however, has led to a critical oversight in the field: an inadequate understanding of why individuals want next-generation devices and what trade-offs they are willing to make for faster and more personalized communication. The turn to ML brings this oversight into sharp relief. Individuals should provide input about the data sets used to construct their personal language models, but this raises important ethical questions about what individuals value, how they understand their identity, and what trade-offs they are willing to make relative to their personalized communication data. The goal of this supplement is to fill this gap in understanding so that researchers can implement ML into next generation AAC-BCI systems in a way that is sensitive to the ethical concerns of future users. There are four components to this ethics supplement: (1) to design a toolbox of ethics vignettes tailored to ethical concerns raised by both BCI communication and ML; (2) to administer monthly vignette-based online ethics surveys to individuals with severe communication impairments due to motor neuron disease (e.g., ALS) (n=25) or movement disorders (e.g., Parkinson's disease) (n=25); (3) to conduct semi-structured vignette-based interviews with individuals with pre- clinical or mild communication impairment due to motor neuron disease (n=10) or movement disorder (n=10). Components (2) and (3) will employ an iterative, parallel mixed-method approach. Trends in Likert-style online responses to ethics vignettes in the severe communication impairment cohort will be used to inform and modify the semi-structured interview prompts asked of the pre-clinical or mild impairment cohort. In parallel, themes emerging from direct content analysis of interviews will be used to refine online survey questions. Results of this iterative, mix-methods approach will be used (4) to outline a framework of core ethical domains and preliminary tools (vignettes and discussion prompts) that AAC-BCI researchers can use to assess ethical concerns while developing and iteratively refining communication technology for personalized language models. Project Narrative The populations of US citizens with severe speech and physical impairments secondary to neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies. Bioethical issues about privacy, agency and identity must be included in technology development and implementation as the parent grant implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Ethical Considerations for Language Modeling within Brain-Computer Interfaces,9929337,R01DC009834,"['Address', 'Administrative Supplement', 'Affect', 'Attention', 'Attitude', 'Augmentative and Alternative Communication', 'Award', 'Bioethical Issues', 'Bioethics', 'Clinical', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Computers', 'Data', 'Data Set', 'Decision Making', 'Development', 'Devices', 'Disease', 'Electroencephalography', 'Electronic Mail', 'Encapsulated', 'Engineering', 'Ensure', 'Ethical Analysis', 'Ethical Issues', 'Ethics', 'Foundations', 'Future', 'Goals', 'Home environment', 'Impairment', 'Individual', 'Informed Consent', 'Interview', 'Language', 'Letters', 'Life', 'Link', 'Literature', 'Locked-In Syndrome', 'Machine Learning', 'Medical', 'Medical Technology', 'Methods', 'Modeling', 'Monkeys', 'Motor Neuron Disease', 'Movement', 'Movement Disorders', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Oregon', 'Outcome', 'Parents', 'Parkinson Disease', 'Participant', 'Patient advocacy', 'Patients', 'Population', 'Privacy', 'Privatization', 'Public Health', 'Reporting', 'Research Personnel', 'Review Literature', 'Role', 'Secondary to', 'Self-Help Devices', 'Source', 'Speech', 'Structure', 'Surveys', 'System', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Voice', 'Work', 'advocacy organizations', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'cohort', 'communication device', 'computer science', 'design', 'expectation', 'informant', 'neurophysiology', 'next generation', 'novel', 'parent grant', 'pre-clinical', 'recruit', 'research and development', 'response', 'signal processing', 'skills', 'spelling', 'technology development', 'technology validation', 'tool', 'trend', 'uptake']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,153834,-0.016393750033562977
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9772541,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structural Models', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,264255,-0.00586639813089011
"Leveraging Twitter to monitor nicotine and tobacco-related cancer communication Patterns in Twitter data have revolutionized understanding of public health events such as influenza outbreaks. While researchers have begun to examine messaging related to substance use on Twitter, this project will strengthen the use of Twitter as an infoveillance tool to more rigorously examine nicotine, tobacco, and cancer- related communication. Twitter is particularly suited to this work because its users are commonly adolescents, young adults, and racial and ethnic minorities, all of whom are at increased risk for nicotine and tobacco product (NTP) use and related health consequences. Additionally, due to the openness of the platform, searches are replicable and transparent, enabling large-scale systematic research. Therefore, our multidisciplinary team of experts in diverse relevant fields—including public health, behavioral science, computational linguistics, computer science, biomedical informatics, and information privacy and security—will build upon our previous research to develop and validate structured algorithms providing automated surveillance of Twitter’s multifaceted and continuously evolving information related to NTPs. First, we will qualitatively assess a stratified random sample of relevant NTP-related tweets for specific coded variables, such as the message’s primary sentiment and other key information of potential value (e.g., whether a message involves buying/selling, policy/law, and cancer-related communication). Tweets will be obtained directly from Twitter using software we developed that leverages a comprehensive list of Twitter-optimized search strings related to NTPs. Second, we will statistically determine what message characteristics (e.g., the presence of certain words, punctuation, and/or structures) are most strongly associated with each of the coded variables for each search string. Using this information, we will create specialized Machine Learning (ML) algorithms based on state-of-the-art methods from Natural Language Processing (NLP) to automatically assess and categorize future Twitter data. Third, we will use this information to provide automatic assessment of current and future streaming data. Time series analyses using seasonal Auto-Regressive Integrated Moving Averages (ARIMA) will determine if there are significant changes over time in volume of messaging related to each specific coded variables of interest. Trends will be examined at the daily, weekly, and monthly level, because each of these levels is potentially valuable for intervention. To maximize the translational value of this project, we will partner with public health department stakeholders who are experts in streamlining dissemination of actionable trends data. In summary, this project will substantially advance our understanding of representations of NTPs on social media—as well as our ability to conduct automated surveillance and analysis of this content. This project will result in important and concrete deliverables, including open-source algorithms for future researchers and processes to quickly disseminate actionable data for tailoring community- level interventions. For this project, we gathered a team of public health researchers and computer scientists to leverage the power of Twitter as a novel surveillance tool to better understand communication about nicotine and tobacco products (NTPs) and related messages about cancer and cancer prevention. We will gather a random sample of Twitter messages (“tweets”) related to NTPs and examine them in depth and use this information to create specialized computer algorithms that can automatically categorize future Twitter data. Then, we will examine changes over time related to attitudes towards and interest in NTPs, as well as cancer-related discussion around various NTPs, which will dramatically improve our ability to better understand Twitter as a tool for this type of surveillance.",Leveraging Twitter to monitor nicotine and tobacco-related cancer communication,9656981,R01CA225773,"['Adolescent', 'Affect', 'Alcohol or Other Drugs use', 'Algorithms', 'Attitude', 'Behavioral', 'Behavioral Sciences', 'Cancer Control', 'Categories', 'Characteristics', 'Cigarette', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Computers', 'County', 'Data', 'Disease Outbreaks', 'Electronic cigarette', 'Epidemiologic Methods', 'Event', 'Food', 'Football game', 'Future', 'Gold', 'Health', 'Health Care Costs', 'Individual', 'Influenza A Virus, H1N1 Subtype', 'Intervention', 'Laws', 'Linguistics', 'Literature', 'Malignant Neoplasms', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Nicotine', 'Outcome', 'Pattern', 'Policies', 'Privacy', 'Process', 'Public Health', 'Public Opinion', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Scientist', 'Security', 'Specificity', 'Stream', 'Structure', 'Techniques', 'Testing', 'Time', 'Time Series Analysis', 'Tobacco', 'Tobacco use', 'Tobacco-Related Carcinoma', 'Twitter', 'Work', 'automated analysis', 'base', 'biomedical informatics', 'cancer prevention', 'computer program', 'computer science', 'computerized tools', 'ethnic minority population', 'geographic difference', 'hookah', 'improved', 'influenza outbreak', 'interest', 'machine learning algorithm', 'mortality', 'multidisciplinary', 'nicotine use', 'novel', 'open source', 'phrases', 'prospective', 'racial minority', 'social', 'social media', 'software development', 'statistics', 'time use', 'tobacco products', 'tool', 'trend', 'vaping', 'young adult']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2019,431185,-0.0041078332516917265
"An Individualized Vocabulary Intervention for Dual Language Learners Project Summary/Abstract The goal of this proposed project is to examine the feasibility of an individualized vocabulary intervention program for preschool dual language learners (DLL) from low socioeconomic (SES) backgrounds. Children who grow up in low SES and language minority homes (L1) and learn English (L2) as a second language in school settings are likely to be at risk for reading difficulties and poor academic performance (e.g., August et al., 2006). In order to serve the particular needs of DLLs from diverse backgrounds, scientific evidence is critically needed about the intervention strategies for these preschoolers. In this proposed study, we examine the feasibility of using machine learning methods to generate individually tailored interventions for low SES dual language learners who learn two typologically different languages, Cantonese (L1) and English (L2). Two important strategies will be used in this study. First, a computation model will be built to predict and select appropriate bilingual target words for individual DLLs. Second, this intervention will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps. There are two specific aims in this proposed study: 1. Model normative lexical development in Cantonese-English DLLs. We will leverage  data previously collected by Dr. Kan on Cantonese-English vocabulary development at  Head Start Centers, and computational models of typical lexical development in monolingual  English speakers, to build a computational model of typical bilingual lexical development in  Cantonese-English dual language learners. 2. Evaluate the feasibility and effectiveness of a model-based individualized vocabulary  intervention program. We will use the computational model to make individual level target  word recommendations for 200 Cantonese-English DLLs, and work with teachers at 8 Head  Start centers to integrate the recommendations into their existing curriculum. The goal of this project is to examine the feasibility and effectiveness of using machine learning methods to develop an individualized, personalized vocabulary intervention programs for preschool dual language learners from low socioeconomic backgrounds. The individualized intervention program for each child will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps.",An Individualized Vocabulary Intervention for Dual Language Learners,9771334,R21HD092837,"['Address', 'Child', 'Computer Simulation', 'Data', 'Development', 'Educational Curriculum', 'Effectiveness', 'Exposure to', 'Face', 'Family', 'Goals', 'Head Start Program', 'Home environment', 'Individual', 'Intervention', 'Justice', 'Knowledge', 'Language', 'Learning', 'Linguistics', 'Machine Learning', 'Methods', 'Minority', 'Modeling', 'Nursery Schools', 'Performance', 'Preventive', 'Recommendation', 'Risk', 'Schools', 'Testing', 'Use Effectiveness', 'Vocabulary', 'Work', 'base', 'bilingualism', 'design', 'follow-up', 'intervention program', 'kindergarten', 'learning strategy', 'lexical', 'low socioeconomic status', 'peer', 'post intervention', 'programs', 'reading difficulties', 'skills', 'socioeconomics', 'teacher']",NICHD,UNIVERSITY OF COLORADO,R21,2019,186473,-0.02461967778418482
"Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria Project Summary/Abstract Fungal and bacterial pathogens are a major threat to human health. Few therapeutics exist to treat fungal infections while bacteria are becoming increasingly resistant to existing therapeutics. Humans have been using natural products to treat infections for thousands of years, long before the causal agents of infection were understood. Natural products have continued to be used as therapeutics in the modern age of medicine. Rates of rediscovery of known natural products have increased in traditional sources of natural products, such as soil bacteria. Recently, symbiotic Actinobacteria from insect agricultural systems have been recognized as a promising source of bioactive compounds, especially antifungal agents. These bacteria often produce natural products that defend an insect’s fungal crop from pathogenic fungus. The work proposed here will use chemical biology approaches such as phenotypic interaction screens, genomics, and a new bioinformatics approach to systematically search for bioactive natural products produced by Actinobacteria symbionts and other organisms in insect agricultural systems. The first part of this proposal focuses on using existing techniques to identify new bioactive natural products. Phenotypic interaction screens can identify bioactive natural products by determining if a symbiotic bacteria produces a natural product that inhibits the growth of a fungal pathogen and vice-versa. We will then use genomic sequencing, bioinformatics, and heterologous expression to identify and characterize biosynthetic gene clusters (BGCs) that are not expressed in the phenotypic interaction screens. The second part of the proposed work involves the use of a new bioinformatics technique to identify interesting bioactive natural products. Existing bioinformatics techniques identify BGCs and predict the most likely chemical structure of the corresponding natural product. However, they do not conclude anything concerning the functional role that the natural product plays. The technique developed here will use machine learning to predict the function that the natural product fulfills in the ecological context of the organism. This algorithm will facilitate the identification of bioactive natural products with therapeutically relevant functions. Project Narrative Fungal infections are an underappreciated threat to human health with high mortality rates and few effective therapeutic agents for treatment. Symbiotic Actinobacteria from insect agricultural systems are a promising source of antifungal agents since they often produce natural products with antifungal activity protecting an insect’s fungal crop from pathogenic fungus. The work proposed here will use phenotypic interaction screens, genome sequencing, and the development of a novel bioinformatics method to systematically mine Actinobacteria for antifungal and antibacterial products – leading to the discovery of new bioactive small molecules along with a deeper understanding of how natural products mediate the interaction between species in insect agricultural systems.",Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria,9716392,F32GM128267,"['Actinobacteria class', 'Age', 'Agriculture', 'Algorithms', 'Anti-Bacterial Agents', 'Antibiotics', 'Antifungal Agents', 'Ants', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bioinformatics', 'Biological Assay', 'Biology', 'Breathing', 'Chemical Structure', 'Chemicals', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Data Set', 'Development', 'Ecosystem', 'Gene Cluster', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Infection', 'Insecta', 'Learning', 'Life', 'Literature', 'Machine Learning', 'Mediating', 'Medicine', 'Methods', 'Mining', 'Modernization', 'Molecular Structure', 'Mycoses', 'Natural Products', 'Organism', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Public Health', 'Resistance', 'Role', 'Soil', 'Source', 'Structure', 'System', 'Techniques', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'Validation', 'Work', 'base', 'bioactive natural products', 'drug discovery', 'fungus', 'genetic information', 'genome sequencing', 'human disease', 'machine learning algorithm', 'mortality', 'novel', 'pathogen', 'pathogenic bacteria', 'pathogenic fungus', 'post-doctoral training', 'prediction algorithm', 'small molecule', 'symbiont']",NIGMS,HARVARD MEDICAL SCHOOL,F32,2019,61226,-0.001956418254996384
"Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia Project Summary/Abstract Aphasia is an impairment of language that is a common consequence of stroke and has serious negative effects on health and well-being. Aphasia diagnosis continues to be organized around a 19th century model of the neural basis of language, but cognitive neuroscience research over the last 15-20 years has converged to a very different model of the cognitive and neural organization of spoken language. This contemporary model provides a precise computational account of the sub-systems that support spoken language, but does not explain how those sub-systems produce functional communication – the outcome that is most important to people with aphasia and to clinicians. The long-term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information. The overall objective of this application is to determine the relationships between spoken functional communication impairments of language sub-systems, and neuroanatomical disruption in chronic post-stroke aphasia. The overall project is divided into three specific aims: (1) Determine how spoken functional communication is related to deficits in language sub-systems. We will test how the three key language sub-systems – semantics, phonology, and sentence planning – are related to functional communication in a large sample of individuals with post-stroke aphasia. (2) Identify the lesion correlates of spoken functional communication deficits using lesion-symptom mapping. We will conduct the first LSM study of spoken functional communication using multimodal neuroimaging and machine learning tools to discover robust lesion correlates of spoken functional communication. (3) Develop a prediction model of chronic language sub-system and functional communication deficits based on acute lesion data. Routine clinical neuroimaging data collected in the acute stage (48-72 hours after stroke) will be used to build and evaluate a prediction model of chronic deficits in language sub- systems and functional communication. Upon completion of this project, we will have determined how behavioral deficits and lesion patterns are related to functional communication deficits, and developed a prediction model of such deficits based on acute-stage clinical neuroimaging. This integration of psycholinguistics, neuroanatomy, and functional communication will provide theory-informed, clinically-relevant predictions of communication deficits. This project addresses NIDCD Strategic Priority Area 3 (Improving Diagnosis, Treatment, and Prevention) by developing a neural biomarker of objective diagnosis and prognosis for acquired language impairments. Project Narrative This project will integrate investigate how the cognitive and neural sub-systems that support spoken language work together to allow speakers with language deficits to convey their message. The studies apply machine learning tools to behavioral assessments, neuroimaging, and measures of functional communication in order to reveal how they are related. The long- term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information.",Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia,9738055,R01DC017137,"['Acute', 'Address', 'Age', 'Aphasia', 'Area', 'Behavior assessment', 'Behavioral', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communications Media', 'Data', 'Diagnosis', 'Financial compensation', 'Gestures', 'Goals', 'Health', 'Hour', 'Impairment', 'Individual', 'Intuition', 'Language', 'Language Disorders', 'Lesion', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Neuroanatomy', 'Neurosciences Research', 'Outcome', 'Pattern', 'Personal Satisfaction', 'Predictive Factor', 'Prevention', 'Psycholinguistics', 'Quality of life', 'Recovery', 'Recovery of Function', 'Sampling', 'Science', 'Semantics', 'Severities', 'Social Interaction', 'Speech', 'Stroke', 'Structure', 'Support System', 'Symptoms', 'System', 'Testing', 'Work', 'acute stroke', 'aphasia recovery', 'base', 'clinically relevant', 'cognitive neuroscience', 'cost', 'improved', 'language impairment', 'multimodality', 'negative affect', 'neural model', 'neuroimaging', 'outcome forecast', 'personalized medicine', 'phonology', 'post stroke', 'predictive modeling', 'prognostic tool', 'relating to nervous system', 'stroke survivor', 'stroke-induced aphasia', 'theories', 'tool']",NIDCD,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2019,303944,-0.04074289427439861
"Exploring the evolving relationship between tobacco, marijuana and e-cigarettes Abstract The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana products (respectively). In order to understand this changing landscape we need new, ﬂexible, and responsive research methods capable of rapidly providing insights into product initiation patterns, use patterns, and cessation strategies. Social media — here deﬁned as including internet discussion forums — provides a ready-made source of abundant, naturalistic, longitudinal, publicly accessible, ﬁrst-person narratives with which to understand health behaviours and attitudes. We propose to use a combination of qualitative methods and automated natural language processing techniques to investigate online discussion forums devoted to tobacco, marijuana, and e-cigarettes in order to understand user trajectories through the three product categories. PROJECT NARRATIVE The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana (respectively). In order to make sense of this rapidly changing landscape, we need new, ﬂexible, and responsive research methods capable of providing insights into tobacco, marijuana, and e- cigarette product use patterns. We propose to use a combination of qualitative and automated natural language processing techniques to investigate online discussion forums related to tobacco, marijuana, and e-cigarettes in order to better understand user trajectories through these different product classes.","Exploring the evolving relationship between tobacco, marijuana and e-cigarettes",9788381,R21DA043775,"['Adolescent and Young Adult', 'Adult', 'Age', 'Algorithms', 'Attitude to Health', 'Categories', 'Chronic Bronchitis', 'Code', 'Consumption', 'Data', 'Data Science', 'Devices', 'Educational Status', 'Electronic cigarette', 'Health', 'Health behavior', 'High School Student', 'Individual', 'Internet', 'Manuals', 'Marijuana', 'Modeling', 'Multiple Marriages', 'Natural Language Processing', 'Pattern', 'Persons', 'Population', 'Qualitative Methods', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'Role', 'Sampling', 'Smoking', 'Source', 'Surgeon', 'Techniques', 'Therapeutic', 'Tobacco', 'Tobacco use', 'Training', 'Work', 'base', 'cigarette smoking', 'combustible cigarette', 'electronic cigarette use', 'flexibility', 'high school', 'innovation', 'insight', 'man', 'marijuana use', 'nicotine replacement', 'smoking cessation', 'social media']",NIDA,UNIVERSITY OF UTAH,R21,2019,225147,0.029035085132531273
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9731439,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2019,39939,-0.01379878569711056
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9670145,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'medication safety', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke therapy', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2019,163080,0.004358534786618019
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9803507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Simulation', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'learning strategy', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2019,334599,-0.06517355351281684
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability ﻿    DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9750002,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2019,234158,0.03528383659148018
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9674437,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,557010,-0.0235616654882302
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9665255,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Infrastructure', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,461012,-0.0010828404437110153
"Collaborative Research: Statistical algorithms for anomaly  detection and patterns recognition in patient care and safety event reports     Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. Numerous healthcare providers have adopted these systems, which provide a framework for healthcare provlder staff to report patient safety events. Public databases like MAUDE and VAERS have also been created to collect and trend safety events across healthcare systems. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter ls not constrained to limited categories or selection options and is able to freely descrlbe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) ldentifylng document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. An important advantage of our research team is the involvement of healthcare domain experts and access to frontline staff, and we will leverage this strength to develop our algorithms. A key feature of our work is the generalizability of our methods, which will be applicable to biomedical documents arising across a remarkable variety of areas, such as patient safety and equipment malfunction reports, electronic health records, adverse drug or vaccine reports, etc. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. Estimates of preventable adverse events in healthcare are staggering, despite the frequently cited Institute of Medicine (IOM) report that first brought attention to the problem over ten years ago. Identifying temporal trends and patterns in the data is particularly important to improving patient safety and patient care. Using our algorithms to effectively analyze documents from reporting systems has the potential to dramatically improve the safety and quality of care by exposing possible weaknesses in the care process.",Collaborative Research: Statistical algorithms for anomaly  detection and patterns recognition in patient care and safety event reports    ,9914443,R01LM013309,"['Address', 'Adopted', 'Adverse event', 'Algorithms', 'Area', 'Attention', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Deterioration', 'Electronic Health Record', 'Equipment Malfunction', 'Event', 'Goals', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Institute of Medicine (U.S.)', 'Instruction', 'Interest Group', 'Intervention', 'Lead', 'Medical Errors', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Process', 'Quality of Care', 'Report (document)', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'Structure', 'System', 'Text', 'Time', 'Time trend', 'United States', 'Vaccines', 'Work', 'adverse outcome', 'hazard', 'improved', 'novel', 'open source', 'patient safety', 'spatiotemporal', 'trend']",NLM,VIRGINIA POLYTECHNIC INST AND ST UNIV,R01,2019,279001,0.01405276839005004
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status –While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9937918,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Database Management Systems', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Serious Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'risk prediction model', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2019,97055,0.0317248466253714
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status –While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9637319,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Database Management Systems', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Serious Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'risk prediction model', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2019,619389,0.0317248466253714
"Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods No abstract available Narrative Prescription Medication (PM) abuse is a major epidemic in the United States, and monitoring and studying the characteristics of the PM abuse problem requires the development of novel approaches. Social media encapsulates an abundance of data about PM abuse from different demographics, but extracting that data and converting it to knowledge requires advanced natural language processing and data-centric artificial intelligence systems. Our proposed social media mining framework will automate the process of big data to knowledge conversion for PM abuse, providing crucial insights to toxicologists about targeted populations and enabling the future development of directed intervention strategies.",Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods,10001871,R01DA046619,[' '],NIDA,EMORY UNIVERSITY,R01,2019,347317,-0.02712116619647307
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9650545,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Infrastructure', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Text Messaging', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2019,655251,-0.02317514486991191
"Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign Project Summary/Abstract Written The objective of the proposed research is to reduce the patient safety hazards associated with electronic medication administration records (eMARs) by, (1) understanding current usability and safety gaps, and (2) creating design and development documents, wireframes, and prototypes to serve as the foundation for future eMARs that will eliminate these gaps. In particular, we focus on communication and information flow challenges between nurses, pharmacists, and physicians during medication administration and use of the eMAR. The proposed research is in direct response to special emphasis notice (NOT-HS-16-009). We will develop a broad understanding of usability and safety hazards associated with eMARs by analyzing a large dataset of 1.7 million patient safety event reports and detailed medication error related narratives. We will then conduct heuristic analyses of current eMARs, and interviews and observations of physicians, nurses, and pharmacists. These data will serve to inform the development of eMAR design documents, wireframes, and prototypes as the foundation for future development. This project utilizes the extensive expertise of the research team in human factors and safety science, health information technology (health IT), informatics, and data science. Our research team includes physicians, nurses, pharmacists, and human factors engineers, and experts in natural language processing. In addition, our partnerships include a patient safety organization and a health IT vendor. The proposal addresses fundamental aspects of the call for proposals by providing new insights on the safety of health IT and improves current practices by developing use cases and new prototypes for immediate use by healthIT vendors. Contributions from this research will include a fundamental understanding of the role of health IT during medication administration with a focus on communication and information flow, design, development and testing documents for vendors and providers, and eMAR wireframes and prototypes to improve development. Our research will also provide organizations like the Office of the National Coordinator with medication related test scenarios to assess current health IT systems. Project Narrative This project is relevant to public health because it applies the sciences of human factors and informatics to improve the usability and safety of the electronic medication administration records (eMARs), which will ultimately improve patient care. Patient safety event report data will be analyzed to identify usability and safety hazards in eMARs, and interviews and observations will be conducted to identify clinician needs. Based on this knowledge eMAR design documents, wireframes, and prototypes will be developed, tested, and disseminated with the goal of improving communication and information flow to reduce medication related errors.",Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign,9731456,R01HS025136,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2019,399999,0.0406343353391531
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9445485,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'patient subsets', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'readmission risk', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,376490,0.044858714187790825
"Improving Specialty Care Delivery in the Safety Net with Natural Language Processing Project Summary  Safety net providers treat a substantial share of socioeconomically vulnerable patients in their communities, but struggle to provide timely access to high quality specialty care for their patients. Delayed access to specialty care is associated with worse health outcomes and potentially contributes to health disparities across socioeconomic groups. Given their limited resources, safety net providers must seek creative approaches to improve specialty access. However, to choose what programs to implement, safety net providers need to understand the specialty care needs of their populations. Fortunately, the adoption of eConsult systems by safety net providers across the US provides a valuable opportunity to systematically measure patterns of specialty care referrals for minority, underserved populations.  In this project, we propose using state-of-the-art methods in machine learning and natural language processing (NLP) to help safety net providers extract actionable, population wide data from their electronic consultation systems. We will do this in partnership with three of the most prominent safety net health systems in the US in Los Angeles, San Francisco and New York City. Using specialty request databases from our collaborators, we will build NLP systems to automatically classify specialty requests along two dimensions: the “clinical issue” motivating the request (e.g., chest pain), and the “question type” (e.g., request for a procedure, help with medication management). This automated classification of electronic specialty requests can enable identification of promising targets for interventions to improve specialty access and quality of care.  After developing these NLP systems, we will analyze >1 million specialty requests to describe trends in how safety net patients are referred to specialists and examine variation in referral patterns by clinic and individual provider. The goal is to identify the most impactful opportunities to improve specialty access and quality. For example, a high rate of referrals for esophageal reflux, which most PCPs can treat on their own with specialist guidance, could lead to new treatment algorithms, potentially reducing the need for these requests and improving access for other patients.  This proposal is a “high-risk high-reward” project that creates new research tools to identify and evaluate data-driven interventions to improve specialty care delivery for underserved populations. Project Narrative Access to timely, high-quality specialty care is a fundamental component of a well-functioning health system, yet safety net health care providers face persistent challenges delivering such care. Quality improvement efforts to improve specialty access have been thwarted in part because safety net providers lack the data to understand a basic question – why patients are referred for specialty care. Taking advantage of the growing use of electronic specialty referral systems by safety net providers, we propose using natural language processing to conduct automated analysis and classification of specialty requests in safety net populations, which will enable the design of targeted interventions to improve specialty care access and delivery.",Improving Specialty Care Delivery in the Safety Net with Natural Language Processing,9600732,R21MD012693,"['Acute', 'Adopted', 'Adoption', 'Algorithms', 'Caring', 'Chest Pain', 'Chronic Kidney Failure', 'Classification', 'Clinic', 'Clinical', 'Communities', 'Consultations', 'County', 'Data', 'Data Set', 'Databases', 'Education', 'Epidemiology', 'Face', 'Federally Qualified Health Center', 'Gastroesophageal reflux disease', 'Goals', 'Health', 'Health Personnel', 'Health Services', 'Health Services Accessibility', 'Health system', 'Heart failure', 'Hospitals', 'Improve Access', 'Individual', 'Intervention', 'Lead', 'Los Angeles', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Education', 'Medical center', 'Medication Management', 'Methods', 'Minority', 'Morbidity - disease rate', 'Natural Language Processing', 'New York City', 'Online Systems', 'Ophthalmology', 'Outcome', 'Patients', 'Pattern', 'Play', 'Population', 'Primary Care Physician', 'Procedures', 'Provider', 'Public Hospitals', 'Quality of Care', 'Research', 'Resources', 'Retinal Diseases', 'Role', 'San Francisco', 'Specialist', 'System', 'Taxonomy', 'Telemedicine', 'Text', 'Time', 'Transplantation', 'Triage', 'Underserved Population', 'Variant', 'Visit', 'care delivery', 'design', 'diabetic', 'disease classification', 'ethnic minority population', 'follow-up', 'health disparity', 'high reward', 'high risk', 'improved', 'medical specialties', 'medically underserved', 'minority communities', 'mortality', 'performance tests', 'programs', 'racial and ethnic', 'safety net', 'screening', 'socioeconomic disadvantage', 'socioeconomics', 'tool', 'trend', 'two-dimensional']",NIMHD,BOSTON CHILDREN'S HOSPITAL,R21,2018,278902,0.013190330471263334
"Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods Project Summary The problem of prescription medication (PM) abuse has reached epidemic proportions in the United States. According to a 2014 report by the Director of the National Institute on Drug Abuse (NIDA), an estimated 52 million people, have been involved in the non-medical use of PMs— a significant portion of which can be classified as abuse. PMs that are commonly abused include opioids, central nervous system depressants and stimulants, and the consequences of their abuse may be severe. Increases in PM misuse and abuse over the last 15 years have resulted in increased emergency department visits, rates of addiction and overdose deaths. Due to the rapidly escalating morbidity and mortality, it is now receiving national attention. The opioid crisis, which has its root in opioid-based PM abuse, has been declared a national emergency by the president of the United States. Despite the problems associated with PM abuse, surveillance programs such as prescription drug monitoring programs (PDMPs) are inadequate and suffer from numerous shortcomings, thus limiting their usefulness in real life. Studies evaluating the long-term effects of distinct classes of PMs on cohorts of abusers are scarce and expensive to conduct. To better characterize the problem and to monitor it in real-time, new sources of information need to be identified and novel monitoring techniques need to be developed. To address these problems, our project aims to utilize social media data for performing toxicovigilance. Social media encapsulates an abundance of knowledge about PM abuse and the abusers in the form of noisy natural language text. At the heart of the proposed approach is a machine learning system that can automatically distinguish between `abuse' and `non-abuse' indicating user posts collected from social media. Using this classification system, users will be categorized into multiple groups—(i) abusers, (ii) medical users and (iii) non users. The developed system will collect longitudinal data for users exposed the selected PMs via periodic collection of their publicly available posts/discussions and automatically categorize them based on age, gender and additional demographic feature, when possible. This will enable the conducting of observational studies on targeted cohorts, involving hundreds of thousands of cohort members. The cohort studies will focus on analyzing the transition rates from medical use to abuse for distinct PMs and transition rates from abuse of PMs to illicit analogs. Implementation of this data-centric framework, which will be open source, will revolutionize the mechanism by which PM abuse monitoring is performed and enable the future development of intervention strategies targeted towards specific cohorts, at the most effective time periods. Narrative Prescription Medication (PM) abuse is a major epidemic in the United States, and monitoring and studying the characteristics of the PM abuse problem requires the development of novel approaches. Social media encapsulates an abundance of data about PM abuse from different demographics, but extracting that data and converting it to knowledge requires advanced natural language processing and data-centric artificial intelligence systems. Our proposed social media mining framework will automate the process of big data to knowledge conversion for PM abuse, providing crucial insights to toxicologists about targeted populations and enabling the future development of directed intervention strategies.",Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods,9577760,R01DA046619,"['Adderall', 'Address', 'Affect', 'Age', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Behavior Therapy', 'Benzodiazepines', 'Big Data', 'Big Data to Knowledge', 'Categories', 'Central Nervous System Depressants', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Cohort Studies', 'Collection', 'Communities', 'Control Groups', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Drug abuse', 'Emergency Situation', 'Emergency department visit', 'Encapsulated', 'Epidemic', 'Event', 'Exposure to', 'Fentanyl', 'Forensic Medicine', 'Future', 'Gender', 'Geographic Locations', 'Goals', 'Guidelines', 'Health', 'Health Professional', 'Heart', 'Heroin', 'Hospitalization', 'Individual', 'Ingestion', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Long-Term Effects', 'Machine Learning', 'Manuals', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'National Institute of Drug Abuse', 'Natural History', 'Natural Language Processing', 'Observational Study', 'Occupations', 'Opioid', 'Outcome', 'Overdose', 'Oxycodone', 'Patient Self-Report', 'Pattern', 'Percocet', 'Periodicity', 'Pharmaceutical Preparations', 'Pilot Projects', 'Plant Roots', 'Population', 'Population Characteristics', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Infrastructure', 'Schools', 'Social Impacts', 'Source', 'Supervision', 'Surveillance Program', 'Surveys', 'System', 'Target Populations', 'Techniques', 'Text', 'Time', 'TimeLine', 'Training', 'United States', 'Variant', 'Vicodin', 'Work', 'addiction', 'adverse outcome', 'age group', 'analog', 'base', 'cohort', 'deep neural network', 'demographics', 'design', 'drug misuse', 'experimental group', 'innovation', 'insight', 'interest', 'intervention program', 'learning strategy', 'member', 'misuse of prescription only drugs', 'mortality', 'natural language', 'nonmedical use', 'novel', 'novel strategies', 'open source', 'opioid epidemic', 'overdose death', 'prescription drug abuse', 'prescription monitoring program', 'quetiapine', 'social media', 'spelling', 'study characteristics', 'therapy development']",NIDA,UNIVERSITY OF PENNSYLVANIA,R01,2018,402500,0.013406538095068744
"Leveraging Twitter to monitor nicotine and tobacco-related cancer communication Patterns in Twitter data have revolutionized understanding of public health events such as influenza outbreaks. While researchers have begun to examine messaging related to substance use on Twitter, this project will strengthen the use of Twitter as an infoveillance tool to more rigorously examine nicotine, tobacco, and cancer- related communication. Twitter is particularly suited to this work because its users are commonly adolescents, young adults, and racial and ethnic minorities, all of whom are at increased risk for nicotine and tobacco product (NTP) use and related health consequences. Additionally, due to the openness of the platform, searches are replicable and transparent, enabling large-scale systematic research. Therefore, our multidisciplinary team of experts in diverse relevant fields—including public health, behavioral science, computational linguistics, computer science, biomedical informatics, and information privacy and security—will build upon our previous research to develop and validate structured algorithms providing automated surveillance of Twitter’s multifaceted and continuously evolving information related to NTPs. First, we will qualitatively assess a stratified random sample of relevant NTP-related tweets for specific coded variables, such as the message’s primary sentiment and other key information of potential value (e.g., whether a message involves buying/selling, policy/law, and cancer-related communication). Tweets will be obtained directly from Twitter using software we developed that leverages a comprehensive list of Twitter-optimized search strings related to NTPs. Second, we will statistically determine what message characteristics (e.g., the presence of certain words, punctuation, and/or structures) are most strongly associated with each of the coded variables for each search string. Using this information, we will create specialized Machine Learning (ML) algorithms based on state-of-the-art methods from Natural Language Processing (NLP) to automatically assess and categorize future Twitter data. Third, we will use this information to provide automatic assessment of current and future streaming data. Time series analyses using seasonal Auto-Regressive Integrated Moving Averages (ARIMA) will determine if there are significant changes over time in volume of messaging related to each specific coded variables of interest. Trends will be examined at the daily, weekly, and monthly level, because each of these levels is potentially valuable for intervention. To maximize the translational value of this project, we will partner with public health department stakeholders who are experts in streamlining dissemination of actionable trends data. In summary, this project will substantially advance our understanding of representations of NTPs on social media—as well as our ability to conduct automated surveillance and analysis of this content. This project will result in important and concrete deliverables, including open-source algorithms for future researchers and processes to quickly disseminate actionable data for tailoring community- level interventions. For this project, we gathered a team of public health researchers and computer scientists to leverage the power of Twitter as a novel surveillance tool to better understand communication about nicotine and tobacco products (NTPs) and related messages about cancer and cancer prevention. We will gather a random sample of Twitter messages (“tweets”) related to NTPs and examine them in depth and use this information to create specialized computer algorithms that can automatically categorize future Twitter data. Then, we will examine changes over time related to attitudes towards and interest in NTPs, as well as cancer-related discussion around various NTPs, which will dramatically improve our ability to better understand Twitter as a tool for this type of surveillance.",Leveraging Twitter to monitor nicotine and tobacco-related cancer communication,9503469,R01CA225773,"['Adolescent', 'Affect', 'Alcohol or Other Drugs use', 'Algorithms', 'Attitude', 'Behavioral', 'Behavioral Sciences', 'Cancer Control', 'Categories', 'Characteristics', 'Cigarette', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Computers', 'County', 'Data', 'Disease Outbreaks', 'Electronic cigarette', 'Epidemiologic Methods', 'Event', 'Food', 'Football game', 'Future', 'Gold', 'Health', 'Health Care Costs', 'Individual', 'Influenza A Virus, H1N1 Subtype', 'Intervention', 'Laws', 'Linguistics', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Nicotine', 'Outcome', 'Pattern', 'Policies', 'Privacy', 'Process', 'Public Health', 'Public Opinion', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Scientist', 'Security', 'Specificity', 'Stream', 'Structure', 'Techniques', 'Testing', 'Time', 'Time Series Analysis', 'Tobacco', 'Tobacco use', 'Tobacco-Related Carcinoma', 'Work', 'base', 'biomedical informatics', 'cancer prevention', 'computer program', 'computer science', 'computerized tools', 'ethnic minority population', 'geographic difference', 'hookah', 'improved', 'influenza outbreak', 'interest', 'mortality', 'multidisciplinary', 'nicotine use', 'novel', 'open source', 'phrases', 'prospective', 'racial and ethnic', 'racial minority', 'social', 'social media', 'software development', 'statistics', 'time use', 'tool', 'trend', 'vaping', 'young adult']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2018,505649,-0.0041078332516917265
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9543557,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,264277,-0.00586639813089011
"Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance PROJECT SUMMARY The Center for Medicare and Medicaid Services Quality Payment Program is designed to motivate healthcare providers to adhere to best practices in clinical healthcare and patient safety. Unfortunately, extracting quality measures data from the clinical record is burdensome and as such, participation among clinical healthcare providers is suboptimal. Our aim is to develop a system to facilitate automatic extraction of quality data. This will reduce the burden of data collection and help remove the barrier to participation that keeps more providers from participating in the program. The proposed project, titled “Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance”, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. We envision this to be an effective research partnership that leverages the complementary assets of SaferMD, a small business unit, and the University of Michigan, a non-profit research institution, to develop and evaluate a prototype tool to extract clinical quality measures data, and increase participation in the Quality Payment Program. PROJECT NARRATIVE The proposed project, titled “Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance”, aims to develop novel natural language processing methods to recognize key elements from the clinical notes to enable proper documentation of meaningful use and compliance with quality payment. The project will develop algorithms to identify fields relevant for quality measures and develop tools to extract and analyze these data elements from large sets of radiology reports. Finally, the proposed work will initiate the extracted measures into existing quality service offerings by SaferMD. Successful completion of this project will advance the tools available for CMS clients to achieve higher adherence and compliance to the quality payment initiatives and help public health officials and policy developers advance the meaningful use of electronic health records.",Using advanced natural language processing to facilitate documentation of meaningful use and quality payment compliance,9677579,R41LM013050,"['Address', 'Adherence', 'Algorithms', 'Benchmarking', 'Businesses', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Development', 'Disease', 'Documentation', 'Electronic Health Record', 'Elements', 'Experimental Models', 'Funding', 'Goals', 'Guidelines', 'Health Personnel', 'Healthcare', 'Human', 'Incentives', 'Institution', 'Label', 'Leadership', 'Manuals', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physicians', 'Policies', 'Procedures', 'Process', 'Production', 'Provider', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Role', 'Running', 'Semantics', 'Services', 'System', 'Techniques', 'Technology', 'Telephone', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Work', 'analytical tool', 'base', 'clinical practice', 'clinically relevant', 'computerized data processing', 'dashboard', 'deep neural network', 'design', 'improved', 'interest', 'novel', 'novel strategies', 'patient safety', 'payment', 'programs', 'prototype', 'success', 'technological innovation', 'tool']",NLM,"SAFERMED, LLC",R41,2018,149953,0.03591027183026011
"An Individualized Vocabulary Intervention for Dual Language Learners Project Summary/Abstract The goal of this proposed project is to examine the feasibility of an individualized vocabulary intervention program for preschool dual language learners (DLL) from low socioeconomic (SES) backgrounds. Children who grow up in low SES and language minority homes (L1) and learn English (L2) as a second language in school settings are likely to be at risk for reading difficulties and poor academic performance (e.g., August et al., 2006). In order to serve the particular needs of DLLs from diverse backgrounds, scientific evidence is critically needed about the intervention strategies for these preschoolers. In this proposed study, we examine the feasibility of using machine learning methods to generate individually tailored interventions for low SES dual language learners who learn two typologically different languages, Cantonese (L1) and English (L2). Two important strategies will be used in this study. First, a computation model will be built to predict and select appropriate bilingual target words for individual DLLs. Second, this intervention will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps. There are two specific aims in this proposed study: 1. Model normative lexical development in Cantonese-English DLLs. We will leverage  data previously collected by Dr. Kan on Cantonese-English vocabulary development at  Head Start Centers, and computational models of typical lexical development in monolingual  English speakers, to build a computational model of typical bilingual lexical development in  Cantonese-English dual language learners. 2. Evaluate the feasibility and effectiveness of a model-based individualized vocabulary  intervention program. We will use the computational model to make individual level target  word recommendations for 200 Cantonese-English DLLs, and work with teachers at 8 Head  Start centers to integrate the recommendations into their existing curriculum. The goal of this project is to examine the feasibility and effectiveness of using machine learning methods to develop an individualized, personalized vocabulary intervention programs for preschool dual language learners from low socioeconomic backgrounds. The individualized intervention program for each child will be integrated into the extant preschool curriculum, thus resulting in a potentially sustainable, scalable approach to decreasing language proficiency gaps.",An Individualized Vocabulary Intervention for Dual Language Learners,9530276,R21HD092837,"['Address', 'Child', 'Computer Simulation', 'Data', 'Development', 'Educational Curriculum', 'Effectiveness', 'Exposure to', 'Face', 'Family', 'Goals', 'Head Start Program', 'Home environment', 'Individual', 'Intervention', 'Justice', 'Knowledge', 'Language', 'Learning', 'Linguistics', 'Machine Learning', 'Methods', 'Minority', 'Modeling', 'Nursery Schools', 'Performance', 'Preventive', 'Recommendation', 'Risk', 'Schools', 'Testing', 'Use Effectiveness', 'Vocabulary', 'Work', 'base', 'bilingualism', 'design', 'follow-up', 'intervention program', 'kindergarten', 'learning strategy', 'lexical', 'low socioeconomic status', 'peer', 'post intervention', 'programs', 'reading difficulties', 'skills', 'socioeconomics', 'teacher']",NICHD,UNIVERSITY OF COLORADO,R21,2018,221909,-0.02461967778418482
NIST Assistance with NTP SR Automation NIEHS seeks advice from NIST in the areas of human language technology and natural language processing component evaluations that support the measurement of systems that automatically extract toxicology information from publications to support the complex human task of systematic review of literature. NIST is positioned to assist NIEHS building upon existing test and evaluation infrastructure through its Text Analysis Conference (TAC) program. NIST is coordinating the 2019 Systematic Review Information Extraction evaluation (SRIE 2019) task for NIEHS as part of the Retrieval Group’s Text Analysis Conference (TAC) program. This coordination includes advising NIEHS on developing annotation guidelines; advising NIEHS on dataset construction and distribution; writing guidelines for the evaluation task; developing scoring methods and supporting software; including the evaluation task as part of the TAC program and call for participation; accepting participant submissions in the evaluation; evaluating those submissions; and reporting results of the evaluation. NIST and NIH will design an evaluation task in this domain. n/a,NIST Assistance with NTP SR Automation,9794240,ES18001002,"['Advertisements', 'Area', 'Automation', 'Complex', 'Computer software', 'Data Set', 'Development', 'Evaluation', 'Guidelines', 'Human', 'Language', 'Measurement', 'National Institute of Environmental Health Sciences', 'Natural Language Processing', 'Participant', 'Positioning Attribute', 'Preparation', 'Publications', 'Reporting', 'Research', 'Research Infrastructure', 'Retrieval', 'Review Literature', 'Scoring Method', 'System', 'Technology', 'Testing', 'Text', 'Toxicology', 'United States National Institutes of Health', 'Writing', 'biomedical informatics', 'design', 'programs', 'symposium', 'systematic review']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,Y01,2018,200000,-0.009882796262459274
"Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria Project Summary/Abstract Fungal and bacterial pathogens are a major threat to human health. Few therapeutics exist to treat fungal infections while bacteria are becoming increasingly resistant to existing therapeutics. Humans have been using natural products to treat infections for thousands of years, long before the causal agents of infection were understood. Natural products have continued to be used as therapeutics in the modern age of medicine. Rates of rediscovery of known natural products have increased in traditional sources of natural products, such as soil bacteria. Recently, symbiotic Actinobacteria from insect agricultural systems have been recognized as a promising source of bioactive compounds, especially antifungal agents. These bacteria often produce natural products that defend an insect’s fungal crop from pathogenic fungus. The work proposed here will use chemical biology approaches such as phenotypic interaction screens, genomics, and a new bioinformatics approach to systematically search for bioactive natural products produced by Actinobacteria symbionts and other organisms in insect agricultural systems. The first part of this proposal focuses on using existing techniques to identify new bioactive natural products. Phenotypic interaction screens can identify bioactive natural products by determining if a symbiotic bacteria produces a natural product that inhibits the growth of a fungal pathogen and vice-versa. We will then use genomic sequencing, bioinformatics, and heterologous expression to identify and characterize biosynthetic gene clusters (BGCs) that are not expressed in the phenotypic interaction screens. The second part of the proposed work involves the use of a new bioinformatics technique to identify interesting bioactive natural products. Existing bioinformatics techniques identify BGCs and predict the most likely chemical structure of the corresponding natural product. However, they do not conclude anything concerning the functional role that the natural product plays. The technique developed here will use machine learning to predict the function that the natural product fulfills in the ecological context of the organism. This algorithm will facilitate the identification of bioactive natural products with therapeutically relevant functions. Project Narrative Fungal infections are an underappreciated threat to human health with high mortality rates and few effective therapeutic agents for treatment. Symbiotic Actinobacteria from insect agricultural systems are a promising source of antifungal agents since they often produce natural products with antifungal activity protecting an insect’s fungal crop from pathogenic fungus. The work proposed here will use phenotypic interaction screens, genome sequencing, and the development of a novel bioinformatics method to systematically mine Actinobacteria for antifungal and antibacterial products – leading to the discovery of new bioactive small molecules along with a deeper understanding of how natural products mediate the interaction between species in insect agricultural systems.",Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria,9540546,F32GM128267,"['Actinobacteria class', 'Age', 'Agriculture', 'Algorithms', 'Anti-Bacterial Agents', 'Antibiotics', 'Antifungal Agents', 'Ants', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bioinformatics', 'Biological Assay', 'Biology', 'Breathing', 'Chemical Structure', 'Chemicals', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Data Set', 'Development', 'Ecosystem', 'Gene Cluster', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Infection', 'Insecta', 'Learning', 'Life', 'Literature', 'Machine Learning', 'Mediating', 'Medicine', 'Methods', 'Mining', 'Modernization', 'Molecular Structure', 'Mycoses', 'Natural Products', 'Organism', 'Pathogenicity', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Public Health', 'Resistance', 'Role', 'Soil', 'Source', 'System', 'Techniques', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'Validation', 'Work', 'base', 'bioactive natural products', 'drug discovery', 'fungus', 'genetic information', 'genome sequencing', 'human disease', 'mortality', 'novel', 'pathogen', 'post-doctoral training', 'prediction algorithm', 'small molecule', 'symbiont']",NIGMS,HARVARD MEDICAL SCHOOL,F32,2018,58282,-0.001956418254996384
"Development of Tools for Evaluating the National Toxicology Program's Effectiveness  NIEHS funds research grants and conducts research to evaluate agents of public health concern. NIEHS has need for research and development tools for use in its research evaluations both the Division of the National Toxicology Program (DNTP) and the Division of Extramural Research and Training (DERT). These tools will enable NTP to evaluate its effectiveness across multiple stakeholder groups to determine use and ability to affect change for public health. Additionally, NTP has interests in using natural language processing for tools that can assist with information extraction from scientific publications ultimately for use in assessing potential hazards. DERT has need for categorical evaluation of its grants portfolio by extracting information and organizing them relative to outcomes and impacts. The Department of Energy’s Oak Ridge National Laboratory (ORNL) has research experience in analysis of textual information and has developed a unique publication mining capability that enable automated evaluation of scientific publications. NIEHS wants to take advantage of these ORNL capabilities for use in its research evaluations. n/a",Development of Tools for Evaluating the National Toxicology Program's Effectiveness ,9770622,ES16002001,"['Affect', 'Area', 'Bibliometrics', 'Categories', 'Computer software', 'Department of Energy', 'Effectiveness', 'Evaluation', 'Evaluation Research', 'Extramural Activities', 'Funding', 'Grant', 'Internet', 'Laboratories', 'Methods', 'Mining', 'National Institute of Environmental Health Sciences', 'National Toxicology Program', 'Natural Language Processing', 'Outcome', 'Program Effectiveness', 'Public Health', 'Publications', 'Research', 'Research Project Grants', 'Research Training', 'Retrieval', 'Scientific Evaluation', 'Techniques', 'Visual', 'experience', 'hazard', 'interest', 'research and development', 'tool', 'tool development']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,Y01,2018,380000,0.007505726625587486
"Exploring the evolving relationship between tobacco, marijuana and e-cigarettes Abstract The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana products (respectively). In order to understand this changing landscape we need new, ﬂexible, and responsive research methods capable of rapidly providing insights into product initiation patterns, use patterns, and cessation strategies. Social media — here deﬁned as including internet discussion forums — provides a ready-made source of abundant, naturalistic, longitudinal, publicly accessible, ﬁrst-person narratives with which to understand health behaviours and attitudes. We propose to use a combination of qualitative methods and automated natural language processing techniques to investigate online discussion forums devoted to tobacco, marijuana, and e-cigarettes in order to understand user trajectories through the three product categories. PROJECT NARRATIVE The relationship between marijuana, tobacco, and e-cigarettes is both rapidly changing and poorly understood, particularly in the light of recent federal and state-level regulatory changes governing the availability of e- cigarettes and marijuana (respectively). In order to make sense of this rapidly changing landscape, we need new, ﬂexible, and responsive research methods capable of providing insights into tobacco, marijuana, and e- cigarette product use patterns. We propose to use a combination of qualitative and automated natural language processing techniques to investigate online discussion forums related to tobacco, marijuana, and e-cigarettes in order to better understand user trajectories through these different product classes.","Exploring the evolving relationship between tobacco, marijuana and e-cigarettes",9530020,R21DA043775,"['Adolescent and Young Adult', 'Adult', 'Age', 'Algorithms', 'Attitude to Health', 'Categories', 'Chronic Bronchitis', 'Code', 'Data', 'Data Science', 'Devices', 'Educational Status', 'Electronic cigarette', 'Health', 'Health behavior', 'High School Student', 'Individual', 'Internet', 'Manuals', 'Marijuana', 'Modeling', 'Multiple Marriages', 'Natural Language Processing', 'Pattern', 'Persons', 'Population', 'Qualitative Methods', 'Reporting', 'Research', 'Research Methodology', 'Resources', 'Role', 'Sampling', 'Smoking', 'Source', 'Surgeon', 'Techniques', 'Therapeutic', 'Tobacco', 'Tobacco use', 'Training', 'Work', 'base', 'cigarette smoking', 'combustible cigarette', 'electronic cigarette use', 'flexibility', 'high school', 'innovation', 'insight', 'man', 'marijuana use', 'nicotine replacement', 'smoking cessation', 'social media']",NIDA,UNIVERSITY OF UTAH,R21,2018,201771,0.029035085132531273
"Evaluating the Impact of Changes in Opioid Prescribing Across Health Systems Implementing Zero Suicide This timely supplement would support our goals for the current award: An Evaluation of the National Zero Suicide Model Across Learning Healthcare Systems (U01MH114087) by capitalizing on a natural experiment, the planned the national roll-out of safety planning templates in behavioral health departments across five Kaiser Permanente regions and Henry Ford Health System in 2019. Safety planning is a highly recommended practice within the Zero Suicide (ZS) framework, but little is known about the effectiveness of the individual elements that can make up a safety plan, such as lethal means assessment, identification of supportive contacts, coping skills, warning signs, and sources of distraction. The current Zero Suicide award proposes to examine the impact of safety planning and lethal means assessment using a stepped-wedged interrupted time- series (ITS) approach, measuring each as a binary variable (e.g. safety planning did or did not occur). The ITS approach requires that some sites implement safety planning (intervention sites for safety planning), while others do not (control sites for safety planning). The proposed ITS approach is now problematic without further work for two reasons: 1) All Kaiser Permanente sites and Henry Ford have decided to uniformly implement safety planning around the same time, therefore there are no control sites 2) Without control sites, metrics that can accurately measure variation in safety planning/lethal means assessment at baseline and then longitudinally thereafter would enable our evaluation to take place, but all of the documentation lives in text- based clinical narratives. In working with our health system leads on the development of Zero Suicide metrics, we have been informed that the rate for safety planning and lethal means assessment at baseline is not zero, but the actual rate is unknown. This supplement will support development of new metrics using Natural Language Processing to determine baseline rates, from which, we can quantify the change in safety planning and lethal means assessment practice longitudinally after implementation of new safety planning templates using our Zero Suicide main award. Furthermore, we propose to take advantage of the newly implemented templates to address an important mediator of the effect of safety planning on suicide outcomes, the impact of fidelity to the new templates, which we define as quality, completeness, and level of integration with ongoing care. We propose the following three specific aims for this supplemental work: 1) Identify key terms for safety planning and lethal means assessment 1.) Develop Natural Language Processing (NLP) metrics to assess the occurrence of safety planning and lethal means assessment at three Zero Suicide sites 2) Implement NLP queries for identification of safety planning and lethal means assessment and measure baseline rates 3) Upon implementation of electronic safety planning templates in medical records, develop and implement metrics using NLP for assessing fidelity (completeness, quality, integration with care) to safety planning templates. Project Narrative: This supplement to the current award: An Evaluation of the National Zero Suicide Model Across Learning Healthcare Systems (U01MH114087) will take advantage of a national roll-out for safety planning templates in the electronic medical record across 5 Kaiser Permanente regions and Henry Ford Health System. It will support the development of innovative measures using natural language processing to efficiently quantify the baseline rates of safety planning and lethal means assessment across multiple sites, which will enable a rigorous evaluation to take place upon implementation of the new electronic templates. Furthermore, we propose to take advantage of the safety planning template roll-out by measuring fidelity (quality, completeness, and level of integration with care), because it may be an important mediator of the relationship between safety planning and suicide outcomes.",Evaluating the Impact of Changes in Opioid Prescribing Across Health Systems Implementing Zero Suicide,9676620,U01MH114087,"['Accident and Emergency department', 'Address', 'Adopted', 'Algorithms', 'Award', 'Caring', 'Clinical', 'Code', 'Colorado', 'Computerized Medical Record', 'Coping Skills', 'Country', 'Development', 'Disease', 'Documentation', 'Effectiveness', 'Elements', 'Evaluation', 'Firearms', 'Frequencies', 'Future', 'Goals', 'Health', 'Health system', 'Healthcare Systems', 'Individual', 'Institutes', 'Interruption', 'Intervention', 'Investigation', 'Learning', 'Measures', 'Mediator of activation protein', 'Medical Records', 'Mental Health', 'Mining', 'Natural Language Processing', 'Natural experiment', 'Outcome', 'Pharmaceutical Preparations', 'Predictive Value', 'Process', 'Research', 'Research Personnel', 'Safety', 'Series', 'Site', 'Source', 'Standardization', 'Suicide', 'Suicide prevention', 'System', 'Text', 'Time', 'Variant', 'Work', 'base', 'behavioral health', 'behavioral outcome', 'design', 'distraction', 'health plan', 'health record', 'improved', 'innovation', 'method development', 'prescription opioid', 'reducing suicide', 'safety practice', 'suicidal behavior', 'suicide model', 'tool']",NIMH,HENRY FORD HEALTH SYSTEM,U01,2018,262124,-0.09110407369220766
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9612777,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2018,39939,-0.01379878569711056
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9460286,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke treatment', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2018,163080,0.004358534786618019
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability ﻿    DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9535837,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2018,243172,0.03528383659148018
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9461502,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,607626,-0.0235616654882302
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9454246,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease Surveillance', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,461012,-0.0010828404437110153
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status –While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9419767,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Severe Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,619389,0.0317248466253714
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9432500,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'User-Computer Interface', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'recruit', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2018,651980,-0.02317514486991191
"Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign Project Summary/Abstract Written The objective of the proposed research is to reduce the patient safety hazards associated with electronic medication administration records (eMARs) by, (1) understanding current usability and safety gaps, and (2) creating design and development documents, wireframes, and prototypes to serve as the foundation for future eMARs that will eliminate these gaps. In particular, we focus on communication and information flow challenges between nurses, pharmacists, and physicians during medication administration and use of the eMAR. The proposed research is in direct response to special emphasis notice (NOT-HS-16-009). We will develop a broad understanding of usability and safety hazards associated with eMARs by analyzing a large dataset of 1.7 million patient safety event reports and detailed medication error related narratives. We will then conduct heuristic analyses of current eMARs, and interviews and observations of physicians, nurses, and pharmacists. These data will serve to inform the development of eMAR design documents, wireframes, and prototypes as the foundation for future development. This project utilizes the extensive expertise of the research team in human factors and safety science, health information technology (health IT), informatics, and data science. Our research team includes physicians, nurses, pharmacists, and human factors engineers, and experts in natural language processing. In addition, our partnerships include a patient safety organization and a health IT vendor. The proposal addresses fundamental aspects of the call for proposals by providing new insights on the safety of health IT and improves current practices by developing use cases and new prototypes for immediate use by healthIT vendors. Contributions from this research will include a fundamental understanding of the role of health IT during medication administration with a focus on communication and information flow, design, development and testing documents for vendors and providers, and eMAR wireframes and prototypes to improve development. Our research will also provide organizations like the Office of the National Coordinator with medication related test scenarios to assess current health IT systems. Project Narrative This project is relevant to public health because it applies the sciences of human factors and informatics to improve the usability and safety of the electronic medication administration records (eMARs), which will ultimately improve patient care. Patient safety event report data will be analyzed to identify usability and safety hazards in eMARs, and interviews and observations will be conducted to identify clinician needs. Based on this knowledge eMAR design documents, wireframes, and prototypes will be developed, tested, and disseminated with the goal of improving communication and information flow to reduce medication related errors.",Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign,9447854,R01HS025136,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2018,400000,0.0406343353391531
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9567932,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,249135,0.04622739256534773
"Developing Evidence for Safety Surveillance from Device Adverse Event Reports Title: Developing Evidence for Safety Surveillance from Device Adverse Event Reports Project Summary/Abstract Population level studies have shown that the device-based hysteroscopic sterilization was associated with increased risks of reoperation during follow-up, when compared to traditional laparoscopic sterilization. However, secondary data sources often lack the granularity to understand the nature of patient and device complications related to the device removal and additional surgery. The Manufacturer and User Facility Device Experience (MAUDE) database houses medical device reports submitted to the FDA by mandatory and voluntary reporters. These reports contain detailed information of patient and device adverse events. But due to its narrative structure, research with the reports has been limited, partially due to the restrictions of keyword search and manual review. The proposed study will innovatively apply natural language processing (NLP) to analyze MAUDE reports of device removals. NLP is a powerful tool capable of extracting information efficiently from documents such as medical notes, allowing the summarization of thousands of adverse event reports in a cost-effective way. The primary aim is to develop an NLP program to extract and summarize patient- and device-specific complications associated with device removal and additional surgeries following hysteroscopic sterilization. Secondary objective is to evaluate the impact of regulatory activities on adverse event reporting behavior and structure. The hypotheses are that the majority of reported removals were associated with device-related complications as opposed to persistent symptoms only, and that after the FDA convened a panel discussion in September 2015, adverse event reports were more likely to be submitted by mandatory reporters, with improvement in structured presentation. Adverse event reports related to device removal will be selected from the MAUDE database using keyword search first, and 1,000 reports will be annotated and used to develop and validate the NLP tool. Applying the developed NLP to all reports, extracted information will be used for the analysis, and comparisons will be made before and after September 2015. The significance of the proposed research is that it will develop a method to better utilize adverse event reports to obtain crucial device safety information supplemental to regular population-level studies. By achieving this, the long term goal is to create a useful tool for future medical device safety surveillance to understand the nature of adverse events. The immediate next step will be to use the tool to investigate device safety in other areas. The comprehension of the nature of device adverse events and the elucidation of the crucial role of regulatory activity in facilitating reliable adverse event reporting will help promote patient safety evaluation and monitoring. Project Narrative The proposed research will focus on device adverse event reports and develop a powerful tool to analyze reports to understand the nature of patient and device complications related to device removals and additional surgeries. The study will also elucidate the impact of regulatory activities on adverse event reporting. Thus, the proposed research is relevant to part of AHRQ's mission to make health care safer.",Developing Evidence for Safety Surveillance from Device Adverse Event Reports,9586941,R03HS026291,[' '],AHRQ,WEILL MEDICAL COLL OF CORNELL UNIV,R03,2018,96907,0.0052371130607531576
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions. PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.",Natural language processing for characterizing psychopathology,9254614,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Clinical stratification', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Risk stratification', 'Severities', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinically relevant', 'cohort', 'cost', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'translational scientist', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,377260,0.044858714187790825
"IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP n/a","IGF::OT::IGF  Natural Language Processing Meeting, December 8-9, 2016; POP November 4, 2016 - February 3, 2017. Labor for NLP",9581371,61201400011I,"['Natural Language Processing', 'meetings']",NCI,"SCIENTIFIC CONSULTING GROUP, INC.",N01,2017,9923,0.010347232136125317
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9365558,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Cereals', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Graph', 'Image', 'Informatics', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Models', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'learning strategy', 'molecular modeling', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2017,264299,-0.00586639813089011
"From genomics to natural language processing: A protected environment for research computing in the health science NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Health sciences researchers are often required to manage, mine, and analyze restricted patient data (Protected Health Information, PHI) to facilitate and advance their research aims. They are often required to do this without access to central information technology expertise or resources to facilitate their research aims. These researchers are often left to their own devices to “solve” their research compute and data needs and are challenged due to lack of available resources, barriers from central IT, and/or lack of knowledge of available resources. A further challenge is that “small” data sets— data that researchers could formerly handle on office resources—have morphed and grown into the big data domain through the explosion of technical advances and significant expansion in various research directions. Examples include: genomics research, image analysis, simulation, natural language processing, and mining of EMRs. Therefore, the need exists to develop a framework for managing and processing this data securely and reliably. This S10 equipment proposal is to replace the “protected environment” (PE) prototype the University of Utah’s Center for High Performance Computing (CHPC) and Department of Biomedical Informatics built six years ago and has operated since. The PE consists of both high performance computing and virtual machine (VM) components and associated storage sufficient to manage, protect and analyze HIPAA protected health information. This environment has been very successful and has grown significantly in scope. CHPC isolated this protected environment in the secured University of Utah Downtown Data Center and setup a network protected logical partition that provided research groups specific access to individual data sets. As the environment and technology developed, CHPC added additional security features such as two-factor authentication for entry and audit/monitoring. Unfortunately, the prototype has reached the point where demand is surpassing capability and all the hardware is aged and off-warranty. To give an idea of users of the virtual machine farm component, the Biomedical Informatics Core (BMIC) REDCap (Research Electronic Data Capture) environment for data collection has over 2,500 users in 1,500 projects supporting over $25M in NIH funding at the University of Utah, including support for more than 25 active NIH R-01 grants. Moreover, the HIPAA compliant protected environment was a key factor that aided passing the recent University of Utah HIPAA audit. The “protected environment” also helped the University of Utah Health Sciences Center and the BMIC justify the NCATS Center Clinical and Translational Science award (1ULTR001067). NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Project Narrative: The proposed “Protected Environment” instrument will provide research computing and data management capabilities for health sciences researchers to properly manage, secure, and analyze HIPAA regulated protected health information. The technology will not only support a large number of clinical trials, but also enable research in Human Genetics and Natural Language Processing of electronic health records.",From genomics to natural language processing: A protected environment for research computing in the health science,9274445,S10OD021644,"['Award', 'Big Data', 'Clinical Sciences', 'Data', 'Data Collection', 'Data Set', 'Devices', 'Environment', 'Equipment', 'Explosion', 'Farming environment', 'Funding', 'Genomics', 'Grant', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'High Performance Computing', 'Image Analysis', 'Individual', 'Information Technology', 'Knowledge', 'Left', 'Mining', 'Monitor', 'Natural Language Processing', 'Patients', 'Research', 'Research Personnel', 'Resources', 'Secure', 'Security', 'Technology', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Utah', 'aged', 'biomedical informatics', 'computerized data processing', 'electronic data', 'prototype', 'simulation', 'virtual']",OD,UNIVERSITY OF UTAH,S10,2017,493595,0.011102162297762074
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9294543,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'comparative effectiveness', 'effectiveness research', 'improved', 'interdisciplinary approach', 'medication compliance', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke treatment', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2017,163080,0.004358534786618019
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability ﻿    DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9322409,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2017,248917,0.03528383659148018
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9311162,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,608789,-0.0235616654882302
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status –While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9290660,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Severe Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,644888,0.0317248466253714
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk. PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9249484,R01AI117011,"['Animals', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Manuals', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'Zoonoses', 'improved', 'information model', 'interest', 'journal article', 'molecular sequence database', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2017,461012,-0.0010828404437110153
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9233069,R01DC009834,"['21 year old', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Custom', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Event-Related Potentials', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'experimental study', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'mindfulness meditation', 'multimodality', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2017,652111,-0.02317514486991191
"Neural mechanisms of auditory temporal pattern perception Project Summary/Abstract: Processing acoustic communication signals is among the most difficult, yet vital capabilities that the auditory system must achieve. These abilities lie at the heart of language and speech processing, and their success or failure can have profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, as well as improving diagnoses and treatments for learning disabilities and communication disorders such as auditory processing disorder, dyslexia, and specific language impairment. While much has been learned about the loci of language-related processing using non-invasive neuroscience techniques in humans, these techniques cannot answer how individual neurons and neural circuits implement language-relevant computations. As a result, the explicit cellular circuit-level and neuro-computational mechanisms that support acoustic communication signal processing are poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language, in particular the processing of temporal patterns within communication signals. The experiments outlined in this proposal investigate the neural mechanisms of auditory temporal pattern processing. In humans, the transition statistics between adjacent speech sounds (phonemes) can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Sensitivity to transition statistics is not exclusive to speech signals however, but reflects general auditory processes shared by many animals. In Aim 1 we investigate the categorical perception of complex auditory objects in populations of cortical neurons in an animal model, and ask how these neural representations are effected by temporal context. In addition to which elements occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Studies in Aim 2 focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. In Aim 3, we propose a basic circuit in which population level representations of auditory objects could be differentially modulated by patterning rules, and test this proposed pattern processing circuit using direct, casual manipulations. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Neural mechanisms of auditory temporal pattern perception,9527903,R56DC016408,"['Acoustics', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Biological Assay', 'Biological Models', 'Birds', 'Categories', 'Code', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computational Technique', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrophysiology (science)', 'Elements', 'Environment', 'Failure', 'Foundations', 'Goals', 'Heart', 'Human', 'Individual', 'Infant', 'Knowledge', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Link', 'Longevity', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Nuclear', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Population Dynamics', 'Process', 'Property', 'Quality of life', 'Research', 'Role', 'Services', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Structure', 'Sturnus vulgaris', 'Superior temporal gyrus', 'System', 'Systems Development', 'Techniques', 'Testing', 'Time', 'Training', 'Transition Elements', 'Work', 'auditory processing', 'bird song', 'cognitive process', 'experimental study', 'hearing impairment', 'improved', 'language processing', 'microstimulation', 'model development', 'neural circuit', 'neural patterning', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R56,2017,363607,-0.08678392875653781
"NLP to Improve Accuracy and Quality of Dictated Medical Documents ﻿    DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005). PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9352296,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2017,249995,0.006259430443487905
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9352770,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,249135,0.04622739256534773
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,9307936,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Databases', 'Disease', 'Drug Exposure', 'Drug Modelings', 'Drug toxicity', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'cost', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'genomic data', 'improved', 'longitudinal dataset', 'novel', 'open source', 'personalized medicine', 'phenotypic data', 'public health relevance', 'rapid growth', 'rare variant', 'response', 'study population', 'success', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,600474,-0.0075613908288467025
"Natural language processing for characterizing psychopathology ﻿    DESCRIPTION (provided by applicant):  Convergent genetic and epidemiologic evidence suggests the importance of understanding psychiatric illness from a dimensional rather than solely a categorical perspective. The limitations of traditional diagnostic categories motivated a major NIMH-supported effort to identify measures of psychopathology that more closely align with underlying disease biology.  At present, however, the available large clinical data sets, whether health claims, registries, or electronic health records, do not include such dimensional measures. Even with the integration of structure clinician and patient-reported outcomes, generating such cohorts could require a decade or more. Moreover, coded data does not systematically capture clinically-important concepts such as health behaviors or stressors.  While such cohorts are developed, natural language processing can facilitate the application of existing electronic health records to enable precision medicine in psychiatry. Specifically, while traditional natural language tools focus on extracting individual terms, emerging methods including those in development by the investigators allow extraction of concepts and dimensions.  The present investigation proposes to develop a toolkit for natural language processing of narrative patient notes to extract measures of psychopathology, including estimated RDoC domains. In preliminary investigations in a large health system, these tools have demonstrated both face validity and predictive validity. This toolkit also allows extraction o complex concepts from narrative notes, such as stressors and health behaviors.  In the proposed study, these natural language processing tools will be applied to a large psychiatric inpatient data set as well as a large general medical inpatient data set, to derive measures of psychopathology and other topics. The resulting measures will then be used in combination with coded data to build regression and machine-learning-based models to predict clinical outcomes including length of hospital stay and risk of readmission. The models will then be validated in independent clinical cohorts.  By combining expertise in longitudinal clinical investigation, natural language processing, and machine learning, the proposed study brings together a team with the needed skills to develop a critical toolkit for understanding health records dimensionally The resulting models can be applied to facilitate investigation of dimensions of psychopathology and related topics, allowing stratification of clinical risk to enable development of targeted interventions.         PUBLIC HEALTH RELEVANCE:  Public health significance many aspects of psychiatric illness are not adequately captured by diagnostic codes. This study will apply natural language processing and machine learning to electronic health records from large health systems. The resulting symptom dimensions will allow better stratification of risk for clinically-important outcomes, including prolonged hospital stays and early readmissions.            ",Natural language processing for characterizing psychopathology,9105846,R01MH106577,"['Admission activity', 'Antidepressive Agents', 'Applaud', 'Area', 'Back', 'Biology', 'Categories', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease', 'Electronic Health Record', 'Electronics', 'Epidemiology', 'Face', 'Genetic', 'Health', 'Health behavior', 'Health system', 'Healthcare Systems', 'Hospitals', 'Individual', 'Inpatients', 'Intervention', 'Interview', 'Investigation', 'Length of Stay', 'Machine Learning', 'Measures', 'Medical', 'Mental Depression', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Moods', 'National Institute of Mental Health', 'Natural Language Processing', 'New England', 'Outcome', 'Patient Outcomes Assessments', 'Patients', 'Penetration', 'Pharmaceutical Preparations', 'Process', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychopathology', 'Public Health', 'Registries', 'Reporting', 'Research Domain Criteria', 'Research Personnel', 'Resources', 'Risk', 'Severities', 'Stratification', 'Structure', 'Subgroup', 'Symptoms', 'System', 'Text', 'United States National Academy of Sciences', 'Work', 'base', 'clinical investigation', 'clinical risk', 'cohort', 'health data', 'health record', 'hospital readmission', 'improved', 'natural language', 'neuropsychiatric symptom', 'novel', 'outcome prediction', 'precision medicine', 'predict clinical outcome', 'public health relevance', 'skills', 'stressor', 'success', 'terabyte', 'tool', 'trend']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2016,413500,0.044858714187790825
"Dynamic behavioral and neural effects of cognitive control on language processing DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications. PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.",Dynamic behavioral and neural effects of cognitive control on language processing,9116243,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2016,60210,0.007383513560755328
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability ﻿    DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy. PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9145193,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2016,248974,0.03528383659148018
"Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error ﻿    DESCRIPTION (provided by applicant): Tracking evolutionary changes in viral genomes and their spread often requires the use of data deposited in public databases such as GenBank, the Influenza Research Database (IRD), or the Virus Pathogen Resource (ViPR). GenBank provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. IRD and ViPR are NIH/NIAID funded programs that import data from GenBank but contain additional data sources, visualization, and search tools for their users. Tracking evolutionary changes and spread also requires the geospatial assignment of taxa, which is often obtained from GenBank metadata. Unfortunately, geospatial metadata such as host location is often uncertain in GenBank entries, with only 36% containing a precise location such as a county, town, or region within a state. For example, information such as China or USA was indicated instead of Beijing or Bedford, NH. While town or county might be included in the corresponding journal article, this valuable information is not available for immediate use unless it is extracted and then linked back to the appropriate sequence. The goal of our work is to enable health agencies and other researchers to automatically generate phylogeographic models that incorporate enhanced geospatial data for better estimates of virus spread. This proposal focuses on developing and applying information extraction and statistical phylogeography approaches to enhance models that track evolutionary changes in viral genomes and their spread. We propose a framework that uses natural language processing (NLP) for the automatic extraction of relevant geospatial data from the literature, and assigns a confidence between such geospatial mentions and the GenBank record. We will then use these locations and the estimates as observation error in the creation of phylogeographic models of zoonotic virus spread. We hypothesize that a combined NLP-phylogeography infrastructure that produces models that include observation error in the geospatial assignment of taxa will be closer to a gold standard than phylogeographic models that do not include them. Our research will extend phylogeography and zoonotic surveillance by: creating a NLP infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the estimates from Aim 1 as observation error (Aim 2), and evaluating our approach by comparing the models it produces to models that do not account for observation error in the geospatial assignment of taxa (Aim 3). We will allow users to generate enhanced models and view results on a web portal accessible via a LinkOut feature from GenBank, IRD, and ViPR. The addition of more precise geospatial information in building such models could enable health agencies to better target areas that represent the greatest public health risk.         PUBLIC HEALTH RELEVANCE: We will develop and evaluate an infrastructure that uses Natural Language Processing (NLP) to identify more precise geographic information for modeling spread of zoonotic viruses. These new models could enable public health agencies to identify the most at-risk areas. In addition, by improving geospatial information in popular sequence databases such as GenBank, we will enrich other sciences that utilize this information such as molecular epidemiology, population genetics, and environmental health.                ",Tracking Evolution and Spread of Viral Genomes by Geospatial Observation Error,9065021,R01AI117011,"['Accounting', 'Animals', 'Applied Research', 'Area', 'Award', 'Back', 'China', 'Computer software', 'County', 'Data', 'Data Sources', 'Databases', 'Deposition', 'Development', 'Diffusion', 'Disease', 'Environmental Health', 'Evaluation', 'Evolution', 'Funding', 'Genbank', 'Genetic Variation', 'Genome', 'Goals', 'Gold', 'Hantavirus', 'Health', 'Human', 'Imagery', 'Influenza', 'Knowledge', 'Link', 'Literature', 'Location', 'Metadata', 'Methods', 'Modeling', 'Molecular Epidemiology', 'National Institute of Allergy and Infectious Disease', 'Natural Language Processing', 'Nucleotides', 'Population Genetics', 'Public Health', 'Publications', 'RNA Viruses', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Source', 'Surveillance Modeling', 'System', 'Taxon', 'Time', 'Trees', 'United States National Institutes of Health', 'Viral', 'Viral Genome', 'Virus', 'Work', 'improved', 'information model', 'interest', 'journal article', 'pathogen', 'population health', 'programs', 'public health relevance', 'simulation', 'surveillance data', 'tool', 'web portal']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2016,479735,-0.0010828404437110153
"Challenges in Natural Language Processing in Clinical Text No abstract available Challenges in Natural Language Processing for Clinical Narratives Narrative: This project aims to organize a series of shared task challenges that open electronic health records to the research community for advancing the state of the art in natural language processing in clinical records. The proposed shared tasks are complemented by workshops, conference proceedings, and journal special issues that aim to disseminate the knowledge generated by the challenges.",Challenges in Natural Language Processing in Clinical Text,9597333,R13LM011411,[' '],NLM,GEORGE MASON UNIVERSITY,R13,2016,20000,0.03367305857832579
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002). PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Clinic Interactions of a Brain-Computer Interface for Communication,9038348,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'human-in-the-loop', 'improved', 'innovation', 'intervention program', 'learning strategy', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2016,652362,-0.02317514486991191
"NLP to Improve Accuracy and Quality of Dictated Medical Documents ﻿    DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005). PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9146893,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,249994,0.006259430443487905
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,9144757,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,249135,0.04622739256534773
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,9068953,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Health', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'genomic data', 'improved', 'large-scale database', 'novel', 'open source', 'personalized medicine', 'rapid growth', 'rare variant', 'response', 'study population', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2016,536892,-0.0075613908288467025
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in several subprojects which use natural language processing techniques:  1) We have developed a machine learning algorithm for abbreviation definition identification in text which makes use of what we term naturally labeled data. Positive training examples are naturally occurring potential abbreviation-definition pairs in text. Negative training examples are generated by randomly mixing potential abbreviations with unrelated potential definitions. The machine learner is trained to distinguish between these two sets of examples. Then, the learned feature weights are used to identify the abbreviation full form. This approach does not require manually labeled training data. We evaluate the performance of our algorithm on the Ab3P, BIOADI and Medstract corpora. Our system demonstrated results that compare favourably to the existing Ab3P and BIOADI systems. We achieve an F-measure of 91.36% on Ab3P corpus, and an F-measure of 87.13% on BIOADI corpus which are superior to the results reported by Ab3P and BIOADI systems. Moreover, we outperform these systems in terms of recall, which is one of our goals. 2) We are studying paraphrases in MEDLINE abstracts. These come about because an author is describing some entity of interest and uses a phrase like ""drug abuse"" and then needing to describe the same entity again a sentence or two latter does not wish to use exactly the same wording again and may use a variant of the phrase such as ""drug use"" which in the context of ""drug abuse"" has substantially the same meaning.  3) An author disambiguation algorithm has been developed which relies on machine learning based on the assumption that if an author name is infrequent in the data it probably represents the same person in all documents where it is found. This gives us positive instances. Negative instances are sampled from pairs of documents that have no author in common. Such positive and negative data allows us to do machine learning on all aspects of the document other than the name in question. This allows us to learn how to weight this data for best performance in distinguishing the positive and negative instances from each other. This learning is then applied in individual name cases or spaces to determine which author document pairs represent the same author. 4) We are using results of dependency parsers and syntactic parsers to create features for improved machine learning and also to automatically find good titles for document clusters. The BioC environment and the BioC tools including the Natural language processing pipelines have facilitated this work. n/a",Natural Language Processing Techniques To Enhance Information Access.,9160915,ZIALM000090,"['Abbreviations', 'Algorithms', 'Automated Abstracting', 'Data', 'Dependency', 'Drug abuse', 'Drug usage', 'Environment', 'Goals', 'Individual', 'Information Retrieval', 'Label', 'Learning', 'MEDLINE', 'Machine Learning', 'Measures', 'Names', 'Natural Language Processing', 'Performance', 'Persons', 'Reporting', 'Sampling', 'System', 'Techniques', 'Text', 'Training', 'Variant', 'Weight', 'Work', 'abstracting', 'base', 'improved', 'indexing', 'interest', 'phrases', 'spelling', 'syntax', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2015,224965,0.03865624798224484
"IGF::CL::IGF  MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015. MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015 n/a","IGF::CL::IGF  MEETING SUPPORT FOR THE NATURAL LANGUAGE PROCESSING WORKSHOP OCTOBER 8, 2015.",9162846,61201400011I,"['Educational workshop', 'Natural Language Processing', 'meetings']",NCI,"SCIENTIFIC CONSULTING GROUP, INC.",N03,2015,16100,0.07816655999507688
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) Code has been multithreaded and memory mapping capabilities added to speed up processing. 6) Most recently the code has been updated to work in a 64 bit environment.   The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system is currently proving useful in testing different retrieval parameters and methods on the PubMedHealth records.  We have recently developed a software system called DStor that allows us to store all of PubMed in a manner which is easily updateable and allows fast access. This system is now being used to maintain and update five different versions of the PubMed data twice a week. This system has greatly improved our access to PubMed data in various useful forms and we anctipate that its use will continue to grow. In addition we have developed software to maintain and update a list of strings where each string is associated with some fixed vector of integers. We currently maintain a list of all multi-word phrases without stop words or punctuation and with each is associated a vector of six integers representing counts of different types associated with each phrase where counts are computed over all PubMed records having abstracts. We also maintain a list of all one and two word phrases and MeSH terms in various forms (with & without stars and subheadings) and two counts with each consisting of the document frequency and the total frequency counting all occurrences in each document over all of PubMed. n/a",A Document Processing System,9160906,ZIALM000022,"['Code', 'Data', 'Databases', 'Environment', 'Frequencies', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'MeSH Thesaurus', 'Memory', 'Methods', 'Process', 'Programming Languages', 'PubMed', 'Records', 'Research', 'Retrieval', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Update', 'Work', 'abstracting', 'base', 'computerized data processing', 'improved', 'phrases', 'repository', 'software development', 'software systems', 'vector']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2015,439705,0.01803741764598154
"Dynamic behavioral and neural effects of cognitive control on language processing     DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications.         PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.                ",Dynamic behavioral and neural effects of cognitive control on language processing,8850708,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'public health relevance', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2015,60542,0.007383513560755328
"Free Text Gene Name Recognition 1) I have been a co-organizer of the BioCreative Workshops since 2005 and have taken part in BioCreative II (2007), BioCreative III (2010), BioCreative-2012 Workshop (2012), and BioCreative IV (2013) and my group is taking part in BioCreative V (2015) which has not yet taken place. The overall goal of the BioCreative Workshops is to promote the development of text mining and text processing tools which are useful to the communities of researchers and database curators in the biological sciences.  2) We are currently working to develop more general methods of finding high value articles for PPI based on their abstracts. This effort involves not only more powerful ranking methods, but also ways to display evidence to the user for a users quick evaluation. 3) We are also investigating an approach to named entity recognition for a large number of biologically important entity types. We have found certain general patterns that can be used to find genes and other entity types with a higher reliability than can be done with a general CRF. This is ongoing research with a promise for more useful general patterns.  4) We have begun a project called BioC which is an effort to create a general XML format defined by a DTD and software to read and write this format. Currently this approach has been implemented in C++, Java, Python, Pearl, Ruby, and GO. The idea is to use this common currency to make software modules that are useful for natural language processing  more interoperable. The project is in its early stages, but already we have software to read and write in the languages mentioned as well as significant NLP processing modules using this approach and over 25 gold standard NLP annotated data sets available in the format. The approach was featured in the BioCreative IV Workshop and the approach has formed the basis of the BioC Collaborative Track at BioCreative V which will take place in a short time. This track has received contributions from eight teams besides our own and has built a user interface which displays annotated articles to Biogrid curators to assist them in their work. n/a",Free Text Gene Name Recognition,9160916,ZIALM000093,"['Biological Sciences', 'Biology', 'Communities', 'Computer software', 'Data Set', 'Databases', 'Development', 'Educational workshop', 'Evaluation', 'Extensible Markup Language', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Gold', 'Java', 'Language', 'Literature', 'Methods', 'Names', 'Natural Language Processing', 'Pattern', 'Process', 'Proteins', 'Proteomics', 'Pythons', 'Reading', 'Research', 'Research Personnel', 'Staging', 'Techniques', 'Text', 'Time', 'Variant', 'Work', 'Writing', 'abstracting', 'base', 'improved', 'text searching', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2015,143160,-0.010029437533465736
"Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability ﻿    DESCRIPTION (provided by applicant): The objective of the proposed research is to provide an evidence-base to better inform user centered design and implementation processes to improve health information technology (health IT) usability and safety. The proposed research is in direct response to special emphasis notice (NOT-HS-15-005). Utilizing a hybrid approach of expert manual review and machine learning techniques, specifically natural language processing, we will develop methods to rapidly analyze patient safety event data to determine which events are health IT related. We will then further categorize the health IT related safety events to determine which events could have been prevented by effective usability or implementation processes. Through this analysis we will be able to specify the usability and implementation processes that are critical to the safe and effective use of health IT. This project utilizes the extensive expertise of the research team in human factors and safety science, health IT, and computer science. The proposed research is based on unique insights that our team gleaned from previous research that we conducted focusing on health IT vendor design and implementation processes. The application addresses fundamental aspects of the call for applications by providing an evidence base to improve health IT usability and safety to better inform policy and practice. This research effort is being conducted in partnership with a health IT vendor and a patient safety organization to ensure that our results align with vendor needs and to ensure the results are generalizable. Contributions from this research will include a fundamental understanding of the critical user centered design and implementation processes to inform vendor and provider practice. Our research will also provide organizations like the Office of the National Coordinator with the information to better inform health IT policy.         PUBLIC HEALTH RELEVANCE    Project Narrative This project is relevant to public health because it applies the science of human factors and data analytics to improve the usability and safety of health information technology and ultimately improve patient care. Patient safety event data will be analyzed to support specific user centered design and implementation processes to better inform the design and development of health information technology.            ",Developing Evidence- based User Centered Design and Implementation Guidelines to Improve Health Information Technology Usability,9030048,R01HS023701,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2015,249752,0.03528383659148018
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8804856,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2015,217500,-0.004001859673669807
"Probabilistic Disease Surveillance DESCRIPTION (provided by applicant):         The proposed research will further develop and evaluate a probabilistic approach to disease surveillance. In this approach, a probabilistic case detection system (CDS) uses Bayesian diagnostic networks to compute the likelihoods of patient findings for each of a set of infectious diseases for every patient in a monitored population. CDS computes these likelihoods from data in electronic medical records, including information derived from free-text reports by natural language processing. CDS makes those estimates available to a probabilistic outbreak detection and characterization component (ODCS).             ODCS also utilizes a Bayesian approach to compute the probability that an outbreak is ongoing for each of a set of infectious diseases of interest, given information from CDS. ODCS also computes probability distributions over the current and future size of a detected outbreak and other characteristics such as incubation period used by public health officials when responding to an outbreak.                        The proposed research will extend the approach, which we have already developed and evaluated for the disease influenza to six additional respiratory infectious diseases. The research will also extend the capabilities of ODCS to utilize non-EMR data, detect an unknown disease, and detect and characterize concurrent outbreaks. The planned evaluations will measure the accuracy of both CDS and ODCS using historical surveillance data from two regions and simulated outbreak data, which we will create by adding outbreak cases generated by an agent-based epidemic simulator to real baseline surveillance data from non-outbreak periods.                        The innovation being advanced by this research is a novel, integrated, Bayesian approach for the early and accurate detection of cases of diseases that threaten health and for the detection and characterization of outbreaks of diseases that threaten public health. The proposed approach has significant potential to improve the information available to public health officials and physicians, which can be expected to improve clinical and public health decision making, and ultimately to improve population health. Project Relevance  The proposed research will improve the ability of public health officials and physicians to estimate the current incidence of influenza and other infectious diseases and to predict the future course of epidemics of those diseases. The improved information will better support decisions made by health departments to control epidemics, which is expected to reduce morbidity and mortality from epidemic diseases.",Probabilistic Disease Surveillance,8875053,R01LM011370,"['Accident and Emergency department', 'Advanced Development', 'Area', 'Bayesian Method', 'Characteristics', 'Clinical', 'Code', 'Communicable Diseases', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'County', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Disease model', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Future', 'Health', 'Healthcare', 'Healthcare Systems', 'Incidence', 'Individual', 'Influenza', 'Intervention', 'Knowledge', 'Laboratories', 'Lung diseases', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Public Health', 'Public Health Practice', 'Publications', 'ROC Curve', 'Reporting', 'Research', 'Schools', 'Sensitivity and Specificity', 'Severities', 'Sodium Chloride', 'Structure', 'Support System', 'System', 'Systems Integration', 'Testing', 'Text', 'Time', 'Topaz', 'Universities', 'Utah', 'Vaccination', 'advanced system', 'base', 'computer code', 'diagnostic accuracy', 'disorder control', 'follow-up', 'improved', 'influenza outbreak', 'innovation', 'interest', 'knowledge base', 'mortality', 'novel', 'novel strategies', 'operation', 'pandemic disease', 'population health', 'portability', 'reproductive', 'respiratory', 'surveillance data']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2015,531035,0.012850094520740941
"Co-construction of lexica in primary progressive aphasia DESCRIPTION (provided by applicant): Individuals with primary progressive aphasia (PPA) present with an insidious onset and gradual loss of word finding, object naming, or word-comprehension skills which profoundly affect their verbal participation in daily activities. The overall goal of this innovative research is to take an initial step toward the creation of adaptive language prostheses that augment lexical access and word use in PPA as skills are lost. The short term objective is to determine whether individuals with mild-to-moderate PPA improve or maintain word finding skills during conversation when provided with a novel intervention tool, namely a mobile technology application called CO-CHAT that automatically presents related vocabulary to them as needed. CO-CHAT is a simulated social media app for research which creates lexical displays synthesized from a user's self-generated photos, comments from social network contacts, the device's metadata, and a curated list of key words generated with Natural Language Processing (NLP) techniques. Aim 1 addresses development of the simulated social media app with NLP applications. Aim 2 proposes a research study to determine whether people with PPA can use the CO-CHAT lexical displays to improve or maintain word finding skills in conversation. Two hypotheses will be tested: (1) The number (and percentage) of target words spoken by participants during conversations will increase when the CO-CHAT lexical displays are available~ (2) The number (and percentage) of questions needed by conversation partners to obtain information from participants about daily activities will decrease when the CO-CHAT lexical displays are available. Participants are 10 individuals with mild-to-moderate PPA (agrammatic or semantic variants) recruited from the Oregon Alzheimer's Disease Center. A withdrawal ABAB design with intra-subject and inter-subject replication is proposed. Each participant engages in community- based activities, taking photos and sending them to a simulated social network for comment. By relying on the technology's automatic manipulation of language, photos comments then are analyzed. Related words that are mined from large lexical semantic databases are placed in the lexical displays with the original photo. Participants describe the community activities to familiar partners in 5-minute conversations without technology (baseline phase A) and with CO- CHAT (experimental phase B). Visual analysis of changes across conditions and repeated measures ANOVAs evaluate intervention effects. The proposed research addresses the need to identify effective language compensation strategies to treat individuals experiencing PPA, a relatively new diagnosis for which compensatory treatment paradigms are yet to be developed. Results will support a larger research agenda to further develop adaptive assistive technologies for intervention, and to implement outcomes-based clinical studies that determine the efficacy of a stage-based longitudinal AAC/NLP intervention for patients with PPA in order to maintain vocabulary access, communication functions and social networks with mobile technology over the course of language degeneration. PUBLIC HEALTH RELEVANCE: The population of adults presenting with dementia syndromes and degenerative language disorders is increasing exponentially in the U.S., in the absence of clinical guidelines for effective language intervention. This research will provide evidence to support intervention standards with assistive technologies for persons with primary progressive aphasia, as well as provide scientific data to justify medical insurance reimbursement, and help family members advocate for increases in standard clinical care.",Co-construction of lexica in primary progressive aphasia,8852594,R21DC014099,"['Address', 'Adult', 'Advocate', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Apple', 'Clinical', 'Clinical Research', 'Cognitive', 'Communication', 'Communication Aids for Disabled', 'Communities', 'Computer software', 'Data', 'Databases', 'Dementia', 'Development', 'Devices', 'Diagnosis', 'Electronics', 'Experimental Designs', 'Family member', 'Financial compensation', 'Goals', 'Guidelines', 'Health', 'Image', 'Impairment', 'Individual', 'Insurance', 'Intervention', 'Intervention Studies', 'Language', 'Language Disorders', 'Measures', 'Medical', 'Metadata', 'Mining', 'Names', 'Natural Language Processing', 'Oregon', 'Outcome', 'Participant', 'Patients', 'Persons', 'Phase', 'Pilot Projects', 'Population', 'Primary Progressive Aphasia', 'Prosthesis', 'Published Comment', 'Recruitment Activity', 'Research', 'Research Project Grants', 'Secondary to', 'Self-Help Devices', 'Semantics', 'Social Network', 'Sodium Chloride', 'Staging', 'Structure', 'Syndrome', 'Tablets', 'Techniques', 'Technology', 'Testing', 'Transcript', 'Variant', 'Visual', 'Vocabulary', 'Withdrawal', 'alternative communication', 'base', 'clinical care', 'comprehension skill', 'computer science', 'design', 'digital', 'experience', 'handheld mobile device', 'improved', 'innovation', 'innovative technologies', 'intervention effect', 'lexical', 'mobile application', 'novel', 'research study', 'skills', 'social', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2015,194301,0.005986690392820058
"Clinic Interactions of a Brain-Computer Interface for Communication ﻿    DESCRIPTION (provided by applicant): The promise of brain-computer interfaces (BCI) for communication is becoming a reality for individuals with severe speech and physical impairments (SSPI) who cannot rely on speech or writing to express themselves. While the majority of research efforts are devoted to technology development to address problems of stability, reliability and/or classification, clinical and behavioral challenges are becoming more apparent as individuals with SSPI and their family/care teams assess the systems during novice or long-term trials. The objective of the RSVP Keyboard(tm) BCI translational research team is to address the clinical challenges raised during functional BCI use with innovative engineering design, thereby enhancing the potential of this novel assistive technology. Four specific aims are proposed: (1) to develop a BCI Communication Application Suite (BCI-CAS) that offers a set of language modules to people with SSPI that can meet their language/literacy skills; (2) to develop improved statistical signal models for personalized feature extraction, artifact/interference handling, and robust, accurate intent evidence extraction from physiologic signals; (3) to develop improved language models and stimulus sequence optimization methods; and (4) to evaluate cognitive variables that affect learning and performance of the BCI-CAS. Five language modules are proposed that rely on a multimodal evidence fusion framework for model-based context-aware optimal intent inference: RSVP Keyboard(tm) generative spelling; RSVP texting; RSVP in-context typing; RSVP in-context icon typing; and binary yes/no responses with SSVEPs. Usability data on the current RSVP Keyboard(tm) and SSVEP system drive all proposed aims. Users select a language module, and the BCI system optimizes performance for each individual based on user adaptation, intent inference, and personalized language modeling. A unique simulation function drives individualization of system parameters. The robustness of the BCI customization efforts are evaluated continually by adults with SSPI and neurotypical controls in an iterative fashion. The effect of three intervention programs that address the cognitive construct of attention (process-specific attention training, mindfulness meditation training and novel stimulus presentations) will be implemented through hypothesis-driven single subject designs. Thirty participants, ages 21 years and older with SSPI will be included in home-based interventions. By measuring information transfer rate (ITR), user satisfaction, and intrinsic user factors, we will identify learning strategies that influence BCI sill acquisition and performance for adults with neurodegenerative or neurodevelopmental conditions. The translational teams include (1) signal processing (Erdogmus); (2) clinical neurophysiology (Oken); (3) natural language processing (Bedrick/Gorman); and (4) assistive technology (Fried-Oken). We continue to rely on a solid Bayesian foundation and theoretical frameworks: ICF disability classification (WHO, 2001), the AAC model of participation (Beukelman & Mirenda, 2013) and the Matching Person to Technology Model (Scherer, 2002).         PUBLIC HEALTH RELEVANCE: The populations of patients with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means to interface with communication systems. The BCI Communication Applications Suite is a hybrid brain-computer interface that is an innovative technological advance so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.                ",Clinic Interactions of a Brain-Computer Interface for Communication,8876473,R01DC009834,"['21 year old', 'Accounting', 'Address', 'Adult', 'Advocate', 'Affect', 'Analysis of Variance', 'Attention', 'Behavior', 'Behavioral', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Code', 'Cognitive', 'Collaborations', 'Communication', 'Complex', 'Data', 'Decision Making', 'Dependency', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Foundations', 'Heterogeneity', 'Home environment', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Informed Consent', 'Intercept', 'Intervention', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Movement', 'Natural Language Processing', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Outcome', 'P300 Event-Related Potentials', 'Participant', 'Partner Communications', 'Patients', 'Performance', 'Persons', 'Physiological', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Public Health', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Role', 'Running', 'Secondary to', 'Self-Help Devices', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Statistical Models', 'Stimulus', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Validation', 'Visual', 'Visual evoked cortical potential', 'Vocabulary', 'Writing', 'acronyms', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinically relevant', 'cognitive system', 'computer science', 'cost', 'design', 'disability', 'engineering design', 'improved', 'innovation', 'intervention program', 'literacy', 'meetings', 'mindfulness meditation', 'neurophysiology', 'novel', 'patient population', 'preference', 'public health relevance', 'research study', 'residence', 'response', 'satisfaction', 'signal processing', 'simulation', 'skills', 'spelling', 'statistics', 'syntax', 'technology development', 'time interval', 'usability', 'vigilance']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2015,665012,-0.02317514486991191
"NLP to Improve Accuracy and Quality of Dictated Medical Documents ﻿    DESCRIPTION (provided by applicant):  Errors in medical documents represent a critical issue that can adversely affect healthcare quality and safety. Physician use of speech recognition (SR) technology has risen in recent years due to its ease of use and efficiency at the point of care. However, high error rates, upwards of 10-23%, have been observed in SR-generated medical documents. Error correction and content editing can be time consuming for clinicians. A solution to this problem is to improve accuracy through automated error detection using natural language processing (NLP). In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) build a large corpus of clinical documents dictated via SR across different healthcare institutions and clinical settings; 2) conduct error analysis to estimate the prevalence and severity of SR errors; 3) develop innovative methods based on NLP for automated error detection and correction and create a comprehensive knowledge base that contains confusion sets, error frequencies and other error patterns; 4) evaluate the performance of the proposed methods and tool; and 5) distribute our methods and findings to make them available to other researchers.  We believe this application aligns with AHRQ's HIT and Patient Safety portfolios as well as AHRQ's Special Emphasis Notice to support projects to generate new evidence on health IT system safety (NOT- HS-15-005).         PUBLIC HEALTH RELEVANCE    Public Health Relevance Statement  Errors in medical documents are dangerous for patients. Physician use of speech recognition technology, a computerized form of medical transcription, has risen in recent years due to its ease of use and efficiency. However, high error rates, upwards of 10-23%, have been observed. The goal of this study is two-fold: 1) to study the nature of such errors and how they may affect the quality of care and 2) to develop innovative methods based on computerized natural language processing to automatically detect these errors in clinical documents so that physicians can correct the documents before entering them into the patient's medical record.            ",NLP to Improve Accuracy and Quality of Dictated Medical Documents,9004939,R01HS024264,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,250000,0.006259430443487905
"Learning from patient safety events: A case base tool kit DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture. PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.",Learning from patient safety events: A case base tool kit,8928596,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,249655,0.04622739256534773
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers. PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,8929257,R01GM103859,"['Adverse drug event', 'Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Health', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Population Study', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'improved', 'large-scale database', 'novel', 'open source', 'personalized medicine', 'rapid growth', 'rare variant', 'response', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY,R01,2015,598996,-0.0075613908288467025
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in several subprojects which use natural language processing techniques:  1) We have developed a machine learning algorithm for abbreviation definition identification in text which makes use of what we term naturally labeled data. Positive training examples are naturally occurring potential abbreviation-definition pairs in text. Negative training examples are generated by randomly mixing potential abbreviations with unrelated potential definitions. The machine learner is trained to distinguish between these two sets of examples. Then, the learned feature weights are used to identify the abbreviation full form. This approach does not require manually labeled training data. We evaluate the performance of our algorithm on the Ab3P, BIOADI and Medstract corpora. Our system demonstrated results that compare favourably to the existing Ab3P and BIOADI systems. We achieve an F-measure of 91.36% on Ab3P corpus, and an F-measure of 87.13% on BIOADI corpus which are superior to the results reported by Ab3P and BIOADI systems. Moreover, we outperform these systems in terms of recall, which is one of our goals. 2) We are studying paraphrases in MEDLINE abstracts. These come about because an author is describing some entity of interest and uses a phrase like ""drug abuse"" and then needing to describe the same entity again a sentence or two latter does not wish to use exactly the same wording again and may use a variant of the phrase such as ""drug use"" which in the context of ""drug abuse"" has substantially the same meaning.  3) An author disambiguation algorithm has been developed which relies on machine learning based on the assumption that if an author name is infrequent in the data it probably represents the same person in all documents where it is found. This gives us positive instances. Negative instances are sampled from pairs of documents that have no author in common. Such positive and negative data allows us to do machine learning on all aspects of the document other than the name in question. This allows us to learn how to weight this data for best performance in distinguishing the positive and negative instances from each other. This learning is then applied in individual name cases or spaces to determine which author document pairs represent the same author. 4) We are using results of dependency parsers and syntactic parsers to create features for improved machine learning and also to automatically find good titles for document clusters. n/a",Natural Language Processing Techniques To Enhance Information Access.,8943224,ZIALM000090,"['Abbreviations', 'Algorithms', 'Automated Abstracting', 'Data', 'Dependency', 'Drug abuse', 'Drug usage', 'Goals', 'Individual', 'Information Retrieval', 'Label', 'Learning', 'MEDLINE', 'Machine Learning', 'Measures', 'Names', 'Natural Language Processing', 'Performance', 'Persons', 'Reporting', 'Sampling', 'System', 'Techniques', 'Text', 'Training', 'Variant', 'Weight', 'abstracting', 'base', 'improved', 'indexing', 'interest', 'phrases', 'spelling', 'syntax', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2014,561533,0.026899642436717157
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) Code has been multithreaded and memory mapping capabilities added to speed up processing. 6) Most recently the code has been updated to work in a 64 bit environment.   The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system is currently proving useful in testing different retrieval parameters and methods on the PubMedHealth records.  We have recently developed a software system called DStor that allows us to store all of PubMed in a manner which is easily updateable and allows fast access. This system is now being used to maintain and update five different versions of the PubMed data twice a week. This system has greatly improved our access to PubMed data in various useful forms and we anctipate that its use will continue to grow. In addition we have developed software to maintain and update a list of strings where each string is associated with some fixed vector of integers. We currently maintain a list of all multi-word phrases without stop words or punctuation and with each is associated a vector of six integers representing counts of different types associated with each phrase where counts are computed over all PubMed records having abstracts. We also maintain a list of all one and two word phrases and MeSH terms in various forms (with & without stars and subheadings) and two counts with each consisting of the document frequency and the total frequency counting all occurrences in each document over all of PubMed. n/a",A Document Processing System,8943215,ZIALM000022,"['Code', 'Data', 'Databases', 'Environment', 'Frequencies', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'MeSH Thesaurus', 'Memory', 'Methods', 'Process', 'Programming Languages', 'PubMed', 'Records', 'Research', 'Retrieval', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Update', 'Work', 'abstracting', 'base', 'computerized data processing', 'improved', 'phrases', 'repository', 'software development', 'software systems', 'vector']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2014,187178,0.01803741764598154
"Dynamic behavioral and neural effects of cognitive control on language processing     DESCRIPTION (provided by applicant): Cognitive control allows individuals to adjust thoughts and actions on-the-fly upon discovering conflict across informational sources during processing; it is therefore critical to both memory and language functions (e.g., recognizing objects correctly despite interfering memoranda; recovering from temporary misinterpretation during reading or spoken language comprehension). The overall objective of this project is to understand the interplay among multiple cognitive systems, whether the same cognitive control functions operate systematically across conflict types that arise in different domains, and to characterize the behavioral and neurobiological mechanisms that underlie their interaction. In doing so, this research will contribute to our knowledge about shared language and memory functions and the extent to which cognitive control engagement in one domain influences performance in another. Specifically, this proposal tests whether the experience of information conflict within memory alters subsequent conflict-control procedures in language processing, ultimately deriving quantitative assessments of these effects in both brain and behavior. This project has three specific aims. The first is to test how the experience of information-conflict during non- linguistc task performance (and thus the engagement of cognitive control) affects real-time language processing, indexed by eye-movement patterns to objects in a scene as listeners carry out spoken instructions. Experiment 1 harnesses the phenomenon of ""conflict adaptation"" (wherein conflict detection triggers cognitive control to facilitate conflict resolution on a subsequent tril) to examine whether listeners dynamically adjust language processing behavior (e.g., easier recovery from misinterpretation) following conflict detection in the Stroop task, a classic cognitive control measure. Second, this proposal examines neurobiological changes during language processing depending on whether cognitive control has been triggered by a preceding conflict trial outside the syntactic domain. Experiment 2 utilizes single-trial analysis of fMRI daa to form a quantitative link between fMRI signal amplitude and both eye-tracking and behavioral indexes of resolving syntactic ambiguity. Third, this proposal investigates the extent to which a wide range of ostensibly different tasks share a common conflict-control mind state. Experiment 3 includes a battery of memory and language tasks with high cognitive control demands to test whether machine-learning algorithms (i.e., multi-voxel pattern analysis, or MVPA) can accurately classify conflict states broadly across domains. The proposed experiments adopt converging eye-tracking and neuroimaging techniques (single-trial and multivariate analyses) to help address a central issue in cognitive science: how language processing is relatively affected by the engagement status of the cognitive control system. Because cognitive control deficits affect patients' memory and language performance alike, elucidating the dynamic interplay between these cognitive systems has major health implications.         PUBLIC HEALTH RELEVANCE: The results from this research will inform an understanding of common language and memory functions in the human mind and brain, insights that can be applied to public knowledge about how various cognitive systems develop typically and atypically during childhood, and how they fail following injury to the underlying neurobiological structures. Critically, we will be able to draw conclusions about the malleability (or causal nature) of certain language and memory processes, findings that can ultimately be disseminated to and used in clinical, educational, and government settings.                ",Dynamic behavioral and neural effects of cognitive control on language processing,8714196,F32HD080306,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Brain', 'Childhood', 'Clinical', 'Cognitive Science', 'Conflict (Psychology)', 'Data', 'Detection', 'Eye', 'Eye Movements', 'Functional Magnetic Resonance Imaging', 'Government', 'Health', 'Human', 'Individual', 'Inferior frontal gyrus', 'Injury', 'Instruction', 'Knowledge', 'Language', 'Left', 'Lesion', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Memory', 'Methodology', 'Methods', 'Mind', 'Multivariate Analysis', 'Nature', 'Neurobiology', 'Patients', 'Pattern', 'Performance', 'Play', 'Procedures', 'Process', 'Psyche structure', 'Psycholinguistics', 'Reader', 'Reading', 'Recovery', 'Regulation', 'Research', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Stimulus', 'Structure', 'System', 'Task Performances', 'Techniques', 'Testing', 'Thinking', 'Time', 'Training', 'Work', 'base', 'brain behavior', 'cognitive control', 'cognitive system', 'conflict resolution', 'experience', 'indexing', 'innovation', 'insight', 'language comprehension', 'language processing', 'memory process', 'mind control', 'neurobiological mechanism', 'neuroimaging', 'public health relevance', 'relating to nervous system', 'research study', 'stimulus processing', 'syntax']",NICHD,"UNIV OF MARYLAND, COLLEGE PARK",F32,2014,57782,0.007383513560755328
"Using NLP to Extract Clinically Important Recommendations from Radiology Reports  Abstract Communication of clinically important follow-up recommendations when abnormalities are identified on imaging studies is prone to error. The absence of an automated system to identify and track radiology follow-up recommendations is an important barrier to ensuring timely follow-up of patients, especially for non-acute but potentially life threatening and unexpected findings. The primary goal of this proposal is to develop a Natural Language Processing (NLP) system to extract clinically important recommendation information from free-text radiology reports. Each radiology report will be preprocessed at the structural, syntactic, and semantic level to generate features that will be used to extract the boundaries of sentences that include recommendation information as well as the details of reason for recommendation, requested imaging test, and recommendation time frame. We will use a large corpus of free-text radiology reports represented by a mixture of modalities (e.g., radiography, computed tomography, ultrasound, and magnetic resonance imaging (MRI)) from three different institutions. Using this dataset we will perform the following specific aims: Aim 1. Create a multi- institutional radiology report corpus annotated for clinically important recommendation information; Aim 2. Develop a novel NLP system to extract clinically important recommendations in radiology reports. The proposed research is innovative because it will generate a new text processing approach that can be used to flag reports visually and electronically so that separate workflow processes can be initiated to reduce the chance that necessary investigations or interventions suggested in the report are missed by clinicians. The proposed set of tools will be disseminated to the biomedical informatics community as open source tools. PUBLIC HEALTH RELEVANCE: Communication of recommendations for necessary investigations and interventions when abnormalities are identified on imaging studies is prone to error. When recommendations are not systematically identified and promptly communicated to referrers, poor patient outcomes can result. We propose to build natural language processing tools to automatically extract clinically important recommendation information from radiology reports.                ",Using NLP to Extract Clinically Important Recommendations from Radiology Reports,8635902,R21EB016872,"['Academic Medical Centers', 'Address', 'Adopted', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computerized Medical Record', 'Data Set', 'Dependency', 'Diagnostic', 'Diagnostic radiologic examination', 'Ensure', 'Funding', 'Future', 'Goals', 'Gold', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Imaging technology', 'Incidental Findings', 'Institution', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Lung nodule', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medical center', 'Methods', 'Modality', 'Natural Language Processing', 'Outcome', 'Output', 'Patient Care', 'Patients', 'Persons', 'Process', 'Provider', 'Quality of Care', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Risk', 'Safety', 'Semantics', 'Shapes', 'Societies', 'Specific qualifier value', 'Speech', 'System', 'Telephone', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Ultrasonography', 'Unified Medical Language System', 'Washington', 'Writing', 'X-Ray Computed Tomography', 'biomedical informatics', 'cancer care', 'care delivery', 'design', 'falls', 'follow-up', 'health care delivery', 'imaging modality', 'improved', 'innovation', 'novel', 'open source', 'phrases', 'public health relevance', 'radiologist', 'screening', 'syntax', 'tool']",NIBIB,UNIVERSITY OF WASHINGTON,R21,2014,257300,-0.004001859673669807
"Probabilistic Disease Surveillance     DESCRIPTION (provided by applicant):         The proposed research will further develop and evaluate a probabilistic approach to disease surveillance. In this approach, a probabilistic case detection system (CDS) uses Bayesian diagnostic networks to compute the likelihoods of patient findings for each of a set of infectious diseases for every patient in a monitored population. CDS computes these likelihoods from data in electronic medical records, including information derived from free-text reports by natural language processing. CDS makes those estimates available to a probabilistic outbreak detection and characterization component (ODCS).             ODCS also utilizes a Bayesian approach to compute the probability that an outbreak is ongoing for each of a set of infectious diseases of interest, given information from CDS. ODCS also computes probability distributions over the current and future size of a detected outbreak and other characteristics such as incubation period used by public health officials when responding to an outbreak.                        The proposed research will extend the approach, which we have already developed and evaluated for the disease influenza to six additional respiratory infectious diseases. The research will also extend the capabilities of ODCS to utilize non-EMR data, detect an unknown disease, and detect and characterize concurrent outbreaks. The planned evaluations will measure the accuracy of both CDS and ODCS using historical surveillance data from two regions and simulated outbreak data, which we will create by adding outbreak cases generated by an agent-based epidemic simulator to real baseline surveillance data from non-outbreak periods.                        The innovation being advanced by this research is a novel, integrated, Bayesian approach for the early and accurate detection of cases of diseases that threaten health and for the detection and characterization of outbreaks of diseases that threaten public health. The proposed approach has significant potential to improve the information available to public health officials and physicians, which can be expected to improve clinical and public health decision making, and ultimately to improve population health.                  Project Relevance  The proposed research will improve the ability of public health officials and physicians to estimate the current incidence of influenza and other infectious diseases and to predict the future course of epidemics of those diseases. The improved information will better support decisions made by health departments to control epidemics, which is expected to reduce morbidity and mortality from epidemic diseases.",Probabilistic Disease Surveillance,8708209,R01LM011370,"['Accident and Emergency department', 'Advanced Development', 'Area', 'Bayesian Method', 'Characteristics', 'Clinical', 'Code', 'Communicable Diseases', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'County', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Disease model', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Future', 'Health', 'Healthcare', 'Healthcare Systems', 'Incidence', 'Individual', 'Influenza', 'Intervention', 'Knowledge', 'Laboratories', 'Lung diseases', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Public Health', 'Public Health Practice', 'Publications', 'ROC Curve', 'Reporting', 'Research', 'Schools', 'Sensitivity and Specificity', 'Severities', 'Simulate', 'Sodium Chloride', 'Structure', 'Support System', 'System', 'Systems Integration', 'Testing', 'Text', 'Time', 'Topaz', 'Universities', 'Utah', 'Vaccination', 'advanced system', 'base', 'computer code', 'diagnostic accuracy', 'disorder control', 'follow-up', 'improved', 'influenza outbreak', 'innovation', 'interest', 'knowledge base', 'mortality', 'novel', 'novel strategies', 'operation', 'pandemic disease', 'population health', 'portability', 'reproductive', 'respiratory', 'surveillance data']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2014,535841,0.012850094520740941
"Co-construction of lexica in primary progressive aphasia     DESCRIPTION (provided by applicant): Individuals with primary progressive aphasia (PPA) present with an insidious onset and gradual loss of word finding, object naming, or word-comprehension skills which profoundly affect their verbal participation in daily activities. The overall goal of this innovative research is to take an initial step toward the creation of adaptive language prostheses that augment lexical access and word use in PPA as skills are lost. The short term objective is to determine whether individuals with mild-to-moderate PPA improve or maintain word finding skills during conversation when provided with a novel intervention tool, namely a mobile technology application called CO-CHAT that automatically presents related vocabulary to them as needed. CO-CHAT is a simulated social media app for research which creates lexical displays synthesized from a user's self-generated photos, comments from social network contacts, the device's metadata, and a curated list of key words generated with Natural Language Processing (NLP) techniques. Aim 1 addresses development of the simulated social media app with NLP applications. Aim 2 proposes a research study to determine whether people with PPA can use the CO-CHAT lexical displays to improve or maintain word finding skills in conversation. Two hypotheses will be tested: (1) The number (and percentage) of target words spoken by participants during conversations will increase when the CO-CHAT lexical displays are available~ (2) The number (and percentage) of questions needed by conversation partners to obtain information from participants about daily activities will decrease when the CO-CHAT lexical displays are available. Participants are 10 individuals with mild-to-moderate PPA (agrammatic or semantic variants) recruited from the Oregon Alzheimer's Disease Center. A withdrawal ABAB design with intra-subject and inter-subject replication is proposed. Each participant engages in community- based activities, taking photos and sending them to a simulated social network for comment. By relying on the technology's automatic manipulation of language, photos comments then are analyzed. Related words that are mined from large lexical semantic databases are placed in the lexical displays with the original photo. Participants describe the community activities to familiar partners in 5-minute conversations without technology (baseline phase A) and with CO- CHAT (experimental phase B). Visual analysis of changes across conditions and repeated measures ANOVAs evaluate intervention effects. The proposed research addresses the need to identify effective language compensation strategies to treat individuals experiencing PPA, a relatively new diagnosis for which compensatory treatment paradigms are yet to be developed. Results will support a larger research agenda to further develop adaptive assistive technologies for intervention, and to implement outcomes-based clinical studies that determine the efficacy of a stage-based longitudinal AAC/NLP intervention for patients with PPA in order to maintain vocabulary access, communication functions and social networks with mobile technology over the course of language degeneration.         PUBLIC HEALTH RELEVANCE: The population of adults presenting with dementia syndromes and degenerative language disorders is increasing exponentially in the U.S., in the absence of clinical guidelines for effective language intervention. This research will provide evidence to support intervention standards with assistive technologies for persons with primary progressive aphasia, as well as provide scientific data to justify medical insurance reimbursement, and help family members advocate for increases in standard clinical care.            ",Co-construction of lexica in primary progressive aphasia,8764466,R21DC014099,"['Address', 'Adult', 'Advocate', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Apple', 'Clinical', 'Clinical Research', 'Cognitive', 'Communication', 'Communication Aids for Disabled', 'Communities', 'Comprehension', 'Computer software', 'Data', 'Databases', 'Dementia', 'Development', 'Devices', 'Diagnosis', 'Electronics', 'Experimental Designs', 'Family member', 'Financial compensation', 'Goals', 'Guidelines', 'Image', 'Impairment', 'Individual', 'Insurance', 'Intervention', 'Intervention Studies', 'Language', 'Language Disorders', 'Measures', 'Medical', 'Metadata', 'Mining', 'Names', 'Natural Language Processing', 'Oregon', 'Outcome', 'Participant', 'Patients', 'Persons', 'Phase', 'Pilot Projects', 'Population', 'Primary Progressive Aphasia', 'Prosthesis', 'Published Comment', 'Recruitment Activity', 'Research', 'Research Project Grants', 'Secondary to', 'Self-Help Devices', 'Semantics', 'Simulate', 'Social Network', 'Sodium Chloride', 'Staging', 'Structure', 'Syndrome', 'Tablets', 'Techniques', 'Technology', 'Testing', 'Transcript', 'Variant', 'Visual', 'Vocabulary', 'Withdrawal', 'alternative communication', 'base', 'clinical care', 'computer science', 'design', 'digital', 'experience', 'handheld mobile device', 'improved', 'innovation', 'innovative technologies', 'intervention effect', 'lexical', 'mobile application', 'novel', 'public health relevance', 'research study', 'skills', 'social', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2014,234765,0.005986690392820058
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453          PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8722026,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2014,342375,0.0368925720561588
"Learning from patient safety events: A case base tool kit     DESCRIPTION (provided by applicant): Medical error is one of the leading causes of death in the US. The study and reduction of medical errors have become a major concern in healthcare today. It is believed that medical error reporting systems could be a good resource to share and to learn from errors if medical error data are collected in a properly structured format and are useful for the detection of patterns, discovery of underlying factors, and generation of solutions. Effectively gathering information from previous lessons and timely informing the subsequent action are the two major goals for the design, development and utilization of such a system. The Common Formats (CFs) suggested by AHRQ tend to unify the future reporting format, which holds promise in improving data consistency and reducing unsafe conditions through lessons learned. However, effective gathering medical incident data does not merely rely on a unified structure. To be able to learn from previous lessons, it heavily depends upon the quality reports and learning features offered by systems. Medical incident data are always the key components and invaluable assets in patient safety research. The long term goal of the project is to understand the occurrence and causes of medical incidents in real practice and to develop interventions based on collection of incident reports to minimize the recurrence of similar incidents that have been reported. The objective of this application is to improve the utilization f voluntary reporting systems that each healthcare institution has been put in use by developing a learning toolkit that can systematically collect and analyze incident reports, automatically link historical reports with WebM&M, the highest quality of voluntary reports and expert reviews in patient safety. As moving toward CFs, the researchers propose a user-centered, learning-supportive, and ontological approach that will help reporters generate complete and accurate reports through user-friendly guidance and offer timely comments and relevant peer reviews through educational tools during and after incident reporting. The researchers employ a case-based reasoning and natural language processing techniques to demonstrate the feasibility and effectiveness of the knowledge-based toolkit which helps reporters improve the communication about patient safety through clear working definitions and advance training that builds knowledge about the safety culture and then provides continuing education through the system. The project holds promise in revolutionizing the design of voluntary medical incident reporting systems from an incident data repository to an advanced resource promoting complete and accurate incident reporting and learning toward a just and learning culture.         PUBLIC HEALTH RELEVANCE: Timely reporting and effective learning from medical incidents is considered an effective way in developing strategies for reducing medical errors. Utilizing an innovative a user-centered, learning-supportive, and ontological approach combining with case-based reasoning and natural language processing techniques, we propose to develop a knowledgebase and learning toolkit that can systematically collect and analyze incident reports, linking historical reports with WebM&M, the highest quality of voluntary reports and expert reviews on patient safety. We envision that the innovative approach will facilitate timely, quality reporting and learning from the incidents and ultimately cultivating a just and learning culture of patient safety.            ",Learning from patient safety events: A case base tool kit,8818528,R01HS022895,[' '],AHRQ,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,249655,0.04622739256534773
"Informatics Tools for Pharmacogenomic Discovery using Practice-based Data     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for observational research. More recently, huge efforts have linked EMR databases with archived biological material, to accelerate research in personalized medicine. EMR- linked DNA biobanks have identified common and rare genetic variants that contribute to risk of disease. An appealing vision, which has not been extensively explored, is to use EMRs-linked biobanks for pharmacogenomic studies, which identify associations between genetic variation and drug efficacy and toxicity. The longitudinal nature of the data contained within EMRs make them ideal for quantifying drug outcome (both efficacy and toxicity). Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large-scale studies of treatment outcome, specifically within the context of routine clinical care. Despite its success, EMR-based pharmacogenomic studies are often hampered by its data-intensive nature -- it is time- consuming and costly to extract and integrate data from multiple heterogeneous EMR databases, for large-scale pharmacogenomic studies. The Informatics for Integrating Biology and the Bedside (i2b2) is a National Center for Biomedical Computing based at Partners Healthcare System. I2b2 has developed a scalable informatics framework to enable clinical researchers to repurpose existing EMR data for clinical and genomic discovery. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by proposing the following specific aims: 1) Develop new methods to extract and model drug exposure and outcome information from EMR and integrate them with the i2b2 NLP components; 2) Build ontology tools to normalize and integrate pharmacogenomic data across different sites; 3) Conduct known and novel pharmacogenomic studies to evaluate and refine tools developed in Aim 1 and 2; and 4) Disseminate the developed informatics tools among pharmacogenomic researchers.         PUBLIC HEALTH RELEVANCE: Longitudinal electronic medical records (EMRs) linked with DNA biobanks have become valuable resources for genomic and pharmacogenomics research, allowing identification of associations between genetic variations and drug efficacy and toxicity. The Informatics for Integrating Biology and the Bedside (i2b2), a National Center for Biomedical Computing based at Partners Healthcare System, has developed a scalable informatics framework to enable clinical researchers to use existing EMR data for genomic knowledge discovery of diseases. In this study, we will collaborate with i2b2 to extend its informatics framework to the pharmacogenomics domain, by developing new natural language processing, ontology components, and user-friendly interfaces, and then apply these tools to real-world pharmacogenomic studies.            ",Informatics Tools for Pharmacogenomic Discovery using Practice-based Data,8629996,R01GM103859,"['Adverse event', 'Algorithms', 'Anthracyclines', 'Archives', 'Award', 'Biocompatible Materials', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Boston', 'Cardiotoxicity', 'Cells', 'Clinic', 'Clinical', 'Clinical Data', 'Clostridium difficile', 'Colitis', 'Communities', 'Computer software', 'Computerized Medical Record', 'Coupled', 'DNA', 'Data', 'Data Set', 'Databases', 'Disease', 'Drug Exposure', 'Drug toxicity', 'Electronics', 'Event', 'Foundations', 'Funding', 'Genetic Variation', 'Genomics', 'Genotype', 'Grant', 'Healthcare Systems', 'Heparin', 'Informatics', 'Information Management', 'Institution', 'Knowledge Discovery', 'Link', 'Medicine', 'Methods', 'Modeling', 'Morphologic artifacts', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Population Heterogeneity', 'Population Study', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Site', 'Standardization', 'Structure', 'System', 'Terminology', 'Text', 'Thrombocytopenia', 'Time', 'TimeLine', 'Toxic effect', 'Treatment outcome', 'United States National Institutes of Health', 'Vancomycin', 'Vision', 'Warfarin', 'base', 'biobank', 'case control', 'clinical care', 'clopidogrel', 'data integration', 'disorder risk', 'drug efficacy', 'exome sequencing', 'genetic variant', 'improved', 'large-scale database', 'novel', 'open source', 'public health relevance', 'rapid growth', 'rare variant', 'response', 'success', 'surveillance study', 'tool', 'user-friendly', 'virtual']",NIGMS,VANDERBILT UNIVERSITY,R01,2014,648591,-0.0075613908288467025
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in three subprojects which use natural language processing techniques:  1) We have developed a machine learning algorithm for abbreviation definition identification in text which makes use of what we term naturally labeled data. Positive training examples are naturally occurring potential abbreviation-definition pairs in text. Negative training examples are generated by randomly mixing potential abbreviations with unrelated potential definitions. The machine learner is trained to distinguish between these two sets of examples. Then, the learned feature weights are used to identify the abbreviation full form. This approach does not require manually labeled training data. We evaluate the performance of our algorithm on the Ab3P, BIOADI and Medstract corpora. Our system demonstrated results that compare favourably to the existing Ab3P and BIOADI systems. We achieve an F-measure of 91.36% on Ab3P corpus, and an F-measure of 87.13% on BIOADI corpus which are superior to the results reported by Ab3P and BIOADI systems. Moreover, we outperform these systems in terms of recall, which is one of our goals. 2) We are studying paraphrases in MEDLINE abstracts. These come about because an author is describing some entity of interest and uses a phrase like ""drug abuse"" and then needing to describe the same entity again a sentence or two latter does not wish to use exactly the same wording again and may use a variant of the phrase such as ""drug use"" which in the context of ""drug abuse"" has substantially the same meaning.  3) An author disambiguation algorithm has been developed which relies on machine learning based on the assumption that if an author name is infrequent in the data it probably represents the same person in all documents where it is found. This gives us positive instances. Negative instances are sampled from pairs of documents that have no author in common. Such positive and negative data allows us to do machine learning on all aspects of the document other than the name in question. This allows us to learn how to weight this data for best performance in distinguishing the positive and negative instances from each other. This learning is then applied in individual name cases or spaces to determine which author document pairs represent the same author. n/a",Natural Language Processing Techniques To Enhance Information Access.,8746735,ZIALM000090,"['Abbreviations', 'Algorithms', 'Automated Abstracting', 'Data', 'Dependency', 'Drug abuse', 'Drug usage', 'Goals', 'Individual', 'Information Retrieval', 'Label', 'Learning', 'MEDLINE', 'Machine Learning', 'Measures', 'Names', 'Natural Language Processing', 'Performance', 'Persons', 'Reporting', 'Sampling', 'System', 'Techniques', 'Text', 'Training', 'Variant', 'Weight', 'abstracting', 'base', 'indexing', 'interest', 'phrases', 'spelling', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2013,534204,0.02998052445495597
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) Code has been multithreaded and memory mapping capabilities added to speed up processing. 6) Most recently the code has been updated to work in a 64 bit environment.   The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system is currently proving useful in testing different retrieval parameters and methods on the PubMedHealth records.  We have recently developed a software system called DStor that allows us to store all of PubMed in a manner which is easily updateable and allows fast access. This system is now being used to maintain and update five different versions of the PubMed data twice a week. This system has greatly improved our access to PubMed data in various useful forms and we anctipate that its use will continue to grow. In addition we have developed software to maintain and update a list of strings where each string is associated with some fixed vector of integers. We currently maintain a list of all multi-word phrases without stop words or punctuation and with each is associated a vector of six integers representing counts of different types associated with each phrase where counts are computed over all PubMed records having abstracts. We also maintain a list of all one and two word phrases and MeSH terms in various forms (with & without stars and subheadings) and two counts with each consisting of the document frequency and the total frequency counting all occurrences in each document over all of PubMed. n/a",A Document Processing System,8746725,ZIALM000022,"['Code', 'Data', 'Databases', 'Environment', 'Frequencies', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'MeSH Thesaurus', 'Memory', 'Methods', 'Online Systems', 'Process', 'Programming Languages', 'PubMed', 'Records', 'Research', 'Retrieval', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Update', 'Work', 'abstracting', 'base', 'computerized data processing', 'improved', 'phrases', 'repository', 'software development', 'software systems', 'vector']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2013,102732,0.01803741764598154
"Measuring and Improving Colonoscopy Quality Using Natural Language Processing No abstract available  Prior research has shown that the quality of colonoscopy varies from physician to physician. It is important to address low quality because patients who see physicians with lower quality colonoscopies have a higher risk of developing colorectal cancer in the future. To help address poor quality of colonoscopy, we propose to use a computer software program to measure colonoscopy quality, survey physicians to understand why there is variation in quality, and test methods of physician feedback to stimulate quality improvement.                 ",Measuring and Improving Colonoscopy Quality Using Natural Language Processing,8752179,R01CA168959,"['Address', 'Affect', 'Cancer Etiology', 'Cecum', 'Cessation of life', 'Colon', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Detection', 'Effectiveness', 'Environment', 'Feedback', 'Future', 'Gastroenterology', 'Geographic Locations', 'Goals', 'Gold', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Incidence', 'Institution', 'Knowledge', 'Link', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Metric', 'Monitor', 'Names', 'Natural Language Processing', 'Pathology Report', 'Patients', 'Performance', 'Physicians', 'Provider', 'Randomized', 'Reading', 'Recommendation', 'Records', 'Reporting', 'Research', 'Risk', 'Science', 'Societies', 'Sum', 'Surveys', 'System', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Variant', 'Work', 'adenoma', 'base', 'colorectal cancer screening', 'computer science', 'cost effective', 'high risk', 'improved', 'innovation', 'medical specialties', 'novel', 'payment', 'peer', 'screening', 'symposium', 'tool']",NCI,HARVARD MEDICAL SCHOOL,R01,2013,634795,0.009543382197113273
"Phenotype Discovery in NHLBI Genomic Studies (PhD)    DESCRIPTION (provided by applicant): Abstract Researchers continually upload data into public repositories at a rapid pace, yet utilize few common standards for annotation, making it close to impossible to compare or associate data across studies. To address this problem, we will develop a defined meta- data model and build an integrated system called Phenotype Discovery (PhD) that enables researchers to query and find genomic studies of interest in public repositories as well as upload new data into our database (sdGaP), in a standardized manner. A Query Interpreter (QI) will utilize text mining and natural language processing techniques to map free text into concepts in biomedical ontologies, allowing non-structured queries to be answered efficiently. In Phase I of the project, we will develop a proof-of-concept system that can retrospectively structure phenotypic descriptions in dbGaP, and will work with domain experts in pneumology to build use cases and evaluate the automated mappings. In Phase II of the project, we will extend the domain expertise to cardiology, hematology, and sleep disorders to build a more comprehensive system, expanding the phenotype annotation to transcriptome databases, and integrating a flexible automated genotype annotation tool for sdGaP. We will develop a user-friendly interface to prospectively assist researchers in uploading their data with standardized phenotypic annotations. We will provide the tool for free from our website and continuously improve its quality, based on user feedback and usage data.        Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.         ",Phenotype Discovery in NHLBI Genomic Studies (PhD),8733018,UH3HL108785,"['Address', 'Bioinformatics', 'Cardiology', 'Characteristics', 'Collaborations', 'Computer software', 'Data', 'Databases', 'Deposition', 'Dictionary', 'Ensure', 'Environment', 'Feedback', 'Funding', 'Gene Expression Profile', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Informatics', 'Learning', 'Lung diseases', 'Maps', 'Methodology', 'Methods', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Privacy', 'Protocols documentation', 'Pulmonology', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Sleep Disorders', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Text', 'Training', 'Work', 'abstracting', 'base', 'biomedical informatics', 'biomedical ontology', 'data modeling', 'database of Genotypes and Phenotypes', 'flexibility', 'improved', 'interest', 'novel', 'programs', 'prototype', 'repository', 'study characteristics', 'text searching', 'tool', 'user-friendly', 'web site']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",UH3,2013,500000,-0.00638769649576948
"Text Processing and Geospatial Uncertainty for Phylogeography of Zoonotic Viruses     DESCRIPTION (provided by applicant): Phylogeography of zoonotic viruses studies the geographical spread and genetic lineages of viruses that are transmittable between animals and humans such as avian influenza and rabies. This science can help state public health and agriculture agencies identify the animal hosts that most impact virus propagation in a particular geographic region, the migration path of the virus including its origin, and the patterns of infection in various host populations, including humans, over time. The National Center for Biotechnology Information (NCBI), specifically GenBank, provides an abundance of available viral sequence data for phylogeography. Sequences and their metadata can be downloaded and imported into software applications that generate phylogeographic trees and models for surveillance. However, geospatial metadata such as host location is inconsistently represented and sparse across GenBank entries, with our preliminary studies showing only about 20% of the GenBank records contain specific information such as a county, town, or region within a state. While this detailed geospatial information might be included in the corresponding journal article, it is not available for immediate use in a bioinformatics or GIS application unless it is manually extracted and linked back to the appropriate sequence. Absence of precise sampling locations from easily-computable secondary data sources such as GenBank increases the difficulty of achieving accurate phylogeographic models of virus migration. We propose an infrastructure to improve phylogeographic models of virus migration by linking relevant geospatial data from the literature. This work represents the first effort to use automatically extracted geospatial data present in journal articles corresponding to GenBank records in order to enhance modeling of virus migration. Our research will extend phylogeography and zoonotic surveillance by: creating a Natural Language Processing (NLP) infrastructure that will improve the level of detail of geospatial data for phylogeography of zoonotic viruses (Aim 1), develop phylogeographic models using the data extracted in Aim 1 with adequate biostatistical models (Aim 2), and evaluating the impact of our approach for phylogeography and surveillance of zoonotic viruses (Aim 3). Thus, this work will provide researchers with a framework for population surveillance using an integrated biomedical informatics approach including NLP, biostatistics, bioinformatics, and database design.           We will create Natural Language Processing Infrastructure and novel phylogeographic models of zoonotic viruses that will allow state public health and agriculture agencies and other researchers to study virus migration. This will enhance population health surveillance including identification of the animal hosts that most impact virus propagation in a particular geographic region, the migration path of zoonotic pathogens, and the patterns of infection in various host populations over time, including humans. This resource will enable state agencies to implement improved public health control measures that will reduce morbidity and mortality of animals and humans from zoonotic diseases.                ",Text Processing and Geospatial Uncertainty for Phylogeography of Zoonotic Viruses,8698542,R56AI102559,"['Accounting', 'Address', 'Agriculture', 'Animals', 'Applied Research', 'Avian Influenza', 'Back', 'Bioinformatics', 'Biometry', 'Biotechnology', 'China', 'Computer software', 'Country', 'County', 'Data', 'Data Sources', 'Databases', 'Development', 'Disease', 'Epidemiologist', 'Evaluation', 'Event', 'Foundations', 'Funding', 'Genbank', 'Generations', 'Genes', 'Genetic', 'Genomics', 'Geographic Locations', 'Goals', 'Gold', 'Habitats', 'Hantavirus', 'Human', 'Infection', 'Influenza', 'Information Systems', 'Label', 'Link', 'Literature', 'Location', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Pattern', 'Population', 'Population Surveillance', 'Process', 'Public Health', 'Publications', 'Rabies', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Sampling', 'Science', 'Scientist', 'Solutions', 'Surveillance Modeling', 'System', 'Techniques', 'Text', 'Time', 'Trees', 'Uncertainty', 'Vertebrates', 'Viral', 'Viral Genome', 'Virus', 'Work', 'animal mortality', 'biomedical informatics', 'data modeling', 'database design', 'disease transmission', 'improved', 'journal article', 'migration', 'mortality', 'novel', 'pathogen', 'population health', 'web site']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R56,2013,451478,0.002201659148121558
"Probabilistic Disease Surveillance     DESCRIPTION (provided by applicant):         The proposed research will further develop and evaluate a probabilistic approach to disease surveillance. In this approach, a probabilistic case detection system (CDS) uses Bayesian diagnostic networks to compute the likelihoods of patient findings for each of a set of infectious diseases for every patient in a monitored population. CDS computes these likelihoods from data in electronic medical records, including information derived from free-text reports by natural language processing. CDS makes those estimates available to a probabilistic outbreak detection and characterization component (ODCS).             ODCS also utilizes a Bayesian approach to compute the probability that an outbreak is ongoing for each of a set of infectious diseases of interest, given information from CDS. ODCS also computes probability distributions over the current and future size of a detected outbreak and other characteristics such as incubation period used by public health officials when responding to an outbreak.                        The proposed research will extend the approach, which we have already developed and evaluated for the disease influenza to six additional respiratory infectious diseases. The research will also extend the capabilities of ODCS to utilize non-EMR data, detect an unknown disease, and detect and characterize concurrent outbreaks. The planned evaluations will measure the accuracy of both CDS and ODCS using historical surveillance data from two regions and simulated outbreak data, which we will create by adding outbreak cases generated by an agent-based epidemic simulator to real baseline surveillance data from non-outbreak periods.                        The innovation being advanced by this research is a novel, integrated, Bayesian approach for the early and accurate detection of cases of diseases that threaten health and for the detection and characterization of outbreaks of diseases that threaten public health. The proposed approach has significant potential to improve the information available to public health officials and physicians, which can be expected to improve clinical and public health decision making, and ultimately to improve population health.                  Project Relevance  The proposed research will improve the ability of public health officials and physicians to estimate the current incidence of influenza and other infectious diseases and to predict the future course of epidemics of those diseases. The improved information will better support decisions made by health departments to control epidemics, which is expected to reduce morbidity and mortality from epidemic diseases.",Probabilistic Disease Surveillance,8578484,R01LM011370,"['Accident and Emergency department', 'Advanced Development', 'Area', 'Characteristics', 'Clinical', 'Code', 'Communicable Diseases', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'County', 'Data', 'Data Sources', 'Decision Making', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Disease model', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Future', 'Health', 'Healthcare', 'Healthcare Systems', 'Incidence', 'Individual', 'Influenza', 'Intervention', 'Knowledge', 'Laboratories', 'Lung diseases', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Public Health', 'Public Health Practice', 'Publications', 'ROC Curve', 'Reporting', 'Research', 'Schools', 'Sensitivity and Specificity', 'Severities', 'Simulate', 'Sodium Chloride', 'Structure', 'Support System', 'System', 'Systems Integration', 'Testing', 'Text', 'Time', 'Topaz', 'Universities', 'Utah', 'Vaccination', 'advanced system', 'base', 'computer code', 'diagnostic accuracy', 'disorder control', 'follow-up', 'improved', 'influenza outbreak', 'innovation', 'interest', 'knowledge base', 'mortality', 'novel', 'novel strategies', 'operation', 'pandemic disease', 'population health', 'portability', 'reproductive', 'respiratory', 'surveillance data']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2013,590023,0.012850094520740941
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8413778,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2013,655370,0.03946333657474815
"Improving access to multi-lingual health information through machine translation No abstract available  PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8517814,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2013,323176,0.04167961826307417
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in three subprojects which use natural language processing techniques:  1) We have developed a machine learning algorithm for abbreviation definition identification in text which makes use of what we term naturally labeled data. Positive training examples are naturally occurring potential abbreviation-definition pairs in text. Negative training examples are generated by randomly mixing potential abbreviations with unrelated potential definitions. The machine learner is trained to distinguish between these two sets of examples. Then, the learned feature weights are used to identify the abbreviation full form. This approach does not require manually labeled training data. We evaluate the performance of our algorithm on the Ab3P, BIOADI and Medstract corpora. Our system demonstrated results that compare favourably to the existing Ab3P and BIOADI systems. We achieve an F-measure of 91.36% on Ab3P corpus, and an F-measure of 87.13% on BIOADI corpus which are superior to the results reported by Ab3P and BIOADI systems. Moreover, we outperform these systems in terms of recall, which is one of our goals. 2) We are studying paraphrases in MEDLINE abstracts. These come about because an author is describing some entity of interest and uses a phrase like ""drug abuse"" and then needing to describe the same entity again a sentence or two latter does not wish to use exactly the same wording again and may use a variant of the phrase such as ""drug use"" which in the context of ""drug abuse"" has substantially the same meaning.  3) An author disambiguation algorithm has been developed which relies on machine learning based on the assumption that if an author name is infrequent in the data it probably represents the same person in for all documents where it is found. This gives us positive instances. Negative instances are sampled from pairs of documents that have no author in common. Such positive and negative data allows us to do machine learning on all aspects of the document other than the name in question. This allows us to learn how to weight this data for best performance in distinguishing the positive and negative instances from each other. This learning is then applied in individual name cases or spaces to determine which author document pairs represent the same author. n/a",Natural Language Processing Techniques To Enhance Information Access.,8558106,ZIALM000090,"['Abbreviations', 'Algorithms', 'Automated Abstracting', 'Data', 'Dependency', 'Drug abuse', 'Drug usage', 'Goals', 'Individual', 'Information Retrieval', 'Label', 'Learning', 'MEDLINE', 'Machine Learning', 'Measures', 'Names', 'Natural Language Processing', 'Performance', 'Persons', 'Reporting', 'Sampling', 'System', 'Techniques', 'Text', 'Training', 'Variant', 'Weight', 'abstracting', 'base', 'indexing', 'interest', 'phrases', 'spelling', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2012,477226,0.02998052445495597
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",8318253,R01LM010016,"['Adverse event', 'Affect', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Evaluation', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2012,327503,0.0069846714944846915
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) Code has been multithreaded and memory mapping capabilities added to speed up processing. 6) Most recently the code has been updated to work in a 64 bit environment.   The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system is currently proving useful in testing different retrieval parameters and methods on the PubMedHealth records.  We have recently developed a software system called DStor that allows us to store all of PubMed in a manner which is easily updateable and allows fast access. This system is now being used to maintain and update five different versions of the PubMed data twice a week. This system has greatly improved our access to PubMed data in various useful forms and we anctipate that its use will continue to grow. n/a",A Document Processing System,8558096,ZIALM000022,"['Code', 'Data', 'Databases', 'Environment', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'Memory', 'Methods', 'Online Systems', 'Process', 'Programming Languages', 'PubMed', 'Records', 'Research', 'Retrieval', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Update', 'Work', 'base', 'computerized data processing', 'improved', 'repository', 'software systems']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2012,86768,0.019386782441653455
"Phenotype Discovery in NHLBI Genomic Studies (PhD)    DESCRIPTION (provided by applicant): Abstract Researchers continually upload data into public repositories at a rapid pace, yet utilize few common standards for annotation, making it close to impossible to compare or associate data across studies. To address this problem, we will develop a defined meta- data model and build an integrated system called Phenotype Discovery (PhD) that enables researchers to query and find genomic studies of interest in public repositories as well as upload new data into our database (sdGaP), in a standardized manner. A Query Interpreter (QI) will utilize text mining and natural language processing techniques to map free text into concepts in biomedical ontologies, allowing non-structured queries to be answered efficiently. In Phase I of the project, we will develop a proof-of-concept system that can retrospectively structure phenotypic descriptions in dbGaP, and will work with domain experts in pneumology to build use cases and evaluate the automated mappings. In Phase II of the project, we will extend the domain expertise to cardiology, hematology, and sleep disorders to build a more comprehensive system, expanding the phenotype annotation to transcriptome databases, and integrating a flexible automated genotype annotation tool for sdGaP. We will develop a user-friendly interface to prospectively assist researchers in uploading their data with standardized phenotypic annotations. We will provide the tool for free from our website and continuously improve its quality, based on user feedback and usage data.        Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.         ",Phenotype Discovery in NHLBI Genomic Studies (PhD),8303361,UH2HL108785,"['Address', 'Bioinformatics', 'Cardiology', 'Characteristics', 'Collaborations', 'Computer software', 'Data', 'Databases', 'Deposition', 'Dictionary', 'Ensure', 'Environment', 'Feedback', 'Funding', 'Gene Expression Profile', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Informatics', 'Learning', 'Lung diseases', 'Maps', 'Methodology', 'Methods', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Privacy', 'Protocols documentation', 'Pulmonology', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Sleep Disorders', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Text', 'Training', 'Work', 'abstracting', 'base', 'biomedical informatics', 'biomedical ontology', 'data modeling', 'database of Genotypes and Phenotypes', 'flexibility', 'improved', 'interest', 'novel', 'programs', 'prototype', 'repository', 'study characteristics', 'text searching', 'tool', 'user-friendly', 'web site']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",UH2,2012,516448,-0.00638769649576948
"An in-silico method for epidemiological studies using Electronic Medical Records Observational epidemiological studies are effective methods for identifying  factors affecting the health and illness of populations, as well as for determining optimal  treatments for diseases, such as cancers. However, conventional epidemiological  research usually involves personnel-intensive effort (such as manual chart and public  records review) and can be very time consuming before conclusive results are obtained.  Recently, a large amount of detailed longitudinal clinical data has been accumulated at  hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data  source for epidemiological studies. However, there are two obstacles that prevent the  wide usage of EMR data in epidemiological studies. First, most of the detailed clinical  information in EMRs is embedded in narrative text and it is very costly to extract that  information manually. Second, EMRs usually have data quality problems such as  selection bias and missing data, which require adaptation of conventional statistical  methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for  observational epidemiological studies using EMR data. We hypothesize that existing  EMR data can be used for certain types of epidemiological studies in a very efficient  manner with the help of informatics methods. The informatics-based approach will  contain two major components. One is an NLP (Natural Language Processing) based  information extraction system that can automatically extract detailed clinical information  from EMR and another is a set of statistical and informatics methods that can be used to  analyze EMR-derived data. If the feasibility of this approach is proven, it will change the  standard paradigm of observational epidemiological research, because it has the  capability to answer an epidemiological question in a very short time at a very low cost.   The specific aim of this study is to develop an automated informatics approach to  extract both fine-grained cancer findings and general clinical information from EMRs and  use them to conduct cancer related epidemiological studies. We will perform both case-  control and cohort studies related to prevention and treatment of breast and colon  cancers using EMR data. The informatics approach will be validated on EMRs from two  major hospitals to demonstrate its generalizability. Epidemiological findings from our  study will be compared to reported findings for validation. Project Narrative  According to the American Cancer Society, about 7.6 million people died from various  types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,8298614,R01CA141307,"['Address', 'Affect', 'American Cancer Society', 'Breast Cancer Treatment', 'Case-Control Studies', 'Cereals', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Collection', 'Data Quality', 'Data Sources', 'Databases', 'Discipline of Nursing', 'Disease', 'Documentation', 'Effectiveness', 'Epidemiologic Studies', 'Epidemiology', 'Ethics', 'Gold', 'Health', 'Healthcare Industry', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Language', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Education', 'Methods', 'Natural Language Processing', 'Nature', 'New York', 'Observational Study', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Play', 'Population', 'Presbyterian Church', 'Prevention', 'Process', 'Quality of Care', 'Radiology Specialty', 'Randomized Clinical Trials', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Risk Factors', 'Role', 'Selection Bias', 'Statistical Methods', 'Structure', 'Syndrome', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic Agents', 'Therapeutic procedure', 'Time', 'Translational Research', 'Universities', 'University Hospitals', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'clinical application', 'clinical practice', 'cost', 'efficacy testing', 'improved', 'malignant breast neoplasm', 'novel', 'prevent', 'prognostic indicator', 'public health research', 'statistics', 'treatment effect']",NCI,VANDERBILT UNIVERSITY,R01,2012,56569,-0.0055384958395470986
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8465025,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2012,40000,0.03946333657474815
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8213637,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2012,699362,0.03946333657474815
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453           PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8319670,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2012,352514,0.0368925720561588
"An insilico method for epidemiological studies using Electonic Medical Records Observational epidemiological studies are effective methods for identifying  factors affecting the health and illness of populations, as well as for determining optimal  treatments for diseases, such as cancers. However, conventional epidemiological  research usually involves personnel-intensive effort (such as manual chart and public  records review) and can be very time consuming before conclusive results are obtained.  Recently, a large amount of detailed longitudinal clinical data has been accumulated at  hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data  source for epidemiological studies. However, there are two obstacles that prevent the  wide usage of EMR data in epidemiological studies. First, most of the detailed clinical  information in EMRs is embedded in narrative text and it is very costly to extract that  information manually. Second, EMRs usually have data quality problems such as  selection bias and missing data, which require adaptation of conventional statistical  methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for  observational epidemiological studies using EMR data. We hypothesize that existing  EMR data can be used for certain types of epidemiological studies in a very efficient  manner with the help of informatics methods. The informatics-based approach will  contain two major components. One is an NLP (Natural Language Processing) based  information extraction system that can automatically extract detailed clinical information  from EMR and another is a set of statistical and informatics methods that can be used to  analyze EMR-derived data. If the feasibility of this approach is proven, it will change the  standard paradigm of observational epidemiological research, because it has the  capability to answer an epidemiological question in a very short time at a very low cost.   The specific aim of this study is to develop an automated informatics approach to  extract both fine-grained cancer findings and general clinical information from EMRs and  use them to conduct cancer related epidemiological studies. We will perform both case-  control and cohort studies related to prevention and treatment of breast and colon  cancers using EMR data. The informatics approach will be validated on EMRs from two  major hospitals to demonstrate its generalizability. Epidemiological findings from our  study will be compared to reported findings for validation. Project Narrative  According to the American Cancer Society, about 7.6 million people died from various  types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An insilico method for epidemiological studies using Electonic Medical Records,8589201,R01CA141307,[' '],NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2012,195838,-0.006531543388727244
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,8318797,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly woman', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2012,383445,0.005392198830064085
"Near Miss Narratives from the Fire Service: A Bayesian Analysis    DESCRIPTION (provided by applicant): This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source that has not yet been rigorously investigated. The proposal has 3 aims:  I. to use recently developed auto coding methods to characterize firefighter near miss narratives and classify these narratives into mechanisms of risk/injury. This analysis will apply the International Classification of External Cause of Injuries (ICECI) using Bayesian machine learning techniques to identify the various mechanisms captured in the near miss narratives and their relative prevalence.  II. To identify the correlation between each mechanism of risk/injury and each of the ""Contributing Factors"" listed on the NFFNMRS reporting form. The results will reveal any patterns and trends in the distribution of the contributing factors among the mechanisms, creating a deeper understanding of near miss circumstances, as well as a basis for improving the quality of future near miss data collection.  III. To use manual coding to identify actual injury incidents contained within a random sample of 1,000 near miss narratives and correlate these injuries with the ""Loss Potential"" categories on the NFFNMRS reporting form. The results will demonstrate how actual injuries are distributed within the reporting form's ""Loss Potential"" categories. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention. This study addresses a major gap in firefighter safety knowledge, i.e. the insufficient understanding of near miss events, and will have a high impact on efforts to improve the occupational health and safety of firefighters.         This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source, the NFFNMRS that has not yet been rigorously investigated. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention.         ",Near Miss Narratives from the Fire Service: A Bayesian Analysis,8325335,R03OH009984,[' '],NIOSH,DREXEL UNIVERSITY,R03,2012,76332,0.008641795635575792
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in four subprojects which use natural language processing techniques:  1) We have developed a machine learning algorithm for abbreviation definition identification in text which makes use of what we term naturally labeled data. Positive training examples are naturally occurring potential abbreviation-definition pairs in text. Negative training examples are generated by randomly mixing potential abbreviations with unrelated potential definitions. The machine learner is trained to distinguish between these two sets of examples. Then, the learned feature weights are used to identify the abbreviation full form. This approach does not require manually labeled training data. We evaluate the performance of our algorithm on the Ab3P, BIOADI and Medstract corpora. Our system demonstrated results that compare favourably to the existing Ab3P and BIOADI systems. We achieve an F-measure of 91.36% on Ab3P corpus, and an F-measure of 87.13% on BIOADI corpus which are superior to the results reported by Ab3P and BIOADI systems. Moreover, we outperform these systems in terms of recall, which is one of our goals. 2) We are studying paraphrases in MEDLINE abstracts. These come about because an author is describing some entity of interest and uses a phrase like ""drug abuse"" and then needing to describe the same entity again a sentence or two latter does not wish to use exactly the same wording again and may use a variant of the phrase such as ""drug use"" which in the context of ""drug abuse"" has substantially the same meaning.  3) An author disambiguation algorithm has been developed which relies on machine learning based on the assumption that if an author name is infrequent in the data it probably represents the same person in for all documents where it is found. This gives us positive instances. Negative instances are sampled from pairs of documents that have no author in common. Such positive and negative data allows us to do machine learning on all aspects of the document other than the name in question. This allows us to learn how to weight this data for best performance in distinguishing the positive and negative instances from each other. This learning is then applied in individual name cases or spaces to determine which author document pairs represent the same author. n/a",Natural Language Processing Techniques To Enhance Information Access.,8344949,ZIALM000090,"['Abbreviations', 'Algorithms', 'Automated Abstracting', 'Data', 'Dependency', 'Drug abuse', 'Drug usage', 'Goals', 'Individual', 'Information Retrieval', 'Label', 'Learning', 'MEDLINE', 'Machine Learning', 'Measures', 'Names', 'Natural Language Processing', 'Performance', 'Persons', 'Reporting', 'Sampling', 'System', 'Techniques', 'Text', 'Training', 'Variant', 'Weight', 'abstracting', 'base', 'indexing', 'interest', 'phrases', 'spelling', 'tool']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2011,539651,0.02998052445495597
"USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING    DESCRIPTION (provided by applicant): Understanding mechanisms of action is key to improving psychosocial interventions for cancer and other chronic disease conditions. In cancer, emotional expression has been identified as one possible mediator of the effect of psychosocial intervention on patient-reported outcomes. However, scientific evaluations of psychological mechanisms of adjustment to cancer and other chronic diseases are constrained by limitations associated with self-report measures. Because self-care resources, peer-to-peer networks, and more recent forms of psychosocial intervention are increasingly being delivered online, linguistic and behavioral data can be used to characterize internal coping processes, social interactions, and other manifest behaviors. Few tools are currently available for harnessing text as a potential data source, and signal detection indices of existing tools leave room for considerable improvement in these methodologies (Bantum & Owen, 2009). In the present study, natural language processing and other tools of computational linguistics will be used to develop a machine-learning classifier to identify emotional expression in electronic text data. The aims of the study are: 1) to annotate a large text corpus from cancer survivors using an objective and reliable emotion-coding procedure, 2) to incorporate linguistic and psychological features into a machine-learning classification method and identify which of these features are most strongly associated with codes assigned by trained human raters, and 3) to develop combined psychological and natural language processing (NLP) methods for identifying linguistic markers of emotional coping behaviors. To accomplish these aims, a comprehensive corpus of emotionally-laden cancer communications will be developed from 5 existing linguistic datasets. Five raters will be selected and undergo a rigorous training procedure for coding emotional expression using an emotion-coding system previously developed by the research. Coding will take place using an Internet-based coding interface that will allow the investigators to continuously monitor inter-rater reliability. Simultaneous with the coding process, the investigators will link the electronic text data with key linguistic and psychological features, including Linguistic Inquiry and Word Count (LIWC), Affective Norms for English Words (ANEW), WordNet, part of speech tags, patterns of capitalization and punctuation, emoticons, and textual context. A machine-learning classifier, using tools of natural language processing, will then be applied to the text/feature data and validated against human-rated emotion codes. The long-term objective of this research is to advance a methodology for objectively identifying coping behavior, particularly emotional expression, in order to supplement self-report measures and improve scientific understanding of adjustment to chronic disease, trauma, or other psychological conditions. This work is essential for identifying mechanisms of action in psychosocial interventions for cancer survivors and others and has significance for the fields of medicine, psychology, computational linguistics, and artificial intelligence.      PUBLIC HEALTH RELEVANCE: Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.           Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.",USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING,8120220,R21CA143642,"['Affective', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Cancer Intervention', 'Cancer Survivor', 'Categories', 'Characteristics', 'Chronic Disease', 'Classification', 'Code', 'Cognitive', 'Communication', 'Coping Behavior', 'Coping Skills', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Detection', 'Distress', 'Educational process of instructing', 'Effectiveness of Interventions', 'Electronics', 'Emotional', 'Emotions', 'Goals', 'Health', 'Health behavior', 'Heart Rate', 'Human', 'Hydrocortisone', 'Individual', 'Internet', 'Intervention', 'Intervention Studies', 'Left', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediator of activation protein', 'Medicine', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Predictive Value', 'Problem Solving', 'Procedures', 'Process', 'Psychological adjustment', 'Psychology', 'Publishing', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Recovery', 'Regulation', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Sampling', 'Scientific Evaluation', 'Screening procedure', 'Self Care', 'Signal Transduction', 'Social Interaction', 'Social support', 'Specificity', 'Speech', 'Survey Methodology', 'Sympathetic Nervous System', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Treatment/Psychosocial Effects', 'Work', 'anticancer research', 'base', 'behavior observation', 'computerized', 'computerized tools', 'coping', 'effective intervention', 'emotional experience', 'experience', 'improved', 'indexing', 'innovation', 'lexical', 'natural language', 'peer', 'programs', 'psychologic', 'psychosocial', 'public health relevance', 'showing emotion', 'skills', 'skills training', 'symptom management', 'tool']",NCI,LOMA LINDA UNIVERSITY,R21,2011,161797,0.005981109928717229
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,8144459,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2011,147161,0.019303748581653287
"A Study of Social Web Data on Buprenorphine Abuse Using Semantic Web Technology    DESCRIPTION (provided by applicant): The non-medical use of pharmaceutical opioids has been identified as one of the fastest growing forms of drug abuse in the U.S. There is a critical need to enhance current epidemiological monitoring, early warning, and post-marketing surveillance systems by providing additional and more timely data. The World Wide Web has been identified as one of the ""leading edge"" data sources for detecting patterns and changes in drug use practices. Many websites provide a venue for individuals to freely share their own experiences, post questions, and offer comments about different drugs. Such User Generated Content (UGC) can be used as a very rich data source to study knowledge, attitudes, and behaviors related to illicit drugs. To harness the full potential of the Web for drug abuse research, the field needs to develop a highly automated way of accessing, extracting, and analyzing Web-based data related to illicit drug use. This exploratory R21 is a multi-principal investigator, collaborative effort between researchers at the Center for Interventions, Treatment and Addictions Research (CITAR) and the Center for Knowledge-Enabled Information Services and Science (Kno.e.sis) at Wright State University. The purpose of this Web-based study is to apply cutting-edge information processing techniques, such as the Semantic Web, Natural Language Processing, and Machine Learning, to qualitative and quantitative content analysis of user generated content to achieve the following aims: 1) Describe drug users' knowledge, attitudes, and behaviors related to the illicit use of Suboxone(R) (buprenorphine/naloxone) and Subutex(R) (buprenorphine); 2) Identify and describe temporal patterns of the illicit use of these drugs as reflected on web-based forums. To collect data, the study will use websites that allow for the free discussion of illicit drugs, contain information on illicit prescription drug use, and are accessible for public viewing. The study will generate new information about the practices of buprenorphine abuse and will contribute to the advancement of public health and substance abuse research by providing automatic coding and information extraction tools needed to handle rapidly growing Web-based data. Automated information extraction methods applied in this study will enhance current early warning and epidemiological surveillance systems and could advance qualitative and Web-based research methods in other areas of public health.      PUBLIC HEALTH RELEVANCE: Building on inter-disciplinary collaboration and cutting-edge information processing techniques, this exploratory, Web-based study will generate new information about Suboxone(R) (buprenorphine/naloxone) and Subutex(R) (buprenorphine) abuse practices, thereby informing public health interventions and policy. It will also contribute to the advancement of public health and substance abuse research methods by providing automatic coding and information extraction tools needed to handle rapidly growing Web-based data.              Building on inter-disciplinary collaboration and cutting-edge information processing techniques, this exploratory, Web-based study will generate new information about Suboxone(R) (buprenorphine/naloxone) and Subutex(R) (buprenorphine) abuse practices, thereby informing public health interventions and policy. It will also contribute to the advancement of public health and substance abuse research methods by providing automatic coding and information extraction tools needed to handle rapidly growing Web-based data.            ",A Study of Social Web Data on Buprenorphine Abuse Using Semantic Web Technology,8190799,R21DA030571,"['Accident and Emergency department', 'Archives', 'Area', 'Behavior', 'Buprenorphine', 'Code', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Data', 'Data Sources', 'Drug Rehabilitation Centers', 'Drug abuse', 'Drug usage', 'Drug user', 'Early identification', 'Epidemiologic Monitoring', 'Epidemiologic Studies', 'Epidemiology', 'Face', 'Health', 'Health Knowledge, Attitudes, Practice', 'Health Professional', 'Heroin Dependence', 'Hospitals', 'Illicit Drugs', 'Individual', 'Information Sciences', 'Information Services', 'Information Systems', 'Internet', 'Intervention', 'Intervention Studies', 'Interview', 'Knowledge', 'Label', 'Language', 'Link', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Monitor', 'NIH Program Announcements', 'Naloxone', 'Natural Language Processing', 'Online Systems', 'Opioid', 'Overdose', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Poison Control Centers', 'Policies', 'Population', 'Prevention', 'Principal Investigator', 'Process', 'Public Health', 'Published Comment', 'Qualitative Research', 'Reading', 'Reliance', 'Research', 'Research Methodology', 'Research Personnel', 'Sampling', 'Selection Bias', 'Self Disclosure', 'Semantics', 'Source', 'Substance abuse problem', 'Subutex', 'Surveillance Methods', 'Surveys', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'addiction', 'buprenorphine abuse', 'computer based Semantic Analysis', 'design', 'emotional disclosure', 'empowered', 'experience', 'informant', 'information processing', 'misuse of prescription only drugs', 'population survey', 'post-market', 'prescription drug abuse', 'programs', 'response', 'social', 'tool', 'trend', 'web site', 'working group']",NIDA,WRIGHT STATE UNIVERSITY,R21,2011,219000,-0.02125077424061771
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",8105502,R01LM010016,"['Adverse event', 'Affect', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Evaluation', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2011,333575,0.0069846714944846915
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) The latest work on this system has involved adding the ability to generate themes using an EM algorithm approach. Also recently code has been multithreaded and memory mapping capabilities added to speed up processing.  The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system is currently proving useful in testing different retrieval parameters and methods on the PubMedHealth records. n/a",A Document Processing System,8344939,ZIALM000022,"['Algorithms', 'Code', 'Data', 'Databases', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'Memory', 'Methods', 'Online Systems', 'Process', 'Programming Languages', 'PubMed', 'Records', 'Research', 'Retrieval', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Work', 'base', 'computerized data processing', 'repository', 'software systems']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2011,79948,0.025056650143701318
"Phenotype Discovery in NHLBI Genomic Studies (PhD)    DESCRIPTION (provided by applicant): Abstract Researchers continually upload data into public repositories at a rapid pace, yet utilize few common standards for annotation, making it close to impossible to compare or associate data across studies. To address this problem, we will develop a defined meta- data model and build an integrated system called Phenotype Discovery (PhD) that enables researchers to query and find genomic studies of interest in public repositories as well as upload new data into our database (sdGaP), in a standardized manner. A Query Interpreter (QI) will utilize text mining and natural language processing techniques to map free text into concepts in biomedical ontologies, allowing non-structured queries to be answered efficiently. In Phase I of the project, we will develop a proof-of-concept system that can retrospectively structure phenotypic descriptions in dbGaP, and will work with domain experts in pneumology to build use cases and evaluate the automated mappings. In Phase II of the project, we will extend the domain expertise to cardiology, hematology, and sleep disorders to build a more comprehensive system, expanding the phenotype annotation to transcriptome databases, and integrating a flexible automated genotype annotation tool for sdGaP. We will develop a user-friendly interface to prospectively assist researchers in uploading their data with standardized phenotypic annotations. We will provide the tool for free from our website and continuously improve its quality, based on user feedback and usage data.      PUBLIC HEALTH RELEVANCE: Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.           Relevance Phenotype Discovery (PhD) represents a novel, automated system to describe the characteristics of patients whose genetic information is available in public data repositories, without compromising their privacy. This initiative is greatly needed so that more researchers can make use of data collected from projects funded by public agencies. PhD uses new methodology for natural language processing and semantic integration to interpret the narrative text as well as variables and their values from studies in genomic databases. Standardized terminologies will be utilized to ensure that data can be analyzed across different studies.         ",Phenotype Discovery in NHLBI Genomic Studies (PhD),8145134,UH2HL108785,"['Address', 'Bioinformatics', 'Cardiology', 'Characteristics', 'Collaborations', 'Computer software', 'Data', 'Databases', 'Deposition', 'Dictionary', 'Ensure', 'Environment', 'Feedback', 'Funding', 'Gene Expression Profile', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Hematology', 'Informatics', 'Learning', 'Lung diseases', 'Maps', 'Methodology', 'Methods', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Privacy', 'Protocols documentation', 'Pulmonology', 'Research', 'Research Personnel', 'Scientist', 'Semantics', 'Sleep Disorders', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Text', 'Training', 'Work', 'abstracting', 'base', 'biomedical informatics', 'biomedical ontology', 'data modeling', 'database of Genotypes and Phenotypes', 'flexibility', 'improved', 'interest', 'novel', 'programs', 'prototype', 'repository', 'study characteristics', 'text searching', 'tool', 'user-friendly', 'web site']",NHLBI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",UH2,2011,540294,0.0015746896271708092
"An in-silico method for epidemiological studies using Electronic Medical Records DESCRIPTION: Observational epidemiological studies are effective methods for identifying factors affecting the health and illness of populations, as well as for determining optimal treatments for diseases, such as cancers. However, conventional epidemiological research usually involves personnel-intensive effort (such as manual chart and public records review) and can be very time consuming before conclusive results are obtained. Recently, a large amount of detailed longitudinal clinical data has been accumulated at hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data source for epidemiological studies. However, there are two obstacles that prevent the wide usage of EMR data in epidemiological studies. First, most of the detailed clinical information in EMRs is embedded in narrative text and it is very costly to extract that information manually. Second, EMRs usually have data quality problems such as selection bias and missing data, which require adaptation of conventional statistical methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for observational epidemiological studies using EMR data. We hypothesize that existing EMR data can be used for certain types of epidemiological studies in a very efficient manner with the help of informatics methods. The informatics-based approach will contain two major components. One is an NLP (Natural Language Processing) based information extraction system that can automatically extract detailed clinical information from EMR and another is a set of statistical and informatics methods that can be used to analyze EMR-derived data. If the feasibility of this approach is proven, it will change the standard paradigm of observational epidemiological research, because it has the capability to answer an epidemiological question in a very short time at a very low cost. The specific aim of this study is to develop an automated informatics approach to extract both fine-grained cancer findings and general clinical information from EMRs and use them to conduct cancer related epidemiological studies. We will perform both casecontrol and cohort studies related to prevention and treatment of breast and colon cancers using EMR data. The informatics approach will be validated on EMRs from two major hospitals to demonstrate its generalizability. Epidemiological findings from our study will be compared to reported findings for validation.  Project Narrative According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of cancers and to determine optimal treatments of cancers, and epidemiological study is one of the methods to achieve it. This proposed study will use natural language processing technologies to automatically extract fine-grained cancer information from existing patient electronic medical records and use it to conduct cancer related epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,8110041,R01CA141307,"['Affect', 'American Cancer Society', 'Breast Cancer Treatment', 'Cereals', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Quality', 'Data Sources', 'Disease', 'Epidemiologic Studies', 'Epidemiology', 'Health', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Natural Language Processing', 'Patients', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Selection Bias', 'Statistical Methods', 'System', 'Technology', 'Text', 'Time', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'cost', 'prevent']",NCI,VANDERBILT UNIVERSITY,R01,2011,252298,-0.005612176511910946
"Functional neuroimaging of language processing in primary progressive aphasia No abstract available  PPA is a devastating disorder that prevents individuals from communicating and functioning in society. The knowledge gained in this study will increase our understanding of the neural basis of language processing and its breakdown in PPA, and will contribute to earlier, more accurate differential diagnosis of PPA variants, enabling emerging therapies to be targeted to likely underlying etiologies.",Functional neuroimaging of language processing in primary progressive aphasia,8207220,R03DC010878,"['Address', 'Affect', 'Aging', 'Agrammatism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anterior', 'Aphasia', 'Atrophic', 'Characteristics', 'Clinical', 'Cognitive', 'Complement', 'Comprehension', 'Data', 'Diagnosis', 'Differential Diagnosis', 'Discrimination', 'Disease', 'Etiology', 'Frontotemporal Dementia', 'Functional Aphasias', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Goals', 'Grant', 'Image', 'Individual', 'Inferior', 'Knowledge', 'Language', 'Left', 'Linguistics', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Memory', 'Neurologic', 'Neurons', 'Patients', 'Pattern', 'Play', 'Primary Progressive Aphasia', 'Process', 'Progressive Aphasias', 'Recruitment Activity', 'Research', 'Role', 'Semantic Dementias', 'Short-Term Memory', 'Societies', 'Speech', 'Stroke', 'Syndrome', 'System', 'Taxes', 'Temporal Lobe', 'Variant', 'Work', 'base', 'cerebral atrophy', 'cohort', 'frontal lobe', 'improved', 'language processing', 'lexical', 'neuroimaging', 'neuropsychological', 'normal aging', 'prevent', 'programs', 'relating to nervous system', 'syntax']",NIDCD,UNIVERSITY OF ARIZONA,R03,2011,121967,0.011287958970452889
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,8020057,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Award', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2011,698439,0.03946333657474815
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453           PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,8138590,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2011,356340,0.0368925720561588
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,8143550,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly woman', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2011,389385,0.005392198830064085
"Near Miss Narratives from the Fire Service: A Bayesian Analysis    DESCRIPTION (provided by applicant): This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source that has not yet been rigorously investigated. The proposal has 3 aims:  I. to use recently developed auto coding methods to characterize firefighter near miss narratives and classify these narratives into mechanisms of risk/injury. This analysis will apply the International Classification of External Cause of Injuries (ICECI) using Bayesian machine learning techniques to identify the various mechanisms captured in the near miss narratives and their relative prevalence.  II. To identify the correlation between each mechanism of risk/injury and each of the ""Contributing Factors"" listed on the NFFNMRS reporting form. The results will reveal any patterns and trends in the distribution of the contributing factors among the mechanisms, creating a deeper understanding of near miss circumstances, as well as a basis for improving the quality of future near miss data collection.  III. To use manual coding to identify actual injury incidents contained within a random sample of 1,000 near miss narratives and correlate these injuries with the ""Loss Potential"" categories on the NFFNMRS reporting form. The results will demonstrate how actual injuries are distributed within the reporting form's ""Loss Potential"" categories. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention. This study addresses a major gap in firefighter safety knowledge, i.e. the insufficient understanding of near miss events, and will have a high impact on efforts to improve the occupational health and safety of firefighters.      PUBLIC HEALTH RELEVANCE:  This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source, the NFFNMRS that has not yet been rigorously investigated. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention.            This study will analyze the narrative text fields in all National Fire Fighter Near-Miss Reporting System (NFFNMRS) reports submitted since the system was created in 2005 (3,695 reports as of September 30, 2009). Near miss reporting systems have made major contributions to safety in such industries as aviation, nuclear power, petrochemical processing, steel production, and military operations, because the same patterns of causes of failure and their relations precede both adverse events and near misses. However, firefighters and researchers lack a scientific system to fully analyze the near miss data collected each year. This innovative effort will advance knowledge in firefighter safety by applying novel Bayesian methods of analysis to the narrative text fields of a new data source, the NFFNMRS that has not yet been rigorously investigated. This proposed study of the near miss narrative text in combination with coded data has the potential to reveal new insights that can strengthen firefighter safety through primary prevention.         ",Near Miss Narratives from the Fire Service: A Bayesian Analysis,8206110,R03OH009984,[' '],NIOSH,DREXEL UNIVERSITY,R03,2011,74075,0.007742104114914777
"USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING    DESCRIPTION (provided by applicant): Understanding mechanisms of action is key to improving psychosocial interventions for cancer and other chronic disease conditions. In cancer, emotional expression has been identified as one possible mediator of the effect of psychosocial intervention on patient-reported outcomes. However, scientific evaluations of psychological mechanisms of adjustment to cancer and other chronic diseases are constrained by limitations associated with self-report measures. Because self-care resources, peer-to-peer networks, and more recent forms of psychosocial intervention are increasingly being delivered online, linguistic and behavioral data can be used to characterize internal coping processes, social interactions, and other manifest behaviors. Few tools are currently available for harnessing text as a potential data source, and signal detection indices of existing tools leave room for considerable improvement in these methodologies (Bantum & Owen, 2009). In the present study, natural language processing and other tools of computational linguistics will be used to develop a machine-learning classifier to identify emotional expression in electronic text data. The aims of the study are: 1) to annotate a large text corpus from cancer survivors using an objective and reliable emotion-coding procedure, 2) to incorporate linguistic and psychological features into a machine-learning classification method and identify which of these features are most strongly associated with codes assigned by trained human raters, and 3) to develop combined psychological and natural language processing (NLP) methods for identifying linguistic markers of emotional coping behaviors. To accomplish these aims, a comprehensive corpus of emotionally-laden cancer communications will be developed from 5 existing linguistic datasets. Five raters will be selected and undergo a rigorous training procedure for coding emotional expression using an emotion-coding system previously developed by the research. Coding will take place using an Internet-based coding interface that will allow the investigators to continuously monitor inter-rater reliability. Simultaneous with the coding process, the investigators will link the electronic text data with key linguistic and psychological features, including Linguistic Inquiry and Word Count (LIWC), Affective Norms for English Words (ANEW), WordNet, part of speech tags, patterns of capitalization and punctuation, emoticons, and textual context. A machine-learning classifier, using tools of natural language processing, will then be applied to the text/feature data and validated against human-rated emotion codes. The long-term objective of this research is to advance a methodology for objectively identifying coping behavior, particularly emotional expression, in order to supplement self-report measures and improve scientific understanding of adjustment to chronic disease, trauma, or other psychological conditions. This work is essential for identifying mechanisms of action in psychosocial interventions for cancer survivors and others and has significance for the fields of medicine, psychology, computational linguistics, and artificial intelligence.      PUBLIC HEALTH RELEVANCE: Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.           Identifying specific emotional, cognitive, and behavioral factors that contribute to adjustment to cancer and other chronic diseases is essential for being able to develop and improve effective interventions to promote health and well-being. To date, the study of these factors as mechanisms of action has been limited to self-report measures that may not correlate well with other more objective indicators. The proposed study will improve our ability to identify mechanisms of action by supplementing self-report measures with objectively identified markers of coping behaviors such as emotional expression in natural language used by individuals living with cancer.",USE OF NATURAL LANGUAGE PROCESSING TO IDENTIFY LINGUISTIC MARKERS OF COPING,7991498,R21CA143642,"['Affective', 'Artificial Intelligence', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Cancer Intervention', 'Cancer Survivor', 'Categories', 'Characteristics', 'Chronic Disease', 'Classification', 'Code', 'Cognitive', 'Communication', 'Coping Behavior', 'Coping Skills', 'Data', 'Data Set', 'Data Sources', 'Decision Making', 'Detection', 'Distress', 'Educational process of instructing', 'Effectiveness of Interventions', 'Electronics', 'Emotional', 'Emotions', 'Goals', 'Health', 'Health behavior', 'Heart Rate', 'Human', 'Hydrocortisone', 'Individual', 'Internet', 'Intervention', 'Intervention Studies', 'Left', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediator of activation protein', 'Medicine', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Predictive Value', 'Problem Solving', 'Procedures', 'Process', 'Psychological adjustment', 'Psychology', 'Publishing', 'Quality of life', 'Recommendation', 'Recording of previous events', 'Recovery', 'Regulation', 'Relative (related person)', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Sampling', 'Scientific Evaluation', 'Screening procedure', 'Self Care', 'Signal Transduction', 'Social Interaction', 'Social support', 'Specificity', 'Speech', 'Survey Methodology', 'Sympathetic Nervous System', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Trauma', 'Treatment/Psychosocial Effects', 'Work', 'anticancer research', 'base', 'behavior observation', 'computerized', 'computerized tools', 'coping', 'effective intervention', 'emotional experience', 'experience', 'improved', 'indexing', 'innovation', 'lexical', 'natural language', 'peer', 'programs', 'psychologic', 'psychosocial', 'public health relevance', 'showing emotion', 'skills', 'skills training', 'symptom management', 'tool']",NCI,LOMA LINDA UNIVERSITY,R21,2010,223207,0.005981109928717229
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in four subprojects which use natural language processing techniques:  1) The presence of unrecognized abbreviations in text hinders indexing algorithms and adversely affects information retrieval and extraction.  Automatic abbreviation definition identification can help resolve these issues.  However, abbreviations and their definitions identified by an automatic process are of uncertain validity.  Due to the size of databases such as MEDLINE only a small fraction of abbreviation-definition pairs can be examined manually.  An automatic way to estimate the accuracy of abbreviation-definition pairs extracted from text is needed.  We have proposed an abbreviation definition identification algorithm that employs a variety of strategies to identify the most probable abbreviation definition.  In addition our algorithm produces an accuracy estimate, pseudo-precision, for each strategy without using a human-judged gold standard. The pseudo-precisions determine the order in which the algorithm applies the strategies in seeking to identify the definition of an abbreviation. The results are generally a couple of percentage points better than the Schwartz-Hearst algorithm and also allow one to enforce a threshold for those applications where high precision is critical. In recent work we are extending this approach using machine learning to apply it to more abbreviation instances. 2) We are studying paraphrases in MEDLINE abstracts. These come about because an author is describing some entity of interest and uses a phrase like ""drug abuse"" and then needing to describe the same entity again a sentence or two latter does not wish to use exactly the same wording again and may use a variant of the phrase such as ""drug use"" which in the context of ""drug abuse"" has substantially the same meaning.  3) An author disambiguation algorithm has been developed which relies on machine learning based on the assumption that if an author name is infrequent in the data it probably represents the same person in for all documents where it is found. This gives us positive instances. Negative instances are sampled from pairs of documents that have no author in common. Such positive and negative data allows us to do machine learning on all aspects of the document other than the name in question. This allows us to learn how to weight this data for best performance in distinguishing the positive and negative instances from each other. This learning is then applied in individual name cases or spaces to determine which author document pairs represent the same author. n/a",Natural Language Processing Techniques To Enhance Information Access.,8149603,ZIALM000090,"['Natural Language Processing', 'Techniques']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2010,450501,0.01923944233499189
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7936999,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Epidemiology', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Mental Depression', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2010,499697,0.030589328755736205
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7921455,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2010,148350,0.019303748581653287
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7779983,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,343397,0.0069846714944846915
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,8142701,R01LM010140,"['Affect', 'Case Study', 'Curiosities', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Goals', 'Hand', 'Hospitals', 'Laboratories', 'Literature', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Persons', 'Population', 'Presbyterian Church', 'Rare Diseases', 'Reporting', 'Statistical Methods', 'Stream', 'System', 'Testing', 'blind', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'statistics', 'virology']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,10000,0.0046567880392566156
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,7828239,R01LM010140,"['Affect', 'Case Study', 'Curiosities', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Goals', 'Hand', 'Hospitals', 'Laboratories', 'Literature', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Persons', 'Population', 'Presbyterian Church', 'Rare Diseases', 'Reporting', 'Statistical Methods', 'Stream', 'System', 'Testing', 'blind', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'statistics', 'virology']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,531496,0.0046567880392566156
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7942766,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2010,320155,0.0429267158532645
"An in-silico method for epidemiological studies using Electronic Medical Records DESCRIPTION: Observational epidemiological studies are effective methods for identifying factors affecting the health and illness of populations, as well as for determining optimal treatments for diseases, such as cancers. However, conventional epidemiological research usually involves personnel-intensive effort (such as manual chart and public records review) and can be very time consuming before conclusive results are obtained. Recently, a large amount of detailed longitudinal clinical data has been accumulated at hospitals' Electronic Medical Records (EMR) systems and it has become a valuable data source for epidemiological studies. However, there are two obstacles that prevent the wide usage of EMR data in epidemiological studies. First, most of the detailed clinical information in EMRs is embedded in narrative text and it is very costly to extract that information manually. Second, EMRs usually have data quality problems such as selection bias and missing data, which require adaptation of conventional statistical methods developed for randomized controlled trials.   In this study, we propose an in silico informatics-based approach for observational epidemiological studies using EMR data. We hypothesize that existing EMR data can be used for certain types of epidemiological studies in a very efficient manner with the help of informatics methods. The informatics-based approach will contain two major components. One is an NLP (Natural Language Processing) based information extraction system that can automatically extract detailed clinical information from EMR and another is a set of statistical and informatics methods that can be used to analyze EMR-derived data. If the feasibility of this approach is proven, it will change the standard paradigm of observational epidemiological research, because it has the capability to answer an epidemiological question in a very short time at a very low cost. The specific aim of this study is to develop an automated informatics approach to extract both fine-grained cancer findings and general clinical information from EMRs and use them to conduct cancer related epidemiological studies. We will perform both casecontrol and cohort studies related to prevention and treatment of breast and colon cancers using EMR data. The informatics approach will be validated on EMRs from two major hospitals to demonstrate its generalizability. Epidemiological findings from our study will be compared to reported findings for validation. Narrative: According to the American Cancer Society, about 7.6 million people died from various types of cancer in the world during 2007. It is very important to identify risk factors of  cancers and to determine optimal treatments of cancers, and epidemiological study is  one of the methods to achieve it. This proposed study will use natural language  processing technologies to automatically extract fine-grained cancer information from  existing patient electronic medical records and use it to conduct cancer related  epidemiological studies, thus accelerating knowledge accumulation of cancer research.",An in-silico method for epidemiological studies using Electronic Medical Records,7925776,R01CA141307,"['Affect', 'American Cancer Society', 'Breast', 'Cereals', 'Clinical', 'Clinical Data', 'Cohort Studies', 'Colon Carcinoma', 'Computer Simulation', 'Computerized Medical Record', 'Data', 'Data Quality', 'Data Sources', 'Disease', 'Epidemiologic Studies', 'Epidemiology', 'Health', 'Hospitals', 'Human Resources', 'Informatics', 'Knowledge', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Natural Language Processing', 'Patients', 'Population', 'Prevention', 'Randomized Controlled Trials', 'Records', 'Reporting', 'Research', 'Risk Factors', 'Selection Bias', 'Statistical Methods', 'System', 'Technology', 'Text', 'Time', 'Validation', 'anticancer research', 'base', 'cancer therapy', 'cancer type', 'cost', 'prevent']",NCI,VANDERBILT UNIVERSITY,R01,2010,259993,-0.0055983435575504645
"New Resources for e-Patients    DESCRIPTION (provided by applicant): ""New Resources for e-Patients"" addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in currently available online health information resources. It will maximize the value of public domain health information from U.S. Government sources. Textual consumer health information will be collected from NIH, FDA and other government sources. This information will be subjected to automated topic analysis and classification using methods of natural language processing and statistical text-mining to discover and extract topics on i) diseases and conditions; ii) treatments, benefits and risks; and iii) genomic risks and responses. These topics will be integrated and mapped to the most frequent health topics of interest to consumers. Personally-controlled electronic health records and personal genotypes will be studied for their potential contributions to personalized medicine for e-patients. Phase I of this project will achieve proof-of-principle and develop an advanced prototype as a foundation for construction of a new web-based resource in Phase II.    PUBLIC HEALTH RELEVANCE: This project addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in current online health information resources and also target new opportunities in genomic and personalized medicine. In the process we will create consumer-friendly, automated systems that make online information search and retrieval more efficient more efficient and maximize the value of public domain health information from U.S. Government sources. The work will lead to more reliable, personalized and actionable information for a new generation of web-savvy and socially-networked ""e-patients"" and will lead to more efficient and productive encounters between patients and healthcare systems.           This project addresses the unmet medical needs of consumers who search for  health and healthcare information online, currently a population of more than  160 million people in the U.S. It will fill gaps and address deficiencies in current  online health information resources and also target new opportunities in  genomic and personalized medicine. In the process we will create consumer-  friendly, automated systems that make online information search and retrieval  more efficient more efficient and maximize the value of public domain health  information from U.S. Government sources. The work will lead to more reliable,  personalized and actionable information for a new generation of web-savvy and  socially-networked ""e-patients"" and will lead to more efficient and productive  encounters between patients and healthcare systems.",New Resources for e-Patients,8129905,R43HG005046,"['Address', 'Benefits and Risks', 'Businesses', 'Classification', 'Communication', 'Data', 'Development', 'Development Plans', 'Disease', 'Electronic Health Record', 'Foundations', 'Fund Raising', 'Generations', 'Genes', 'Genomics', 'Genotype', 'Government', 'Health', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Information Resources', 'Institutes', 'Internet', 'Lead', 'Maps', 'Marketing', 'Medical', 'Medicine', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Public Domains', 'Research', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Site', 'Source', 'Surveys', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Update', 'Validation', 'Work', 'base', 'commercialization', 'data integration', 'design', 'health record', 'interest', 'prototype', 'public health relevance', 'research study', 'response', 'text searching', 'web site']",NHGRI,"RESOUNDING HEALTH, INC.",R43,2010,35000,-0.0013502670142054773
"Online Social Networking as an Alternative Information Source for Clinical Resear    DESCRIPTION (provided by applicant): Clinical trials and patient records have been the main information sources for clinical research. While well- designed clinical trials can produce high quality data, they are generally very expensive and time consuming. Prior studies have also shown that patients enrolled in clinical trials are not necessarily representative of the general patient population. Chart reviews, which rely on the patient records, avoid some of the drawbacks of the clinical trials approach. Although chart review studies are more labor intensive, new developments in structured data entry and natural language processing (NLP) are helping to automate the process. However, studies which use chart reviews are limited by the accuracy and completeness of the data in the records.       In the past decade, online social networks have grown exponentially. Some health-focused social network sites have attracted large numbers of users and begun accumulating large quantities of detailed clinical information. The PatientsLikeMe site, for instance, has about 3,200 amyotrophic lateral sclerosis (ALS) patients worldwide, and includes about 5% of the ALS population in the US. Information gathered by online social networks is primarily intended for patients to share with each other. Such information has also begun to attract the attention of medical researchers.[3, 4]       Because using information from online social networks for medical research is a fairly new phenomenon, the value and limitation of this type of information source have not been systematically examined. To do so, we propose to conduct a comparison study of patient-contributed information from PatientsLikeMe and records from a large medical record data repository - the Research Patient Data Registry (RPDR) of the Partners Healthcare Systems. The proposed study will focus on ALS, multiple sclerosis (MS), and Parkinson's disease (PD). The general goal is to explore how the medical record and online networking data differ, and if and how online networking data could complement the medical record data. The specific aims are:    1) Extract symptom and treatment information from the two different data sources.    2) Compare the prevalence of symptoms and treatments from the two information sources and analyze the difference.    3) Extract treatment response of prescription medications from PatientsLikeMe and analyze the confounding effect of the misunderstanding of medication indication.      PUBLIC HEALTH RELEVANCE: The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.           The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.",Online Social Networking as an Alternative Information Source for Clinical Resear,7941839,R21NS067463,"['Amyotrophic Lateral Sclerosis', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Communities', 'Comparative Study', 'Complement', 'Data', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Enrollment', 'Frequencies', 'Goals', 'Healthcare Systems', 'Medical Records', 'Medical Research', 'Multiple Sclerosis', 'Natural Language Processing', 'Nature', 'Parkinson Disease', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Prevalence', 'Process', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Site', 'Source', 'Structure', 'Symptoms', 'System', 'Text', 'Time', 'Update', 'experience', 'information gathering', 'medical attention', 'patient population', 'public health relevance', 'social networking website', 'statistics', 'treatment response', 'web-based social networking']",NINDS,UNIVERSITY OF UTAH,R21,2010,233374,-0.011443478929157749
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,7743573,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical and Translational Science Awards', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2010,724428,0.03946333657474815
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7935475,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2010,50100,0.0064004723403621195
"Improving access to multi-lingual health information through machine translation    DESCRIPTION (provided by applicant): The results of our proposed research will extend the usability of MT in healthcare and serve as a foundation for further research into improving the availability of health materials for individuals with Limited English Proficiency. Our description of public health translation work from Aim 1 will provide new understanding of existing barriers to translation. The error analysis from Aim 2 will identify specific focus areas for improving MT. Aim 3 will provide fundamentally new MT technology designed to adapt generic systems to the health domain, as well as a prototype implementation of a domain-adapted post-processing module. The evaluation studies in Aim 4 will provide a model for evaluation of machine translation technologies and provide benchmarks from which to evaluate advances in the machine translations for health materials in the future. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for those with limited English proficiency.    Review CriteriaSignificanceInvestigator(s)InnovationApproachEnvironmentReviewer 121321Reviewer 212121Reviewer 333453           PROJECT NARRATIVE The ability to access health information in the U.S. depends greatly on the ability to speak English. Yet a growing number of people in this country speak a language other than English. We propose to develop novel domain-specific natural language processing and machine translation technology and evaluate its impact on the process of producing multilingual health materials. Ultimately, this work will advance us towards the long term goal of eliminating health disparities caused by language barriers and improve access to pertinent multilingual health information for individuals with limited English proficiency.",Improving access to multi-lingual health information through machine translation,7946175,R01LM010811,"['Achievement', 'Address', 'Affect', 'Area', 'Arts', 'Benchmarking', 'Child', 'Cognitive', 'Communities', 'Computational algorithm', 'Country', 'Decision Making', 'Disasters', 'Disease Outbreaks', 'Evaluation', 'Evaluation Studies', 'Foundations', 'Funding', 'Future', 'Generic Drugs', 'Goals', 'Health', 'Health Communication', 'Health Professional', 'Healthcare', 'Home environment', 'Improve Access', 'Individual', 'Information Services', 'Language', 'Life', 'Measures', 'Modeling', 'Natural Language Processing', 'Outcome', 'Population', 'Process', 'Production', 'Public Health', 'Public Health Practice', 'Readiness', 'Regulation', 'Research', 'Safe Sex', 'System', 'Taxonomy', 'Techniques', 'Technology', 'Time', 'Translating', 'Translation Process', 'Translations', 'Trust', 'United States', 'United States National Library of Medicine', 'Update', 'Vaccinated', 'Work', 'Writing', 'base', 'cost', 'design', 'flu', 'health disparity', 'health literacy', 'improved', 'insight', 'meetings', 'member', 'novel', 'portability', 'prototype', 'usability']",NLM,UNIVERSITY OF WASHINGTON,R01,2010,370693,0.0368925720561588
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) The latest work on this system has involved adding the ability to generate themes using an EM algorithm approach. Also recently code has been multithreaded and memory mapping capabilities added to speed up processing.  The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system has been used for mining email communications for the NLM help desk. n/a",A Document Processing System,8149592,ZIALM000022,"['Data', 'Electronic Mail', 'Process', 'PubMed', 'System', 'computerized data processing']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2010,176283,0.022706810070122003
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,7940855,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2010,417999,0.005392198830064085
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in four subprojects which use natural language processing techniques:  1) The presence of unrecognized abbreviations in text hinders indexing algorithms and adversely affects information retrieval and extraction.  Automatic abbreviation definition identification can help resolve these issues.  However, abbreviations and their definitions identified by an automatic process are of uncertain validity.  Due to the size of databases such as MEDLINE only a small fraction of abbreviation-definition pairs can be examined manually.  An automatic way to estimate the accuracy of abbreviation-definition pairs extracted from text is needed.  We have proposed an abbreviation definition identification algorithm that employs a variety of strategies to identify the most probable abbreviation definition.  In addition our algorithm produces an accuracy estimate, pseudo-precision, for each strategy without using a human-judged gold standard. The pseudo-precisions determine the order in which the algorithm applies the strategies in seeking to identify the definition of an abbreviation. The results are generally a couple of percentage points better than the Schwartz-Hearst algorithm and also allow one to enforce a threshold for those applications where high precision is critical.  2) A significant fraction of queries in PubMed are multiterm queries and PubMed generally handles them as a Boolean conjunction of the terms. However, analysis of queries in PubMed indicates that many such queries are meaningful phrases, rather than simply collections of terms. We have examined whether or not it makes a difference, in terms of retrieval quality, if such queries are interpreted as a phrase or as a conjunction of query terms. And, if it does, what is the optimal way of searching with such queries. To address the question, we developed an automated retrieval evaluation method, based on machine learning techniques, that enables us to evaluate and compare various retrieval outcomes. We show that classes of records that contain all the search terms, but not the phrase, qualitatively differ from the class of records containing the phrase. We also show that the difference is systematic, depending on the proximity of query terms to each other within the record. Based on these results, one can establish the best retrieval order for the records. Our findings are consistent with studies in proximity searching. The important insight here for indexing is that in some cases where the words of a phrase occur in text, but not as the phrase, the phrase may still be an appropriate concept to use in indexing the text. 3) We have developed a spell checking algorithm that does quite accurate correction ( 87%) and handles one or two edits, and more edits if the string to be corrected is sufficiently long. It handles words that are fragmented or merged. Where queries consist of more than a single token the algorithm attempts to make use of the additional information as context to aid the correction process. The algorithm is based on the noisy channel model of spelling correction and makes use of statistics on miss-spellings gathered from approximately one million miss-spelling incidents in the PubMed log files. These incidents were identified as cases where a user entered a query and then within five minutes corrected that query to another term which is close in edit distance and with at least ten times as many hits in the PubMed database. These statistics are not only used in the actual correction process, but were used to simulate miss-spellings in real words and phrases to discover the regions of validity of the method of correction and estimates of its accuracy. Additional work was done on the vocabulary of the PubMed database to remove frequent miss-spellings and improve performance. The algorithm is implemented in the PubMed search engine and there it frequently makes over 200,000 suggestions in a day and about 45% of these suggestions are accepted by users. The algorithm is efficient in adding only about 25% to the average query response time for users and much of this is seen only for misspelled queries. There is the possibility of improving the algorithm by the use of more context around the sites of errors within words. There is also the possibility of improving the algorithm by learning how to make better use of the context supplied by queries consisting of multiple tokens. But in both cases such an effort must consider how to maintain efficiency in the light of a huge vocabulary of phrases (>14 million) and individual words (>2.5 million) recognized by the search engine. There is also the possibility to use phonetic encodings to improve the handling of some of the errors that currently challenge the system. However, preliminary calculations suggest it would be difficult to make a major improvement by using phonetic encodings. 4) We explored a syntactic approach to sentence compression in the biomedical domain, grounded in the context of result presentation for related article search in the PubMed search engine. By automatically trimming inessential fragments of article titles, a system can effectively display more results in the same amount of space. Our implemented prototype operates by applying a sequence of syntactic trimming rules over the parse trees of article titles. Two separate studies were conducted using a corpus of manually compressed examples from MEDLINE: an automatic evaluation using Bleu and a summative evaluation involving human assessors. Experiments show that a syntactic approach to sentence compression is effective in the biomedical domain and that the presentation of compressed article titles supports accurate interest judgments, decisions by users as to whether an article is worth examining in more detail. n/a",Natural Language Processing Techniques To Enhance Information Access.,7969224,ZIALM000090,"['Abbreviations', 'Address', 'Affect', 'Algorithms', 'Automated Abstracting', 'Body of uterus', 'Classification', 'Collection', 'Data', 'Databases', 'Evaluation', 'Gold', 'Human', 'Individual', 'Information Retrieval', 'Judgment', 'Learning', 'Light', 'MEDLINE', 'Machine Learning', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Performance', 'Phonetics', 'Process', 'PubMed', 'Reaction Time', 'Records', 'Retrieval', 'Simulate', 'Site', 'Suggestion', 'System', 'Techniques', 'Text', 'Time', 'Trees', 'Vocabulary', 'Work', 'base', 'improved', 'indexing', 'insight', 'interest', 'phrases', 'prototype', 'research study', 'spelling', 'statistics', 'syntax']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2009,608137,-0.013730627103559406
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7933293,R01LM006910,"['Address', 'Area', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Machine Learning', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'clinical care', 'data mining', 'improved', 'knowledge base', 'natural language', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,152617,0.03338015532901871
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7918614,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'clinical practice', 'forgetting', 'innovation', 'natural language', 'preference', 'speech processing', 'symposium']",NLM,UNIVERSITY OF CHICAGO,R01,2009,185745,0.009694427718879153
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7554153,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'clinical care', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2009,422728,-0.00907085832185968
"Natural Language Processing to Study Epidemiology of Statin Side Effects    DESCRIPTION (provided by applicant): This application addresses broad Challenge Area (10) Information Technology for Processing Health Care Data and specific Challenge Topic 10-LM-101: Informatics for post-marketing surveillance. The overall goal of this study is to develop a generalizable framework for studying medication side effects recorded in narrative medical documents. We will implement and test this system on the example of epidemiologic characterization of side effects of HMG-CoA reductase inhibitors (a.k.a. statins). Statins are the most commonly used class of medications for treatment of hypercholesterolemia in the U.S. In randomized clinical trials statins are associated only with a slight increase in adverse reactions and no increase in discontinuation of treatment compared to placebo. However, in clinical practice the rates of side effects and discontinuation appear significantly higher and represent a major barrier to a critical, potentially lifesaving therapy. For example, myalgias are reported to be relatively rare in clinical trials but are thought to be more common in clinical practice. Additionally, a number of other statin-associated complaints reported anecdotally but not well elucidated in clinical trials include depression, irritability, and memory loss among others. Most of these have been poorly epidemiologically characterized and their prevalence and risk factors remain unknown. Structured electronic medical record (EMR) and administrative data have been used to study medication side effects. However, structured data have important limitations. They may not contain temporal or causative information necessary to link particular problems to medications and may not be sufficiently granular to identify specific adverse reactions. Narrative EMR data, such as provider notes, can provide documentation of causative links between medication and adverse events at high levels of granularity. Natural language processing (NLP) is an emerging technology that enables computational abstraction of information from narrative medical documents. In prior work we have successfully applied natural language processing to abstract medication information from narrative provider notes, including medication intensification, medication non-adherence and medication discontinuation. We will leverage these tools and the extensive EMR infrastructure at Partners HealthCare to develop and test a natural language processing system to study medication side effects. We will validate this system on the example of studying epidemiology of adverse reactions to statins. The findings of this project will lay the foundation for an open-source system that can be used for post-marketing surveillance of medication side effects using narrative EMR data.       PUBLIC HEALTH RELEVANCE (provided by applicant): Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.                 Natural Language Processing to Study Epidemiology of Statin Side Effects  Project Narrative  Frequency and risk factors for side effects of statins (medications used to treat high cholesterol) in everyday medical practice (as opposed to research studies) are not known. In this project we will design a system for analyzing the information about statin side effects in the electronic medical records. If successful, this approach can be subsequently generalized to study side effects of many other medications.",Natural Language Processing to Study Epidemiology of Statin Side Effects,7834605,RC1LM010460,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Area', 'Cholesterol', 'Clinical Trials', 'Computerized Medical Record', 'Data', 'Documentation', 'Emerging Technologies', 'Foundations', 'Frequencies', 'Goals', 'Healthcare', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Hypersensitivity', 'Incidence', 'Informatics', 'Information Technology', 'Link', 'Medical', 'Memory Loss', 'Myalgia', 'Natural Language Processing', 'Pharmaceutical Preparations', 'Placebos', 'Prevalence', 'Process', 'Provider', 'Randomized Clinical Trials', 'Reaction', 'Records', 'Reporting', 'Research Infrastructure', 'Risk Factors', 'Semantics', 'Side', 'Structure', 'System', 'Systems Analysis', 'Testing', 'Text', 'Work', 'abstracting', 'clinical practice', 'depression', 'design', 'epidemiology study', 'hypercholesterolemia', 'medication compliance', 'open source', 'post-market', 'public health relevance', 'repository', 'research study', 'tool']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,RC1,2009,499818,0.030589328755736205
"Adapting Natural Language Processing Tools for Biosurveillance    DESCRIPTION (provided by applicant):       Early detection of disease outbreaks can decrease patient morbidity and mortality and minimize the spread of diseases. Early detection requires accurate classification of patient symptoms early in the course of their illness. One approach is biosurveillance, in which electronic symptom data are captured early in the course of illness, and analyzed for signals that might indicate an outbreak requiring investigation and response by the public health system. Emergency department (ED) patient records are particularly useful for biosurveillance, given their timely, electronic availability. ED data elements used in surveillance systems include the chief complaint (a brief description of the patient's primary symptom(s)), and triage nurses' note (also known as history of present illness).The chief complaint is the most widely used ED data element, because it is recorded electronically by the majority of EDs. One study showed that adding triage notes increased the sensitivity of biosurveillance case detection. The increased sensitivity is because the triage note increases the amount of data available: instead of one symptom in a chief complaint (e.g., fever), triage notes may contain multiple symptoms (e.g., ""fever, cough & shortness of breath for 12 hours""). Surveillance efforts are hampered, however, by the wide variability of free text data in ED chief complaints and triage notes. They often include misspellings, abbreviations, acronyms and other lexical and semantic variants that are difficult to group into symptom clusters (e.g., fever, temp 104, fvr, febrile). Tools are needed to address the lexical and semantic variation in symptom terms in ED data in order to improve biosurveillance. Natural language processing tools have been shown to facilitate concept extraction from more structured clinical data such as radiology reports, but there has been limited application of these techniques to free text ED triage notes. The project team developed the Emergency Medical Text Processor (EMT-P) to preprocess the chief complaint. EMT-P cleans and normalizes brief chief complaint entries and then extracts standardized concepts, but it is not sufficient in its current state to preprocess longer, more complex text passages such as triage notes. This proposed project will further strengthen biosurveillance by adapting EMT-P and other statistical and classical natural language processing tools to develop a system that extracts concepts from triage notes for biosurveillance.           Project Narrative Relevance: The public health system is responsible for monitoring large amounts of timely, electronic health data and needs more sophisticated tools to faciliate detection of, and response to, emerging infectious diseases and potential bioterrorism threats. The proposed project addresses this need by developing a system to extract relevant information from emergency department records.",Adapting Natural Language Processing Tools for Biosurveillance,7693117,G08LM009787,"['Abbreviations', 'Accident and Emergency department', 'Acute', 'Address', 'American', 'Avian Influenza', 'Bioterrorism', 'Bird Flu vaccine', 'Breathing', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Collection', 'Communicable Diseases', 'Communities', 'Complex', 'Contracts', 'Coughing', 'Country', 'Data', 'Data Element', 'Data Quality', 'Detection', 'Diagnosis', 'Disease', 'Disease Outbreaks', 'Early Diagnosis', 'Electronic Health Record', 'Electronics', 'Emergency Medicine', 'Emergency Situation', 'Emerging Communicable Diseases', 'Epidemiologist', 'Evaluation', 'Event', 'Fever', 'Genetic Transcription', 'Goals', 'Gold', 'Health', 'Health Services', 'Health system', 'Hour', 'Intervention', 'Investigation', 'Manuals', 'Measures', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'North Carolina', 'Nurses', 'Patients', 'Performance', 'Pertussis', 'Physicians', 'Predictive Value', 'Process', 'Public Health', 'Radiology Specialty', 'Recording of previous events', 'Records', 'Reporting', 'Sampling', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Shortness of Breath', 'Signal Transduction', 'Smallpox', 'Structure', 'Symptoms', 'System', 'Techniques', 'Temperature', 'Text', 'Translating', 'Triage', 'Variant', 'acronyms', 'base', 'experience', 'improved', 'lexical', 'mortality', 'pandemic disease', 'population based', 'prototype', 'research to practice', 'response', 'satisfaction', 'syntax', 'tool']",NLM,UNIV OF NORTH CAROLINA CHAPEL HILL,G08,2009,145926,0.019303748581653287
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7870862,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,172278,0.0069846714944846915
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7631876,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,344239,0.0069846714944846915
"Pharmacovigilence using Natural Language Processing, Statistics, and the EHR    DESCRIPTION (provided by applicant):       The long-term objective of this proposal is to advance patient safety and reduce the cost of medical care by discovering novel adverse drug events (ADEs) through use of automated methods. We will utilize natural language processing (NLP) and data mining methodologies on vast quantities of clinical data in electronic health records (EHRs) to detect novel ADE signals. ADEs are major problems world-wide and cause hospitalizations, deaths, and incur a huge cost to health care. Therefore, continued post-marketing surveillance encompassing large and varied patient populations is crucial for patient safety. EHRs contain a comprehensive amount of clinical information, which if harnessed properly, would be invaluable for pharmacovigilance. We have already demonstrated that we can accurately encode information in clinical reports using the NLP system MedLEE, and that we can accurately detect associations among clinical events using statistical methods that we developed. Therefore, this is an excellent opportunity to continue our research accomplishments and to advance the state of the art in pharmacovigilance.       More specifically, MedLEE will be used to map comprehensive clinical information in the EHR to codified data, and then statistical methods will be used to generate an extensive knowledge base of disease-symptom, disease-drug, drug-drug, and drug-symptom associations, which will be used to discover new ADEs. Additionally, we will develop methods to determine the correct sequence of drug, disease, and symptom events, which is critical for detecting ADEs. We will also develop methods to map fine-grained concepts into higher level concepts, which is important for optimizing the statistical methods. The performance of our discovery methods will be evaluated by testing the methods using drugs currently in use with known ADEs, and also by using historical rollback. We will first focus on discovery of short-term events using inpatient records, and then longer-term events using outpatient office visits.       This proposal is well positioned to overcome problems associated with existing automated methods based on spontaneous reporting databases and administrative databases. We are confident the methods will be effective because a strong infrastructure is in place for us to build upon. Most importantly, the methodology developed in this proposal presents an excellent chance to dramatically improve patient safety and reduce costs.               This proposal aims to improve patient safety and reduce health care costs by developing effective methods for the discovery of new adverse drug events. The use of natural language processing on vast quantities of EHR records will result in the harnessing of comprehensive clinical information for this purpose, overcoming some of the limitations of current methods that rely on spontaneous reporting and administrative databases.","Pharmacovigilence using Natural Language Processing, Statistics, and the EHR",7937173,R01LM010016,"['Adverse event', 'Affect', 'Arts', 'Back', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Data', 'Databases', 'Detection', 'Disease', 'Drug usage', 'Electronic Health Record', 'Event', 'Grouping', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitalization', 'Inpatients', 'Knowledge', 'Maps', 'Marketing', 'MeSH Thesaurus', 'Medical', 'Medical Care Costs', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Office Visits', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Signal Transduction', 'Source', 'Statistical Methods', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'United States National Library of Medicine', 'administrative database', 'base', 'cost', 'data mining', 'drug testing', 'improved', 'knowledge base', 'novel', 'patient population', 'patient safety', 'post-market', 'statistics', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,172210,0.0069846714944846915
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) The latest work on this system has involved adding the ability to generate themes using an EM algorithm approach. Also recently code has been multithreaded and memory mapping capabilities added to speed up processing.  The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system has been used for mining email communications for the NLM help desk. n/a",A Document Processing System,7969199,ZIALM000022,"['Algorithms', 'Code', 'Communication', 'Data', 'Databases', 'Electronic Mail', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'Memory', 'Methods', 'Mining', 'Online Systems', 'Process', 'Programming Languages', 'PubMed', 'Records', 'Research', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Work', 'base', 'computerized data processing', 'repository', 'software systems']",NLM,NATIONAL LIBRARY OF MEDICINE,ZIA,2009,202712,0.022706810070122003
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7672256,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Readability', 'Reader', 'Reading', 'Self Care', 'Self Management', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'fourth grade', 'improved', 'instrument', 'literacy', 'ninth grade', 'patient oriented', 'prevent', 'programs', 'tenth grade', 'tool', 'web site']",NIDDK,UNIVERSITY OF UTAH,R01,2009,398216,0.03732313668540896
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7691699,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,311821,0.0429267158532645
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7908950,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Code', 'Computational Technique', 'Computerized Medical Record', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Methodology', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Procedures', 'Process', 'Reaction', 'Records', 'Reference Standards', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Safety', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'data mining', 'design', 'experience', 'flexibility', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient population', 'patient safety', 'phrases', 'post-market', 'practice-based research network', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2009,17240,0.0429267158532645
"Integrated discovery and hypothesis testing of new associations in rare diseases    DESCRIPTION (provided by applicant): Rare diseases are studied in isolated laboratories, forgotten by main stream pharmacological companies, and considered almost academic curiosities. Finding variables that correlate/cause rare diseases (a condition is rare when it affects less than 1 person per 2,000) is a difficult task. The low number of cases and the sparse nature of the reports make it difficult to obtain significant/meaningful statistical results. There are two ways to avoid these problems. The first is to integrate reported cases and associations to generate enough statistical power. The second way is to have an independent data set, big enough to cover rare cases. Each of the two methods has intrinsic problems. For instance, the search in the literature puts together different studies, each of them with their own biases in population, methodology and objectives. On the other hand, blind searches for associations in big databases introduce a large number of false positives due to multiple hypothesis testing.       These problems could be avoided by developing innovative methods that allow the integration of information and methodologies in the literature and longitudinal databases. To achieve this goal, we propose a team that combines expertise in natural language processing systems (Carol Friedman), electronic health records (George Hripcsak), statistics in combined databases and computational virology (Raul Rabadan). This team will generate an interdisciplinary approach to mine and integrate the literature and the dataset collected at Columbia/New York Presbyterian hospital. Identifying unusual correlations in rare diseases is the first step to understanding the origin of the diseases and to finding a cure for them. We hypothesize that we will develop effective methods aimed at improving our understanding of rare diseases by combining hypothesis testing and hypothesis discovery, and by integrating information from the literature and from the patient record to obtain increased statistical power. This will involve using natural language processing and statistical methods to mine both the literature and the electronic health record (EHR).           Project Narrative We will test reported associations in rare diseases and discover new ones by integrating information from the literature and from Electronic Health Records in hospitals.",Integrated discovery and hypothesis testing of new associations in rare diseases,7727710,R01LM010140,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Case Study', 'Cells', 'Clinical', 'Code', 'Computer software', 'Curiosities', 'Data', 'Data Set', 'Databases', 'Disease', 'Electronic Health Record', 'Electronics', 'Environmental Risk Factor', 'Evaluation', 'Frequencies', 'Goals', 'Hand', 'Hospitals', 'Immunocompromised Host', 'Incidence', 'Individual', 'Inequality', 'Informatics', 'Information Theory', 'Kaposi Sarcoma', 'Kidney Diseases', 'Laboratories', 'Link', 'Literature', 'Liver diseases', 'Methodology', 'Methods', 'Mining', 'Natural Language Processing', 'Nature', 'New York', 'Patients', 'Pattern', 'Persons', 'Population', 'Presbyterian Church', 'Process', 'PubMed', 'Rare Diseases', 'Records', 'Reporting', 'Research', 'Source', 'Statistical Methods', 'Stratification', 'Stream', 'Stress', 'System', 'Techniques', 'Testing', 'Text', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Virus', 'Work', 'Writing', 'abstracting', 'base', 'blind', 'data mining', 'forgetting', 'improved', 'innovation', 'interdisciplinary approach', 'longitudinal database', 'novel', 'pathogen', 'repository', 'research study', 'statistics', 'text searching', 'tool', 'virology', 'web site']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,533007,0.0046567880392566156
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7638001,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Non-Prescription Drugs', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'clinical practice', 'evidence base', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'patient population', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY,R01,2009,374185,0.00322337502843009
"New Resources for e-Patients    DESCRIPTION (provided by applicant): ""New Resources for e-Patients"" addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in currently available online health information resources. It will maximize the value of public domain health information from U.S. Government sources. Textual consumer health information will be collected from NIH, FDA and other government sources. This information will be subjected to automated topic analysis and classification using methods of natural language processing and statistical text-mining to discover and extract topics on i) diseases and conditions; ii) treatments, benefits and risks; and iii) genomic risks and responses. These topics will be integrated and mapped to the most frequent health topics of interest to consumers. Personally-controlled electronic health records and personal genotypes will be studied for their potential contributions to personalized medicine for e-patients. Phase I of this project will achieve proof-of-principle and develop an advanced prototype as a foundation for construction of a new web-based resource in Phase II.    PUBLIC HEALTH RELEVANCE: This project addresses the unmet medical needs of consumers who search for health and healthcare information online, currently a population of more than 160 million people in the U.S. It will fill gaps and address deficiencies in current online health information resources and also target new opportunities in genomic and personalized medicine. In the process we will create consumer-friendly, automated systems that make online information search and retrieval more efficient more efficient and maximize the value of public domain health information from U.S. Government sources. The work will lead to more reliable, personalized and actionable information for a new generation of web-savvy and socially-networked ""e-patients"" and will lead to more efficient and productive encounters between patients and healthcare systems.           This project addresses the unmet medical needs of consumers who search for  health and healthcare information online, currently a population of more than  160 million people in the U.S. It will fill gaps and address deficiencies in current  online health information resources and also target new opportunities in  genomic and personalized medicine. In the process we will create consumer-  friendly, automated systems that make online information search and retrieval  more efficient more efficient and maximize the value of public domain health  information from U.S. Government sources. The work will lead to more reliable,  personalized and actionable information for a new generation of web-savvy and  socially-networked ""e-patients"" and will lead to more efficient and productive  encounters between patients and healthcare systems.",New Resources for e-Patients,7748337,R43HG005046,"['Address', 'Benefits and Risks', 'Body of uterus', 'Businesses', 'Classification', 'Communication', 'Data', 'Development', 'Development Plans', 'Disease', 'Electronic Health Record', 'Foundations', 'Fund Raising', 'Generations', 'Genes', 'Genomics', 'Genotype', 'Government', 'Health', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Information Resources', 'Institutes', 'Internet', 'Lead', 'Maps', 'Marketing', 'Medical', 'Medicine', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'National Institute of Neurological Disorders and Stroke', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Population', 'Process', 'Proxy', 'Public Domains', 'Research', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Site', 'Source', 'Surveys', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Update', 'Validation', 'Work', 'base', 'commercialization', 'data integration', 'design', 'health record', 'interest', 'prototype', 'public health relevance', 'research study', 'response', 'text searching', 'web site']",NHGRI,"RESOUNDING HEALTH, INC.",R43,2009,119499,-0.0013502670142054773
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7908946,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'meetings', 'natural language', 'population based', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2009,71200,0.023291810531148024
"Online Social Networking as an Alternative Information Source for Clinical Resear    DESCRIPTION (provided by applicant): Clinical trials and patient records have been the main information sources for clinical research. While well- designed clinical trials can produce high quality data, they are generally very expensive and time consuming. Prior studies have also shown that patients enrolled in clinical trials are not necessarily representative of the general patient population. Chart reviews, which rely on the patient records, avoid some of the drawbacks of the clinical trials approach. Although chart review studies are more labor intensive, new developments in structured data entry and natural language processing (NLP) are helping to automate the process. However, studies which use chart reviews are limited by the accuracy and completeness of the data in the records.       In the past decade, online social networks have grown exponentially. Some health-focused social network sites have attracted large numbers of users and begun accumulating large quantities of detailed clinical information. The PatientsLikeMe site, for instance, has about 3,200 amyotrophic lateral sclerosis (ALS) patients worldwide, and includes about 5% of the ALS population in the US. Information gathered by online social networks is primarily intended for patients to share with each other. Such information has also begun to attract the attention of medical researchers.[3, 4]       Because using information from online social networks for medical research is a fairly new phenomenon, the value and limitation of this type of information source have not been systematically examined. To do so, we propose to conduct a comparison study of patient-contributed information from PatientsLikeMe and records from a large medical record data repository - the Research Patient Data Registry (RPDR) of the Partners Healthcare Systems. The proposed study will focus on ALS, multiple sclerosis (MS), and Parkinson's disease (PD). The general goal is to explore how the medical record and online networking data differ, and if and how online networking data could complement the medical record data. The specific aims are:    1) Extract symptom and treatment information from the two different data sources.    2) Compare the prevalence of symptoms and treatments from the two information sources and analyze the difference.    3) Extract treatment response of prescription medications from PatientsLikeMe and analyze the confounding effect of the misunderstanding of medication indication.      PUBLIC HEALTH RELEVANCE: The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.           The proposed project will investigate an emerging data source for clinical research: online social network. This data source may complement and supplement the data from clinical trials and medical records, with a unique emphasis on patients' experience and perspectives.",Online Social Networking as an Alternative Information Source for Clinical Resear,7777633,R21NS067463,"['Amyotrophic Lateral Sclerosis', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Communities', 'Comparative Study', 'Complement', 'Data', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Enrollment', 'Frequencies', 'Goals', 'Healthcare Systems', 'Medical Records', 'Medical Research', 'Multiple Sclerosis', 'Natural Language Processing', 'Nature', 'Parkinson Disease', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Prevalence', 'Process', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Site', 'Source', 'Structure', 'Symptoms', 'System', 'Text', 'Time', 'Update', 'experience', 'information gathering', 'medical attention', 'patient population', 'public health relevance', 'social networking website', 'statistics', 'treatment response', 'web-based social networking']",NINDS,UNIVERSITY OF UTAH,R21,2009,219896,-0.011443478929157749
"Translational refinement of adaptive communication system for locked-in patients    DESCRIPTION (provided by applicant): The proliferation of brain-computer interface (BCI) technology promises locked-in patients potential ways to communicate successfully. Most BCI systems either involve selection from among a set of simultaneously presented stimuli, requiring extensive control of the interface; or use binary stimulus selection mechanisms that fail to achieve high communication rates because of slow intent detection or a fixed (context independent) ordering of stimuli. We propose a new interface using binary selection of text input via rapid serial visual presentation of natural language components. Individuals with severe speech and physical impairments (SSPI) resulting from acquired neurological disorders (amyotrophic lateral sclerosis, brainstem stroke, Parkinson's disease, multiple sclerosis, spinal cord injury) and neurodevelopmental disorders (cerebral palsy, muscular dystrophy) drive the proposed research. Four laboratories form an alliance for this translational research project: basic research (Erdogmus, engineering; Roark, computer science and natural language processing), and clinical research (Oken, neurology/neurophysiology; Fried-Oken, augmentative communication/neurogenic communication disorders). Our aims are (1) to develop an innovative EEG-based BCI that achieves increased communication rates with fewer errors and greater satisfaction for the target SSPI populations; (2) to iteratively refine the system in the laboratory with user feedback from healthy subjects and expert LIS users of marketed AAC systems; (3) to evaluate the performance of the system within the natural clinical settings of SSPI patients. The innovative BCI is the RSVP Keyboard with three essential features: (1) rapid serial visual presentation (RSVP) of linguistic components ranging from letters to words to phrases; (2) a detection mechanism that employs multichannel electroencephalography (EEG) and/or other suitable response mechanisms that can reliably indicate the binary intent of the user and adapt based on individualized neurophysiologic data of the user; and (3) an open-vocabulary natural language model with a capability for accurate predictions of upcoming text. Theoretical framework is based on a solid Bayesian foundation; clinical usability is based on the WHO ICF (WHO, 2001) and an Augmentative and Alternative Communication (AAC) model of participation. Rigorous experimental scrutiny in both clinical laboratory and natural settings will be obtained with able-bodied subjects and SSPI patients. Measures of learning rate, speed of message production, error rate and user satisfaction for different iterations of the RSVP keyboard will be obtained using an hypothesis-driven crossover design for 36 healthy subjects, and alternating treatment randomization design for 40 patients with SSPI. Descriptions of the motor, cognitive, and language skills of LIS patients using the novel system in their natural environments will inform clinical guidelines and functional device adaptations to better individualize treatment for children and adults with SSPI. The collaborative nature of the proposed translational research is expected to yield new knowledge for both BCI development and clinical AAC use.    Relevance: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.              Public health relevance statement: The populations of patients with locked-in syndrome are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily care giving if they had faster, more reliable means to interface with communication systems. The RSVP keyboard and proposed language models are innovative technological discoveries that are being applied to clinical augmentative communication tools so that patients and their families can participate in daily activities and advocate for improvements in standard clinical care. The proposed project stresses the translation of basic computer science into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Translational refinement of adaptive communication system for locked-in patients,7570367,R01DC009834,"['Address', 'Adult', 'Advocate', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Base of the Brain', 'Basic Science', 'Brain', 'Brain Stem Infarctions', 'Cerebral Palsy', 'Characteristics', 'Child', 'Classification', 'Clinical', 'Clinical Research', 'Clinical and Translational Science Awards', 'Cognitive', 'Collaborations', 'Communication', 'Communication Aids for Disabled', 'Communication Methods', 'Communication Tools', 'Computers', 'Crossover Design', 'Data', 'Decision Making', 'Detection', 'Development', 'Devices', 'Electroencephalography', 'Engineering', 'Environment', 'Family', 'Feedback', 'Foundations', 'Funding', 'Generations', 'Guidelines', 'Human Resources', 'Impairment', 'Individual', 'Individuation', 'Informed Consent', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Linguistics', 'Locked-In Syndrome', 'Marketing', 'Measures', 'Medical', 'Medical Technology', 'Modeling', 'Motor', 'Movement', 'Multiple Sclerosis', 'Muscular Dystrophies', 'Natural Language Processing', 'Nature', 'Neurodevelopmental Disorder', 'Neurogenic Communication Disorders', 'Neurologist', 'Neurology', 'Oregon', 'Outcome Measure', 'Parkinson Disease', 'Pathologist', 'Patients', 'Pattern Recognition', 'Performance', 'Population', 'Production', 'Public Health', 'Randomized', 'Research', 'Research Institute', 'Research Personnel', 'Research Project Grants', 'Scientist', 'Sensory', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speed', 'Spinal cord injury', 'Stimulus', 'Stress', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translational Research', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Visual', 'Vocabulary', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'computer science', 'computerized data processing', 'design', 'improved', 'innovation', 'literate', 'natural language', 'nervous system disorder', 'neurophysiology', 'novel', 'patient population', 'phrases', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'satisfaction', 'skills', 'therapy design', 'usability']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2009,708748,0.03946333657474815
"Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts    DESCRIPTION (provided by applicant):  Accurate and complete medication lists are critical inputs to effective medication reconciliation to prevent medication prescribing and administration errors. Previous research aggregated structured medication data form multiple sources to generate and maintain a reconciled medication list. Medications documented in clinical texts also need to be reconciled. However, most reconciliation methods currently have limited capability to process textual data and temporal information (e.g., dates, duration and status). Our goal is to pilot and test methodologies and applications in the fields of natural language processing (NLP) and temporal reasoning to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. Clinic notes and free-text ""comments"" fields in medication lists in an ambulatory electronic medical record system will be considered in the study. An NLP system and a temporal reasoning system will be adapted to automatically extract medication and associated temporal information from clinical texts and encode the medications using a controlled terminology. Multiple knowledge bases will be used to develop a mechanism to represent the timing of medication use, detect the changes (e.g., active or inactive), and then to organize medications into appropriate groups (e.g., by ingredient or by status). The feasibility and efficiency of the proposed methods and tools in improving the process of medication   reconciliation will be assessed. Domain experts will serve as judges to assess the success of capturing, coding, and organizing the medications and temporal information and also to evaluate whether our methods are complementary to those currently used for medication management.           Accurate and complete medication information at the point of care is crucial for delivery of high-quality care and prevention of adverse events. Most previous studies aggregated structured medication data from EMR and CPOE (Computerized Physician Order Entry) systems to generate and maintain a reconciled medication list. However, medications in non-structured narrative sources (such as clinic notes and free-text comments) must also be reconciled. Structured data presented in a standard, predictable form can be easily processed by a computer. By contrast, narrative data does not have a well-defined structure, so processing such data is very challenging. Our goal is to pilot and test methodologies and applications in the fields of natural language processing (any system that manipulates text) and temporal reasoning (e.g., identifying the timing of medication use) to facilitate the use of electronic clinical texts in order to improve the ""correctness"" and ""completeness"" of medication lists. The feasibility and efficiency of the proposed methods and tools in improving the process of medication reconciliation will be assessed.",Improving Outpatient Medication Lists Using Temporal Reasoning and Clinical Texts,7774682,R03HS018288,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R03,2009,48782,0.0064004723403621195
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,7767483,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2009,314000,0.005392198830064085
"Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects    DESCRIPTION (provided by applicant):        	Epidemiologic analyses of health care data can provide critical evidence on the effectiveness and safety of therapeutics. This is particularly vital during the transition from the point of regulatory approval through the early marketing of new drugs, a time when physicians, regulators and payers are all struggling with incomplete data. Health plans pay for these drugs without knowing how their effectiveness and safety compares with established alternatives, as new compounds are tested against placebos rather than active agents, and tested only in selected patients. Non-randomized studies in large healthcare databases can provide fast and less costly evidence on drug effects. However, conventional adjustment methods that rely on a small number of investigator-specified confounders often fail and may produce biased results.     We propose and have preliminary evidence that employing modern medical informatics algorithms that structure and search databases to empirically identify thousands of new covariates. These will then enter established propensity score-based models and so make far more effective use of the information contained in health care databases and electronic medical records (EMRs), resulting in more valid causal interpretations of treatment effects. We will:    - Develop algorithms that make greater use of information contained in longitudinal claims and EMR databases by empirically identifying thousands of potential confounders. The performance of these approaches will be evaluated in 6 example studies encompassing recent drug safety and comparative effectiveness problems, and will be implemented in multiple large claims databases supplemented by such data as lab values and EMR information in subgroups.    -- Develop novel methods for confounding adjustment based on textual information found in EMRs.    -- Expand the newly developed mining algorithms into a framework that integrates distributed database networks with uneven information content, similar to the Sentinel Network recently initiated by FDA.                            This project is likely to produce groundbreaking results at the interface of medicine, biomedical informatics, and epidemiologic methods. After completion of this project a library of documented and validated algorithms will be available to significantly improve confounder control in a range of healthcare databases. The theoretical foundation and the ready-to-use algorithms will likely lead to a fundamental shift in how databases contribute to the fast and accurate assessment of newly-marketed medications.            Large healthcare databases are used to assess the safety and effectiveness of drugs. However, conventional adjustment methods that rely on a limited number of investigator-specific covariates often fail to produce unbiased results. We will develop algorithms that make greater use of information contained in longitudinal claims data and electronic medical records databases by empirically identifying thousands of potential confounders. This will result in improved causal inference on the comparative safety and effectiveness of newly marketed medications that is both less susceptible to investigator omissions and faster than conventional approaches.",Analyzing Complex Healthcare Data to Determine Causality of Observed Drug Effects,7767483,R01LM010213,"['Address', 'Algorithms', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Distributed Databases', 'Effectiveness', 'Elderly', 'Epidemiologic Methods', 'Epidemiology', 'Etiology', 'Evaluation', 'Foundations', 'Head', 'Health Planning', 'Healthcare', 'Heterogeneity', 'Individual', 'Insurance', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Marketing', 'Medical Informatics', 'Medicare/Medicaid', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Placebos', 'Population', 'Pregnant Women', 'Process', 'Publications', 'Randomized', 'Research', 'Research Personnel', 'Safety', 'Scoring Method', 'Sentinel', 'Severity of illness', 'Solid', 'Solutions', 'Specific qualifier value', 'Speed', 'Staging', 'Structure', 'Subgroup', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'To specify', 'Training', 'base', 'biomedical informatics', 'comparative', 'comparative effectiveness', 'compare effectiveness', 'data mining', 'improved', 'indexing', 'lectures', 'novel', 'outcome forecast', 'patient privacy', 'programs', 'routine care', 'symposium', 'treatment effect']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2009,143541,0.005392198830064085
"Natural Language Processing Techniques To Enhance Information Access. Recently we have been involved in four subprojects which use natural language processing techniques:  1) The presence of unrecognized abbreviations in text hinders indexing algorithms and adversely affects information retrieval and extraction.  Automatic abbreviation definition identification can help resolve these issues.  However, abbreviations and their definitions identified by an automatic process are of uncertain validity.  Due to the size of databases such as MEDLINE only a small fraction of abbreviation-definition pairs can be examined manually.  An automatic way to estimate the accuracy of abbreviation-definition pairs extracted from text is needed.  We have proposed an abbreviation definition identification algorithm that employs a variety of strategies to identify the most probable abbreviation definition.  In addition our algorithm produces an accuracy estimate, pseudo-precision, for each strategy without using a human-judged gold standard. The pseudo-precisions determine the order in which the algorithm applies the strategies in seeking to identify the definition of an abbreviation. The results are generally a couple of percentage points better than the Schwartz-Hearst algorithm and also allow one to enforce a threshold for those applications where high precision is critical.  2) A significant fraction of queries in PubMed are multiterm queries and PubMed generally handles them as a Boolean conjunction of the terms. However, analysis of queries in PubMed indicates that many such queries are meaningful phrases, rather than simply collections of terms. We have examined whether or not it makes a difference, in terms of retrieval quality, if such queries are interpreted as a phrase or as a conjunction of query terms. And, if it does, what is the optimal way of searching with such queries. To address the question, we developed an automated retrieval evaluation method, based on machine learning techniques, that enables us to evaluate and compare various retrieval outcomes. We show that classes of records that contain all the search terms, but not the phrase, qualitatively differ from the class of records containing the phrase. We also show that the difference is systematic, depending on the proximity of query terms to each other within the record. Based on these results, one can establish the best retrieval order for the records. Our findings are consistent with studies in proximity searching. The important insight here for indexing is that in some cases where the words of a phrase occur in text, but not as the phrase, the phrase may still be an appropriate concept to use in indexing the text. 3) We have developed a spell checking algorithm that does quite accurate correction ( 87%) and handles one or two edits, and more edits if the string to be corrected is sufficiently long. It handles words that are fragmented or merged. Where queries consist of more than a single token the algorithm attempts to make use of the additional information as context to aid the correction process. The algorithm is based on the noisy channel model of spelling correction and makes use of statistics on miss-spellings gathered from approximately one million miss-spelling incidents in the PubMed log files. These incidents were identified as cases where a user entered a query and then within five minutes corrected that query to another term which is close in edit distance and with at least ten times as many hits in the PubMed database. These statistics are not only used in the actual correction process, but were used to simulate miss-spellings in real words and phrases to discover the regions of validity of the method of correction and estimates of its accuracy. Additional work was done on the vocabulary of the PubMed database to remove frequent miss-spellings and improve performance. The algorithm is implemented in the PubMed search engine and there it frequently makes over 200,000 suggestions in a day and about 45% of these suggestions are accepted by users. The algorithm is efficient in adding only about 25% to the average query response time for users and much of this is seen only for misspelled queries. There is the possibility of improving the algorithm by the use of more context around the sites of errors within words. There is also the possibility of improving the algorithm by learning how to make better use of the context supplied by queries consisting of multiple tokens. But in both cases such an effort must consider how to maintain efficiency in the light of a huge vocabulary of phrases (>14 million) and individual words (>2.5 million) recognized by the search engine. There is also the possibility to use phonetic encodings to improve the handling of some of the errors that currently challenge the system. However, preliminary calculations suggest it would be difficult to make a major improvement by using phonetic encodings. 4) We explored a syntactic approach to sentence compression in the biomedical domain, grounded in the context of result presentation for related article search in the PubMed search engine. By automatically trimming inessential fragments of article titles, a system can effectively display more results in the same amount of space. Our implemented prototype operates by applying a sequence of syntactic trimming rules over the parse trees of article titles. Two separate studies were conducted using a corpus of manually compressed examples from MEDLINE: an automatic evaluation using Bleu and a summative evaluation involving human assessors. Experiments show that a syntactic approach to sentence compression is effective in the biomedical domain and that the presentation of compressed article titles supports accurate interest judgments, decisions by users as to whether an article is worth examining in more detail. n/a",Natural Language Processing Techniques To Enhance Information Access.,7735077,Z01LM000090,"['Abbreviations', 'Address', 'Affect', 'Algorithms', 'Automated Abstracting', 'Body of uterus', 'Class', 'Classification', 'Collection', 'Data', 'Databases', 'Evaluation', 'Gold', 'Human', 'Individual', 'Information Retrieval', 'Judgment', 'Learning', 'Light', 'MEDLINE', 'Machine Learning', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Performance', 'Phonetics', 'Process', 'PubMed', 'Reaction Time', 'Records', 'Retrieval', 'Simulate', 'Site', 'Standards of Weights and Measures', 'Suggestion', 'System', 'Techniques', 'Text', 'Time', 'Title', 'Trees', 'Vocabulary', 'Work', 'base', 'concept', 'day', 'improved', 'indexing', 'insight', 'interest', 'prototype', 'research study', 'size', 'spelling', 'statistics', 'syntax']",NLM,NATIONAL LIBRARY OF MEDICINE,Z01,2008,224159,-0.013730627103559406
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7495030,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2008,338600,0.03338015532901871
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7675157,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Language', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'day', 'forgetting', 'innovation', 'preference', 'speech processing', 'symposium']",NLM,UNIVERSITY OF CHICAGO,R01,2008,354823,0.009694427718879153
"Extracting Semantic Knowledge from Clinical Reports    DESCRIPTION (provided by applicant): Analyzing and processing free-text medical reports for data mining and clinical data interchange is one of the most challenging problems in medical informatics, yet it is crucial for continued research advances and improvements in clinical care. Natural language processing (NLP) is an important enabling technology, but has been held back because it is difficult to understand human language, since it requires extensive domain knowledge. In Phase I, we developed new statistical and machine learning methods that apply domain specific knowledge to the semantic analysis of free-text radiology reports. The methods enabled the creation of two new prototype applications - a SNOMED CT (Systematized Nomenclature of Medicine--Clinical Terms) coding service called SnomedCoder, and a text mining tool for analyzing a large corpus of medical reports, called DataMiner. In Phase II, we will accomplish the following specific aims: 1) Improve the semantic extraction methods developed in Phase I, 2) Expand the semantic knowledge base and classify at least two million new unique sentences from multiple medical institutions, 3) Provide a SNOMED CT auto coding service (alpha service) to participating Indiana Health Information Exchange hospitals, and 4) Build a commercial version of the DataMiner software, and test its functionality using researchers at the Regenstrief Institute.       These scientific innovations will revolutionize the ability of health care researchers to analyze vast repositories of clinical information currently locked up in electronic medical records, and correlate this data with new biomedical discoveries in proteonomics and genomics. The ability to codify text rapidly will extend the potential for clinical decision support beyond its narrow base of numeric and structured medical data, and enable SNOMED CT to become a useful coding standard. Phase III will offer coding and data mining services to healthcare payers (both private and government), pharmaceuticals, and academic researchers. A key advantage of our approach over other NLP systems is that we attempt to codify all the information in the report and not just a limited subset, and insist on expert validation which provides a high degree of confidence in the accuracy of the coded data.Project Narrative           n/a",Extracting Semantic Knowledge from Clinical Reports,7394699,R44RR024929,"['Address', 'Algorithms', 'Back', 'Bioinformatics', 'Body of uterus', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Code', 'Collection', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Reporting', 'Decision Making', 'Effectiveness', 'Genomics', 'Goals', 'Government', 'Health', 'Healthcare', 'Hospitals', 'Human', 'Indiana', 'Institutes', 'Institution', 'Journals', 'Knowledge', 'Language', 'Longitudinal Studies', 'Machine Learning', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Natural Language Processing', 'Paper', 'Pharmacologic Substance', 'Phase', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Testing', 'Text', 'Thinking', 'Trees', 'Trust', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Validation', 'base', 'computerized', 'data mining', 'health care quality', 'improved', 'indexing', 'innovation', 'knowledge base', 'novel strategies', 'patient safety', 'prototype', 'repository', 'research and development', 'success', 'text searching', 'tool']",NCRR,"LOGICAL SEMANTICS, INC.",R44,2008,429955,-0.00907085832185968
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7478824,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2008,177729,-0.023529065249888185
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) The latest work on this system has involved adding the ability to generate themes using an EM algorithm approach. Also recently code has been multithreaded and memory mapping capabilities added to speed up processing.  The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system has been used for mining email communications for the NLM help desk. n/a",A Document Processing System,7735064,Z01LM000022,"['Algorithms', 'Class', 'Code', 'Communication', 'Data', 'Databases', 'Electronic Mail', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'Memory', 'Methods', 'Mining', 'Numbers', 'Online Systems', 'Process', 'Programming Languages', 'PubMed', 'Purpose', 'Records', 'Research', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Work', 'base', 'computerized data processing', 'repository', 'software systems']",NLM,NATIONAL LIBRARY OF MEDICINE,Z01,2008,206916,0.022706810070122003
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7677599,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2008,20000,0.025148296148449368
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7475712,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2008,438476,0.03732313668540896
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7671784,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2008,48482,0.03732313668540896
"Sematic Relatedness for Active Medication Safety and Outcomes Surveillance    DESCRIPTION (provided by applicant):       Medication-related morbidity and mortality in ambulatory care in the United States results in estimated 100,000 deaths and $177 billion spending annually. Post-marketing passive surveillance of outcomes associated with medication use has been recognized as a necessary component in drug safety monitoring to overcome the limitations of pre- marketing clinical trials. Information technology applied to the patient's electronic medical and therapeutic record holds promise to improve this situation by detecting alarming trends in signs and symptoms in patient populations exposed to the same medication. Currently, much of the information necessary for active drug safety surveillance is ""locked"" in the unstructured text of electronic records. Our long-term goal is to develop information technology to recognize and prevent drug therapy related adverse events. Sophisticated natural language processing systems have been developed to find medical terms and their synonyms in the unstructured text and use them to retrieve information. In order to monitor alarming trends in symptoms in medical records, we need mechanisms that will allow not only accurate term and concept identification but also grouping of semantically related concepts that may not necessarily be synonymous. Measures of semantic relatedness rely on existing ontologies of domain knowledge as well as large textual corpora to compute a numeric score indicating the strength of relatedness between two concepts. Our central hypothesis is that such measures will be able to make fine-grained distinctions among concepts in the biomedical text, and provide a foundation upon which to organize concepts into meaningful groups automatically. In particular, this proposal seeks to develop methods that leverage the medical knowledge contained within Unified Medical Language System (UMLS) and corpora of clinical text. Our short-term goals are 1) develop new methods, specific to clinical text, for computing semantic relatedness 2) integrate these specific methods for computing semantic relatedness into more general methods of natural language processing 3) integrate semantic relatedness into methods for identifying labeled semantic relations in clinical text. Labeled relations significantly enhance the ability of natural language processing to support accurate automatic analysis of medical information for improving patient safety. Our next step will be to develop and validate a generalizable active medication safety surveillance system that will automatically track medication exposure and alarming trends in signs and symptoms in ambulatory and hospitalized populations for a broad range of diseases.           This project will a) create and validate a common open-source platform for developing and testing semantic relatedness measures, b) determine the validity of electronic medical records with respect to identification of symptoms associated with medication- related problems and c) develop a novel methodology to aggregate adverse reaction terms used to code spontaneous post-marketing drug safety surveillance reports. The results of this project will enable more effective medication safety surveillance efforts and thus will improve patient safety.",Sematic Relatedness for Active Medication Safety and Outcomes Surveillance,7579478,R01LM009623,"['Address', 'Adverse effects', 'Adverse event', 'Adverse reactions', 'Ambulatory Care', 'Angina Pectoris', 'Area', 'Body of uterus', 'Cereals', 'Cessation of life', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Computational Technique', 'Computerized Medical Record', 'Count', 'Databases', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronics', 'Exposure to', 'Foundations', 'Generic Drugs', 'Goals', 'Group Identifications', 'Grouping', 'Health', 'Healthcare', 'Heart failure', 'Information Technology', 'Knowledge', 'Label', 'Linguistics', 'Mandatory Reporting', 'Manuals', 'Maps', 'Marketing', 'Measures', 'Medical', 'Medical Electronics', 'Medical History', 'Medical Informatics', 'Medical Records', 'Medical Surveillance', 'Methods', 'Minnesota', 'Monitor', 'Morbidity - disease rate', 'Natural Language Processing', 'Nature', 'Numbers', 'One-Step dentin bonding system', 'Ontology', 'Outcome', 'Patients', 'Pharmaceutical Cares', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Pharmacy facility', 'Physicians', 'Pliability', 'Population', 'Positioning Attribute', 'Practice based research', 'Primary Health Care', 'Procedures', 'Process', 'Purpose', 'Range', 'Reaction', 'Records', 'Reference Standards', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Role', 'Safety', 'Score', 'Semantics', 'Signs and Symptoms', 'Statistical Models', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Therapeutic Effect', 'Time', 'Training', 'Unified Medical Language System', 'United States', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'computer science', 'concept', 'data mining', 'design', 'experience', 'improved', 'information organization', 'knowledge base', 'metathesaurus', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'prevent', 'social', 'treatment planning', 'trend']",NLM,UNIVERSITY OF MINNESOTA,R01,2008,299619,0.0429267158532645
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7448662,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY,R01,2008,383338,0.00322337502843009
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7414601,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2008,142400,0.023291810531148024
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7288319,R01LM006910,"['Address', 'Area', 'Caring', 'Cities', 'Clinical', 'Code', 'Collaborations', 'Computerized Medical Record', 'Data', 'Data Sources', 'Databases', 'Event', 'Goals', 'Health', 'Healthcare', 'Knowledge', 'Language', 'Machine Learning', 'Medical Surveillance', 'Mental Health', 'Methods', 'Natural Language Processing', 'New York City', 'Persons', 'Preparation', 'Process', 'Reporting', 'Research', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Uncertainty', 'Work', 'base', 'data mining', 'improved', 'knowledge base', 'satisfaction', 'syndromic surveillance']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,345833,0.03338015532901871
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7217497,R01LM008799,"['Address', 'Biological Models', 'Clinical', 'Complex', 'Data', 'Databases', 'Devices', 'Diagnosis', 'Face', 'Generations', 'Goals', 'Hand', 'Human', 'Information Resources', 'Knowledge', 'Language', 'Librarians', 'Machine Learning', 'Medical', 'Medical Errors', 'Medical Students', 'Modality', 'Modeling', 'Natural Language Processing', 'Patient Care', 'Patients', 'Physicians', 'Process', 'Reporting', 'Research', 'Resources', 'Retrieval', 'Software Tools', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'day', 'forgetting', 'innovation', 'preference', 'speech processing', 'symposium']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2007,361696,0.009694427718879153
"Feasibility of a Natural Language Processing-based Dental Charting Application    DESCRIPTION (provided by applicant): The absence of a flexible, robust, and accurate natural language interface is a significant barrier to the direct use of computer-based patient records by dental clinicians. While providing patient care, dentists, hygienists and assistants are handicapped in using a keyboard and mouse to interact with a computer, primarily because of infection control concerns. The objective of this proposal is to develop and evaluate a prototype dental charting system with a speech-driven interface that will allow the dentist to chart dental conditions using natural language. The system will use Natural Language Processing (NLP) to extract the key concepts associated with 16 dental conditions from transcribed dental examinations. These concepts, coded using the standardized terminologies, would provide a structured summary of a patient's initial dental exam. The proposal has two aims: 1) evaluate the accuracy of speech recognition technology for clinical dental examinations; and 2) develop and evaluate an NLP application for mapping transcribed text to a structured dental chart. This proposal describes a new, exploratory and innovative research project that could radically impact the practice of dental charting. Expected outcomes for this proposal include: 1) an understanding of the accuracy of speech recognition for real-time dictated dental exams; and 2) NLP-based tools to automatically chart restorative and periodontal conditions for each tooth into a structured dental chart. This developmental work will provide a strong foundation for developing a chairside NLP-based dental charting application that would automatically generate a structured dental chart suitable for chairside decision support.          n/a",Feasibility of a Natural Language Processing-based Dental Charting Application,7305430,R21DE018158,"['Caring', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Computerized Patient Records', 'Computers', 'Condition', 'Data', 'Dental', 'Dental Dictionaries', 'Dental General Practice', 'Dental Hygienists', 'Dental Informatics', 'Dental Offices', 'Dental Records', 'Dentistry', 'Dentists', 'Development', 'Devices', 'Disabled Persons', 'Documentation', 'Evaluation', 'Foundations', 'Goals', 'Human Resources', 'Infection Control', 'Language', 'Manuals', 'Maps', 'Measurement', 'Medical', 'Medical Transcription', 'Mus', 'Natural Language Processing', 'Numbers', 'Outcome', 'Patient Care', 'Patients', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Project Grants', 'Services', 'Speech', 'Speech Recognition Software', 'Structure', 'Surveys', 'System', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Tooth structure', 'Training', 'Transcript', 'Universities', 'Vocabulary', 'Work', 'base', 'biomedical informatics', 'concept', 'dental structure', 'design', 'digital', 'experience', 'handicapping condition', 'improved', 'innovation', 'prevent', 'prototype', 'restoration', 'speech recognition', 'tool']",NIDCR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2007,229030,-0.023529065249888185
"A Document Processing System A system of C++ language programs has been developed for the purpose of finding the closely related documents in Medline and for the purpose of performing machine learning on sets of documents. The system has a number of unique features: 1) It is based on a number of C++ classes and highly modular so that alterations in the system are relatively simple to perform. 2) The system currently processes PubMed data by extracting from the Sybase repositories using a C++ interface to Sybase. However, a change in the interface portion of the system would allow it to be applied to any large database consisting of discrete textual records. 3) Data processed by the system is stored as compressed file structures, etc. These structures are updatable so that new data may be continually added to the system as it becomes available. 4) Documents are compared with each other using a Bayesian form of analysis. 5) The latest work on this system has involved adding the ability to generate themes using an EM algorithm approach. Also recently code has been multithreaded and memory mapping capabilities added to speed up processing.  The system described here is now not only being used to process all of MEDLINE for our research purposes, but also to produce the related documents for arbitrary pieces of text by other groups here in the NLM and outside of the NLM. The system has been used for mining email communications for the NLM help desk. n/a",A Document Processing System,7594456,Z01LM000022,"['Algorithms', 'Class', 'Code', 'Communication', 'Data', 'Databases', 'Electronic Mail', 'Literature', 'MEDLINE', 'Machine Learning', 'Maps', 'Memory', 'Methods', 'Mining', 'Numbers', 'Online Systems', 'Process', 'Programming Languages', 'PubMed', 'Purpose', 'Records', 'Research', 'Speed', 'Structure', 'System', 'Testing', 'Text', 'Work', 'base', 'computerized data processing', 'repository', 'software systems']",NLM,NATIONAL LIBRARY OF MEDICINE,Z01,2007,52962,0.022706810070122003
"Using Natural Language Processing to Monitor Product Claims Compliance for FDA    DESCRIPTION (provided by applicant): Linguastat, Inc. proposes to develop a means to automate the process of monitoring and identifying companies engaged in false advertising and deceptive practices in the marketing of drugs, dietary supplements, and/or food products. By leveraging state of the art approaches in computational linguistics such as Information Extraction and Natural Language Processing, it should be feasible, with some adaptation, to use this technology to: 1) automatically and continuously monitor the websites, TV transcripts, press releases and other electronic marketing text communications of tens of thousands of companies for various claims and product information 2) automatically ""red-flag"" instances in which claims have a high likelihood of potential harm to consumers, according to FDA priorities 3) automatically identify and extract the companies, products and claims embedded in electronic product information and electronic promotional materials to create a database easily searchable by the FDA and 4) automatically capture web-based or other electronic content for human review and store it as ""evidence."" Such automated technology would enable the FDA to significantly stretch its limited human resource to more effectively and comprehensively identify noncompliant product information, detect deceptive ads and other illegal practices, successfully prosecute offenders, and prevent harm to American consumers. For this Phase I SBIR project we propose to assess the feasibility of automated claims monitoring in three steps: In the first step, we will train information extraction and natural language processing algorithms to extract product marketing claims from text. In the second, step we will apply data mining and rules-based algorithms to assess which claims are likely to be non-compliant and merit further attention by FDA staff. In the third step, we will design and build a database of product claims that allows analysts to search, organize, and prioritize product claims based on the type of claim (e.g. what ailments does the product claim to treat), the type of product, and the likelihood of non- compliance. This technology will enable regulators and consumers to better monitor and detect cases of false, misleading, or deceptive advertising and product information. By enabling more effective enforcement of FDA regulations and giving consumers tools to make better buying decisions, the public health can be better protected by minimizing the impact of products that cause harm, give false hope, or entice consumers to forgo conventional remedies.          n/a",Using Natural Language Processing to Monitor Product Claims Compliance for FDA,7326883,R43FD003406,[' '],FDA,"LINGUASTAT, INC.",R43,2007,99773,0.025148296148449368
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts    DESCRIPTION (provided by applicant):  Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted readability levels with no critical information loss, using statistical natural language processing techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive impact on reader comprehension. We will use as a test bed for our system a general internal medicine clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public.              n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7303652,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2007,435682,0.03732313668540896
"Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts Many studies have shown that the readability of the health information provided to consumers does not match their general reading levels (Rudd, Moeykens et al. 2000). Even with the efforts of healthcare providers and writers to make materials more readable, today most patient-oriented Web sites, pamphlets, drug-labels, and discharge instructions still require the consumer to have a tenth grade reading level or higher (Nielsen-Bohlman, Panzer et al. 2004). Not infrequently, however, consumer reading levels are as low as fourth grade. To address this problem, we propose developing a computer-based method for providing texts of appropriate readability to a consumer. Recent progress in statistical natural language processing techniques (Barzilay 2003; Barzilay and Elhadad 2003; Elhadad, McKeown et al. 2005) lead us to believe that computer programs can be developed to dramatically increase the range and amount of readable content available to consumers. It may also help improve comprehension, self management and eventually clinical outcome. The general goal of this project is to provide consumers with readable content through the automated translation of content from difficult to understand to easy to understand. The specific aims are 1. To develop a computerized instrument for assessing the readability of health texts. We will enhance  existing readability instruments (Zakaluk and Samuels March 1, 1988) by including measurements of  health term difficulty, text cohesion, and content organization and layout. 2. To develop a ""Plain English"" tool for translating complex health texts into new versions at targeted  readability levels with no critical information loss, using statistical natural language processing  techniques. 3. To conduct an evaluation study to verify that providing content with appropriate readability has a positive  impact on reader comprehension. We will use as a test bed for our system a general internal medicine  clinic and its diabetes patients. We will provide self-care materials to these patients. Relevance to public health: The proposed development of a readability assessment instrument and ""Plain English"" tool will help translating complex health materials into reader-appropriate texts. It has the potential of making the vast amount of available information in the health domain more accessible to the lay public. n/a",Improving Health Outcomes through Computer Generation of Reader-Appropriate Texts,7492453,R01DK075837,"['Address', 'Beds', 'Clinic', 'Clinical', 'Complex', 'Comprehension', 'Computers', 'Development', 'Diabetes Mellitus', 'Drug Labeling', 'Evaluation Studies', 'Exercise', 'Generations', 'Goals', 'Health', 'Health Personnel', 'Health education', 'Home environment', 'Instruction', 'Internal Medicine', 'Internet', 'Lead', 'Measurement', 'Metabolic Control', 'Methods', 'Natural Language Processing', 'Nursing Faculty', 'Outcome', 'Pamphlets', 'Patients', 'Public Health', 'Range', 'Readability', 'Reader', 'Reading', 'Score', 'Self Care', 'Self Management', 'Site', 'Smog', 'Software Tools', 'System', 'Teaching Materials', 'Techniques', 'Testing', 'Text', 'Today', 'Translating', 'Translations', 'Weight maintenance regimen', 'Work', 'Writing', 'base', 'cohesion', 'computer program', 'computerized', 'improved', 'instrument', 'literacy', 'patient oriented', 'prevent', 'programs', 'tool']",NIDDK,BRIGHAM AND WOMEN'S HOSPITAL,R01,2007,47853,0.036699376983130125
"MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME    DESCRIPTION (provided by applicant):       The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care.       Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients.      Public Statement      The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury.          n/a",MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME,7262635,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY MED CTR,R01,2007,304785,0.00322337502843009
"TIME:(Tools for Inpatient Monitoring using Evidence)for Safe & AppropriateTesting The MOMENT (Monitoring for Outpatient Medication Effects and New Toxicities) in TIME project will extend the in-progress TIME (Tools for Inpatient Monitoring using Evidence) for Safe and Appropriate Testing grant, #5 R01 LM007995-03, by developing sophisticated text-mining and data extraction tools to examine adverse drug effects in patients presenting for emergency and hospital care. Using a UMLS-based concept identifier enhanced with natural language processing, the MOMENT project will detect: (a) individual clinical manifestations (symptoms and physical exam findings) that are potentially drug related; (b) clinical syndromes (e.g., hepatoxicity, myopathy, renal insufficiency, glucose intolerance); and, (c) and clinical diseases (such as systemic lupus induced by hydralazine or procainamide, or acute myocardial infarction associated with rofecoxib). Innovative aspects of the proposed work include use of advanced natural language processing techniques to abstract concepts representing potential drug effects from patient history and physical examination records and ancillary test reports, the combination of evidence- based templates and diagnostic algorithms to detect complex patterns of drug toxicity (e.g., hepatocelluar damage, pulmonary fibrosis, or acute coronary syndrome), advanced statistical methods for determining medication effects in large populations, and utilization of a clinical database containing data on more than 100,000 patients. Public Statement The MOMENT project (Monitoring for Outpatient Medication Effects and New Toxicities) will demonstrate the feasibility of combining informatics applications increasingly present in many healthcare institutions - electronic medical record systems and care provider order entry (CPOE) systems - to create an advanced detection and monitoring system for adverse medication effects. The project will develop tools and algorithms to detect the patient symptoms, physical exam signs, test results, and medical diagnoses that may indicate drug-induced injury. n/a",TIME:(Tools for Inpatient Monitoring using Evidence)for Safe & AppropriateTesting,7347232,R01LM007995,"['Abnormal Laboratory Test Result', 'Accreditation', 'Acute myocardial infarction', 'Admission activity', 'Adverse drug effect', 'Adverse effects', 'Algorithms', 'Ambulatory Monitoring', 'Appendix', 'Basic Science', 'Caring', 'Chest Pain', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer Assisted', 'Computerized Medical Record', 'Condition', 'Congenital Abnormality', 'Coronary heart disease', 'Data', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Diuretics', 'Drug Delivery Systems', 'Drug Exposure', 'Drug Prescriptions', 'Drug Utilization', 'Drug toxicity', 'Drug usage', 'Edema', 'Electronic Health Record', 'Emergency Situation', 'Evaluation', 'Event', 'Frequencies', 'Glucose Intolerance', 'Grant', 'Healthcare', 'Hepatotoxicity', 'Hormones', 'Hospitalization', 'Hospitals', 'Hour', 'Hydralazine', 'Image', 'Inappropriate ADH Syndrome', 'Individual', 'Informatics', 'Injury', 'Inpatients', 'Institution', 'Joints', 'Kidney Failure', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Literature', 'Liver Cirrhosis', 'Lower Extremity', 'Lupus', 'Manufacturer Name', 'Marketing', 'Medical', 'Medical Surveillance', 'Methods', 'Methotrexate', 'Modality', 'Monitor', 'Myopathy', 'Natural Language Processing', 'Numbers', 'Outcome', 'Outpatients', 'Pathology', 'Patients', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase II/III Trial', 'Physical Examination', 'Population', 'Predictive Value', 'Procainamide', 'Process', 'Provider', 'Pulmonary Fibrosis', 'Purpose', 'Recording of previous events', 'Records', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Rofecoxib', 'Sampling', 'Score', 'Screening procedure', 'Sentinel', 'Severities', 'Site', 'Standards of Weights and Measures', 'Statistical Methods', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Test Result', 'Testing', 'Text', 'Time', 'TimeLine', 'Toxic effect', 'United States Food and Drug Administration', 'Universities', 'Vocabulary', 'Work', 'abstracting', 'acute coronary syndrome', 'base', 'care systems', 'concept', 'healthy volunteer', 'impression', 'innovation', 'knowledge base', 'member', 'mortality', 'novel', 'post-market', 'programs', 'telithromycin', 'text searching', 'tool']",NLM,VANDERBILT UNIVERSITY MED CTR,R01,2007,55295,0.0021698718075861935
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7195053,G08LM008983,"['Academy', 'Address', 'Basic Science', 'Collection', 'Computer Systems Development', 'County', 'Digital Libraries', 'Effectiveness', 'Elements', 'Ensure', 'Evaluation', 'Frequencies', 'Funding', 'Goals', 'Gray unit of radiation dose', 'Harvest', 'Health', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Improve Access', 'Information Systems', 'Intervention', 'Language', 'Librarians', 'Life', 'Literature', 'MEDLINE', 'Measures', 'Medicine', 'Metric', 'Mission', 'Modeling', 'Natural Language Processing', 'New York', 'Online Systems', 'Outcome Measure', 'Perception', 'Population', 'Process', 'Public Health', 'Reporting', 'Research', 'Research Project Grants', 'Retrieval', 'Source', 'Specialist', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Today', 'Training', 'Translating', 'United States National Library of Medicine', 'Update', 'Wood material', 'Work', 'base', 'cost', 'design', 'digital', 'experience', 'feeding', 'improved', 'research to practice', 'tool']",NLM,SYRACUSE UNIVERSITY,G08,2007,145510,0.023291810531148024
Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing No abstract available n/a,Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing,8449372,R01PH000022,[' '],PHPPO,MAYO CLINIC ROCHESTER,R01,2007,157257,0.05868494349919874
"Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing Bioterrorism remains a significant threat to our public health. Early identification of an increased rate of occurance of patient presentations consistent with an exposure to an agent of bioterrorism is one important method to contain bioterror attacks and effect more rapid treatment of exposed individuals. Often presentations consistent with an exposure to an agent of bioterrorism occur in significant numbers prior to the recognition that a bioterrorism related exposure has occurred. This presents an opportunity to capture and analyze signals from patient records. We propose to provide an abstraction of automated clinical information from the clinical record (section by section) that will be coded using SNOMED-CT which can serve as the substrate for surveillance data. We believe that this data (sets of codes by section of the clinical record) which holds the important and salient medical facts (codes) regarding the patients' presentation, findings, medications, allergies and co-morbidities could be abstracted from clinical records. In this study, we will analyze SNOMED-CT's ability to provide adequate content coverage for constellations of symptoms associated with exposures to agents of bioterrorism (i.e. Anthrax, Small Pox, Ricin, and Radiation exposure). Our method builds on the considerable body of research already available within our laboratory. We have been researching methods for codifying medical content using controlled medical vocabularies since 1987. For this study, we will employ the Mayo Vocabulary Server (MVS) developed in the Mayo Laboratory of Biomedical Informatics and has been used at Mayo, Johns Hopkins University and the VA medical centers all with great success. Our performanc2 of the MVS toolkit has been validated for diagnoses where we showed a sensitivity of 99.7% and a specificity of 97.9%. This proposal deals with practical issues that lead the way toward interoperable data. The fruits of this research will assist our national initiatives to pave the way toward a safe and effective BioSecure biosurveillance solution. n/a",Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing,7790142,R01PH000022,[' '],PHPPO,MOUNT SINAI SCHOOL OF MEDICINE,R01,2007,677278,-0.0014582175152174947
"Analysis and Remediation of Language Production DESCRIPTION (provided by applicant): Aphasia strikes approximately one in 250 Americans. The reduced ability to communicate with language represents, in most cases, a catastrophic loss of self-sufficiency and a source of profound social isolation. No treatment for aphasia reported to date has reliably brought about changes in language production that migrate from highly constrained laboratory tasks such as single picture description to more challenging and socially functional tasks such as the production of entire narratives. The current climate in health care limits access to speech therapy, and thus it is imperative to develop approaches to treatment which allow patients to supplement 1:1 clinical treatment with intensive independent home practice. We have developed two computer programs to address the need for effective aphasia treatments that can be used semi-independently. One is a communication system (CS), which allows aphasic users to record spoken sentences a single word or phrase at a time, to replay these words or phrases, and to build them into sentences and narratives by manipulating visual icons on a computer screen. The other program is a language therapy system (TS) incorporating speech recognition and natural language understanding technology, which allows the computer to 'understand' the patient's spoken sentence and to provide feedback about whether it correctly describes a picture on the screen. This allows independent home practice of spoken language. The goals of this project are: (1) to replicate pilot results showing measurably more structured language production by aphasic patients using the CS, and to link these effects to characteristics of subjects' language processing impairments (Exp. 1); (2) to assess the impact of enhancing the CS with word-finding support for more severely impaired patients (Exp. 2); (3) to replicate the positive outcomes in pilot studies which used the TS and CS to improve aphasic patients' spoken language production, and to use the TS to train subjects on grammatical structures that provide tests of specific hypotheses about the impact of impaired short term memory on aphasic production (Exp. 3); and (4) to use data automatically collected by the CS to investigate the nature of the underlying disruption and to motivate the most effective approaches to remediation (Exp. 4). Information obtained from these studies will provide a basis for the further development of novel, theoretically motivated approaches to aphasia treatment. n/a",Analysis and Remediation of Language Production,7188572,R01DC005629,"['Address', 'American', 'Aphasia', 'Characteristics', 'Climate', 'Clinical Treatment', 'Communication', 'Computer software', 'Computers', 'Condition', 'Data', 'Development', 'Disruption', 'Elements', 'Employee Strikes', 'Evaluation', 'Facility Construction Funding Category', 'Feedback', 'Funding', 'Goals', 'Head', 'Healthcare', 'Home environment', 'Impairment', 'Knowledge', 'Laboratories', 'Language', 'Language Therapy', 'Linguistics', 'Link', 'Measures', 'Monitor', 'Natural Language Processing', 'Nature', 'Numbers', 'Outcome', 'Patients', 'Performance', 'Pilot Projects', 'Play', 'Process', 'Production', 'Property', 'Psycholinguistics', 'Reporting', 'Role', 'Semantics', 'Short-Term Memory', 'Social isolation', 'Source', 'Speech', 'Speech Therapy', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Visual', 'analytical method', 'aphasic', 'base', 'computer program', 'improved', 'language processing', 'lexical', 'lexical retrieval', 'novel', 'phonology', 'programs', 'remediation', 'size', 'speech recognition', 'syntax', 'treatment effect']",NIDCD,UNIVERSITY OF MARYLAND BALTIMORE,R01,2007,337888,-0.021902373602299942
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,7076099,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2006,162000,0.04698494348970951
"Discovering and Applying Knowledge in Clinical Databases    DESCRIPTION (provided by applicant):  The ongoing goal of our project, ""Discovering and applying knowledge in clinical databases,"" is to develop and apply methods to exploit electronic medical record data for decision support, with an emphasis on narrative data. Since the inception of our project as an R29 in 1994, we have been developing methods for preparing raw electronic medical record data, applying and evaluating natural language processing, developing data mining techniques including machine learning, and putting the results to use for clinical care and research.       In this competing continuation, we propose to address the temporal information in the electronic medical record and to apply natural language processing and temporal processing to the task of syndromic surveillance in collaboration with the New York City Department of Health and Mental Hygiene (NYC DOHMH).       We have begun work on a temporal processing system. It extracts temporal assertions stated in narrative reports, uses the MedLEE natural language processor to parse the non-temporal information, infers implicit temporal assertions based on a knowledge base, and produces the information in the form of a simple temporal constraint satisfaction problem. The latter can be used to answer questions about the time of events and the temporal relation between pairs of events. We propose to complete the system, expand the knowledge base, speed computation, address the uncertainty of temporal assertions, incorporate temporal information from structured data, and evaluate the system.       NYC DOHMH has a mature syndromic surveillance system that watches over almost eight million persons, and it has as-yet unexploited data sources in the form of narrative and structured electronic medical records. We propose to apply natural language processing and our proposed temporal processing to convert the data to a form appropriate for surveillance. We will evaluate the incremental benefit of structured data, narrative data, and temporally processed narrative data.           n/a",Discovering and Applying Knowledge in Clinical Databases,7147611,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,372106,0.03338015532901871
Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing No abstract available n/a,Biosurveillance Utilizing SNOMED-CT Based Natural Language Processing,7119574,R01PH000022,[' '],PHPPO,MAYO CLINIC,R01,2006,834535,0.05868494349919874
"Answering Information Needs in Workflow    DESCRIPTION (provided by applicant): Needs for information arise continuously during the course of clinical practice, especially for physicians in training, e.g. when examining a patient or participating in rounds. In most of these situations, it is difficult or impossible for the clinician to immediately access appropriate information resources. Most needs are never adequately articulated or recorded, and consequently are forgotten by the end of the day. Moreover, when clinicians do recall information needs, they don't act on them, due to the significant limitations of current retrieval systems and the exigencies of clinical practice. The specific aims of the proposed project are: 1) to capture information needs in a convenient manner at the moment they occur using different modalities such as text input and voice capture on hand-held devices, 2) to translate high-level information needs into complex search strategies that adapt to user needs and are tuned to the capabilities of resources, and 3) to deliver relevant materials to the clinician in an accessible format and in a timely manner. The project will develop a central hub for addressing the information needs of medical students and residents, to be transmitted electronically as they occur in the field. A unique feature of the project is the use of natural language processing technology to identify context, goals and preferences in clinicians' questions. The major innovation is the generation of complex search strategies that exploit this contextual information, based on studies of human searching experts (reference librarians).              n/a",Answering Information Needs in Workflow,7101997,R01LM008799,"['clinical research', 'human', 'language', 'memory disorders', 'model', 'physicians', 'training', 'voice']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,372499,0.009694427718879153
"Improving Public Health Grey Literature Access for the Public Health Workforce    DESCRIPTION (provided by applicant): The long-term objective of the proposed project is to provide the public health (PH) workforce with improved access to high quality, relevant PH grey literature reports in order to positively impact the planning, conducting, and evaluating of PH interventions. The project will consist of two components: 1) continuation of user-focused technical system development, and 2) deployment and evaluation of this system's impact on the tasks of the PH workforce in county health departments.      The system will automatically harvest web-based grey literature reports (utilizing rules trained on input from PH professionals) and then produce rich summaries of PH grey literature reports using the model of essential elements of PH intervention reports validated by PH specialists (Turner et al, In Press). After developing a user interface that capitalizes on both natural language querying and the display of search results in a structured, model-based summary, the system will be introduced into several county health departments and evaluated to determine its impact on information flows and uses.      The project will include intrinsic evaluations of: 1) the appropriateness of the grey literature reports harvested by the system; 2) the quality and sufficiency of summaries representing the full reports based on the PH intervention model and; 3) retrieval results for users' queries using metrics of precision and recall. Extrinsic evaluation will be done in PH departments participating in the New York Academy of Medicine's ongoing study of the relationship between information and effectiveness. The research will provide baseline measures. We will evaluate: 1) the ease and frequency of use, perceptions of currency, accuracy, and completeness of retrieved reports by county PH personnel, and; 2) impact of the system's usage on information flows and uses based on internal outcome measures within the county health departments.      The work proposed here shares both the missions of public health and the National Library of Medicine   through the design of an information system that exploits natural language processing technology to   efficiently collect and provide access to quality public health grey literature for the public health workforce.         n/a",Improving Public Health Grey Literature Access for the Public Health Workforce,7019753,G08LM008983,"['clinical research', 'public health']",NLM,SYRACUSE UNIVERSITY,G08,2006,149472,0.023291810531148024
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,7007660,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2006,29424,0.020514014020238117
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6898458,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2005,162000,0.04698494348970951
"Biosurveillance/SNOMED-CT Natural Language Processing Bioterrorism remains a significant threat to our public health. Early identification of an increased rate of occurance of patient presentations consistent with an exposure to an agent of bioterrorism is one important method to contain bioterror attacks and effect more rapid treatment of exposed individuals. Often presentations consistent with an exposure to an agent of bioterrorism occur in significant numbers prior to the recognition that a bioterrorism related exposure has occurred. This presents an opportunity to capture and analyze signals from patient records. We propose to provide an abstraction of automated clinical information from the clinical record (section by section) that will be coded using SNOMED-CT which can serve as the substrate for surveillance data. We believe that this data (sets of codes by section of the clinical record) which holds the important and salient medical facts (codes) regarding the patients' presentation, findings, medications, allergies and co-morbidities could be abstracted from clinical records. In this study, we will analyze SNOMED-CT's ability to provide adequate content coverage for constellations of symptoms associated with exposures to agents of bioterrorism (i.e. Anthrax, Small Pox, Ricin, and Radiation exposure). Our method builds on the considerable body of research already available within our laboratory. We have been researching methods for codifying medical content using controlled medical vocabularies since 1987. For this study, we will employ the Mayo Vocabulary Server (MVS) developed in the Mayo Laboratory of Biomedical Informatics and has been used at Mayo, Johns Hopkins University and the VA medical centers all with great success. Our performanc2 of the MVS toolkit has been validated for diagnoses where we showed a sensitivity of 99.7% and a specificity of 97.9%. This proposal deals with practical issues that lead the way toward interoperable data. The fruits of this research will assist our national initiatives to pave the way toward a safe and effective BioSecure biosurveillance solution.  n/a",Biosurveillance/SNOMED-CT Natural Language Processing,7098649,R01PH000022,"['abstracting', 'artificial intelligence', 'biohazard detection', 'bioterrorism /chemical warfare', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'disease outbreaks', 'early diagnosis', 'environmental health', 'human data', 'mathematical model', 'medical records', 'model design /development', 'public health', 'rapid diagnosis', 'vocabulary development for information system']",PHPPO,MAYO CLINIC,R01,2005,514616,-0.0014582175152174947
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6892934,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,384538,0.03090559219459159
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6902613,R01MH066228,"['behavioral /social science research tag', 'clinical research', 'computational neuroscience', 'human middle age (35-64)', 'human subject', 'language', 'neural information processing', 'neuropsychology', 'psychopathology', 'schizophrenia', 'short term memory', 'young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2005,220725,-0.009043377010702366
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,6847778,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2005,29424,0.020514014020238117
"Natural Language Processing for Respiratory Surveillance    DESCRIPTION (provided by applicant): The applicant's long-term career goal is to become an independent investigator in biomedical informatics research. She will dedicate her career to developing and evaluating methodologies for improving the processes and outcomes of healthcare using data locked in textual documents. This career development award will provide her with initial support for achieving her career goals.      The applicant has three goals for her career development over the next three years. First, she will compare the performance of different machine learning techniques at detecting patients with a respiratory syndrome. The proposed research will expand the state-of-the-art syndromic surveillance capabilities by integrating findings, symptoms, and diseases described in textual medical records. The product of the first research goal will be a model for respiratory syndromic case detection for monitoring natural and bioterrorism induced respiratory outbreaks. Second, she will apply existing methods and develop new techniques for extracting clinical conditions required for respiratory case detection from emergency department notes, contributing new knowledge to the medical language processing field using sentence and report level models that account for uncertainty, negation, and temporal occurrence. The product of the second goal will be a better understanding of the information required for accurate detection of respiratory related conditions from text and useful tools for automatically extracting that information. Third, she will teach, promote, and facilitate the use of natural language processing in the biomedical informatics field. The product of the third goal will be a graduate class surveying medical language processing methodology and applications and development of general tools sets for researchers who need encoded data from textual patient records.        The proposed research will focus on:   Aim 1. Development and evaluation of a respiratory case detection model;   Aim 2. Integration of existing natural language processing tools and development of new methodologies for extracting clinical conditions needed for respiratory case detection from textual records; and   Aim 3. Comparison of existing syndromic detection algorithms that use admit data against the same algorithms using conditions extracted from textual reports.         n/a",Natural Language Processing for Respiratory Surveillance,6768325,K22LM008301,"['automated data processing', 'automated medical record system', 'bioinformatics', 'bioterrorism /chemical warfare', 'clinical research', 'communicable disease diagnosis', 'computer assisted diagnosis', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease outbreaks', 'early diagnosis', 'hospital utilization', 'human data', 'language translation', 'respiratory disorder epidemiology', 'severe acute respiratory syndrome', 'sign /symptom']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K22,2004,135000,0.04698494348970951
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6754395,R01LM006910,"['artificial intelligence', 'classification', 'clinical research', 'computer assisted medical decision making', 'computer assisted patient care', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'health care facility information system', 'human data', 'information system analysis', 'method development', 'vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,380979,0.03090559219459159
"Preserving Privacy in Medical Data Sets Privacy is a fundamental right and needs to be protected.  For health care related d information, there are regulations for disclosure.  These regulations were motivated by the public's concern of breaches of confidentiality that might result in discrimination.  The recent progress in electronic medical record technology, the Internet, and the genetic revolution, together with media reports on violations of privacy have generated increasing interest in this topic.  A common belief is that sensitive information is more easily available with the use of networked computers. Since total lack of disclosure is not realistic, current regulations require that the ""minimal amount"" of information be given to a certain party.  A thorough study on what constitutes ""minimal"" for particular types of applications and a ""usefulness index"" is lacking.  An exact quantification of the potential for privacy breach in de-identified or anonymized databases is also lacking.  Definition and quantification of these indices is important for decision-making.  As we demonstrate, de-identified data sets can still be used for inference and therefore may disclose sensitive information.  The use of machine learning methods to verify the remaining functional dependencies in a de- identified data set leads to better understanding of the possible inferences.  Anonymization techniques based on logic, statistics, database theory, and machine learning methods can help in the protection of privacy. We will formally define and study anonymity in databases, from a theoretical and a practical standpoint.  We will develop and implement algorithms to anonymize data sets that will be in accordance with the balance of anonymity and ""usefulness"" of the disclosed data sets.  We will also develop and implement algorithms to verify the anonymity of a given data set and indicate the type of records that are at highest risk for a privacy attack.  We will make our methods and documented tools freely available to researchers via the WWW. n/a",Preserving Privacy in Medical Data Sets,6733529,R01LM007273,"['Internet', 'behavioral /social science research tag', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'confidentiality', 'data management', 'decision making', 'health care facility information system', 'health care policy', 'human data', 'human rights', 'information dissemination', 'information retrieval', 'mathematical model', 'medical records', 'model design /development', 'patient oriented research', 'statistics /biometry']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2004,406979,0.002743328434305304
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6754401,R01MH066228,"['behavioral /social science research tag', 'clinical research', 'computational neuroscience', 'human middle age (35-64)', 'human subject', 'language', 'neural information processing', 'neuropsychology', 'psychopathology', 'schizophrenia', 'short term memory', 'young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2004,220725,-0.009043377010702366
"PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES    DESCRIPTION (provided by applicant): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate as opposed to being gleaned post-natally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from machine learning and statistics, along with methods from theories of syntax and semantics in linguistics. Experiments comparing results from the methods to be implemented with those of other, existing unsupervised learning systems for grammatical inference as benchmarks will be carried out, computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small sets of data, but with a view to eventual scaling up so that the system can be trained on large sets of data characterizing actual natural language use in conversational contexts.         n/a",PREDOCTORAL FELLOWSHIPS FOR STUDENTS WITH DISABILITIES,6743829,F31HD041927,"['behavioral /social science research tag', 'computer simulation', 'language development', 'learning', 'predoctoral investigator', 'syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2004,29424,0.020514014020238117
"Access to distributed de-identified imaging data DESCRIPTION (provided by applicant):    The widespread adoption of picture archiving and communications systems (PACS) in radiology and the implementation and deployment of the DICOM communication standard represent an opportunity to link multiple PACS at multiple sites into a distributed data warehouse of great potential utility for investigators in oncology research and epidemiology. Where the federal HIPAA privacy regulations have largely been seen as an emerging impediment to oncology research from the creation, management and use of cancer registries to large-scale retrospective studies addressing rarer forms of neoplasia, in fact the digital nature of PACS-based imaging data lends itself to automated de-identification that could transform multiple distributed clinical information systems into a readily accessible treasure trove of research data that falls within the ""safe harbor"" provisions of HIPAA's privacy regulations. Our firm has developed a platform, originally intended for clinical use, to securely link multiple PACS and RIS from multiple vendors beneath a web interface giving users transparent access to a ""virtual archive"" spanning an arbitrary number of institutions. In this Phase I SBIR application, we propose to explore the feasibility of extending our system to grant researchers access to large volumes of dynamically de-identified imaging data while surmounting each of the major criticisms of the viability of such data for research purposes. We propose developing an open web-services architecture that will enable straightforward integration with any other information system and propose a design that adheres to existing industry standards while laying the groundwork for compliance with future standards and informatics initiatives. This study will also involve examining the regulation of re-identification through the use of threshold cryptography, as well as the feasibility of a probabilistic sampling search engine intended to prevent unauthorized identification of patients through multiple intersecting queries on narrowing criteria, while still permitting researchers to choose the appropriate resolving power of the engine to suit a particular investigation. These studies will include benchmarking the performance of these dynamic processes, quantifying the load they place on live clinical information systems, and optimizing the design to minimize such impact. Should feasibility be demonstrated, Phase II would involve a proof-of-concept demonstration across multiple academic medical institutions as well as steps to prepare for commercialization including indexing studies based on structured reporting and natural language processing, content-based information retrieval, refinement and usability testing of the web interfaces, and extension of the system to permit IRB-approved research on individually-identifiable data. Commercialization is expected as subscription service not unlike current bioinformatics databases, granting investigators access to a large-scale, globally distributed data warehouse comprised of participating PACS-enabled medical centers. n/a",Access to distributed de-identified imaging data,6777517,R43EB000608,"['archives', 'clinical research', 'computer data analysis', 'computer system design /evaluation', 'confidentiality', 'data management', 'health care policy', 'health related legal', 'human data', 'imaging /visualization /scanning', 'information systems']",NIBIB,"HX TECHNOLOGIES, INC.",R43,2004,149200,0.00928231751957905
"UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE   DESCRIPTION (adapted from the Abstract):                                             With the explosion of medical information accessible via the Internet, there         is a growing need for development of better access to the online medical             literature databases through user-friendly systems and interface.  The               proliferation of online information and the diversity of interfaces to data          collections has led to a medical information gap between medical researchers         and the accessibility of medical literature databases.  Users who need access        to such information must visit a variety of sources, which can be both               excessively time consuming and potentially dangerous if the information is           needed for treatment decisions.  In addition, information generated by using         existing search engines is often too general or inaccurate.  Particularly            frustrating is that simple queries can result in an excessive number of              documents retrieved - too many to search through to determine which are and          which are not relevant.                                                                                                                                                   The goal of this research is to extend a bridge across the medical information       gap by creating easy-to-use interfaces to medical literature databases based         on UMLS-enhanced Semantic Parsing and Personalized Medical Agent (PMA):                                                                                                   (1)  UMLS-enhanced Semantic Parsing: Our first goal will be to combine noun          phrasing and co-occurrence analysis techniques recently developed by The             University of Arizona Artificial Intelligence Lab (AI Lab) for the NSF-funded        Illinois Digital Library Initiative (DLI) project with existing components           found in the Unified Medical Language System (UMLS) developed by NLM.                                                                                                     (2)  Personalized Medical Agent: The second goal will be to develop a dynamic,       intelligent medical agent interface to assist searchers in effortlessly              locating documents and summarizing topics in the documents.  The interface is        particularly suited for busy physicians.                                                                                                                                  n/a",UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE,6637557,R01LM006919,"['abstracting', ' artificial intelligence', ' cancer information system', ' computer system design /evaluation', ' human data', ' information retrieval', ' information system analysis', ' literature citation', ' semantics', ' vocabulary development for information system']",NLM,UNIVERSITY OF ARIZONA,R01,2003,148818,0.010211461611554909
"Discovering and Applying Knowledge in Clinical Databases DESCRIPTION (provided by applicant):     With the advent of improved clinical information system products (e.g., ambulatory systems, order entry  systems), improved data entry technologies (e.g., speech recognition, text processing techniques), and  further adoption of data interchange standards, more institutions are generating electronic medical records, and these records will expand in breadth, depth, and degree of coding in the future. The records are used mainly for individual patient care, but exploiting the records for clinical research and quality functions has lagged behind. Major challenges include the wide range of complex data and missing and inaccurate data.      We propose to continue our work to develop and test methods to mine a clinical data repository. A  special emphasis will be to exploit the vast amount of information in the repository (latent associations and knowledge) and to use computer intensive techniques and advances in data representation and manipulation to better interpret what is in the database and to overcome the challenges of complex, missing, and inaccurate data. We hypothesize that data mining techniques can be applied to a repository to generate accurate clinical interpretations. We further hypothesize that associations latent in a clinically rich repository can be used to improve the classification of cases in that repository.      We aim to develop methods to prepare data for mining; to characterize the information in the clinical data repository; to develop similarity measures based on manipulation of natural language processor output and on information retrieval techniques; to apply nearest neighbor technique and case-based reasoning to improve classification; to develop a statistically based method to improve classification of cases with incomplete or inaccurate data; and to apply our methods to real clinical research questions and carry out additional data mining research.      The researchers in the Department of Medical Informatics at Columbia University are uniquely positioned to carry out this research, given the experience of the team (data mining, statistics, health data organization, health knowledge representation, natural language processing), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data. n/a",Discovering and Applying Knowledge in Clinical Databases,6630735,R01LM006910,"['artificial intelligence', ' classification', ' clinical research', ' computer assisted medical decision making', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' health care facility information system', ' human data', ' information system analysis', ' method development', ' vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,377617,0.03090559219459159
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6657426,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2003,369494,0.05345535578166235
"Preserving Privacy in Medical Data Sets Privacy is a fundamental right and needs to be protected.  For health care related d information, there are regulations for disclosure.  These regulations were motivated by the public's concern of breaches of confidentiality that might result in discrimination.  The recent progress in electronic medical record technology, the Internet, and the genetic revolution, together with media reports on violations of privacy have generated increasing interest in this topic.  A common belief is that sensitive information is more easily available with the use of networked computers. Since total lack of disclosure is not realistic, current regulations require that the ""minimal amount"" of information be given to a certain party.  A thorough study on what constitutes ""minimal"" for particular types of applications and a ""usefulness index"" is lacking.  An exact quantification of the potential for privacy breach in de-identified or anonymized databases is also lacking.  Definition and quantification of these indices is important for decision-making.  As we demonstrate, de-identified data sets can still be used for inference and therefore may disclose sensitive information.  The use of machine learning methods to verify the remaining functional dependencies in a de- identified data set leads to better understanding of the possible inferences.  Anonymization techniques based on logic, statistics, database theory, and machine learning methods can help in the protection of privacy. We will formally define and study anonymity in databases, from a theoretical and a practical standpoint.  We will develop and implement algorithms to anonymize data sets that will be in accordance with the balance of anonymity and ""usefulness"" of the disclosed data sets.  We will also develop and implement algorithms to verify the anonymity of a given data set and indicate the type of records that are at highest risk for a privacy attack.  We will make our methods and documented tools freely available to researchers via the WWW. n/a",Preserving Privacy in Medical Data Sets,6620783,R01LM007273,"['Internet', ' behavioral /social science research tag', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data management', ' decision making', ' health care facility information system', ' health care policy', ' human data', ' human rights', ' information dissemination', ' information retrieval', ' mathematical model', ' medical records', ' model design /development', ' patient oriented research', ' statistics /biometry']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2003,380761,0.002743328434305304
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6615572,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2003,114544,0.025224018002619326
"Neural Network Models of Language DESCRIPTION (provided by applicant): Schizophrenia is characterized by alterations of language and inferential processes. In spite of extensive research, core mechanisms of these disturbances remain uncertain. The overall objective of this RO1 proposal is to use DISCERN, a neural network simulation of natural language processing (Miikkulainen & Dyer 1991; Miikkulainen 1993, 1998), to investigate the mechanism(s) of language-based disturbances in schizophrenia. DISCERN learns stories, utilizes inferential processes, replies to questions, and produces coherent, multi-sentence narrative paraphrases of episodic memories. To enhance applicability of DISCERN as a model of human narrative language production, a larger corpus of stories will be learned that incorporates emotion-coding and self-reference. Simulations will be conducted to determine if disrupted function in different neural modules of DISCERN can produce three core language-based illness manifestations of schizophrenia -- (I) positive thought disorder (such as derailment and illogicality), (II) negative thought disorder (reduced language outputs), and (III) delusions of the idee fixe type. DISCERN will be used to compare and contrast effects of excessive noise versus reduced network connectivity when applied to semantic and working memory modules. Both types of ""lesions"" have been postulated to play an important role in the pathophysiology of schizophrenia. Noise-induced lesions are predicted to produce word selection errors and curtail language output -- but not to produce positive thought disorder or delusions. In contrast, connectivity loss, when applied to story processing modules, is predicted to simulate all three disturbances, i.e., derailment and curtailment of language outputs as well as production of ""fixed"" narratives that simulate delusions. A parallel, pilot study of normal subjects and patients with schizophrenia will assess narrative recall of episodic memory. These behavioral data will be used to test and refine models of normal and schizophrenic language production. These findings will significantly advance our understanding of illness mechanisms in schizophrenia and direct future research aimed at developing more selective treatments that reverse these abnormalities. n/a",Neural Network Models of Language,6679518,R01MH066228,"['behavioral /social science research tag', ' clinical research', ' computational neuroscience', ' human middle age (35-64)', ' human subject', ' language', ' neural information processing', ' neuropsychology', ' psychopathology', ' schizophrenia', ' short term memory', ' young adult human (21-34)']",NIMH,YALE UNIVERSITY,R01,2003,220725,-0.009043377010702366
"Language and Learning DESCRIPTION (provided by investigator): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate, as opposed to being gleaned postnatally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from statistical machine learning, along with theoretical methods from theories of syntax and semantics in linguistics. Experiments using existing grammars as benchmarks will be carried out computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small fragments of the grammar of English, but with a view to eventual scaling up so that the system can be trained on large sets of data deriving from actual natural language use in conversational contexts. n/a",Language and Learning,6622537,F31HD041927,"['behavioral /social science research tag', ' behavioral genetics', ' child psychology', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' gene environment interaction', ' health science research support', ' language', ' learning', ' mathematical model', ' model design /development', ' predoctoral investigator', ' psychological models', ' semantics', ' statistics /biometry', ' syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2003,28193,0.005331885036151065
"Access to distributed de-identified imaging data DESCRIPTION (provided by applicant):    The widespread adoption of picture archiving and communications systems (PACS) in radiology and the implementation and deployment of the DICOM communication standard represent an opportunity to link multiple PACS at multiple sites into a distributed data warehouse of great potential utility for investigators in oncology research and epidemiology. Where the federal HIPAA privacy regulations have largely been seen as an emerging impediment to oncology research from the creation, management and use of cancer registries to large-scale retrospective studies addressing rarer forms of neoplasia, in fact the digital nature of PACS-based imaging data lends itself to automated de-identification that could transform multiple distributed clinical information systems into a readily accessible treasure trove of research data that falls within the ""safe harbor"" provisions of HIPAA's privacy regulations. Our firm has developed a platform, originally intended for clinical use, to securely link multiple PACS and RIS from multiple vendors beneath a web interface giving users transparent access to a ""virtual archive"" spanning an arbitrary number of institutions. In this Phase I SBIR application, we propose to explore the feasibility of extending our system to grant researchers access to large volumes of dynamically de-identified imaging data while surmounting each of the major criticisms of the viability of such data for research purposes. We propose developing an open web-services architecture that will enable straightforward integration with any other information system and propose a design that adheres to existing industry standards while laying the groundwork for compliance with future standards and informatics initiatives. This study will also involve examining the regulation of re-identification through the use of threshold cryptography, as well as the feasibility of a probabilistic sampling search engine intended to prevent unauthorized identification of patients through multiple intersecting queries on narrowing criteria, while still permitting researchers to choose the appropriate resolving power of the engine to suit a particular investigation. These studies will include benchmarking the performance of these dynamic processes, quantifying the load they place on live clinical information systems, and optimizing the design to minimize such impact. Should feasibility be demonstrated, Phase II would involve a proof-of-concept demonstration across multiple academic medical institutions as well as steps to prepare for commercialization including indexing studies based on structured reporting and natural language processing, content-based information retrieval, refinement and usability testing of the web interfaces, and extension of the system to permit IRB-approved research on individually-identifiable data. Commercialization is expected as subscription service not unlike current bioinformatics databases, granting investigators access to a large-scale, globally distributed data warehouse comprised of participating PACS-enabled medical centers. n/a",Access to distributed de-identified imaging data,6694270,R43EB000608,"['archives', ' clinical research', ' computer data analysis', ' computer system design /evaluation', ' data management', ' health care policy', ' health related legal', ' human data', ' imaging /visualization /scanning', ' information systems']",NIBIB,"HX TECHNOLOGIES, INC.",R43,2003,250800,0.00928231751957905
"DISCOVERING AND APPLYING KNOWLEDGE IN CLINICAL DATABASES A real-time clinical repository contains a wealth of detailed information useful for clinical care, research, and administration.  In their raw form, however, the data are difficult to use there is too much volume, too much detail, missing values, and inaccuracies. Clinicians, researchers, and administrators require higher level interpretations that address their questions. For example, a clinician may need to know whether a patient is at sufficient risk for having active tuberculosis to warrant respiratory isolation. The answer to the question may be spread around the clinical repository in chest radiographs, laboratory tests, medication histories, vital signs, and physician's notes. Translating from these raw data to the interpretation (at risk or not) is a difficult and laborious task. The hypothesis of this proposal is that data mining techniques can be applied to a real-time clinical repository to discover knowledge and generate accurate clinical interpretations, and that these interpretations can be automated. The project differs from earlier machine learning studies in its emphasis on a real clinical repository and the use of natural language processing to supply coded clinical data. The specific aims are: (l) Select clinical domains--Several clinical domains with interesting, non-trivial clinical problems will be selected. Problems for which a gold standard answer can or has been assembled for a retrospective cohort will be chosen. (2) Prepare raw clinical data for mining--The raw data from a clinical repository will be transformed into a structure that facilitates data mining. The data will be flattened, pivoted, summarized, and mapped as needed for the domains. Narrative data will be coded using the MedLEE natural language processor. The preparation process will be automated. (3) Use data mining algorithms to discover knowledge- Several data mining algorithms will be applied to the selected clinical domains. Algorithms will include decision tree generation, rule discovery, neural networks, nearest neighbor, logistic regression, and composite algorithms (for variable reduction). The algorithms will be trained on a training set for each domain, and their predictive accuracy will be measured and compared to each other and to expert-written rules. The performance of human experts writing rules using manual data mining visualization techniques (which does not require an explicit training set) will also be measured. (4) Study the dependence of data mining on the training set--The performance of data mining algorithms depends on the data used the train them. The sensitivity of the algorithms to noise (inaccurate data), missing data, and training set size will be measured. (5) Use the discovered knowledge to generate real-time interpretations-- The output of the algorithms (decision tree, rules, neural network equation, or logistic regression equation, but not nearest neighbor) along with the necessary data preparation steps will be encoded in Arden Syntax Medical Logic Modules. They will be run against the clinical repository to verify that the interpretation can be automated in real time. (6) Disseminate the methods and results--The methods and results will be disseminated via publications and a Web site, and tools will be made available.  n/a",DISCOVERING AND APPLYING KNOWLEDGE IN CLINICAL DATABASES,6538211,R01LM006910,"['Internet', ' artificial intelligence', ' clinical research', ' computer assisted medical decision making', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' health care facility information system', ' human data', ' information dissemination', ' information system analysis', ' vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2002,403006,0.004516515218287874
"UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE   DESCRIPTION (adapted from the Abstract):                                             With the explosion of medical information accessible via the Internet, there         is a growing need for development of better access to the online medical             literature databases through user-friendly systems and interface.  The               proliferation of online information and the diversity of interfaces to data          collections has led to a medical information gap between medical researchers         and the accessibility of medical literature databases.  Users who need access        to such information must visit a variety of sources, which can be both               excessively time consuming and potentially dangerous if the information is           needed for treatment decisions.  In addition, information generated by using         existing search engines is often too general or inaccurate.  Particularly            frustrating is that simple queries can result in an excessive number of              documents retrieved - too many to search through to determine which are and          which are not relevant.                                                                                                                                                   The goal of this research is to extend a bridge across the medical information       gap by creating easy-to-use interfaces to medical literature databases based         on UMLS-enhanced Semantic Parsing and Personalized Medical Agent (PMA):                                                                                                   (1)  UMLS-enhanced Semantic Parsing: Our first goal will be to combine noun          phrasing and co-occurrence analysis techniques recently developed by The             University of Arizona Artificial Intelligence Lab (AI Lab) for the NSF-funded        Illinois Digital Library Initiative (DLI) project with existing components           found in the Unified Medical Language System (UMLS) developed by NLM.                                                                                                     (2)  Personalized Medical Agent: The second goal will be to develop a dynamic,       intelligent medical agent interface to assist searchers in effortlessly              locating documents and summarizing topics in the documents.  The interface is        particularly suited for busy physicians.                                                                                                                                  n/a",UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE,6530779,R01LM006919,"['abstracting', ' artificial intelligence', ' cancer information system', ' computer system design /evaluation', ' human data', ' information retrieval', ' information system analysis', ' literature citation', ' semantics', ' vocabulary development for information system']",NLM,UNIVERSITY OF ARIZONA,R01,2002,144484,0.010211461611554909
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6528316,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2002,360015,0.05345535578166235
"Human Subject Research Enhancements Program We propose to enhance the data consistency and integrity of oversight and tracking systems for human subjects research at Mayo Foundation. Our specific aims include: 1) a comprehensive information modeling exercise to understand the interrelationships and dependencies of administrative and clinical data elements related to human subjects research oversight; 2) building common application components that will simplify the creation of research protocols, IRB application, research subject enrollment and consent, and administrative tracking; 3) providing full text and natural language processing based indices to project abstracts, applications, minutes, and administrative notes, to facilitate the authorized searching and retrieval of materials human subject related to human subject review; and 4) coordinating the information model, modular software tools, and textual indexing, as preliminary work for a competitive informatics proposal for adverse event recognition, pattern detection, and the consistent recording of drugs, devices and outcomes measures. n/a",Human Subject Research Enhancements Program,6591449,S07RR018225,"['abstracting', ' behavioral /social science research tag', ' clinical research', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' health science research support', ' human rights', ' information systems']",NCRR,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",S07,2002,1,0.023646876892956976
"Human Subject Research Enhancements Program We propose to enhance the data consistency and integrity of oversight and tracking systems for human subjects research at Mayo Foundation. Our specific aims include: 1) a comprehensive information modeling exercise to understand the interrelationships and dependencies of administrative and clinical data elements related to human subjects research oversight; 2) building common application components that will simplify the creation of research protocols, IRB application, research subject enrollment and consent, and administrative tracking; 3) providing full text and natural language processing based indices to project abstracts, applications, minutes, and administrative notes, to facilitate the authorized searching and retrieval of materials human subject related to human subject review; and 4) coordinating the information model, modular software tools, and textual indexing, as preliminary work for a competitive informatics proposal for adverse event recognition, pattern detection, and the consistent recording of drugs, devices and outcomes measures. n/a",Human Subject Research Enhancements Program,6591449,S07RR018225,"['abstracting', ' behavioral /social science research tag', ' clinical research', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' health science research support', ' human rights', ' information systems']",NCRR,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",S07,2002,183410,0.023646876892956976
"Human Subject Research Enhancements Program We propose to enhance the data consistency and integrity of oversight and tracking systems for human subjects research at Mayo Foundation. Our specific aims include: 1) a comprehensive information modeling exercise to understand the interrelationships and dependencies of administrative and clinical data elements related to human subjects research oversight; 2) building common application components that will simplify the creation of research protocols, IRB application, research subject enrollment and consent, and administrative tracking; 3) providing full text and natural language processing based indices to project abstracts, applications, minutes, and administrative notes, to facilitate the authorized searching and retrieval of materials human subject related to human subject review; and 4) coordinating the information model, modular software tools, and textual indexing, as preliminary work for a competitive informatics proposal for adverse event recognition, pattern detection, and the consistent recording of drugs, devices and outcomes measures. n/a",Human Subject Research Enhancements Program,6591449,S07RR018225,"['abstracting', ' behavioral /social science research tag', ' clinical research', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' health science research support', ' human rights', ' information systems']",NCRR,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",S07,2002,8329,0.023646876892956976
"Human Subject Research Enhancements Program We propose to enhance the data consistency and integrity of oversight and tracking systems for human subjects research at Mayo Foundation. Our specific aims include: 1) a comprehensive information modeling exercise to understand the interrelationships and dependencies of administrative and clinical data elements related to human subjects research oversight; 2) building common application components that will simplify the creation of research protocols, IRB application, research subject enrollment and consent, and administrative tracking; 3) providing full text and natural language processing based indices to project abstracts, applications, minutes, and administrative notes, to facilitate the authorized searching and retrieval of materials human subject related to human subject review; and 4) coordinating the information model, modular software tools, and textual indexing, as preliminary work for a competitive informatics proposal for adverse event recognition, pattern detection, and the consistent recording of drugs, devices and outcomes measures. n/a",Human Subject Research Enhancements Program,6591449,S07RR018225,"['abstracting', ' behavioral /social science research tag', ' clinical research', ' computer system design /evaluation', ' data collection methodology /evaluation', ' data management', ' health science research support', ' human rights', ' information systems']",NCRR,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",S07,2002,58260,0.023646876892956976
"Preserving Privacy in Medical Data Sets Privacy is a fundamental right and needs to be protected.  For health care related d information, there are regulations for disclosure.  These regulations were motivated by the public's concern of breaches of confidentiality that might result in discrimination.  The recent progress in electronic medical record technology, the Internet, and the genetic revolution, together with media reports on violations of privacy have generated increasing interest in this topic.  A common belief is that sensitive information is more easily available with the use of networked computers. Since total lack of disclosure is not realistic, current regulations require that the ""minimal amount"" of information be given to a certain party.  A thorough study on what constitutes ""minimal"" for particular types of applications and a ""usefulness index"" is lacking.  An exact quantification of the potential for privacy breach in de-identified or anonymized databases is also lacking.  Definition and quantification of these indices is important for decision-making.  As we demonstrate, de-identified data sets can still be used for inference and therefore may disclose sensitive information.  The use of machine learning methods to verify the remaining functional dependencies in a de- identified data set leads to better understanding of the possible inferences.  Anonymization techniques based on logic, statistics, database theory, and machine learning methods can help in the protection of privacy. We will formally define and study anonymity in databases, from a theoretical and a practical standpoint.  We will develop and implement algorithms to anonymize data sets that will be in accordance with the balance of anonymity and ""usefulness"" of the disclosed data sets.  We will also develop and implement algorithms to verify the anonymity of a given data set and indicate the type of records that are at highest risk for a privacy attack.  We will make our methods and documented tools freely available to researchers via the WWW. n/a",Preserving Privacy in Medical Data Sets,6421732,R01LM007273,"['Internet', ' behavioral /social science research tag', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data management', ' decision making', ' health care facility information system', ' health care policy', ' human data', ' human rights', ' information dissemination', ' information retrieval', ' mathematical model', ' medical records', ' model design /development', ' patient oriented research', ' statistics /biometry']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2002,384388,0.002743328434305304
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6539200,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2002,152849,0.025224018002619326
"Language and Learning DESCRIPTION (provided by investigator): The aim of the dissertation is to shed light on the question of what linguistic knowledge available to children language learners is innate, as opposed to being gleaned postnatally from the environment, and to do it by answering a more basic question: what, if it were innate, would assist language learning, and what would not? The method involves implementing a formal model for learning a basic but quite versatile kind of grammar for natural language syntax using methods borrowed from statistical machine learning, along with theoretical methods from theories of syntax and semantics in linguistics. Experiments using existing grammars as benchmarks will be carried out computing measures of performance commonly accepted by computational linguists to assess the accuracy of competing grammars. Initially the testing will be done on small fragments of the grammar of English, but with a view to eventual scaling up so that the system can be trained on large sets of data deriving from actual natural language use in conversational contexts. n/a",Language and Learning,6450183,F31HD041927,"['behavioral /social science research tag', ' behavioral genetics', ' child psychology', ' computational neuroscience', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' gene environment interaction', ' health science research support', ' language', ' learning', ' mathematical model', ' model design /development', ' predoctoral investigator', ' psychological models', ' semantics', ' statistics /biometry', ' syntax']",NICHD,UNIVERSITY OF CALIFORNIA SANTA CRUZ,F31,2002,26141,0.005331885036151065
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6528412,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2002,325555,-0.014669715195660349
"DISCOVERING AND APPLYING KNOWLEDGE IN CLINICAL DATABASES A real-time clinical repository contains a wealth of detailed information useful for clinical care, research, and administration.  In their raw form, however, the data are difficult to use there is too much volume, too much detail, missing values, and inaccuracies. Clinicians, researchers, and administrators require higher level interpretations that address their questions. For example, a clinician may need to know whether a patient is at sufficient risk for having active tuberculosis to warrant respiratory isolation. The answer to the question may be spread around the clinical repository in chest radiographs, laboratory tests, medication histories, vital signs, and physician's notes. Translating from these raw data to the interpretation (at risk or not) is a difficult and laborious task. The hypothesis of this proposal is that data mining techniques can be applied to a real-time clinical repository to discover knowledge and generate accurate clinical interpretations, and that these interpretations can be automated. The project differs from earlier machine learning studies in its emphasis on a real clinical repository and the use of natural language processing to supply coded clinical data. The specific aims are: (l) Select clinical domains--Several clinical domains with interesting, non-trivial clinical problems will be selected. Problems for which a gold standard answer can or has been assembled for a retrospective cohort will be chosen. (2) Prepare raw clinical data for mining--The raw data from a clinical repository will be transformed into a structure that facilitates data mining. The data will be flattened, pivoted, summarized, and mapped as needed for the domains. Narrative data will be coded using the MedLEE natural language processor. The preparation process will be automated. (3) Use data mining algorithms to discover knowledge- Several data mining algorithms will be applied to the selected clinical domains. Algorithms will include decision tree generation, rule discovery, neural networks, nearest neighbor, logistic regression, and composite algorithms (for variable reduction). The algorithms will be trained on a training set for each domain, and their predictive accuracy will be measured and compared to each other and to expert-written rules. The performance of human experts writing rules using manual data mining visualization techniques (which does not require an explicit training set) will also be measured. (4) Study the dependence of data mining on the training set--The performance of data mining algorithms depends on the data used the train them. The sensitivity of the algorithms to noise (inaccurate data), missing data, and training set size will be measured. (5) Use the discovered knowledge to generate real-time interpretations-- The output of the algorithms (decision tree, rules, neural network equation, or logistic regression equation, but not nearest neighbor) along with the necessary data preparation steps will be encoded in Arden Syntax Medical Logic Modules. They will be run against the clinical repository to verify that the interpretation can be automated in real time. (6) Disseminate the methods and results--The methods and results will be disseminated via publications and a Web site, and tools will be made available.  n/a",DISCOVERING AND APPLYING KNOWLEDGE IN CLINICAL DATABASES,6391286,R01LM006910,"['Internet', ' artificial intelligence', ' clinical research', ' computer assisted medical decision making', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' health care facility information system', ' human data', ' information dissemination', ' information system analysis', ' vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2001,396315,0.004516515218287874
"UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE   DESCRIPTION (adapted from the Abstract):                                             With the explosion of medical information accessible via the Internet, there         is a growing need for development of better access to the online medical             literature databases through user-friendly systems and interface.  The               proliferation of online information and the diversity of interfaces to data          collections has led to a medical information gap between medical researchers         and the accessibility of medical literature databases.  Users who need access        to such information must visit a variety of sources, which can be both               excessively time consuming and potentially dangerous if the information is           needed for treatment decisions.  In addition, information generated by using         existing search engines is often too general or inaccurate.  Particularly            frustrating is that simple queries can result in an excessive number of              documents retrieved - too many to search through to determine which are and          which are not relevant.                                                                                                                                                   The goal of this research is to extend a bridge across the medical information       gap by creating easy-to-use interfaces to medical literature databases based         on UMLS-enhanced Semantic Parsing and Personalized Medical Agent (PMA):                                                                                                   (1)  UMLS-enhanced Semantic Parsing: Our first goal will be to combine noun          phrasing and co-occurrence analysis techniques recently developed by The             University of Arizona Artificial Intelligence Lab (AI Lab) for the NSF-funded        Illinois Digital Library Initiative (DLI) project with existing components           found in the Unified Medical Language System (UMLS) developed by NLM.                                                                                                     (2)  Personalized Medical Agent: The second goal will be to develop a dynamic,       intelligent medical agent interface to assist searchers in effortlessly              locating documents and summarizing topics in the documents.  The interface is        particularly suited for busy physicians.                                                                                                                                  n/a",UMLS ENHANCED DYNAMIC AGENTS TO MANAGE MEDICAL KNOWLEDGE,6258188,R01LM006919,"['abstracting', ' artificial intelligence', ' cancer information system', ' computer system design /evaluation', ' human data', ' information retrieval', ' information system analysis', ' literature citation', ' semantics', ' vocabulary development for information system']",NLM,UNIVERSITY OF ARIZONA,R01,2001,140274,0.010211461611554909
"Mining Complex Clinical Data for Patient Safety Research Medical errors hurt patients, cost money, and undermine the health care system. The first step to reducing errors is detecting them, for what cannot be detected cannot be managed. A number of approaches have been applied to medical error detection, including mandatory event reporting, voluntary near-miss reporting, chart review, and automated surveillance using information systems. Automated surveillance promises large-scale detection, minimal labor, and, potentially, detection in real time to prevent or recover from errors. Unfortunately, large amounts of important clinical information lie locked in narrative reports, unavailable to automated decision support systems. A number of tools have emerged from medical informatics and computer science- natural language processing, visualization tools, and machine learning- as well as methods for understanding cognitive processes. We hypothesize that the electronic medical record contains information useful for detecting errors and that natural language processing and other tools will allow us to retrieve the information. We will assemble a team skilled in natural language processing, data mining, terminology, patient safety research, and health care. We will use a clinical repository with ten years of data on two million patients. It includes administrative, laboratory, and pharmacy coded information as well as a wide range of narrative reports including discharge summaries, operative reports, outpatient notes, autopsy reports, resident signout notes, nursing notes, and reports from numerous ancillary services (radiology, pathology, etc.). We will apply a proven natural language processor called MedLEE to code the information and measure the accuracy of automated queries to detect and characterize errors. We will target several areas: explicit error reporting in the medical record, NYPORTS mandatory event reporting, clinical conflicts in record, and other sources of error information. We will use a systems approach to errors and cognitive analysis to uncover cues to improve error detection. We will incorporate the system into the hospital's current event surveillance program and assess the impact on error detection. We will adhere to strict privacy policies and security procedures. This project represents a unique opportunity to apply the most advanced medical language processing system to a large, comprehensive clinical repository to advance patient safety research.  n/a",Mining Complex Clinical Data for Patient Safety Research,6448720,R18HS011806,"['automated medical record system', ' clinical research', ' computer data analysis', ' diagnosis quality /standard', ' health service demonstration project', ' human data', ' iatrogenic disease', ' patient care', ' patient safety /medical error']",AHRQ,COLUMBIA UNIVERSITY HEALTH SCIENCES,R18,2001,356099,0.05345535578166235
"Referential Contrast Effects in Language Processing   DESCRIPTION (provided by applicant): A great deal of work in sentence                processing over the years has dealt with the question of whether contextual          information can guide language processing. There is by now considerable              evidence that suggests that some kinds of information from the discourse             context have immediate effects. However, the question of how these effects           occur has remained largely ignored. The studies in this proposal focus on the        discourse properties of modified definite noun phrases. Work in sentence             processing has shown that the resolution of ambiguities in which one of the          possible readings involves noun modification is affected by the availability of      a discourse model in which the modificational phrase serves to distinguish           between two possible referents. A central question is whether such discourse         effects found with modifiers reflect a general, conventionalized property of         modification, or whether they are more aptly characterized as a more subtle          system based on expectations regarding typical usages. A series of studies is        proposed to investigate the hypothesis that a typical default expression exists      for neutral (i.e., non-contrastive) contexts, and that the use of a more             informative expression signals a contrastive function in the discourse, with         immediate processing consequences. Data will come from elicited production           tasks, on-line comprehension experiments which monitor subjects' eye movements       to a visual array in response to spoken linguistic stimuli, traditional reading      time studies, and prosodic analyses in a read-aloud task. The current proposal       represents a significant departure from existing work in two salient ways:           First, it attempts to provide a detailed investigation into the nature of the        referential effects, using a methodology that is especially well-suited for          studying referential aspects of language. Second, whereas previous findings          have been couched almost exclusively in terms of the mechanisms of sentence          processing, the current proposal seeks to integrate experiments from on-line         language processing and language production. Results of this project may be          useful in developing models for language disorders, for the development of           pedagogical tools, and for progress in artificial intelligence.                                                                                                           n/a",Referential Contrast Effects in Language Processing,6399830,R01MH062566,"['clinical research', ' computer data analysis', ' data collection methodology /evaluation', ' eye movements', ' human subject', ' language', ' language development', ' neural information processing', ' phonology', ' reading', ' speech', ' syntax', ' visual stimulus', ' visual tracking']",NIMH,BROWN UNIVERSITY,R01,2001,145788,0.025224018002619326
"Dynamic Language Modeling for Transcription Systems The high cost of data entry is a critical issue that has challenged the evolution of computerized patient record systems. Development of dynamic language models is proposed for significantly improving the cost performance of medical transcription systems. The innovative use of speech recognition, computer telephony integration, and the Internet is proposed for the management and transcription of physician dictation. Results of Phase I research demonstrate significant cost savings to healthcare organizations. Our goal in Phase II is to apply multiple dynamic language models to both improve accuracy and the robustness of the system. We propose to create a physician specific mapping of historical transcriptions to their spoken counterparts. We then propose to explore different methodologies for building language models for specific physician work-type combinations using a database of processed historical transcriptions based on dictations from over 1,500 physicians. In addition, the output of the recognition system will be processed by a natural language processing engine to transform it into a formatted, styled draft transcription for review and editing by a transcriptionist. Our unique approach integrates seamlessly into a physician's workflow and does not require the alteration of physician work patterns. We expect this research and development will result in a commercially viable transcription system that significantly reduces costs associated with medical transcription. eScription has obtained three paying pilot customers with whom we are working closely with to develop this system. These customers have/will provide eScription with textual data, audio data, and medical transcriptionists who will test the final system. All have expressed a keen interest in becoming corporate partners for Phase III. Two are currently using our prototype system in their production environments today. We are submitting this grant request to partially cover the cost of constructing and testing the system. PROPOSED COMMERCIAL APPLICATIONS: eScription focuses on alleviating significant healthcare cost pressures associated with transcription of medical dictation. We apply new technologies such as speech recognition, computer telephony and Internet communications, which are not commonly used for medical transcription. We will directly sell our software products and services to Integrated Delivery Networks (IDNs) and to Transcription Services Companies.  n/a",Dynamic Language Modeling for Transcription Systems,6404288,R44LM006930,"['computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' language', ' medical records', ' speech recognition', ' telemedicine', ' vocabulary development for information system']",NLM,"ESCRIPTION, INC.",R44,2001,673495,-0.014669715195660349
"DISCOVERING AND APPLYING KNOWLEDGE IN CLINICAL DATABASES A real-time clinical repository contains a wealth of detailed information useful for clinical care, research, and administration.  In their raw form, however, the data are difficult to use there is too much volume, too much detail, missing values, and inaccuracies. Clinicians, researchers, and administrators require higher level interpretations that address their questions. For example, a clinician may need to know whether a patient is at sufficient risk for having active tuberculosis to warrant respiratory isolation. The answer to the question may be spread around the clinical repository in chest radiographs, laboratory tests, medication histories, vital signs, and physician's notes. Translating from these raw data to the interpretation (at risk or not) is a difficult and laborious task. The hypothesis of this proposal is that data mining techniques can be applied to a real-time clinical repository to discover knowledge and generate accurate clinical interpretations, and that these interpretations can be automated. The project differs from earlier machine learning studies in its emphasis on a real clinical repository and the use of natural language processing to supply coded clinical data. The specific aims are: (l) Select clinical domains--Several clinical domains with interesting, non-trivial clinical problems will be selected. Problems for which a gold standard answer can or has been assembled for a retrospective cohort will be chosen. (2) Prepare raw clinical data for mining--The raw data from a clinical repository will be transformed into a structure that facilitates data mining. The data will be flattened, pivoted, summarized, and mapped as needed for the domains. Narrative data will be coded using the MedLEE natural language processor. The preparation process will be automated. (3) Use data mining algorithms to discover knowledge- Several data mining algorithms will be applied to the selected clinical domains. Algorithms will include decision tree generation, rule discovery, neural networks, nearest neighbor, logistic regression, and composite algorithms (for variable reduction). The algorithms will be trained on a training set for each domain, and their predictive accuracy will be measured and compared to each other and to expert-written rules. The performance of human experts writing rules using manual data mining visualization techniques (which does not require an explicit training set) will also be measured. (4) Study the dependence of data mining on the training set--The performance of data mining algorithms depends on the data used the train them. The sensitivity of the algorithms to noise (inaccurate data), missing data, and training set size will be measured. (5) Use the discovered knowledge to generate real-time interpretations-- The output of the algorithms (decision tree, rules, neural network equation, or logistic regression equation, but not nearest neighbor) along with the necessary data preparation steps will be encoded in Arden Syntax Medical Logic Modules. They will be run against the clinical repository to verify that the interpretation can be automated in real time. (6) Disseminate the methods and results--The methods and results will be disseminated via publications and a Web site, and tools will be made available.  n/a",DISCOVERING AND APPLYING KNOWLEDGE IN CLINICAL DATABASES,6031325,R01LM006910,"['Internet', ' artificial intelligence', ' clinical research', ' computer assisted medical decision making', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' health care facility information system', ' human data', ' information dissemination', ' information system analysis', ' vocabulary development for information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2000,433383,0.004516515218287874
"IMIA WG6 CONFERENCE The basic science of representing patient events, findings, interventions, and outcomes in a semantically consistent and logically reproducible way is medical concept representation.  It embodies principles of linguistics, logic, computer science, cognition, biology and clinical medicine to undertake this highly multidisciplinary activity. Much of this work is undertaken in experimental settings, which hypothesize practical extensions to existing models, and test their utility against standardized retrieval sets or clinical usability environments. The proposed conference intends to continue the tradition of the International Medical Informatics Association (IMIA), Working Group 6 on Medical Concept Representation, to provide a forum for the academic discussion of problems, issues, theories, and applications of natural language processing, knowledge representation, terminology development, and concept coordination to biomedicine and healthcare.  the proposed tracks at this time are: 1. Natural Language Processing  2. Clinical Classifications 3. Cognitive Evaluations  4. Terminology Models  5. Maintenance and Uptake Strategies.  n/a",IMIA WG6 CONFERENCE,6027283,R13LM006899,"['informatics', ' international health /scientific organization', ' meeting /conference /symposium', ' travel']",NLM,MAYO CLINIC ROCHESTER,R13,2000,20000,0.041835039959645236
"Natural Language Processing and Machine Learning for Cancer Surveillance The purpose of this call order is to provide support in the area of quality control and improvement of cancer data, specifically for Clinical Document Annotation and Processing Pipeline (CDAP), LabKey Software, and the development of annotation schema. n/a",Natural Language Processing and Machine Learning for Cancer Surveillance,10281318,6116004B91020F00002,"['Area', 'Automated Annotation', 'Clinical', 'Data', 'Machine Learning', 'Malignant Neoplasms', 'Natural Language Processing', 'Quality Control', 'software development']",NCI,"WESTAT, INC.",N02,2020,149865,-0.001739678390987983
"Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods Project Summary The problem of prescription medication (PM) abuse has reached epidemic proportions in the United States. According to a 2014 report by the Director of the National Institute on Drug Abuse (NIDA), an estimated 52 million people, have been involved in the non-medical use of PMs— a significant portion of which can be classified as abuse. PMs that are commonly abused include opioids, central nervous system depressants and stimulants, and the consequences of their abuse may be severe. Increases in PM misuse and abuse over the last 15 years have resulted in increased emergency department visits, rates of addiction and overdose deaths. Due to the rapidly escalating morbidity and mortality, it is now receiving national attention. The opioid crisis, which has its root in opioid-based PM abuse, has been declared a national emergency by the president of the United States. Despite the problems associated with PM abuse, surveillance programs such as prescription drug monitoring programs (PDMPs) are inadequate and suffer from numerous shortcomings, thus limiting their usefulness in real life. Studies evaluating the long-term effects of distinct classes of PMs on cohorts of abusers are scarce and expensive to conduct. To better characterize the problem and to monitor it in real-time, new sources of information need to be identified and novel monitoring techniques need to be developed. To address these problems, our project aims to utilize social media data for performing toxicovigilance. Social media encapsulates an abundance of knowledge about PM abuse and the abusers in the form of noisy natural language text. At the heart of the proposed approach is a machine learning system that can automatically distinguish between `abuse' and `non-abuse' indicating user posts collected from social media. Using this classification system, users will be categorized into multiple groups—(i) abusers, (ii) medical users and (iii) non users. The developed system will collect longitudinal data for users exposed the selected PMs via periodic collection of their publicly available posts/discussions and automatically categorize them based on age, gender and additional demographic feature, when possible. This will enable the conducting of observational studies on targeted cohorts, involving hundreds of thousands of cohort members. The cohort studies will focus on analyzing the transition rates from medical use to abuse for distinct PMs and transition rates from abuse of PMs to illicit analogs. Implementation of this data-centric framework, which will be open source, will revolutionize the mechanism by which PM abuse monitoring is performed and enable the future development of intervention strategies targeted towards specific cohorts, at the most effective time periods. Narrative Prescription Medication (PM) abuse is a major epidemic in the United States, and monitoring and studying the characteristics of the PM abuse problem requires the development of novel approaches. Social media encapsulates an abundance of data about PM abuse from different demographics, but extracting that data and converting it to knowledge requires advanced natural language processing and data-centric artificial intelligence systems. Our proposed social media mining framework will automate the process of big data to knowledge conversion for PM abuse, providing crucial insights to toxicologists about targeted populations and enabling the future development of directed intervention strategies.",Mining Social Media Big Data for Toxicovigilance: Automating the Monitoring of Prescription Medication Abuse via Natural Language Processing and Machine Learning Methods,9933852,R01DA046619,"['Adderall', 'Address', 'Affect', 'Age', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Behavior Therapy', 'Benzodiazepines', 'Big Data', 'Big Data to Knowledge', 'Categories', 'Central Nervous System Depressants', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Cohort Studies', 'Collection', 'Communities', 'Control Groups', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Drug abuse', 'Emergency Situation', 'Emergency department visit', 'Encapsulated', 'Epidemic', 'Event', 'Expert Systems', 'Exposure to', 'Fentanyl', 'Forensic Medicine', 'Future', 'Gender', 'Geographic Locations', 'Goals', 'Guidelines', 'Health', 'Health Professional', 'Heart', 'Heroin', 'Hospitalization', 'Individual', 'Infrastructure', 'Ingestion', 'Intervention', 'Investigation', 'Knowledge', 'Life', 'Long-Term Effects', 'Machine Learning', 'Manuals', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'National Institute of Drug Abuse', 'Natural History', 'Natural Language Processing', 'Observational Study', 'Occupations', 'Opioid', 'Outcome', 'Overdose', 'Oxycodone', 'Patient Self-Report', 'Pattern', 'Percocet', 'Periodicity', 'Pharmaceutical Preparations', 'Pilot Projects', 'Plant Roots', 'Population', 'Population Characteristics', 'Process', 'Public Health', 'Reporting', 'Research', 'Schools', 'Social Impacts', 'Source', 'Supervision', 'Surveillance Program', 'Surveys', 'System', 'Target Populations', 'Techniques', 'Text', 'Time', 'TimeLine', 'Training', 'Twitter', 'United States', 'Variant', 'Vicodin', 'Work', 'addiction', 'adverse outcome', 'age group', 'analog', 'base', 'cohort', 'deep neural network', 'demographics', 'design', 'drug misuse', 'experimental group', 'innovation', 'insight', 'interest', 'intervention program', 'large datasets', 'machine learning method', 'member', 'misuse of prescription only drugs', 'mortality', 'natural language', 'nonmedical use', 'novel', 'novel strategies', 'open source', 'opioid epidemic', 'overdose death', 'prescription drug abuse', 'prescription monitoring program', 'quetiapine', 'social media', 'social observations', 'spelling', 'study characteristics', 'supervised learning', 'therapy development']",NIDA,EMORY UNIVERSITY,R01,2020,332269,0.013406538095068744
"Identifying False HPV-Vaccine Information and Modeling Its Impact on Risk Perceptions PROJECT SUMMARY/ABSTRACT Human papillomavirus (HPV) is the most common sexually transmitted infection in the United States, with over 30,000 new HPV-related-cancers are diagnosed annually. Although HPV vaccines have been approved by the Food and Drug Administration (FDA) since 2006 and recommended for routine vaccination for school-age girls and boys, vaccination rates remain low. One reason that has contributed to low vaccination rates is incorrect “risk perceptions” around HPV vaccines such as the high perceived risks of adverse events or side effects from the HPV vaccine. Incorrect risk perceptions are often rooted in the false information about HPV vaccines that people are exposed to in their daily life, including social media. The impact of social media on health information is substantial. Negative social-media HPV-vaccine information has been found to have an association with low vaccination coverage. Given the negative consequences of false information, there is a need to develop a robust and scalable way to detect false HPV-vaccine information before it propagates and negatively impacts behavior. The overarching goal of the proposed research is to build a model to identify false HPV-vaccine information on Twitter, demonstrate its impact on individual risk perceptions and measure its underlying mechanisms on risk perception formation. We propose a novel approach to leverage machine learning, natural language processing, network analysis, crowdsourcing/expert data annotation, psycholinguistic analysis and statistical modeling to investigate the false HPV-vaccine information collectively (in terms of its detection and propagation patterns) and individually (in terms of its impact and underlying cognitive mechanisms). Our study will first build a computational model to detect false HPV-vaccine information on Twitter. By modeling the domain-specific HPV- vaccine related text content, information-veracity related linguistic features, individual and collective user behaviors, and dissemination patterns, our model will be able to detect false HPV-vaccine information before it gets verified and spreads widely. We will then investigate the impact of false HPV-vaccine information on risk perceptions around HPV vaccination operationalized by natural language processing methods and a developed HPV-vaccine Risk Lexicon. We will further conduct psycholinguistic analysis on the false HPV-vaccine information and use statistical modeling to uncover the underlying mechanism of risk perceptions. Our study will make a critical and timely contribution to identifying the false HPV-vaccine information and its impact, which has the potential to be applied to other health topics. This proposed project will also address the National Cancer Institute priorities in promoting HPV vaccines and combating misinformation in cancer prevention and control. PROJECT NARRATIVE The uptake of human papillomavirus (HPV) vaccine remains low in part because of incorrect perceptions of vaccination risks, which has been linked to the spread of false HPV-vaccine information. The proposed study seeks to build a computational model to detect false HPV-vaccine information on social media (Twitter) and determine its impact on risk perceptions of the HPV vaccine. The findings will provide important contributions to understand the impact of false health information on HPV vaccination behavior and could be expanded to other health topics.",Identifying False HPV-Vaccine Information and Modeling Its Impact on Risk Perceptions,9954963,R21CA237483,"['Address', 'Affect', 'Age', 'Anxiety', 'Attitude', 'Behavior', 'Cancer Control', 'Categories', 'Cognitive', 'Communication', 'Comprehension', 'Computer Models', 'Data', 'Decision Making', 'Detection', 'Diagnosis', 'Electronic cigarette', 'Event', 'Exposure to', 'Fright', 'Goals', 'Harm Reduction', 'Health', 'Human Papilloma Virus Vaccination', 'Human Papilloma Virus Vaccine', 'Human Papilloma Virus-Related Malignant Neoplasm', 'Human Papillomavirus', 'Human papilloma virus infection', 'Individual', 'Information Dissemination', 'Knowledge', 'Lesion', 'Life', 'Linguistics', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methods', 'Misinformation', 'Modeling', 'National Cancer Institute', 'Natural Language Processing', 'Neural Network Simulation', 'Participant', 'Pathway Analysis', 'Patients', 'Pattern', 'Perception', 'Plant Roots', 'Politics', 'Property', 'Psycholinguistics', 'Psychological reinforcement', 'Research', 'Risk', 'Safety', 'School-Age Population', 'Semantics', 'Sexually Transmitted Diseases', 'Source', 'Statistical Models', 'Text', 'Time', 'Twitter', 'United States', 'United States Food and Drug Administration', 'Vaccination', 'Vaccines', 'Work', 'adverse event risk', 'boys', 'cancer diagnosis', 'cancer prevention', 'combat', 'crowdsourcing', 'deep learning', 'girls', 'high risk', 'information model', 'information processing', 'multilevel analysis', 'news', 'novel strategies', 'premalignant', 'prevent', 'recurrent neural network', 'response', 'risk perception', 'side effect', 'social media', 'theories', 'uptake']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,211659,0.010221972372592241
"Leveraging Twitter to Monitor Nicotine and Tobacco Cancer Communication Patterns in Twitter data have revolutionized understanding of public health events such as influenza outbreaks. While researchers have begun to examine messaging related to substance use on Twitter, this project will strengthen the use of Twitter as an infoveillance tool to more rigorously examine nicotine, tobacco, and cancer- related communication. Twitter is particularly suited to this work because its users are commonly adolescents, young adults, and racial and ethnic minorities, all of whom are at increased risk for nicotine and tobacco product (NTP) use and related health consequences. Additionally, due to the openness of the platform, searches are replicable and transparent, enabling large-scale systematic research. Therefore, our multidisciplinary team of experts in diverse relevant fields—including public health, behavioral science, computational linguistics, computer science, biomedical informatics, and information privacy and security—will build upon our previous research to develop and validate structured algorithms providing automated surveillance of Twitter’s multifaceted and continuously evolving information related to NTPs. First, we will qualitatively assess a stratified random sample of relevant NTP-related tweets for specific coded variables, such as the message’s primary sentiment and other key information of potential value (e.g., whether a message involves buying/selling, policy/law, and cancer-related communication). Tweets will be obtained directly from Twitter using software we developed that leverages a comprehensive list of Twitter-optimized search strings related to NTPs. Second, we will statistically determine what message characteristics (e.g., the presence of certain words, punctuation, and/or structures) are most strongly associated with each of the coded variables for each search string. Using this information, we will create specialized Machine Learning (ML) algorithms based on state-of-the-art methods from Natural Language Processing (NLP) to automatically assess and categorize future Twitter data. Third, we will use this information to provide automatic assessment of current and future streaming data. Time series analyses using seasonal Auto-Regressive Integrated Moving Averages (ARIMA) will determine if there are significant changes over time in volume of messaging related to each specific coded variables of interest. Trends will be examined at the daily, weekly, and monthly level, because each of these levels is potentially valuable for intervention. To maximize the translational value of this project, we will partner with public health department stakeholders who are experts in streamlining dissemination of actionable trends data. In summary, this project will substantially advance our understanding of representations of NTPs on social media—as well as our ability to conduct automated surveillance and analysis of this content. This project will result in important and concrete deliverables, including open-source algorithms for future researchers and processes to quickly disseminate actionable data for tailoring community- level interventions. For this project, we gathered a team of public health researchers and computer scientists to leverage the power of Twitter as a novel surveillance tool to better understand communication about nicotine and tobacco products (NTPs) and related messages about cancer and cancer prevention. We will gather a random sample of Twitter messages (“tweets”) related to NTPs and examine them in depth and use this information to create specialized computer algorithms that can automatically categorize future Twitter data. Then, we will examine changes over time related to attitudes towards and interest in NTPs, as well as cancer-related discussion around various NTPs, which will dramatically improve our ability to better understand Twitter as a tool for this type of surveillance.",Leveraging Twitter to Monitor Nicotine and Tobacco Cancer Communication,10111658,R01CA225773,"['Adolescent', 'Affect', 'Alcohol or Other Drugs use', 'Algorithms', 'Attitude', 'Behavioral', 'Behavioral Sciences', 'Cancer Control', 'Categories', 'Characteristics', 'Cigarette', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computational Linguistics', 'Computational algorithm', 'Computer software', 'Computers', 'County', 'Data', 'Disease Outbreaks', 'Electronic cigarette', 'Epidemiologic Methods', 'Event', 'Food', 'Football game', 'Future', 'Gold', 'Health', 'Health Care Costs', 'Individual', 'Influenza A Virus, H1N1 Subtype', 'Intervention', 'Laws', 'Linguistics', 'Literature', 'Malignant Neoplasms', 'Marketing', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Nicotine', 'Outcome', 'Pattern', 'Policies', 'Privacy', 'Process', 'Public Health', 'Public Opinion', 'Research', 'Research Personnel', 'Resources', 'Retrieval', 'Risk', 'Sampling', 'Scientist', 'Security', 'Specificity', 'Structure', 'Techniques', 'Testing', 'Time', 'Time Series Analysis', 'Tobacco', 'Tobacco use', 'Twitter', 'Work', 'automated analysis', 'base', 'biomedical informatics', 'cancer prevention', 'computer program', 'computer science', 'computerized tools', 'data standards', 'data streams', 'ethnic minority population', 'geographic difference', 'hookah', 'improved', 'influenza outbreak', 'interest', 'machine learning algorithm', 'mortality', 'multidisciplinary', 'nicotine use', 'novel', 'open source', 'phrases', 'prospective', 'racial minority', 'social', 'social media', 'software development', 'statistics', 'time use', 'tobacco products', 'tool', 'trend', 'vaping', 'young adult']",NCI,UNIVERSITY OF ARKANSAS AT FAYETTEVILLE,R01,2020,491992,-0.004793283006831146
"Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App PROJECT SUMMARY Background: Depression during pregnancy and the postpartum period affects up to 15% of US mothers, imposing costs on mother, child, and society. Early detection can significantly reduce the incidence of depression, yet depressive symptoms are often missed during prenatal visits, which tend to focus on maternal and fetal physical health, leaving less time for maternal mental health. Even if mental health is addressed during prenatal care, women may not feel comfortable answering questions that are perceived to be embarrassing or invasive. Failing to detect depression is even more likely during the postpartum period due to infrequent physician visits once the baby has been born. Measurement in the form of daily journals, which can be analyzed using natural language processing, can promote early and more frequent detection of depression during pregnancy and the postpartum period. Study Aims: 1) Model which dynamic features of language used over time best predict changes in depression status in the pregnancy and postpartum periods, creating phenotypes of depression risk; 2) examine how the language patterns that predict depression differ for African-American and Caucasian women; and 3) identify the relationship between the characteristics of what depressed peripartum women say and their treatment-seeking behavior. Innovation: The proposed research is innovative in its use of high frequency natural language measurements, captured in daily journals using a smartphone app, combined with advances in natural language processing models, to assess the onset and trajectory of depression during pregnancy and the postpartum period. This is the first prospective longitudinal study using natural language collection for risk prediction in a clinical population and the first to: 1) characterize the critical topics women discuss during the peripartum period over time using open-ended journals; 2) evaluate multiple facets of language to gain a more comprehensive understanding of the relationship between language and depression; 3) use a longitudinal design approach allowing for optimal modeling of language changes associated with depression onset. Methodology and Expected Results: Monthly depression risk identified from the Edinburgh Postnatal Depression Scale. will be collected through the MyHealthyPregnancy smartphone app, a mobile health application developed through close collaboration between decision scientists, clinicians, statisticians, and local peripartum women. A daily journal embedded in the MyHealthyPregnancy app will collect natural language text from the participants for 10 months (from their first prenatal visit through two months postpartum). Using three distinct natural language processing algorithmic approaches, this study will characterize how the natural language used by peripartum women in their daily journal entries is connected to the onset and experience of peripartum depression, as measured through monthly-administered depression scales. Group- based trajectory modeling will then classify women according to the patterns in their depression scores over time. Potential Impact: This work lays the foundation for developing and evaluating real-time interventions that could be deployed at scale to women who are using language that signals high depression risk. PROJECT NARRATIVE This research will examine how the topics (the people and events mentioned), sentiment (the positive, negative, and neutral affect), and other aspects of language expressed in daily journal entries correspond to diagnostic measures of depression and treatment-seeking in a peripartum clinical population. Psychometric and daily journal entry data will be gathered through an existing smartphone app, MyHealthyPregnancy, which monitors risk and delivers actionable information as part of routine prenatal care provided to the pregnant members of a large regional healthcare system.",Identification and Prediction of Peripartum Depression from Natural Language Collected in a Mobile Health App,9892136,R21MH119450,"['Address', 'Affect', 'African American', 'Algorithms', 'Appointment', 'Behavior', 'Behavioral Sciences', 'Birth', 'Caring', 'Caucasians', 'Characteristics', 'Child', 'Childbirth', 'Clinical', 'Collaborations', 'Collection', 'Data', 'Data Collection', 'Depressed mood', 'Detection', 'Developmental Delay Disorders', 'Diagnostic', 'Disclosure', 'Early Diagnosis', 'Early treatment', 'Emotions', 'Environment', 'Event', 'Failure to Thrive', 'Feeling', 'Foundations', 'Frequencies', 'Healthcare Systems', 'Incidence', 'Infant', 'Intervention', 'Journals', 'Language', 'Longitudinal observational study', 'Longitudinal prospective study', 'Measurable', 'Measurement', 'Measures', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Mobile Health Application', 'Modeling', 'Monitor', 'Moods', 'Mothers', 'National Institute of Mental Health', 'Natural Language Processing', 'Participant', 'Patients', 'Pattern', 'Perinatal', 'Phenotype', 'Physicians', 'Population', 'Postpartum Depression', 'Postpartum Period', 'Pregnancy', 'Pregnant Women', 'Premature Birth', 'Prenatal care', 'Psychometrics', 'Race', 'Reporting', 'Research', 'Risk', 'Risk Assessment', 'Scientist', 'Signal Transduction', 'Societies', 'Source', 'Stress', 'Technology', 'Text', 'Time', 'Variant', 'Visit', 'Voice', 'Well in self', 'Woman', 'Work', 'antepartum depression', 'base', 'cohort', 'cost', 'depression model', 'depressive symptoms', 'experience', 'fetal', 'health assessment', 'improved', 'innovation', 'longitudinal design', 'machine learning algorithm', 'member', 'motherhood', 'natural language', 'patient subsets', 'peripartum depression', 'physical conditioning', 'pregnant', 'racial disparity', 'response', 'routine screening', 'smartphone Application', 'social culture', 'sociodemographics', 'statistical and machine learning', 'time use', 'vector']",NIMH,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,233832,-0.008657918555084894
"Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit SUMMARY  Many of the estimated four million adults in the U.S. with severe speech and physical impairments (SSPI) resulting from neurodevelopmental or neurodegenerative diseases cannot rely on current assistive technologies (AT) for communication. During a single day, or as their disease progresses, they may transition from one access technology to another due to fatigue, medications, changing physical status, or progressive motor dysfunction. There are currently no clinical or AT solutions that adapt to the multiple, dynamic access needs of these individuals, leaving many people poorly served. This competitive renewal, called BCI-FIT (Brain Computer Interface-Functional Implementation Toolkit) adds to our innovative multidisciplinary translational research conducted over the past 11 years for the advancement of science related to non-invasive BCIs for communication for these clinical populations. BCI-FIT relies on active inference and transfer learning to customize a completely adaptive intent estimation classifier to each user's multiple modality signals in real-time. The BCI-FIT acronym has many implications: our BCI fits to each user's brain signals; to the environment, offering relevant personal language; to the user's internal states, adjusting signals based on drowsiness, medications, physical and cognitive abilities; and to users' learning patterns from BCI introduction to expert use.  Three specific aims are proposed: (1) Develop and evaluate methods for optimizing system and user performance with on-line, robust adaptation of multi-modal signal models. (2) Develop and evaluate methods for efficient user intent inference through active querying. (3) Integrate language interaction and letter/word supplementation as input modalities in real-time BCI use. Four single case experimental research designs will evaluate both user performance and technology performance for functional communication with 35 participants with SSPI in the community, and 30 healthy controls for preliminary testing. The same dependent variables will be tested in all experiments: typing accuracy (correct character selections divided by total character selections), information transfer rate (ITR), typing speed (correct characters/minute), and user experience (UX) questionnaire responses about comfort, workload, and satisfaction. Our goal is to establish individualized recommendations for each user based on a combination of clinical and machine expertise. The clinical expertise plus user feedback added to active sensor fusion and reinforcement learning for intent inference will produce optimized multi-modal BCIs for each end-user that can adjust to short- and long-term fluctuating function. Our research is conducted by four sub-teams who have collaborated successfully to implement translational science: Electrical/computer engineering; Neurophysiology and systems science; Natural language processing; and Clinical rehabilitation. The project is grounded in solid machine learning approaches with models of participatory action research and AAC participation. This project will improve technologies and BCI technical capabilities, demonstrate BCI implementation paradigms and clinical guidelines for people with severe disabilities. PROJECT NARRATIVE The populations of US citizens with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies, as proposed in BCI-FIT. This project implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit,10044301,R01DC009834,"['Adult', 'Attention', 'Behavioral', 'Brain', 'Calibration', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communication', 'Communities', 'Computers', 'Custom', 'Data', 'Decision Making', 'Disease', 'Drowsiness', 'Electroencephalography', 'Engineering', 'Environment', 'Eye Movements', 'Fatigue', 'Feedback', 'Goals', 'Guidelines', 'Head Movements', 'Impairment', 'Individual', 'Informed Consent', 'Knowledge', 'Language', 'Learning', 'Letters', 'Life', 'Locked-In Syndrome', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Motor Skills', 'Movement', 'Muscle', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Participant', 'Partner Communications', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Population', 'Protocols documentation', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Questionnaires', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Design', 'Role', 'Science', 'Secondary to', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Solid', 'Source', 'Speech', 'Speed', 'Supplementation', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vocabulary', 'Workload', 'acronyms', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinical implementation', 'cognitive ability', 'community based participatory research', 'computer science', 'disability', 'experience', 'experimental study', 'improved', 'innovation', 'learning strategy', 'motor disorder', 'multidisciplinary', 'multimodality', 'neurophysiology', 'phrases', 'residence', 'response', 'satisfaction', 'sensor', 'signal processing', 'simulation', 'spelling', 'theories', 'visual tracking']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2020,929399,-0.0141831050221877
"SBIR Phase I- Topic 410 - Cancer Clinical Trials Recruitment and Retention Tools for Participant Engagement.  Many clinical trials fail to meet their accrual and retention goals, which leads to delays, early termination, or inability to draw conclusions at trial completion due to loss of statistical power. NCI wants to enhance clinical trials recruitment and retention by developing tools that could enhance communication between participants and study staff. In this Phase 1 tool development application we address the NCI interest in simplified informed consent documents that enhance personal communication during the informed consent process. In this Phase I proposal we leverage natural language processing technology and our teams prior work on the Informed Consent Ontology (ICO) to improve the language in consent documents related specifically to permissions granted by a research participant. n/a",SBIR Phase I- Topic 410 - Cancer Clinical Trials Recruitment and Retention Tools for Participant Engagement. ,10265762,5N91020C00017,"['Address', 'Authorization documentation', 'Clinical Trials', 'Communication', 'Comprehension', 'Consent Forms', 'Goals', 'Grant', 'Health', 'Informed Consent', 'Language', 'Natural Language Processing', 'Ontology', 'Participant', 'Personal Communication', 'Phase', 'Process', 'Research', 'Small Business Innovation Research Grant', 'Technology', 'Work', 'base', 'cancer clinical trial', 'improved', 'interest', 'prototype', 'recruit', 'tool', 'tool development', 'user-friendly']",NCI,"MELAX TECHNOLOGIES, INC.",N43,2020,400000,0.020943920498334063
"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",Evidence Extraction Systems for the Molecular Interaction Literature,9983144,R01LM012592,"['Area', 'Binding', 'Biochemical', 'Bioinformatics', 'Biological Assay', 'Burn injury', 'Classification', 'Co-Immunoprecipitations', 'Code', 'Communities', 'Complex', 'Consult', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Database Management Systems', 'Databases', 'Detection', 'Disease', 'Engineering', 'European', 'Event', 'Experimental Designs', 'Experimental Models', 'Gel', 'Goals', 'Grain', 'Graph', 'Image', 'Informatics', 'Information Retrieval', 'Institutes', 'Intelligence', 'Knowledge', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Weight', 'Names', 'Natural Language Processing', 'Paper', 'Pattern', 'Positioning Attribute', 'Privatization', 'Process', 'Protein Structure Initiative', 'Proteins', 'Protocols documentation', 'Publications', 'Reading', 'Records', 'Reporting', 'Research', 'Scientist', 'Source Code', 'Specific qualifier value', 'Structural Models', 'Structure', 'Surface', 'System', 'Systems Biology', 'Taxonomy', 'Text', 'Time', 'Training', 'Typology', 'Western Blotting', 'Work', 'base', 'data modeling', 'experimental study', 'human disease', 'image processing', 'machine learning method', 'open source', 'optical character recognition', 'protein protein interaction', 'repository', 'software systems', 'structured data', 'text searching', 'tool']",NLM,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,264232,-0.00586639813089011
"Development of Tools for Evaluating the National Toxicology Program's Effectiveness  NIEHS funds research grants and conducts research to evaluate agents of public health concern. NIEHS has need for research and development tools for use in its research evaluations both the Division of the National Toxicology Program (DNTP) and the Division of Extramural Research and Training (DERT). These tools will enable NTP to evaluate its effectiveness across multiple stakeholder groups to determine use and ability to affect change for public health. Additionally, NTP has interests in using natural language processing for tools that can assist with information extraction from scientific publications ultimately for use in assessing potential hazards. DERT has need for categorical evaluation of its grants portfolio by extracting information and organizing them relative to outcomes and impacts. The Department of Energy’s Oak Ridge National Laboratory (ORNL) has research experience in analysis of textual information and has developed a unique publication mining capability that enable automated evaluation of scientific publications. NIEHS wants to take advantage of these ORNL capabilities for use in its research evaluations. n/a",Development of Tools for Evaluating the National Toxicology Program's Effectiveness ,10237828,ES16002001,"['Affect', 'Area', 'Bibliometrics', 'Categories', 'Computer software', 'Department of Energy', 'Effectiveness', 'Evaluation', 'Evaluation Research', 'Extramural Activities', 'Funding', 'Grant', 'Information Retrieval', 'Internet', 'Laboratories', 'Methods', 'Mining', 'National Institute of Environmental Health Sciences', 'National Toxicology Program', 'Natural Language Processing', 'Outcome', 'Program Effectiveness', 'Public Health', 'Publications', 'Research', 'Research Project Grants', 'Research Training', 'Retrieval', 'Scientific Evaluation', 'Techniques', 'Visual', 'experience', 'hazard', 'interest', 'research and development', 'tool', 'tool development']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,Y01,2020,500000,0.007505726625587486
"Improving Cardiovascular Drug Safety With Automated Bleeding Classification PROJECT SUMMARY Atrial fibrillation (AF) treatment often includes drug therapy with oral anticoagulants (OAC) to prevent stroke. Bleeding, however, is a common complication of these drugs, affecting up to one in four patients. The Center for Medicare and Medicaid Services recently prioritized OAC-related drug safety as a key quality measure. Currently, however, no method exists to accurately identify bleeding events and severity in large populations. Prior methods use diagnoses codes, which lack sensitivity and clinical detail, or manual chart review, which cannot be implemented in large populations. The proposed research aims address this knowledge gap by applying a natural language processing (NLP)-based approach to identify bleeding events and classify severity in a real-world AF population. The tools will be validated in patients treated at a different institution, to ensure reproducibility across provider settings. In addition, we will apply the bleeding classification tool to evaluate the association between bleeding severity and mortality. Dr. Shah is an emerging young investigator whose career development plan is focused on acquiring the biomedical informatics skills to needed to accurately identify and reduce patient harm. Her training plan focuses on learning core competencies in natural language processing, with the goal of turning the wealth of data in the electronic medical record into useable knowledge. She will combine mentorship from established experts and targeted coursework to acquire skills in biomedical informatics, data science, advanced analytic methods, and research leadership. Completion of these research and training aims will create a platform for future R01 proposals by: (i) enabling safety focused comparative effectiveness research in AF (ii) setting the stage to identify bleeding complications in other cardiovascular diseases and (iii) developing a skill set that allows leadership of a multidisciplinary research team. Through this career development plan, Dr. Shah will build upon her prior training in clinical cardiology and research methodology and lay a strong foundation for a high impact research career. PUBLIC HEALTH RELEVANCE Atrial fibrillation affects six million US adults, and the prevalence is expected to double by 2030. As new drug and device treatments for stroke prevention emerge, patients and providers increasingly need accurate methods to monitor and improve patient safety.",Improving Cardiovascular Drug Safety With Automated Bleeding Classification,9899862,K08HL136850,"['Accounting', 'Address', 'Adult', 'Adverse event', 'Affect', 'Age', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Biomedical Research', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Code', 'Comparative Effectiveness Research', 'Competence', 'Complication', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Science', 'Development Plans', 'Devices', 'Diagnosis', 'Ensure', 'Event', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Hemorrhage', 'Incidence', 'Institution', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Letters', 'Link', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Oral', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Provider', 'Quality of life', 'Race', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Research Training', 'Risk', 'Safety', 'Severities', 'Site', 'Standardization', 'Stroke', 'Stroke prevention', 'System', 'Techniques', 'Testing', 'Text', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Vital Status', 'acute coronary syndrome', 'advanced analytics', 'aging population', 'analytical method', 'base', 'biomedical informatics', 'career', 'career development', 'clinically relevant', 'cohort', 'improved', 'interdisciplinary approach', 'medication compliance', 'medication safety', 'mortality', 'neglect', 'novel', 'novel therapeutics', 'patient safety', 'personalized medicine', 'portability', 'public health relevance', 'screening', 'sex', 'skills', 'stroke risk', 'stroke therapy', 'tool']",NHLBI,UNIVERSITY OF UTAH,K08,2020,163080,0.004358534786618019
"Multicenter Study of the Emergency Department Trigger Tool Existing methods for surveillance of patient harm in the ED setting are inadequate, without any meaningful change in decades. Trigger tools, popularized by the Institute for Healthcare Improvement’s Global Trigger Tool, have been developed for multiple clinical areas and are used across the world, outperform traditional approaches for surveillance of adverse events. These tools use a two-tiered review process where a nurse screens records for triggers (predefined findings that make the presence of an AE more likely) and reviews records with triggers for AEs, discarding those without triggers. We developed a consensus-based ED trigger tool (EDTT) using a multicenter, transdisciplinary modified Delphi approach, subsequently pilot testing this in a multicenter fashion with encouraging results. This was followed by a recently completed, AHRQ-funded single center study to automate, refine and validate this tool. This study demonstrated that the EDTT is a high-yield and efficient instrument for identifying adverse events in the ED. The present study will evaluate the refined, automated EDTT), in a multicenter study. We will evaluate the EDTT’s generalizability and robustness at three sites with large emergency departments, with a planned in-depth review of 9,000 ED admissions. We will use natural language processing of electronic medical record narratives and machine learning to improve the EDTT efficiency in trigger detection and AE discovery. We will establish the basis for a wider use and prepare for scalability and usability of the tool, creating standardized, streamlined and free online training materials, and by evaluating the tool in a real-world manner consistent with intended use. Project Narrative Commonly used approaches in Emergency Departments to detect adverse events are low yield and have not changed in decades, providing inadequate surveillance for patient harm. The need for improved methodology is critical, given the evolving role of the emergency department in the health care system. Trigger tools, developed for use in many healthcare settings across the world, detect all-cause harm, helping direct resources by identifying areas of risk and allowing an assessment of the effectiveness of quality improvement efforts over time. Trigger tools involve screening of records by a nurse for triggers (findings that make an adverse event more likely) and a review of only records with triggers searching for adverse events. Any events identified undergo confirmatory physician review. We developed a trigger tool for the ED, applying rigorous methods to identify predictive triggers, to computerize the screen for triggers eliminating manual review and improving record selection to enhance yield and efficiency. This tool demonstrates superior performance for detecting adverse events. We will now test this tool in a multicenter project to evaluate its broad application, confirming its utility and to continue to improve its yield and efficiency in adverse event detection by applying natural language processing and machine learning techniques.",Multicenter Study of the Emergency Department Trigger Tool,10098792,R01HS027811,[' '],AHRQ,WASHINGTON UNIVERSITY,R01,2020,398528,0.007496605517267393
"Identifying the neural structures and dynamics that regulate phonological structure The systematic patterning of language is a fundamental property of cognition. One aspect of this patterning, constraints on the combination of speech sounds to form words (phonotactic structure), has been implicated in constraining diverse processes related to language acquisition, perception, and production, bilingual language use, memory and even influences non-linguistic processes including the memorability of novel words and consumer reaction to novel brand names. This patterning changes in a variety of common acquired and developmental communication disorders. We will explore two explanations for these effects. One, developed in linguistic theory, argues that language users discover a set of abstract, language-specific rules or constraints that shape language use. The other view, developed in connectionist and dynamic systems theory, argues that phonotactic constraints emerge from top-down lexical influences on speech perception. Discriminating between these approaches is difficult because both explain behavioral data well. It is essential to discriminate between these accounts for two reasons. This question offers an excellent opportunity to resolve the debate over whether abstract linguistic rules/constraints create or simply describe the patterning of language. The resolution of this question has fundamental implications for the way linguistic formalism and connectionist simulations relate to human processing. At a more immediate level, this research offers the opportunity to identify a common core mechanism (either the leveraged use of abstract linguistic rules or top-down lexical influences) that explains and unites diverse linguistic and cognitive phenomena. Past efforts to resolve these issues have failed because of fundamental inferential limitations of behavioral and BOLD imaging paradigms. Accordingly, we have developed new tools and research strategies that allow us to identify patterns of directed interaction between brain regions (effective connectivity), and use these analyses to draw much stronger inferences about the dynamic processes that shape cognition. Observers in the field have argued that our methods have already provided “definitive” evidence to resolve the decades old debate over the role of top- down processes in speech processing. This proposal would extend those methods, and introduce innovative neural decoding analyses that we will use to characterize the categories (e.g. rules, words, abstract phonological representations needed to support rule application) that are encoded in localized brain activity. Using these methods, we will determine whether top-down lexical processes that we have shown produce phonotactic phenomena related to the processing of patterns that occur in speaker's language generalize to unfamiliar patterns. We will also use them to identify the substrates of rule- versus word-mediated processing, to provide a baseline for interpreted the representations and dynamic processes that support phonotactic effects in natural language processing. The human ability to learn and use language is the result of a complex set of dynamic brain processes that can break down as the result of disease, injury or developmental disorders. This work uses new non-invasive techniques to observe and understand some of the most fundamental brain processes that shape language learning and use so that we may better understand how they break down. This understanding should one day guide the development of better ways to treat diverse language disorders.",Identifying the neural structures and dynamics that regulate phonological structure,9894782,R01DC015455,"['Address', 'Affect', 'Algebra', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Common Core', 'Communication impairment', 'Competence', 'Complex', 'Data', 'Development', 'Developmental Communication Disorders', 'Disease', 'Evaluation', 'Frequencies', 'Goals', 'Heart', 'Human', 'Image', 'Imaging Techniques', 'Injury', 'Intuition', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Language Development', 'Language Disorders', 'Learning', 'Linguistics', 'Mediating', 'Mediation', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Neighborhoods', 'Pathology', 'Pattern', 'Perception', 'Performance', 'Process', 'Production', 'Property', 'Reaction', 'Research', 'Resolution', 'Role', 'Shapes', 'Speech', 'Speech Perception', 'Speech Sound', 'Structure', 'Structure of supramarginal gyrus', 'Systems Theory', 'Techniques', 'Testing', 'Work', 'bilingualism', 'developmental disease', 'dynamic system', 'experience', 'innovation', 'lexical', 'lexical processing', 'models and simulation', 'novel', 'phonology', 'relating to nervous system', 'simulation', 'sound', 'spatiotemporal', 'speech processing', 'theories', 'tool', 'word learning']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,517151,-0.0235616654882302
"Collaborative Research: Statistical algorithms for anomaly detection and patterns recognition in patient care and safety event reports Medical errors have been shown to be the third leading cause of death in the United States. The Institute of Medicine and several state legislatures have recommended the use of patient safety event reporting systems (PSRS) to better understand and improve safety hazards. Numerous healthcare providers have adopted these systems, which provide a framework for healthcare provlder staff to report patient safety events. Public databases like MAUDE and VAERS have also been created to collect and trend safety events across healthcare systems. A patient safety event (PSE) report generally consists of both structured and unstructured data elements. Structured data are pre-defined, fixed fields that solicit specific information about the event. The unstructured data fields generally include a free text field where the reporter can enter a text description of the event. The text descriptions are often a rich data source in that the reporter ls not constrained to limited categories or selection options and is able to freely descrlbe the details of the event. The goal of this project is to develop novel statistical methods to analyze unstructured text like patient safety event reports arising in healthcare, which can lead to significant improvements to patient safety and enable timely intervention strategies. We address three problems: (a) Building realistic and meaningful baseline models for near misses, and detecting systematic deterioration of adverse outcomes relative to such baselines; (b) Understanding critical factors that lead to near misses & quantifying severity of outcomes; and (c) ldentifylng document groups of interest. We will use novel statistical approaches that combine Natural Language Processing with Statistical Process Monitoring, Statistical Networks Analysis, and Spatio-temporal Modeling to build a generalizable toolbox that can address these issues in healthcare. An important advantage of our research team is the involvement of healthcare domain experts and access to frontline staff, and we will leverage this strength to develop our algorithms. A key feature of our work is the generalizability of our methods, which will be applicable to biomedical documents arising across a remarkable variety of areas, such as patient safety and equipment malfunction reports, electronic health records, adverse drug or vaccine reports, etc. We will also release open source software via R packages & GitHub, which will enable healthcare staff and researchers to execute our methods on their datasets. Estimates of preventable adverse events in healthcare are staggering, despite the frequently cited Institute of Medicine (IOM) report that first brought attention to the problem over ten years ago. Identifying temporal trends and patterns in the data is particularly important to improving patient safety and patient care. Using our algorithms to effectively analyze documents from reporting systems has the potential to dramatically improve the safety and quality of care by exposing possible weaknesses in the care process.",Collaborative Research: Statistical algorithms for anomaly detection and patterns recognition in patient care and safety event reports,10211805,R01LM013309,"['Address', 'Adopted', 'Adverse event', 'Algorithms', 'Area', 'Attention', 'Caring', 'Categories', 'Cause of Death', 'Computer software', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Deterioration', 'Electronic Health Record', 'Equipment Malfunction', 'Event', 'Goals', 'Health Personnel', 'Healthcare', 'Healthcare Systems', 'Institute of Medicine (U.S.)', 'Interest Group', 'Intervention', 'Lead', 'Medical Errors', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pharmaceutical Preparations', 'Process', 'Quality of Care', 'Report (document)', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Safety', 'Severities', 'Statistical Algorithm', 'Statistical Computing', 'Statistical Methods', 'System', 'Text', 'Time', 'Time trend', 'United States', 'Vaccines', 'Work', 'adverse outcome', 'hazard', 'improved', 'novel', 'open source', 'patient safety', 'spatiotemporal', 'structured data', 'trend', 'unstructured data']",NLM,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R01,2020,278731,0.01405276839005004
"Automated Data Collection on Antimicrobial Use in Dogs and Cats in a Tertiary Hospital and Private Practices Judicious antimicrobial use in veterinary medicine is important because improper antimicrobial use can contribute to the evolution of antimicrobial resistance in bacterial pathogens, which makes subsequent use of these drugs less effective in both human and veterinary medicine. There is very little on-the-ground information about veterinary clinicians’ antimicrobial use (AMU) practices in companion animal practice in the US. veterinary medicine. To improve our understanding of antimicrobial use in dogs and cats, we propose to create a nationwide digital surveillance system to collect critical AMU data using existing electronic practice information management systems (PIMS) in collaboration with veterinary industry partners. The system will automatically harvest AMU and patient data from digital PIMS. The proposed system will harvest data collected in routine veterinary examinations from existing PIMS systems and therefore will not require any additional effort from practitioners to participate in the program. Natural language processing, a machine learning method used to classify unstructured text, will be used to review electronic medical records to determine patients’ diagnosis. We aim to prototype the system in our native digital PIMS at North Carolina State University’s College of Veterinary Medicine Teaching hospital. We will then enroll additional private veterinary practices, including general practice, specialty hospitals, and emergency clinics, as sentinels and collect the same detailed PIMS data from a more representative set of clinics. Working closely with the sentinel clinics will provide a deep understanding of how our system operates in private clinics, and in the final stage we aim to expand the fully automated system to PIMS nationwide. The combination of sentinel clinics with the nationwide survey of clinics will create a powerful broad and deep surveillance system for antimicrobial use in veterinary clinics. A broad suite of AMU parameters will be estimated from this data, and the results reported to the FDA in an annual report. Additionally, we will share the data with other researchers through an web-based portal and GitHub repositories. This system will provide the critical data and analysis to understand veterinary AMU in the US. NARRATIVE Veterinarians play a central role in protecting animal and human health by preserving the efficacy of the antibiotics that their use for their patients. We have created a partnership among a public university, private veterinary hospitals, and a leading industry partner to collect information on how antibiotics are being used in cat and dog practices across the country with no disruption to the participating hospitals. The data will support FDA’s commitment to promoting antimicrobial stewardship.",Automated Data Collection on Antimicrobial Use in Dogs and Cats in a Tertiary Hospital and Private Practices,10166402,U01FD007057,[' '],FDA,NORTH CAROLINA STATE UNIVERSITY RALEIGH,U01,2020,199999,-0.0002498522650846786
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status –While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,9854882,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Database Management Systems', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Information Retrieval', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Serious Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data warehouse', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'risk prediction model', 'structured data', 'unstructured data', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2020,766226,0.0317248466253714
"Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria Project Summary/Abstract Fungal and bacterial pathogens are a major threat to human health. Few therapeutics exist to treat fungal infections while bacteria are becoming increasingly resistant to existing therapeutics. Humans have been using natural products to treat infections for thousands of years, long before the causal agents of infection were understood. Natural products have continued to be used as therapeutics in the modern age of medicine. Rates of rediscovery of known natural products have increased in traditional sources of natural products, such as soil bacteria. Recently, symbiotic Actinobacteria from insect agricultural systems have been recognized as a promising source of bioactive compounds, especially antifungal agents. These bacteria often produce natural products that defend an insect’s fungal crop from pathogenic fungus. The work proposed here will use chemical biology approaches such as phenotypic interaction screens, genomics, and a new bioinformatics approach to systematically search for bioactive natural products produced by Actinobacteria symbionts and other organisms in insect agricultural systems. The first part of this proposal focuses on using existing techniques to identify new bioactive natural products. Phenotypic interaction screens can identify bioactive natural products by determining if a symbiotic bacteria produces a natural product that inhibits the growth of a fungal pathogen and vice-versa. We will then use genomic sequencing, bioinformatics, and heterologous expression to identify and characterize biosynthetic gene clusters (BGCs) that are not expressed in the phenotypic interaction screens. The second part of the proposed work involves the use of a new bioinformatics technique to identify interesting bioactive natural products. Existing bioinformatics techniques identify BGCs and predict the most likely chemical structure of the corresponding natural product. However, they do not conclude anything concerning the functional role that the natural product plays. The technique developed here will use machine learning to predict the function that the natural product fulfills in the ecological context of the organism. This algorithm will facilitate the identification of bioactive natural products with therapeutically relevant functions. Project Narrative Fungal infections are an underappreciated threat to human health with high mortality rates and few effective therapeutic agents for treatment. Symbiotic Actinobacteria from insect agricultural systems are a promising source of antifungal agents since they often produce natural products with antifungal activity protecting an insect’s fungal crop from pathogenic fungus. The work proposed here will use phenotypic interaction screens, genome sequencing, and the development of a novel bioinformatics method to systematically mine Actinobacteria for antifungal and antibacterial products – leading to the discovery of new bioactive small molecules along with a deeper understanding of how natural products mediate the interaction between species in insect agricultural systems.",Bioinformatics and Chemical Biology Approaches for Identifying Bioactive Natural Products of Symbiotic Actinobacteria,9963295,F32GM128267,"['Actinobacteria class', 'Age', 'Agriculture', 'Algorithms', 'Anti-Bacterial Agents', 'Antibiotics', 'Antifungal Agents', 'Ants', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bioinformatics', 'Biological Assay', 'Biology', 'Breathing', 'Chemical Structure', 'Chemicals', 'Collaborations', 'Computational Biology', 'Computing Methodologies', 'Data Set', 'Development', 'Ecosystem', 'Gene Cluster', 'Genome', 'Genomics', 'Growth', 'Health', 'Human', 'Infection', 'Insecta', 'Learning', 'Life', 'Literature', 'Machine Learning', 'Mediating', 'Medicine', 'Methods', 'Mining', 'Modernization', 'Molecular Structure', 'Mycoses', 'Natural Products', 'Organism', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Public Health', 'Resistance', 'Role', 'Soil', 'Source', 'Structure', 'System', 'Techniques', 'Therapeutic', 'Therapeutic Agents', 'Time', 'Training', 'Treatment Efficacy', 'Validation', 'Work', 'algorithm development', 'base', 'bioactive natural products', 'drug discovery', 'fungus', 'genetic information', 'genome sequencing', 'human disease', 'machine learning algorithm', 'mortality', 'novel', 'pathogen', 'pathogenic bacteria', 'pathogenic fungus', 'post-doctoral training', 'prediction algorithm', 'small molecule', 'symbiont']",NIGMS,HARVARD MEDICAL SCHOOL,F32,2020,65310,-0.001956418254996384
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,9939507,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2020,334688,-0.06517355351281684
"Transforming Patient Safety Event Data into Actionable Insights through Advanced Analytics Abstract The objective of the proposed research is to develop an innovative algorithms and a software tool to reduce the burden of safety event report classification and analysis so that report data can be transformed to actionable insights. Making safety event data more actionable will support the proactive identification of safety hazards before patients are harmed. We will achieve our research objective through (1) the development of natural language processing algorithms to classify safety event reports into actionable medication error categories; (2) the development of prototype software that will automatically categorize and visualize safety event reports to support trend identification; and (3) the pilot testing of prototype software with hospital and patient safety organization safety analysts. This project utilizes the extensive expertise of the research team in human factors and safety science, including computer science, specifically regarding information retrieval and data classification. Our research team includes patient safety organizations and collaboration with the computer science department at Georgetown University. The proposal is directly aligned with AHRQ’s priority area of making health care safer. Contributions from this research will include an expansion of our understanding of natural language processing and its application to categorizing clinical text, advances in visual analytics, and the development of a software tool to support patient safety analysts. The outputs of this research will serve both healthcare organizations and patient safety organizations allowing them to more efficiently and effectively analyze safety report data. Project Narrative This project is relevant to public health because it applies human factors and computer science to develop software to improve the analysis of patient safety event report data to reduce safety hazards and prevent patient harm. Patient safety event report data will be analyzed using natural language processing algorithms to more efficiently classify events into error categories. Based on these algorithms, prototype software will be developed, tested, and disseminated with the goal of automatic categorization and visualization of safety event reports to identify important safety hazards.",Transforming Patient Safety Event Data into Actionable Insights through Advanced Analytics,9962801,R01HS026481,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2020,398080,0.0470532188625992
"Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia Project Summary/Abstract Aphasia is an impairment of language that is a common consequence of stroke and has serious negative effects on health and well-being. Aphasia diagnosis continues to be organized around a 19th century model of the neural basis of language, but cognitive neuroscience research over the last 15-20 years has converged to a very different model of the cognitive and neural organization of spoken language. This contemporary model provides a precise computational account of the sub-systems that support spoken language, but does not explain how those sub-systems produce functional communication – the outcome that is most important to people with aphasia and to clinicians. The long-term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information. The overall objective of this application is to determine the relationships between spoken functional communication impairments of language sub-systems, and neuroanatomical disruption in chronic post-stroke aphasia. The overall project is divided into three specific aims: (1) Determine how spoken functional communication is related to deficits in language sub-systems. We will test how the three key language sub-systems – semantics, phonology, and sentence planning – are related to functional communication in a large sample of individuals with post-stroke aphasia. (2) Identify the lesion correlates of spoken functional communication deficits using lesion-symptom mapping. We will conduct the first LSM study of spoken functional communication using multimodal neuroimaging and machine learning tools to discover robust lesion correlates of spoken functional communication. (3) Develop a prediction model of chronic language sub-system and functional communication deficits based on acute lesion data. Routine clinical neuroimaging data collected in the acute stage (48-72 hours after stroke) will be used to build and evaluate a prediction model of chronic deficits in language sub- systems and functional communication. Upon completion of this project, we will have determined how behavioral deficits and lesion patterns are related to functional communication deficits, and developed a prediction model of such deficits based on acute-stage clinical neuroimaging. This integration of psycholinguistics, neuroanatomy, and functional communication will provide theory-informed, clinically-relevant predictions of communication deficits. This project addresses NIDCD Strategic Priority Area 3 (Improving Diagnosis, Treatment, and Prevention) by developing a neural biomarker of objective diagnosis and prognosis for acquired language impairments. Project Narrative This project will integrate investigate how the cognitive and neural sub-systems that support spoken language work together to allow speakers with language deficits to convey their message. The studies apply machine learning tools to behavioral assessments, neuroimaging, and measures of functional communication in order to reveal how they are related. The long- term goal of this project is to develop theory-informed, clinically-relevant prognostic tools that combine behavioral and neuroimaging information.",Cognitive and Neural Basis of Functional Communication Deficits in Post-Stroke Aphasia,9997876,R01DC017137,"['Acute', 'Address', 'Age', 'Aphasia', 'Area', 'Behavior assessment', 'Behavioral', 'Biological Markers', 'Caring', 'Chronic', 'Clinical', 'Cognitive', 'Communication', 'Communication impairment', 'Communications Media', 'Data', 'Diagnosis', 'Financial compensation', 'Gestures', 'Goals', 'Health', 'Hour', 'Impairment', 'Individual', 'Intuition', 'Language', 'Language Disorders', 'Lesion', 'Machine Learning', 'Measures', 'Modality', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Neuroanatomy', 'Neurosciences Research', 'Outcome', 'Pattern', 'Personal Satisfaction', 'Predictive Factor', 'Prevention', 'Psycholinguistics', 'Quality of life', 'Recovery', 'Recovery of Function', 'Sampling', 'Science', 'Semantics', 'Severities', 'Social Interaction', 'Speech', 'Stroke', 'Structure', 'Support System', 'Symptoms', 'System', 'Testing', 'Work', 'acute stroke', 'aphasia recovery', 'base', 'clinically relevant', 'cognitive neuroscience', 'cost', 'improved', 'language impairment', 'multimodality', 'negative affect', 'neural model', 'neuroimaging', 'outcome forecast', 'personalized medicine', 'phonology', 'post stroke', 'predictive modeling', 'prognostic tool', 'relating to nervous system', 'stroke survivor', 'stroke-induced aphasia', 'theories', 'tool']",NIDCD,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2020,283332,-0.04074289427439861
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9944489,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2020,39939,-0.01379878569711056
"Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign Project Summary/Abstract Written The objective of the proposed research is to reduce the patient safety hazards associated with electronic medication administration records (eMARs) by, (1) understanding current usability and safety gaps, and (2) creating design and development documents, wireframes, and prototypes to serve as the foundation for future eMARs that will eliminate these gaps. In particular, we focus on communication and information flow challenges between nurses, pharmacists, and physicians during medication administration and use of the eMAR. The proposed research is in direct response to special emphasis notice (NOT-HS-16-009). We will develop a broad understanding of usability and safety hazards associated with eMARs by analyzing a large dataset of 1.7 million patient safety event reports and detailed medication error related narratives. We will then conduct heuristic analyses of current eMARs, and interviews and observations of physicians, nurses, and pharmacists. These data will serve to inform the development of eMAR design documents, wireframes, and prototypes as the foundation for future development. This project utilizes the extensive expertise of the research team in human factors and safety science, health information technology (health IT), informatics, and data science. Our research team includes physicians, nurses, pharmacists, and human factors engineers, and experts in natural language processing. In addition, our partnerships include a patient safety organization and a health IT vendor. The proposal addresses fundamental aspects of the call for proposals by providing new insights on the safety of health IT and improves current practices by developing use cases and new prototypes for immediate use by healthIT vendors. Contributions from this research will include a fundamental understanding of the role of health IT during medication administration with a focus on communication and information flow, design, development and testing documents for vendors and providers, and eMAR wireframes and prototypes to improve development. Our research will also provide organizations like the Office of the National Coordinator with medication related test scenarios to assess current health IT systems. Project Narrative This project is relevant to public health because it applies the sciences of human factors and informatics to improve the usability and safety of the electronic medication administration records (eMARs), which will ultimately improve patient care. Patient safety event report data will be analyzed to identify usability and safety hazards in eMARs, and interviews and observations will be conducted to identify clinician needs. Based on this knowledge eMAR design documents, wireframes, and prototypes will be developed, tested, and disseminated with the goal of improving communication and information flow to reduce medication related errors.",Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign,9912124,R01HS025136,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2020,398492,0.0406343353391531
