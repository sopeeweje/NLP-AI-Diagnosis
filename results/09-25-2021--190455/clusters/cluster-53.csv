text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9768545,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,383874,0.05033605041530459
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9794757,R01LM012817,"['Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Comorbidity', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,337238,0.03330308183350187
"Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks Project Summary In this project we develop new methods for extracting important information from electronic health records based on recurrent neural networks. These methods represent the hierarchical and sequential nature of human language, leverage large scale datasets to make learning sophisticated representations possible, and make use of novel sources of supervision that are available at this scale. The model architecture we propose is a hierarchical recurrent neural network (RNN). This architecture explicitly represents temporality at multiple different time scales, with stacked RNN layers representing words, sentences, paragraphs, and documents. At the word level, the model is trained to predict important pieces of clinical information, such as negation and temporality, using existing labeled data sets. Training for clinical information extraction at the lowest level ensures that the higher-level models have a foundation of medically relevant inputs. We are still left with the challenge of training higher-level networks, because these models require massive amounts of labeled training data to learn. We solve this problem by taking advantage of the temporal aspect of information in an EHR, and having each higher-level recurrent layer train getting supervision from the future. For example, the document RNN is trained to predict billing codes and NLP concept codes that were found in the subsequent document. This source of supervision is scalable, and our preliminary data shows that it is effective at learning how to generate generalizable patient representations. The patient representations that our model learns are shareable across multiple tasks, potentially streamlining EHR-based research by eliminating what was previously a manual step – designing text-based variables to represent patients. We demonstrate a new workflow for text-based EHR research, showing how the same representations can be used for two completely distinct phenotyping tasks. These phenotyping studies make use of high-quality datasets of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital. PH is relatively rare, so finding every patient with a phenotyping algorithm is important for clinical research. ASD has several sub-phenotypes, and finding large numbers of patients from each sub- phenotype can help to better understand the mechanisms of ASD. Along with demonstrating the applicability of our representations on these specific clinical research use cases, we incorporate our patient representations into the i2b2 clinical research software, making them available to all clinical investigators using this platform at Boston Children’s Hospital. Project Narrative This project develops methods for extracting universal patient representations from unstructured text in electronic health records. These methods leverage huge amounts of clinical data, recurrent neural network architectures, and novel training techniques to incorporate information at multiple time scales. These methods are evaluated using public datasets to promote reproducibility, and applied to clinical research tasks that extend the knowledge of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital.",Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks,9642922,R01LM012973,"['Algorithms', 'Architecture', 'Boston', 'Brain', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Comorbidity', 'Computer software', 'Data', 'Data Set', 'Electronic Health Record', 'Ensure', 'Event', 'Face', 'Felis catus', 'Foundations', 'Future', 'Healthcare Systems', 'Human', 'Human Characteristics', 'Human Resources', 'Intensive Care Units', 'Israel', 'Knowledge', 'Label', 'Language', 'Learning', 'Left', 'Linguistics', 'Location', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phenotype', 'Problem Solving', 'Process', 'Pulmonary Hypertension', 'Rare Diseases', 'Records', 'Recurrence', 'Reproducibility', 'Research', 'Research Personnel', 'Source', 'Statistical Methods', 'Supervision', 'System', 'Text', 'Time', 'Training', 'Training Technics', 'Uncertainty', 'autism spectrum disorder', 'base', 'clinically relevant', 'cohort', 'data resource', 'deep neural network', 'design', 'disease phenotype', 'learning strategy', 'machine translation', 'neural network', 'neural network architecture', 'novel', 'recurrent neural network', 'relating to nervous system']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2019,386910,0.040116463554508985
"Integrative data science approaches for rare disease discovery in health records ABSTRACT: There are nearly 7,000 diseases that have a prevalence of only one in 2,000 individuals or less. Yet, such rare diseases are estimated to collectively affect over 300 million people worldwide, representing a significant healthcare concern. Although rare diseases have predominantly genetic origins, nearly half of them do not manifest symptoms until adulthood and frequently confound discovery and diagnosis. Even in the case of early onset disorders, the sheer number of possible diagnoses can often overwhelm clinicians. As a result, rare diseases are often diagnosed with delay, misdiagnosed or even remain undiagnosed, not only disrupting patient lives but also hindering progress on our understanding of such diseases. Data science methods that mine large-scale retrospective health record data for phenotypic information will aid in timely and accurate diagnoses of rare diseases, especially when combined with additional data types, thus, having significant real- world impact. This proposal will integrate electronic health record (EHR) data sets with publicly available vocabularies and ontologies, and genomic data for the improved identification and characterization of patients with rare diseases, using approaches from machine learning, natural language processing (NLP) and basic bioinformatics. The work has three specific aims and will be carried out in two phases. During the mentored phase, the principal investigator (PI) will develop data-driven methods to extract standardized concepts related to rare diseases from clinical notes and infer the occurrence of each disease (Aim 1). He will also develop data science approaches to compare and contrast longitudinal patterns associated with patients' journeys through the healthcare system when seeking a diagnosis for a rare disease, and aid in clinical decision-making by leveraging these patterns (Aim 2). During the independent phase (Aim 3), computational methods will be developed for the integrated modeling and analysis of genotypic (from Aim 3) and phenotypic information (from Aims 1 and 2). Cohorts to be sequenced will cover diseases for which causal genes or disease definitions are unclear (discovery), as well as those for which these are well known (validation). This work will be carried out under the mentorship of four faculty members with complementary expertise in biomedical informatics, data science, NLP, and rare disease genomics at the University of Washington, the largest medical system in the Pacific Northwest (four million EHRs), world-renowned researchers in medical genetics, and a robust data science environment. In addition, under the direction of the mentoring team, the PI will complete advanced coursework, receive training in translational bioinformatics and clinical research informatics, submit manuscripts, and seek an independent research position. This proposal will yield preliminary results for subsequent studies on data-driven phenotyping and enable the realization of the PI's career goals by providing him with the necessary training to build on his machine learning and basic bioinformatics expertise to transition into an independent investigator in biomedical data science. PROJECT NARRATIVE Rare genetic diseases are estimated to affect the lives of 25 to 30 million Americans and their families, and present a significant economic burden on the healthcare system. Currently, our knowledge of the broad spectrum of the 7,000 observed rare diseases is limited to a few well-studied ones, hindering our ability to make correct and timely diagnoses. The objective of this study is to improve the identification of patients with rare diseases in healthcare systems by developing data science approaches that automatically recognize rare disease-related patterns in patient health records and correlate them with genomic data, thus, aiding in diagnosis and discovery.",Integrative data science approaches for rare disease discovery in health records,9645433,K99LM012992,"['Adult', 'Affect', 'American', 'Award', 'Basic Science', 'Behavioral', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Research', 'Computing Methodologies', 'Consensus', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostics Research', 'Disease', 'Economic Burden', 'Electronic Health Record', 'Environment', 'Faculty', 'Family', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Manuscripts', 'Markov Chains', 'Medical', 'Medical Genetics', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Pacific Northwest', 'Patient Recruitments', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Principal Investigator', 'Rare Diseases', 'Recording of previous events', 'Research', 'Research Personnel', 'Standardization', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Vocabulary', 'Washington', 'Work', 'accurate diagnosis', 'base', 'biomedical informatics', 'career', 'causal variant', 'clinical data warehouse', 'clinical decision-making', 'cohort', 'diagnostic accuracy', 'disease phenotype', 'early onset disorder', 'exome sequencing', 'gene discovery', 'genomic data', 'health care delivery', 'health data', 'health record', 'improved', 'member', 'multimodal data', 'novel', 'open source', 'phenotypic data', 'prototype', 'psychologic', 'rare condition', 'rare genetic disorder', 'recruit', 'skills', 'software development', 'support tools', 'tool', 'trait']",NLM,UNIVERSITY OF WASHINGTON,K99,2019,92070,0.009773052051236188
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9774338,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2019,1521748,0.11204763808267015
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,9637480,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'Receiver Operating Characteristics', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2019,432969,0.02927535792193516
"Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data SUMMARY The modernization and standardization of clinical care information systems is creating large networks of linked electronic health records (EHR) that capture key treatments and select patient outcomes for millions of patients throughout the country. The observational data emerging from these systems provide an unparalleled opportunity to learn about the effectiveness of existing and novel treatments, and to monitor potential safety issues that may arise when interventions are used in broad patient populations. However, observational clinical data have exposures that are driven by many factors and therefore aggressive adjustment is needed to remove as much confounding bias as possible in order to make attribution regarding select exposures. The field of machine learning provides a powerful collection of data-driven approaches for performing flexible, thorough confounding adjustment, but performing reliable statistical inference is particularly challenging when these techniques are used as part of the analytic strategy. We propose to advance reproducible research methods by developing and illustrating novel targeted learning tools that leverage the flexibility of machine learning methods to detect and characterize health effect signals using large-scale EHR data. Specifically, we will first develop techniques for making efficient, statistically valid and robust inference for treatment effects using state-of-the-art machine learning tools. We will also develop online learning techniques to make such inference in the context of streaming EHR data. Methodological advances will enable us to formulate a formal, rigorous and practical framework for conducting continuous, effective and reliable surveillance for safety endpoints. Finally, we will develop statistical approaches for incorporating prior information -- including demographic, epidemiologic or pharmacodynamic knowledge, for example -- to improve health effect estimation and inference when the health outcome of interest is rare and the statistical problem is thus difficult, as often occurs in safety surveillance. The ultimate goal of the proposed research is to enable biomedical researchers and public health regulators to carefully monitor and protect the health of the public by allowing them to more effectively and more reliably detect critical health effect signals that may be contained in population-scale EHR data. PROJECT NARRATIVE The modernization and standardization of clinical care information systems is creating large networks of linked electronic medical records that capture key treatments and select patient outcomes for millions of U.S. subjects. The population scale of contemporary health care data is opening new opportunities for quickly learning from observational data, and is now supporting on-going national surveillance that will monitor the risks and benefits of both existing and novel treatment paths. The objective of this proposal is to provide an inferential framework that leverages the flexibility of machine learning methods to detect health effect signals, including in the important setting of high-dimensional confounders and/or rare events, and to develop a real-time sequential updating methodology for safety signal detection.",Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data,9816009,R01HL137808,"['Algorithms', 'Benefits and Risks', 'Characteristics', 'Clinical Data', 'Complex', 'Computer software', 'Computerized Medical Record', 'Confidence Intervals', 'Country', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Estimation Techniques', 'Event', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Heterogeneity', 'Information Systems', 'Infrastructure', 'Intervention', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modernization', 'Monitor', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacodynamics', 'Population', 'Population Surveillance', 'Procedures', 'Public Health', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Safety', 'Sentinel', 'Signal Transduction', 'Standardization', 'Statistical Methods', 'Stream', 'Structural Models', 'Subgroup', 'Surveillance Program', 'System', 'Techniques', 'Testing', 'Time', 'Treatment outcome', 'Update', 'base', 'clinical care', 'comparative treatment', 'flexibility', 'high dimensionality', 'improved', 'interest', 'learning strategy', 'national surveillance', 'novel', 'open source', 'patient population', 'patient subsets', 'risk minimization', 'software development', 'surveillance data', 'tool', 'treatment effect', 'user-friendly']",NHLBI,UNIVERSITY OF WASHINGTON,R01,2019,502815,0.026103887901016715
"Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records Project Summary/Abstract This project proposes new methods for representing data in electronic health records (EHR) to improve pre- dictive modeling and interpretation of patient outcomes. EHR data offer a promising opportunity for advancing the understanding of how clinical decisions and patient conditions interact over time to inﬂuence patient health. However, EHR data are difﬁcult to use for predictive modeling due to the various data types they contain (con- tinuous, categorical, text, etc.), their longitudinal nature, the high amount of non-random missingness for certain measurements, and other concerns. Furthermore, patient outcomes often have heterogenous causes and re- quire information to be synthesized from several clinical lab measures and patient visits. The core challenge at hand is overcoming the mismatch between data representations in the EHR and the assumptions underly- ing commonly used statistical and machine learning (ML) methods. To this end, this project proposes novel wrapper-based methods for learning informative features from EHR data. Both methods propose specialized operators to handle sequential data, time delays, and variable interactions, and have the capacity to discover underlying clinical rules/decisions that affect patient outcomes. Importantly, both methods also produce archives of possible models that represent the best trade-offs between complexity and accuracy, which assists in model interpretation. These method advances are made possible by encoding a rich set of data operations as nodes in a directed acyclic graph, and optimizing the graph structures using multi-objective optimization. The central hypothesis of this research is that multi-objective optimization can learn effective data representations from the EHR to produce accurate, explanatory models of patient outcomes. Preliminary work has shown that these methods can effectively learn low-order data representations that improve the predictive ability of several state- of-the-art ML methods. This technique demonstrates good scaling properties with high-dimensional biomedical data. Aim 1 (K99) is to develop a multi-objective feature engineering method that pairs with existing ML methods to iteratively improve their performance by constructing new features from the raw data and using feedback from the trained model to guide feature construction. In Aim 2 (K99), this method is applied to form predictive models of the risk of heart disease and heart failure using longitudinal EHR data. The resultant models will be inter- preted with the help of mentors in order to translate predictions into clinical recommendations. For Aim 3 (R00), a second method is proposed that uses a similar framework to optimize existing neural network approaches in order to simplify their structure as much as possible while maintaining accuracy. The goal of Aim 4 (R00) is to identify hospital patients who are at risk of readmission and propose point-of-care strategies to mitigate that risk. This goal is facilitated through the application of the proposed methods to patient data collected from the Hospital of the University of Pennsylvania, the Geisinger Health System, and publicly available EHR databases. Project Narrative  Understanding how clinical decisions interact with a patient's health and environmental over time to inﬂuence patient outcomes is central to the goals of enhancing health, reducing illness and improving quality of life. The proposed research provides important methodological advances for extracting these insights from widely available patient health records.",Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records,9744166,K99LM012926,"['Address', 'Affect', 'Archives', 'Area', 'Automobile Driving', 'Cardiovascular Diseases', 'Categories', 'Clinical', 'Communities', 'Complex', 'Couples', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Disease', 'Electronic Health Record', 'Engineering', 'Feedback', 'Goals', 'Graph', 'Hand', 'Health', 'Health Sciences', 'Health system', 'Heart Diseases', 'Heart failure', 'Hospitals', 'Inpatients', 'Knowledge', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical Records', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pennsylvania', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Process', 'Property', 'Protocols documentation', 'Quality of life', 'Recommendation', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Risk', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'University Hospitals', 'Visit', 'Work', 'base', 'care costs', 'cluster computing', 'data archive', 'deep learning', 'deep neural network', 'design', 'disease diagnosis', 'disorder subtype', 'health record', 'heart disease risk', 'high dimensionality', 'hospital readmission', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network', 'novel', 'open source', 'operation', 'point of care', 'predictive modeling', 'readmission rates', 'readmission risk', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,K99,2019,89260,0.045224738917660684
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,9759499,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2019,20000,0.07787767182766175
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,9759984,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2019,640832,0.08339181344218961
"Development and validation of an electronic health record prediction tool for first-episode psychosis Psychosis is a major public health challenge, with approximately 100,000 adolescents and young adults in the US experiencing a first episode of psychosis (FEP) every year. Early intervention following FEP is critical for achieving improved outcomes, yet treatment of FEP is often delayed between 1 and 3 years in the US due to delays in detection and referral. The World Health Organization has advocated shortening the duration of untreated psychosis (DUP) to three months or less. The goal of this study is to develop and validate a universal EHR-based screening tool for early detection of FEP across large clinical populations in diverse healthcare settings. In order to maximize the impact and generalizability of the tool across a wide range of healthcare settings, we will rely only on coded medical information collected in the course of care and thus widely available in EHRs. The tool will be developed and validated with data from three diverse health systems that cover over 8 million patients spanning a wide range of demographic, socioeconomic and ethnic backgrounds: Partners Healthcare System, Boston Children's Hospital, and Boston Medical Center. The study will be conducted by a closely collaborating interdisciplinary team of clinical specialists, psychosis researchers, and risk modeling experts based at these health systems and Harvard Medical School, with extensive experience in treating psychosis patients, and developing strategies for detecting FEP and EHR-based risk screening tools for early detection of various clinical conditions. Our preliminary studies show that EHR-based risk models can be used to sensitively and specifically detect FEP cases, on average 2 years before the first psychosis diagnosis appears in their EHR. Our specific aims include: 1. Define a robust cross-site case definition for FEP that relies only on information commonly available in EHRs and validate it through expert chart review; 2. Train and validate a predictive model for early detection of FEP based on large samples of patient data from the three sites; 3. Develop and validate FEP early detection models for key subpopulations, including patients receiving care at mental health clinics, adolescent medicine outpatient programs, and substance abuse treatment programs; and 4. Engage clinical stakeholders in the process of developing a prototype clinician-facing EHR-based risk screening tool for FEP, and release it as an open source SMART App, enabling further validation and clinical integration across a wide range of healthcare settings. Completion of these aims would provide a novel, clinically deployable, and potentially transformative tool for improving the trajectory of those affected with psychosis and reducing the burden and costs of untreated illness. Psychosis is a major public health challenge, with difficulties and delays in detecting its onset that can lead to worse clinical outcomes. The proposed research will develop a clinician-facing electronic-health-record-based automated screening tool for early detection of the first episode of psychosis, with implications for reducing the duration of untreated psychosis as recommended by the NIMH and World Health Organization. The tool will be validated across three large and diverse health systems and released as an open source application (SMART App), increasing its potential for rapid implementation in health systems and clinical care.",Development and validation of an electronic health record prediction tool for first-episode psychosis,9660167,R01MH116042,"['Accident and Emergency department', 'Adolescent Medicine', 'Adolescent and Young Adult', 'Advocate', 'Affect', 'Boston', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Code', 'Communities', 'Data', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Early Intervention', 'Electronic Health Record', 'General Population', 'Goals', 'Health system', 'Healthcare Systems', 'Inpatients', 'Intervention', 'Laboratories', 'Lead', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical center', 'Mental Health', 'Modeling', 'National Institute of Mental Health', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Primary Health Care', 'Procedures', 'Process', 'Psychotic Disorders', 'Public Health', 'Research', 'Research Personnel', 'Research Support', 'Risk', 'Risk Factors', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Specialist', 'Suicide', 'Testing', 'Time', 'Training', 'Validation', 'Work', 'World Health Organization', 'base', 'clinical care', 'cost', 'data resource', 'design', 'experience', 'first episode psychosis', 'health care settings', 'improved', 'improved outcome', 'individual patient', 'interest', 'medical schools', 'medical specialties', 'novel', 'open source', 'outpatient programs', 'predictive modeling', 'prototype', 'random forest', 'socioeconomics', 'substance abuse treatment', 'tool', 'treatment program']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,892010,0.01716294381192491
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9628032,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Guidelines', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intelligence', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Reaction', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'pharmacovigilance', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'supervised learning', 'tool']",NHLBI,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,809552,0.057239751766122594
"Addressing Bias from Missing Data in EHR Based Studies of CVD Project Summary This NHLBI K01 application supports the career development of Dr. Nrupen A. Bhavsar, PhD, an Assistant Professor of Medicine at the Duke University School of Medicine. Dr. Bhavsar is a chronic disease epidemiologist who has performed multidisciplinary studies in the epidemiology of CVD, chronic kidney disease and cancer. He is passionate about pursuing a career in clinical research at the intersection of epidemiology, informatics, and biostatistics. At the end of the award period, Dr. Bhavsar will be an independent investigator applying knowledge gained through this K01 to develop large scale EHR-based population studies that identify individuals at high risk for cardiovascular disease (CVD) events. Through training in data linkage, machine learning, and causal inference, he will apply missing data methods to conduct rigorous non-randomized studies to improve health. The topical areas of the proposed training and research are diabetes and incident CVD events in the application of data linkage, machine learning, and causal inference. Career development aim: Obtain transdisciplinary competencies within informatics, biostatistics, and population sciences to investigate methodological challenges inherent in the use of multi-health system EHR data for clinical research. The training approach will leverage didactic and experiential training complemented by analyses of data derived from a multi-health system, multi-state research collaborative. Study population: Patients who received care at one of the North Carolina or South Carolina “Carolinas Collaborative” institutions (Duke University Medical Center, UNC-CH Health System, Wake Forest Baptist Health Center, and 9 additional health systems collaborating within the Health Sciences of South Carolina institutions). Specific aims: This proposal will identify approaches to account for missing data when patients seek care across multiple health systems but EHR data is only available from a single health system. Estimating the systemic bias introduced by missing data for single institution studies and identifying methods for accounting for missing data biases may improve the ability of EHR data to be used for clinical research. Anticipated results: Through this NHLBI K01 Research Scientist Career Development Award, Dr. Bhavsar will acquire essential training and research experience to develop large scale EHR-based population studies in CVD. PROJECT NARRATIVE Data from the electronic health records (EHR) are increasingly being used for clinical research, yet there is limited information on the best approaches to address the methodological limitations of the EHR, such as missing data. In patients with diabetes at risk of cardiovascular disease events, I will examine the impact that missing data has on the ability to use the EHR for clinical research and develop approaches to address the biases resulting from missing data.",Addressing Bias from Missing Data in EHR Based Studies of CVD,9742515,K01HL140146,"['Academic Medical Centers', 'Accounting', 'Address', 'Area', 'Award', 'Baptist Church', 'Biometry', 'Cardiovascular Diseases', 'Caring', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cohort Studies', 'Comorbidity', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Linkages', 'Data Quality', 'Data Science', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Goals', 'Health', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitalization', 'Individual', 'Informatics', 'Institution', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal', 'Machine Learning', 'Medicine', 'Meta-Analysis', 'Methodology', 'Methods', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Sciences', 'Population Study', 'Privacy', 'Publishing', 'Renal carcinoma', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Research Priority', 'Risk', 'Risk Factors', 'Scientist', 'South Carolina', 'Stroke', 'Training', 'Universities', 'Work', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'cardiovascular health', 'care seeking', 'career', 'career development', 'clinical care', 'cohort', 'distributed data', 'electronic data', 'epidemiologic data', 'epidemiology study', 'experience', 'forest', 'high risk', 'improved', 'medical schools', 'multidisciplinary', 'novel', 'patient population', 'population health', 'practical application', 'professor', 'randomized trial', 'skills', 'study population']",NHLBI,DUKE UNIVERSITY,K01,2019,165554,0.005662396119683093
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9607596,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Big Data Methods', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2019,762619,0.06544120305770963
"PsycheMERGE: Leveraging electronic health records and genomics for mental health research Neuropsychiatric disorders are the leading causes of disability in the US and are associated with increased mortality (e.g. through suicide and associations with chronic diseases and their risk factors). Evidence suggests that early detection and treatment of psychiatric illness is essential to improving long-term outcomes and may even modify illness trajectories at a biological level. Unfortunately, a substantial proportion of patients undergo a long diagnostic odyssey before receiving an appropriate diagnosis and initiating effective treatment. Efforts to improve surveillance for emerging or occult psychopathology are often complex, costly, and have limited yield. Thus, there is an urgent public health need to improve clinical decision support for the early detection of psychiatric disorders in clinical settings. The growing availability of large-scale biobanks linking EHRs to biospecimens has created a powerful, but still relatively untapped, opportunity for psychiatric research. In 2007, the NHGRI organized the Electronic Medical Records and Genomics (eMERGE) network which has brought together investigators around the U.S. to facilitate EHR-based genomic research and the implementation of genomic medicine. To date, however, EHR-based risk prediction and genomics have not been widely leveraged for psychiatric research. To address this gap, we have created a new, large-scale collaborative consortium—PsycheMERGE—which leverages the resources and existing infrastructure of the eMERGE network, the Psychiatric Genomics Consortium (PGC), and local EHR and biobank resources. In this proposal, we aim to: (1) phenotypically and genomically validate and harmonize case and control phenotypes across multiple disorders (2) build clinically-useful risk surveillance models for mood disorders that also leverage cross-institutional genomewide data, and (3) examine whether EHR- and genomic-based risk profiles are associated with clinically-relevant health outcomes. We will further use these risk profiles to examine disparities in diagnostic delay by age, sex and race/ethnicity. The resulting diagnostic and risk prediction algorithms will be made available to the scientific community through the eMERGE network. Successful completion of these aims would represent a major advance in demonstrating the utility of EHR resources for precision medicine approaches to psychiatry, provide the first step toward clinical decision support tools that can be implemented within health systems, and create an invaluable resource for the scientific community. Neuropsychiatric disorders are leading causes of disability and even mortality. We have created a collaborative consortium of health systems--PsycheMERGE—to enable clinical and genetic research that will improve the understanding and early detection of psychiatric disorders. We will use cutting-edge computational and genetic methods to examine the predictors of psychiatric illness and provide a key step toward the goals of “precision psychiatry”.",PsycheMERGE: Leveraging electronic health records and genomics for mental health research,9641499,R01MH118233,"['Address', 'Adult', 'Age', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Biological', 'Bipolar Disorder', 'Childhood', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Communities', 'Comorbidity', 'Complex', 'Computerized Medical Record', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Ethnic Origin', 'Genetic', 'Genetic Research', 'Genomic medicine', 'Genomics', 'Gilles de la Tourette syndrome', 'Goals', 'Health', 'Health system', 'Heritability', 'Individual', 'Infrastructure', 'Insurance Coverage', 'Link', 'Machine Learning', 'Major Depressive Disorder', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Mood Disorders', 'National Human Genome Research Institute', 'Obsessive-Compulsive Disorder', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Probability', 'Process', 'Psychiatry', 'Psychopathology', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Schizophrenia', 'Site', 'Suicide', 'Surveillance Modeling', 'Testing', 'Training', 'Validation', 'Variant', 'autism spectrum disorder', 'base', 'biobank', 'case control', 'clinical decision support', 'clinical risk', 'clinically relevant', 'cost', 'data resource', 'delay sex', 'disability', 'disorder risk', 'effective therapy', 'genome wide association study', 'genome-wide', 'genomic predictors', 'health care service utilization', 'high risk', 'improved', 'indexing', 'mortality', 'neuropsychiatric disorder', 'precision medicine', 'prediction algorithm', 'predictive modeling', 'random forest', 'sex', 'support tools']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,855687,0.002432655985347165
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design. The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children.  Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis. ","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9626417,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Infrastructure', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Pediatric cohort', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient registry', 'pediatric emergency', 'pediatric patients', 'predictive modeling', 'repository', 'risk prediction model', 'septic patients', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,616807,0.030738328843347002
"Investigating the documentation of E-cigarette use in the VA EHR PROJECT SUMMARY Electronic cigarettes were developed in China in the early 2000s and first introduced to the US market in 2007. Once established in the US, the product experienced explosive growth, with the number of electronic cigarette users doubling every year between 2008 and 2012. In 2012, it was estimated that 75% of US adults had heard of electronic cigarettes, and 8% had tried them. While electronic cigarettes have been studied over the last sev- eral years, no scientific consensus has emerged regarding either the safety of electronic cigarettes, or their po- tential as a smoking cessation aid. With this proposal, we will investigate how electronic cigarette use is documented in the Veterans Association Electronic Health Record, focusing specifically on the relationship between electronic cigarette use and com- bustible tobacco use, with the goal of understanding both how electronic cigarette use is documented in the context of the United States’ only nationwide health system, and how electronic cigarette related information can be reliably extracted from narrative clinical text using fully automated Natural Language Processing meth- ods. PROJECT NARRATIVE The proposed research focuses on the use of Natural Language Processing methods to automatically extract mentions of electronic cigarette use from the Veterans Association Electronic Health Record. The research will provide insight into important, currently unresolved questions regarding how clinicians record electronic cigarette use in the context of a nationwide health system, and whether patients report the use of electronic cigarettes as a smoking cessation aid or use the devices in conjunction with combustible tobacco.",Investigating the documentation of E-cigarette use in the VA EHR,9652537,R03DA047577,"['Address', 'Adult', 'Algorithms', 'American', 'Area', 'China', 'Cities', 'Clinical', 'Consensus', 'Dangerousness', 'Data', 'Data Set', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Electronic Nicotine Delivery Systems', 'Electronic cigarette', 'Environment', 'Epidemiology', 'Evaluation', 'Geography', 'Goals', 'Government', 'Growth', 'Health', 'Health system', 'Healthcare Systems', 'Hearing', 'Individual', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Professional Organizations', 'Public Health', 'Public Health Applications Research', 'Reporting', 'Research', 'Risk', 'Safety', 'Scheme', 'Smoking', 'Sodium Chloride', 'Source', 'Structure', 'Technology', 'Text', 'Tobacco', 'Tobacco use', 'Tweens', 'United States', 'Universities', 'Utah', 'Variant', 'Veterans', 'Work', 'authority', 'electronic cigarette use', 'electronic cigarette user', 'electronic hookah', 'evidence base', 'experience', 'information model', 'innovation', 'insight', 'men', 'smoking cessation', 'success', 'systems research', 'tobacco control', 'tool', 'vaping']",NIDA,UNIVERSITY OF UTAH,R03,2019,76250,0.023494331983313178
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy ﻿    DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9901995,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Base Sequence', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'DNA sequencing', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Recommendation', 'Records', 'Research', 'Research Institute', 'Research Personnel', 'Ritalin', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'autism spectrum disorder', 'base', 'biobank', 'clinical care', 'clinical decision support', 'clinically actionable', 'cohort', 'cost', 'data modeling', 'data warehouse', 'database of Genotypes and Phenotypes', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'patient oriented', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'social', 'success', 'support tools', 'targeted sequencing', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2019,742762,0.06839775224295544
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,9731453,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2019,160164,0.039711305588894893
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,9657648,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'infection risk', 'informatics infrastructure', 'informatics\xa0tool', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'risk prediction model', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2019,636882,0.11797991676305263
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9650406,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'adverse drug reaction', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,410983,0.02962824301994994
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9774751,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'informatics\xa0tool', 'interest', 'learning algorithm', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'pharmacovigilance', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2019,600683,0.04361768583817861
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9768293,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'clinical decision support', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'recruit', 'repository', 'therapy design', 'tool', 'treatment optimization']",NIAAA,YALE UNIVERSITY,U24,2019,279784,-0.022073069000700787
"Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization Project summary Intimate partner violence (IPV) is a significant public health and criminal justice problem that negatively impacts millions of victims yearly in the United States, primarily women (85%). Most IPV-related healthcare visits (83%) occurred in an emergency department (ED), and these clinical encounters are unique opportunities to identify IPV victims and potentially provide assistance. Although numerous health professional organizations have endorsed universal screening and counseling for IPV since 1992, actual screening rates, detection of IPV victims, and referrals to IPV services remain low in the ED. As a result, many IPV victims pass through the ED unidentified and untreated. Computerized screening tools have been developed and implemented in clinical settings in order to assist providers in screening and detecting IPV. However, these tools have a great limitation in that they rely on information collected from the patient and do not utilize the longitudinal data in electronic health records (EHR). Recently, researchers demonstrated that a history of IPV diagnoses and associated clinical symptoms highly predict current and future IPV (OR=7.8), and these important IPV data could serve as red flags that trigger providers to assess patients further for IPV. In order to enhance IPV screening in the ED, we propose to develop and assess an automatic clinical data summarizer that extracts, abstracts and synthesizes patient historical IPV data (structured and unstructured), and delivers patient historical IPV data to ED providers through an intuitive interface. The specific aims are: 1) develop and evaluate natural language processing (NLP) strategies to identify and extract patient historical IPV incidents and timelines from clinic notes; 2) develop and evaluate a web service-based summary tool (IPV-Summary-Service) that synthesizes patient- specific IPV information from both NLP-processed data elements and structured data; and 3) develop and pilot test an enhanced IPV screening strategy that delivers clinical evidence generated by the IPV-Summary- Service through a specific EHR (Epic) to providers during the patient universal IPV screening in the ED. This automatic clinical date summary for IPV will be piloted in one ED at MUSC. There are two major outcomes to be measured for the IPV-Summary enhanced screening for 6 months before and after the index date of pilot testing: 1) rate of successful referral to the IPV 24-hour dedicated IPV nurse; and 2) rate of initiation of referral and identification of persons at high risk of IPV. We will use mixed effect generalized linear regression models to estimate the effects of IPV-Summary on the referral rate and IPV case identification rate. Through survey studies, we will assess secondary outcomes including factors of system feasibility, usability, and providers' satisfaction. These analyses can identify potentially important correlates of the major outcomes and may help us improve the design of the intervention. The results from this study will form the foundation for a broader implementation in a regional health information exchange for EDs. Narrative Computer-based approaches for intimate partner violence (IPV) universal screening have led to significantly higher screening rate and detection rate, as well as receipt of IPV services in the emergency department (ED). However, these approaches rely on information collected from the patient and do not utilize the longitudinal IPV data existing in electronic health records (EHR), which have high predictive power of IPV risk. In order to enhance the effectiveness of IPV screening, we propose to develop and assess an automatic clinical data summary tool that extracts, abstracts, and synthesizes patient historical IPV information from EHR and then delivers that critical information to ED providers at the point of care.",Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization,9739347,R21LM012945,"['Accident and Emergency department', 'Acute', 'Address', 'Adopted', 'Adult', 'American', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Client', 'Clinic', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Counseling', 'Crime', 'Criminal Justice', 'Data', 'Data Element', 'Decision Making', 'Detection', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Emergency Department patient', 'Emergency department visit', 'Event', 'Face', 'Female', 'Foundations', 'Future', 'Health', 'Health Care Visit', 'Health Professional', 'Hour', 'Injury', 'Intuition', 'Linear Regressions', 'Link', 'Masks', 'Measures', 'Medical', 'Modeling', 'Natural Language Processing', 'Nurses', 'Outcome', 'Patient Self-Report', 'Patients', 'Persons', 'Process', 'Professional Organizations', 'Provider', 'Public Health', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Screening procedure', 'Services', 'South Carolina', 'Structure', 'Surveys', 'Symptoms', 'System', 'Testing', 'Time', 'TimeLine', 'Trauma', 'United States', 'Universities', 'Victimization', 'Violent injury', 'Woman', 'Work', 'base', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized', 'experience', 'high risk', 'improved', 'indexing', 'intimate partner violence', 'point of care', 'pressure', 'satisfaction', 'screening', 'secondary outcome', 'therapy design', 'tool', 'usability', 'web services']",NLM,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R21,2019,168188,0.05630862729154971
"Advancing Quality and Outcomes Measurement in Rheumatology PROJECT SUMMARY Healthcare has changed rapidly in the last decade with the widespread use of electronic health records (EHRs) and the creation of national EHR-based data networks that aim to improve the quality of care. The American College of Rheumatology's RISE registry is a federally Qualified Clinical Data Registry that collects EHR data from the practices of almost 1000 rheumatologists nationally, analyzes these data centrally, and continuously feeds back performance on quality measures to practices via a web-based dashboard. In this K24 proposal, the applicant proposes to utilize novel methods in clinical informatics to increase the accuracy of quality measurement, while also developing and testing new EHR-based quality measures relevant to rheumatic diseases. The proposed research will leverage her strong research portfolio, including grants from the National Institute of Arthritis and Musculoskeletal and Skin Diseases and the Agency for Healthcare Research and Quality, her successful track record of achieving national endorsement for EHR-based quality measures, existing data from over 1.4 million patients in the RISE database, and the outstanding institutional environment at the University of California, San Francisco. It will also support her ongoing career development in clinical informatics methods relevant to EHR-based clinical research. For this five year K24 award proposal, she plans to increase the time spent mentoring junior investigators in the field or quality and outcomes measurement in rheumatology, with the goal of helping trainees successfully launch academic research careers in patient- oriented research. Aligned with a comprehensive mentoring plan, the proposal outlines two specific aims, including using natural language processing to increase the accuracy of EHR-based quality measurement in RISE, and developing and validating new, prototype electronic clinical quality measures to monitor and address high impact gaps in care for patients with rheumatic disease. The work will prioritize outcome measures and use eMeasurement standards, including the Quality Data Model and Health Quality Measures Format to develop, specify and test measures. Measures developed through this research and mentoring program will be candidates for nationwide dissemination across rheumatology practices to improve care for individuals with rheumatic disease. PROJECT NARRATIVE This mid-career investigator award will support a program in patient-oriented research in rheumatic diseases at the University of California, San Francisco. The award will allow the applicant to expand her research on the development and validation of health care quality measures and support her mentoring of early investigators. The proposed research aims to create quality measures that can be deployed across rheumatology practices to improve the quality of care, while training new researchers to perform innovative patient-oriented research in the area of electronic health record-based quality and outcomes measurement.",Advancing Quality and Outcomes Measurement in Rheumatology,9645973,K24AR074534,"['Address', 'Algorithms', 'American', 'Area', 'Award', 'Back', 'Benchmarking', 'California', 'Cardiovascular Diseases', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Collection', 'Comorbidity', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Analyses', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Dictionary', 'Disease', 'Electronic Health Record', 'Environment', 'Feeds', 'Foundations', 'Funding', 'Goals', 'Gout', 'Grant', 'Growth', 'Health', 'Healthcare', 'Healthcare Systems', 'High Prevalence', 'Individual', 'Informatics', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Leadership', 'Learning', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Monitor', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Preventive care', 'Process', 'Public Health', 'Quality of Care', 'Registries', 'Research', 'Research Personnel', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatology', 'Role', 'Safety', 'San Francisco', 'Scientist', 'Specific qualifier value', 'Structure', 'Testing', 'Text', 'Time', 'Training', 'United States', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vision', 'Work', 'base', 'career', 'career development', 'college', 'dashboard', 'data mining', 'data modeling', 'data registry', 'data warehouse', 'design', 'digital', 'evidence base', 'feeding', 'health care quality', 'improved', 'informatics infrastructure', 'innovation', 'interest', 'learning progression', 'novel', 'patient oriented', 'patient oriented research', 'patient registry', 'patient safety', 'programs', 'prototype', 'research study', 'rheumatologist', 'success', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K24,2019,189666,0.025019071783615912
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (“Bio-REP”) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (“Bio- REP”) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,9749915,R21AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Infrastructure', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R21,2019,198750,0.021507516792962877
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9615037,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Source', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'population based', 'prevent', 'sociodemographics', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2019,784820,0.04888605349630882
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes ?DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9655950,K01HL124045,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Genomics', 'Goals', 'Government Agencies', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare Systems', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Population Study', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Risk stratification', 'Safety', 'Science', 'Site', 'Specialist', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision support', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'epidemiology study', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'informatics\xa0tool', 'investigator training', 'mortality', 'mortality risk', 'multidisciplinary', 'novel', 'patient oriented', 'patient oriented research', 'point of care', 'portability', 'predictive modeling', 'professor', 'prognostic', 'prognostic tool', 'public health relevance', 'repository', 'research and development', 'risk prediction model', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2019,170856,0.07165173661562618
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as “EHR-driven phenotyping” is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9774075,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Consumption', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Fast Healthcare Interoperability Resources', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare Systems', 'Human', 'Informatics', 'Infrastructure', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'knowledge base', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2019,706851,0.08662084124151313
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9730585,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic Diseases', 'Genetic screening method', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heritability', 'Individual', 'Infrastructure', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Lipoprotein (a)', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'care providers', 'case-based', 'clinical decision support', 'clinical implementation', 'epidemiology study', 'evaluation/testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'screening', 'screening program', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2019,675136,0.049222846950836736
"EHR-based Genomic Discovery and Implementation PROJECT SUMMARY Electronic health record (EHR)-linked biobanks are uniquely positioned for genomic discovery and for implementing genomic medicine to improve patient care. In eMERGE I, we leveraged an EHR-linked biobank, high-density genotyping data, and electronic phenotyping algorithms to discover 29 genetic loci associated with cardiovascular traits. In eMERGE II we began implementing genomic medicine by conducting an EHR-based randomized clinical trial of disclosing genomic risk of coronary heart disease and incorporating pharmacogenomic information in the EHR with linkage to clinical decision support. In eMERGE III, we propose to build on our prior work to conduct a genomic medicine implementation project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders–familial hypercholesterolemia (FH) and familial colorectal cancer (CRC)–we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will obtain informed consent from 3000 participants of Mayo Clinic biobanks in Rochester MN and Phoenix AZ who have moderate to severe hypercholesterolemia or colon polyps. DNA will be sent for CLIA-certified targeted sequencing of 100 disease genes. We will use state-of-the-art methods to classify variant pathogenicity, finalize actionable variants for return, examine near-term outcomes, economic implications and behavioral and psychosocial consequences of such return. We will also conduct genomic discovery leveraging a network-wide data set of ~25,000 individuals with sequence data and an existing network-wide data set of ~50,000 individuals with high-density genotype data linked to the EHR. We will exploit the unique potential of the EHR to assess pleiotropy using novel approaches. In partnership with Mountain Park Health Center, a primary care practice that serves a minority population of Mexican Americans in Phoenix AZ, we will contribute high-density genotyping and phenotype data on 1000 Hispanics for genomic discovery and pilot mechanisms for implementing genomic medicine at this site. PROJECT NARRATIVE Electronic health record (EHR)-linked biobanks are uniquely positioned to discover genetic variants relevant to human health and to implement genomic medicine to improve patient care. We propose to build on prior work to implement a genomic medicine project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders – familial hypercholesterolemia (FH) and familial colorectal cancer (CRC) – we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will expand our efforts to identify genetic variants relevant to human health by leveraging available network-wide data sets.",EHR-based Genomic Discovery and Implementation,9694811,U01HG006379,"['Address', 'Algorithms', 'Behavioral', 'Bioinformatics', 'CLIA certified sequencing', 'Cardiovascular system', 'Clinic', 'Colonic Polyps', 'Colorectal Cancer', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Familial Hypercholesterolemia', 'Familial colorectal cancer', 'Family', 'Family member', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Diseases', 'Genomic medicine', 'Genomics', 'Genotype', 'Health', 'Hispanics', 'Human', 'Individual', 'Informed Consent', 'Insurance Coverage', 'Link', 'Lipids', 'Low income', 'Medical Economics', 'Methods', 'Mexican Americans', 'Minority', 'Natural Language Processing', 'Outcome', 'Participant', 'Pathogenicity', 'Patient Care', 'Patient-Focused Outcomes', 'Penetrance', 'Pharmacogenomics', 'Phenotype', 'Plasma', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Public Health', 'Randomized Clinical Trials', 'Reporting', 'Research', 'Resources', 'Risk', 'Site', 'Therapeutic Intervention', 'Translating', 'Treatment/Psychosocial Effects', 'Variant', 'Work', 'actionable mutation', 'adverse drug reaction', 'base', 'biobank', 'clinical decision support', 'clinical decision-making', 'clinically actionable', 'cohort', 'community based practice', 'cost', 'density', 'economic implication', 'genetic variant', 'genomic data', 'health care disparity', 'health care service utilization', 'hypercholesterolemia', 'improved', 'interest', 'multidisciplinary', 'novel strategies', 'phenotypic data', 'pleiotropism', 'point of care', 'psychosocial', 'rare variant', 'recruit', 'screening', 'targeted sequencing', 'trait', 'treatment response', 'variant of unknown significance']",NHGRI,MAYO CLINIC ROCHESTER,U01,2019,826601,0.024591818053997332
"Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data PROJECT SUMMARY Large electronic health record research (EHR) data integrated with -omics data from linked biorepositories have expanded opportunities for precision medicine research. These integrated datasets open opportunities for developing accurate EHR-based personalized cancer risk and progression prediction models, which can be easily incorporated into clinical practice and ultimately realize the promise of precision oncology. However, efficiently and effectively using EHR for cancer research remains challenging due to practical and methodological obstacles. For example, obtaining precise event time information such as time of cancer recurrence is a major bottleneck in using EHR for precision medicine research due to the requirement of laborious medical record review and the lack of documentation. Simple estimates of the event time based on billing or procedure codes may poorly approximate the true event time. Naive use of such estimated event times can lead to highly biased estimates due to the approximation error. Such biases impose challenges to performing pragmatic trials when the study endpoint is time to events and captured using EHR. The overall goal of this proposal is to fill these methodological gaps in risk assessment for cancer research using EHR data, which will advance our ability to achieve the promise of precision oncology. Statistical algorithms and software will be developed to (i) automatically assign event time information using longitudinally recorded EHR information; and (ii) to perform accurate risk assessment using noisy proxies of event times. The proposed tools for risk assessment using imperfect EHR data without requiring extensive manual chart review could greatly improve the utility of EHR for oncology research. PROJECT NARRATIVE This proposal addresses major methodological gaps in effectively utilizing EHR data for risk assessment due to the noisy nature of EHR data. We propose novel statistical algorithms and software to (i) efficiently annotate event time by combining multiple longitudinally recorded code information and (ii) to provide precise risk estimates using noisy proxies of event times. By drawing upon the rich albeit imperfect data from bio-repository linked EHR, our algorithms will advance our ability to use EHR data for precision oncology research.",Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data,9827744,R21CA242940,"['Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Biological', 'Boston', 'Cancer Patient', 'Clinical', 'Clinical Trials', 'Code', 'Cohort Studies', 'Data', 'Data Set', 'Diagnosis', 'Documentation', 'Electronic Health Record', 'Event', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Infrastructure', 'Label', 'Laboratories', 'Lead', 'Link', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measurement', 'Medical Records', 'Methodology', 'Methods', 'Nature', 'Patients', 'Phenotype', 'Procedures', 'Progression-Free Survivals', 'Proxy', 'Registries', 'Research', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Software Tools', 'Source', 'Statistical Algorithm', 'Supervision', 'Testing', 'Time', 'adjudicate', 'anticancer research', 'base', 'biobank', 'cancer recurrence', 'cancer risk', 'clinical practice', 'cohort', 'electronic data', 'evidence base', 'genomic data', 'improved', 'learning algorithm', 'multimodality', 'novel', 'oncology', 'patient population', 'patient subsets', 'pragmatic trial', 'precision medicine', 'precision oncology', 'predictive modeling', 'repository', 'supervised learning', 'tool', 'tumor progression', 'user friendly software', 'web site']",NCI,HARVARD SCHOOL OF PUBLIC HEALTH,R21,2019,192385,0.08580396517588129
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9579181,R01LM012918,"['Adult', 'Adverse drug event', 'Adverse effects', 'Algorithms', 'Apache', 'Area', 'Biological Neural Networks', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'Structure', 'Supervision', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'base', 'case finding', 'improved', 'learning strategy', 'malignant breast neoplasm', 'method development', 'natural language', 'new technology', 'news', 'novel', 'open source', 'point of care', 'social media', 'software systems', 'statistics', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2018,416066,0.05033605041530459
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9670540,R01LM012817,"['AIDS education', 'Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Comorbidity', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,370291,0.03330308183350187
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9547946,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2018,1542081,0.11204763808267015
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9534183,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2018,387966,0.07305810936392906
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9418526,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2018,16608,0.057239751766122594
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9698030,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Cost efficiency', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'primary endpoint', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,874586,0.057239751766122594
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,9406887,R00LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Standardization', 'Structure', 'Supervision', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'electronic structure', 'health care delivery', 'health care quality', 'improved', 'learning strategy', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2018,248969,0.053831220473555555
"Natural Language Question Understanding for Electronic Health Records ﻿    DESCRIPTION (provided by applicant): Patient information in the electronic health record (EHR) such as lab results, medications, and past medical history is the basis for physician decisions about patient care. It also helps patients better understand and manage their care. Efficient access to this patient information is thus essential. One of the most intuitive ways of accessing data is by asking natural language questions. A significant amount of work in medical question answering has been conducted, yet little work has been performed in question answering for EHRs. Natural language questions can be represented in logical forms, a standard structured knowledge representation technique. This project proposes to take natural language EHR questions, both for doctors and patients, and automatically convert them to a logical form. The logical forms can then be converted to a structured query such as those used by EHRs. A major obstacle to this approach is the lack of data containing questions annotated with logical forms. This project hypothesizes that a small set of questions can be manually annotated, and then paraphrases can be produced for each annotated question. Since paraphrasing is a simpler task than logical form annotation, crowd-sourcing techniques can be used to collect thousands of question paraphrases. This question paraphrase corpus will then be used to build a semantic grammar capable of recognizing the logical structure of EHR questions. To ensure a robust, generalizable grammar, existing NLP techniques will be used to pre-process questions, simplifying their syntactic structure and abstracting their medical concepts.     In order to develop such a method, the candidate, Dr. Kirk Roberts, requires additional training and mentoring in natural language processing and biomedical informatics. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Roberts to achieve the goals of this project as well as transition to a career as an independent researcher. He will be mentored by Dr. Dina Demner-Fushman, a leading medical NLP researcher, and co-mentored by Dr. Clement McDonald, a leading EHR and medical informatics researcher.     The specific aims of the project are: (1) Build a paraphrase collection of EHR questions, where each prototype question will have many unique paraphrases. The paraphrases encompass different lexical and syntactic means of conveying the same logical form. (2) Construct a semantic grammar for EHR questions. The grammar can then be used to convert a natural language question to a logical form. (3) Implement an end- to-end question analyzer that generalizes EHR questions for improved parsing, parses the question into a logical form using the grammar, and converts the logical form into a leading structured EHR query format. PROJECT NARRATIVE The proposed work aims to significantly improve the ability of both doctors and patients to find information within electronic health records (EHR). By providing an interface to EHRs where users can specify their information needs in the form of a natural language question, the proposed work provides a more intuitive means of finding patient data than is currently available.",Natural Language Question Understanding for Electronic Health Records,9479293,R00LM012104,"['Artificial Intelligence', 'Award', 'Blood Glucose', 'Caring', 'Clinical', 'Collection', 'Computer software', 'Data', 'Databases', 'Development Plans', 'Electronic Health Record', 'Ensure', 'Glucose', 'Goals', 'Health', 'Intuition', 'Knowledge', 'Literature', 'Manuals', 'Medical', 'Medical History', 'Medical Informatics', 'Mentors', 'Methods', 'Natural Language Processing', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Semantics', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Work', 'abstracting', 'base', 'biomedical informatics', 'career', 'career development', 'crowdsourcing', 'data access', 'design', 'electronic structure', 'health data', 'illiterate', 'improved', 'information organization', 'lexical', 'natural language', 'open source', 'operation', 'patient portal', 'phrases', 'prototype', 'syntax']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R00,2018,248999,0.05743936357234501
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,9535477,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2018,694405,0.08339181344218961
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9481256,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2018,227899,0.033614668698451325
"Algorithms to Identify Systemic Lupus from Electronic Health Record Data Abstract  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. The personal and economic costs in decreased quality of life and increase in healthcare expenditures, respectively, highlight the critical unmet need to develop new therapeutic strategies to treat lupus, so that treatment or participation in clinical trials occurs as early as possible to mitigate against disease-related damage. Therefore, it is important to find better ways to identify SLE patents.  Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. Despite this potential, to date few accurate algorithms have been developed to identify SLE patients using EHR data. Construction of an effective algorithm, either by rule-based or machine learning methods, requires access to at two data resources not commonly available: 1) a validated “gold standard” patient data set with clear documentation of criteria that are indicative of SLE that can be compared against EHR data and 2) an integrated health record dataset that contains data from multiple health care institutions and reflects that SLE patients receive healthcare at multiple institutions and healthcare providers given their chronic, progressive disease. Over the past several years, our team has created both key resources: the Chicago Lupus Database (CLD), a physician-validated registry of 880 patients and gold standard data set and the Chicago HealthLNK Data Repository (HDR), a regional data resource including integrated medical records for 2.1 million patients across multiple institutions. Jointly, these two datasets enable the creation, testing and validation of algorithms for the identification of SLE in EHR data and provide a more complete picture of a patient population at risk for lupus.  We propose three specific aims to address the need to reduce the time to identify those with SLE in order to initiate treatment in a timelier fashion and to identify candidates for clinical trials. These aims are: 1) To create and validate a series of algorithms to identify SLE patients in EHR data against a gold standard curated registry, CLD, using validated classification criteria for SLE to build concepts for rule-based and machine learning methods that incorporate structured data, laboratory data, and unstructured data, e.g., physician notes, 2) To determine whether identification of SLE patients is improved when algorithms to identify SLE patients are extended to an integrated medical record dataset that includes data from multiple health care institutions, and 3) To use clustering techniques on SLE patients identified from EHR data to isolate clinically distinct sub-populations of patients, which could inform patient selection for participation in clinical trials. Project Narrative  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. This study will test and validate algorithms for the identification of SLE from EHR data and thus will help provide a more complete picture of a patient population at risk for lupus.",Algorithms to Identify Systemic Lupus from Electronic Health Record Data,9536683,R21AR072263,"['Address', 'Affect', 'Algorithms', 'American', 'Autoimmune Process', 'Caring', 'Chicago', 'Chronic', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Collection', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Flare', 'General Population', 'Goals', 'Gold', 'Health Expenditures', 'Health Personnel', 'Health system', 'Healthcare', 'Institution', 'Laboratories', 'Legal patent', 'Lupus', 'Machine Learning', 'Medical Care Costs', 'Medical Records', 'Medicine', 'Patient Selection', 'Patients', 'Phenotype', 'Physicians', 'Populations at Risk', 'Progressive Disease', 'Quality of Care', 'Quality of life', 'Registries', 'Research', 'Resources', 'Sensitivity and Specificity', 'Series', 'Site', 'Source', 'Structure', 'Symptoms', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Time', 'Validation', 'base', 'clinical candidate', 'clinical practice', 'data resource', 'data warehouse', 'economic cost', 'health care settings', 'health record', 'improved', 'learning strategy', 'mortality', 'novel therapeutic intervention', 'patient population', 'patient subsets', 'personalized medicine', 'prevent', 'standard of care', 'targeted treatment', 'therapeutic evaluation']",NIAMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2018,173800,0.03555157374071851
"Addressing Bias from Missing Data in EHR Based Studies of CVD Project Summary This NHLBI K01 application supports the career development of Dr. Nrupen A. Bhavsar, PhD, an Assistant Professor of Medicine at the Duke University School of Medicine. Dr. Bhavsar is a chronic disease epidemiologist who has performed multidisciplinary studies in the epidemiology of CVD, chronic kidney disease and cancer. He is passionate about pursuing a career in clinical research at the intersection of epidemiology, informatics, and biostatistics. At the end of the award period, Dr. Bhavsar will be an independent investigator applying knowledge gained through this K01 to develop large scale EHR-based population studies that identify individuals at high risk for cardiovascular disease (CVD) events. Through training in data linkage, machine learning, and causal inference, he will apply missing data methods to conduct rigorous non-randomized studies to improve health. The topical areas of the proposed training and research are diabetes and incident CVD events in the application of data linkage, machine learning, and causal inference. Career development aim: Obtain transdisciplinary competencies within informatics, biostatistics, and population sciences to investigate methodological challenges inherent in the use of multi-health system EHR data for clinical research. The training approach will leverage didactic and experiential training complemented by analyses of data derived from a multi-health system, multi-state research collaborative. Study population: Patients who received care at one of the North Carolina or South Carolina “Carolinas Collaborative” institutions (Duke University Medical Center, UNC-CH Health System, Wake Forest Baptist Health Center, and 9 additional health systems collaborating within the Health Sciences of South Carolina institutions). Specific aims: This proposal will identify approaches to account for missing data when patients seek care across multiple health systems but EHR data is only available from a single health system. Estimating the systemic bias introduced by missing data for single institution studies and identifying methods for accounting for missing data biases may improve the ability of EHR data to be used for clinical research. Anticipated results: Through this NHLBI K01 Research Scientist Career Development Award, Dr. Bhavsar will acquire essential training and research experience to develop large scale EHR-based population studies in CVD. PROJECT NARRATIVE Data from the electronic health records (EHR) are increasingly being used for clinical research, yet there is limited information on the best approaches to address the methodological limitations of the EHR, such as missing data. In patients with diabetes at risk of cardiovascular disease events, I will examine the impact that missing data has on the ability to use the EHR for clinical research and develop approaches to address the biases resulting from missing data.",Addressing Bias from Missing Data in EHR Based Studies of CVD,9598902,K01HL140146,"['Academic Medical Centers', 'Accounting', 'Address', 'Area', 'Award', 'Baptist Church', 'Biometry', 'Cardiovascular Diseases', 'Caring', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cohort Studies', 'Comorbidity', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Linkages', 'Data Quality', 'Data Science', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Goals', 'Health', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitalization', 'Individual', 'Informatics', 'Institution', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal', 'Machine Learning', 'Medicine', 'Meta-Analysis', 'Methodology', 'Methods', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Sciences', 'Population Study', 'Privacy', 'Publishing', 'Renal carcinoma', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Research Priority', 'Risk', 'Risk Factors', 'Scientist', 'South Carolina', 'Stroke', 'Training', 'Universities', 'Work', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'cardiovascular health', 'care seeking', 'career', 'career development', 'clinical care', 'cohort', 'distributed data', 'electronic data', 'epidemiologic data', 'epidemiology study', 'experience', 'forest', 'high risk', 'improved', 'medical schools', 'multidisciplinary', 'novel', 'patient population', 'population health', 'practical application', 'professor', 'randomized trial', 'skills', 'study population']",NHLBI,DUKE UNIVERSITY,K01,2018,166645,0.005662396119683093
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9421556,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Personal Satisfaction', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2018,793522,0.06544120305770963
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design. The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children.  Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis. ","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9419932,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient registry', 'pediatric emergency', 'pediatric patients', 'predictive modeling', 'repository', 'septic patients', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2018,623932,0.030738328843347002
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy ﻿    DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9515026,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Base Sequence', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'DNA sequencing', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Ritalin', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinical decision support', 'clinically actionable', 'cohort', 'cost', 'data modeling', 'data warehouse', 'database of Genotypes and Phenotypes', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'patient oriented', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'social', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2018,855289,0.06839775224295544
"Improving accreditation, certification and quality improvement programs through automated abstraction of electronic health data. ABSTRACT SBIR Phase I: Reduce the burden of data abstraction for certification, accreditation and quality improvement programs via a new platform to automate the abstraction of measures and a novel interface to improve human abstractor workflow. The broad impact/commercial potential of this SBIR Phase I project is to drive down the burden of participation in quality improvement programs, specifically, the resource intensive manual data abstraction process to derive and report quality measures that are instrumental to improving health outcomes and controlling costs. Patient Insight proposes improvements through automated abstraction methods and an interface for human abstractors to better visualize electronic health record (EHR) data and complete their work. The existing approach is a barrier to broader uptake of quality improvement initiatives such as accreditation. Patient Insight’s proposed solution consists of leveraging both proven and proprietary technologies to extract data via EHR agnostic application programming interfaces (APIs), better target eligible patients, and calculate measures via natural language processing (NLP) algorithms and custom queries. The core innovation is a novel data mining engine and user interface that improves the process of human data abstraction for clinical and quality documentation such as those required to achieve accreditation. The proposed project will allow Patient Insight, in partnership with the American College of Cardiology, a leader in the hospital based accreditation space, to develop a proof-of-concept pilot project at a select hospital and compare human and automated data abstraction methods for a pre-selected number of measures that are mandated as part of the ACC’s Heart Failure Accreditation program. Once completed, Patient Insight will expand on the technology, design and user research data/requirements with a roadmap for product enhancements for Phase II that will enable the building of a commercially viable ‘add-on’ service for sites participating in the ACC’s suite of accreditation programs and eventually expand to additional ACC service lines as well as other accreditation and certifying bodies. Success will represent a transformative change in general-purpose abstraction and an interface that will support a broad array of accreditation measures and abstraction workflows thereby solving a critical inefficiency both clinically and financially for hospitals while improving patient health outcomes. PROJECT NARRATIVE Health service accreditation and certification programs are a critical mechanism to direct care quality improvements and ensure compliance with regulations. Reporting on requisite measures is a resource intensive and costly process requiring human data abstractors to interpret heterogeneous and disparately presented data elements from the electronic health record (EHR). Replacing human elements using evolving automated data abstraction methods and an interface for abstractors to better visualize EHR data and manage their workflow would solve an important, unmet need and offer a dramatic improvement over the status quo. Patient Insight’s commercial technology solution will facilitate efficiencies in automated data abstraction and human-to-computer interactions in quality improvement reporting.","Improving accreditation, certification and quality improvement programs through automated abstraction of electronic health data.",9622944,R43LM012955,"['Accreditation', 'Algorithms', 'American', 'Appointment', 'Back', 'Beds', 'Budgets', 'Cardiac rehabilitation', 'Cardiology', 'Caring', 'Certification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Computers', 'Cost Control', 'Custom', 'Data', 'Data Element', 'Diuretics', 'Documentation', 'Electronic Health Record', 'Elements', 'Ensure', 'Event', 'Expenditure', 'Feedback', 'Hand', 'Health', 'Health Services', 'Health Services Accessibility', 'Health Status', 'Healthcare', 'Heart failure', 'Hospitals', 'Human', 'Information Technology', 'Investments', 'Licensing', 'Manuals', 'Measures', 'Methods', 'Mining', 'Natural Language Processing', 'Outcome', 'Outcome Measure', 'Paper', 'Patient Care', 'Patients', 'Phase', 'Pilot Projects', 'Population', 'Process', 'Quality of Care', 'Regulation', 'Reporting', 'Research', 'Resources', 'Schedule', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Work', 'application programming interface', 'base', 'cardiology service', 'certificate program', 'college', 'cost', 'data management', 'data mining', 'data visualization', 'design', 'exercise program', 'follow-up', 'health assessment', 'health data', 'human data', 'improved', 'innovation', 'insight', 'new technology', 'novel', 'product development', 'programs', 'readmission rates', 'success', 'tool', 'uptake', 'usability']",NLM,"PATIENT INSIGHT, INC.",R43,2018,259060,0.030928317317105103
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,9599186,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2018,160164,0.039711305588894893
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",9534182,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Caring', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Structure', 'Supervision', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'application programming interface', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'patient-clinician communication', 'personalized medicine', 'tool', 'trend analysis']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2018,335217,0.109925388337497
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort - Diversity Supplement Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort - Diversity Supplement,9693037,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Reaction', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,49920,0.02962824301994994
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,9486584,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Infection', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'informatics infrastructure', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2018,484387,0.11797991676305263
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9441852,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Reaction', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,399573,0.02962824301994994
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9476980,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'base', 'clinical decision support', 'clinical implementation', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2018,300000,0.07667980954354772
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics ﻿    DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9674607,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2018,79500,0.04361768583817861
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics ﻿    DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9789497,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2018,79500,0.04361768583817861
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics ﻿    DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9548987,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2018,620106,0.04361768583817861
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (“Bio-REP”) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (“Bio- REP”) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,9503117,R21AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R21,2018,238500,0.021507516792962877
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9545635,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'clinical decision support', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'recruit', 'repository', 'therapy design', 'tool', 'treatment optimization']",NIAAA,YALE UNIVERSITY,U24,2018,279784,-0.022073069000700787
"Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization Project summary Intimate partner violence (IPV) is a significant public health and criminal justice problem that negatively impacts millions of victims yearly in the United States, primarily women (85%). Most IPV-related healthcare visits (83%) occurred in an emergency department (ED), and these clinical encounters are unique opportunities to identify IPV victims and potentially provide assistance. Although numerous health professional organizations have endorsed universal screening and counseling for IPV since 1992, actual screening rates, detection of IPV victims, and referrals to IPV services remain low in the ED. As a result, many IPV victims pass through the ED unidentified and untreated. Computerized screening tools have been developed and implemented in clinical settings in order to assist providers in screening and detecting IPV. However, these tools have a great limitation in that they rely on information collected from the patient and do not utilize the longitudinal data in electronic health records (EHR). Recently, researchers demonstrated that a history of IPV diagnoses and associated clinical symptoms highly predict current and future IPV (OR=7.8), and these important IPV data could serve as red flags that trigger providers to assess patients further for IPV. In order to enhance IPV screening in the ED, we propose to develop and assess an automatic clinical data summarizer that extracts, abstracts and synthesizes patient historical IPV data (structured and unstructured), and delivers patient historical IPV data to ED providers through an intuitive interface. The specific aims are: 1) develop and evaluate natural language processing (NLP) strategies to identify and extract patient historical IPV incidents and timelines from clinic notes; 2) develop and evaluate a web service-based summary tool (IPV-Summary-Service) that synthesizes patient- specific IPV information from both NLP-processed data elements and structured data; and 3) develop and pilot test an enhanced IPV screening strategy that delivers clinical evidence generated by the IPV-Summary- Service through a specific EHR (Epic) to providers during the patient universal IPV screening in the ED. This automatic clinical date summary for IPV will be piloted in one ED at MUSC. There are two major outcomes to be measured for the IPV-Summary enhanced screening for 6 months before and after the index date of pilot testing: 1) rate of successful referral to the IPV 24-hour dedicated IPV nurse; and 2) rate of initiation of referral and identification of persons at high risk of IPV. We will use mixed effect generalized linear regression models to estimate the effects of IPV-Summary on the referral rate and IPV case identification rate. Through survey studies, we will assess secondary outcomes including factors of system feasibility, usability, and providers' satisfaction. These analyses can identify potentially important correlates of the major outcomes and may help us improve the design of the intervention. The results from this study will form the foundation for a broader implementation in a regional health information exchange for EDs. Narrative Computer-based approaches for intimate partner violence (IPV) universal screening have led to significantly higher screening rate and detection rate, as well as receipt of IPV services in the emergency department (ED). However, these approaches rely on information collected from the patient and do not utilize the longitudinal IPV data existing in electronic health records (EHR), which have high predictive power of IPV risk. In order to enhance the effectiveness of IPV screening, we propose to develop and assess an automatic clinical data summary tool that extracts, abstracts, and synthesizes patient historical IPV information from EHR and then delivers that critical information to ED providers at the point of care.",Enhancing Intimate Partner Violence (IPV) Identification through Automated EHR Summarization,9520862,R21LM012945,"['Accident and Emergency department', 'Acute', 'Address', 'Adopted', 'Adult', 'American', 'Caring', 'Centers for Disease Control and Prevention (U.S.)', 'Chronic', 'Client', 'Clinic', 'Clinical', 'Clinical Data', 'Complex', 'Computers', 'Counseling', 'Crime', 'Criminal Justice', 'Data', 'Data Element', 'Decision Making', 'Detection', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Emergency Department patient', 'Emergency department visit', 'Event', 'Face', 'Female', 'Foundations', 'Future', 'Health', 'Health Care Visit', 'Health Professional', 'Hour', 'Injury', 'Intuition', 'Linear Regressions', 'Link', 'Masks', 'Measures', 'Medical', 'Modeling', 'Natural Language Processing', 'Nurses', 'Outcome', 'Patient Self-Report', 'Patients', 'Persons', 'Process', 'Professional Organizations', 'Provider', 'Public Health', 'Recording of previous events', 'Research Personnel', 'Resources', 'Risk', 'Screening procedure', 'Services', 'South Carolina', 'Structure', 'Surveys', 'Symptoms', 'System', 'Testing', 'Time', 'TimeLine', 'Trauma', 'United States', 'Universities', 'Victimization', 'Violent injury', 'Woman', 'Work', 'base', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized', 'experience', 'high risk', 'improved', 'indexing', 'intimate partner violence', 'point of care', 'pressure', 'satisfaction', 'screening', 'secondary outcome', 'therapy design', 'tool', 'usability', 'web services']",NLM,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R21,2018,201825,0.05630862729154971
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9395941,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Data Sources', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'population based', 'prevent', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2018,803425,0.04888605349630882
"Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding Project Summary/Abstract  With increasing use of electronic medical records for a variety of patients, a large investment is being made in a resource still vastly underused. Especially in mental health, where problems are highly individualized, requiring personalized intervention, and often accompanied by rich data not easily captured in structured templates, the need for extracting information from free text in existing records for use as large-scale stand- alone datasets or in combination with other data is real. Without scalable and effective computational approaches to capture this data, much time, effort and money is used to create limited-use records that instead could be leveraged into precious data sources to inform existing research and lead to new insights, progress and treatments. Our broad, long-term goal is processing free text in EHR in mental health. We focus on Autism Spectrum Disorders (ASD), a particularly interesting example of both shortcomings and opportunities.  ASD’s prevalence has increased over the years, and estimates range from 1 in 150 in 2000 to 1 in 68 in 2010(1-5). These numbers are based on surveillance using electronic health records. The increasing prevalence is not well understood, and hypotheses range from changing diagnostic criteria to environmental factors. The lines of inquiry used to find cures are similarly broad and range from brain scans and genetics, resulting in large structured datasets, to highly individualized therapies, resulting in rich but unstructured data. Currently the text information in the electronic records is not being leveraged on a large scale.  The proposed project continues our preliminary work and uses a data-driven approach to create human- interpretable models that allow automated extraction of relevant structured data from free text. The Diagnostic and Statistical Manual of Mental Disorders (DSM) is the starting point for identifying features. A database of thousands of records is leveraged to design and test the algorithms. The two specific aims are: 1) design and test natural language processing (NLP) algorithms to detect DSM criteria for ASD in free text in EHR, and 2) demonstrate feasibility and usefulness of the models for large-scale analysis of ASD cases, which is inconceivable today with current approaches. Our methods include analysis of free text in electronic records and end-user annotations to create a large gold standard of instances of DSM criteria for ASD, application of machine learning and rule-based approaches to create human-interpretable models for automated annotation of diagnostic patterns in textual records, and demonstrate usefulness with new research (e.g., Automatically detect ASD vs. no-ASD status for challenging cases; evaluate prevalence of symptoms over time). Through NLP algorithms, this project has the potential to significantly shift away from the current paradigm of attempting to understand ASD by relying on small-scale data from individual interventions and lack of integration between different data sources, to leveraging information from existing large-scale data sources to propose novel analyses and hypotheses. Project Narrative  Lack of sophisticated tools to extract relevant diagnostic patterns from free text from the increasingly large number of electronic medical/health records is a critical barrier in the field of mental health to leverage and utilize the already available data. Natural language processing (NLP) algorithms designed specifically for mental health can make new data analysis and integration with other sources possible at a scale previously unseen. Using a data-driven process, this project will design NLP algorithms to annotate free text with criteria from the Diagnostic and Statistical Manual of Mental Disorders (DSM) and demonstrate scope, feasibility and usefulness by focusing on Autism Spectrum Disorders (ASD) where prevalence is increasing and much rich clinical text is stored in electronic health records (EHR).",Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding,9547263,R21HS024988,[' '],AHRQ,UNIVERSITY OF ARIZONA,R21,2018,146202,0.010590899438505904
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes ﻿    DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9443655,K01HL124045,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Genomics', 'Goals', 'Government Agencies', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Population Study', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Risk stratification', 'Safety', 'Science', 'Site', 'Specialist', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision support', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'epidemiology study', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'patient oriented research', 'point of care', 'portability', 'predictive modeling', 'professor', 'prognostic', 'prognostic tool', 'public health relevance', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2018,170856,0.07165173661562618
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as “EHR-driven phenotyping” is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9547873,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'interoperability', 'knowledge base', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2018,706851,0.08662084124151313
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as “EHR-driven phenotyping” is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9707366,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'interoperability', 'knowledge base', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2018,429621,0.08662084124151313
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9490424,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic Diseases', 'Genetic screening method', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heritability', 'Individual', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Lipoprotein (a)', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'care providers', 'case-based', 'clinical decision support', 'clinical implementation', 'epidemiology study', 'evaluation/testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'screening', 'screening program', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2018,653490,0.049222846950836736
"EHR-based Genomic Discovery and Implementation ﻿    DESCRIPTION (provided by applicant): Electronic health record (EHR)-linked biobanks are uniquely positioned for genomic discovery and for implementing genomic medicine to improve patient care. In eMERGE I, we leveraged an EHR-linked biobank, high-density genotyping data, and electronic phenotyping algorithms to discover 29 genetic loci associated with cardiovascular traits. In eMERGE II we began implementing genomic medicine by conducting an EHR-based randomized clinical trial of disclosing genomic risk of coronary heart disease and incorporating pharmacogenomic information in the EHR with linkage to clinical decision support. In eMERGE III; we propose to build on our prior work to conduct a genomic medicine implementation project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders-familial hypercholesterolemia (FH) and familial colorectal cancer (CRC)-we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will obtain informed consent from 3000 participants of Mayo Clinic biobanks in Rochester MN and Phoenix AZ who have moderate to severe hypercholesterolemia or colon polyps. DNA will be sent for CLIA-certified targeted sequencing of 100 disease genes. We will use state-of-the-art methods to classify variant pathogenicity, finalize actionable variants for return, examine near-term outcomes, economic implications and behavioral and psychosocial consequences of such return. We will also conduct genomic discovery leveraging a network-wide data set of ~25,000 individuals with sequence data and an existing network-wide data set of ~50,000 individuals with high-density genotype data linked to the EHR. We will exploit the unique potential of the EHR to assess pleiotropy using novel approaches. In partnership with Mountain Park Health Center, a primary care practice that serves a minority population of Mexican Americans in Phoenix AZ, we will contribute high-density genotyping and phenotype data on 1000 Hispanics for genomic discovery and pilot mechanisms for implementing genomic medicine at this site. PUBLIC HEALTH RELEVANCE: Electronic health record (EHR)-linked biobanks are uniquely positioned to discover genetic variants relevant to human health and to implement genomic medicine to improve patient care. We propose to build on prior work to implement a genomic medicine project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders - familial hypercholesterolemia (FH) and familial colorectal cancer (CRC) - we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will expand our efforts to identify genetic variants relevant to human health by leveraging available network-wide data sets.",EHR-based Genomic Discovery and Implementation,9502299,U01HG006379,"['Address', 'Algorithms', 'Behavioral', 'Bioinformatics', 'CLIA certified sequencing', 'Cardiovascular system', 'Clinic', 'Colonic Polyps', 'Colorectal Cancer', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Familial Hypercholesterolemia', 'Familial colorectal cancer', 'Family', 'Family member', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genetic Diseases', 'Genomic medicine', 'Genomics', 'Genotype', 'Health', 'Hispanics', 'Human', 'Individual', 'Informed Consent', 'Insurance Coverage', 'Link', 'Lipids', 'Low income', 'Medical Economics', 'Methods', 'Mexican Americans', 'Minority', 'Natural Language Processing', 'Outcome', 'Participant', 'Pathogenicity', 'Patient Care', 'Patient-Focused Outcomes', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Plasma', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Public Health', 'Randomized Clinical Trials', 'Reaction', 'Reporting', 'Research', 'Resources', 'Risk', 'Site', 'Therapeutic Intervention', 'Translating', 'Treatment/Psychosocial Effects', 'Variant', 'Work', 'actionable mutation', 'base', 'biobank', 'clinical decision support', 'clinical decision-making', 'clinically actionable', 'cohort', 'community based practice', 'cost', 'density', 'economic implication', 'genetic variant', 'genomic data', 'health care disparity', 'health care service utilization', 'hypercholesterolemia', 'improved', 'interest', 'multidisciplinary', 'novel strategies', 'phenotypic data', 'pleiotropism', 'point of care', 'psychosocial', 'public health relevance', 'rare variant', 'recruit', 'screening', 'targeted sequencing', 'trait', 'treatment response', 'variant of unknown significance']",NHGRI,MAYO CLINIC ROCHESTER,U01,2018,831652,0.024921476546033217
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9337267,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face Processing', 'Goals', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Supervision', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability', 'word learning']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,463061,0.03945738904599107
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,9385056,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Biological Preservation', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Meta-Analysis', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phrases', 'portability', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2017,1589604,0.11204763808267015
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9325065,R01LM011934,"['Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Ontology', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'information model', 'novel', 'open source', 'profiles in patients', 'public health relevance', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2017,387966,0.07305810936392906
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9190384,R01HL125089,"['Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Etiology', 'Frequencies', 'Health Care Costs', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Prevention', 'Process', 'Regimen', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'clinical practice', 'cost', 'data resource', 'disorder prevention', 'dosage', 'epidemiology study', 'high risk', 'improved', 'innovation', 'mortality', 'natural language', 'novel', 'open source', 'patient safety', 'predictive modeling', 'prospective', 'public health relevance', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2017,1177432,0.057239751766122594
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,9201329,R00LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Standardization', 'Structure', 'Supervision', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'electronic structure', 'health care delivery', 'health care quality', 'improved', 'learning strategy', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2017,248969,0.053831220473555555
"Natural Language Question Understanding for Electronic Health Records ﻿    DESCRIPTION (provided by applicant): Patient information in the electronic health record (EHR) such as lab results, medications, and past medical history is the basis for physician decisions about patient care. It also helps patients better understand and manage their care. Efficient access to this patient information is thus essential. One of the most intuitive ways of accessing data is by asking natural language questions. A significant amount of work in medical question answering has been conducted, yet little work has been performed in question answering for EHRs. Natural language questions can be represented in logical forms, a standard structured knowledge representation technique. This project proposes to take natural language EHR questions, both for doctors and patients, and automatically convert them to a logical form. The logical forms can then be converted to a structured query such as those used by EHRs. A major obstacle to this approach is the lack of data containing questions annotated with logical forms. This project hypothesizes that a small set of questions can be manually annotated, and then paraphrases can be produced for each annotated question. Since paraphrasing is a simpler task than logical form annotation, crowd-sourcing techniques can be used to collect thousands of question paraphrases. This question paraphrase corpus will then be used to build a semantic grammar capable of recognizing the logical structure of EHR questions. To ensure a robust, generalizable grammar, existing NLP techniques will be used to pre-process questions, simplifying their syntactic structure and abstracting their medical concepts.     In order to develop such a method, the candidate, Dr. Kirk Roberts, requires additional training and mentoring in natural language processing and biomedical informatics. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Roberts to achieve the goals of this project as well as transition to a career as an independent researcher. He will be mentored by Dr. Dina Demner-Fushman, a leading medical NLP researcher, and co-mentored by Dr. Clement McDonald, a leading EHR and medical informatics researcher.     The specific aims of the project are: (1) Build a paraphrase collection of EHR questions, where each prototype question will have many unique paraphrases. The paraphrases encompass different lexical and syntactic means of conveying the same logical form. (2) Construct a semantic grammar for EHR questions. The grammar can then be used to convert a natural language question to a logical form. (3) Implement an end- to-end question analyzer that generalizes EHR questions for improved parsing, parses the question into a logical form using the grammar, and converts the logical form into a leading structured EHR query format. PROJECT NARRATIVE The proposed work aims to significantly improve the ability of both doctors and patients to find information within electronic health records (EHR). By providing an interface to EHRs where users can specify their information needs in the form of a natural language question, the proposed work provides a more intuitive means of finding patient data than is currently available.",Natural Language Question Understanding for Electronic Health Records,9254613,R00LM012104,"['Artificial Intelligence', 'Award', 'Blood Glucose', 'Caring', 'Clinical', 'Collection', 'Computer software', 'Data', 'Databases', 'Development Plans', 'Electronic Health Record', 'Ensure', 'Glucose', 'Goals', 'Health', 'Intuition', 'Knowledge', 'Literature', 'Manuals', 'Medical', 'Medical History', 'Medical Informatics', 'Mentors', 'Methods', 'Natural Language Processing', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Semantics', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Work', 'abstracting', 'base', 'biomedical informatics', 'career', 'career development', 'crowdsourcing', 'data access', 'design', 'electronic structure', 'health data', 'illiterate', 'improved', 'information organization', 'lexical', 'natural language', 'open source', 'operation', 'phrases', 'prototype', 'syntax']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R00,2017,248999,0.05743936357234501
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,9365759,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2017,636560,0.08339181344218961
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9275946,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2017,227900,0.033614668698451325
"Algorithms to Identify Systemic Lupus from Electronic Health Record Data Abstract  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. The personal and economic costs in decreased quality of life and increase in healthcare expenditures, respectively, highlight the critical unmet need to develop new therapeutic strategies to treat lupus, so that treatment or participation in clinical trials occurs as early as possible to mitigate against disease-related damage. Therefore, it is important to find better ways to identify SLE patents.  Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. Despite this potential, to date few accurate algorithms have been developed to identify SLE patients using EHR data. Construction of an effective algorithm, either by rule-based or machine learning methods, requires access to at two data resources not commonly available: 1) a validated “gold standard” patient data set with clear documentation of criteria that are indicative of SLE that can be compared against EHR data and 2) an integrated health record dataset that contains data from multiple health care institutions and reflects that SLE patients receive healthcare at multiple institutions and healthcare providers given their chronic, progressive disease. Over the past several years, our team has created both key resources: the Chicago Lupus Database (CLD), a physician-validated registry of 880 patients and gold standard data set and the Chicago HealthLNK Data Repository (HDR), a regional data resource including integrated medical records for 2.1 million patients across multiple institutions. Jointly, these two datasets enable the creation, testing and validation of algorithms for the identification of SLE in EHR data and provide a more complete picture of a patient population at risk for lupus.  We propose three specific aims to address the need to reduce the time to identify those with SLE in order to initiate treatment in a timelier fashion and to identify candidates for clinical trials. These aims are: 1) To create and validate a series of algorithms to identify SLE patients in EHR data against a gold standard curated registry, CLD, using validated classification criteria for SLE to build concepts for rule-based and machine learning methods that incorporate structured data, laboratory data, and unstructured data, e.g., physician notes, 2) To determine whether identification of SLE patients is improved when algorithms to identify SLE patients are extended to an integrated medical record dataset that includes data from multiple health care institutions, and 3) To use clustering techniques on SLE patients identified from EHR data to isolate clinically distinct sub-populations of patients, which could inform patient selection for participation in clinical trials. Project Narrative  Systemic lupus erythematosus (SLE) is a chronic, autoimmune, multisystem disease that is often difficult to diagnose because of the diverse manifestations that occur over time and across care sites leading to increased damage and early mortality. Electronic health records (EHR) are now used in a majority of health care settings throughout the country, and present a rich source of information about patients which can be mined for earlier diagnosis and identification to improve quality of care, or enable high throughput clinical studies. This study will test and validate algorithms for the identification of SLE from EHR data and thus will help provide a more complete picture of a patient population at risk for lupus.",Algorithms to Identify Systemic Lupus from Electronic Health Record Data,9375416,R21AR072263,"['Address', 'Affect', 'Algorithms', 'American', 'Autoimmune Process', 'Caring', 'Chicago', 'Chronic', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical Trials Design', 'Collection', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Documentation', 'Early Diagnosis', 'Early identification', 'Electronic Health Record', 'Expenditure', 'Flare', 'General Population', 'Goals', 'Gold', 'Health Personnel', 'Health system', 'Healthcare', 'Institution', 'Laboratories', 'Legal patent', 'Lupus', 'Machine Learning', 'Medical', 'Medical Records', 'Medicine', 'Patient Selection', 'Patients', 'Phenotype', 'Physicians', 'Populations at Risk', 'Progressive Disease', 'Quality of Care', 'Quality of life', 'Registries', 'Research', 'Resources', 'Sensitivity and Specificity', 'Series', 'Site', 'Source', 'Structure', 'Symptoms', 'Systemic Lupus Erythematosus', 'Techniques', 'Testing', 'Time', 'Validation', 'base', 'clinical candidate', 'clinical practice', 'cost', 'data resource', 'economic cost', 'health record', 'improved', 'learning strategy', 'mortality', 'novel therapeutic intervention', 'patient population', 'personalized medicine', 'prevent', 'standard of care', 'targeted treatment', 'therapeutic evaluation']",NIAMS,NORTHWESTERN UNIVERSITY AT CHICAGO,R21,2017,208395,0.03555157374071851
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9199581,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Injectable', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Public Health', 'Research', 'Semantics', 'Solid', 'Standardization', 'Stream', 'Supervision', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'method development', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2017,798827,0.06544120305770963
"Automated Detection of Anomalous Accesses to Electronic Health Records DESCRIPTION (provided by applicant): Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in is infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems. As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,9332474,R01LM010207,"['Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Dimensions', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Geography', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Interruption', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data access', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward', 'web portal']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,341475,0.04941442276411166
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design. The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children.  Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis. ","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9239711,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient registry', 'pediatric patients', 'predictive modeling', 'repository', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2017,735263,0.030738328843347002
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy ﻿    DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9282532,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Base Sequence', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'DNA sequencing', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'cost', 'data modeling', 'database of Genotypes and Phenotypes', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'patient oriented', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'social', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2017,811897,0.06839775224295544
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",9332464,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Caring', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Structure', 'Supervision', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'application programming interface', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'personalized medicine', 'tool', 'trend analysis']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2017,335217,0.109925388337497
"Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients Project Summary Epilepsy is one of the leading neurological disorders in the United States, affecting more than 479,000 children and over 2 million adults. Approximately 30% of epileptic patients have poor seizure control despite antiepileptic medications and are potential candidates for neurosurgical intervention. Early identification and referral of children who are potential surgical candidates is complex and while relevant guidelines exist, there is no standard process to efficiently identify those patients meeting criteria for neurosurgical intervention. Given the large corpus of note-based data available in the electronic health record (EHR), it is challenging for providers to efficiently retain and process all the pertinent patient information. Natural Language Processing (NLP) and machine learning techniques have been successfully used to evaluate clinical notes and make recommendations in the research setting. However, NLP techniques are rarely integrated into practice to provide real-time clinical decision support. We developed and retrospectively evaluated a NLP system to help identify those patients who meet neurosurgical criteria and therefore enable surgical consults and evaluations to occur sooner. Knowing clinical decision support can improve outcomes of care, our proposed research will implement NLP into clinical practice and develop a decision support mechanism to improve the time to surgery for eligible patients. The objective of this project is to implement NLP directly into clinical care and determine the most effective decision support mechanism for provider adherence to epilepsy surgical consult recommendations. The long- term goal of this project is to reduce the time to initial surgery evaluation for patients with intractable epilepsy by integrating NLP-classification criteria into clinical practice. This project is one of the first in the field to study the integration of NLP recommendations into clinical care. We will use a human factors engineering framework to design and to analyze two different alerting methodologies for the best-fit for clinical workflow to produce the optimum provider adherence while reducing alert fatigue. Epilepsy progress notes can be classified across hospitals, and if successful, the system will be implemented in additional pediatric institutions around the United States. Project Narrative Epilepsy affects more than 479,000 children; 30% of those are not controlled with medication and may require surgery. We developed a novel Natural Language Processing (NLP) algorithm that can be integrated into neurology practice to detect patients who may be eligible for epilepsy surgical consults. Once implemented, this research can help to drive successful implementations of NLP and identify and use ideal alerting mechanisms in neurological care.",Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients,9355161,R21HS024977,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2017,159334,0.04191660507322299
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9309793,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Reaction', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'glutaryl coA', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,406123,0.02962824301994994
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9251814,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2017,300000,0.07667980954354772
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics ﻿    DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9331533,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Award', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'longitudinal dataset', 'novel', 'open source', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2017,623596,0.04361768583817861
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9338098,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Recruitment Activity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'repository', 'therapy design', 'tool']",NIAAA,YALE UNIVERSITY,U24,2017,282773,-0.022073069000700787
"Temporal relation discovery for clinical text ﻿    DESCRIPTION (provided by applicant):         The overarching long-term vision of our research is to create novel technologies for processing clinical free text. We will build upon the previous work of our ongoing project ""Temporal relation discovery for clinical text"" (R01LM010090) dubbed Temporal Histories of Your Medical Events (THYME; thyme.healthnlp.org) which has been focusing on methodology for event, temporal expressions and temporal relations discovery from the clinical text residing in the Electronic Health Records (EHR). We developed a comprehensive approach to temporality in the clinical text and innovated in computable temporal representations, methods for temporal relation discovery and their evaluation, rendering temporality to end users - resulting in over 35+ papers and presentations. Our dissemination is international and far-reaching as the best performing methods are released open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (ctakes.apache.org). The methods we developed are now being used in such nation-wide initiatives as the Electronic Medical Records and Genomics (eMERGE), Pharmacogenomics Network (PGRN), Informatics for Integrating the Biology and the Bedside (i2b2), Patient Centered Outcomes Research Institute and National Cancer Institute's Informatics Technology for Cancer Research (ITCR). Through our participation in organizing major international bakeoffs - CLEF/ShARe 2014, SemEval 2014 Analysis of Clinical Text Task 7, SemEval 2015 Analysis of Clinical Text Task 14, SemEval 2015 Clinical TempEval Task 6 - we further disseminated the THYME resources and challenged the international research community to explore new solutions to the unsolved temporality task. Through all these activities it became clear that computational approaches to temporality still present great challenges and usability of the output is still limited. Therefore, we propose to further innovate on methodologies and end user experience.             Specific Aim 1: Extract enhanced representations and novel features to support deriving timeline information.     Specific Aim 2: Develop methods to amalgamate individual patient episode timelines into an aggregate patient-level timeline.     Specific Aim 3: Mine the EHR - the unstructured clinical text and the structured codified information - for full patient-level temporality.     Specific Aim 4: Develop a comprehensive temporal visualization tool     Specific Aim 5: Develop methodology for and perform extrinsic evaluation on specific use case.     Specific Aim 6: (1) Evaluate state-of-the-art of temporal relations through organizing international challenges under the auspices of SemEval, (2) Disseminate the results through publications, presentations, and open source code in Apache cTAKES. Functional testing. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EHR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,9337497,R01LM010090,"['Apache', 'Automobile Driving', 'Biology', 'Chronology', 'Clinical', 'Collection', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Evaluation', 'Event', 'Genomics', 'Goals', 'Human', 'Informatics', 'Information Retrieval', 'International', 'Intuition', 'Joints', 'Knowledge Extraction', 'Language', 'Life', 'Link', 'Machine Learning', 'Malignant neoplasm of brain', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'National Cancer Institute', 'Output', 'Paper', 'Patient-Focused Outcomes', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Publications', 'Recording of previous events', 'Records', 'Research', 'Research Institute', 'Resolution', 'Resources', 'Science', 'Semantics', 'Signs and Symptoms', 'Source Code', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Thyme', 'Time', 'TimeLine', 'Translational Research', 'Trees', 'Vision', 'Visualization software', 'Work', 'anticancer research', 'autism spectrum disorder', 'clinically relevant', 'data mining', 'electronic structure', 'experience', 'individual patient', 'innovation', 'new technology', 'next generation', 'novel', 'open source', 'symptom treatment', 'syntax', 'usability']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2017,643621,0.013496523760124399
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9215012,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Data Sources', 'Development', 'Diagnostic', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'outcome forecast', 'population based', 'prevent', 'socioeconomics', 'surveillance data', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2017,836858,0.04888605349630882
"Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding Project Summary/Abstract  With increasing use of electronic medical records for a variety of patients, a large investment is being made in a resource still vastly underused. Especially in mental health, where problems are highly individualized, requiring personalized intervention, and often accompanied by rich data not easily captured in structured templates, the need for extracting information from free text in existing records for use as large-scale stand- alone datasets or in combination with other data is real. Without scalable and effective computational approaches to capture this data, much time, effort and money is used to create limited-use records that instead could be leveraged into precious data sources to inform existing research and lead to new insights, progress and treatments. Our broad, long-term goal is processing free text in EHR in mental health. We focus on Autism Spectrum Disorders (ASD), a particularly interesting example of both shortcomings and opportunities.  ASD’s prevalence has increased over the years, and estimates range from 1 in 150 in 2000 to 1 in 68 in 2010(1-5). These numbers are based on surveillance using electronic health records. The increasing prevalence is not well understood, and hypotheses range from changing diagnostic criteria to environmental factors. The lines of inquiry used to find cures are similarly broad and range from brain scans and genetics, resulting in large structured datasets, to highly individualized therapies, resulting in rich but unstructured data. Currently the text information in the electronic records is not being leveraged on a large scale.  The proposed project continues our preliminary work and uses a data-driven approach to create human- interpretable models that allow automated extraction of relevant structured data from free text. The Diagnostic and Statistical Manual of Mental Disorders (DSM) is the starting point for identifying features. A database of thousands of records is leveraged to design and test the algorithms. The two specific aims are: 1) design and test natural language processing (NLP) algorithms to detect DSM criteria for ASD in free text in EHR, and 2) demonstrate feasibility and usefulness of the models for large-scale analysis of ASD cases, which is inconceivable today with current approaches. Our methods include analysis of free text in electronic records and end-user annotations to create a large gold standard of instances of DSM criteria for ASD, application of machine learning and rule-based approaches to create human-interpretable models for automated annotation of diagnostic patterns in textual records, and demonstrate usefulness with new research (e.g., Automatically detect ASD vs. no-ASD status for challenging cases; evaluate prevalence of symptoms over time). Through NLP algorithms, this project has the potential to significantly shift away from the current paradigm of attempting to understand ASD by relying on small-scale data from individual interventions and lack of integration between different data sources, to leveraging information from existing large-scale data sources to propose novel analyses and hypotheses. Project Narrative  Lack of sophisticated tools to extract relevant diagnostic patterns from free text from the increasingly large number of electronic medical/health records is a critical barrier in the field of mental health to leverage and utilize the already available data. Natural language processing (NLP) algorithms designed specifically for mental health can make new data analysis and integration with other sources possible at a scale previously unseen. Using a data-driven process, this project will design NLP algorithms to annotate free text with criteria from the Diagnostic and Statistical Manual of Mental Disorders (DSM) and demonstrate scope, feasibility and usefulness by focusing on Autism Spectrum Disorders (ASD) where prevalence is increasing and much rich clinical text is stored in electronic health records (EHR).",Enabling large-scale research on autism spectrum disorders through automated processing of EHR using natural language understanding,9381416,R21HS024988,[' '],AHRQ,UNIVERSITY OF ARIZONA,R21,2017,146202,0.010590899438505904
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes ﻿    DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9210555,K01HL124045,"['Address', 'Adult', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Government Agencies', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Population Study', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Risk stratification', 'Safety', 'Science', 'Site', 'Specialist', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'epidemiology study', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'point of care', 'portability', 'predictive modeling', 'professor', 'prognostic', 'prognostic tool', 'public health relevance', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2017,170856,0.07165173661562618
"NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department Summary Timely identification of relevant or “need to know” clinical information about a patient’s history in the acute care setting can be critical for patient safety and medical decision-making. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. Currently, it is estimated that over 50% of the EHR is free-text. EHR search tools today are often inefficient, simplistic, and unable to rank or evoke the relevance of information for a particular problem or complaint. This is compounded by the fact that EHRs are amassing clinical information at an exponential rate. While the benefits of having a wealth of information at a provider’s fingertips seem obvious, the time and energy cost of culling through enormous amounts of data creates new issues of decreased efficiency and information overload for providers seeking to identify the most pertinent and relevant information about their patients. In the emergency department, where patients can present with life threatening conditions, timely unlocking of clinically relevant information for a patient’s problem or complaint at the point of care can be critical to medical decision-making and patient safety. In this study, we plan to address this challenge through the development of a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information based on the patients presenting complaint. We will accomplish this through the following specific aims: 1) identify and define complaint- specific information elements within a patient’s history and 2) develop and test an NLP-based information retrieval tool. Narrative Patient safety hinges on having right information about the right patient and the right time. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. The purpose of this study is to develop and evaluate a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information from EHRs that providers rely upon to make medical decisions for their patients. This study comes at an important time where data in the EHRs is increasing at an exponential rate, creating a new problem for clinicians, that of finding all the relevant information for patient’s particular problem. This is particularly true in the emergency department setting where providers have limited if any prior relationship and often have to make quick decisions for patients with life threatening conditions. This search tool will provide a snapshot of clinically relevant information that the providers can view alongside the structured information already in the EHR. We believe this approach has the potential to increase clinician efficiency, decrease healthcare costs by avoiding duplicate diagnostic tests, and provide clinicians with the tools they need to make well-informed medical decisions, thereby improving patient safety and reducing suffering.",NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department,9342692,R21HS024541,[' '],AHRQ,UNIVERSITY OF COLORADO DENVER,R21,2017,148922,0.06121349564249143
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as “EHR-driven phenotyping” is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,9381197,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Data', 'Data Element', 'Data Quality', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Event', 'Exclusion Criteria', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare', 'Healthcare Systems', 'Human', 'Informatics', 'Intuition', 'Knowledge', 'Learning', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness', 'cost', 'data modeling', 'database query', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'interoperability', 'knowledge base', 'learning strategy', 'meetings', 'portability', 'precision medicine', 'repository', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2017,745771,0.08662084124151313
"Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record ﻿    DESCRIPTION (provided by applicant): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposed a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer, and established its feasibility. To advance this new system from a prototype to an accurate, adaptable, and robust system, integrated into the commercial EHR system used in our implementation and testing site (Huntsman Cancer Institute and University of Utah Hospital, Salt Lake City, Utah), and ready for commercialization efforts, we will work on the following aims: 1) enhance the NLP system performance, scalability, and quality, 2) develop an advanced visualization interface for local adaptation of the NLP system, and 3) integrate the NLP system with a commercial EHR system. A large and varied reference standard for training and testing the information extraction application will also be developed, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute and at the University of Utah Hospital (Salt Lake City, Utah), with problems and allergies annotated by domain experts. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare & Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and its output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment. PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.",Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record,9357564,R42CA180190,"['Adverse drug event', 'Cessation of life', 'Cities', 'Clinical', 'Code', 'Communications Media', 'Complex', 'Development', 'Disease', 'Electronic Health Record', 'Ensure', 'Environment', 'Excision', 'Goals', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'Hospitals', 'Huntsman Cancer Institute at the University of Utah', 'Hybrids', 'Hypersensitivity', 'Imagery', 'Incentives', 'Injury', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Modernization', 'Natural Language Processing', 'Outpatients', 'Output', 'Patient Care', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Savings', 'Secure', 'Site', 'Sodium Chloride', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Utah', 'Work', 'base', 'cancer care', 'commercial application', 'commercialization', 'computerized physician order entry', 'cost', 'design', 'improved', 'payment', 'prevent', 'processing speed', 'prototype', 'public health relevance', 'software development', 'standard measure', 'usability', 'web services']",NCI,"CLINACUITY,INC.",R42,2017,767485,0.09457510367320064
"EHR-based Genomic Discovery and Implementation ﻿    DESCRIPTION (provided by applicant): Electronic health record (EHR)-linked biobanks are uniquely positioned for genomic discovery and for implementing genomic medicine to improve patient care. In eMERGE I, we leveraged an EHR-linked biobank, high-density genotyping data, and electronic phenotyping algorithms to discover 29 genetic loci associated with cardiovascular traits. In eMERGE II we began implementing genomic medicine by conducting an EHR-based randomized clinical trial of disclosing genomic risk of coronary heart disease and incorporating pharmacogenomic information in the EHR with linkage to clinical decision support. In eMERGE III; we propose to build on our prior work to conduct a genomic medicine implementation project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders-familial hypercholesterolemia (FH) and familial colorectal cancer (CRC)-we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will obtain informed consent from 3000 participants of Mayo Clinic biobanks in Rochester MN and Phoenix AZ who have moderate to severe hypercholesterolemia or colon polyps. DNA will be sent for CLIA-certified targeted sequencing of 100 disease genes. We will use state-of-the-art methods to classify variant pathogenicity, finalize actionable variants for return, examine near-term outcomes, economic implications and behavioral and psychosocial consequences of such return. We will also conduct genomic discovery leveraging a network-wide data set of ~25,000 individuals with sequence data and an existing network-wide data set of ~50,000 individuals with high-density genotype data linked to the EHR. We will exploit the unique potential of the EHR to assess pleiotropy using novel approaches. In partnership with Mountain Park Health Center, a primary care practice that serves a minority population of Mexican Americans in Phoenix AZ, we will contribute high-density genotyping and phenotype data on 1000 Hispanics for genomic discovery and pilot mechanisms for implementing genomic medicine at this site. PUBLIC HEALTH RELEVANCE: Electronic health record (EHR)-linked biobanks are uniquely positioned to discover genetic variants relevant to human health and to implement genomic medicine to improve patient care. We propose to build on prior work to implement a genomic medicine project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders - familial hypercholesterolemia (FH) and familial colorectal cancer (CRC) - we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will expand our efforts to identify genetic variants relevant to human health by leveraging available network-wide data sets.",EHR-based Genomic Discovery and Implementation,9282529,U01HG006379,"['Address', 'Algorithms', 'Behavioral', 'Bioinformatics', 'CLIA certified sequencing', 'Cardiovascular system', 'Clinic', 'Clinical', 'Colonic Polyps', 'Colorectal Cancer', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomic medicine', 'Genomics', 'Genotype', 'Health', 'Hereditary Disease', 'Hispanics', 'Human', 'Individual', 'Informed Consent', 'Insurance Coverage', 'Link', 'Lipids', 'Low income', 'Medical Economics', 'Methods', 'Mexican Americans', 'Minority', 'Natural Language Processing', 'Outcome', 'Participant', 'Pathogenicity', 'Patient Care', 'Patient-Focused Outcomes', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Plasma', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Public Health', 'Randomized Clinical Trials', 'Reaction', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Risk', 'Site', 'Therapeutic Intervention', 'Translating', 'Treatment/Psychosocial Effects', 'Variant', 'Work', 'base', 'biobank', 'clinical decision-making', 'clinically actionable', 'cohort', 'community based practice', 'cost', 'density', 'economic implication', 'genetic variant', 'genomic data', 'health care disparity', 'health care service utilization', 'hypercholesterolemia', 'improved', 'interest', 'multidisciplinary', 'novel strategies', 'phenotypic data', 'pleiotropism', 'point of care', 'psychosocial', 'public health relevance', 'rare variant', 'screening', 'targeted sequencing', 'trait', 'treatment response', 'variant of unknown significance']",NHGRI,MAYO CLINIC ROCHESTER,U01,2017,840645,0.024921476546033217
"EHR-based Genomic Discovery and Implementation ﻿    DESCRIPTION (provided by applicant): Electronic health record (EHR)-linked biobanks are uniquely positioned for genomic discovery and for implementing genomic medicine to improve patient care. In eMERGE I, we leveraged an EHR-linked biobank, high-density genotyping data, and electronic phenotyping algorithms to discover 29 genetic loci associated with cardiovascular traits. In eMERGE II we began implementing genomic medicine by conducting an EHR-based randomized clinical trial of disclosing genomic risk of coronary heart disease and incorporating pharmacogenomic information in the EHR with linkage to clinical decision support. In eMERGE III; we propose to build on our prior work to conduct a genomic medicine implementation project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders-familial hypercholesterolemia (FH) and familial colorectal cancer (CRC)-we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will obtain informed consent from 3000 participants of Mayo Clinic biobanks in Rochester MN and Phoenix AZ who have moderate to severe hypercholesterolemia or colon polyps. DNA will be sent for CLIA-certified targeted sequencing of 100 disease genes. We will use state-of-the-art methods to classify variant pathogenicity, finalize actionable variants for return, examine near-term outcomes, economic implications and behavioral and psychosocial consequences of such return. We will also conduct genomic discovery leveraging a network-wide data set of ~25,000 individuals with sequence data and an existing network-wide data set of ~50,000 individuals with high-density genotype data linked to the EHR. We will exploit the unique potential of the EHR to assess pleiotropy using novel approaches. In partnership with Mountain Park Health Center, a primary care practice that serves a minority population of Mexican Americans in Phoenix AZ, we will contribute high-density genotyping and phenotype data on 1000 Hispanics for genomic discovery and pilot mechanisms for implementing genomic medicine at this site. PUBLIC HEALTH RELEVANCE: Electronic health record (EHR)-linked biobanks are uniquely positioned to discover genetic variants relevant to human health and to implement genomic medicine to improve patient care. We propose to build on prior work to implement a genomic medicine project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders - familial hypercholesterolemia (FH) and familial colorectal cancer (CRC) - we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will expand our efforts to identify genetic variants relevant to human health by leveraging available network-wide data sets.",EHR-based Genomic Discovery and Implementation,9481916,U01HG006379,"['Address', 'Algorithms', 'Behavioral', 'Bioinformatics', 'CLIA certified sequencing', 'Cardiovascular system', 'Clinic', 'Clinical', 'Colonic Polyps', 'Colorectal Cancer', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomic medicine', 'Genomics', 'Genotype', 'Health', 'Hereditary Disease', 'Hispanics', 'Human', 'Individual', 'Informed Consent', 'Insurance Coverage', 'Link', 'Lipids', 'Low income', 'Medical Economics', 'Methods', 'Mexican Americans', 'Minority', 'Natural Language Processing', 'Outcome', 'Participant', 'Pathogenicity', 'Patient Care', 'Patient-Focused Outcomes', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Plasma', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Public Health', 'Randomized Clinical Trials', 'Reaction', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Risk', 'Site', 'Therapeutic Intervention', 'Translating', 'Treatment/Psychosocial Effects', 'Variant', 'Work', 'base', 'biobank', 'clinical decision-making', 'clinically actionable', 'cohort', 'community based practice', 'cost', 'density', 'economic implication', 'genetic variant', 'genomic data', 'health care disparity', 'health care service utilization', 'hypercholesterolemia', 'improved', 'interest', 'multidisciplinary', 'novel strategies', 'phenotypic data', 'pleiotropism', 'point of care', 'psychosocial', 'public health relevance', 'rare variant', 'screening', 'targeted sequencing', 'trait', 'treatment response', 'variant of unknown significance']",NHGRI,MAYO CLINIC ROCHESTER,U01,2017,98698,0.024921476546033217
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9389934,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Caring', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'Computerized Medical Record', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic screening method', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hereditary Disease', 'Heritability', 'Individual', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Preclinical Drug Evaluation', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'case-based', 'epidemiology study', 'evaluation/testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'programs', 'screening', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2017,520081,0.049222846950836736
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,9132834,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'learning strategy', 'model building', 'model development', 'novel', 'open source', 'real world application', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,463405,0.03945738904599107
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,9115996,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'profiles in patients', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2016,387966,0.07305810936392906
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,9275795,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2016,305257,0.057239751766122594
"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",EHR Anticoagulants Pharmacovigilance,8976618,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2016,832278,0.057239751766122594
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,9033918,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2016,562809,0.1021838402010993
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,9187058,R00LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Structure', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'health care delivery', 'improved', 'learning strategy', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2016,251021,0.053831220473555555
"Natural Language Question Understanding for Electronic Health Records ﻿    DESCRIPTION (provided by applicant): Patient information in the electronic health record (EHR) such as lab results, medications, and past medical history is the basis for physician decisions about patient care. It also helps patients better understand and manage their care. Efficient access to this patient information is thus essential. One of the most intuitive ways of accessing data is by asking natural language questions. A significant amount of work in medical question answering has been conducted, yet little work has been performed in question answering for EHRs. Natural language questions can be represented in logical forms, a standard structured knowledge representation technique. This project proposes to take natural language EHR questions, both for doctors and patients, and automatically convert them to a logical form. The logical forms can then be converted to a structured query such as those used by EHRs. A major obstacle to this approach is the lack of data containing questions annotated with logical forms. This project hypothesizes that a small set of questions can be manually annotated, and then paraphrases can be produced for each annotated question. Since paraphrasing is a simpler task than logical form annotation, crowd-sourcing techniques can be used to collect thousands of question paraphrases. This question paraphrase corpus will then be used to build a semantic grammar capable of recognizing the logical structure of EHR questions. To ensure a robust, generalizable grammar, existing NLP techniques will be used to pre-process questions, simplifying their syntactic structure and abstracting their medical concepts.     In order to develop such a method, the candidate, Dr. Kirk Roberts, requires additional training and mentoring in natural language processing and biomedical informatics. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Roberts to achieve the goals of this project as well as transition to a career as an independent researcher. He will be mentored by Dr. Dina Demner-Fushman, a leading medical NLP researcher, and co-mentored by Dr. Clement McDonald, a leading EHR and medical informatics researcher.     The specific aims of the project are: (1) Build a paraphrase collection of EHR questions, where each prototype question will have many unique paraphrases. The paraphrases encompass different lexical and syntactic means of conveying the same logical form. (2) Construct a semantic grammar for EHR questions. The grammar can then be used to convert a natural language question to a logical form. (3) Implement an end- to-end question analyzer that generalizes EHR questions for improved parsing, parses the question into a logical form using the grammar, and converts the logical form into a leading structured EHR query format. PROJECT NARRATIVE The proposed work aims to significantly improve the ability of both doctors and patients to find information within electronic health records (EHR). By providing an interface to EHRs where users can specify their information needs in the form of a natural language question, the proposed work provides a more intuitive means of finding patient data than is currently available.",Natural Language Question Understanding for Electronic Health Records,9228509,R00LM012104,"['Artificial Intelligence', 'Award', 'Blood Glucose', 'Caring', 'Clinical', 'Collection', 'Computer software', 'Data', 'Development Plans', 'Electronic Health Record', 'Ensure', 'Glucose', 'Goals', 'Health', 'Knowledge', 'Literature', 'Medical', 'Medical History', 'Medical Informatics', 'Mentors', 'Methods', 'Natural Language Processing', 'Pathway interactions', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Semantics', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'TimeLine', 'Training', 'United States National Institutes of Health', 'Work', 'abstracting', 'base', 'biomedical informatics', 'career', 'career development', 'crowdsourcing', 'data access', 'database structure', 'design', 'health data', 'illiterate', 'improved', 'information organization', 'lexical', 'natural language', 'open source', 'operation', 'phrases', 'prototype', 'syntax']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R00,2016,249000,0.05743936357234501
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death. PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.",Identification of Patients with Low Life Expectancy,9115065,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,227891,0.033614668698451325
"Extended Methods and Software Development for Health NLP PROJECT SUMMARY There is a deluge of health-related texts in many genres, from the clinical narrative to newswire and social media. These texts are diverse in content, format, and style, and yet they represent complementary facets of biomedical and health knowledge. Natural Language Processing (NLP) holds much promise to extract, understand, and distill valuable information from these overwhelming large and complex streams of data, with the ultimate goal to advance biomedicine and impact the health and wellbeing of patients. There have been a number of success stories in various biomedical NLP applications, but the NLP methods investigated are usually tailored to one specific phenotype and one institution, thus reducing portability and scalability. Moreover, while there has been much work in the processing of clinical texts, other genres of health texts, like narratives and posts authored by health consumers and patients, are lacking solutions to marshal and make sense of the health information they contain. Robust NLP solutions that answer the needs of biomedicine and health in general have not been fully investigated yet. A unified, data-science approach to health NLP enables the exploration of methods and solutions unprecedented up to now.  Our vision is to unravel the information buried in the health narratives by advancing text-processing methods in a unified way across all the genres of texts. The crosscutting theme is the investigation of methods for health NLP (hNLP) made possible by big data, fused with health knowledge. Our proposal moves the field into exploring semi-supervised and fully unsupervised methods, which only succeed when very large amounts of data are leveraged and knowledge is injected into the methods with care. Our hNLP proposal also targets a key challenge of current hNLP research: the lack of shared software. We seek to provide a clearinghouse for software created under this proposal, and as such all developed tools will be disseminated. Starting from the data characteristics of health texts and information needs of stakeholders, we will develop and evaluate methods for information extraction, information understanding. We will translate our research into the publicly available NLP software platform cTAKES, through robust modules for extraction and understanding across all genres of health texts. We will also demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine, to participatory medicine. Finally, we will disseminate our work through community activities, such as challenges to advance the state of the art in health natural language processing. PROJECT NARRATIVE  There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,9029656,R01GM114355,"['Apache', 'Benchmarking', 'Big Data', 'Caring', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Event', 'Foundations', 'Goals', 'Gold', 'Health', 'Information Resources', 'Institution', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Link', 'Literature', 'Marshal', 'Medicine', 'Methods', 'Names', 'Natural Language Processing', 'Ontology', 'Patients', 'Phenotype', 'Philosophy', 'Process', 'Public Health', 'Research', 'Semantics', 'Solid', 'Stream', 'System', 'Terminology', 'Text', 'Translating', 'Translational Research', 'Vision', 'Work', 'commercialization', 'design', 'health knowledge', 'improved', 'information organization', 'novel', 'point of care', 'portability', 'precision medicine', 'programs', 'social media', 'software development', 'success', 'syntax', 'tool', 'translational medicine']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2016,844963,0.06544120305770963
"Automated Detection of Anomalous Accesses to Electronic Health Records DESCRIPTION (provided by applicant): Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in is infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems. As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,9143798,R01LM010207,"['Accounting', 'Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Healthcare Systems', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data access', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward', 'web portal']",NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2016,341475,0.04941442276411166
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy ﻿    DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9134798,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'response', 'senior faculty', 'skills', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2016,855289,0.06839775224295544
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy ﻿    DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9247889,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'response', 'senior faculty', 'skills', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2016,54784,0.06839775224295544
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy ﻿    DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics. PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,9358502,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'learning strategy', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'response', 'senior faculty', 'skills', 'success', 'support tools', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2016,62400,0.06839775224295544
"Use Frailty Status to Predict Postoperative Outcomes in Elderly Patient Frailty is increasingly recognized as a leading indicator of poor health outcomes, even death, as well as a barometer of how well patients respond to treatment. To truly provide patient-centered care, providers should be aware of each patient's frailty status and incorporate it into clinical decision making. Providers can now offer a number of invasive and aggressive procedures for cardiovascular disease, which involve risk, and can be painful. The treatment intensity need to match the expected patient outcome, yet providers do not have a reliable method to estimate prognosis for frail patients. In the study proposed here, we will use a novel approach that leverages the electronic health record (EHR) in identifying patient frailty status, with the goal of supporting retrospective clinical studies and prospective clinical decision making. Our preliminary studies have demonstrated the availability of frailty-related findings in EHR, the feasibility of extracting frailty findings, and the feasibility of using EHR-extracted frailty for outcome prediction. The specific aims of the project are to 1) Create a frailty ontology building on existing functional status and quality of life measurements; 2) Develop ontology guided, natural language processing (NLP) methods for extracting frailty descriptions and measurements; 3) Develop a model to aggregate NLP-extracted frailty findings to generate a patient-level frailty score; 4) Examine the all-cause mortality and all-cause hospital readmission one year after major cardiac procedures in heart failure patients with different frailty scores and assess the impact of this information on surgical decision making. Frailty is an important, but often overlooked, determinant of health outcomes in older adults. Providers can now offer invasive and aggressive treatments for various conditions, but these interventions involve risk and careful patient selection that balances risk and benefit is imperative. We will develop automated methods to extract frailty information from clinical records and generate an aggregated frailty score, which will enable retrospective analyses of EHR data for risk prediction and support prospective clinical decisional making.",Use Frailty Status to Predict Postoperative Outcomes in Elderly Patient,9354376,R56AG052536,"['Address', 'Affect', 'American', 'Atrial Fibrillation', 'Benefits and Risks', 'Cardiac', 'Cardiac Surgery procedures', 'Cardiovascular Diseases', 'Caregivers', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collection', 'Comorbidity', 'Critical Care', 'Data', 'Data Sources', 'Databases', 'Decision Making', 'Devices', 'Dimensions', 'Disease', 'Documentation', 'Elderly', 'Electronic Health Record', 'Equilibrium', 'Fatigue', 'Goals', 'Health', 'Heart failure', 'Hospitalization', 'Implantable Defibrillators', 'Informatics', 'Intervention', 'Investigation', 'Life', 'Life Expectancy', 'Malnutrition', 'Measurement', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Modeling', 'Natural Language Processing', 'Ontology', 'Operative Surgical Procedures', 'Outcome', 'Pain', 'Patient Care', 'Patient Selection', 'Patient-Centered Care', 'Patient-Focused Outcomes', 'Patients', 'Perioperative', 'Population', 'Postoperative Period', 'Procedures', 'Provider', 'Quality of life', 'Records', 'Research Personnel', 'Risk', 'Technology', 'Veterans', 'base', 'clinical decision-making', 'cohort', 'comparative effectiveness', 'exercise capacity', 'frailty', 'functional status', 'hospital readmission', 'indexing', 'individualized medicine', 'interest', 'mortality', 'novel strategies', 'older patient', 'outcome forecast', 'outcome prediction', 'patient population', 'predictive modeling', 'prospective', 'treatment choice', 'treatment planning', 'trend']",NIA,GEORGE WASHINGTON UNIVERSITY,R56,2016,616197,0.04188022764157706
"Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients Project Summary Epilepsy is one of the leading neurological disorders in the United States, affecting more than 479,000 children and over 2 million adults. Approximately 30% of epileptic patients have poor seizure control despite antiepileptic medications and are potential candidates for neurosurgical intervention. Early identification and referral of children who are potential surgical candidates is complex and while relevant guidelines exist, there is no standard process to efficiently identify those patients meeting criteria for neurosurgical intervention. Given the large corpus of note-based data available in the electronic health record (EHR), it is challenging for providers to efficiently retain and process all the pertinent patient information. Natural Language Processing (NLP) and machine learning techniques have been successfully used to evaluate clinical notes and make recommendations in the research setting. However, NLP techniques are rarely integrated into practice to provide real-time clinical decision support. We developed and retrospectively evaluated a NLP system to help identify those patients who meet neurosurgical criteria and therefore enable surgical consults and evaluations to occur sooner. Knowing clinical decision support can improve outcomes of care, our proposed research will implement NLP into clinical practice and develop a decision support mechanism to improve the time to surgery for eligible patients. The objective of this project is to implement NLP directly into clinical care and determine the most effective decision support mechanism for provider adherence to epilepsy surgical consult recommendations. The long- term goal of this project is to reduce the time to initial surgery evaluation for patients with intractable epilepsy by integrating NLP-classification criteria into clinical practice. This project is one of the first in the field to study the integration of NLP recommendations into clinical care. We will use a human factors engineering framework to design and to analyze two different alerting methodologies for the best-fit for clinical workflow to produce the optimum provider adherence while reducing alert fatigue. Epilepsy progress notes can be classified across hospitals, and if successful, the system will be implemented in additional pediatric institutions around the United States. Project Narrative Epilepsy affects more than 479,000 children; 30% of those are not controlled with medication and may require surgery. We developed a novel Natural Language Processing (NLP) algorithm that can be integrated into neurology practice to detect patients who may be eligible for epilepsy surgical consults. Once implemented, this research can help to drive successful implementations of NLP and identify and use ideal alerting mechanisms in neurological care.",Optimal Methods for Notifying Clinicians about Epilepsy Surgery Patients,9222109,R21HS024977,[' '],AHRQ,CINCINNATI CHILDRENS HOSP MED CTR,R21,2016,137233,0.04191660507322299
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",9115724,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patient Care', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Structure', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'application programming interface', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'personalized medicine', 'tool', 'trend analysis']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2016,335217,0.109925388337497
"Secondary use of EMRs for surgical complication surveillance DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.",Secondary use of EMRs for surgical complication surveillance,9050675,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'abstracting', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'meetings', 'patient safety', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2016,300000,0.07667980954354772
"Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing ﻿    DESCRIPTION (provided by applicant): The adoption of Electronic Health Record (EHR) systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format, with tremendous potentials, but also equally growing concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfill the potentials for high quality healthcare, improved healthcare management, and effective clinical research. NIH expects that larger research projects share their research data in a way that protects the confidentiality of the research subjects. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data, and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes, and de-identification of clinical text is a tedious ad costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for much faster de- identification than manual approaches. Clinacuity, Inc. proposes to develop a new system to automatically de-identify clinical notes found in the EHR, to then improve the availability of clinical text for secondary uses, as well as ameliorate the protection of patient data confidentiality. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the text de-identification application, a reference standard that will include a random sample of clinical narratives with protected health information annotated by domain experts; 2) develop a prototype to automatically de-identify clinical text in near real-time, a prototype that will implement a novel stepwise hybrid approach to maximize sensitivity first (our priority for de-identification), and then filter out false positives to enhance positive predictive value, and also replace PHI with realistic substitutes for improved protection; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing, and also train and test the prototype with a reference standard from another healthcare organization. Commercial application: To strengthen patient information confidentiality protection, the HITECH Act heightened financial penalties incurred for breaches of PHI, even introducing criminal penalties. These new severe consequences for violation of patient information confidentiality render protection requirements even more obvious, and automatic high-accuracy clinical text de-identification, as offered by the system Clinacuity proposes, will strongly help healthcare and clinical research organizations avoid such consequences. This system has potential commercial applications in clinical research and in healthcare settings. It will improve access to richer, more detailed, and more accurate clinical data (in clinical text) for clinical researchers. It will also ease research data sharing, and help healthcare organizations protect patient data confidentiality. PUBLIC HEALTH RELEVANCE: The adoption of Electronic Health Record systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical daa becoming available in electronic format, with tremendous potentials, but also equally growing concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfil the potentials for high quality healthcare and effective clinical research. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data, and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes that have been dictated and transcribed or directly typed in, and de-identification of clinical text is a tedious and costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for much faster de-identification than manual approaches. The overall goal of this project is to develop a new system to automatically de-identify clinical narrative text in he Electronic Health Record, to then improve the availability of clinical text for secondary uses, as well as ameliorate the protection of patient data confidentiality.",Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing,8982010,R41GM116479,"['Abbreviations', 'Adoption', 'Affect', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Confidentiality of Patient Information', 'Consent', 'Data', 'Direct Costs', 'Electronic Health Record', 'Electronics', 'Enrollment', 'Eponyms', 'Gilbert Disease', 'Goals', 'Growth', 'Health', 'Health Care Research', 'Health Insurance Portability and Accountability Act', 'Healthcare', 'Hybrids', 'Improve Access', 'Incentives', 'Informed Consent', 'Manuals', 'Measurement', 'Measures', 'Methods', 'National Institute of General Medical Sciences', 'Natural Language Processing', 'Patient Care', 'Patient Data Privacy', 'Patients', 'Population', 'Predictive Value', 'Privacy', 'Reference Standards', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrospective Studies', 'Risk', 'Sampling', 'Structure', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'United States National Institutes of Health', 'Validation', 'Vision', 'Work', 'base', 'commercial application', 'common rule', 'data sharing', 'flexibility', 'health care quality', 'improved', 'novel', 'patient privacy', 'payment', 'prototype', 'statistics', 'text searching']",NIGMS,"CLINACUITY,INC.",R41,2016,223924,0.04127075796803885
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics ﻿    DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities.         PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.            ",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9094161,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Award', 'Benefits and Risks', 'CCL4 gene', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Intervention', 'Learning', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'interest', 'novel', 'open source', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2016,652772,0.04361768583817861
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),9206595,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Source', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Update', 'Validation', 'Work', 'alcohol research', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'repository', 'therapy design', 'tool']",NIAAA,YALE UNIVERSITY,U24,2016,311314,-0.022073069000700787
"Temporal relation discovery for clinical text ﻿    DESCRIPTION (provided by applicant):         The overarching long-term vision of our research is to create novel technologies for processing clinical free text. We will build upon the previous work of our ongoing project ""Temporal relation discovery for clinical text"" (R01LM010090) dubbed Temporal Histories of Your Medical Events (THYME; thyme.healthnlp.org) which has been focusing on methodology for event, temporal expressions and temporal relations discovery from the clinical text residing in the Electronic Health Records (EHR). We developed a comprehensive approach to temporality in the clinical text and innovated in computable temporal representations, methods for temporal relation discovery and their evaluation, rendering temporality to end users - resulting in over 35+ papers and presentations. Our dissemination is international and far-reaching as the best performing methods are released open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (ctakes.apache.org). The methods we developed are now being used in such nation-wide initiatives as the Electronic Medical Records and Genomics (eMERGE), Pharmacogenomics Network (PGRN), Informatics for Integrating the Biology and the Bedside (i2b2), Patient Centered Outcomes Research Institute and National Cancer Institute's Informatics Technology for Cancer Research (ITCR). Through our participation in organizing major international bakeoffs - CLEF/ShARe 2014, SemEval 2014 Analysis of Clinical Text Task 7, SemEval 2015 Analysis of Clinical Text Task 14, SemEval 2015 Clinical TempEval Task 6 - we further disseminated the THYME resources and challenged the international research community to explore new solutions to the unsolved temporality task. Through all these activities it became clear that computational approaches to temporality still present great challenges and usability of the output is still limited. Therefore, we propose to further innovate on methodologies and end user experience.             Specific Aim 1: Extract enhanced representations and novel features to support deriving timeline information.     Specific Aim 2: Develop methods to amalgamate individual patient episode timelines into an aggregate patient-level timeline.     Specific Aim 3: Mine the EHR - the unstructured clinical text and the structured codified information - for full patient-level temporality.     Specific Aim 4: Develop a comprehensive temporal visualization tool     Specific Aim 5: Develop methodology for and perform extrinsic evaluation on specific use case.     Specific Aim 6: (1) Evaluate state-of-the-art of temporal relations through organizing international challenges under the auspices of SemEval, (2) Disseminate the results through publications, presentations, and open source code in Apache cTAKES. Functional testing. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EHR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,9146765,R01LM010090,"['Apache', 'Automobile Driving', 'Biology', 'Chronology', 'Clinical', 'Collection', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Evaluation', 'Event', 'Genomics', 'Goals', 'Human', 'Imagery', 'Informatics', 'Information Retrieval', 'International', 'Joints', 'Knowledge Extraction', 'Language', 'Life', 'Link', 'Machine Learning', 'Malignant neoplasm of brain', 'Medical', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Multiple Sclerosis', 'National Cancer Institute', 'Outcomes Research', 'Output', 'Paper', 'Patient-Focused Outcomes', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Process', 'Publications', 'Recording of previous events', 'Records', 'Research', 'Research Institute', 'Resolution', 'Resources', 'Science', 'Semantics', 'Signs and Symptoms', 'Source Code', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Thyme', 'Time', 'TimeLine', 'Translating', 'Translational Research', 'Trees', 'Vision', 'Work', 'abstracting', 'anticancer research', 'autism spectrum disorder', 'clinically relevant', 'data mining', 'experience', 'individual patient', 'innovation', 'new technology', 'next generation', 'novel', 'open source', 'symptom treatment', 'syntax', 'tool', 'usability']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2016,643863,0.013496523760124399
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)  DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a tool to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,9110716,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Assistant', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Underrepresented Students', 'Validity and Reliability', 'Work', 'computer science', 'curriculum enhancement', 'falls', 'forging', 'high risk', 'improved', 'interest', 'learning strategy', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social media', 'tool', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2016,245338,0.042030679398829665
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)  DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a tool to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,9349080,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Assistant', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Underrepresented Students', 'Validity and Reliability', 'Work', 'computer science', 'curriculum enhancement', 'falls', 'forging', 'high risk', 'improved', 'interest', 'learning strategy', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social media', 'tool', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2016,25000,0.042030679398829665
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes ﻿    DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases. PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,9031137,K01HL124045,"['Address', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronics', 'Epidemiologic Studies', 'Epidemiology', 'Genomics', 'Goals', 'Government', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Mining', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Safety', 'Science', 'Site', 'Specialist', 'Stratification', 'Stroke', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'experience', 'health information technology', 'high risk', 'improved', 'improved outcome', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'physical symptom', 'point of care', 'population based', 'predictive modeling', 'professor', 'prognostic', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2016,170856,0.07165173661562618
"Encoding and Processing Patient Allergy Information in EHRs DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use. PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.",Encoding and Processing Patient Allergy Information in EHRs,9142280,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2016,491053,0.06851199347786183
"NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department Summary Timely identification of relevant or “need to know” clinical information about a patient’s history in the acute care setting can be critical for patient safety and medical decision-making. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. Currently, it is estimated that over 50% of the EHR is free-text. EHR search tools today are often inefficient, simplistic, and unable to rank or evoke the relevance of information for a particular problem or complaint. This is compounded by the fact that EHRs are amassing clinical information at an exponential rate. While the benefits of having a wealth of information at a provider’s fingertips seem obvious, the time and energy cost of culling through enormous amounts of data creates new issues of decreased efficiency and information overload for providers seeking to identify the most pertinent and relevant information about their patients. In the emergency department, where patients can present with life threatening conditions, timely unlocking of clinically relevant information for a patient’s problem or complaint at the point of care can be critical to medical decision-making and patient safety. In this study, we plan to address this challenge through the development of a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information based on the patients presenting complaint. We will accomplish this through the following specific aims: 1) identify and define complaint- specific information elements within a patient’s history and 2) develop and test an NLP-based information retrieval tool. Narrative Patient safety hinges on having right information about the right patient and the right time. Often the relevant information is buried in unstructured or free-text narratives within the Electronic Health Record (EHR), making it difficult to access in a timely fashion. The purpose of this study is to develop and evaluate a sophisticated natural language processing (NLP) search tool to automatically identify and rank clinically relevant information from EHRs that providers rely upon to make medical decisions for their patients. This study comes at an important time where data in the EHRs is increasing at an exponential rate, creating a new problem for clinicians, that of finding all the relevant information for patient’s particular problem. This is particularly true in the emergency department setting where providers have limited if any prior relationship and often have to make quick decisions for patients with life threatening conditions. This search tool will provide a snapshot of clinically relevant information that the providers can view alongside the structured information already in the EHR. We believe this approach has the potential to increase clinician efficiency, decrease healthcare costs by avoiding duplicate diagnostic tests, and provide clinicians with the tools they need to make well-informed medical decisions, thereby improving patient safety and reducing suffering.",NLP to Identify and Rank Clinically Relevant Information for EHRs in the Emergency Department,9245525,R21HS024541,[' '],AHRQ,UNIVERSITY OF COLORADO DENVER,R21,2016,148922,0.06121349564249143
"Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record ﻿    DESCRIPTION (provided by applicant): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposed a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer, and established its feasibility. To advance this new system from a prototype to an accurate, adaptable, and robust system, integrated into the commercial EHR system used in our implementation and testing site (Huntsman Cancer Institute and University of Utah Hospital, Salt Lake City, Utah), and ready for commercialization efforts, we will work on the following aims: 1) enhance the NLP system performance, scalability, and quality, 2) develop an advanced visualization interface for local adaptation of the NLP system, and 3) integrate the NLP system with a commercial EHR system. A large and varied reference standard for training and testing the information extraction application will also be developed, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute and at the University of Utah Hospital (Salt Lake City, Utah), with problems and allergies annotated by domain experts. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare & Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and its output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment.         PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.           ",Automated Problem and Allergy Lists Enrichment Based on High Accuracy Information Extraction from the Electronic Health Record,9138574,R42CA180190,"['Adverse drug event', 'Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinical', 'Code', 'Communications Media', 'Complex', 'Development', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Environment', 'Excision', 'Goals', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'Hospitals', 'Huntsman Cancer Institute at the University of Utah', 'Hybrids', 'Hypersensitivity', 'Imagery', 'Incentives', 'Injury', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Process', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Secure', 'Site', 'Sodium Chloride', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Utah', 'Work', 'base', 'commercial application', 'commercialization', 'computerized physician order entry', 'design', 'improved', 'payment', 'prevent', 'processing speed', 'prototype', 'public health relevance', 'software development', 'standard measure', 'usability', 'web services']",NCI,"CLINACUITY,INC.",R42,2016,684880,0.09457510367320064
"EHR-based Genomic Discovery and Implementation ﻿    DESCRIPTION (provided by applicant): Electronic health record (EHR)-linked biobanks are uniquely positioned for genomic discovery and for implementing genomic medicine to improve patient care. In eMERGE I, we leveraged an EHR-linked biobank, high-density genotyping data, and electronic phenotyping algorithms to discover 29 genetic loci associated with cardiovascular traits. In eMERGE II we began implementing genomic medicine by conducting an EHR-based randomized clinical trial of disclosing genomic risk of coronary heart disease and incorporating pharmacogenomic information in the EHR with linkage to clinical decision support. In eMERGE III; we propose to build on our prior work to conduct a genomic medicine implementation project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders-familial hypercholesterolemia (FH) and familial colorectal cancer (CRC)-we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will obtain informed consent from 3000 participants of Mayo Clinic biobanks in Rochester MN and Phoenix AZ who have moderate to severe hypercholesterolemia or colon polyps. DNA will be sent for CLIA-certified targeted sequencing of 100 disease genes. We will use state-of-the-art methods to classify variant pathogenicity, finalize actionable variants for return, examine near-term outcomes, economic implications and behavioral and psychosocial consequences of such return. We will also conduct genomic discovery leveraging a network-wide data set of ~25,000 individuals with sequence data and an existing network-wide data set of ~50,000 individuals with high-density genotype data linked to the EHR. We will exploit the unique potential of the EHR to assess pleiotropy using novel approaches. In partnership with Mountain Park Health Center, a primary care practice that serves a minority population of Mexican Americans in Phoenix AZ, we will contribute high-density genotyping and phenotype data on 1000 Hispanics for genomic discovery and pilot mechanisms for implementing genomic medicine at this site. PUBLIC HEALTH RELEVANCE: Electronic health record (EHR)-linked biobanks are uniquely positioned to discover genetic variants relevant to human health and to implement genomic medicine to improve patient care. We propose to build on prior work to implement a genomic medicine project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders - familial hypercholesterolemia (FH) and familial colorectal cancer (CRC) - we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will expand our efforts to identify genetic variants relevant to human health by leveraging available network-wide data sets.",EHR-based Genomic Discovery and Implementation,9134797,U01HG006379,"['Address', 'Algorithms', 'Behavioral', 'Bioinformatics', 'CLIA certified sequencing', 'Cardiovascular system', 'Clinic', 'Clinical', 'Colonic Polyps', 'Colorectal Cancer', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Electronics', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomic medicine', 'Genomics', 'Genotype', 'Health', 'Hereditary Disease', 'Hispanics', 'Human', 'Individual', 'Informed Consent', 'Insurance Coverage', 'Link', 'Lipids', 'Low income', 'Medical Economics', 'Methods', 'Mexican Americans', 'Minority', 'Natural Language Processing', 'Outcome', 'Participant', 'Pathogenicity', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Plasma', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Public Health', 'Randomized Clinical Trials', 'Reaction', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Risk', 'Site', 'Translating', 'Treatment/Psychosocial Effects', 'Variant', 'Work', 'base', 'biobank', 'clinical decision-making', 'clinically actionable', 'cohort', 'community based practice', 'cost', 'density', 'economic implication', 'electronic data', 'genetic variant', 'genomic data', 'health care disparity', 'health care service utilization', 'hypercholesterolemia', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'novel therapeutic intervention', 'pleiotropism', 'point of care', 'psychosocial', 'rare variant', 'screening', 'targeted sequencing', 'trait', 'treatment response', 'variant of unknown significance']",NHGRI,MAYO CLINIC ROCHESTER,U01,2016,849369,0.024921476546033217
"EHR-based Genomic Discovery and Implementation ﻿    DESCRIPTION (provided by applicant): Electronic health record (EHR)-linked biobanks are uniquely positioned for genomic discovery and for implementing genomic medicine to improve patient care. In eMERGE I, we leveraged an EHR-linked biobank, high-density genotyping data, and electronic phenotyping algorithms to discover 29 genetic loci associated with cardiovascular traits. In eMERGE II we began implementing genomic medicine by conducting an EHR-based randomized clinical trial of disclosing genomic risk of coronary heart disease and incorporating pharmacogenomic information in the EHR with linkage to clinical decision support. In eMERGE III; we propose to build on our prior work to conduct a genomic medicine implementation project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders-familial hypercholesterolemia (FH) and familial colorectal cancer (CRC)-we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will obtain informed consent from 3000 participants of Mayo Clinic biobanks in Rochester MN and Phoenix AZ who have moderate to severe hypercholesterolemia or colon polyps. DNA will be sent for CLIA-certified targeted sequencing of 100 disease genes. We will use state-of-the-art methods to classify variant pathogenicity, finalize actionable variants for return, examine near-term outcomes, economic implications and behavioral and psychosocial consequences of such return. We will also conduct genomic discovery leveraging a network-wide data set of ~25,000 individuals with sequence data and an existing network-wide data set of ~50,000 individuals with high-density genotype data linked to the EHR. We will exploit the unique potential of the EHR to assess pleiotropy using novel approaches. In partnership with Mountain Park Health Center, a primary care practice that serves a minority population of Mexican Americans in Phoenix AZ, we will contribute high-density genotyping and phenotype data on 1000 Hispanics for genomic discovery and pilot mechanisms for implementing genomic medicine at this site. PUBLIC HEALTH RELEVANCE: Electronic health record (EHR)-linked biobanks are uniquely positioned to discover genetic variants relevant to human health and to implement genomic medicine to improve patient care. We propose to build on prior work to implement a genomic medicine project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders - familial hypercholesterolemia (FH) and familial colorectal cancer (CRC) - we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will expand our efforts to identify genetic variants relevant to human health by leveraging available network-wide data sets.",EHR-based Genomic Discovery and Implementation,9336097,U01HG006379,"['Address', 'Algorithms', 'Behavioral', 'Bioinformatics', 'CLIA certified sequencing', 'Cardiovascular system', 'Clinic', 'Clinical', 'Colonic Polyps', 'Colorectal Cancer', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Electronics', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomic medicine', 'Genomics', 'Genotype', 'Health', 'Hereditary Disease', 'Hispanics', 'Human', 'Individual', 'Informed Consent', 'Insurance Coverage', 'Link', 'Lipids', 'Low income', 'Medical Economics', 'Methods', 'Mexican Americans', 'Minority', 'Natural Language Processing', 'Outcome', 'Participant', 'Pathogenicity', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Plasma', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Public Health', 'Randomized Clinical Trials', 'Reaction', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Risk', 'Site', 'Translating', 'Treatment/Psychosocial Effects', 'Variant', 'Work', 'base', 'biobank', 'clinical decision-making', 'clinically actionable', 'cohort', 'community based practice', 'cost', 'density', 'economic implication', 'electronic data', 'genetic variant', 'genomic data', 'health care disparity', 'health care service utilization', 'hypercholesterolemia', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'novel therapeutic intervention', 'pleiotropism', 'point of care', 'psychosocial', 'rare variant', 'screening', 'targeted sequencing', 'trait', 'treatment response', 'variant of unknown significance']",NHGRI,MAYO CLINIC ROCHESTER,U01,2016,233600,0.024921476546033217
"Interactive machine learning methods for clinical natural language processing DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3. Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8936515,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model building', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,448348,0.03945738904599107
"Challenges in Natural Language Processing for Clinical Narratives DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges. Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8913773,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2015,19800,0.061963252261071605
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts. PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8928647,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'query optimization', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2015,376327,0.07305810936392906
"EHR Anticoagulants Pharmacovigilance     DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page         PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.            ",EHR Anticoagulants Pharmacovigilance,8791564,R01HL125089,"['Accounting', 'Adult', 'Adverse drug event', 'Adverse event', 'Algorithms', 'Anticoagulant therapy', 'Anticoagulants', 'Anticoagulation', 'Area', 'Atrial Fibrillation', 'Biometry', 'Boxing', 'Cardiology', 'Cardiovascular Agents', 'Cardiovascular Diseases', 'Classification', 'Clinical', 'Controlled Vocabulary', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Electronic Health Record', 'Elements', 'Epidemiologic Studies', 'Etiology', 'Frequencies', 'Health', 'Health Promotion', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Illinois', 'Injury', 'Institutes', 'Intervention', 'Lead', 'Length of Stay', 'Linguistics', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Marketing', 'Massachusetts', 'Medical', 'Methods', 'Monitor', 'Morbidity - disease rate', 'Names', 'Natural Language Processing', 'Ontology', 'Outcomes Research', 'Package Insert', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Prevention', 'Product Packaging', 'Regimen', 'Reporting', 'Resources', 'Risk', 'Risk Factors', 'Route', 'Safety', 'Schedule', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Structure', 'System', 'Systems Analysis', 'Text', 'Thromboembolism', 'Time', 'Toxic effect', 'United States', 'United States Food and Drug Administration', 'Universities', 'Venous', 'Work', 'cost', 'disorder prevention', 'dosage', 'high risk', 'improved', 'innovation', 'mortality', 'novel', 'open source', 'patient safety', 'post-market', 'predictive modeling', 'tool']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2015,864744,0.057239751766122594
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications DESCRIPTION (provided by applicant): Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develp a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery. PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,8978947,K99LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Solutions', 'Structure', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'health care delivery', 'improved', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MASSACHUSETTS GENERAL HOSPITAL,K99,2015,83160,0.053831220473555555
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,8826771,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2015,571551,0.1021838402010993
"IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC) This study seeks to leverage electronic pathology (ePath) reports through NLP and machine learning methods to automate the annotation of NSCLC lung cases with results from EGFR and ALK gene mutation testing.  Objectives:  1)	Develop and implement machine-learned predictive NLP models to automatically process ePath reports to ascertain the use of and reported results of EGFR and ALK testing in stage IV non-squamous NSCLC cases.   2)	Conduct a multiphase validation study of the NLP algorithms initially involving cases included in the Kentucky SEER registry, and posteriorly validating the algorithms for cases in the Seattle_Puget Sound SEER registry. 3)	Develop and evaluate an open source, distributable software implementation of the NLP algorithms, an accompanying application programming interface (API), and documentation that can be integrated into SEER*DMS and other registry software applications. n/a",IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC),9161889,61201300013I,"['ALK gene', 'Algorithms', 'Automated Annotation', 'Computer software', 'Documentation', 'EGFR gene', 'Electronics', 'Epidermal Growth Factor Receptor', 'Gene Mutation', 'Kentucky', 'Lung', 'Machine Learning', 'Methods', 'Modeling', 'Molecular Profiling', 'Non-Small-Cell Lung Carcinoma', 'Pathology Report', 'Process', 'Registries', 'Reporting', 'Staging', 'Testing', 'c-erbB-1 Proto-Oncogenes', 'open source', 'programs', 'sound', 'validation studies']",NCI,UNIVERSITY OF KENTUCKY,N01,2015,87813,-0.017590276563981332
"IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC). The overarching goal of this research proposal is to develop and validate Natural Language Processing (NLP) algorithms for ascertainment of use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC cases.  Successful achievement of this goal will occur through the accomplishment of the study objectives outlined below.  Objectives: 1)	 Develop Natural Language Processing (NLP) algorithms to ascertain use, results, and techniques employed for EGFR and ALK testing, respectively, from SEER electronic pathology reports of stage IV non-squamous NSCLC registry cases diagnosed between 09/01/2011 and 12/31/2013. 2)	Conduct a multiphase validation study of NLP algorithms for ascertainment of EGFR and ALK testing initially involving cases included in the Seattle Puget-Sound SEER registry, and posteriorly validating the NLP algorithms in the Kentucky SEER registry. n/a",IGF::OT::IGF EXPANDING SEER TO INCLUDE MOLECULAR PROFILING IN NON-SMALL CELL LUNG CANCER (NSCLC).,9161888,61201300012I,"['Achievement', 'Algorithms', 'Cells', 'Diagnosis', 'Electronics', 'Epidermal Growth Factor Receptor', 'Goals', 'Kentucky', 'Lung', 'Molecular Profiling', 'Natural Language Processing', 'Non-Small-Cell Lung Carcinoma', 'Pathology Report', 'Registries', 'Research Proposals', 'Staging', 'Techniques', 'Testing', 'neoplasm registry', 'sound', 'validation studies']",NCI,FRED HUTCHINSON CANCER RESEARCH CENTER,N01,2015,156435,0.028679952029901125
"Identification of Patients with Low Life Expectancy ﻿    DESCRIPTION (provided by applicant): It is increasingly recognized that optimal treatment is not the same for every patient - it depends on the individual patient's circumstances. One important factor that determines the optimal clinical management is the patient's life expectancy, which determines the temporal horizon within which medical decisions have to operate. For example, while adding an extra diabetes medication may save a 40-year-old individual from going blind or developing kidney failure 20 years later, it will not bring any benefits to an 80-yer old with a metastatic malignancy who is expected to live only a few months.  Consequently, it is critical that when we measure quality of care, suggest treatment options to clinicians through clinical decision support or compare different treatment strategies, we take into account the patient's life expectancy. However, currently there are no methods available that can do this with sufficient accuracy.  Most commonly used techniques to assess a patient's mortality risk draw primarily on administrative data and other structured data fields in electronic medical records. This approach leaves out a large amount of information that is only available in narrative documents such as provider notes, radiology reports, etc. In this project we propose to test the hypothesis that application of two novel technologies - artificial intelligence technique Dynamic Logic and natural language processing (NLP) - could leverage the information in narrative electronic documents to significantly improve the accuracy of identification of patients with low life expectancy.  Dynamic Logic allows to circumvent the challenge of combinatorial complexity that limits the number of variables and their combinations that can be considered as predictors of an outcome by most currently used analytical methods. Dynamic Logic makes use of a limited number of iterative approximations to reduce the complexity of a problem with multiple predictor variables from exponential to approximately linear. Utilization of Dynamic Logic will allow us to greatly increase the richness of the models for identification of patients with low life expectancy and ultimately improve their accuracy.  Information such as the patient's functional status that is usually only found in narrative documents may be critical to improving accuracy of identifying frail patients at high mortality risk. Modern NLP techniques can effectively identify key concepts in medical text but until now analytical methods allowed consideration of only a few of pre-selected concepts in prediction models. Combining NLP with Dynamic Logic will allow us to greatly expand the number of concepts from narrative text that could be included in the life expectancy prediction model, likely leading to a considerable improvement in accuracy.  In the proposed translational multidisciplinary project our team that will include experts on artificial intelligence, natural language processing, analysis of data in electronic medical records, and geriatrics will test whether a combination of Dynamic Logic and NLP improves identification of patients at high risk of death.         PUBLIC HEALTH RELEVANCE: Identification of patients with limited life expectancy is important for accurate measurement of quality of care delivered by clinicians, clinical decision support in electronic medical records and research that compares different treatment options for patients. However, currently available methods suffer from low accuracy or use information that is not widely available. In this project we propose to combine two advanced computational technologies - artificial intelligence technique Dynamic Logic and natural language processing - to improve accuracy of identification of patients with low life expectancy.            ",Identification of Patients with Low Life Expectancy,8942806,R01HS024090,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,232521,0.033614668698451325
"Automated Detection of Anomalous Accesses to Electronic Health Records DESCRIPTION (provided by applicant): Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in is infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems. As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,8882547,R01LM010207,"['Accounting', 'Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Healthcare Systems', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Internet', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward']",NLM,VANDERBILT UNIVERSITY,R01,2015,80,0.04941442276411166
"Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy ﻿    DESCRIPTION (provided by applicant): In May 2012 Cincinnati Children's (CCHMC) joined eMERGE II with our Boston Children's partner. Since then we have developed algorithms for the electronic health record (EHR), led the Pediatric Workgroup, developed pharmacogenomics, evaluated the preferences of parents and caregivers to advance genomic medicine and assimilated technical advances into our EHR. The eMERGE effort has become the basic fabric of the institutional initiative to incorporate the extraordinary advances of genetics, genomics and the electronic medical record into healthcare. In addition, we bring a comprehensive EHR (EPIC), operating in every venue for healthcare delivery at CCHMC; a deidentified i2b2 data warehouse of 1.2 million patient records; and a Biobank with 150,000 consents that allow return of results to 38,000 patients and guardians who have provided 58,000 DNA samples, all with consent to return results and i2b2 EHR records. Now, we present our plan to join the eMERGE III network with 17 proposed initiatives. Our eMERGE effort is designed to move an entire institution with our eMERGE III partners into a genomic-EHR era of healthcare implementation and discovery. Our effort is divided into Genomics , Aim 1, where we hope to help the eMERGE III Steering Committee identify the 100 or so genes for the eMERGE III Targeted Gene Panel (eTGP), select our 2,000 CCHMC patients to be sequenced (of the 38,000 in our Biobank), review 4,000 targeted gene panels from clinical care at CCHMC for somatic mosaicism and reinterpretation, and further develop and disseminate a software workflow suite for sequence analysis (CASSI). For Phenotypes, Aim 2, we will extend our work generating EHR phenotype algorithms using heuristic and machine learning methods with a comprehensive set of EHR features derived from data driven algorithms to describe phenotypic pleiotropy of eTGP gene variants. We will develop working collaborations with Patients Care Outcomes Research Institute (PCORI) and the Million Veterans Program by applying eMERGE developed EHR algorithms to these large electronic data warehouses. For Implementation and Evaluation, Aim 3, we will develop tools to evaluate adolescent return of results preferences, examine the ethical and legal obligations and potential to reanalyze results, analyze the cost of tacrolimus management of kidney transplant with and without CYP3A5 testing, develop clinical decision support for phenotyping, test ordering, and returning eTGP results. Our success in these eMERGE III studies will be enhanced by the ongoing institutional investments made in the CCHMC BioBank, the comprehensive EHR (EPIC), and the i2b2 deidentified medical record data warehouse, and hundreds of Faculty and senior staff who make genomics or informatics an active focus of their research. We present a comprehensive program addressing all of the salient elements presented in the RFP for eMERGE III (HG-14-025) to enhance our collaborative productivity within the eMERGE Network in ways that ultimately improve our healthcare systems through discovery, implementation, and advanced applications of genomics and informatics.         PUBLIC HEALTH RELEVANCE: The Cincinnati Children's Hospital Medical Center (CCHMC) proposes to contribute as a funded site in the eMERGE III Network by pursuing a series of initiatives designed to advance genomics and the electronic health record (EHR). We propose 100 genes to evaluate by sequencing in 2,000 patients consented for return of results, to advance genomics by evaluating fee for service for DNA sequence-based genetic testing at CCHMC, to develop the reliable identification many diseases in the EHR and along with genome wide genetic testing, to explore genetic variants for alleged and unknown clinical manifestations, to extend the work of eMERGE to other large collections of EHR and genetic data, to evaluate cost benefits of genetic testing, to characterize the genetics of pain, to explor the preferences of adolescents concerning the genetic results they prefer to learn, and to explore the legal, ethical, and social issues that surround the re-interpretation of genetic variants. All of this work will be pursued with our eMERGE III Network colleagues the goal of improving the quality of the health care we deliver.                ",Better Outcomes for Children: Promoting Excellence in Healthcare Genomics to Inform Policy,8967443,U01HG008666,"['Abdominal Aortic Aneurysm', 'Address', 'Administrator', 'Adolescent', 'Algorithms', 'Appendicitis', 'Archives', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Boston', 'Budgets', 'CYP3A5 gene', 'Caregivers', 'Caring', 'Child', 'Childhood', 'Chronic Obstructive Airway Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Computer software', 'Computerized Medical Record', 'Computers', 'Consent', 'Cost Analysis', 'Costs and Benefits', 'DNA', 'DNA Sequence', 'DNA Sequence Analysis', 'Data', 'Decision Making', 'Disease', 'Dose', 'Effectiveness', 'Ehlers-Danlos Syndrome', 'Electronic Health Record', 'Electronics', 'Elements', 'Ethics', 'Evaluation', 'Faculty', 'Familial Hypercholesterolemia', 'Fee-for-Service Plans', 'Fibromyalgia', 'Foundations', 'Funding', 'Gene Targeting', 'Genes', 'Genetic', 'Genetic screening method', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Investments', 'Kidney Transplantation', 'Learning', 'Legal Obligations', 'Letters', 'Machine Learning', 'Malignant hyperpyrexia due to anesthesia', 'Medical Records', 'Medical center', 'Medicine', 'Methods', 'Methylphenidate', 'Migraine', 'Modification', 'Mosaicism', 'Narcotic Addiction', 'Natural Language Processing', 'Neonatal Abstinence Syndrome', 'Outcome', 'Outcomes Research', 'Outpatients', 'PTEN gene', 'Pain', 'Parents', 'Patient Care', 'Patients', 'Pediatric Hospitals', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Policies', 'Positioning Attribute', 'Primary Ciliary Dyskinesias', 'Process', 'Productivity', 'Pyloric Stenosis', 'Reading', 'Recommendation', 'Records', 'Research', 'Research Infrastructure', 'Research Institute', 'Research Personnel', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Series', 'Site', 'Tacrolimus', 'Testing', 'Textiles', 'Time', 'Tonsillectomy', 'Translating', 'Variant', 'Veterans', 'Work', 'base', 'biobank', 'clinical care', 'clinically actionable', 'cohort', 'data modeling', 'design', 'economic impact', 'electronic data', 'ethical legal social implication', 'follow-up', 'gene panel', 'genetic information', 'genetic variant', 'genome-wide', 'genomic variation', 'health care delivery', 'health care quality', 'heuristics', 'improved', 'interest', 'member', 'next generation sequencing', 'pleiotropism', 'preference', 'primary pulmonary hypertension', 'programs', 'public health relevance', 'response', 'skills', 'success', 'tool', 'tool development']",NHGRI,CINCINNATI CHILDRENS HOSP MED CTR,U01,2015,855289,0.06839775224295544
"An Information Fusion Approach to Longitudinal Health Records DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted. Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8906937,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved', 'screening']",NLM,OHIO STATE UNIVERSITY,R01,2015,297811,0.05321076473574123
"Patient Medical History Representation, Extraction, and Inference from EHR Data DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported. Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",8911361,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patient Care', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Solutions', 'Structure', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'base', 'clinical practice', 'cohort', 'colon cancer patients', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'personalized medicine', 'programs', 'tool', 'trend']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2015,325159,0.109925388337497
"Secondary use of EMRs for surgical complication surveillance     DESCRIPTION (provided by applicant):  Recent statistics indicate that worldwide almost 234 million major surgical procedures are performed each year with the rates of major postsurgical complications (PSCs) range from 3% to 16% and rates of permanent disability or death range from 0.4% to 0.8%. Early detection of PSCs is crucial since early intervention could be lifesaving. Meanwhile, with the rapid adoption of electronic medical records (EMRs) and the accelerated advance of health information technology (HIT), detection of PSCs by applying advanced analytics on EMRs makes it possible for near real-time PSC surveillance. We have developed a rule-based PSC surveillance system to detect most frequent colorectal PSCs near real-time from EMRs where a pattern-based natural language processing (NLP) engine is used to extract PSC related information from text and a set of expert rules is used to detect PSCs. Two challenges are identified. First, it is very challenging to integrate a diverse set of relevant data using expert rules. In the past, probabilistic approaches such as Bayesian Network which can integrate a diverse set of relevant data have become popular in clinical decision support and disease outbreak surveillance. Can we implement probabilistic approaches for PSC surveillance? Secondly, a large portion of the clinical information is embedded in text and it has been quite expensive to manually obtain the patterns used in the NLP system since it requires team effort of subject matter experts and NLP specialists. In the research field, statistical NLP has been quite popular. However, decision making in clinical practice demands tractable evidences while models for statistical NLP are not human interpretable. Can we incorporate statistical NLP to accelerate the NLP knowledge engineering process? We hypothesize that a probabilistic approach for PSC surveillance can be developed for improved case detection which can integrate multiple evidences from structured as well as unstructured EMR data. We also hypothesize that empirical NLP can accelerate the knowledge engineering process needed for building pattern- based NLP systems used in practice. Specific aims include: i) developing and evaluating an innovative Bayesian PSC surveillance system that incorporates evidences from both structured and unstructured EMR data; and ii) incorporating and evaluating statistical NLP in accelerating the NLP knowledge engineering process of pattern-based NLP for PSC surveillance. Given the significance of HIT, our study results will advance the science in developing practical NLP systems that can be translated to meet NLP needs in health care practice. Additionally, given the significance of PSCs, our study results will address significant patient safety and quality issues in surgical practice. Utilizing automated methods to detect postsurgical complications will enable early detection of complications compared to other methods and therefore have great potential of improving patient safety and health care quality while reducing cost. The results could lead to large scale PSC surveillance and quality improvement towards safer and better health care.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to unprecedented opportunities to use EMRs for clinical practice and research. We explore the use of EMRs for near real-time postsurgical complication surveillance with the aim of improving health care quality and reducing health care cost through enhanced analytics towards surgical excellence.                ",Secondary use of EMRs for surgical complication surveillance,8798027,R01EB019403,"['Abscess', 'Address', 'Adoption', 'Age', 'Anesthetics', 'Area', 'Bayesian Method', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Colorectal', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Decision Making', 'Detection', 'Development', 'Disease Outbreaks', 'Early Diagnosis', 'Early Intervention', 'Educational workshop', 'Engineering', 'Goals', 'Health Care Costs', 'Healthcare', 'Hemorrhage', 'Human', 'Ileus', 'Knowledge', 'Lead', 'Manuals', 'Methods', 'Minor', 'Motivation', 'Natural Language Processing', 'Nature', 'Nutritional', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perioperative', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Registries', 'Reporting', 'Research', 'Risk Factors', 'Science', 'Severities', 'Specialist', 'Statistical Models', 'Structure', 'Surgeon', 'Surgical complication', 'System', 'Testing', 'Text', 'Time', 'Translating', 'Uncertainty', 'Work', 'Wound Infection', 'abstracting', 'base', 'clinical practice', 'computer based statistical methods', 'cost', 'disability', 'health care quality', 'health information technology', 'improved', 'innovation', 'meetings', 'patient safety', 'public health relevance', 'rapid growth', 'statistics']",NIBIB,MAYO CLINIC ROCHESTER,R01,2015,299888,0.07667980954354772
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases. The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8917296,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,BROWN UNIVERSITY,R01,2015,342049,0.03416301249769739
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)  DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a tool to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,8932003,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Educational Curriculum', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Underrepresented Students', 'Validity and Reliability', 'Work', 'computer science', 'falls', 'forging', 'high risk', 'improved', 'interest', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social', 'tool', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2015,248507,0.042030679398829665
"Temporal relation discovery for clinical text ﻿    DESCRIPTION (provided by applicant):         The overarching long-term vision of our research is to create novel technologies for processing clinical free text. We will build upon the previous work of our ongoing project ""Temporal relation discovery for clinical text"" (R01LM010090) dubbed Temporal Histories of Your Medical Events (THYME; thyme.healthnlp.org) which has been focusing on methodology for event, temporal expressions and temporal relations discovery from the clinical text residing in the Electronic Health Records (EHR). We developed a comprehensive approach to temporality in the clinical text and innovated in computable temporal representations, methods for temporal relation discovery and their evaluation, rendering temporality to end users - resulting in over 35+ papers and presentations. Our dissemination is international and far-reaching as the best performing methods are released open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (ctakes.apache.org). The methods we developed are now being used in such nation-wide initiatives as the Electronic Medical Records and Genomics (eMERGE), Pharmacogenomics Network (PGRN), Informatics for Integrating the Biology and the Bedside (i2b2), Patient Centered Outcomes Research Institute and National Cancer Institute's Informatics Technology for Cancer Research (ITCR). Through our participation in organizing major international bakeoffs - CLEF/ShARe 2014, SemEval 2014 Analysis of Clinical Text Task 7, SemEval 2015 Analysis of Clinical Text Task 14, SemEval 2015 Clinical TempEval Task 6 - we further disseminated the THYME resources and challenged the international research community to explore new solutions to the unsolved temporality task. Through all these activities it became clear that computational approaches to temporality still present great challenges and usability of the output is still limited. Therefore, we propose to further innovate on methodologies and end user experience.             Specific Aim 1: Extract enhanced representations and novel features to support deriving timeline information.     Specific Aim 2: Develop methods to amalgamate individual patient episode timelines into an aggregate patient-level timeline.     Specific Aim 3: Mine the EHR - the unstructured clinical text and the structured codified information - for full patient-level temporality.     Specific Aim 4: Develop a comprehensive temporal visualization tool     Specific Aim 5: Develop methodology for and perform extrinsic evaluation on specific use case.     Specific Aim 6: (1) Evaluate state-of-the-art of temporal relations through organizing international challenges under the auspices of SemEval, (2) Disseminate the results through publications, presentations, and open source code in Apache cTAKES. Functional testing.             Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EHR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,8927274,R01LM010090,"['Apache Indians', 'Automobile Driving', 'Biology', 'Chronology', 'Clinical', 'Collection', 'Colon Carcinoma', 'Communication', 'Communities', 'Complex', 'Computerized Medical Record', 'Data', 'Data Set', 'Disease', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Evaluation', 'Event', 'Genomics', 'Goals', 'Human', 'Imagery', 'Individual', 'Informatics', 'Information Retrieval', 'International', 'Joints', 'Knowledge Extraction', 'Language', 'Life', 'Link', 'Machine Learning', 'Malignant neoplasm of brain', 'Medical', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Multiple Sclerosis', 'National Cancer Institute', 'Outcomes Research', 'Output', 'Paper', 'Patient-Focused Outcomes', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Process', 'Publications', 'Recording of previous events', 'Records', 'Research', 'Research Institute', 'Resolution', 'Resources', 'Science', 'Semantics', 'Signs and Symptoms', 'Solutions', 'Source Code', 'Statistical Models', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Thyme', 'Time', 'TimeLine', 'Translating', 'Translational Research', 'Trees', 'Vision', 'Work', 'abstracting', 'anticancer research', 'autism spectrum disorder', 'clinically relevant', 'data mining', 'experience', 'innovation', 'new technology', 'next generation', 'novel', 'open source', 'syntax', 'tool', 'usability']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2015,720481,0.013496523760124399
"Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes ﻿    DESCRIPTION (provided by applicant): The applicant and principal investigator (PI) is a board-certified cardiologist, Assistant Professor of Medicine and Senior Associate Consultant in the Mayo Clinic Cardiovascular Division. [The long-term goal of the PI is to become an independent clinician-investigator in translational informatics focused on the development, validation and deployment of electronic tools to the point-of-care to improve outcomes for patients with cardiovascular disease. The PI intends to leverage the EHR to conduct population-based studies using electronic algorithms that include NLP and by application of state-of-the-art informatics approaches to deliver the knowledge at the point-of-care in support of patient-centered decision-making for patients with peripheral arterial disease (PAD). The electronic tools developed will be portable to different institutions and other health conditions. The PI will be uniquely positioned as a cardiologist within a large academic health system working with novel NLP techniques at the interface of the EHR and CDS to rapidly translate knowledge acquired in community-based epidemiologic investigations to patient care.] The PI has proposed a research career development plan to acquire expertise in translational informatics including electronic phenotyping, and automated calculation and visual display of prognostic scores using a novel application integrated with clinical decision support (CDS). The PI will complete comprehensive coursework in informatics science and gain additional patient-oriented and epidemiologic research experience. The primary mentor will be Iftikhar Kullo, M.D., cardiologist and PI of the Mayo Clinic electronic MEdical Records and GEnomics (eMERGE) network and a leader in the development and application of electronic phenotyping for genomic studies of PAD. The mentoring team also includes Dr. Christopher Chute, M.D., Head of Medical Informatics at Mayo Clinic, an expert in informatics and epidemiology, and co-PI of the Mayo eMERGE grant and co-investigator of the Rochester Epidemiology Project; Hongfang Liu, Ph.D., an expert in natural language processing (NLP) and its application for EHR-based phenotyping; and Kent Bailey, Ph.D., senior biostatistician with expertise in development of prognostic risk scores. The specific aims of the proposal are: Aim 1 - Apply phenotyping algorithms that include NLP of clinical notes to [a] identify PAD cases and controls without PAD in the community from 1998-2011; and [b] ascertain adverse cardiovascular and limb outcomes through December 2013. Aim 2 - Create multivariable prognostic risk models and scores for adverse outcomes in PAD cases from the community. We will estimate the relative risk of death in PAD patients compared to controls without PAD. Aim 3 - Develop and evaluate usefulness of a novel electronic application within the Mayo EHR to retrieve relevant data elements, calculate, and display individualized prognostic scores. On completion of the proposed investigations the deliverables will be new knowledge and an e-health prognostication tool for PAD patients to be disseminated to stakeholders including clinicians, patients, and researchers portable to other institutions and other cardiovascular diseases.         PUBLIC HEALTH RELEVANCE: The applicant, a board certified cardiovascular specialist, proposes to acquire training in translational informatics science which will enable application of novel electronic algorithms to electronic health records to more efficiently conduct community-based studies of peripheral arterial disease, a prevalent but undertreated health condition. These studies will concurrently develop novel electronic tools which will inform patients and providers of risk, facilitate shared-decision making at the point-of-care, and promote compliance to guideline recommended strategies. These tools will be portable to other institutions and to other cardiovascular diseases.            ",Novel Informatics Approaches for Ascertainment of PAD Status and Adverse Outcomes,8891601,K01HL124045,"['Address', 'Adverse event', 'Algorithms', 'Amputation', 'Atherosclerosis', 'Atrial Fibrillation', 'Attention', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Investigator', 'Communities', 'Computerized Medical Record', 'Coronary heart disease', 'Data', 'Data Element', 'Decision Making', 'Dependence', 'Development', 'Development Plans', 'Diagnosis', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Electronic Health Record', 'Electronics', 'Epidemiologic Studies', 'Epidemiology', 'Genomics', 'Goals', 'Government', 'Grant', 'Guidelines', 'Head', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'High Prevalence', 'Image', 'Informatics', 'Institution', 'Investigation', 'Ischemia', 'Knowledge', 'Laboratories', 'Limb structure', 'Link', 'Manuals', 'Medical Informatics', 'Medicine', 'Mentors', 'Methodology', 'Mining', 'Modeling', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Peripheral arterial disease', 'Pharmaceutical Preparations', 'Phenotype', 'Positioning Attribute', 'Principal Investigator', 'Provider', 'Relative Risks', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Safety', 'Science', 'Site', 'Specialist', 'Stratification', 'Stroke', 'Symptoms', 'System', 'Techniques', 'Time', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'adverse outcome', 'base', 'career development', 'case control', 'clinical decision-making', 'cost', 'demographics', 'didactic education', 'eHealth', 'experience', 'health information technology', 'high risk', 'improved', 'investigator training', 'mortality', 'multidisciplinary', 'novel', 'patient oriented', 'point of care', 'population based', 'predictive modeling', 'professor', 'prognostic', 'public health relevance', 'repository', 'research and development', 'shared decision making', 'skills', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,K01,2015,136485,0.07165173661562618
"Encoding and Processing Patient Allergy Information in EHRs DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use. PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.",Encoding and Processing Patient Allergy Information in EHRs,8920540,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2015,488893,0.06851199347786183
"NLP-enabled decision support for cervical cancer screening and surveillance DESCRIPTION (provided by applicant): Although cervical cancer is preventable, it still continues to be a leading cause of death. Following the evidence- based guidelines for cervical cancer prevention is challenging for healthcare providers, due to which many patients do not receive the optimal preventive care. Clinical decision support (CDS) systems can potentially improve the care delivery. However, the current CDS systems only identify patients overdue for screening, and do not suggest the optimal screening interval. Moreover they do not help with surveillance of patients with abnormal screening results. This is because the existing systems lack the capability to process free- text clinical reports that contain information needed for applying the guidelines. Hence there is a critical need for natural language processing (NLP)-enabled CDS systems that can utilize discrete as well as free-text patient information for enhancing the decision support. Our long-term goal is to improve healthcare delivery of cervical cancer prevention with guideline based reminders. The central hypothesis is that NLP- enabled CDS system will significantly improve the quality of care delivery for cervical cancer prevention. The rationale is that use of NLP will improve granularity of the guideline implementation, which will in-turn enhance care delivery. As preliminary work we have developed an NLP-enabled CDS system that automatically interprets the patient information from the electronic health record and applies the national guidelines to compute the optimal recommendation for screening and surveillance. We have performed validation of the system in a non-clinical setting.1 In this application we will proceed towards deployment of the system in the clinical setting, and will carry out studies for measuring the impact on the quality of care delivery. In ai one, we will validate the system in the clinical setting and will optimize its usability and workflw integration. In aim two, we will test the hypothesis that reminders from the NLP-enabled CDS system to primary care providers will improve the quality of care delivery, by performing a one year intervention control study across four sites of a primary care practice. In aim three, we will test the hypothesis that reminders to non-adherent high-risk patients will improve their surveillance rates, by performing a randomized intervention study for three months. In this study, care coordinators will utilize the CDS system for sending reminders to patients that are non-adherent and at high risk due to abnormal screenings. The main contribution of this project will be knowledge about the effectiveness of NLP in enhancing the impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This project is innovative because the CDS system will utilize NLP to generate screening reminders for normal patients and surveillance reminders for patients with abnormal findings. This is a major advancement over existing systems that can only identify patients for screening. PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because it will yield knowledge about the effectiveness of natural language processing (NLP) to enhance impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This research will foster implementation of similar CDS systems across the nation for cervical cancer prevention and for other decision problems, which will improve the quality of healthcare delivery. Thus, the proposed research is relevant to AHRQ's mission to improve the quality, safety, efficiency, and effectiveness of health care for all Americans.",NLP-enabled decision support for cervical cancer screening and surveillance,8934087,R21HS022911,[' '],AHRQ,MAYO CLINIC ROCHESTER,R21,2015,145229,0.035800624435992835
"EHR-based Genomic Discovery and Implementation ﻿    DESCRIPTION (provided by applicant): Electronic health record (EHR)-linked biobanks are uniquely positioned for genomic discovery and for implementing genomic medicine to improve patient care. In eMERGE I, we leveraged an EHR-linked biobank, high-density genotyping data, and electronic phenotyping algorithms to discover 29 genetic loci associated with cardiovascular traits. In eMERGE II we began implementing genomic medicine by conducting an EHR-based randomized clinical trial of disclosing genomic risk of coronary heart disease and incorporating pharmacogenomic information in the EHR with linkage to clinical decision support. In eMERGE III; we propose to build on our prior work to conduct a genomic medicine implementation project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders-familial hypercholesterolemia (FH) and familial colorectal cancer (CRC)-we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will obtain informed consent from 3000 participants of Mayo Clinic biobanks in Rochester MN and Phoenix AZ who have moderate to severe hypercholesterolemia or colon polyps. DNA will be sent for CLIA-certified targeted sequencing of 100 disease genes. We will use state-of-the-art methods to classify variant pathogenicity, finalize actionable variants for return, examine near-term outcomes, economic implications and behavioral and psychosocial consequences of such return. We will also conduct genomic discovery leveraging a network-wide data set of ~25,000 individuals with sequence data and an existing network-wide data set of ~50,000 individuals with high-density genotype data linked to the EHR. We will exploit the unique potential of the EHR to assess pleiotropy using novel approaches. In partnership with Mountain Park Health Center, a primary care practice that serves a minority population of Mexican Americans in Phoenix AZ, we will contribute high-density genotyping and phenotype data on 1000 Hispanics for genomic discovery and pilot mechanisms for implementing genomic medicine at this site.         PUBLIC HEALTH RELEVANCE: Electronic health record (EHR)-linked biobanks are uniquely positioned to discover genetic variants relevant to human health and to implement genomic medicine to improve patient care. We propose to build on prior work to implement a genomic medicine project to establish mechanisms for return of actionable findings from targeted sequencing of 100 disease-relevant genes. Focusing on two common genetic disorders - familial hypercholesterolemia (FH) and familial colorectal cancer (CRC) - we will begin to translate genomic discovery and implementation efforts in eMERGE to impact public health. We will expand our efforts to identify genetic variants relevant to human health by leveraging available network-wide data sets.                ",EHR-based Genomic Discovery and Implementation,8967774,U01HG006379,"['Address', 'Algorithms', 'Behavioral', 'Bioinformatics', 'CLIA certified sequencing', 'Cardiovascular system', 'Clinic', 'Clinical', 'Colonic Polyps', 'Colorectal Cancer', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Electronics', 'Familial Hypercholesterolemia', 'Family', 'Family member', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Health', 'Healthcare', 'Hereditary Disease', 'Hispanics', 'Human', 'Individual', 'Informed Consent', 'Insurance Coverage', 'Link', 'Lipids', 'Low income', 'Medical Economics', 'Medicine', 'Methods', 'Mexican Americans', 'Minority', 'Natural Language Processing', 'Outcome', 'Participant', 'Pathogenicity', 'Patient Care', 'Patients', 'Penetrance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Plasma', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Public Health', 'Randomized Clinical Trials', 'Reaction', 'Recruitment Activity', 'Relative (related person)', 'Reporting', 'Research', 'Resources', 'Risk', 'Site', 'Translating', 'Treatment/Psychosocial Effects', 'Variant', 'Work', 'base', 'biobank', 'clinical decision-making', 'clinically actionable', 'cohort', 'community based practice', 'cost', 'density', 'economic implication', 'electronic data', 'genetic variant', 'health care service utilization', 'hypercholesterolemia', 'improved', 'interest', 'multidisciplinary', 'novel', 'novel strategies', 'novel therapeutic intervention', 'pleiotropism', 'point of care', 'psychosocial', 'public health relevance', 'rare variant', 'screening', 'targeted sequencing', 'trait', 'treatment response', 'variant of unknown significance']",NHGRI,MAYO CLINIC ROCHESTER,U01,2015,859901,0.024921476546033217
"Interactive machine learning methods for clinical natural language processing     DESCRIPTION (provided by applicant): Growing deployments of electronic health records (EHRs) systems have made massive clinical data available electronically. However, much of detailed clinical information of patients is embedded in narrative text and is not directly accessible for computerized clinical applications. Therefore, natural language processing (NLP) technologies, which can unlock information in narrative document, have received great attention in the medical domain. Current state-of-the-art NLP approaches often involve building probabilistic models. However, the wide adoption of statistical methods in clinical NLP faces two grand challenges: 1) the lack of large annotated clinical corpora; and 2) the lack of methodologies that can efficiently integrate linguistic and domain knowledge with statistical learning. High-performance statistical NLP methods rely on large scale and high quality annotations of clinical text, but it is time-consuming and costly to create large annotated clinica corpora as it often requires manual review by physicians. Moreover, the medical domain is knowledge intensive. To achieve optimal performance, probabilistic models need to leverage medical domain knowledge. Therefore, methods that can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost would be highly desirable for clinical text processing.    In this study, we propose to investigate interactive machine learning (IML) methods to address the above challenges in clinical NLP. An IML system builds a classification model in an iterative process, which can actively select informative samples for annotation based on models built on previously annotated samples, thus reducing the annotation cost for model development. More importantly, an IML system also involves human inputs to the learning process (e.g., an expert can specify important features for a classification task based on domain knowledge). Thus, IML is an ideal framework for efficiently integrating rule-based (via domain experts specifying features) and statistics-based (via different learning algorithms) approaches to clinical NLP. To achieve our goal, we propose three specific aims. In Aim 1, we plan to investigate different aspects of IML for word sense disambiguation, including developing new active learning algorithms and conducting cognitive usability analysis for efficient feature annotation by users. To demonstrate the broad uses of IML, we further extend IML approaches to two other important clinical NLP classification tasks: named entity recognition and clinical phenoytping in Aim 2. Finally we propose to disseminate the IML methods and tools to the biomedical research community in Aim 3.             Project Narrative In this project, we propose to develop interactive machine learning methods to process clinical text stored in electronic health records (EHRs) systems. Such methods can efficiently integrate domain and expert knowledge with machine learning processes to quickly build high-quality probabilistic models with minimum annotation cost, thus improving performance of text processors. This technology will allow more accurate data extraction from clinical documents, thus to facilitate clinical research that rely on EHRs data.",Interactive machine learning methods for clinical natural language processing,8818096,R01LM010681,"['Abbreviations', 'Active Learning', 'Address', 'Adoption', 'Algorithms', 'Attention', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cognitive', 'Communities', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Electronic Health Record', 'Face', 'Goals', 'Grant', 'Human', 'Hybrids', 'Knowledge', 'Label', 'Learning', 'Linguistics', 'Machine Learning', 'Manuals', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Sampling', 'Solutions', 'Source', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'System', 'Technology', 'Testing', 'Text', 'Time', 'United States National Library of Medicine', 'base', 'clinical application', 'clinical phenotype', 'cohort', 'computer human interaction', 'computerized', 'cost', 'experience', 'improved', 'model development', 'novel', 'open source', 'statistics', 'success', 'tool', 'usability']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,558372,0.03945738904599107
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                 Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8722031,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2014,19998,0.061963252261071605
"Semi-structured Information Retrieval in Clinical Text for Cohort Identification     DESCRIPTION (provided by applicant):  Natural Language Processing (NLP) techniques have shown promise for extracting data from the free text of electronic health records (EHRs), but studies have consistently found that techniques do not readily generalize across application settings. Unfortunately, most of the focus in applying NLP to real use cases has remained on a paradigm of single, well-defined application settings, so that generalizability to unseen use cases remains implicitly unaddressed. We propose to explicitly account for unseen application settings by adopting an information retrieval (IR) perspective with the objective of patient-level cohort identification. To do so, we introduce layered language models, an IR framework that enables the reuse of NLP-produced artifacts. Our long term goal is to accelerate investigations of patient health and disease by providing robust, user- centric tools that are necessary to process, retrieve, and utilize the free text of EHRs. The main goal of this proposal is to accurately retrieve ad hoc, realistic cohorts from clinical text at Mayo Clinic and OHSU, establishing methods, resources, and evaluation for patient-level IR. We hypothesize that cohort identification can be addressed in a generalizable fashion by a new IR framework: layered language models. We will test this hypothesis through four specific aims. In Aim 1, we will make medical NLP artifacts searchable in our layered language IR framework. This involves storing and indexing the NLP artifacts, as well as using statistical language models to retrieve documents based on text and its associated NLP artifacts. In Aim 2, we deal with the practical setting of ad hoc cohort identification, moving to patient-level (rather than document-level) IR. To accurately handle patient cohorts in which qualifying evidence may be spread over multiple documents, we will develop and implement patient-level retrieval models that account for cross- document relational and temporal combinations of events. In Aim 3, we will construct parallel IR test collections using EHR data from two sites; a diverse set of cohort queries written by multiple people toward various clinical or epidemiological ends; and assessments of which patients are relevant to which queries at both sites. Finally, in Aim 4, we refine and evaluate patient-level layered language IR on the ad hoc cohort identification task, making comparisons across the users, queries, optimization metrics, and institutions. We will draw additional extrinsic comparisons with pre-existing techniques, e.g., for cohorts from the Electronic Medical Records and Genonmics network. The expected outcomes of the proposed work are: (i) An open-source cohort identification tool, usable by clinicians and epidemiologists, that makes principled use of NLP artifacts for unseen queries; ii) A parallel test collection for cohort identification, includig two intra-institutional document collections, diverse test topics and user-produced text queries, and patient-level judgments of relevance to each query; and (iii) Validation of the reusability of medical NLP via the task of retrieving patient cohorts.         PUBLIC HEALTH RELEVANCE:  With the widespread adoption of electronic medical records, one might expect that it would be simple for a medical expert to find things like ""patients in the community who suffer from asthma."" Unfortunately, on top of lab tests, medications, and demographic information, there are observations that a physician writes down as text - which are difficult for a computer to understand. Therefore, we aim to process text so that a computer can understand enough of it, and then search that text along with the rest of a patient's medical record; this will allow clinicians or researchers to find and study patients groups of interest.                ",Semi-structured Information Retrieval in Clinical Text for Cohort Identification,8811565,R01LM011934,"['Accounting', 'Address', 'Adopted', 'Adoption', 'Asthma', 'Clinic', 'Clinical', 'Collection', 'Communities', 'Computerized Medical Record', 'Computers', 'Data', 'Dictionary', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Goals', 'Health', 'Information Retrieval', 'Information Retrieval Systems', 'Institution', 'Interest Group', 'Investigation', 'Judgment', 'Language', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Modification', 'Morphologic artifacts', 'Names', 'Natural Language Processing', 'Outcome', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Process', 'Publishing', 'Qualifying', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rest', 'Retrieval', 'Sampling', 'Semantics', 'Site', 'Smoke', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Validation', 'Weight', 'Work', 'Writing', 'asthmatic patient', 'base', 'cohort', 'improved', 'indexing', 'novel', 'open source', 'public health relevance', 'syntax', 'text searching', 'tool']",NLM,MAYO CLINIC ROCHESTER,R01,2014,460688,0.07305810936392906
"A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications  PROJECT SUMMARY Electronic Health Records (EHRs) can improve the quality of healthcare delivery in the United States, by providing automated best-practice reminders to clinicians and patients. However such functionality is currently limited to narrow areas of clinical practice, as existing decision support systems can process only structured data, due to lack of a suitable framework and concerns about accuracy and portability. Preliminary work by the PI has shown that rule-based approach can be used to develop broad-domain reminder systems that can utilize free-text in addition to the structured data. The PI has developed prototype systems for cervical and colorectal cancer prevention. These systems consist of rule-based composite models of national guidelines, and rule-based Natural Language Processing (NLP) parsers. The NLP parsers extract the patient variables required for applying the guidelines. However further research is needed to extend the systems and to ensure their accuracy for clinical deployment. In the mentored phase, the PI will collaborate with clinicians to extend and iteratively optimize and validate the systems, and will make them available in open-source so that they can be adapted for deployment at other institutions (aim 1 - K99). In the independent phase, the PI will research methods to facilitate rapid development, deployment and cross- institutional portability of similar systems. Specifically, the PI will develop a hybrid design for the parsers and investigate domain adaptation and active learning methods, for reducing the manual effort for development and adaptation of the NLP parsers (aim 2 - R00). To enable other researchers to reuse the developed methodologies and software resources, a toolkit will be developed that will support the construction and deployment of similar systems (aim 3 - R00). The toolkit will consist of user-friendly tools and templates to replicate the processes engineered in the case studies, and will build on the SHARPn data normalization tooling and other open-source tools. The independent phase will be in collaboration with Intermountain Healthcare. The PI's career goal is to become a scientific leader in clinical informatics with a focus on optimizing clinical decision making. The PI has strong background in clinical medicine and medical informatics, and will receive mentoring from Drs. Hongfang Liu, Christopher Chute, Robert Greenes and Rajeev Chaudhry, who have complimentary areas of expertise. The mentored (K99) phase will be for 2 years at Mayo Clinic Rochester, wherein the PI will undertake courses on decision support and will get mentored training in NLP and health information standards. This will prepare the PI for independent research in R00 phase on portability and tooling. Completion of the proposed work will enable the PI to seek further funding for piloting clinical deployment of the developed systems, measuring their clinical impact, and for scaling the approach to other clinical domains and institutions. The career grant will enable the PI to establish himself as an independent investigator and to make significant contributions towards advancing clinical decision support for improving care delivery.  PUBLIC HEALTH RELEVANCE STATEMENT The potential of Electronic Health Records (EHRs) to improve care delivery by providing best-practice reminders is unrealized, because reminder systems currently operate in narrow areas of clinical practice, as they can process only structured data. The proposed framework will enable construction of reminder systems that can encompass broader areas of practice, due to their capability to utilize free-text as well as structured EHR data. This pioneering research directly impacts public health by improving the quality of care through enhanced reminder functionality in the EHRs.",A Framework to Enhance Decision Support by Invoking NLP: Methods and Applications,8633838,K99LM011575,"['Active Learning', 'Address', 'Area', 'Caregivers', 'Caring', 'Case Study', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Collaborations', 'Colorectal Cancer', 'Computer software', 'Computers', 'Data', 'Decision Support Systems', 'Development', 'Electronic Health Record', 'Engineering', 'Ensure', 'Fostering', 'Funding', 'Goals', 'Grant', 'Guidelines', 'Health', 'Health Care Costs', 'Healthcare', 'Hybrids', 'Institution', 'Language', 'Learning', 'Machine Learning', 'Malignant neoplasm of cervix uteri', 'Manuals', 'Measures', 'Medical Informatics', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Phase', 'Process', 'Public Health', 'Quality of Care', 'Reminder Systems', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Solutions', 'Structure', 'System', 'Text', 'Training', 'United States', 'Validation', 'Work', 'base', 'care delivery', 'career', 'clinical application', 'clinical decision-making', 'clinical practice', 'colorectal cancer prevention', 'colorectal cancer screening', 'design', 'health care delivery', 'improved', 'open source', 'portability', 'prevent', 'prototype', 'public health relevance', 'tool', 'user-friendly']",NLM,MAYO CLINIC ROCHESTER,K99,2014,96232,0.05328265496802439
"Natural language processing for clinical and translational research DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive. PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.",Natural language processing for clinical and translational research,8920720,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2014,160000,0.1021838402010993
"Natural language processing for clinical and translational research     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.                ",Natural language processing for clinical and translational research,8640959,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'public health relevance', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2014,580082,0.1021838402010993
"Automated Detection of Anomalous Accesses to Electronic Health Records  Health information technology (HIT) can lower costs, strengthen productivity, and promote safety. To realize such benefits on a large scale, healthcare organizations (HCOs) are adopting electronic health records (EHRs) to provide various capabilities. Yet, as EHRs and the healthcare workforce grow in diversity, so does their complexity. This is a concern because evidence suggests complex HIT can interrupt care delivery, contribute to medical errors, and expose patient data to privacy breaches. Moreover, such events tend to be discovered only after they transpire en masse, leading to negative media coverage, loss of patients' trust, and sanctions. Federal regulations now enable patients to receive accountings of who accessed their medical records during treatment, payment, and operations related activities. Yet, for patients to make sense of such accountings, they need to be provided with explanations regarding the extent to which accesses are normal in the context of routine HCO activities. We believe that relating specific accesses to patterns of healthcare operations can help explain how medical records are utilized. Unfortunately, many of the aforementioned problems manifest because EHR utilization patterns rarely guide the design and refinement of healthcare management practices. Thus, the overarching objective of our research is to develop novel strategies to automatically learn HCO behavior based on EHR usage. The past several years has witnessed a flurry of activity in this field, but it remains in its infancy and has only scratched the surface of care patterns and the types of anomalies that can be detected. Through this project, we propose to develop anomaly detection methods that integrate the semantics of healthcare operations and allow for the detection of workflows over time. This will enable HCOs and patients to audit in a meaningful way. Moreover, we believe the innovation and dissemination of such data mining strategies will enable HCOs to detect anomalous events that indicate system misuse and patients who require special attention, but also effectively audit business practices and discover inefficient workflows. The specific aims of this project are (1) to develop machine learning approaches, based on intrasession utilization patterns, to streamline EHR interface configuration and detect anomalous sessions, (2) to design a data mining framework, based on intersession EHR access patterns, to characterize HCO departmental interactions in patient treatment and detect anomalous events, and (3) to infer patient management pathways to consolidate redundant processes and detect deviations from anticipated workflows. In support of these goals, we will evaluate, compare, and contrast the workflows and anomalies in the EHR systems of two large medical centers. Additionally, we will ensure that our methods are integrated into an open source software system that can assist HCOs to extract, transform, and load (ETL) access data from EHRs, analyze such data for anomalies, and visualize the results in interfaces that enable review by healthcare administrators and patients. In doing so, we will be able to compare and contrast behavior of the workflows and multiple institutions and develop methods that appropriately generalize across EHR systems.  As electronic health record systems, and healthcare organizations, grow in diversity, so do their complexity, which can lead to inefficient documentation, management of patients, and expose patient data to privacy breaches. In this research, we will develop technologies, to be disseminated through an open source software suite, to learn patterns associated with healthcare operations, upon which anomaly detection techniques can be based. The specific goals of this project are to 1) model HCO users' intrasession behaviors when interacting with an EHR, 2) learn interdepartmental relations based on the accesses of common patients, and 3) infer patient management pathways based on the sequence of accesses to a patient's record.",Automated Detection of Anomalous Accesses to Electronic Health Records,8694383,R01LM010207,"['Accounting', 'Administrator', 'Admission activity', 'Adopted', 'Architecture', 'Attention', 'Behavior', 'Businesses', 'Caring', 'Case Manager', 'Case Study', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Security', 'Detection', 'Documentation', 'Electronic Health Record', 'Employee', 'Engineering', 'Ensure', 'Entropy', 'Event', 'Goals', 'Grant', 'Graph', 'Healthcare', 'Healthcare Systems', 'Inpatients', 'Institution', 'Interdepartmental Relations', 'Internet', 'Lead', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Medical Errors', 'Medical Records', 'Medical center', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Movement', 'Neonatal Intensive Care', 'Neonatology', 'Pathway interactions', 'Patient Care', 'Patients', 'Pattern', 'Patterns of Care', 'Phase', 'Practice Management', 'Primary Health Care', 'Privacy', 'Process', 'Productivity', 'Provider', 'Recording of previous events', 'Regulation', 'Research', 'Research Personnel', 'Safety', 'Semantics', 'Simulate', 'Surface', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Trust', 'Variant', 'Work', 'base', 'care delivery', 'comparative', 'cost', 'data mining', 'design', 'follow-up', 'health information technology', 'infancy', 'innovation', 'novel strategies', 'open source', 'operation', 'organizational structure', 'payment', 'programs', 'software systems', 'ward']",NLM,VANDERBILT UNIVERSITY,R01,2014,392500,0.04907558587667868
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8714052,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,UNIVERSITY OF UTAH,R01,2014,579144,0.03513980659979021
"An Information Fusion Approach to Longitudinal Health Records     DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted.                  Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8722624,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved', 'screening']",NLM,OHIO STATE UNIVERSITY,R01,2014,300537,0.05321076473574123
"Patient Medical History Representation, Extraction, and Inference from EHR Data     DESCRIPTION (provided by applicant): The significance of developing tools for automatically harvesting temporal constraints of clinical events from Electronic Health Records (EHR) cannot be overestimated. Efficient analysis of the temporal aspects in EHR data could boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine.     One big challenge we are facing is to automatically untangle and linearize the temporal constraints of clinical events embedded in highly diverse large-scale EHR data. Barriers to temporal data modeling, normalization, extraction, and reasoning have precluded the efficient use of EHR data sources for event history evaluation and trending analysis: (1) The current federally-supported EHR data normalization tools do not focus on the time aspect of unstructured data yet; (2) Existing time models focus only on structured data with absolute time, lack of supporting reasoning systems, or only offer application-specific partial solutions which cannot be adopted by the complex EHR data; (3) Current temporal information extraction approaches are either difficult to be adopted to EHR data, not scalable, or only offers application-specific partial solution.     This proposed project fills in the current gaps among ontologies, Natural Language Processing (NLP), and EHR-based clinical research for temporal data representation, normalization, extractions, and reasoning. We propose to develop novel approaches for automatic temporal data representation, normalization and reasoning for large, diverse, and heterogeneous EHR data and prepare the integrated data for further analysis. We will build new reasoning and extraction capacities on our TIMER (Temporal Information Modeling, Extracting, and Reasoning) framework to provide an end-to-end, open-source, standard-conforming software package. TIMER will be built on strong prior work by our team. We will develop new features in our CNTRO (Clinical Narrative Temporal Relation Ontology) for semantically defining the time domain and representing temporal data in complex EHR data. On top of the new developed CNTRO semantics, we will implement temporal relation reasoning capacities to automatically normalize temporal expressions, compute and infer temporal relations, and resolve ambiguities. We will leverage existing NLP tools and work on top of these tools to develop new extraction approaches to fill in the current gaps between NLP approaches and ontology-based reasoning approaches. We will adapt the SHARPn EHR data normalization pipeline and cTAKES for extracting and normalizing clinical event mentions from clinical narratives. We will explore an innovative approach for temporal relation extraction and event coreference, and make it work with the TIMER framework. We will evaluate the system using Diabetes Mellitus (DM) and colorectal cancer (CRC) patient cohorts from two insititutions. Each component will be tested separately first followed by an evaluation of the whole framework. Results such as precision, recall, and f-measure will be reported.                 Project Narrative The significance of developing capabilities for automatically harvesting temporal constraints for clinical events from Electronic Health Records (EHR) cannot be overestimated. A substantial portion of the information in the EHR is historical in nature. Patient medical history can be long, especially in complex patients. The proposed work, by offering an end-to-end open-source framework for automatically extracting, normalizing, and reasoning clinically-important time-relevant information from large-scale EHR data, can boost an array of clinical and translational research such as disease progression studies, decision support systems, and personalized medicine; as well as facilitate clinical practice for early disease detection, post-treatment care, and patient-clinician communication.","Patient Medical History Representation, Extraction, and Inference from EHR Data",8760594,R01LM011829,"['Address', 'Adopted', 'Aftercare', 'Archives', 'Automated Annotation', 'Big Data', 'Cancer Patient', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Colorectal Cancer', 'Communication', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Databases', 'Decision Support Systems', 'Detection', 'Diabetes Mellitus', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Event', 'Goals', 'Gold', 'Harvest', 'Human', 'Institutes', 'Maps', 'Measures', 'Medical History', 'Medical Records', 'Medicine', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patient Care', 'Patients', 'Performance', 'Recording of previous events', 'Registries', 'Reporting', 'Resolution', 'Semantics', 'Solutions', 'Structure', 'System', 'Testing', 'Time', 'Translational Research', 'Work', 'base', 'clinical practice', 'cohort', 'data modeling', 'data structure', 'information model', 'innovation', 'novel strategies', 'open source', 'programs', 'tool', 'trend']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2014,398307,0.109925388337497
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors     DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases.                  The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8727661,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,R01,2014,320343,0.03416301249769739
"SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs)  ﻿    DESCRIPTION (provided by applicant): Smart algorithms that effectively analyze patient care data can enhance clinical communication to save lives. In 2000, the Institute of Medicine estimated 98,000 preventable patient deaths occur annually in US hospitals due to miscommunication [1]. Electronic health records (EHRs) were expected to facilitate accurate communication within the care team and provide data to enable automated clinical decision support systems. Unfortunately, miscommunication remains a significant cause of patient deaths [2]. Providers are now required to demonstrate meaningful use of EHR systems to improve quality of care and patient outcomes. Despite this, providers continue to report that EHR systems are cumbersome and interfere with care-team communication. Information entered into an EHR is rarely used by nurses due to the time and difficulty involved in its retrieval. As a result, nurses continue to verbally convey critical patient care information to the next nurse during shift changes. Verbal report or hand-off, where critical patient information is exchanged in only minutes, is inefficient. Worse, it is highly susceptible to communication errors. Broader Impacts: Research: 1) Increase patient safety; 2) Provide preliminary data to expand this work to include physician-physician and physician-RN communication and decision-making in the EHR; 3) Share our discoveries to inform other industries who may also benefit from this technology. Education: 1) Contribute to curriculum enhancements whereby RN students learn strategies to recognize and effectively communicate CEs; 2) As part of curriculum enhancements, include healthcare applications for computer and information science students; 3) Disseminate findings via academic publications, professional meetings, a project website and social media. Mentoring: 1) Mentor budding scientists in the roles of research assistants (RAs) and post doctoral fellows studying nursing and computer science to forge collaborative interdisciplinary relationships for ongoing research; 2) Interest and recruit underrepresented students in STEM and careers in healthcare. RELEVANCE (See instructions): The electronic health record (EHR) has been thought to be a top! to decrease patient deaths related to miscommunication. However, the current EHR falls short of this goal. We propose to develop and test an algorithm that will augment the EHR to more effectively assist nurses in decision-making and communication, ultimately increasing patient safety.                 n/a",SCH: Enhancing Nurse Decision-Making via Augmented Communication Tools (ACTs) ,8894220,R01EB020395,"['Agreement', 'Algorithms', 'Caring', 'Cessation of life', 'Clinical', 'Clinical Decision Support Systems', 'Communication', 'Communication Tools', 'Computer Simulation', 'Conscious', 'Data', 'Data Reporting', 'Decision Making', 'Discipline of Nursing', 'Documentation', 'Education', 'Educational Curriculum', 'Effectiveness', 'Electronic Health Record', 'Electronics', 'Event', 'Fever', 'Goals', 'Hand', 'Health', 'Healthcare', 'Hemorrhage', 'Hospitals', 'Imagery', 'Industry', 'Information Sciences', 'Institute of Medicine (U.S.)', 'Instruction', 'Lead', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Mentors', 'Nurses', 'Outcome', 'Output', 'Pain', 'Patient Care', 'Patients', 'Physicians', 'Postdoctoral Fellow', 'Principal Investigator', 'Provider', 'Publications', 'Quality of Care', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'STEM career', 'Sampling', 'Scientist', 'Severities', 'Students', 'Symptoms', 'System', 'Technology', 'Testing', 'Time', 'Validity and Reliability', 'Work', 'computer science', 'falls', 'forging', 'high risk', 'improved', 'interest', 'light weight', 'meetings', 'patient safety', 'prototype', 'respiratory', 'social', 'usability', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2014,251572,0.04192564534321336
"Encoding and Processing Patient Allergy Information in EHRs     DESCRIPTION (provided by applicant): Allergies affect one in five Americans and are the 5th leading chronic disease in the U.S. Each year, allergies account for more than 17 million outpatient office visits. Although documenting and exchanging allergy information in electronic health records (EHRs) is becoming increasingly important, we still face multiple challenges. These include: lack of well-adopted standard terminologies for representing allergies, frequent entry of allergy information as free-text, and no existing process for reconciling allergy information. In this study, we will provide solutions to these challenges by addressing the following specific aims: 1) conduct analyses on standard terminologies and a large allergy repository to build a comprehensive knowledge base for representing allergy information; 2) design, develop and evaluate a natural language processing (NLP) module for extracting and encoding free-text allergy information and integrate it with an existing NLP system; 3) measure the feasibility and efficiency of the proposed NLP system for the new process of allergy reconciliation; and 4) distribute our methods and tool, so they are widely available to other researchers and healthcare institutions for non-commercial use.         PUBLIC HEALTH RELEVANCE: Managing allergy information within the electronic health record (EHR) is vital to ensuring patient safety. The goal of this study is to propose a comprehensive solution to assess existing terminology standards and knowledge bases for representing allergy information, develop and evaluate a natural language processing (NLP) system for extracting and encoding allergy information from free-text clinical documents, and finally measure the feasibility of using NLP output to facilitate the allergy reconciliation proces.            ",Encoding and Processing Patient Allergy Information in EHRs,8741955,R01HS022728,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R01,2014,489854,0.06851199347786183
"Automated Dynamic Lists for Efficient Electronic Health Record Management DESCRIPTION (provided by APPLICANT): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposes to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the information extraction application, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute Cancer Clinics (Salt Lake City, Utah), with problems and allergies annotated by domain experts; 2) develop a prototype to automatically extract medical problems and allergies, implementing a novel stepwise hybrid approach to maximize sensitivity first, and also enhance positive predictive value; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare and Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and it is output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment. PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.",Automated Dynamic Lists for Efficient Electronic Health Record Management,8926527,R41CA180190,"['Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinic', 'Clinical', 'Code', 'Complex', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Event', 'Excision', 'Goals', 'Health', 'Health Personnel', 'Healthcare', 'Hybrids', 'Hypersensitivity', 'Incentives', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Metric', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Predictive Value', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Sodium Chloride', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Work', 'base', 'commercial application', 'computerized physician order entry', 'design', 'improved', 'novel', 'payment', 'prevent', 'prototype']",NCI,"CLINACUITY,INC.",R41,2014,24960,0.05801450318897336
"Automated Dynamic Lists for Efficient Electronic Health Record Management     DESCRIPTION (provided by APPLICANT): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposes to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the information extraction application, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute Cancer Clinics (Salt Lake City, Utah), with problems and allergies annotated by domain experts; 2) develop a prototype to automatically extract medical problems and allergies, implementing a novel stepwise hybrid approach to maximize sensitivity first, and also enhance positive predictive value; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare and Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and it is output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment.         PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.           ",Automated Dynamic Lists for Efficient Electronic Health Record Management,8830154,R41CA180190,"['Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinic', 'Clinical', 'Code', 'Complex', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Event', 'Excision', 'Goals', 'Health Personnel', 'Healthcare', 'Hybrids', 'Hypersensitivity', 'Incentives', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Metric', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Predictive Value', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Sodium Chloride', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Work', 'base', 'commercial application', 'computerized physician order entry', 'design', 'improved', 'novel', 'payment', 'prevent', 'prototype', 'public health relevance']",NCI,"CLINACUITY,INC.",R41,2014,119730,0.05801450318897336
"NLP-enabled decision support for cervical cancer screening and surveillance     DESCRIPTION (provided by applicant): Although cervical cancer is preventable, it still continues to be a leading cause of death. Following the evidence- based guidelines for cervical cancer prevention is challenging for healthcare providers, due to which many patients do not receive the optimal preventive care. Clinical decision support (CDS) systems can potentially improve the care delivery. However, the current CDS systems only identify patients overdue for screening, and do not suggest the optimal screening interval. Moreover they do not help with surveillance of patients with abnormal screening results. This is because the existing systems lack the capability to process free- text clinical reports that contain information needed for applying the guidelines. Hence there is a critical need for natural language processing (NLP)-enabled CDS systems that can utilize discrete as well as free-text patient information for enhancing the decision support. Our long-term goal is to improve healthcare delivery of cervical cancer prevention with guideline based reminders. The central hypothesis is that NLP- enabled CDS system will significantly improve the quality of care delivery for cervical cancer prevention. The rationale is that use of NLP will improve granularity of the guideline implementation, which will in-turn enhance care delivery. As preliminary work we have developed an NLP-enabled CDS system that automatically interprets the patient information from the electronic health record and applies the national guidelines to compute the optimal recommendation for screening and surveillance. We have performed validation of the system in a non-clinical setting.1 In this application we will proceed towards deployment of the system in the clinical setting, and will carry out studies for measuring the impact on the quality of care delivery. In ai one, we will validate the system in the clinical setting and will optimize its usability and workflw integration. In aim two, we will test the hypothesis that reminders from the NLP-enabled CDS system to primary care providers will improve the quality of care delivery, by performing a one year intervention control study across four sites of a primary care practice. In aim three, we will test the hypothesis that reminders to non-adherent high-risk patients will improve their surveillance rates, by performing a randomized intervention study for three months. In this study, care coordinators will utilize the CDS system for sending reminders to patients that are non-adherent and at high risk due to abnormal screenings. The main contribution of this project will be knowledge about the effectiveness of NLP in enhancing the impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This project is innovative because the CDS system will utilize NLP to generate screening reminders for normal patients and surveillance reminders for patients with abnormal findings. This is a major advancement over existing systems that can only identify patients for screening.         PUBLIC HEALTH RELEVANCE: The proposed research is relevant to public health because it will yield knowledge about the effectiveness of natural language processing (NLP) to enhance impact of CDS systems for cervical cancer prevention, and for clinical practice in general. This research will foster implementation of similar CDS systems across the nation for cervical cancer prevention and for other decision problems, which will improve the quality of healthcare delivery. Thus, the proposed research is relevant to AHRQ's mission to improve the quality, safety, efficiency, and effectiveness of health care for all Americans.            ",NLP-enabled decision support for cervical cancer screening and surveillance,8678798,R21HS022911,[' '],AHRQ,MAYO CLINIC ROCHESTER,R21,2014,145229,0.035800624435992835
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                  Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8538500,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2013,18400,0.061963252261071605
"Natural language processing for clinical and translational research     DESCRIPTION (provided by applicant): Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. This growth is being fueled by recent federal legislation that provides generous financial incentives to institutions demonstrating aggressive application and ""meaningful use"" of comprehensive EMRs. Efforts are already underway to link these EMRs across institutions, and standardize the definition of phenotypes for large scale studies of disease onset and treatment outcome, specifically within the context of routine clinical care. However, a well-known challenge for secondary use of EMR data for clinical and translational research is that much of detailed patient information is embedded in narrative text. Natural Language Processing (NLP) technologies, which are able to convert unstructured clinical text into coded data, have been introduced into the biomedical domain and have demonstrated promising results. Researchers have used NLP systems to identify clinical syndromes and common biomedical concepts from radiology reports, discharge summaries, problem lists, nursing documentation, and medical education documents. Different NLP systems have been developed at different institutions and utilized to convert clinical narrative text into structured data that may be used for other clinical applications and studies. Successful stories in applying NLP to clinical and translational research have been reported widely. However, institutions often deploy different NLP systems, which produce various types of output formats and make it difficult to exchange information between sites. Therefore, the lack of interoperability among different clinical NLP systems becomes a bottleneck for efficient multi-site studies. In addition, many successful studies often require a strong interdisciplinary team where informaticians and clinicians have to work very closely to iteratively define optimal algorithms for clinical phenotypes. As intensive informatics support may not be available to every clinical researcher, the usability of NLP systems for end users is another important issue. The proposed project builds upon first-hand knowledge and experience across the research team in the use of NLP for clinical and translational research projects. There are several big informatics initiatives for clinical and translational research but those initiatives generally assume one shoe fits all and follow top-down approaches to develop NLP solutions. Complementary to those initiatives, we will use a bottom-up approach to handle interoperability and usability: i) we will obtain a common NLP data model and exchange format through empirical analysis of existing NLP systems and NLP results; ii) we will develop a user-centric NLP front end interface for NLP systems wrapped to be consistent with the proposed NLP data model and exchange format incorporating usability analysis into the agile development process. All deliverables will be distributed through the open health NLP (OHNLP) consortium which we intend to make it more open and inclusive.         PUBLIC HEALTH RELEVANCE: Rapid growth in the clinical implementation of large electronic medical records (EMRs) has led to an unprecedented expansion in the availability of dense longitudinal datasets for clinical and translational research. We propose the development of a novel framework to enable the use of clinical information embedded in clinical narratives for clinical and translational research.                ",Natural language processing for clinical and translational research,8505753,R01GM102282,"['Acceleration', 'Adopted', 'Adoption', 'Adverse drug effect', 'Algorithms', 'Architecture', 'Attention', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'DNA Databases', 'Data', 'Data Set', 'Development', 'Dictionary', 'Discipline of Nursing', 'Disease Association', 'Documentation', 'Elements', 'Exclusion Criteria', 'Genes', 'Genomics', 'Goals', 'Growth', 'Health', 'Informatics', 'Institution', 'Knowledge', 'Link', 'Logical Observation Identifiers Names and Codes', 'Manuals', 'Medical Education', 'Modeling', 'Natural Language Processing', 'Onset of illness', 'Output', 'Patients', 'Pharmacogenomics', 'Phenotype', 'Play', 'Process', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Role', 'SNOMED Clinical Terms', 'Semantics', 'Shoes', 'Site', 'Solutions', 'Statutes and Laws', 'Structure', 'Syndrome', 'System', 'Technology', 'Text', 'Translational Research', 'Treatment outcome', 'Work', 'base', 'clinical application', 'clinical care', 'clinical phenotype', 'computer human interaction', 'data exchange', 'data modeling', 'experience', 'financial incentive', 'flexibility', 'human centered computing', 'interoperability', 'novel', 'open source', 'patient safety', 'public health relevance', 'rapid growth', 'success', 'tool', 'usability', 'user-friendly']",NIGMS,MAYO CLINIC ROCHESTER,R01,2013,630706,0.1021838402010993
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.       PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.         ","Annotation, development and evaluation for clinical information extraction",8501543,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,370221,0.09280350181789764
"An Information Fusion Approach to Longitudinal Health Records     DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted.                  Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8532982,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved', 'screening']",NLM,OHIO STATE UNIVERSITY,R01,2013,312584,0.05321076473574123
"EHR-based patient safety: Automated error detection in neonatal intensive care     DESCRIPTION (provided by applicant): In the field of neonatal patient safety, the paucity of systematic research is a critical barrier to progress. Notably missing are studies that meticulously investigate Electronic Health Records (EHR) and information technology in detecting neonatal intensive care-related errors. The expert panel at the National Institute of Child Health and Human Development (NICHHD) identified multiple gaps in the current knowledge of neonatal patient safety research. The proposed work is a well focused response to three dimensions of the Funding Opportunity Announcement:  1.Develop prospective and retrospective study designs to collect data on patient safety and adverse events.  2.Study the strength and limitations of current methods of error reporting systems.  3.Study the usefulness of commercial IT systems and EHRs in reducing medical errors.  In our study we seek to shift patient safety research toward an automated and computerized approach to achieve a more comprehensive patient safety paradigm. We will develop novel Electronic Health Record (EHR) content-based automated algorithms that are new to patient safety research to 1) detect errors (Aim 1) and 2) categorize subsequent harm (Aim 2). State of the art information extraction and statistical classification techniques from the field of clinical Natural Language Processing (NLP) will be adapted to the patient safety research tasks.  In Aim 1 we will fill the gap in the literatre by implementing a focused manual review of 700 charts (one full year of patient admissions at our institution) in one of the largest Neonatal Intensive Care Units (NICU) in the nation. Using a trigger tool, we will identify errors occurring in three specified categories - laboratory test errrs, medication/fluid errors, and airway management errors. We will develop novel algorithms for automated EHR-based detection of the errors and evaluate the performance of the new algorithms against the performance of both trigger tool review by human chart reviewers (current gold standard) and the voluntary incident reporting system (accepted standard). In Aim 2, we will study the utility of novel EHR-based information extraction and statistical algorithms for the automated categorization of errors according to the resulting level of harm.  Our proposed work has the potential to accomplish a paradigm shift in the methods of neonatal patient safety research and practice. The study is a fundamental step to automating patient safety monitoring on a large scale and improving error identification and patient safety in NICUs for millions of children every year.          We are developing an automated error detection technique to improve the safety of newborn babies during hospital care. Our work is the first known attempt to use text analysis in the electronic health records on a large scale to reduce the cost while at the same time increase the speed and comprehensiveness of error detection in the clinical care of newborns.            ",EHR-based patient safety: Automated error detection in neonatal intensive care,8517787,R21HD072883,"['Adverse event', 'Algorithms', 'Caring', 'Categories', 'Cessation of life', 'Characteristics', 'Child', 'Child health care', 'Classification', 'Clinical', 'Data', 'Detection', 'Dimensions', 'Electronic Health Record', 'Foundations', 'Funding Opportunities', 'Gold', 'Hospitals', 'Hour', 'Human', 'Human Development', 'Information Systems', 'Information Technology', 'Institutes', 'Institution', 'Intervention', 'Knowledge', 'Laboratories', 'Liquid substance', 'Literature', 'Manuals', 'Medical Errors', 'Medication Errors', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Neonatal', 'Neonatal Intensive Care', 'Neonatal Intensive Care Units', 'Newborn Infant', 'Patient Admission', 'Patient Monitoring', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Prevention', 'Process', 'Prospective Studies', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Risk', 'Safety', 'Solid', 'Specific qualifier value', 'Speed', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Work', 'base', 'clinical care', 'computerized', 'cost', 'design', 'experience', 'improved', 'indexing', 'innovation', 'novel', 'patient safety', 'phrases', 'response', 'tool']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R21,2013,254095,0.03441468611372719
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8536940,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2013,292186,0.03324760539655547
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors     DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases.                  The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8532983,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,R01,2013,303833,0.03416301249769739
"Integration of an NLP-based application to support medication management     DESCRIPTION (provided by applicant): An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. Stage 1 of Meaningful Use requires certified EHRs to be capable of providing a user with the ability to perform medication reconciliation. However, most previous studies have taken place in the inpatient setting, while medication reconciliation in the outpatient setting is importnt and challenging. In addition, clinical notes contain critical medication information that also need to be reconciled. Our goal of this study is to develop novel methods and a system using natural language processing (NLP) and other technologies to facilitate the medication reconciliation process in the ambulatory setting. Our specific aims are to : 1) identify the requirements, use cases, work flow issues, barriers to and facilitators of using clinical notes and a NLP-based system in the medication reconciliation process; 2) design a generic system architecture and an application that integrates an NLP system and a web-based user interface within an existing medication reconciliation system; 3) pilot this study in two primary care clinics and measure the utilization, usability, performance and feasibility of the proposed methods and the tool; and 4) distribute our methods and the tool and to make them widely available to other researchers and healthcare institutions for non-commercial use.          An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.            ",Integration of an NLP-based application to support medication management,8496045,R21HS021544,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R21,2013,148223,0.032569961063029576
"Annotation, development and evaluation for clinical information extraction (transfer) Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible. In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction (transfer)",8868500,R01GM090187,[' '],NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2013,297936,0.09257858492491666
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann No abstract available  Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8520393,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,19641,0.03857102837092286
"Automated Dynamic Lists for Efficient Electronic Health Record Management     DESCRIPTION (provided by APPLICANT): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposes to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the information extraction application, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute Cancer Clinics (Salt Lake City, Utah), with problems and allergies annotated by domain experts; 2) develop a prototype to automatically extract medical problems and allergies, implementing a novel stepwise hybrid approach to maximize sensitivity first, and also enhance positive predictive value; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare and Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and it is output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment.         PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.           ",Automated Dynamic Lists for Efficient Electronic Health Record Management,8590856,R41CA180190,"['Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinic', 'Clinical', 'Code', 'Complex', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Event', 'Excision', 'Goals', 'Health Personnel', 'Healthcare', 'Hybrids', 'Hypersensitivity', 'Incentives', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Metric', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Predictive Value', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Sodium Chloride', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Work', 'base', 'commercial application', 'computerized physician order entry', 'design', 'improved', 'novel', 'payment', 'prevent', 'prototype', 'public health relevance']",NCI,"CLINACUITY,INC.",R41,2013,195683,0.05801450318897336
"Automated Dynamic Lists for Efficient Electronic Health Record Management     DESCRIPTION (provided by APPLICANT): Medical errors are recognized as the cause of numerous deaths, and even if some are difficult to avoid, many are preventable. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information in the electronic health record (EHR). Unfortunately, a substantial proportion of the information available in the EHR is only mentioned in narrative clinical documents. Electronic lists of problems and allergies are available in most EHRs, but they require manual management by their users, to add new problems, modify existing ones, and the removal of the ones that are irrelevant. Consequently, these electronic lists are often incomplete, inaccurate, and out of date. Clinacuity, Inc. proposes to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the EHR of patients suffering from cancer. To establish the merit and feasibility of such a system, we will work on the following objectives: 1) create a reference standard for training and testing the information extraction application, a reference standard including a random sample of de-identified clinical narratives from patients treated at the Huntsman Cancer Institute Cancer Clinics (Salt Lake City, Utah), with problems and allergies annotated by domain experts; 2) develop a prototype to automatically extract medical problems and allergies, implementing a novel stepwise hybrid approach to maximize sensitivity first, and also enhance positive predictive value; and 3) test the prototype with the aforementioned reference standard, using a cross-validation approach for training and testing. Commercial application: The system Clinacuity proposes will not only help healthcare providers maintain complete and timely lists of problems and allergies, providing them with an efficient overview of a patient, but also help healthcare organizations attain meaningful use requirements. The proposed system has potential commercial applications in inpatient and outpatient settings, increasing the efficiency of busy healthcare providers by saving time, and aiding healthcare organizations in demonstrating ""meaningful use"" and obtaining Centers for Medicare and Medicaid Services incentive payments. Clinacuity will further extend the commercial potential of the system and it is output, using modular design principles allowing utilization of each module independently, and enhancing its local adaptability for easier deployment.         PUBLIC HEALTH RELEVANCE: Medical errors cause numerous deaths, and even if some are difficult to avoid, many could be prevented. Computerized physician order-entry systems with decision support have been proposed to reduce this risk of medication errors, but these systems rely on structured and coded information such as entries in electronic lists of problems and allergies. Such lists are available in most electronic health records, but they require manual management and are often incomplete, inaccurate, and out of date. On the other hand, clinical text reports contain the majority of the patient information, including problems and allergies. The overall goal of this project is to develop a new system to automatically extract structured and coded medical problems and allergies from clinical narrative text in the electronic health record.           ",Automated Dynamic Lists for Efficient Electronic Health Record Management,8590856,R41CA180190,"['Cancer Patient', 'Caring', 'Cessation of life', 'Cities', 'Clinic', 'Clinical', 'Code', 'Complex', 'Disease', 'Electronic Health Record', 'Electronics', 'Ensure', 'Event', 'Excision', 'Goals', 'Health Personnel', 'Healthcare', 'Hybrids', 'Hypersensitivity', 'Incentives', 'Inpatients', 'Institutes', 'Laboratories', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Errors', 'Medication Errors', 'Methods', 'Metric', 'Natural Language Processing', 'Outpatients', 'Output', 'Patients', 'Pharmaceutical Preparations', 'Predictive Value', 'Reference Standards', 'Reporting', 'Risk', 'Sampling', 'Sodium Chloride', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'United States Centers for Medicare and Medicaid Services', 'Utah', 'Validation', 'Work', 'base', 'commercial application', 'computerized physician order entry', 'design', 'improved', 'novel', 'payment', 'prevent', 'prototype', 'public health relevance']",NCI,"CLINACUITY,INC.",R41,2013,81334,0.05801450318897336
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8305149,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2012,129035,0.0429397228691445
"Challenges in Natural Language Processing for Clinical Narratives     DESCRIPTION (provided by applicant): Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Clinical natural language processing (NLP) technologies for automatic extraction, indexing, searching, and interpretation of EHRs are in development; however, due to privacy concerns related to EHRs, such technologies are usually developed by teams that have privileged access to EHRs in a specific institution. Technologies that are tailored to a specific set of data from a given institution generate inspiring results on that data; however, they can fail to generalize to similar data from other institutions and even other departments from the same institution. Therefore, learning from these technologies and building on them becomes difficult.          In order to improve NLP in EHRs, there is need for head-to-head comparison of approaches that can address a given task on the same data set. Shared-tasks provide one way of conducting systematic head-to- head comparisons. This proposal describes a series of shared-task challenges and conferences, spread over a five year period, that promote the development and evaluation of cutting edge clinical NLP systems by distributing de-identified EHRs to the broad research community, under data use agreements, so that:      *	the state-of-the-art in clinical NLP technologies can be identified and advanced,      *	a set of technologies that enable the use of the information contained in EHR narratives becomes available, and      *	the information from EHR narratives can be made more accessible, for example, for clinical and medical research.          The scientific activities supporting the organization of the shared-task challenges are sponsored in part by Informatics for Integrating Biology and the Bedside (i2b2), grant number U54-LM008748, PI: Kohane.          This proposal aims to organize a series of workshops, conference proceedings, and journal special issues that will accompany the shared-task challenges in order to disseminate the knowledge generated by the challenges.                  Public health relevance: this proposal will address two main challenges related to the use of clinical narratives for research: availability of clinical records for research and identification of the state of the art in clinical natural language processing (NLP) technologies so that we can push the state of the art forward and so that future work can build on the past. Progress in clinical NLP will improve access to electronic health records for research, and for clinical applications, benefiting healthcare and public health.",Challenges in Natural Language Processing for Clinical Narratives,8400218,R13LM011411,"['Access to Information', 'Address', 'Agreement', 'Biology', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Set', 'Development', 'Distributed Systems', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'Healthcare', 'Improve Access', 'Informatics', 'Institution', 'Journals', 'Knowledge', 'Learning', 'Medical Research', 'Natural Language Processing', 'Privacy', 'Public Health', 'Publications', 'Records', 'Research', 'Rest', 'Series', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Work', 'clinical application', 'data sharing', 'head-to-head comparison', 'improved', 'indexing', 'practical application', 'public health relevance', 'symposium']",NLM,STATE UNIVERSITY OF NEW YORK AT ALBANY,R13,2012,20000,0.061963252261071605
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8333306,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,592423,0.03513980659979021
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8288078,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,663130,0.09631224958504313
"Contextual ASR to Support EHR Adoption    DESCRIPTION (provided by applicant): The adoption of electronic health record (EHR) systems is a national healthcare priority. However studies show massive physician productivity drop of up to 25-40% upon transition to EHR. The majority of workflow delay is based on the need to perform manual operations to fill structured forms within the EHR, as opposed to simple unstructured narratives used in traditional written notes and transcriptions. Vanguard Medical Technologies (VMT), under NIH grant 1R43LM010750, proved feasibility for DocTalk, a real-time, speech-driven, open-source augmented, small practice encounter recording system that processes voice to text to structured medical data to EHR input, utilizing integrated automated speech recognition (ASR) and natural language processing (NLP) in the cloud. While NLP accuracy in Phase I was high, voice accuracy prior to physician review was inadequate. Fortunately, the tight integration of ASR and NLP combined with the formal structure of physician notes offers unique context based approaches to address the challenge. Current speech recognition methods use a single general-purpose medical lexicon to train a recognizer when identifying words. Medical context-specific probabilities are ignored. The four Specific Aims of this Phase I SBIR project are to: 1. Create a textual corpus for each section of a patient encounter note by processing 1 million text based narrative structured encounter notes 2. Build a family of Section-Specific Statistical Language Models (SS-SLMs) specialized in recognizing speech pertaining to each specific section of a patient encounter note, using industry standard open source statistical language modeling tools. 3. Use NLP techniques to infer patterns of language usage from text of each section, a. To detect section boundaries to be used as trigger words for invoking SS-SLMs b. To determine characteristic word distributions of each section 4. Assess improvement in accuracy per section due to use of SS-SLMs, with the goal of 50% overall reduction of errors compared to non-section-specific SLMs in the same medical dictation system.      PUBLIC HEALTH RELEVANCE: Successful completion of this innovative proposed program of NLP-enhanced context based ASR, will provide the accuracy required to deploy an integrated, interactive, intuitive, low-cost data entry system for small practice primary care physicians. The augmented DocTalk system will enable physicians to increase usable information, avoid third-party transcription errors, and mitigate workflow delays. Increased small practice EHR adoption directly addresses national healthcare goals.              Successful completion of this innovative proposed program of NLP-enhanced context based ASR, will provide the accuracy required to deploy an integrated, interactive, intuitive, low-cost data entry system for small practice primary care physicians. The augmented DocTalk system will enable physicians to increase usable information, avoid third-party transcription errors, and mitigate workflow delays. Increased small practice EHR adoption directly addresses national healthcare goals.            ",Contextual ASR to Support EHR Adoption,8253003,R43TR000179,"['Address', 'Adoption', 'Characteristics', 'Code', 'Data', 'Documentation', 'Drops', 'Electronic Health Record', 'Electronics', 'Family', 'Genetic Transcription', 'Goals', 'Grant', 'Healthcare', 'Industry', 'Language', 'Libraries', 'Manuals', 'Medical', 'Medical Records', 'Medical Technology', 'Methods', 'Modeling', 'Natural Language Processing', 'Patients', 'Pattern', 'Phase', 'Physicians', 'Positioning Attribute', 'Primary Care Physician', 'Probability', 'Process', 'Productivity', 'Research Infrastructure', 'Safety', 'Small Business Innovation Research Grant', 'Solutions', 'Speech', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Variant', 'Voice', 'Writing', 'base', 'cost', 'innovation', 'open source', 'operation', 'programs', 'speech recognition', 'tool', 'voice recognition']",NCATS,"HEALTH FIDELITY, INC.",R43,2012,150000,0.050990322316714395
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),8318247,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Systematized Nomenclature of Medicine', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2012,366912,0.032345853593277324
"An Information Fusion Approach to Longitudinal Health Records     DESCRIPTION (provided by applicant): Our goal is to leverage an information fusion approach to integrate structured and unstructured information to generate a longitudinal health record (LHR) for accelerating the pace at which patients can be recruited into clinical trials. Because electronic health records (EHR) contain clinical summaries of a patient's clinical history, one would assume that they could be easily leveraged to automatically screen and identify potentially eligible patients. However most EHRs are not well designed to support screening of eligible patients and are composed of multiple data sources that are often redundant or inconsistent, stored in uncoordinated unstructured clinical narratives and structured data. These characteristics make EHRs difficult to use for matching patients against the complex event and temporal criteria of clinical trials protocols. This research proposes that an improved LHR, which contains a comprehensive clinical summary of a patient, can improve patient screening. We propose using a method of information fusion to generate this LHR, which merges information from multiple data sources, that addresses both the meaning and temporal nature of data, such that the resulting information is more accurate than would be possible if these sources were used individually.         The specific aims are to: 1) characterize the barriers of using EHR sources for screening in terms of data redundancy, inconsistency, lack of structure, and temporal imprecision; 2) automatically extract information from unstructured EHR sources necessary for screening patients against clinical trials eligibility criteria using natural language processing; 3) developan LHR appropriate for screening patients against eligibility criteria using information fusion methods based on semantic and temporal information; and 4) evaluate the accuracy of an LHR formed through information fusion for screening patients against clinical trials eligibility critera.         The respective hypotheses to be tested are: 1) Different parts of the EHR will contain variable amounts of redundancy, inconsistency, and temporal imprecision. Some sources will be more valuable for matching patients than others to clinical trials eligibility criteria. 2) Including th information contained in the unstructured notes will reduce the false positive rate of identifying potentially eligible patients over leveraging only the structured data in the EHR. 3) By using information fusion methods based on leveraging semantic and temporal information on a combination of structured and unstructured data, we will be able to accurately summarize the information contained in uncoordinated EHR data sources into an LHR that can be used for screening patients for clinical trials. 4) The use of information fusion to generate a longitudinal health record will increase the sensitivity and specificity of electronic clinical trial screening ver using a traditional EHR.         With an LHR formed through information fusion for screening patients for clinical trials eligibilit, we will be able to not only reduce the amount of staff effort required to recruit a patient into a clinical trial, but also accelerate the pace at which clinical trials can be conducted.                  Narrative This project is focused on generating a longitudinal health record for accelerating the pace at which patients can be recruited into clinical trials. Accelerating the pace at which patients are recruited into clinical trials has the potential for improving the speed at which new treatments are made available to the public.",An Information Fusion Approach to Longitudinal Health Records,8373437,R01LM011116,"['Address', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Decision Support Systems', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Consultations', 'Data', 'Data Sources', 'Electronic Health Record', 'Electronics', 'Eligibility Determination', 'Enrollment', 'Event', 'Failure', 'Goals', 'Hour', 'Laboratories', 'Manuals', 'Measures', 'Methods', 'Natural Language Processing', 'Nature', 'Patient Recruitments', 'Patients', 'Process', 'Randomized', 'Randomized Controlled Trials', 'Recording of previous events', 'Recruitment Activity', 'Research', 'Screening procedure', 'Semantics', 'Sensitivity and Specificity', 'Series', 'Source', 'Speed', 'Structure', 'Techniques', 'Testing', 'Time', 'TimeLine', 'Work', 'base', 'cohort', 'cost', 'design', 'falls', 'health record', 'improved']",NLM,OHIO STATE UNIVERSITY,R01,2012,341342,0.05321076473574123
"Applying NLP to Free Text as an EHR Data Capture Method to Improve EHR Usability     DESCRIPTION (provided by applicant): This proposal aims to ensure the ability of ""NLP-Standalone-or-Hybrid Documentation,"" a method of EHR data capture involving Natural Language Processing and possibly also standard EHR data capture, to improve the usability of EHR by reducing documentation time, increasing documentation quality, and increasing clinician satisfaction. Problem to be Addressed. Limited usability of the Electronic Health Record (""EHR"") and lack of standardized terminology impedes EHR adoption and optimal use, and therefore hinders realization of a universally interoperable and evidence-based reportable health care system. Large amounts of time required for documentation, low clinician satisfaction, and incomplete documentation are problems plaguing EHR. Innovation. Current research has demonstrated that NLP may be used for EHR data capture. ZyDoc is furthering the state of research by assessing the capability of NLP-Standalone-or-Hybrid Documentation to improve EHR usability along several criteria. Long Term Goal. By enabling interoperability and improving EHR usability, through improving clinician satisfaction, improving documentation quality, and reducing data capture time, MediSapien will encourage widespread EHR adoption and optimal use with structured data. Phase I Summary. The purpose of the first Specific Aim of this grant proposal is to ensure that NLP- Standalone-or-Hybrid Documentation is capable of improving clinician satisfaction, efficiency, and documentation quality, relative to standard EHR data capture methods. The purpose of the second Specific Aim is to improve the accuracy of MediSapien's coding. These Specific Aims will ensure the technical feasibility of NLP-Standalone-or-Hybrid Documentation and MediSapien for improving EHR usability. Phase II Objectives. In Phase II, ZyDoc will complete product development, beta test MediSapien at two hospitals, and measure the product's impact on clinical outcomes or documentation results. Commercial Opportunity. ZyDoc will offer MediSapien as a modular component by partnering with vendors that combine MediSapien in their own solutions, enabling their clients to meet EHR meaningful use standards.        PUBLIC HEALTH RELEVANCE: Limited usability of the Electronic Health Record (""EHR"") and lack of standardized terminology impedes EHR adoption and meaningful use, and therefore hinders realization of a universally interoperable and evidence- based reportable health care system. This proposal aims to prove that EHR usability can be increased by applying NLP and other technologies to convert dictated and transcribed unstructured text to structured data and inserting it into the EHR. Achievement of this result will encourage optimal EHR use with searchable, structured data that will enable interoperability.                  Limited usability of the Electronic Health Record (""EHR"") and lack of standardized terminology impedes EHR adoption and meaningful use, and therefore hinders realization of a universally interoperable and evidence- based reportable health care system. This proposal aims to prove that EHR usability can be increased by applying NLP and other technologies to convert dictated and transcribed unstructured text to structured data and inserting it into the EHR. Achievement of this result will encourage optimal EHR use with searchable, structured data that will enable interoperability.                ",Applying NLP to Free Text as an EHR Data Capture Method to Improve EHR Usability,8314587,R43LM011165,"['Achievement', 'Address', 'Adoption', 'Algorithms', 'Applications Grants', 'Client', 'Clinical', 'Code', 'Computer Assisted', 'Data', 'Documentation', 'Electronic Health Record', 'Ensure', 'Genetic Transcription', 'Goals', 'Health', 'Healthcare Systems', 'Hospitals', 'Hybrids', 'ICD-10-CM', 'ICD-9-CM', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Logical Observation Identifiers Names and Codes', 'Maps', 'Measures', 'Medical Informatics', 'Methods', 'Mus', 'Natural Language Processing', 'Outcome', 'Output', 'Patients', 'Phase', 'Physicians', 'Plague', 'Process', 'Provider', 'Records', 'Relative (related person)', 'Research', 'Risk', 'Solutions', 'Speech', 'Structure', 'System', 'Systematized Nomenclature of Medicine', 'Teaching Hospitals', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Vendor', 'base', 'clinical care', 'commercial application', 'evidence base', 'expectation', 'improved', 'innovation', 'interoperability', 'medical specialties', 'meetings', 'novel', 'product development', 'prospective', 'research study', 'satisfaction', 'usability']",NLM,"ZYDOC MEDICAL TRANSCRIPTION, LLC",R43,2012,150000,0.13714279478330033
"EHR-based patient safety: Automated error detection in neonatal intensive care     DESCRIPTION (provided by applicant): In the field of neonatal patient safety, the paucity of systematic research is a critical barrier to progress. Notably missing are studies that meticulously investigate Electronic Health Records (EHR) and information technology in detecting neonatal intensive care-related errors. The expert panel at the National Institute of Child Health and Human Development (NICHHD) identified multiple gaps in the current knowledge of neonatal patient safety research. The proposed work is a well focused response to three dimensions of the Funding Opportunity Announcement:  1.Develop prospective and retrospective study designs to collect data on patient safety and adverse events.  2.Study the strength and limitations of current methods of error reporting systems.  3.Study the usefulness of commercial IT systems and EHRs in reducing medical errors.  In our study we seek to shift patient safety research toward an automated and computerized approach to achieve a more comprehensive patient safety paradigm. We will develop novel Electronic Health Record (EHR) content-based automated algorithms that are new to patient safety research to 1) detect errors (Aim 1) and 2) categorize subsequent harm (Aim 2). State of the art information extraction and statistical classification techniques from the field of clinical Natural Language Processing (NLP) will be adapted to the patient safety research tasks.  In Aim 1 we will fill the gap in the literatre by implementing a focused manual review of 700 charts (one full year of patient admissions at our institution) in one of the largest Neonatal Intensive Care Units (NICU) in the nation. Using a trigger tool, we will identify errors occurring in three specified categories - laboratory test errrs, medication/fluid errors, and airway management errors. We will develop novel algorithms for automated EHR-based detection of the errors and evaluate the performance of the new algorithms against the performance of both trigger tool review by human chart reviewers (current gold standard) and the voluntary incident reporting system (accepted standard). In Aim 2, we will study the utility of novel EHR-based information extraction and statistical algorithms for the automated categorization of errors according to the resulting level of harm.  Our proposed work has the potential to accomplish a paradigm shift in the methods of neonatal patient safety research and practice. The study is a fundamental step to automating patient safety monitoring on a large scale and improving error identification and patient safety in NICUs for millions of children every year.        PUBLIC HEALTH RELEVANCE: We are developing an automated error detection technique to improve the safety of newborn babies during hospital care. Our work is the first known attempt to use text analysis in the electronic health records on a large scale to reduce the cost while at the same time increase the speed and comprehensiveness of error detection in the clinical care of newborns.              We are developing an automated error detection technique to improve the safety of newborn babies during hospital care. Our work is the first known attempt to use text analysis in the electronic health records on a large scale to reduce the cost while at the same time increase the speed and comprehensiveness of error detection in the clinical care of newborns.            ",EHR-based patient safety: Automated error detection in neonatal intensive care,8334934,R21HD072883,"['Adverse event', 'Algorithms', 'Caring', 'Categories', 'Cessation of life', 'Characteristics', 'Child', 'Child health care', 'Classification', 'Clinical', 'Data', 'Detection', 'Dimensions', 'Electronic Health Record', 'Foundations', 'Funding Opportunities', 'Gold', 'Hospitals', 'Hour', 'Human', 'Human Development', 'Information Systems', 'Information Technology', 'Institutes', 'Institution', 'Intervention', 'Knowledge', 'Laboratories', 'Liquid substance', 'Literature', 'Manuals', 'Medical Errors', 'Medication Errors', 'Methodology', 'Methods', 'Monitor', 'Natural Language Processing', 'Neonatal', 'Neonatal Intensive Care', 'Neonatal Intensive Care Units', 'Newborn Infant', 'Patient Admission', 'Patient Monitoring', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Prevention', 'Process', 'Prospective Studies', 'Reporting', 'Research', 'Research Design', 'Retrospective Studies', 'Risk', 'Safety', 'Solid', 'Specific qualifier value', 'Speed', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Work', 'base', 'clinical care', 'computerized', 'cost', 'design', 'experience', 'improved', 'indexing', 'innovation', 'novel', 'patient safety', 'phrases', 'response', 'tool']",NICHD,CINCINNATI CHILDRENS HOSP MED CTR,R21,2012,153000,0.03408411742089798
"Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors     DESCRIPTION (provided by applicant): The importance of understanding interactions among social, behavioral, environmental, and genetic factors and their relationship to health has led to greater interest in studying these determinants of disease in the biomedical research community. While some knowledge exists regarding contributions of specific determinants such as socioeconomic status, educational background, tobacco and alcohol use, and genetic susceptibility to particular diseases or conditions, enhanced methods are needed to analyze and ascertain interrelationships among multiple determinants and to discover potentially unexpected relationships that may ultimately contribute to improving patient care and population health. The increased adoption of electronic health record (EHR) systems has the potential for enhanced collection and access to a wide range of information about an individual's lifetime health status and health care to support a range of ""secondary uses"" such as biomedical, behavioral and social science, and public health research. Traditionally, clinicians document an individual's health history in clinical notes, including social and behavioral factors within the ""social histor"" section and familial factors in the ""family history"" section. While some EHR systems have specific modules for collecting social and family history in structured or semi-structured formats, a large amount of this information is recorded primarily in narrative format, thus necessitating the need for automated methods to facilitate the extraction and integration of social, behavioral, and familial factors for subsequent uses. Once extracted, knowledge acquisition and discovery methods can be applied to both confirm known relationships relative to specific diseases or conditions as well as to potentially discover new relationships. We hypothesize that advanced computational methods can transform social, behavioral, and familial factors from the EHR into a rich longitudinal resource for generating knowledge regarding various determinants of health including their temporal progression, severity, and relationship to health conditions. Towards this goal, the specific aims are to: (1) develop comprehensive information models and natural language processing (NLP) techniques to represent, extract, and integrate social, behavioral, and familial factors from social and family history information in the EHR, (2) adapt and extend data mining techniques to identify non-temporal and temporal relationships among these factors and diseases, and (3) evaluate and validate known and candidate new relationships for specific conditions (pediatric asthma and epilepsy). This multi-site proposal will involve a transdisciplinary team of investigators from the University of Vermont and University of Minnesota, use of EHR data from both institutions, and collaborative development and evaluation of the NLP and data mining techniques. Ultimately, this work has the potential to provide a generalizable approach for supporting and enhancing existing knowledge regarding the interactions among social, behavioral, and familial factors and diseases.                  The ability to systematically collect and analyze social, behavioral, and familial factors from the electronic health record using automated methods could assist in developing a rich longitudinal resource for enhancing knowledge regarding the interactions among these factors and diseases. This knowledge could ultimately contribute to improving patient care and population health. !","Leveraging the EHR to Collect and Analyze Social, Behavioral & Familial Factors",8344467,R01LM011364,"['Adoption', 'Alcohol consumption', 'Area', 'Behavioral', 'Biomedical Research', 'Biometry', 'Childhood Asthma', 'Clinical', 'Collection', 'Communities', 'Computing Methodologies', 'Data', 'Development', 'Disease', 'Educational Background', 'Electronic Health Record', 'Epilepsy', 'Evaluation', 'Family', 'Genetic', 'Genetic Predisposition to Disease', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Incidence', 'Individual', 'Institute of Medicine (U.S.)', 'Institution', 'Knowledge', 'Knowledge Discovery', 'Knowledge acquisition', 'Linguistics', 'Medicine', 'Methods', 'Mining', 'Minnesota', 'Natural Language Processing', 'Patient Care', 'Pattern', 'Pediatric Neurology', 'Public Health', 'Recording of previous events', 'Relative (related person)', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Severities', 'Site', 'Socioeconomic Status', 'Source', 'Structure', 'System', 'Techniques', 'Tobacco use', 'Universities', 'Vermont', 'Work', 'behavioral/social science', 'biomedical informatics', 'comparative effectiveness', 'data mining', 'improved', 'information model', 'interest', 'open source', 'patient population', 'population health', 'public health research', 'social', 'social integration', 'tool']",NLM,UNIVERSITY OF VERMONT & ST AGRIC COLLEGE,R01,2012,392726,0.03416301249769739
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8326648,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2012,318393,0.03324760539655547
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach  Abstract The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The study design is prospective observational study. Scope is limited to cancer patients. There are three specific aims for this project. The first aim is to identify concepts that overlap between the electronic medical record's (EMR) clinical notes and the free text of clinical trial announcements. The PI will use the concepts to develop mapping frames that connect concepts in the text of trial announcements to those found in clinical notes in the medical record. When he has the mapping frames he will build the NLP module for the application. In the software development work he will utilize as many publicly available software components as possible. He will experiment with UIMA, GATE, MetaMap, Stanford Parser, NegEx algorithm and others. The PI will develop the tool around the National Library of Medicine's Unified Medical Language System knowledgebase. He will use Java for programming. The second aim is to create an algorithm that automatically generates questions to request information directly from the patient if the information is not available or accessible in the records. The third aim is to evaluate the in-vitro, laboratory performance of the application. For performance evaluation purposes the PI will recruit cancer care specialists to generate the gold standard lists of eligible clinical trials for study patients. He will publicly release the developed code at the end of the grant period. This K99/R00 project will serve the foundation for future R01 grant applications. The PI is fully committed to become faculty in the Clinical Research Informatics domain with a specialization in biomedical NLP. The support of the K99/R00 grant will enable him to acquire substantial formal training in Computational Linguistics while contributing to the body of knowledge of the Clinical Research Informatics field. The five-year grant support will ensure success in his endeavor. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, EMR based clinical trial recommendations directly to the patients. The results of this research will empower the patients and elevate their role in the decision making process.  Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,8331381,R00LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'abstracting', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'knowledge base', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,CINCINNATI CHILDRENS HOSP MED CTR,R00,2012,238944,0.04064110259212357
"Integration of an NLP-based application to support medication management     DESCRIPTION (provided by applicant): An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. Stage 1 of Meaningful Use requires certified EHRs to be capable of providing a user with the ability to perform medication reconciliation. However, most previous studies have taken place in the inpatient setting, while medication reconciliation in the outpatient setting is importnt and challenging. In addition, clinical notes contain critical medication information that also need to be reconciled. Our goal of this study is to develop novel methods and a system using natural language processing (NLP) and other technologies to facilitate the medication reconciliation process in the ambulatory setting. Our specific aims are to : 1) identify the requirements, use cases, work flow issues, barriers to and facilitators of using clinical notes and a NLP-based system in the medication reconciliation process; 2) design a generic system architecture and an application that integrates an NLP system and a web-based user interface within an existing medication reconciliation system; 3) pilot this study in two primary care clinics and measure the utilization, usability, performance and feasibility of the proposed methods and the tool; and 4) distribute our methods and the tool and to make them widely available to other researchers and healthcare institutions for non-commercial use.        PUBLIC HEALTH RELEVANCE: An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.              An accurate and complete medication list on a patient's electronic health record (EHR) is critical to prevent prescribing and administration errors. In thi study, we will develop novel methods and a tool using natural language processing and other technologies to facilitate the medication reconciliation process. We will implement the system and evaluate our approach in the outpatient setting.            ",Integration of an NLP-based application to support medication management,8354008,R21HS021544,[' '],AHRQ,BRIGHAM AND WOMEN'S HOSPITAL,R21,2012,149342,0.029732469905280078
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8589822,R01LM010681,[' '],NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2012,237877,0.0429397228691445
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,8077875,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2011,374000,0.0429397228691445
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8055880,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical data warehouse', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2011,328942,0.02703861995243101
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8133360,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'clinical care', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,664617,0.09631224958504313
"Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann    DESCRIPTION (provided by applicant):       A critical element of translating science into practice is the ability to find patient populations for clinical research. Many studies rely on administrative data for selecting relevant patients for studies of comparative effectiveness, but the limitations of administrative data is well-known. Much of the information critical for clinical research is locked in free-text dictated reports, such as history and physical exams and radiology reports. Data repositories, such as the Medical Archival Retrieval System (MARS) at the University of Pittsburgh, are useful for identifying supersets of patients for clinical research studies through indexed word searches. However, simple text-based queries are also limited in their effectiveness, and researchers are often left reading through hundreds or thousands of reports to filter out false positive cases. Current processes are time-consuming and extraordinarily expensive. They lead to long delays between the development of a testable hypothesis and the ability to share findings with the medical community at large.       A potential solution to this problem is pre-annotating de-identified clinical reports to facilitate more intelligent and sophisticated retrieval and review. Clinical reports are rich in meaning and structure and can be annotated at many different levels using natural language processing technology. It is not clear, however, what types of annotations would be most helpful to a clinical researcher, nor is it clear how to display the annotations to best assist manual review of reports. There is interdependence between the annotation schema used by an NLP system and the user interface for assisting researchers in retrieving data for retrospective studies. In this proposal, we will interactively revise an NLP annotation schema as well as explore various methods for annotation display based on feedback from users reviewing patient data for specific research studies.       We hypothesize that an interactive search application that relies on NLP-annotated clinical text will increase the accuracy and efficiency of finding patients for clinical research studies and will support visualization techniques for viewing the data in a way that improves a researcher's ability to review patient data.              Narrative We will develop a novel review application for this proposal that will facilitate translational research from secondary use of EHR data by assisting researchers in more efficiently finding retrospective populations of patients for clinical research studies. The application will rely both on multi-layered annotation of the textual data, using natural langauge processing, and on coordinated views of the patient data.",Interactive Search and Review of Clinical Records with Multi-layered Semantic Ann,8022026,R01LM010964,"['Automated Annotation', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Databases', 'Development', 'Effectiveness', 'Elements', 'Feedback', 'Imagery', 'Lead', 'Left', 'Manuals', 'Medical', 'Methods', 'Natural Language Processing', 'Outcome', 'Patients', 'Process', 'Property', 'Radiology Specialty', 'Reading', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Retrospective Studies', 'Science', 'Semantics', 'Solutions', 'Structure', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Translating', 'Translational Research', 'Universities', 'base', 'comparative effectiveness', 'computer human interaction', 'improved', 'indexing', 'novel', 'patient population', 'research study', 'success']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,591195,0.03513980659979021
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),8145183,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Caring', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Systematized Nomenclature of Medicine', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2011,374400,0.032345853593277324
"POET-2: High-performance computing for advanced clinical narrative preprocessing    DESCRIPTION (provided by applicant):       This project focuses on clinical natural language processing (cNLP), a field of emerging importance in informatics. Starting with the Linguistic String Project's Medical Language Processor (New York University) in the 1970s, researchers have made steady gains in cNLP through empirical studies and by building sophisticated high-level cNLP software applications (e.g., Columbia's MedLEE). There are no fewer than four scientific conferences devoted exclusively to biomedical/clinical NLP. The cNLP literature has been growing over the past decade, and this will gain momentum as more clinical text repositories are released, such as the MIMIC II and University of Pittsburgh BLU Lab corpora.       However, sustained success in the field of cNLP is hampered by the reality that clinical texts have a far more noise than do texts traditionally studied in NLP, such as newswire articles, biomedical abstracts, and discharge summaries. Noise in this context is defined by the parseability characteristics of the language and the linguistic structures that appear in text. Clinical texts come in a striking variety of note types, with the best studied types being discharge summaries, radiology reports, and pathology reports. These note types share an important feature: they are written to communicate care issues between healthcare providers and hence typically are well-composed, well-edited, and often are dictated. But the vast majority of notes in the electronic health record are written primarily to document care issues. They communicate as well, of course, but much less care is used in their creation than with discharge summaries and reports. As a result they are often ungrammatical; are composed of short, telegraphic phrases; are replete with misspellings and shorthand (e.g., abbreviations); are ill-formatted with templates and liberal use of white space; and are embedded with ""non-prose"" (e.g., strings of laboratory values). All of these sources of noise complicate otherwise straightforward NLP tasks like tokenization, sentence segmentation, and ultimately information extraction itself.       We propose a systematic study of ways to increase the signal-to-noise ratio in clinical narratives to improve cNLP. This work extends our preliminary research (under the POET project) and has the following aims:        o Develop and implement a suite of parseability improvement tools designed for all clinical note types from multiple healthcare institutions.     o Evaluate the empirical and the functional success of the parseability improvement tools.     o Design and implement a HIPAA-compliant UlMA-based pipeline cNLP framework for use in a typical high-performance, multi-processor computing environment.              Project Narrative We can see in the multi-billion dollar investment in electronic health records (EHRs) by the ARRA that mining clinical data electronically will continue to be essential to informatics research. Most data in the EHR resides as unstructured text, and POET2 provides a means to unlock that data through combining a new, HIPAA- complaint high-performance computing architecture with sophisticated text preprocessing.",POET-2: High-performance computing for advanced clinical narrative preprocessing,8182025,R01LM010981,"['Abbreviations', 'Active Learning', 'Address', 'Architecture', 'Area', 'Authorization documentation', 'Caring', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Data', 'Electronic Health Record', 'Electronics', 'Employee Strikes', 'Ensure', 'Environment', 'Evaluation', 'Face', 'Gold', 'Growth', 'Health Care Reform', 'Health Insurance Portability and Accountability Act', 'Health Personnel', 'Healthcare', 'High Performance Computing', 'Informatics', 'Inpatients', 'Institution', 'Institutional Review Boards', 'Investments', 'Laboratories', 'Language', 'Linguistics', 'Literature', 'Maps', 'Medical', 'Mining', 'Modeling', 'Natural Language Processing', 'New York', 'Noise', 'Occupations', 'Outpatients', 'Paper', 'Pathology', 'Pathology Report', 'Patients', 'Performance', 'Proliferating', 'Publishing', 'Radiology Specialty', 'Records', 'Report (document)', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Research Support', 'Resolution', 'Series', 'Shorthand', 'Signal Transduction', 'Source', 'Structure', 'Summary Reports', 'System', 'Techniques', 'Technology', 'Text', 'Time', 'Universities', 'Voting', 'Work', 'Writing', 'abstracting', 'base', 'cluster computing', 'data mining', 'design', 'improved', 'meetings', 'novel', 'phrases', 'pressure', 'repaired', 'repository', 'research study', 'success', 'symposium', 'tool', 'web services']",NLM,UNIVERSITY OF UTAH,R01,2011,325163,0.03324760539655547
"A Hybrid General Natural Language Processing Architecture    DESCRIPTION (provided by applicant): Electronic medical records and exchanges offer new opportunities for the analysis of population health data; however, new methods in natural language processing (NLP) must first be developed to structure and codify these records, since most medical data is in the form of free text which cannot be stored and manipulated by computers. Once this is accomplished, population health data can be analyzed which will lead to better treatment guidelines, targeted drug therapy, and more cost effective care. Logical Semantics, Inc. (LSI) proposes to develop new statistical NLP methods for analyzing large scale medical domains. These methods will leverage LSI's semantic annotation technology, which has created the largest semantically annotated clinical corpus in the world. LSI's goal is to semantically index large medical record repositories accurately against propositions arranged in knowledge ontologies and make these indices available for text mining applications. The phase one research is focused on three specific aims that will lead to breakthroughs in the science of NLP: (1) Develop new statistical NLP algorithms employing a large semantically annotated medical corpus, (2) Semi-automate knowledge ontology generation, and (3) Develop and combine rule based with statistical NLP algorithms to create a superior hybrid NLP system. The achievement of these aims will result in computer systems that can extract the meaning from free text medical records so researchers, policy makers, and clinicians can use health analytics to improve healthcare.      PUBLIC HEALTH RELEVANCE: Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.           Project Narrative Natural language processing (NLP) has been successful in extracting specific findings and diagnoses from free text medical records. However, for NLP to be useful in health analytics, methods must be devised to capture most of the findings in a medical record. Logical Semantics, Inc. (LSI) proposes to build new statistical algorithms that can scale against the numerous complex findings in medical reports. LSI will leverage its advanced semantic annotation technology which employs corpus linguistics and sentential logic to build these new algorithms. The goal is to abstract over 80% of a free text records into computer readable form so that researchers can develop new treatment guidelines, improve decision support, and deliver more cost effective care.",A Hybrid General Natural Language Processing Architecture,7996937,R43LM010846,"['Achievement', 'Address', 'Algorithms', 'Architecture', 'Businesses', 'Caring', 'Clinical', 'Communities', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Computers', 'Data', 'Diagnosis', 'Discipline', 'Generations', 'Goals', 'Guidelines', 'Health', 'Healthcare', 'Hybrids', 'Knowledge', 'Lead', 'Legal patent', 'Linguistics', 'Logic', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Mining', 'Natural Language Processing', 'Ontology', 'Pattern', 'Pharmacotherapy', 'Phase', 'Policy Maker', 'Process', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Services', 'Structure', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Work', 'abstracting', 'base', 'cost effective', 'improved', 'indexing', 'knowledge base', 'operation', 'phrases', 'population health', 'public health relevance', 'repository', 'stem', 'success', 'text searching', 'tool']",NLM,"LOGICAL SEMANTICS, INC.",R43,2010,148180,0.045857231623223194
"Real-time Disambiguation of Abbreviations in Clinical Notes    DESCRIPTION (provided by applicant): A key prerequisite for high-quality healthcare delivery is effective communication within and across healthcare settings. However, communication can be hampered by the pervasive use of abbreviations in clinical notes. Clinicians use abbreviations to save time during documentation. While abbreviations may seem unambiguous to their authors, they often cause confusion to other readers, including healthcare providers, patients, and natural language processing (NLP) systems attempting to extract clinical terms from text. While the understanding that abbreviations can cause errors is widespread, few have deployed pragmatic solutions for this important problem. The proposed project will develop, evaluate, and share a systematic approach to Clinical Abbreviation Recognition and Disambiguation (CARD), and in doing so substantially aims to benefit existing NLP systems and to improve computer-based documentation systems by reducing ambiguities in electronic records in real-time. The study includes the following five Specific Aims: 1) Develop automated methods to detect abbreviations and their senses from clinical text corpora and build a comprehensive knowledge base of clinical abbreviations; 2) Develop and evaluate three automated word sense disambiguation (WSD) classifiers, and establish methods to combine those classifiers to maximize both their performance and coverage; 3) Develop the CARD system, and demonstrate its effectiveness by integrating it with two established NLP systems (MedLEE and KnowledgeMap); 4) Integrate CARD with an institutional clinical documentation system (Vanderbilt's StarNotes) and evaluate its ability to expand abbreviations in real-time as clinicians generate records; 5) Distribute the CARD knowledge base and software for non-commercial uses.              Project Narrative Abbreviations are widely used throughout all types of clinical documents and they cause confusion to both healthcare providers and patients and limit effective communications within and across care settings. This proposed study will develop informatics methods to automatically detect abbreviations and their possible meanings from large clinical text and to disambiguate abbreviations that have multiple meanings. We will also integrate those methods with clinical documentation systems so that abbreviations will be expanded in real-time when physicians entering clinical notes, thus to improve the quality of health records.",Real-time Disambiguation of Abbreviations in Clinical Notes,7866149,R01LM010681,"['Abbreviations', 'Algorithms', 'Architecture', 'Caring', 'Cessation of life', 'Clinical', 'Communication', 'Computer Systems', 'Computer software', 'Computers', 'Confusion', 'Coronary Arteriosclerosis', 'Databases', 'Detection', 'Disease', 'Documentation', 'Effectiveness', 'Electronics', 'Equipment and supply inventories', 'Frequencies', 'Health Personnel', 'Healthcare', 'Individual', 'Informatics', 'Joints', 'Machine Learning', 'Manuals', 'Medical Records', 'Methods', 'Names', 'Natural Language Processing', 'Nitroglycerin', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Provider', 'Reader', 'Records', 'Serious Adverse Event', 'Solutions', 'System', 'Technology', 'Text', 'Time', 'Work', 'Writing', 'acronyms', 'base', 'health care delivery', 'health record', 'improved', 'innovation', 'insight', 'knowledge base', 'novel', 'phrases', 'satisfaction']",NLM,VANDERBILT UNIVERSITY,R01,2010,387500,0.0429397228691445
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7944035,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Epidemiology', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2010,494477,0.030776077899617137
"An NLP Approach to Generating Patient Record Summaries :  The long-term goal of this proposal is to enhance the manner in which physicians access, process and marshal medical information by providing them with an automatically generated, comprehensive, and up-to date summary of the information appearing in a patient record. At the point of patient care, physicians must often rapidly process a potentially overwhelming quantity of information pertaining to a patient. Failure to do so effectively may lead to provision of suboptimal care. Some electronic health record systems provide an automatically produced “cover sheet” geared to help physicians with a broad overview of a given patient, but the information is derived from the structured data fields in the patient record, ignoring the valuable narrative text entered by clinicians over time. We are building upon our prior work in summarization and natural language processing and leveraging our expertise in cognitive research studying information needs and decision making of clinicians to build a patient record summarizer that gathers information narrative (unstructured) as well as structured parts in the record. We focus on producing a summary for patients with kidney disease, as they often have a complex medical history with numerous conditions, procedures and medications. Providing a holistic, up-to-date summary of their chart would prove valuable to physicians in general and nephrologists in particular. The following three aims will be carried out: (1) conduct a formative study to determine how physicians prioritize and mentally represent relevant information when reviewing a patient chart; (2) create a set of automated methods to select salient pieces of information in the patient record and organize them into a coherent summary; and (3) evaluate the efficacy, efficiency and physician-user satisfaction associated with the use of the summarizer. A primary strength of this proposal is that we are addressing the problem of information overload, a bottleneck in the use of electronic health records, and evaluate the impact of our solution on clinicians’ actions and patients’ health outcomes. Furthermore, we propose to use novel natural language processing, knowledge-based and data mining methods to extract and organize salient information. Finally, we contribute to informatics research by extending the electronic health record functionalities to go beyond a simple documentation-entry system towards a useful reference and decision-making tool for physicians  Project Narrative We propose to design an automatically generated, comprehensive, and up-to-date summary of the information appearing in a patient record. Such a summary would enhance the manner in which both patients and their physicians access, process and marshal medical information.",An NLP Approach to Generating Patient Record Summaries,7925659,R01LM010027,"['Address', 'Allergic', 'Caring', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Data', 'Data Analyses', 'Decision Making', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation Studies', 'Face', 'Failure', 'Feasibility Studies', 'Goals', 'Hand', 'Health', 'Health Status', 'Informatics', 'Information Resources', 'Interview', 'Kidney Diseases', 'Knowledge', 'Laboratories', 'Lead', 'Link', 'Marshal', 'Medical', 'Medical History', 'MedlinePlus', 'Methods', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Personal Health Records', 'Pharmaceutical Preparations', 'Physicians', 'Procedures', 'Process', 'Records', 'Research', 'Resources', 'Solutions', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Visit', 'Work', 'data mining', 'design', 'health literacy', 'information gathering', 'knowledge base', 'literate', 'medical schools', 'meetings', 'novel', 'research study', 'satisfaction', 'stem', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,456856,0.027172162295210422
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,7784533,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical data warehouse', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,341606,0.02703861995243101
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,8056227,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical data warehouse', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,177422,0.02703861995243101
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",7985218,R01GM090187,"['Address', 'Algorithms', 'Automated Annotation', 'Caring', 'Clinical', 'Clinical Research', 'Code', 'Communities', 'Computerized Medical Record', 'Consensus', 'Country', 'Data Set', 'Development', 'Disease', 'Evaluation', 'Goals', 'Gold', 'Guidelines', 'Individual', 'Judgment', 'Knowledge', 'Linguistics', 'Manuals', 'Medical Records', 'Methodology', 'Methods', 'Metric', 'Natural Language Processing', 'Performance', 'Reliance', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Signs and Symptoms', 'System', 'Technology', 'Terminology', 'Text', 'Training', 'Translational Research', 'Translations', 'base', 'cost', 'design', 'flexibility', 'innovation', 'knowledge translation', 'phrases', 'prevent', 'public health relevance', 'research clinical testing', 'research study', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,1,0.09631224958504313
"Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2)    DESCRIPTION (provided by applicant): The eTfor2 project will develop and evaluate open-source programs and knowledge representations to better characterize patients for translational and clinical research studies. The project addresses National Library of Medicine (NLM) RFA initiatives for: (a) information & knowledge processing, including natural language processing and text summarization, (b) approaches for linking phenomic and genomic information, and (c) integration of information from heterogeneous sources. Translational studies correlate clinical patient descriptors (phenome) with results of genomic investigations, e.g., genome-wide association studies (GWAS). Standard methods for defining phenotypes require costly, labor-intensive cohort enrollments to identify patients with diseases and appropriate controls. Recently, translational and clinical researchers have used electronic medical record (EMR) data as an alternative to identifying patient characteristics. However, EMR case extraction requires substantial manual review and ""tuning"" for case selection, due to the inaccuracies inherent in ICD9 billing codes. While relevant and useful natural language processing (NLP) approaches to facilitate EMR text extraction have proliferated, the target patient descriptors these approaches employ typically remain non-standard and locally defined, and vary from disease to disease, project to project and institution to institution. At best, such NLP applications use standard terminology descriptors such as SNOMED-CT as EMR extraction targets. Yet, there is no generally utilized ""standard"" knowledge base that links such ""extractable"" descriptors to an academic-quality knowledge source detailing what findings have been reliably reported to occur in each disease. To facilitate translational and clinical research, the eTfor2 project will make available an open-source, evidence-based, electronic clinical knowledge base (KB) and related NLP tools enabling researchers at any site to extract a standard ""target"" set of EMR-based phenomic descriptors at both the finding and disease levels. It will further include diagnostic decision support logic to confirm the degree of support for patients' diagnoses in their EMR records. The eTfor2 project will decrease effort required to harvest EMR patient descriptors for clinical and translational studies, and enable new translational work that identifies genomic associations at both finding and disease levels. The eTfor2 resources should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.           Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2) Project Narrative When completed successfully, the eTfor2 project will enable researchers at disparate institutions to extract from their respective EMR systems a shared ""target"" set of common phenomic descriptors, in a standard, reproducible manner. Doing so should improve the quality and cross-institutional validity of EMR-based translational and clinical studies.",Evidence-based Diagnostic Tools for Translational and Clinical Research (eTfor2),7950411,R01LM010828,"['18 year old', 'Abdomen', 'Abdominal Pain', 'Address', 'Adult', 'Algorithms', 'Automated Abstracting', 'Biopsy', 'Characteristics', 'Child', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Companions', 'Computer-Assisted Diagnosis', 'Computerized Medical Record', 'Core Facility', 'DNA', 'DNA Databases', 'Data', 'Data Analyses', 'Descriptor', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electronics', 'Enrollment', 'Epigastrium', 'Evaluation Studies', 'Exhibits', 'Generic Drugs', 'Genes', 'Genomics', 'Goals', 'Gold', 'Harvest', 'Human', 'Image', 'Individual', 'Institution', 'Intellectual Property', 'Internal Medicine', 'Internist', 'Intra-abdominal', 'Investigation', 'Knowledge', 'Laboratories', 'Licensing', 'Link', 'Literature', 'Logic', 'Manuals', 'Maps', 'Methods', 'Metric', 'Names', 'Natural Language Processing', 'Negative Finding', 'Normal Range', 'Outcome', 'Pain', 'Patient Care', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Physical Examination', 'Process', 'Proliferating', 'Property Rights', 'Proteomics', 'Publishing', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'SNOMED Clinical Terms', 'Sampling', 'Side', 'Site', 'Source', 'Specific qualifier value', 'Splenomegaly', 'Supplementation', 'Symptoms', 'System', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'United States National Library of Medicine', 'Universities', 'Visceromegaly', 'Vocabulary', 'Work', 'base', 'case control', 'clinical phenotype', 'cohort', 'evidence base', 'genome wide association study', 'improved', 'information organization', 'innovation', 'interest', 'knowledge base', 'meetings', 'member', 'open source', 'phenome', 'phenomics', 'programs', 'research study', 'success', 'theories', 'tool', 'translational study']",NLM,VANDERBILT UNIVERSITY,R01,2010,388125,0.032345853593277324
"Temporal Processing for Medical Discharge Summaries    DESCRIPTION (provided by applicant):       The goals of our project are as follows:     1. Create a corpus of temporally annotated data. Under the supervision of our consultants Dr. Frank Sacks, Dr. Vincent Carey, and two Registered Nurses, we will create a gold-standard annotation of events and temporal information within patient narratives from de- identified Electronic Health Record data using the CLEF and TimeML guidelines. We will use the framework of the Brandeis Annotation Tool, a system we have designed to facilitate the quick construction of accurately annotated corpora against a specified guideline. Extensions to the current event library and lexicon with medical event references will be made during the annotation process, under the guidance of the Registered Nurses.          2. Adapt the TARSQI Toolkit (TTK) to targeted temporal properties and relations in the EHR domain. We will use the TARSQI toolkit, a robust set of temporal processing algorithms we have designed for parsing natural language text, to automatically annotate the events and temporal information in EHR data. Combined with the Brandeis AcroMed Medical Abbreviation Server and those terms introduced in part 1, we will employ the Specialist Lexicon and other medical resources to extend the toolkit capabilities for recognizing and interpreting medical event information. Algorithms for identifying events, temporal expressions, and event anchorings and orderings will be trained against the gold standard created in Aim 1, and tested against held-out data.     3. Create a cross-document temporal database of medical events. Using the recognition algorithms introduced in Aim 2, we will create a searchable, temporally ordered database of medical events such as diseases, symptoms, surgeries/interventions, and test results. Events referred to multiple times in the data will be merged using a constraint- satisfaction analysis in order to create a more coherent narrative for a single patient over multiple records.           Project Narrative It is becoming increasingly common for medical researchers to use Electronic Health Records (EHRs) as a primary source of data for researching correlations between various medical issues and concepts. However, EHRs typically contain unstructured text, making them difficult to mine. This research will create a database of temporal orderings from events extracted from EHR patient narratives, using algorithms previously applied to news articles.",Temporal Processing for Medical Discharge Summaries,7941063,R21LM009633,"['Abbreviations', 'Adopted', 'Algorithms', 'Authorization documentation', 'Clinical', 'Clinical Research', 'Data', 'Data Sources', 'Databases', 'Diagnosis', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Event', 'Goals', 'Gold', 'Guidelines', 'Intervention', 'Language', 'Libraries', 'Licensing', 'Machine Learning', 'Medical', 'Medical History', 'Medical Libraries', 'Mining', 'Operative Surgical Procedures', 'Patients', 'Process', 'Property', 'Records', 'Registered nurse', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Science', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Supervision', 'Symptoms', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Vocabulary', 'acronyms', 'base', 'design', 'evidence base', 'experience', 'interest', 'lexical', 'natural language', 'news', 'open source', 'relational database', 'repository', 'satisfaction', 'tool']",NLM,BRANDEIS UNIVERSITY,R21,2010,175973,0.032605132949269144
"Voice Based, Workflow Enhancing, Primary Care Medical Data Input System    DESCRIPTION (provided by applicant): The adoption of electronic health records (EHR) in hospitals and physician offices has been widely promoted as a single solution to a wide variety of health care issues. Yet 84% of small and medium business (SMB) physician practices in the US have not adopted EHR systems. Interventional Dynamics Corporation (IDC) has conducted more than 200 primary care physician interviews, finding that the major disincentives to adoption are workflow delay and expense. The single greatest factor in the reduction of workflow speed is the data input process. IDC's proposed project has this specific aim: Utilize an innovative voice entry technique and open source code systems to develop a low-cost, automated solution to allow primary care physicians to complete a primary care note entirely during the patient examination process. The narrative speech input will be analyzed in a context-sensitive, domain-restricted manner to produce structured clinical data that can be readily integrated into standards-compliant electronic medical records. By using speech inputs that are converted directly to relevant EHR entries, physicians can increase the accuracy of their notes, eliminate third party transcription errors and avoid workflow delays. The project approach will include:    Further testing and final development of DocTalk, the IDC patent pending speech system that allows accurate natural language processing of structured medical information; Development of a proof-of-concept data system that converts physician voice input from voice to text to structured text to EHR data using domain enhanced open source code; The evaluation of the effectiveness of the proof-of-concept system against traditional EHR  input methods with the following goals: Achieve 50% or more reduction in charting time,  achieve 90% or more accuracy in output, and score greater than 4 of 5 on subjective  metrics including learnability, workflow fit, usability, and overall satisfaction. Successful completion of the proposed program will provide IDC with a viable technology platform that can immediately be useful to primary care physicians in generating structured documents for use with their current EHR platforms. Furthermore, the technology developed and refined within this program can be expanded in multiple ways.      PUBLIC HEALTH RELEVANCE:  The IDC technology is designed to circumvent the normal barriers to adoption in the SMB market and allow for quick increases in workflow and quality of patient care at a minimal price point. IDC will provide physicians who currently use pen and paper a more natural and faster way to input clinical data, eliminating time spent on hunt-and-peck keyboard entry or complicated EHR screen navigation. The system will generate structured clinical data that enables the exchange of health information, the portability of patient records, billing, data analytics (both local practice and public health), marketing, and other benefits, resulting in the reduction of overall healthcare costs.           Narrative The IDC technology is designed to circumvent the normal barriers to adoption in the SMB market and allow for quick increases in workflow and quality of patient care at a minimal price point. IDC will provide physicians who currently use pen and paper a more natural and faster way to input clinical data, eliminating time spent on hunt-and-peck keyboard entry or complicated EHR screen navigation. The system will generate structured clinical data that enables the exchange of health information, the portability of patient records, billing, data analytics (both local practice and public health), marketing, and other benefits, resulting in the reduction of overall healthcare costs.","Voice Based, Workflow Enhancing, Primary Care Medical Data Input System",7924457,R43LM010750,"['Adopted', 'Adoption', 'Architecture', 'Businesses', 'Clinical', 'Clinical Data', 'Code', 'Computer Assisted', 'Computerized Medical Record', 'Data', 'Data Storage and Retrieval', 'Development', 'Disincentive', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Genetic Transcription', 'Goals', 'Health', 'Health Care Costs', 'Healthcare', 'Hospitals', 'Industry', 'Information Systems', 'International', 'Interview', 'Legal patent', 'Marketing', 'Medical', 'Medical Records', 'Methods', 'Metric', 'Natural Language Processing', 'Output', 'Paper', 'Patient Care', 'Patients', 'Pediatric Surgical Procedures', 'Physicians', 'Physicians&apos', ' Offices', 'Price', 'Primary Care Physician', 'Primary Health Care', 'Process', 'Public Health Practice', 'Records', 'Research', 'Research Project Grants', 'Services', 'Solutions', 'Source Code', 'Speech', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Universities', 'Voice', 'base', 'billing data', 'cost', 'design', 'flexibility', 'innovation', 'open source', 'portability', 'programs', 'public health relevance', 'satisfaction', 'speech recognition', 'usability']",NLM,"VMT, INC.",R43,2010,241875,0.04643493418722744
"Annotation, development and evaluation for clinical information extraction    DESCRIPTION (provided by applicant): Much of the clinical information required for accurate clinical research, active decision support, and broad-coverage surveillance is locked in text files in an electronic medical record (EMR). The only feasible way to leverage this information for translational science is to extract and encode the information using natural language processing (NLP). Over the last two decades, several research groups have developed NLP tools for clinical notes, but a major bottleneck preventing progress in clinical NLP is the lack of standard, annotated data sets for training and evaluating NLP applications. Without these standards, individual NLP applications abound without the ability to train different algorithms on standard annotations, share and integrate NLP modules, or compare performance. We propose to develop standards and infrastructure that can enable technology to extract scientific information from textual medical records, and we propose the research as a collaborative effort involving NLP experts across the U.S. To accomplish this goal, we will address three specific aims: Aim 1: Extend existing standards and develop new consensus standards for annotating clinical text in a way that is interoperable, extensible, and usable. Aim 2: Apply existing methods and tools, and develop new methods and tools where necessary for manually annotating a set of publicly available clinical texts in a way that is efficient and accurate. Aim 3: Develop a publicly available toolkit for automatically annotating clinical text and perform a shared evaluation to evaluate the toolkit, using evaluation metrics that are multidimensional and flexible.      PUBLIC HEALTH RELEVANCE: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.           Project narrative: In this project, we will develop a publicly available corpus of annotated clinical texts for NLP research. We will experiment with methods for increasing the efficiency of annotation and will annotate de-identified reports of nine types for linguistic and clinical information. In addition, we will create an NLP toolkit that can be shared and will evaluate it against other NLP systems in a shared task evaluation with the community.","Annotation, development and evaluation for clinical information extraction",8231171,R01GM090187,[' '],NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2010,642650,0.09631224958504313
"Natural Language Processing for Cancer Research Network Surveillance Studies    DESCRIPTION (provided by applicant): This application addresses Broad Challenge Area: (10) Information Technology for Processing Health Care Data and specific Challenge Topic: 10-CA-107 Expand Spectrum of Cancer Surveillance through Informatics Approaches. The proposed project launches a collaborative effort to advance adoption within the HMO Cancer Research Network (CRN) of ""industrial-strength"" natural language processing (NLP) systems useful for mining valuable, research-grade information from unstructured clinical text. Such text is available for processing, now in the electronic medical record (EMR) systems of affiliated CRN health plans. The proposed NLP methods   will create ongoing capacity to tap what has recently been described as ""a treasure trove of historical   unstructured data that provides essential information for the study of disease progression, treatment   effectiveness and long-term outcomes"" (5). The vision of advancing widespread NLP capacity across the CRN, as well as the approach we present here for implementing it, grew out of an in-depth strategic planning effort we completed in December 2008. That effort involved participants from six CRN sites guided by a blue-ribbon panel of NLP experts from three of the nation's leading centers of clinical NLP research: University of Pittsburgh Medical Center, Vanderbilt University, and Mayo Clinic. The vision is to deploy a powerful NLP system locally, manage it with newly hired and trained local NLP technical staff, and conduct NLP-based research projects initiated by local investigators, in consultation with higher-level external NLP experts. Our planning efforts suggest this collaborative model is feasible; we will test the model in the context of the proposed project. An important development in April 2009 yielded what we believe is a potentially transformative opportunity to accelerate adoption of NLP capacity in applied research settings: release of the open-source Clinical Text Analysis and Knowledge Extraction System (cTAKES) software. This software was the result of a collaborative effort between IBM and Mayo Clinic. Built on the same framework Mayo Clinic currently uses to process its repository of over 40 million clinical documents, cTAKES dramatically lowers the cost of adopting a comprehensive and flexible NLP system. Deployment and use of such systems was previously only feasible in institutions with large, academically-oriented biomedical informatics research programs.   Still, other deployment challenges and the need to acquire NLP training for local staff present residual   barriers to adopting comprehensive NLP systems such as cTAKES. In collaboration with five other CRN sites the proposed project mitigates these challenges in two ways: 1) it develops configurable open-source software modules needed to streamline and therefore reduce the cost of deploying cTAKES, and 2) it presents and tests a model for training local staff through hands-on NLP projects overseen by outside NLP expert consultants. The potential impact of this project is evident most clearly in the vast untapped opportunities for text mining represented in CRN-affiliated health plans, where EMR systems have been in place since at least 2005, and whose patients represent 4% of the U.S. population. Clinical text mining offers the potential to provide new or improved data elements for cancer surveillance and other types of research requiring information about patient functional status, medication side-effects, details of therapeutic approaches, and differential information about clinical findings. Another significant impact of this project is its plan to integrate into the cTAKES system   an open-source de-identification tool based on state of the art, best of breed NLP approaches developed by the MITRE Corporation. De-identification of clinical text will make it easier for researchers to get access to clinical text, and will also facilitate multi-site collaborations while protecting patient privacy. Finally, if successful, the NLP algorithm we propose as a proof-of-principle project at Group Health-which will classify sets of patient charts as either containing or not containing a diagnosis of recurrent breast cancer-could dramatically reduce the cost of research in this area; currently all recurrent breast cancer endpoints must be established through costly manual chart abstraction.   Novel aspects of the proposed project include its talented and transdisciplinary research team,   including national experts in NLP, and its resourceful strategy for building the technical resources and ""human capital"" needed to support an ongoing program of applied NLP research. Natural language processing is itself a highly innovative technology; when successfully established in multiple CRN in the future it will represent a watershed moment in the CRN's already impressive history of exploiting data systems to support innovative research. Newly hired staff positions total approximately 2.0 FTE in each project year, most of which we anticipate will be supported by ongoing new research programs after the proposed project concludes. Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.           Project narrative The proposed project develops new measurement technologies for extracting information about disease processes and treatment, currently documented only in clinical text, based on natural language processing approaches. Because these methods are generic they will potentially contribute to public health by advancing research in a wide variety of areas. The ""proof of principle"" algorithm developed in the project to identify recurrent breast cancer diagnoses will advance epidemiologic and clinical research pertaining to the 2.5 million women currently living with breast cancer.",Natural Language Processing for Cancer Research Network Surveillance Studies,7839706,RC1CA146917,"['Address', 'Adopted', 'Adoption', 'Adverse effects', 'Algorithms', 'Applied Research', 'Area', 'Arts', 'Bioinformatics', 'Breeding', 'Cancer Research Network', 'Charge', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Complex', 'Comprehensive Health Care', 'Computer software', 'Computerized Medical Record', 'Consultations', 'Data', 'Data Element', 'Data Quality', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Doctor of Philosophy', 'Environment', 'Exercise', 'Future', 'Generic Drugs', 'Hand', 'Health', 'Health Planning', 'Health system plans', 'Healthcare', 'Human Resources', 'Individual', 'Informatics', 'Information Systems', 'Information Technology', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Licensing', 'Life', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Mining', 'Modeling', 'NCI Center for Cancer Research', 'Natural Language Processing', 'Operating System', 'Outcome', 'Participant', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Process', 'Public Health', 'Recording of previous events', 'Recurrence', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Residual state', 'Resources', 'Risk', 'Site', 'Solutions', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Text', 'Therapeutic', 'Training', 'Treatment Effectiveness', 'Universities', 'Vision', 'Woman', 'base', 'biomedical informatics', 'breast cancer diagnosis', 'cost', 'design', 'experience', 'feeding', 'firewall', 'flexibility', 'functional status', 'human capital', 'improved', 'innovation', 'innovative technologies', 'malignant breast neoplasm', 'novel', 'open source', 'patient privacy', 'programs', 'repository', 'skills', 'software systems', 'surveillance study', 'text searching', 'tool']",NCI,KAISER FOUNDATION HEALTH PLAN OF WASHINGTON,RC1,2009,497857,0.030776077899617137
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7691692,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development', 'web site']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2009,177750,0.07834363094696499
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7850343,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development', 'web site']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2009,99971,0.07834363094696499
"An NLP Approach to Generating Patient Record Summaries :  The long-term goal of this proposal is to enhance the manner in which physicians access, process and marshal medical information by providing them with an automatically generated, comprehensive, and up-to date summary of the information appearing in a patient record. At the point of patient care, physicians must often rapidly process a potentially overwhelming quantity of information pertaining to a patient. Failure to do so effectively may lead to provision of suboptimal care. Some electronic health record systems provide an automatically produced “cover sheet” geared to help physicians with a broad overview of a given patient, but the information is derived from the structured data fields in the patient record, ignoring the valuable narrative text entered by clinicians over time. We are building upon our prior work in summarization and natural language processing and leveraging our expertise in cognitive research studying information needs and decision making of clinicians to build a patient record summarizer that gathers information narrative (unstructured) as well as structured parts in the record. We focus on producing a summary for patients with kidney disease, as they often have a complex medical history with numerous conditions, procedures and medications. Providing a holistic, up-to-date summary of their chart would prove valuable to physicians in general and nephrologists in particular. The following three aims will be carried out: (1) conduct a formative study to determine how physicians prioritize and mentally represent relevant information when reviewing a patient chart; (2) create a set of automated methods to select salient pieces of information in the patient record and organize them into a coherent summary; and (3) evaluate the efficacy, efficiency and physician-user satisfaction associated with the use of the summarizer. A primary strength of this proposal is that we are addressing the problem of information overload, a bottleneck in the use of electronic health records, and evaluate the impact of our solution on clinicians’ actions and patients’ health outcomes. Furthermore, we propose to use novel natural language processing, knowledge-based and data mining methods to extract and organize salient information. Finally, we contribute to informatics research by extending the electronic health record functionalities to go beyond a simple documentation-entry system towards a useful reference and decision-making tool for physicians  Project Narrative We propose to design an automatically generated, comprehensive, and up-to-date summary of the information appearing in a patient record. Such a summary would enhance the manner in which both patients and their physicians access, process and marshal medical information.",An NLP Approach to Generating Patient Record Summaries,7635002,R01LM010027,"['Address', 'Allergic', 'Caring', 'Clinic', 'Clinical', 'Cognitive', 'Complex', 'Data', 'Data Analyses', 'Decision Making', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation Studies', 'Failure', 'Goals', 'Harvest', 'Health', 'Informatics', 'Information Resources', 'Interview', 'Kidney Diseases', 'Kidney Function Tests', 'Knowledge', 'Laboratories', 'Lead', 'Marshal', 'Medical', 'Medical History', 'Methods', 'Natural Language Processing', 'Outcome', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Procedures', 'Process', 'Research', 'Solutions', 'Source', 'Structure', 'Surveys', 'System', 'Techniques', 'Text', 'Time', 'Visit', 'Work', 'data mining', 'design', 'information gathering', 'knowledge base', 'medical schools', 'meetings', 'novel', 'research study', 'satisfaction', 'stem', 'tool']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,455605,0.027172162295210422
"Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data    DESCRIPTION (provided by applicant):       Our long-term objective is to enlarge the scope and efficiency of clinical research through enhanced use of clinical data to support clinical research decisions. This proposal aims to improve the use of electronic health records (EHR) to automate clinical trials eligibility screening by developing a new semantic alignment framework. Clinical trials research is an important step for translating breakthroughs in basic biomedical sciences into knowledge that will benefit clinical practice and human health. However, a significant obstacle is identifying eligible participants. Eighty-six percent of all clinical trials are delayed in patient recruitment for from one to six months and 13% are delayed by more than six months. Enrollment delay is expensive. In a recent large, multi-center trial, about 86.8 staff hours and more than $1000 was spent to enroll each participant. Ineffective enrollment also produces a big social cost in that up to 60% of patients can miss being identified. The broad deployment of EHR systems has created unprecedented opportunities to solve the problem because EHR systems contain a rich source of information about potential participants. However, it is often a knowledge-intensive, time-consuming, and inefficient manual procedure to match eligibility criteria such as ""renal in- sufficiency"" to clinical data such as ""serum creatinine = 1.0 mg/dl for an 80-year old white female patient."" This enduring challenge is partly caused by the disconnection between abstract and ambiguous eligibility criteria and highly specific clinical data manifestations; we call this a semantic gap. Despite earlier work on computer-based clinical guidelines and protocols, limited effort has been devoted to support automatic matching between concepts and their manifestations in patient phenotypes such as signs and symptoms.       We hypothesize that we can characterize the semantic gap and design a knowledge-based, natural-language processing assisted semantic alignment framework to bridge the semantic gap. Therefore, our specific aims are: (1) to investigate the semantic gap between clinical trials eligibility criteria and clinical data; (2) to design a concept-based, computable knowledge representation for eligibility criteria; (3) to design a semantic alignment framework linking an eligibility criteria knowledge base and a clinical data warehouse to generate semantic queries for eligibility identification; and (4) to evaluate the utility of the semantic alignment framework.       This research is novel and unique in that (1) there are no prior studies about the semantic gap between eligibility criteria and clinical data; and (2) for the first time, we design a semantic alignment framework to automatically match eligibility criteria to clinical data. The research team comprising expertise from the Department of Biomedical Informatics at Columbia University and the Division of General Medicine from UCSF are uniquely positioned to carry out this research, given the experience of the team (medical knowledge representation, natural language processing, controlled clinical terminology, ontology-based semantic reasoning, data mining, statistics, health data organization, semantic harmonization, and clinical trials), the availability of a repository of 13 years of data on 2 million patients, and the availability of a natural language processor called MedLEE to convert millions of narrative reports into richly coded clinical data.            This research has the potential to improve process efficiency and accuracy, as well as to reduce cost and required human skills for clinical trials eligibility screening. The ultimate goal is to accelerate scientific discovery of more effective treatments for illness.",Bridging the Semantic Gap Between Research Eligibility Criteria and Clinical Data,7653874,R01LM009886,"['Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Complex', 'Computers', 'Creatinine', 'Data', 'Databases', 'Drug Formulations', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Female', 'Goals', 'Guidelines', 'Health', 'Hour', 'Human', 'Kidney', 'Kidney Failure', 'Knowledge', 'Link', 'Manuals', 'Medical', 'Medicine', 'Methods', 'Natural Language Processing', 'Ontology', 'Participant', 'Patient Recruitments', 'Patients', 'Phenotype', 'Population Surveillance', 'Positioning Attribute', 'Problem Solving', 'Procedures', 'Process', 'Protocols documentation', 'Reporting', 'Research', 'Science', 'Screening procedure', 'Semantics', 'Serum', 'Signs and Symptoms', 'Source', 'System', 'Techniques', 'Terminology', 'Text', 'Time', 'Translating', 'Translations', 'Universities', 'Work', 'abstracting', 'base', 'biomedical informatics', 'clinical phenotype', 'clinical practice', 'cost', 'data mining', 'design', 'effective therapy', 'eligible participant', 'experience', 'improved', 'information organization', 'knowledge base', 'natural language', 'novel', 'repository', 'skills', 'social', 'statistics']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2009,357875,0.02703861995243101
"Temporal Processing for Medical Discharge Summaries    DESCRIPTION (provided by applicant):       The goals of our project are as follows:     1. Create a corpus of temporally annotated data. Under the supervision of our consultants Dr. Frank Sacks, Dr. Vincent Carey, and two Registered Nurses, we will create a gold-standard annotation of events and temporal information within patient narratives from de- identified Electronic Health Record data using the CLEF and TimeML guidelines. We will use the framework of the Brandeis Annotation Tool, a system we have designed to facilitate the quick construction of accurately annotated corpora against a specified guideline. Extensions to the current event library and lexicon with medical event references will be made during the annotation process, under the guidance of the Registered Nurses.          2. Adapt the TARSQI Toolkit (TTK) to targeted temporal properties and relations in the EHR domain. We will use the TARSQI toolkit, a robust set of temporal processing algorithms we have designed for parsing natural language text, to automatically annotate the events and temporal information in EHR data. Combined with the Brandeis AcroMed Medical Abbreviation Server and those terms introduced in part 1, we will employ the Specialist Lexicon and other medical resources to extend the toolkit capabilities for recognizing and interpreting medical event information. Algorithms for identifying events, temporal expressions, and event anchorings and orderings will be trained against the gold standard created in Aim 1, and tested against held-out data.     3. Create a cross-document temporal database of medical events. Using the recognition algorithms introduced in Aim 2, we will create a searchable, temporally ordered database of medical events such as diseases, symptoms, surgeries/interventions, and test results. Events referred to multiple times in the data will be merged using a constraint- satisfaction analysis in order to create a more coherent narrative for a single patient over multiple records.           Project Narrative It is becoming increasingly common for medical researchers to use Electronic Health Records (EHRs) as a primary source of data for researching correlations between various medical issues and concepts. However, EHRs typically contain unstructured text, making them difficult to mine. This research will create a database of temporal orderings from events extracted from EHR patient narratives, using algorithms previously applied to news articles.",Temporal Processing for Medical Discharge Summaries,7789943,R21LM009633,"['Abbreviations', 'Adopted', 'Algorithms', 'Authorization documentation', 'Body of uterus', 'Clinical', 'Clinical Research', 'Data', 'Data Sources', 'Databases', 'Diagnosis', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Event', 'Goals', 'Gold', 'Guidelines', 'Information Resources', 'Intervention', 'Language', 'Libraries', 'Licensing', 'Machine Learning', 'Medical', 'Medical History', 'Medical Libraries', 'Mining', 'Operative Surgical Procedures', 'Patients', 'Process', 'Property', 'Records', 'Registered nurse', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Science', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Supervision', 'Symptoms', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Vocabulary', 'acronyms', 'base', 'design', 'evidence base', 'experience', 'interest', 'lexical', 'natural language', 'news', 'open source', 'repository', 'satisfaction', 'tool']",NLM,BRANDEIS UNIVERSITY,R21,2009,177750,0.032605132949269144
"Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach    DESCRIPTION (provided by applicant):       The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The study design is prospective observational study. Scope is limited to cancer patients. There are three specific aims for this project. The first aim is to identify concepts that overlap between the electronic medical record's (EMR) clinical notes and the free text of clinical trial announcements. The PI will use the concepts to develop mapping frames that connect concepts in the text of trial announcements to those found in clinical notes in the medical record. When he has the mapping frames he will build the NLP module for the application. In the software development work he will utilize as many publicly available software components as possible. He will experiment with UIMA, GATE, MetaMap, Stanford Parser, NegEx algorithm and others. The PI will develop the tool around the National Library of Medicine's Unified Medical Language System knowledgebase. He will use Java for programming. The second aim is to create an algorithm that automatically generates questions to request information directly from the patient if the information is not available or accessible in the records. The third aim is to evaluate the in-vitro, laboratory performance of the application. For performance evaluation purposes the PI will recruit cancer care specialists to generate the gold standard lists of eligible clinical trials for study patients. He will publicly release the developed code at the end of the grant period. This K99/R00 project will serve the foundation for future R01 grant applications. The PI is fully committed to become faculty in the Clinical Research Informatics domain with a specialization in biomedical NLP. The support of the K99/R00 grant will enable him to acquire substantial formal training in Computational Linguistics while contributing to the body of knowledge of the Clinical Research Informatics field. The five-year grant support will ensure success in his endeavor. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, EMR based clinical trial recommendations directly to the patients. The results of this research will empower the patients and elevate their role in the decision making process.           Relevance The long-term objective of this research is to increase the clinical trial enrollment of US patients via a semi- automated, Natural Language Processing (NLP) based, interactive and patient-centered informatics application. The proposed work is highly significant because the dismal clinical trial accrual rates (2-4 % nationally) hampers timely development of new drugs. In addition, studies show that physicians have statistically significant bias against elderly and minority patients to invite participation in clinical trials. The proposed project is synergistic with physician-centered efforts but the goal is to provide individualized, electronic medical record based clinical trial recommendations directly to the patients. The results of this research will empower patients and elevate their role in the decision making process.",Increasing Clinical Trial Enrollment: A Semi-Automated Patient Centered Approach,7770648,K99LM010227,"['Adult', 'Age', 'Algorithms', 'Applications Grants', 'Arts', 'Biomedical Research', 'Cancer Patient', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical trial protocol document', 'Code', 'Commit', 'Complement', 'Computer software', 'Computerized Medical Record', 'Decision Making', 'Development', 'Elderly', 'Elements', 'Eligibility Determination', 'Enrollment', 'Ensure', 'Equation', 'Evaluation', 'Faculty', 'Foundations', 'Future', 'Goals', 'Gold', 'Grant', 'Hand', 'In Vitro', 'Informatics', 'Java', 'Knowledge', 'Laboratories', 'Linguistics', 'Malignant Neoplasms', 'Maps', 'Medical Records', 'Medicine', 'Methods', 'Minority', 'Modification', 'Natural Language Processing', 'Newly Diagnosed', 'Observational Study', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Protocols documentation', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Records', 'Recruitment Activity', 'Research', 'Research Design', 'Role', 'Screening for cancer', 'Screening procedure', 'Specialist', 'Surgeon', 'Text', 'Training', 'Unified Medical Language System', 'United States National Library of Medicine', 'Work', 'base', 'cancer care', 'empowered', 'ethnic minority population', 'information organization', 'novel', 'older patient', 'patient oriented', 'programs', 'prospective', 'research study', 'software development', 'success', 'tool']",NLM,UNIVERSITY OF WASHINGTON,K99,2009,84306,0.0406028016113492
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7908086,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,130902,0.07022916455090412
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7660312,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Constitutional', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,362514,0.07022916455090412
"POET: Consolidated, Comprehensive Clinical Text Preprocessing    DESCRIPTION (provided by applicant):       As electronic health records (EHRs) continue their expansion into clinical settings, there has been a corresponding increase in interest in mining the data they contain, both for research as well as for clinical decision support. Informaticists are increasingly studying ways to mine EHR textual content. This is an important trend, because there is a wealth of information contained in clinical text not represented anywhere else in the EHR. There is a low level text-as-data issue which presents a significant obstacle to the widespread use of available medical NLP systems: hand-typed clinical narratives in EHRs are usually ungrammatical; short or telegraphic in style; full of abbreviations, acronyms, and misspellings; formatted in a templated or pseudo-tabular form; and contain embedded non-text such as a list of laboratory values cut-and-pasted from elsewhere in the EHR. As we show in the Preliminary Studies Section, this makes high-level processing by popular tools like MedLEE and MetaMap effectively useless for all but a few ""clean"" document types like discharge summaries or consult reports (e.g., pathology or radiology reports). This in turn explains why there is so little published about what is certainly the preponderance of clinical texts, those that are not as well-behaved lexically and syntactically as a discharge summary.       In this application we distinguish clinical narratives (e.g., a progress note) from biomedical narratives (e.g., a PubMed abstract). We are interested in texts that arise in the clinical or research setting; texts that are composed by clinicians and researchers directly into a computer system. We propose to build and publish a tool called POET (Parsable Output Extracted from Text). POET will be designed to accept unstructured textual documents and return structured, linguistic equivalents that are, to the extent possible, parsable by higher-level NLP engines. POET will have an architecture is modular, extensible, and based on open-source platforms and sources (e.g., Java, Perl, UMLS, NegEx, the Stanford Parser, HL7 Clinical Document Architecture, caGRID, etc.). To implement POET, we will collect, program, and evaluate published as well as novel algorithms for: acronym/abbreviation resolution; spelling correction; template and pseudo-table re-writing; and removal of embedded non-text. To test POET we will use a large corpus of cross-discipline (e.g., medical, nursing, pharmacy, etc.) clinical note types, as well as the clinical research texts MedWatch reports and IRB adverse event reports. The development of POET will combine the best practices found in the literature and new research efforts as part of the project. To validate the fidelity of POET processing we plan a formal analysis of information loss and information gain pre- and post-process. To ensure broad access to the tools, POET will be released under an open-source license. Finally, we plan to assess the feasibility of offering POET as a Web service for remote processing.           Public Health Relevance This project attempts the construction of POET, a low-level preprocessing system for full text that can be used to open up large portions of the electronic health record (EHR) to high-level NLP systems. The potential public health implications are: 1) POET will allow the expansion of the use of well-proven clinical NLP systems  (currently limited to only a few document types found in the EHR) to the entire  clinical text record; with the entirety of the clinical record accessible to NLP,  serious and realistic attempts at real-time clinical text surveillance can be  mounted to improve patient safety and quality of care; 2) POET will be made available through open source distribution and other means  to encourage the practical deployment of innovative decision support systems  using large healthcare network EHRs across the country; 3) POET meets an important translational public health informatics need by solving  persistent low-level barriers to effective data mining of clinical marriages in the  EHR. The wider public health implications include promoting effective computerized decision support and data mining to improve both personal and public health outcomes.","POET: Consolidated, Comprehensive Clinical Text Preprocessing",7847940,R21LM009967,"['Abbreviations', 'Adverse event', 'Algorithms', 'Architecture', 'Body of uterus', 'Clinical', 'Clinical Pharmacists', 'Clinical Research', 'Computer Systems', 'Consult', 'Country', 'Data', 'Decision Support Systems', 'Development', 'Discipline', 'Discipline of Nursing', 'Electronic Health Record', 'Ensure', 'Excision', 'Hand', 'Healthcare', 'Internet', 'Java', 'Laboratories', 'Licensing', 'Linguistics', 'Literature', 'Marriage', 'Medical', 'Mind', 'Mining', 'Natural Language Processing', 'Nature', 'Nurses', 'Outcome', 'Output', 'Paste substance', 'Pathology', 'Pathology Report', 'Pharmacy facility', 'Physical assessment', 'Process', 'PubMed', 'Public Health', 'Public Health Informatics', 'Publishing', 'Quality of Care', 'Radiology Specialty', 'Report (document)', 'Reporting', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resolution', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Study Section', 'System', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'acronyms', 'base', 'caGrid', 'computerized', 'data mining', 'design', 'discrete data', 'improved', 'innovation', 'interest', 'meetings', 'novel', 'open source', 'patient safety', 'programs', 'public health relevance', 'spelling', 'tool', 'trend']",NLM,UNIVERSITY OF UTAH,R21,2009,84657,0.07932701731826049
"POET: Consolidated, Comprehensive Clinical Text Preprocessing    DESCRIPTION (provided by applicant):       As electronic health records (EHRs) continue their expansion into clinical settings, there has been a corresponding increase in interest in mining the data they contain, both for research as well as for clinical decision support. Informaticists are increasingly studying ways to mine EHR textual content. This is an important trend, because there is a wealth of information contained in clinical text not represented anywhere else in the EHR. There is a low level text-as-data issue which presents a significant obstacle to the widespread use of available medical NLP systems: hand-typed clinical narratives in EHRs are usually ungrammatical; short or telegraphic in style; full of abbreviations, acronyms, and misspellings; formatted in a templated or pseudo-tabular form; and contain embedded non-text such as a list of laboratory values cut-and-pasted from elsewhere in the EHR. As we show in the Preliminary Studies Section, this makes high-level processing by popular tools like MedLEE and MetaMap effectively useless for all but a few ""clean"" document types like discharge summaries or consult reports (e.g., pathology or radiology reports). This in turn explains why there is so little published about what is certainly the preponderance of clinical texts, those that are not as well-behaved lexically and syntactically as a discharge summary.       In this application we distinguish clinical narratives (e.g., a progress note) from biomedical narratives (e.g., a PubMed abstract). We are interested in texts that arise in the clinical or research setting; texts that are composed by clinicians and researchers directly into a computer system. We propose to build and publish a tool called POET (Parsable Output Extracted from Text). POET will be designed to accept unstructured textual documents and return structured, linguistic equivalents that are, to the extent possible, parsable by higher-level NLP engines. POET will have an architecture is modular, extensible, and based on open-source platforms and sources (e.g., Java, Perl, UMLS, NegEx, the Stanford Parser, HL7 Clinical Document Architecture, caGRID, etc.). To implement POET, we will collect, program, and evaluate published as well as novel algorithms for: acronym/abbreviation resolution; spelling correction; template and pseudo-table re-writing; and removal of embedded non-text. To test POET we will use a large corpus of cross-discipline (e.g., medical, nursing, pharmacy, etc.) clinical note types, as well as the clinical research texts MedWatch reports and IRB adverse event reports. The development of POET will combine the best practices found in the literature and new research efforts as part of the project. To validate the fidelity of POET processing we plan a formal analysis of information loss and information gain pre- and post-process. To ensure broad access to the tools, POET will be released under an open-source license. Finally, we plan to assess the feasibility of offering POET as a Web service for remote processing.           Public Health Relevance This project attempts the construction of POET, a low-level preprocessing system for full text that can be used to open up large portions of the electronic health record (EHR) to high-level NLP systems. The potential public health implications are: 1) POET will allow the expansion of the use of well-proven clinical NLP systems  (currently limited to only a few document types found in the EHR) to the entire  clinical text record; with the entirety of the clinical record accessible to NLP,  serious and realistic attempts at real-time clinical text surveillance can be  mounted to improve patient safety and quality of care; 2) POET will be made available through open source distribution and other means  to encourage the practical deployment of innovative decision support systems  using large healthcare network EHRs across the country; 3) POET meets an important translational public health informatics need by solving  persistent low-level barriers to effective data mining of clinical marriages in the  EHR. The wider public health implications include promoting effective computerized decision support and data mining to improve both personal and public health outcomes.","POET: Consolidated, Comprehensive Clinical Text Preprocessing",7689273,R21LM009967,"['Abbreviations', 'Adverse event', 'Algorithms', 'Architecture', 'Body of uterus', 'Clinical', 'Clinical Pharmacists', 'Clinical Research', 'Computer Systems', 'Consult', 'Country', 'Data', 'Decision Support Systems', 'Development', 'Discipline', 'Discipline of Nursing', 'Electronic Health Record', 'Ensure', 'Excision', 'Hand', 'Healthcare', 'Internet', 'Java', 'Laboratories', 'Licensing', 'Linguistics', 'Literature', 'Marriage', 'Medical', 'Mind', 'Mining', 'Natural Language Processing', 'Nature', 'Nurses', 'Outcome', 'Output', 'Paste substance', 'Pathology', 'Pathology Report', 'Pharmacy facility', 'Physical assessment', 'Process', 'PubMed', 'Public Health', 'Public Health Informatics', 'Publishing', 'Quality of Care', 'Radiology Specialty', 'Report (document)', 'Reporting', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resolution', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Study Section', 'System', 'Testing', 'Text', 'Time', 'Unified Medical Language System', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'acronyms', 'base', 'caGrid', 'computerized', 'data mining', 'design', 'discrete data', 'improved', 'innovation', 'interest', 'meetings', 'novel', 'open source', 'patient safety', 'programs', 'public health relevance', 'spelling', 'tool', 'trend']",NLM,UNIVERSITY OF UTAH,R21,2009,166590,0.07932701731826049
"Investigating the generalizability of natural language processing of EMR data    DESCRIPTION (provided by applicant):       The electronic medical record (EMR) offers impressive opportunities for increasing care quality, but challenges stand in the way of realizing this vision. For example, coded EMR data readily available for analysis typically are incomplete (due to the prevalence of free-text clinical notes in EMR implementations), and data from different EMRs are often incommensurate due to differences in standard vocabularies and system implementations. While informatics research has shown the feasibility of automatically coding specific aspects of clinical text using Natural Language Processing (NLP), challenges remain for translating these informatics developments into large-scale care quality assessments. To date, successful NLP solutions for automated quality assessment have tended to be applications that are specific to (a) the target problem or clinical focus, (b) the EMR data system, and (c) the person or team that implements the NLP solution. In this study, we propose to begin addressing the problem of implementation team specificity by developing, evaluating, and making freely available a generalizable NLP development tool suite. The tools will enable widespread adoption of NLP systems to extract and code data from free text clinical notes. The Knowledge Editing Toolkit will simplify development of problem-specific knowledge by helping the user define the rules, concepts, and terms that constitute a domain-specific knowledge module, thus allowing any informaticist to develop an NLP application. The NLP Application Validation Toolkit will allow rapid testing and evaluation of the application against a gold standard of independently-coded test records from any EMR. To evaluate the effects of the toolkits on NLP generalizability, we will have three clinical informaticists each build two NLP applications (for a total of six distinct applications). One of their applications will identify a constellation of common clinical signs or symptoms (e.g., ""persistent cough"") that are relatively discrete concepts using simple language terms for many different clinical purposes. Their second application will assess behavioral counseling (e.g., ""alcohol counseling""), which uses complex language constructs for dedicated clinical purposes. We will describe and evaluate the accuracy of the solutions against independently coded test sets of medical records. We will quantify and compare the difficulty of creating these solutions as measured by the time, number of iterations required to build the applications, and the number of concepts and rules employed, as well as analyze variability in content and accuracy of the solutions created. In addition, we will use qualitative techniques to assess the ease of using the development tools; the difficulty in learning the tools; and specific types of problems, limitations, and bugs encountered. Such an NLP development tool suite has the potential to allow simple, elegant, and reliably good NLP solutions regardless of the clinical problem domain or the person developing the solution.           n/a",Investigating the generalizability of natural language processing of EMR data,7529967,R21LM009728,"['Address', 'Adopted', 'Adoption', 'Affect', 'Alcohols', 'Architecture', 'Behavioral', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Code', 'Complex', 'Computer Systems Development', 'Computerized Medical Record', 'Coughing', 'Counseling', 'Data', 'Databases', 'Development', 'Event', 'Gold', 'Healthcare Systems', 'Human Resources', 'Informatics', 'Information Systems', 'Information Technology', 'Institute of Medicine (U.S.)', 'Knowledge', 'Language', 'Learning', 'Measures', 'Medical Records', 'Modification', 'Natural Language Processing', 'Numbers', 'Performance', 'Persons', 'Positioning Attribute', 'Prevalence', 'Process', 'Proliferating', 'Purpose', 'Quality of Care', 'Records', 'Research', 'Running', 'Solutions', 'Source', 'Specificity', 'Standards of Weights and Measures', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'Translating', 'United States National Academy of Sciences', 'Ursidae Family', 'Validation', 'Vision', 'Vocabulary', 'care delivery', 'concept', 'cost', 'design', 'evaluation/testing', 'experience', 'health care quality', 'stem', 'success', 'tool', 'tool development']",NLM,KAISER FOUNDATION RESEARCH INSTITUTE,R21,2008,213300,0.07834363094696499
"NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports    DESCRIPTION (provided by applicant):       Many NLP applications have been successfully developed to extract information from text. Most of the   applications have focused on identifying individual clinical conditions in textual records, which is the first step in making the conditions available to computerized applications. However, identifying individual instances of clinical conditions is not sufficient for many medical informatics tasks - the context surrounding the condition is crucial for integrating the information within the text to determine the clinical state of a patient. We propose to perform in-depth studies on NLP issues requiring knowledge of the context of clinical conditions in clinical records. We will focus our research by using syndromic surveillance from emergency department (ED) reports as a case study.      For this proposal, we will test the following hypothesis: An NLP system that indexes clinical concepts and integrates contextual information modifying the concepts can identify acute clinical conditions from ED reports as well as physicians can.      We will identify clinical concepts necessary for surveillance of seven syndromes, including respiratory,   gastrointestinal, neurological, rash, hemorrhagic, constitutional, and botulinic. To evaluate the hypothesis, we will perform the following specific aims:      Aim 1. Perform in-depth, foundational studies on four NLP topics to gain a deeper understanding of the      pertinent NLP research capabilities required for identification of acute clinical conditions from ED reports, including negation, uncertainty, temporal discrimination, and finding validation;      Aim 2. Apply the knowledge learned from the foundational studies to develop and evaluate an automated application for ED reports that will determine the values for clinical variables relevant to identifying patients with any of seven syndromes.      The research is innovative, because it will generate an in-depth study of multiple NLP topics crucial to   understanding a patient's clinical state from textual records and will focus on contextual understanding and analysis. The research will be guided by linguistic principles, by the semantics and discourse structure of ED reports, and by the application area of biosurveillance. Because we will develop research methods and tools that are customized to a particular domain, we will constrain the research space, which will provide direction and enhance the chance for success. However, the methods and tools generated by this research should be extensible to other clinical report types and to other domain applications, because we will explicitly specify and study NLP concepts and relationships that are common to many application areas.             n/a",NLP Foundational Studies & Ontologies for Syndromic Surveillance from ED Reports,7469551,R01LM009427,"['Accident and Emergency department', 'Acute', 'Area', 'Case Study', 'Clinical', 'Clinical Data', 'Condition', 'Constitutional', 'Depth', 'Detection', 'Discrimination', 'Exanthema', 'Exhibits', 'Individual', 'Informatics', 'Knowledge', 'Learning', 'Linguistics', 'Medical Informatics', 'Medical Informatics Applications', 'Medical Surveillance', 'Methods', 'Natural Language Processing', 'Neurologic', 'Ontology', 'Patients', 'Physicians', 'Records', 'Reporting', 'Research', 'Research Methodology', 'Semantics', 'Specific qualifier value', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Uncertainty', 'Validation', 'computerized', 'concept', 'gastrointestinal', 'indexing', 'innovation', 'quality assurance', 'respiratory', 'success', 'syndromic surveillance', 'tool']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2008,392337,0.07022916455090412
"POET: Consolidated, Comprehensive Clinical Text Preprocessing    DESCRIPTION (provided by applicant):       As electronic health records (EHRs) continue their expansion into clinical settings, there has been a corresponding increase in interest in mining the data they contain, both for research as well as for clinical decision support. Informaticists are increasingly studying ways to mine EHR textual content. This is an important trend, because there is a wealth of information contained in clinical text not represented anywhere else in the EHR. There is a low level text-as-data issue which presents a significant obstacle to the widespread use of available medical NLP systems: hand-typed clinical narratives in EHRs are usually ungrammatical; short or telegraphic in style; full of abbreviations, acronyms, and misspellings; formatted in a templated or pseudo-tabular form; and contain embedded non-text such as a list of laboratory values cut-and-pasted from elsewhere in the EHR. As we show in the Preliminary Studies Section, this makes high-level processing by popular tools like MedLEE and MetaMap effectively useless for all but a few ""clean"" document types like discharge summaries or consult reports (e.g., pathology or radiology reports). This in turn explains why there is so little published about what is certainly the preponderance of clinical texts, those that are not as well-behaved lexically and syntactically as a discharge summary.       In this application we distinguish clinical narratives (e.g., a progress note) from biomedical narratives (e.g., a PubMed abstract). We are interested in texts that arise in the clinical or research setting; texts that are composed by clinicians and researchers directly into a computer system. We propose to build and publish a tool called POET (Parsable Output Extracted from Text). POET will be designed to accept unstructured textual documents and return structured, linguistic equivalents that are, to the extent possible, parsable by higher-level NLP engines. POET will have an architecture is modular, extensible, and based on open-source platforms and sources (e.g., Java, Perl, UMLS, NegEx, the Stanford Parser, HL7 Clinical Document Architecture, caGRID, etc.). To implement POET, we will collect, program, and evaluate published as well as novel algorithms for: acronym/abbreviation resolution; spelling correction; template and pseudo-table re-writing; and removal of embedded non-text. To test POET we will use a large corpus of cross-discipline (e.g., medical, nursing, pharmacy, etc.) clinical note types, as well as the clinical research texts MedWatch reports and IRB adverse event reports. The development of POET will combine the best practices found in the literature and new research efforts as part of the project. To validate the fidelity of POET processing we plan a formal analysis of information loss and information gain pre- and post-process. To ensure broad access to the tools, POET will be released under an open-source license. Finally, we plan to assess the feasibility of offering POET as a Web service for remote processing.           Public Health Relevance This project attempts the construction of POET, a low-level preprocessing system for full text that can be used to open up large portions of the electronic health record (EHR) to high-level NLP systems. The potential public health implications are: 1) POET will allow the expansion of the use of well-proven clinical NLP systems  (currently limited to only a few document types found in the EHR) to the entire  clinical text record; with the entirety of the clinical record accessible to NLP,  serious and realistic attempts at real-time clinical text surveillance can be  mounted to improve patient safety and quality of care; 2) POET will be made available through open source distribution and other means  to encourage the practical deployment of innovative decision support systems  using large healthcare network EHRs across the country; 3) POET meets an important translational public health informatics need by solving  persistent low-level barriers to effective data mining of clinical marriages in the  EHR. The wider public health implications include promoting effective computerized decision support and data mining to improve both personal and public health outcomes.","POET: Consolidated, Comprehensive Clinical Text Preprocessing",7570254,R21LM009967,"['Abbreviations', 'Adverse event', 'Algorithms', 'Architecture', 'Body of uterus', 'Clinical', 'Clinical Pharmacists', 'Clinical Research', 'Computer Systems', 'Consult', 'Data', 'Development', 'Discipline', 'Discipline of Nursing', 'Electronic Health Record', 'Ensure', 'Excision', 'Hand', 'Internet', 'Java', 'Laboratories', 'Licensing', 'Linguistics', 'Literature', 'Medical', 'Mind', 'Mining', 'Natural Language Processing', 'Nature', 'Nurses', 'Output', 'Paste substance', 'Pathology', 'Pathology Report', 'Pharmacy facility', 'Physical assessment', 'Process', 'PubMed', 'Publishing', 'Radiology Specialty', 'Report (document)', 'Reporting', 'Research', 'Research Ethics Committees', 'Research Personnel', 'Resolution', 'Services', 'Source', 'Specific qualifier value', 'Standards of Weights and Measures', 'Structure', 'Study Section', 'System', 'Testing', 'Text', 'Thinking', 'Unified Medical Language System', 'Vocabulary', 'Work', 'Writing', 'abstracting', 'base', 'data mining', 'design', 'discrete data', 'interest', 'novel', 'open source', 'programs', 'spelling', 'tool', 'trend']",NLM,UNIVERSITY OF UTAH,R21,2008,169313,0.07932701731826049
"Statistical NLP Analysis of Cross-discipline Clinical Text emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical inforrnatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6944955,F38LM008478,"['Categories', 'Clinical', 'Clinical Pathology', 'Computers', 'Coupled', 'Diagnosis', 'Discipline', 'Event', 'Fellowship', 'Goals', 'Human', 'Inpatients', 'Linguistics', 'Machine Learning', 'Medical', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Personal Satisfaction', 'Pharmaceutical Preparations', 'Procedures', 'Radiology Specialty', 'Research', 'Statistical Study', 'Text', 'Training', 'Work', 'Writing', 'design', 'experience', 'knowledge base', 'skills', 'syntax', 'theories', 'tool', 'trend', 'ward']",NLM,UNIVERSITY OF UTAH,F38,2007,38768,0.02553772272855246
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,7110256,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2006,478733,0.06192044762733911
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6912634,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,478937,0.06192044762733911
"Statistical NLP Analysis of Cross-discipline Clinical Text DESCRIPTION (provided by applicant):     An emerging trend in computational linguistics is melding natural language processing (NLP) and machine learning (ML) to help computers make sense of human-generated free text. The blending of these disciplines is relatively rare in biomedical informatics. Past medical NLP/ML research work is biased heavily towards linguistic methods that attempt to reason about grammar and syntax aided by a domain-focal knowledge base (e.g., one for radiology or one for clinical pathology). The aim of the work proposed here takes a different tack: exploring the utility of a statistical approach to clinical NLP, one augmented by machine learning and concentrating on general progress notes from across multiple clinical domains. The specific clinical goal will be to identify adverse drug events described implicitly or explicitly in inpatient progress notes. Rather than relying on a narrow domain focus to provide enough context restriction to make text interpretation tractable, this approach will use statistical patterns in note author information (e.g., profession, note type, treating ward) and patient information (e.g., admit diagnosis, procedures performed, temporal note relationships) for context restriction. The research component of this proposal is divided into two categories: three small-scale projects designed to rapidly hone new skills developed under the training component, and a large-scale project that assesses the feasibility of cross-discipline clinical text analysis. n/a",Statistical NLP Analysis of Cross-discipline Clinical Text,6836781,F38LM008478,"['bioinformatics', 'clinical research', 'computational biology', 'human data', 'library', 'mathematical model', 'public health', 'statistics /biometry']",NLM,UNIVERSITY OF UTAH,F38,2004,94545,0.025625005534947173
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6781785,R01LM007659,"['cancer information system', 'clinical research', 'data collection', 'health science research', 'human data', 'informatics', 'library', 'medical records', 'molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,468590,0.06192044762733911
"Capturing and linking genomic and clinical information DESCRIPTION (provided by applicant):  The long-term aim of this project is to use natural language processing (NLP) to build a high throughput tool for facilitating cancer research by automatically extracting and organizing clinical and genetic information from the Electronic Medical Record (EMR) and from journal articles.  Our research involves advanced NLP techniques to:  1) enable the mining of phenotypic and genotypic data in the EMR; 2) automatically amass knowledge concerned with cancer and biomolecular relationships from journals; 3) develop a WEB-enabled visualization tool for researchers that will present diverse views of the knowledge; and 4) develop an Infrastructure that will link to the clinical data warehouse at New York Presbyterian Hospital (NYPH) and to GeneWays, a related project that allows researchers to visualize pathways.   More specifically, MedLEE (the NLP system we developed that extracts and encodes clinical and environmental information from the EMR) will be extended to extract genetic information contained in the EMR; subsequently, twelve years of patient reports will be processed and the extracted data added to the warehouse.  In addition, a new system, PhenoGenes, will be developed based on MedLEE and GeneWays (which contains another NLP system we developed that extracts and codifies biomolecular relations from journal articles).  PhenoGenes will capture biomolecular interactions directly associated with the treatment, diagnosis, and prognosis of cancer.  It will also generate an XML knowledge base that will integrate and organize the information that will be captured, and a Web-enabled tool that will allow users to browse and view the knowledge clustered according to different orientations (e.g. gene, disease, tissue, interaction, etc.).  The knowledge base will be linked to the GeneWays system, so that relevant pathways can be visualized.   MedLEE is utilized operationally at NYPH.  It also has been demonstrated that both NLP systems are highly effective.  This current project builds upon our experience and success with these systems.  The availability of related compatible clinical and biomolecular NLP systems, provide an exceptional opportunity to pave the way for capture, integration and organization of phenotypic and genotypic data and knowledge that will be used to radically improve patient care. n/a",Capturing and linking genomic and clinical information,6558664,R01LM007659,"['cancer information system', ' clinical research', ' data collection', ' health science research', ' human data', ' informatics', ' library', ' medical records', ' molecular biology information system']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,464049,0.06192044762733911
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6490773,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2002,288252,0.03640521745783852
"UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING   DESCRIPTION (adapted from the Abstract):                                              The long-term aim of this project is to use natural language processing (NLP)        to help realize the full potential of the Electronic Medical Record (EMR).           Our research involves advanced NLP techniques to: 1) extract and encode              information in textual reports; 2) map terms to an authoritative vocabulary;         3) obtain comprehensive domain coverage based on the processing of domain            corpora; and 4) facilitate vocabulary development by providing visualization         tools using the Extensible Markup Language (XML).  It has already been               demonstrated that MedLEE, the NLP system we developed, accurately extracts and       codifies information in the EMR.  This current project builds upon our               experience with MedLEE and uses it to accomplish the latter three goals              concerning vocabulary development and standardization.                                                                                                                    More specifically, MedLEE will be used to map source terms to UMLS concepts.         MedLEE will process and structure the source terms and candidate UMLS                concepts.  Suitable matches will be found based on structural similarity             between components of the source term and candidate concepts.  This should           enhance current methods because knowledge of the type of modifiers that match        should improve the quality of the matches.  We will also use MedLEE to process       a large corpus and generate structured output in XML format.  Statistics based       on the structured output will be computed, and then clinically relevant              composite terms will be detected based on frequencies of the structures              containing the more elementary terms.  Our method differs from other discovery       methods because we use NLP techniques that identify semantic modifiers and           complex relations even if the terms are distant from each other, whereas other       methods use statistical co-occurrence data based on adjacency.  The individual       XML structures and statistics will be combined and mapped into a single XML          tree.  It will be possible to visualize the tree and frequencies using an XML        tree viewer, to navigate the tree, to manipulate the tree, and to reorganize         the tree according to different axes (i.e., procedure, body location,                finding).                                                                                                                                                                 The use of a sophisticated NLP system, such as MedLEE, is ideal as a                 foundation for our proposed work in vocabulary development and                       standardization; medical terminology is an integral part of medical language         and a state of the art NLP system is especially equipped to handle the               inherent complexities of language. n/a",UNLOCKING DATA FROM MEDICAL RECORDS WITH TEXT PROCESSING,6095940,R01LM006274,"['abstracting', ' automated medical record system', ' computer system design /evaluation', ' human data', ' information retrieval', ' method development', ' vocabulary development for information system']",NLM,QUEENS COLLEGE,R01,2001,303860,0.03640521745783852
"A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications PROJECT SUMMARY/ABSTRACT  In radiology practices, timely and accurate formulation of reports is closely linked to patient satisfaction, physician productivity, and reimbursement. While the American College of Radiology and the Radiological Soci- ety of North America have recommended implementation of structured reporting to facilitate clear and consistent communication between radiologists and referring clinicians, cumbersome nature of current structured reporting systems made them unpopular amongst their users. Recently, the emerging techniques of deep learning have been widely and successfully applied in many different natural language processing tasks (NLP). However, when adopted in a certain speciﬁc domain, such as radiology, these techniques should be combined with extensive domain knowledge to improve efﬁciency and accuracy. There is, therefore, a critical need to take advantage of clinical NLP and deep learning to fundamentally change the radiology reporting. The long-term goal in this appli- cation is to improve the form, content, and quality of radiology reports and to facilitate rapid generation of radiol- ogy reports with consistent organization and standardized texts. The overall objective is to use radiology-speciﬁc ontology, NLP and computer vision techniques, and deep learning to construct a radiology-speciﬁc knowledge graph, which will then be used to build a reporting system that can assist radiologists to quickly generate struc- tured and standardized text reports. The rationale for this project is that through integration of new clinical NLP technologies, radiology-speciﬁc knowledge graphs, and development of new reporting system, we can build au- tomatous systems with a higher-level understanding of the radiological world. The speciﬁc aims of this project are to: (1) recognize and normalize named entities in radiology reports; (2) construct a radiology-speciﬁc knowledge graph from free-text and images; and (3) build a reporting system that can dynamically adjust templates based on radiologists' prior entries. The research proposed in this application is innovative, in the applicant's opinion, because it combines deep learning, NLP techniques, and domain knowledge in a single framework to construct comprehensive and accurate knowledge graphs that will enhance the workﬂow of the current reporting systems. The proposed research is signiﬁcant because a novel reporting system can expedite radiologists' workﬂow and acquire well-annotated datasets that facilitate machine learning and data science. To develop such a method, the candidate, Dr. Yifan Peng, requires additional training and mentoring in clinical NLP and radiology. During the K99 phase, Dr. Peng will conduct this research as a research fellow at the National Center for Biotechnology Information. He will be mentored by Dr. Zhiyong Lu, a leading text mining and deep learning researcher, and co- mentored by Dr. Ronald M. Summers, a leading radiologist and clinical informatics researcher. This application for the NIH Pathway to Independence Award (K99/R00) describes a career development plan that will allow Dr. Peng to achieve the career goals of becoming an independent investigator and leader in the study of clinical NLP. PROJECT NARRATIVE The proposed research is relevant to public health because it entails a new strategy to construct a radiology- speciﬁc knowledge graph to facilitate the development of a new reporting system that enables rapid generation of structured radiology reports. The proposed knowledge graph and reporting system will contribute to advancement in understanding of the radiological world, and promise to enhance clinical communication and patient-centric care. Thus, the proposed research is relevant to the part of the NLM's mission that pertains to applying deep knowledge of clinical terminology and natural language processing to improve clinical data science and health services.",A framework to enhance radiology structured report by invoking NLP and DL:  Models and Applications,10197509,R00LM013001,"['Address', 'Adopted', 'American College of Radiology', 'Award', 'Biotechnology', 'Caring', 'Client satisfaction', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Communication', 'Complex', 'Computer Vision Systems', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Formulation', 'Generations', 'Goals', 'Health Services', 'Hospitals', 'Hybrids', 'Image', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Mission', 'Modeling', 'Mus', 'Names', 'Natural Language Processing', 'Nature', 'Nomenclature', 'North America', 'Ontology', 'Outcome', 'Pathway interactions', 'Patients', 'Phase', 'Physicians', 'Picture Archiving and Communication System', 'Process', 'Productivity', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resort', 'Societies', 'Standardization', 'Structure', 'System', 'Systems Development', 'Techniques', 'Technology', 'Terminology', 'Text', 'Time', 'Training', 'United States National Institutes of Health', 'Voice', 'Writing', 'base', 'career', 'career development', 'convolutional neural network', 'deep learning', 'deep neural network', 'impression', 'improved', 'innovation', 'knowledge graph', 'lexical', 'long short term memory', 'neural network', 'neural network architecture', 'novel', 'radiologist', 'repository', 'response', 'syntax', 'text searching']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,R00,2020,236549,0.03523615405633262
"CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare Project Summary Wide adoption of electronic health records (EHRs) has led to huge clinical databases, which enable the rapid growth of healthcare analytics market. One particular challenge for analyzing EHRs data is that much detailed patient information is embedded in clinical documents and not directly available for downstream analysis. Therefore, clinical natural language processing (NLP) technologies, which can unlock information embedded in clinical narratives, have received great attention, with an estimated global market of $2.65 billion by 2021 . In our previous work, we have developed CLAMP (Clinical Language Annotation, Modeling, and Processing), a clinical NLP tool with demonstrated superior performance through multiple international NLP challenges and a large user community (over 1,500 downloads by users from over 700 organizations). Commercialization of CLAMP by Melax Technologies Inc. has been successful (i.e., with a dozen licensed customers now); but it also reveals its limitations as a desktop application in the Cloud era. Therefore, we propose to extend CLAMP to a new Cloud- based, Service-oriented platform (called CLAMP-CS), which will address the identified challenges by: 1) improving clinical NLP performance and reducing annotation cost by leveraging the state-of-the-art algorithms such as deep learning, active learning and transfer learning and making them accessible to less experienced users; 2) following new service-oriented architectures to make CLAMP-CS available via SaaS and PaaS, ready for Cloud-based development and deployment; and 3) improving CLAMP-CS interoperability with downstream applications following two widely used standard representations: HL7 FHIR (Fast Healthcare Interoperability Resources) and OMOP CMD (Common Data Model), to support the use cases in clinical operations and research respectively. With these advanced features, we believe CLAMP-CS will be a leading clinical NLP system in the market and it will accelerate the adoption of NLP technology for diverse healthcare applications and clinical/translational research. Project Narrative In this study, we plan to develop a new clinical natural language processing (NLP) tool based on the existing widely used CLAMP (Clinical Language Annotation, Modeling, and Processing) system, to support enterprise development and deployment of NLP solutions in healthcare. We believe that the new generation of Cloud- based, service-oriented NLP tool will accelerate the adoption of NLP technology for diverse healthcare applications and clinical and translational research.","CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare",10011177,R44TR003254,"['Active Learning', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Architecture', 'Attention', 'Belief', 'Clinical', 'Clinical Research', 'Closure by clamp', 'Cloud Computing', 'Communities', 'Custom', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Generations', 'Grant', 'Growth', 'Health Sciences', 'Healthcare', 'Hospital Administration', 'International', 'Language', 'Licensing', 'Machine Learning', 'Medical', 'Modeling', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Operations Research', 'Output', 'Patients', 'Performance', 'Psychological Transfer', 'Records', 'Research', 'Services', 'System', 'Technology', 'Texas', 'Time', 'Translational Research', 'Universities', 'Work', 'active method', 'base', 'clinical application', 'clinical database', 'cloud based', 'commercialization', 'cost', 'data modeling', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'insight', 'interoperability', 'language training', 'learning algorithm', 'model building', 'next generation', 'novel', 'prevent', 'rapid growth', 'tool', 'user-friendly', 'web app']",NCATS,"MELAX TECHNOLOGIES, INC.",R44,2020,503546,0.05672967531325948
"Automated domain adaptation for clinical natural language processing Project Summary Automatic extraction of useful information from clinical texts enables new clinical research tasks and new technologies at the point of care. The natural language processing (NLP) systems that perform this extraction rely on supervised machine learning. The learning process uses manually labeled datasets that are limited in size and scope, and as a result, applying NLP systems to unseen datasets often results in severely degraded performance. Obtaining larger and broader datasets is unlikely due to the expense of the manual labeling process and the difficulty of sharing text data between multiple different institutions. Therefore, this project develops unsupervised domain adaptation algorithms to adapt NLP systems to new data. Domain adaptation describes the process of adapting a machine learning system to new data sources. The proposed methods are unsupervised in that they do not require manual labels for the new data. This project has three aims. The first aim makes use of multiple existing datasets for the same task to study the differences in domains, and uses this information to develop new domain adaptation algorithms. Evaluation uses standard machine learning metrics, and analysis of performance is tightly bounded by strong baselines from below and realistic upper bounds, both based on theoretical research on machine learning generalization. The second aim develops open source software tools to simplify the process of incorporating domain adaptation into clinical text processing workflows. This software will have input interfaces to connect to methods developed in Aim 1 and output interfaces to connect with Apache cTAKES, a widely used open- source NLP tool. Aim 3 tests these methods in an end-to-end use case, adverse drug event (ADE) extraction on a dataset of pediatric pulmonary hypertension notes. ADE extraction relies on multiple NLP systems, so this use case is able to show how broad improvements to NLP methods can improve downstream methods. This aim also creates new manual labels for the dataset for an end-to-end evaluation that directly measures how improvements to the NLP systems lead to improvement in ADE extraction. Project Narrative Software systems that use machine learning to understand clinical text often suffer severe performance loss when they are applied to new data that looks different than the data that they originally learned from. In this project, we develop and implement methods that allow these systems to automatically adapt to the characteristics of a new data source. We evaluate these methods on the clinical research task of adverse drug event detection, which relies on many different variables found in the text of electronic health records.",Automated domain adaptation for clinical natural language processing,9986899,R01LM012918,"['Adult', 'Adverse drug event', 'Algorithms', 'Apache', 'Area', 'Characteristics', 'Childhood', 'Clinical', 'Clinical Informatics', 'Clinical Research', 'Colon Carcinoma', 'Communities', 'Computer software', 'Computers', 'Conceptions', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Dimensions', 'Ecosystem', 'Educational process of instructing', 'Electronic Health Record', 'Evaluation', 'Human', 'Information Retrieval', 'Institution', 'Knowledge', 'Label', 'Language', 'Lead', 'Learning', 'Linguistics', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Network-based', 'Output', 'Pathology', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Pulmonary Hypertension', 'Radiology Specialty', 'Research', 'Software Tools', 'Source', 'Statistical Models', 'System', 'Testing', 'Text', 'TimeLine', 'Training', 'Update', 'Vision', 'Work', 'adaptation algorithm', 'base', 'case finding', 'improved', 'machine learning method', 'malignant breast neoplasm', 'method development', 'natural language', 'neural network', 'new technology', 'news', 'novel', 'open source', 'point of care', 'side effect', 'social media', 'software systems', 'statistics', 'structured data', 'supervised learning', 'tool', 'tumor', 'unsupervised learning']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,383874,0.05033605041530459
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimer’s Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians’ documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimer’s Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,9998610,R01AG066471,"['Acoustics', 'Acute', 'Address', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'Caregivers', 'Chicago', 'Clinical', 'Clinical assessments', 'Code', 'Cognition', 'Cognitive', 'Data', 'Data Analyses', 'Data Element', 'Data Scientist', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Health Services', 'Health system', 'Impaired cognition', 'Individual', 'Insurance Carriers', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Natural Language Processing', 'Neurocognitive', 'New York City', 'Parkinson Disease', 'Patient Care', 'Patients', 'Persons', 'Physicians', 'Population', 'Positioning Attribute', 'Preventive care', 'Primary Health Care', 'Procedures', 'Provider', 'Psychiatric Diagnosis', 'Reference Standards', 'Research', 'Research Personnel', 'Resource Allocation', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Services', 'Signs and Symptoms', 'Speech', 'Structure', 'Study Subject', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Validation', 'Visit', 'adverse event risk', 'aging population', 'automated speech recognition', 'base', 'care coordination', 'clinical encounter', 'cognitive function', 'cognitive testing', 'deep learning', 'demographics', 'electronic data', 'electronic structure', 'falls', 'feature extraction', 'financial incentive', 'health care settings', 'improved', 'insurance claims', 'learning classifier', 'machine learning algorithm', 'mental state', 'mild cognitive impairment', 'multidisciplinary', 'prevent', 'primary care setting', 'recruit', 'risk mitigation', 'screening', 'secondary analysis', 'structured data', 'success', 'testing services', 'tool', 'treatment choice', 'unstructured data']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2020,855710,0.04151378179657024
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,9957898,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2020,271250,0.027541296720871168
"Resource Curation and Evaluation for EHR Note Comprehension Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. Proper patient self-management is perhaps the most critical and under-exercised element for patients to achieve appropriate glycemic control and thus mitigate complications and comorbid conditions, and implement appropriate preventive strategies (e.g., vaccines, exercise, healthy diet). In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a multi- module natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! ! Title: Resource Curation and Evaluation for EHR Note Comprehension The American Diabetes Association estimates that over 25.8 million Americans have diabetes. In previous work we have shown that educating patients by using content in their medical records improved diabetes outcomes and that NoteAid, a natural language processing system that links medical jargon in electronic health records to definitions, has improved self-reported comprehension. Here we propose to develop NoteAid with a high-quality resource of expert-curated lay definitions and evaluation methods for diabetes patients’ note comprehension. ! !",Resource Curation and Evaluation for EHR Note Comprehension,9925807,R01LM012817,"['Adult', 'Age', 'American', 'Artificial Intelligence', 'Attitude', 'Back', 'Behavior', 'Caregivers', 'Caring', 'Characteristics', 'Clinical', 'Cognitive', 'Communication', 'Complex', 'Comprehension', 'Country', 'Data Science', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Elements', 'Ethnic Origin', 'Evaluation', 'Exercise', 'Eye diseases', 'General Population', 'Health', 'Healthcare', 'Heart Diseases', 'Hospitals', 'Individual', 'Informatics', 'Internet', 'Intervention', 'Kidney Diseases', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Link', 'Machine Learning', 'Massachusetts', 'Measurement', 'Mechanics', 'Medical', 'Medical Records', 'Medical Students', 'Methods', 'Modeling', 'Natural Language Processing', 'Nursing Students', 'Ontology', 'Outcome', 'Patient Education', 'Patient Self-Report', 'Patients', 'Physicians', 'Prevention strategy', 'Questionnaires', 'Race', 'Randomized', 'Reading', 'Resources', 'Risk', 'Self Management', 'Speed', 'Supervision', 'System', 'Techniques', 'Testing', 'Time', 'Trust', 'United States National Institutes of Health', 'Universities', 'Vaccines', 'Visual Aid', 'Vocabulary', 'Work', 'base', 'care outcomes', 'clinically relevant', 'comorbidity', 'cost', 'deep learning', 'design', 'diabetic patient', 'glycemic control', 'good diet', 'improved', 'innovation', 'instrument', 'response', 'sex', 'skills', 'usability']",NLM,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2020,335875,0.03330308183350187
"Great Lakes Node of the Drug Abuse Clinical Trials Network PROJECT SUMMARY  Individuals with substance use disorders are disproportionately experiencing homelessness, poverty, and chronic medical conditions (diabetes and hypertension), which are emerging risk factors for contracting SARS-CoV-2 (official name for the virus that causes COVID-19). Different types of substance use have been associated with development of respiratory infections and progression to severe respiratory failure, also known as Acute Respiratory Distress Syndrome (ARDS). However, complex syndromes like ARDS and behavioral conditions like substance misuse are difficult to identify from the electronic health record. Clinical notes and radiology reports provide a rich source of information that may be used to identify cases of substance misuse and ARDS. This information is routinely recorded during hospital care, and automated, data-driven solutions with natural language processing (NLP) can extract semantics and important risk factors from the unstructured data of clinical notes. The computational methods of NLP derive meaning from clinical notes, from which machine learning can predict risk factors for patients leaving AMA or progressing to respiratory failure. Our team developed tools with >80% sensitivity/specificity to identify individual types of substance misuse using NLP with machine learning (ML). Our single-center models delineated risk factors embedded in the notes (e.g., mental health conditions, socioeconomic indicators). Further, we have developed and externally validated a machine learning tool to identify cases of ARDS with high accuracy for early treatment. We aim to expand this work by pooling data across health systems and build a generalizable and comprehensive classifier that captures multiple types of substance misuse for use in risk stratification and prognostication during the COVID pandemic.  We hypothesize that a single-model NLP substance misuse classifier will provide a standardized, interoperable, and accurate approach for universal analysis of hospitalized patients, and that such information can be used to identify those at risk for disrupted care and those at risk for respiratory failure. We aim to train and test our substance misuse classifiers at Rush in a retrospective dataset of over 60,000 hospitalizations that have been manually screened with the universal screen, AUDIT, and DAST. This Administrative Supplement will allow us to examine the correlations between substances of misuse and risk for COVID-19 as well as development of Acute Respiratory Distress Syndrome (ARDS) in the context of these phenomena. PROJECT NARRATIVE We anticipate that the research proposed will provide novel and critically important tools in artificial intelligence for the detection of substance misuse and COVID-19 from the electronic health record (EHR). Development and validation of a digital classifier would enable a standardized approach to perform screening on all patient encounters on a daily basis in health systems. We will rigorously develop and test the classifier retrospectively on an existing dataset of 60,000 patients. This will serve as the first step towards a comprehensive universal screener that leverages available data in the EHR.",Great Lakes Node of the Drug Abuse Clinical Trials Network,10173503,UG1DA049467,"['2019-nCoV', 'Accident and Emergency department', 'Administrative Supplement', 'Adult', 'Adult Respiratory Distress Syndrome', 'Affect', 'Alcohol or Other Drugs use', 'Artificial Intelligence', 'Behavioral', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Chronic', 'Cities', 'Clinical', 'Clinical Data', 'Clinical Trials Network', 'Communities', 'Complex', 'Computing Methodologies', 'Consumption', 'Contracts', 'Data', 'Data Pooling', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Disasters', 'Drug abuse', 'Drug usage', 'Early treatment', 'Electronic Health Record', 'Ensure', 'Epidemic', 'Equipment', 'Felis catus', 'General Population', 'Health', 'Health Services', 'Health Status', 'Health system', 'Heart Diseases', 'Home environment', 'Homelessness', 'Hospitalization', 'Hospitals', 'Hurricane', 'Hypertension', 'Illicit Drugs', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Medical', 'Mental Health', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Outcome', 'Overdose', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Poverty', 'Prevention', 'Public Health', 'Radiology Specialty', 'Reporting', 'Research', 'Resources', 'Respiratory Failure', 'Respiratory Tract Infections', 'Risk', 'Risk Factors', 'Risk stratification', 'Semantics', 'Sensitivity and Specificity', 'Social support', 'Source', 'Standardization', 'Sterility', 'Substance Use Disorder', 'Syndrome', 'Testing', 'Training', 'Treatment outcome', 'Triage', 'Validation', 'Virus', 'Visit', 'Vulnerable Populations', 'Withdrawal', 'Work', 'behavioral health', 'cohort', 'comorbidity', 'coronavirus disease', 'digital', 'drug market', 'experience', 'high risk', 'improved', 'individual patient', 'interoperability', 'machine learning method', 'marijuana use', 'mortality risk', 'non-opioid analgesic', 'novel', 'opioid misuse', 'overdose death', 'pandemic disease', 'predictive modeling', 'prognostic', 'screening', 'social', 'social exclusion', 'social stigma', 'socioeconomics', 'substance misuse', 'success', 'tool', 'transmission process', 'unstructured data']",NIDA,RUSH UNIVERSITY MEDICAL CENTER,UG1,2020,139752,0.024052500376851655
"Characterizing and targeting subphenotypes of schizophrenia and bipolar disorder via individually imputed tissue and cell-type specific transcriptomes PROJECT SUMMARY  Schizophrenia (SCZ) and bipolar disorder (BD) are highly heritable, severe and complex brain disorders characterized by substantial clinical and biological heterogeneity. Despite this, case-control studies often ignore such heterogeneity through their focus on the average patient, which may be the core reason for a lack of robust biomarkers indicative of an individual’s treatment response and outcome. Although they are classified as independent diagnostic entities, SCZ and BD are highly genetically correlated, exhibit high relative risks among relatives of both BD & SCZ patients, and have partially overlapping symptomatology and treatment. In this project we will use tissue and cell-type specific imputed transcriptomes for individuals with SCZ or BD in our VA discovery cohort comprising the Million Veteran Program (MVP) and Cooperative Studies Program 572 (CSP #572, “The Genetics of Functional Disability in Schizophrenia and Bipolar Illness”), as an intermediate molecular phenotype, to identify, characterize and target subphenotypes of these disorders. Findings from the VA discovery cohort will be validated in the PsycheMERGE and BioMe cohorts.  First, we will impute tissue and cell-type specific transcriptomes for all individuals with schizophrenia (SCZ) or bipolar disorder (BD) in the VA discovery cohort. To achieve this, we will train tissue (brain and peripheral tissues) and cell-type (glutamatergic & GABAergic neurons, astrocytes, oligodendrocytes, and microglia from DLPFC) specific EpiXcan transcriptomic imputation models at the gene and isoform level. Secondly, we will use the imputed transcriptomes as an intermediate molecular phenotype to identify genetically-regulated gene expression (GReX) based subpopulations and within them the key molecular drivers using deep neural networks (DNNs). Lastly, we will identify key non-genetic biomarkers and effective treatments for each validated subphenotype. Non-genetic biomarkers will be based on pre-mined features available from the electronic health records (EHR) and features extracted from the EHR via natural language processing (NLP). The subphenotypes will be validated in the civilian cohorts PsycheMERGE and BioMe.  This project will take place at the Icahn School of Medicine, one of the leading centers of data science, genomics and precision medicine. The mentoring committee comprises experts in the fields of computational and functional genomics, integrative analysis, machine learning (including DNNs and NLP), and EHR mining. Dr. Voloudakis will develop the skills necessary to launch an independent academic career in genetically based EHR-informed precision psychiatry. PROJECT NARRATIVE  Schizophrenia (SCZ) and bipolar disorder (BD) are genetically correlated, highly heritable, severe and complex brain disorders characterized by substantial clinical and biological heterogeneity with partially overlap- ping symptomatology and treatment. This project will use tissue and cell-type specific imputed transcriptomes for individuals with SCZ or BD to identify, characterize and target subphenotypes of those disorders. We will use the Million Veteran Program and Cooperative Studies Program 572 (“The Genetics of Functional Disability in Schizophrenia and Bipolar Illness”) as the discovery cohorts and will validate our findings in the PsycheMERGE and BioMe cohorts.",Characterizing and targeting subphenotypes of schizophrenia and bipolar disorder via individually imputed tissue and cell-type specific transcriptomes,10055546,K08MH122911,"['Astrocytes', 'Biological', 'Biological Markers', 'Biology', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Case-Control Studies', 'Classification', 'Complex', 'Data Science', 'Development', 'Diagnostic', 'Disease', 'Electronic Health Record', 'Epigenetic Process', 'Exhibits', 'Exposure to', 'Functional disorder', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genomic medicine', 'Genomics', 'Genotype', 'Glutamates', 'Goals', 'Heritability', 'Heterogeneity', 'Individual', 'Intervention', 'Machine Learning', 'Mentors', 'Methods', 'Microglia', 'Mining', 'Modeling', 'Molecular', 'Natural Language Processing', 'Neurons', 'Neurosciences', 'Oligodendroglia', 'Outcome', 'Patients', 'Peripheral', 'Pharmaceutical Preparations', 'Pharmacology', 'Phenotype', 'Population Genetics', 'Positioning Attribute', 'Precision therapeutics', 'Prefrontal Cortex', 'Productivity', 'Protein Isoforms', 'Psychiatry', 'Relative Risks', 'Research', 'Risk', 'Sample Size', 'Schizophrenia', 'Selection for Treatments', 'Severity of illness', 'Symptoms', 'Tissues', 'Training', 'Treatment outcome', 'Variant', 'Veterans', 'base', 'biological heterogeneity', 'career', 'cell type', 'clinical heterogeneity', 'cohort', 'comorbidity', 'computational basis', 'cooperative study', 'deep learning', 'deep neural network', 'effective therapy', 'experience', 'functional disability', 'functional genomics', 'improved', 'medical schools', 'molecular phenotype', 'neuropsychiatric disorder', 'next generation', 'non-genetic', 'novel', 'novel therapeutic intervention', 'patient subsets', 'polygenic risk score', 'precision medicine', 'programs', 'psychopharmacologic', 'skills', 'symptomatology', 'trait', 'transcriptome', 'transcriptomics', 'treatment response']",NIMH,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,K08,2020,191944,0.005573817824907681
"Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks Project Summary In this project we develop new methods for extracting important information from electronic health records based on recurrent neural networks. These methods represent the hierarchical and sequential nature of human language, leverage large scale datasets to make learning sophisticated representations possible, and make use of novel sources of supervision that are available at this scale. The model architecture we propose is a hierarchical recurrent neural network (RNN). This architecture explicitly represents temporality at multiple different time scales, with stacked RNN layers representing words, sentences, paragraphs, and documents. At the word level, the model is trained to predict important pieces of clinical information, such as negation and temporality, using existing labeled data sets. Training for clinical information extraction at the lowest level ensures that the higher-level models have a foundation of medically relevant inputs. We are still left with the challenge of training higher-level networks, because these models require massive amounts of labeled training data to learn. We solve this problem by taking advantage of the temporal aspect of information in an EHR, and having each higher-level recurrent layer train getting supervision from the future. For example, the document RNN is trained to predict billing codes and NLP concept codes that were found in the subsequent document. This source of supervision is scalable, and our preliminary data shows that it is effective at learning how to generate generalizable patient representations. The patient representations that our model learns are shareable across multiple tasks, potentially streamlining EHR-based research by eliminating what was previously a manual step – designing text-based variables to represent patients. We demonstrate a new workflow for text-based EHR research, showing how the same representations can be used for two completely distinct phenotyping tasks. These phenotyping studies make use of high-quality datasets of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital. PH is relatively rare, so finding every patient with a phenotyping algorithm is important for clinical research. ASD has several sub-phenotypes, and finding large numbers of patients from each sub- phenotype can help to better understand the mechanisms of ASD. Along with demonstrating the applicability of our representations on these specific clinical research use cases, we incorporate our patient representations into the i2b2 clinical research software, making them available to all clinical investigators using this platform at Boston Children’s Hospital. Project Narrative This project develops methods for extracting universal patient representations from unstructured text in electronic health records. These methods leverage huge amounts of clinical data, recurrent neural network architectures, and novel training techniques to incorporate information at multiple time scales. These methods are evaluated using public datasets to promote reproducibility, and applied to clinical research tasks that extend the knowledge of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital.",Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks,9868326,R01LM012973,"['Architecture', 'Boston', 'Brain', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Computer software', 'Data', 'Data Set', 'Electronic Health Record', 'Ensure', 'Event', 'Face', 'Felis catus', 'Foundations', 'Future', 'Healthcare Systems', 'Human', 'Human Characteristics', 'Human Resources', 'Information Retrieval', 'Intensive Care Units', 'Israel', 'Knowledge', 'Label', 'Language', 'Learning', 'Left', 'Linguistics', 'Location', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phenotype', 'Problem Solving', 'Process', 'Pulmonary Hypertension', 'Rare Diseases', 'Records', 'Recurrence', 'Reproducibility', 'Research', 'Research Personnel', 'Source', 'Statistical Methods', 'Supervision', 'System', 'Text', 'Time', 'Training', 'Training Technics', 'Uncertainty', 'autism spectrum disorder', 'base', 'clinically relevant', 'cohort', 'comorbidity', 'data resource', 'deep neural network', 'design', 'disease phenotype', 'large scale data', 'learning strategy', 'machine translation', 'neural network', 'neural network architecture', 'novel', 'phenotyping algorithm', 'recurrent neural network', 'relating to nervous system']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2020,367184,0.040116463554508985
"Open Health Natural Language Processing Collaboratory Project Summary One of the major barriers in leveraging Electronic Health Record (EHR) data for clinical and translational science is the prevalent use of unstructured or semi-structured clinical narratives for documenting clinical information. Natural Language Processing (NLP), which extracts structured information from narratives, has received great attention and has played a critical role in enabling secondary use of EHRs for clinical and translational research. As demonstrated by large scale efforts such as ACT (Accrual of patients for Clinical Trials), eMERGE, and PCORnet, using EHR data for research rests on the capabilities of a robust data and informatics infrastructure that allows the structuring of clinical narratives and supports the extraction of clinical information for downstream applications. Current successful NLP use cases often require a strong informatics team (with NLP experts) to work with clinicians to supply their domain knowledge and build customized NLP engines iteratively. This requires close collaboration between NLP experts and clinicians, not feasible at institutions with limited informatics support. Additionally, the usability, portability, and generalizability of the NLP systems are still limited, partially due to the lack of access to EHRs across institutions to train the systems. The limited availability of EHR data limits the training available to improve the workforce competence in clinical NLP. We aim to address the above challenges by extending our existing collaboration among multiple CTSA hubs on open health natural language processing (OHNLP) to share distributional information of NLP artifacts (i.e., words, n-grams, phrases, sentences, concept mentions, concepts, and text segments) acquired from real EHRs across multiple institutions. We will leverage the advanced privacy-preserving computing infrastructure of iDASH (integrating Data for Analysis, Anonymization, and SHaring) for privacy- preserving data analysis models and will partner with diverse communities including Observational Health Data Sciences and Informatics (OHDSI), Precision Medicine Initiative (PMI), PCORnet, and Rare Diseases Clinical Research Network (RDCRN) to demonstrate the utility of NLP for translational research. This CTSA innovation award RFA provides us with a unique opportunity to address the challenges faced with clinical NLP and through strong partnership with multiple research communities and leadership roles of the research team in clinical NLP, we envision that the successful delivery of this project will broaden the utilization of clinical NLP across the research community. There are four aims planned: i) obtain PHI-suppressed NLP artifacts with retained distribution information across multiple institutions and assess the privacy risk of accessing PHI- suppressed artifacts, ii) generate a synthetic text corpus for exploratory analysis of clinical narratives and assess its utility in NLP tasks leveraging various NLP challenges, iii) develop privacy-preserving computational phenotyping models empowered with NLP, and iv) partner with diverse communities to demonstrate the utility of our project for translational research. Project Narratives The proposed project aims to broaden the secondary use of electronic health records (EHRs) across the research community by combining innovative privacy-preserving computing techniques and clinical natural language processing.",Open Health Natural Language Processing Collaboratory,10005506,U01TR002062,"['Address', 'Algorithms', 'Attention', 'Award', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Pooling', 'Data Science', 'Detection', 'Disease', 'Electronic Health Record', 'Ensure', 'Familial Hypercholesterolemia', 'Frequencies', 'Health', 'Hepatolenticular Degeneration', 'Individual', 'Informatics', 'Information Distribution', 'Infrastructure', 'Institution', 'Kidney Calculi', 'Knowledge', 'Leadership', 'Learning', 'Measures', 'Medical', 'Minnesota', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Natural Language Processing', 'Observational Study', 'Patients', 'Phenotype', 'Play', 'Precision Medicine Initiative', 'Privacy', 'Process', 'Rare Diseases', 'Research', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sampling', 'Security', 'Semantics', 'Site', 'Source', 'Structure', 'System', 'Talents', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translational Research', 'Universities', 'Work', 'base', 'citizen science', 'cohort', 'collaboratory', 'data infrastructure', 'data registry', 'empowered', 'health data', 'improved', 'indexing', 'individual patient', 'informatics infrastructure', 'innovation', 'interest', 'novel', 'phenotypic data', 'phenotyping algorithm', 'phrases', 'portability', 'preservation', 'privacy preservation', 'recruit', 'statistics', 'tool', 'usability', 'virtual']",NCATS,MAYO CLINIC ROCHESTER,U01,2020,1500847,0.11204763808267015
"Prediction of therapist cultural competency using Natural Language Processing (NLP) models PROJECT SUMMARY  Racial-ethnic minorities (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) individuals experience high levels of psychological distress. Psychological treatments can be effective in addressing mental health concerns, but disparities in quality of care still exist. Although systemic and institutional factors contribute to disparities in care, mental health providers are also critical to examine. A primary focus of efforts to understand and reduce provider contributions to mental health care disparities has been to examine cultural competency (CC), which involves a provider’s ability to navigate the cultural aspects of clinical interactions. Patient ratings of CC are generally associated with treatment outcomes and therapeutic processes. While patient perceptions of provider CC are important, a reliance on retrospective patient ratings limits what we know about how cultural identities are discussed, and the language that constitutes culturally sensitive care. Many studies of provider CC also require observers or patients to make complex judgments based on internal provider characteristics that are not reliably observable (e.g. rate provider awareness of their own cultural values). More studies are needed that examine patient-provider interactions in treatment in order to assess the impact of specific provider behaviors, and how they relate to perceptions of provider CC. Recently, Natural Language Processing (NLP) models have been applied to psychotherapy conversations to automatically capture the use of evidence based treatments, topics of conversation, empathy, and emotional expression. Prior research demonstrating the feasibility of automatically identifying topics of conversation in psychotherapy suggest that NLP models could be trained to automatically identify specific moments in sessions where patients and providers are talking about cultural issues. NLP models could allow researchers to not only examine how specific patterns of provider-patient interactions drive CC, but might also provide rapid feedback to providers, and in turn help address disparities in care. The purpose of the current study is to do the foundational work to develop and evaluate NLP tools that capture the cultural content of provider-patient interactions among REM and LGBTQ patients. First, utilizing 32,436 labeled talk turns from 200 psychotherapy sessions we will evaluate the accuracy of NLP models in recognizing the discussion of cultural topics in psychotherapy. Second, we will use NLP models to explore differences in the content of 1,235 psychotherapy sessions that were rated as highly positive or negative on a measure of cultural competence. PROJECT NARRATIVE Although disparities in the quality of mental health treatment for racial-ethnic minority (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) patients are well known, to date there are no tools that can identify specific patterns of provider-patient interactions that drive disparities in care. This project will evaluate the ability of Natural Language Processing (NLP) models to recognize discussion of cultural topics in psychotherapy among REM and LGBTQ patients, and explore differences in patient-provider interactions with low and high patient ratings of provider cultural competency.",Prediction of therapist cultural competency using Natural Language Processing (NLP) models,9906653,F31MD014941,"['Address', 'Alcohol or Other Drugs use', 'Anxiety', 'Awareness', 'Behavior', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Discrimination', 'Empathy', 'Evidence based treatment', 'Face', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Grant', 'Health Personnel', 'Healthcare', 'Individual', 'Judgment', 'Label', 'Language', 'Lesbian Gay Bisexual Transgender Queer', 'Machine Learning', 'Measures', 'Mental Depression', 'Mental Health', 'Methods', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Outcome', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Provider', 'Psychotherapy', 'Quality of Care', 'Reporting', 'Research', 'Research Personnel', 'Suicide', 'Technology', 'Text', 'Therapeutic', 'Training', 'Treatment outcome', 'Work', 'base', 'commercial application', 'community setting', 'cultural competence', 'cultural values', 'disparity reduction', 'effective intervention', 'ethnic minority population', 'experience', 'health care disparity', 'improved', 'psychologic', 'psychological distress', 'racial and ethnic', 'sexual identity', 'showing emotion', 'substance abuse treatment', 'symptomatic improvement', 'tool', 'treatment disparity', 'university student', 'willingness']",NIMHD,UNIVERSITY OF UTAH,F31,2020,45016,0.03057509467475579
"Sarcopenia: computable phenotypes and clinical outcomes. PROJECT SUMMARY  Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function. Sarcopenia contributes to disability, increased hospitalizations, healthcare costs, and risk of death. Despite being under- recognized clinically, sarcopenia is a major public health concern, with the worldwide prevalence projected to increase by up to 72% in the next 30 years. However, limited knowledge of sarcopenia among clinicians, combined with time pressures in clinical encounters delay its detection, and limit opportunity for intervention or recruitment into clinical trials. To overcome this barrier to detecting sarcopenia, we propose to use advanced big data and machine learning methods to identify additional component variables predicting sarcopenia among the rich electronic health record (EHR) data and develop a validated and portable sarcopenia computable phenotype (which uses a computer algorithm to detect patient characteristics or outcomes from the EHR). This innovative proposal takes advantage of key resources at Indiana University and its affiliation with the Regenstrief Institute and the Indiana Network for Patient Care (INPC), a statewide multi-health system clinical data warehouse including >100 healthcare entities and >18 million unique patients with both coded and text-based data, combined with the ability to perform comprehensive musculoskeletal measurements in the Musculoskeletal Function Imaging and Tissue (MSK-FIT) Core funded through a NIAMS Core Center for Clinical Research grant (P30AR072581). Our long-term goal is to accurately identify patients with, or at risk for, sarcopenia and its consequences in order to provide targeted interventions. We hypothesize that by using medical informatics and machine learning innovations, computable phenotypes can identify patients with sarcopenia from the EHR, predict deficits in measured muscle strength and physical function, and prospectively predict risk of hospitalization and death. In Aim 1, we will categorize >2000 adult participants in the MSK-FIT Core with accessible EHR data, as either sarcopenic or nonsarcopenic according to measurements of muscle strength, muscle mass and physical performance. We will then use 75% of the MSK- FIT Core cohort to train machine deep learning algorithms to detect combinations of variables from these subjects’ EHR predicting whether the patient is sarcopenic or not sarcopenic. The performance of the resulting computable phenotype will then be tested in the remaining 25% of the MSK-FIT Core participants. In Aim 2, we will test the performance of the sarcopenia computable phenotype to detect a clinically meaningful phenotype in the entire INPC adult population (>18 million), by evaluating the ability to predict the rate of hospitalizations and death among patients rated as sarcopenic versus matched controls. Such a computable phenotype will then enable large scale targeted recruitment, pragmatic clinical trials, clinical evaluation and intervention. PROJECT NARRATIVE Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function, and contributing to disability, increased hospitalizations and risk of death. Despite being underrecognized clinically, sarcopenia is a major public health concern, with projected large increases in its prevalence worldwide. The overall goal of this grant is to use advanced, state-of-the art biomedical informatics and big data methods to generate a tool using electronic health record data to detect patients with sarcopenia early and facilitate patient recruitment, engagement and clinical interventions to treat sarcopenia.",Sarcopenia: computable phenotypes and clinical outcomes.,9970930,R01AR077273,"['Adult', 'Aging', 'Algorithms', 'Automated Clinical Decision Support', 'Awareness', 'Big Data', 'Big Data Methods', 'Birth', 'Cessation of life', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Computational algorithm', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Detection', 'Diagnosis', 'Diet', 'Disease', 'Electronic Health Record', 'Exercise', 'Funding', 'Goals', 'Grant', 'Hand Strength', 'Health Care Costs', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Image', 'Impairment', 'Indiana', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical Informatics', 'Methods', 'Muscle', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Outcome', 'Participant', 'Patient Care', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmacology', 'Phenotype', 'Physical Function', 'Physical Performance', 'Physicians', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Process', 'Provider', 'Public Health', 'Public Health Informatics', 'Publishing', 'Race', 'Reporting', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Supervision', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'Universities', 'age group', 'base', 'biomedical informatics', 'clinical center', 'clinical data warehouse', 'clinical encounter', 'cohort', 'comorbidity', 'computable phenotypes', 'deep learning algorithm', 'disability', 'electronic data', 'experience', 'hospitalization rates', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'mortality risk', 'muscle form', 'muscle strength', 'performance tests', 'physical conditioning', 'population health', 'portability', 'pressure', 'prevent', 'prospective', 'ranpirnase', 'recruit', 'reduced muscle mass', 'research clinical testing', 'sarcopenia', 'sex', 'text searching', 'tool']",NIAMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2020,235788,0.022195272758550644
"Integrative data science approaches for rare disease discovery in health records ABSTRACT: There are nearly 7,000 diseases that have a prevalence of only one in 2,000 individuals or less. Yet, such rare diseases are estimated to collectively affect over 300 million people worldwide, representing a significant healthcare concern. Although rare diseases have predominantly genetic origins, nearly half of them do not manifest symptoms until adulthood and frequently confound discovery and diagnosis. Even in the case of early onset disorders, the sheer number of possible diagnoses can often overwhelm clinicians. As a result, rare diseases are often diagnosed with delay, misdiagnosed or even remain undiagnosed, not only disrupting patient lives but also hindering progress on our understanding of such diseases. Data science methods that mine large-scale retrospective health record data for phenotypic information will aid in timely and accurate diagnoses of rare diseases, especially when combined with additional data types, thus, having significant real- world impact. This proposal will integrate electronic health record (EHR) data sets with publicly available vocabularies and ontologies, and genomic data for the improved identification and characterization of patients with rare diseases, using approaches from machine learning, natural language processing (NLP) and basic bioinformatics. The work has three specific aims and will be carried out in two phases. During the mentored phase, the principal investigator (PI) will develop data-driven methods to extract standardized concepts related to rare diseases from clinical notes and infer the occurrence of each disease (Aim 1). He will also develop data science approaches to compare and contrast longitudinal patterns associated with patients' journeys through the healthcare system when seeking a diagnosis for a rare disease, and aid in clinical decision-making by leveraging these patterns (Aim 2). During the independent phase (Aim 3), computational methods will be developed for the integrated modeling and analysis of genotypic (from Aim 3) and phenotypic information (from Aims 1 and 2). Cohorts to be sequenced will cover diseases for which causal genes or disease definitions are unclear (discovery), as well as those for which these are well known (validation). This work will be carried out under the mentorship of four faculty members with complementary expertise in biomedical informatics, data science, NLP, and rare disease genomics at the University of Washington, the largest medical system in the Pacific Northwest (four million EHRs), world-renowned researchers in medical genetics, and a robust data science environment. In addition, under the direction of the mentoring team, the PI will complete advanced coursework, receive training in translational bioinformatics and clinical research informatics, submit manuscripts, and seek an independent research position. This proposal will yield preliminary results for subsequent studies on data-driven phenotyping and enable the realization of the PI's career goals by providing him with the necessary training to build on his machine learning and basic bioinformatics expertise to transition into an independent investigator in biomedical data science. PROJECT NARRATIVE Rare genetic diseases are estimated to affect the lives of 25 to 30 million Americans and their families, and present a significant economic burden on the healthcare system. Currently, our knowledge of the broad spectrum of the 7,000 observed rare diseases is limited to a few well-studied ones, hindering our ability to make correct and timely diagnoses. The objective of this study is to improve the identification of patients with rare diseases in healthcare systems by developing data science approaches that automatically recognize rare disease-related patterns in patient health records and correlate them with genomic data, thus, aiding in diagnosis and discovery.",Integrative data science approaches for rare disease discovery in health records,9884791,K99LM012992,"['Adult', 'Affect', 'American', 'Award', 'Basic Science', 'Behavioral', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Research', 'Computing Methodologies', 'Consensus', 'Data', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostics Research', 'Disease', 'Economic Burden', 'Electronic Health Record', 'Environment', 'Faculty', 'Family', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Healthcare', 'Healthcare Systems', 'Individual', 'Informatics', 'Knowledge', 'Machine Learning', 'Manuscripts', 'Markov Chains', 'Medical', 'Medical Genetics', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Ontology', 'Outcome', 'Pacific Northwest', 'Patient Recruitments', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Prevalence', 'Principal Investigator', 'Rare Diseases', 'Recording of previous events', 'Research', 'Research Personnel', 'Standardization', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Vocabulary', 'Washington', 'Work', 'accurate diagnosis', 'base', 'biomedical data science', 'biomedical informatics', 'career', 'causal variant', 'clinical data warehouse', 'clinical decision-making', 'cohort', 'diagnostic accuracy', 'disease phenotype', 'early onset disorder', 'exome sequencing', 'gene discovery', 'genomic data', 'health care delivery', 'health data', 'health record', 'improved', 'member', 'multimodal data', 'novel', 'open source', 'patient health information', 'phenotypic data', 'prototype', 'psychologic', 'rare condition', 'rare genetic disorder', 'recruit', 'skills', 'software development', 'support tools', 'tool', 'trait']",NLM,UNIVERSITY OF WASHINGTON,K99,2020,92070,0.009773052051236188
"An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions PROJECT SUMMARY Most U.S. adults (68%) take dietary supplements and there is increasing evidence of drug-supplement interactions (DSIs); In recent years, there has been increasing evidence supporting the role of DSs in ADRD in preventing cognitive impairment but there is limited evidence and the sample sizes have been small. Real- world data (RWD) especially the EHR contain detailed treatment and response information from patients and could be used to detect the usage and effect of DSs, DSIs, which is more translational to clinical outcomes (e.g., MCI to ADRD conversion). To the best of our knowledge, there is no investigation on DSs usage and safety among patients in MCI and ADRD using EHR data. Our current parent award is focusing on the development of a translational informatics framework to enable the discovery of drug-supplement interactions (DSIs) by linking scientific evidence from the biomedical literature. To response to NOT-AG-20-008, this administrative supplement application will complement our parent award in multiple aspects: (1) developing novel and advanced data analytic methods for mining RWD in EHR, (2) identifying DSs usage information among patients with ADRD, and (3) detecting safety and effect of DS among patients with ADRD from existing EHR data. In our preliminary work, we have investigated the methods to identify DSs terms on EHR and developed natural language processing (NLP) methods to identify use status of DSs. We will further our efforts to collect a EHR dataset with DSs usage and AE-DSs signals from AD patients and develop innovative informatics methods to extract such information. Our specific aims are: (1) identifying DSs usage among patients with MCI and ADRD from existing EHR data; and (2) detecting the DSs safety signals and exploring the effect of DSs use on the conversion from MCI to ADRD from existing EHR data. The successful completion of this project will stimulate our further investigation on the role of DS use in patients with ADRD in a larger scale involving EHR data from other healthcare institutions. PROJECT NARRATIVE In this administrative supplement application, we will evaluate the usage and safety of dietary supplements (DSs) usage in patients with Mild Cognitive Impairment (MCI) and Alzheimer’s disease and related dementias (ADRD), respectively using electronic health records (EHR) data. We will also explore the feasibility of using EHR to detect DS effect on the conversion from MCI to ADRD. This research will address a critical and unmet need to conduct large-scale clinical research in DSs and improve evidence bases for healthcare practice. The successful accomplishment of this supplement project will deliver a novel informatics methods and generate DSI signals among patients with ADRD. This project will stimulate our further investigation on the role of DS use in patients with ADRD in a larger scale involving EHR data from other healthcare institutions.",An Informatics Framework for Discovery and Ascertainment of Drug-Supplement Interactions,10119590,R01AT009457,"['Address', 'Administrative Supplement', 'Adult', 'Alzheimer&apos', 's disease patient', 'Alzheimer&apos', 's disease related dementia', 'Artificial Intelligence', 'Award', 'Big Data', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Complement', 'Computerized Medical Record', 'Consumption', 'Data', 'Data Analytics', 'Data Set', 'Data Sources', 'Dementia', 'Detection', 'Development', 'Elderly', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Florida', 'Future', 'Genomics', 'Healthcare', 'Healthcare Systems', 'Human', 'Impaired cognition', 'Individual', 'Informatics', 'Institution', 'Intake', 'Investigation', 'Letters', 'Link', 'Literature', 'Methods', 'Mining', 'Natural Language Processing', 'Outcome', 'Parents', 'Patients', 'Pharmaceutical Preparations', 'Records', 'Research', 'Role', 'Safety', 'Sample Size', 'Signal Transduction', 'Surveys', 'Terminology', 'Training', 'Universities', 'Vascular Dementia', 'Work', 'analytical method', 'base', 'cohort', 'deep learning', 'dietary supplements', 'evidence base', 'genomic data', 'improved', 'innovation', 'interest', 'learning strategy', 'mild cognitive impairment', 'novel', 'pharmacovigilance', 'prevent', 'response', 'treatment response']",NCCIH,UNIVERSITY OF MINNESOTA,R01,2020,339298,0.08849322232886234
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,9930152,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2020,20000,0.07787767182766175
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,9873880,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'ROC Curve', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'acute care', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'large scale data', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2020,376860,0.02927535792193516
"Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data SUMMARY The modernization and standardization of clinical care information systems is creating large networks of linked electronic health records (EHR) that capture key treatments and select patient outcomes for millions of patients throughout the country. The observational data emerging from these systems provide an unparalleled opportunity to learn about the effectiveness of existing and novel treatments, and to monitor potential safety issues that may arise when interventions are used in broad patient populations. However, observational clinical data have exposures that are driven by many factors and therefore aggressive adjustment is needed to remove as much confounding bias as possible in order to make attribution regarding select exposures. The field of machine learning provides a powerful collection of data-driven approaches for performing flexible, thorough confounding adjustment, but performing reliable statistical inference is particularly challenging when these techniques are used as part of the analytic strategy. We propose to advance reproducible research methods by developing and illustrating novel targeted learning tools that leverage the flexibility of machine learning methods to detect and characterize health effect signals using large-scale EHR data. Specifically, we will first develop techniques for making efficient, statistically valid and robust inference for treatment effects using state-of-the-art machine learning tools. We will also develop online learning techniques to make such inference in the context of streaming EHR data. Methodological advances will enable us to formulate a formal, rigorous and practical framework for conducting continuous, effective and reliable surveillance for safety endpoints. Finally, we will develop statistical approaches for incorporating prior information -- including demographic, epidemiologic or pharmacodynamic knowledge, for example -- to improve health effect estimation and inference when the health outcome of interest is rare and the statistical problem is thus difficult, as often occurs in safety surveillance. The ultimate goal of the proposed research is to enable biomedical researchers and public health regulators to carefully monitor and protect the health of the public by allowing them to more effectively and more reliably detect critical health effect signals that may be contained in population-scale EHR data. PROJECT NARRATIVE The modernization and standardization of clinical care information systems is creating large networks of linked electronic medical records that capture key treatments and select patient outcomes for millions of U.S. subjects. The population scale of contemporary health care data is opening new opportunities for quickly learning from observational data, and is now supporting on-going national surveillance that will monitor the risks and benefits of both existing and novel treatment paths. The objective of this proposal is to provide an inferential framework that leverages the flexibility of machine learning methods to detect health effect signals, including in the important setting of high-dimensional confounders and/or rare events, and to develop a real-time sequential updating methodology for safety signal detection.",Statistical Methods for Incorporating Machine Learning Tools in Inference and Large-Scale Surveillance using Electronic Medical Records Data,9979940,R01HL137808,"['Algorithms', 'Benefits and Risks', 'Characteristics', 'Clinical Data', 'Complex', 'Computer software', 'Computerized Medical Record', 'Confidence Intervals', 'Country', 'Data', 'Data Collection', 'Data Set', 'Detection', 'Dimensions', 'E-learning', 'Early Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Epidemiology', 'Estimation Techniques', 'Event', 'Frequencies', 'Goals', 'Health', 'Healthcare', 'Heterogeneity', 'Information Systems', 'Infrastructure', 'Intervention', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modernization', 'Monitor', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacodynamics', 'Population', 'Population Surveillance', 'Procedures', 'Public Health', 'Records', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Safety', 'Sentinel', 'Signal Transduction', 'Standardization', 'Statistical Methods', 'Stream', 'Structural Models', 'Subgroup', 'Surveillance Program', 'System', 'Techniques', 'Testing', 'Time', 'Treatment outcome', 'Update', 'base', 'clinical care', 'comparative treatment', 'data streams', 'flexibility', 'high dimensionality', 'improved', 'interest', 'machine learning method', 'national surveillance', 'novel', 'open source', 'patient population', 'patient subsets', 'risk minimization', 'software development', 'surveillance data', 'tool', 'treatment effect', 'user-friendly']",NHLBI,UNIVERSITY OF WASHINGTON,R01,2020,485987,0.026103887901016715
"Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records Project Summary/Abstract This project proposes new methods for representing data in electronic health records (EHR) to improve pre- dictive modeling and interpretation of patient outcomes. EHR data offer a promising opportunity for advancing the understanding of how clinical decisions and patient conditions interact over time to inﬂuence patient health. However, EHR data are difﬁcult to use for predictive modeling due to the various data types they contain (con- tinuous, categorical, text, etc.), their longitudinal nature, the high amount of non-random missingness for certain measurements, and other concerns. Furthermore, patient outcomes often have heterogenous causes and re- quire information to be synthesized from several clinical lab measures and patient visits. The core challenge at hand is overcoming the mismatch between data representations in the EHR and the assumptions underly- ing commonly used statistical and machine learning (ML) methods. To this end, this project proposes novel wrapper-based methods for learning informative features from EHR data. Both methods propose specialized operators to handle sequential data, time delays, and variable interactions, and have the capacity to discover underlying clinical rules/decisions that affect patient outcomes. Importantly, both methods also produce archives of possible models that represent the best trade-offs between complexity and accuracy, which assists in model interpretation. These method advances are made possible by encoding a rich set of data operations as nodes in a directed acyclic graph, and optimizing the graph structures using multi-objective optimization. The central hypothesis of this research is that multi-objective optimization can learn effective data representations from the EHR to produce accurate, explanatory models of patient outcomes. Preliminary work has shown that these methods can effectively learn low-order data representations that improve the predictive ability of several state- of-the-art ML methods. This technique demonstrates good scaling properties with high-dimensional biomedical data. Aim 1 (K99) is to develop a multi-objective feature engineering method that pairs with existing ML methods to iteratively improve their performance by constructing new features from the raw data and using feedback from the trained model to guide feature construction. In Aim 2 (K99), this method is applied to form predictive models of the risk of heart disease and heart failure using longitudinal EHR data. The resultant models will be inter- preted with the help of mentors in order to translate predictions into clinical recommendations. For Aim 3 (R00), a second method is proposed that uses a similar framework to optimize existing neural network approaches in order to simplify their structure as much as possible while maintaining accuracy. The goal of Aim 4 (R00) is to identify hospital patients who are at risk of readmission and propose point-of-care strategies to mitigate that risk. This goal is facilitated through the application of the proposed methods to patient data collected from the Hospital of the University of Pennsylvania, the Geisinger Health System, and publicly available EHR databases. Project Narrative  Understanding how clinical decisions interact with a patient's health and environmental over time to inﬂuence patient outcomes is central to the goals of enhancing health, reducing illness and improving quality of life. The proposed research provides important methodological advances for extracting these insights from widely available patient health records.",Multi-objective representation learning methods for interpetable predictions of patient outcomesusing electronic health records,9936444,K99LM012926,"['Address', 'Affect', 'Archives', 'Area', 'Automobile Driving', 'Cardiovascular Diseases', 'Categories', 'Clinical', 'Communities', 'Complex', 'Couples', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Development', 'Disease', 'Electronic Health Record', 'Engineering', 'Feedback', 'Goals', 'Graph', 'Hand', 'Health', 'Health Sciences', 'Health system', 'Heart Diseases', 'Heart failure', 'Hospitals', 'Inpatients', 'Knowledge', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Nature', 'Outcome', 'Pathology', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pennsylvania', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Process', 'Property', 'Protocols documentation', 'Quality of life', 'Recommendation', 'Replacement Arthroplasty', 'Research', 'Research Personnel', 'Risk', 'Structure', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'University Hospitals', 'Visit', 'Work', 'base', 'care costs', 'cluster computing', 'data archive', 'deep learning', 'deep neural network', 'design', 'disease diagnosis', 'disorder subtype', 'heart disease risk', 'high dimensionality', 'hospital readmission', 'improved', 'insight', 'learning strategy', 'machine learning method', 'network architecture', 'neural network', 'novel', 'open source', 'operation', 'patient health information', 'point of care', 'predictive modeling', 'readmission rates', 'readmission risk', 'statistical and machine learning', 'tool']",NLM,UNIVERSITY OF PENNSYLVANIA,K99,2020,89401,0.045224738917660684
"Bridging the Gap between Genomics and Clinical Outcomes in CHD PROJECT SUMMARY/ABSTRACT The NHLBI has invested extensively in the Pediatric Cardiac Genomics Consortium (PCGC), recognizing that translating genomic discoveries into optimized management and therapeutic strategies for congenital heart disease (CHD) can only be achieved in the context of multi-center, collaborative research. Currently, the PCGC is lacking two fundamental capabilities that hinder its ability to define the genomic basis for CHD outcomes: (1) a robust mechanism for extracting pertinent, machine-readable clinical data from Electronic Health Records (EHRs) across multiple institutions; and (2) a robust Artificial Intelligence (AI) platform that is capable of teasing apart the complex interplay between maternal factors, phenotypes, genotypes, gene functions and clinical outcomes. Here, we propose innovative solutions to these challenges, by assembling teams of content experts to leverage existing infrastructure to extract relevant outcomes directly from the EHR of participating PCGC Centers and by designing best-practice AI tools for outcomes research. Our principal goal is provide the vision, infrastructure and expertise to collaboratively empower CHD outcomes research, foster knowledge exchange, and train the next generation of genomic scientists. We propose to leverage existing data infrastructure to obtain Electronic Health Records (EHR) and other clinical variables at scale by partnering with other research networks to create a PCGC Data Resource. Using this resource, we will create and deploy a platform of Artificial Intelligence (AI)-based predictors for CHD outcomes research, with the goal of translating genomic discoveries into improved management and therapeutic strategies for CHD. PROJECT NARRATIVE The overall goal of this project is to apply genomic discoveries toward prediction of clinical outcomes in congenital heart disease. The proposal encompasses innovative concepts and methodologies that will advance the field of congenital heart disease in a very practical manner.",Bridging the Gap between Genomics and Clinical Outcomes in CHD,10027913,U01HL128711,"['Artificial Intelligence', 'Bayesian Network', 'Bioinformatics', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Code', 'Collaborations', 'Complex', 'Custom', 'Data', 'Data Set', 'Dependence', 'Diagnostic', 'Disease Outcome', 'Electronic Health Record', 'Fostering', 'Foundations', 'Gender', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Heart', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internet', 'Knowledge', 'Methodology', 'Modeling', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Online Systems', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Patients', 'Pediatric Cardiac Genomics Consortium', 'Pediatric cardiology', 'Phenotype', 'Readability', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Risk Factors', 'Scientist', 'Site', 'Societies', 'Standard Model', 'Testing', 'Therapeutic', 'Thoracic Surgical Procedures', 'Training', 'Translating', 'Utah', 'Vision', 'Visit', 'Work', 'base', 'clinical care', 'clinical database', 'comorbidity', 'congenital heart disorder', 'data infrastructure', 'data resource', 'design', 'gene function', 'genomic data', 'improved', 'innovation', 'member', 'next generation', 'novel', 'outcome prediction', 'patient oriented', 'predict clinical outcome', 'programs', 'relational database', 'repository', 'skills', 'surgery outcome', 'tool']",NHLBI,UNIVERSITY OF UTAH,U01,2020,419375,0.02438677876282321
"PsycheMERGE: Leveraging electronic health records and genomics for mental health research Neuropsychiatric disorders are the leading causes of disability in the US and are associated with increased mortality (e.g. through suicide and associations with chronic diseases and their risk factors). Evidence suggests that early detection and treatment of psychiatric illness is essential to improving long-term outcomes and may even modify illness trajectories at a biological level. Unfortunately, a substantial proportion of patients undergo a long diagnostic odyssey before receiving an appropriate diagnosis and initiating effective treatment. Efforts to improve surveillance for emerging or occult psychopathology are often complex, costly, and have limited yield. Thus, there is an urgent public health need to improve clinical decision support for the early detection of psychiatric disorders in clinical settings. The growing availability of large-scale biobanks linking EHRs to biospecimens has created a powerful, but still relatively untapped, opportunity for psychiatric research. In 2007, the NHGRI organized the Electronic Medical Records and Genomics (eMERGE) network which has brought together investigators around the U.S. to facilitate EHR-based genomic research and the implementation of genomic medicine. To date, however, EHR-based risk prediction and genomics have not been widely leveraged for psychiatric research. To address this gap, we have created a new, large-scale collaborative consortium—PsycheMERGE—which leverages the resources and existing infrastructure of the eMERGE network, the Psychiatric Genomics Consortium (PGC), and local EHR and biobank resources. In this proposal, we aim to: (1) phenotypically and genomically validate and harmonize case and control phenotypes across multiple disorders (2) build clinically-useful risk surveillance models for mood disorders that also leverage cross-institutional genomewide data, and (3) examine whether EHR- and genomic-based risk profiles are associated with clinically-relevant health outcomes. We will further use these risk profiles to examine disparities in diagnostic delay by age, sex and race/ethnicity. The resulting diagnostic and risk prediction algorithms will be made available to the scientific community through the eMERGE network. Successful completion of these aims would represent a major advance in demonstrating the utility of EHR resources for precision medicine approaches to psychiatry, provide the first step toward clinical decision support tools that can be implemented within health systems, and create an invaluable resource for the scientific community. Neuropsychiatric disorders are leading causes of disability and even mortality. We have created a collaborative consortium of health systems--PsycheMERGE—to enable clinical and genetic research that will improve the understanding and early detection of psychiatric disorders. We will use cutting-edge computational and genetic methods to examine the predictors of psychiatric illness and provide a key step toward the goals of “precision psychiatry”.",PsycheMERGE: Leveraging electronic health records and genomics for mental health research,9873997,R01MH118233,"['Address', 'Adult', 'Age', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Biological', 'Bipolar Disorder', 'Childhood', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Communities', 'Complex', 'Computerized Medical Record', 'Data', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Ethnic Origin', 'Genetic', 'Genetic Research', 'Genomic medicine', 'Genomics', 'Gilles de la Tourette syndrome', 'Goals', 'Health', 'Health system', 'Heritability', 'Individual', 'Infrastructure', 'Insurance Coverage', 'Link', 'Machine Learning', 'Major Depressive Disorder', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Mood Disorders', 'National Human Genome Research Institute', 'Obsessive-Compulsive Disorder', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Probability', 'Process', 'Psychiatry', 'Psychopathology', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Schizophrenia', 'Site', 'Suicide', 'Surveillance Modeling', 'Testing', 'Training', 'Validation', 'Variant', 'autism spectrum disorder', 'base', 'biobank', 'case control', 'clinical decision support', 'clinical risk', 'clinically relevant', 'comorbidity', 'cost', 'data resource', 'delay sex', 'disability', 'disorder risk', 'effective therapy', 'genome wide association study', 'genome-wide', 'genomic predictors', 'health care service utilization', 'high risk', 'improved', 'indexing', 'mortality', 'neuropsychiatric disorder', 'phenotyping algorithm', 'polygenic risk score', 'precision medicine', 'prediction algorithm', 'predictive modeling', 'psychiatric genomics', 'random forest', 'sex', 'support tools', 'support vector machine']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,791339,0.002432655985347165
"Investigating the documentation of E-cigarette use in the VA EHR PROJECT SUMMARY Electronic cigarettes were developed in China in the early 2000s and first introduced to the US market in 2007. Once established in the US, the product experienced explosive growth, with the number of electronic cigarette users doubling every year between 2008 and 2012. In 2012, it was estimated that 75% of US adults had heard of electronic cigarettes, and 8% had tried them. While electronic cigarettes have been studied over the last sev- eral years, no scientific consensus has emerged regarding either the safety of electronic cigarettes, or their po- tential as a smoking cessation aid. With this proposal, we will investigate how electronic cigarette use is documented in the Veterans Association Electronic Health Record, focusing specifically on the relationship between electronic cigarette use and com- bustible tobacco use, with the goal of understanding both how electronic cigarette use is documented in the context of the United States’ only nationwide health system, and how electronic cigarette related information can be reliably extracted from narrative clinical text using fully automated Natural Language Processing meth- ods. PROJECT NARRATIVE The proposed research focuses on the use of Natural Language Processing methods to automatically extract mentions of electronic cigarette use from the Veterans Association Electronic Health Record. The research will provide insight into important, currently unresolved questions regarding how clinicians record electronic cigarette use in the context of a nationwide health system, and whether patients report the use of electronic cigarettes as a smoking cessation aid or use the devices in conjunction with combustible tobacco.",Investigating the documentation of E-cigarette use in the VA EHR,9852435,R03DA047577,"['Address', 'Adult', 'Algorithms', 'American', 'Area', 'China', 'Cities', 'Clinical', 'Consensus', 'Dangerousness', 'Data', 'Data Set', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Electronic Nicotine Delivery Systems', 'Electronic cigarette', 'Environment', 'Epidemiology', 'Evaluation', 'Geography', 'Goals', 'Government', 'Growth', 'Health', 'Health system', 'Healthcare Systems', 'Hearing', 'Individual', 'Methods', 'Natural Language Processing', 'Patients', 'Pattern', 'Professional Organizations', 'Public Health', 'Public Health Applications Research', 'Reporting', 'Research', 'Risk', 'Safety', 'Scheme', 'Smoking', 'Sodium Chloride', 'Source', 'Technology', 'Text', 'Tobacco', 'Tobacco use', 'United States', 'Universities', 'Utah', 'Variant', 'Veterans', 'Work', 'authority', 'electronic cigarette use', 'electronic cigarette user', 'electronic hookah', 'evidence base', 'experience', 'information model', 'innovation', 'insight', 'smoking cessation', 'structured data', 'success', 'systems research', 'tobacco control', 'tool', 'vape pens']",NIDA,UNIVERSITY OF UTAH,R03,2020,76250,0.023494331983313178
"Multisite Electronic Health Record-Based Surveillance of the Burden of Diabetes by Type in Young Adults Approximately 3 million young adults aged 18-44 years currently have diabetes in the United States. This number is projected to increase to ~5.8 million by 2060. Differentiating diabetes types is crucial, because the etiology, treatments, and outcomes of diabetes differ substantially by type. Type 1 diabetes (T1D) accounts for ~17% and type 2 diabetes (T2D) ~75% of total diabetes in US young adults. This distribution of diabetes types continuously evolves. We do not have a large-scale surveillance system to monitor the prevalence and incidence of T1D and T2D in US young adults. The widespread use and increasing functionality of electronic health record (EHR) systems substantially increase the quantity, breadth, and timeliness of data available for surveillance and reduce costs compared with population-based registries and surveys. EHR algorithms have shown great potential in identifying diabetes cases. This study will analyze both structured EHR data (e.g., diagnosis codes, medications, and laboratory results) and unstructured clinical notes. We will apply expert knowledge, machine learning, and natural language processing to develop the best algorithms for identifying prevalent and incident T1D and T2D cases. The primary objective of this study is to establish an EHR-based surveillance system for monitoring the burden of T1D and T2D in US young adults. We will collaborate with 3 EHR research networks from the National Patient-Centered Clinical Research Network (PCORnet), covering ~6 million racially, ethnically, and socioeconomically diverse young adults from 4 states (IL, LA, NY, and TX) in 3 Census regions. The patient populations in this study are roughly representative of the source populations in the catchment areas. The specific aims of this study are 1) to estimate the prevalence of T1D and T2D in US young adults by age, sex, race/ethnicity, and geographic region in 2019; 2) to estimate the incidence of T1D and T2D in US young adults by age, sex, race/ethnicity, and geographic region in 2019; 3) to estimate 10-year trends in the prevalence and incidence of T1D and T2D in US young adults by age, sex, race/ethnicity, and geographic region, 2014-2023; and 4) to compare the prevalence and incidence of diabetes by type, as well as temporal trends, in US young adults with those in young adults from other countries and regions. This study is innovative, because it will detect a false negative rate as low as 0.2%, leverage EHRs for surveillance (more efficient and cost-effective than registries and surveys), use advanced statistical approaches (e.g., machine learning and natural language processing), estimate a denominator using patient zip codes, build flexibility into the surveillance methods according to local availability of clinical notes, and use a 2-staged sampling approach to improve chart review efficiency. This study will advance our understanding of the age, sex, racial/ethnic, and geographic differences in the burden of T1D and T2D in US young adults. The obtained surveillance data will inform planning for healthcare needs, prioritize the allocation of healthcare resources, and reduce health disparities via identifying and prioritizing subpopulations for prevention of diabetes and related comorbidities. The burden of diabetes has been increasing considerably in recent decades in US young adults. However, there is no large-scale surveillance system for monitoring the burden of diabetes by type in US young adults. This study will build an efficient and cost-effective multisite surveillance system using electronic health records, to estimate the prevalence, incidence, and temporal trends of type 1 and type 2 diabetes in US young adults according to age, sex, race/ethnicity, and geographic region.",Multisite Electronic Health Record-Based Surveillance of the Burden of Diabetes by Type in Young Adults,10085448,U18DP006502,[' '],NCCDPHP,CORNELL UNIVERSITY,U18,2020,250000,-0.01172084490951538
"Development and validation of an electronic health record prediction tool for first-episode psychosis Psychosis is a major public health challenge, with approximately 100,000 adolescents and young adults in the US experiencing a first episode of psychosis (FEP) every year. Early intervention following FEP is critical for achieving improved outcomes, yet treatment of FEP is often delayed between 1 and 3 years in the US due to delays in detection and referral. The World Health Organization has advocated shortening the duration of untreated psychosis (DUP) to three months or less. The goal of this study is to develop and validate a universal EHR-based screening tool for early detection of FEP across large clinical populations in diverse healthcare settings. In order to maximize the impact and generalizability of the tool across a wide range of healthcare settings, we will rely only on coded medical information collected in the course of care and thus widely available in EHRs. The tool will be developed and validated with data from three diverse health systems that cover over 8 million patients spanning a wide range of demographic, socioeconomic and ethnic backgrounds: Partners Healthcare System, Boston Children's Hospital, and Boston Medical Center. The study will be conducted by a closely collaborating interdisciplinary team of clinical specialists, psychosis researchers, and risk modeling experts based at these health systems and Harvard Medical School, with extensive experience in treating psychosis patients, and developing strategies for detecting FEP and EHR-based risk screening tools for early detection of various clinical conditions. Our preliminary studies show that EHR-based risk models can be used to sensitively and specifically detect FEP cases, on average 2 years before the first psychosis diagnosis appears in their EHR. Our specific aims include: 1. Define a robust cross-site case definition for FEP that relies only on information commonly available in EHRs and validate it through expert chart review; 2. Train and validate a predictive model for early detection of FEP based on large samples of patient data from the three sites; 3. Develop and validate FEP early detection models for key subpopulations, including patients receiving care at mental health clinics, adolescent medicine outpatient programs, and substance abuse treatment programs; and 4. Engage clinical stakeholders in the process of developing a prototype clinician-facing EHR-based risk screening tool for FEP, and release it as an open source SMART App, enabling further validation and clinical integration across a wide range of healthcare settings. Completion of these aims would provide a novel, clinically deployable, and potentially transformative tool for improving the trajectory of those affected with psychosis and reducing the burden and costs of untreated illness. Psychosis is a major public health challenge, with difficulties and delays in detecting its onset that can lead to worse clinical outcomes. The proposed research will develop a clinician-facing electronic-health-record-based automated screening tool for early detection of the first episode of psychosis, with implications for reducing the duration of untreated psychosis as recommended by the NIMH and World Health Organization. The tool will be validated across three large and diverse health systems and released as an open source application (SMART App), increasing its potential for rapid implementation in health systems and clinical care.",Development and validation of an electronic health record prediction tool for first-episode psychosis,9864102,R01MH116042,"['Accident and Emergency department', 'Adolescent Medicine', 'Adolescent and Young Adult', 'Advocate', 'Affect', 'Boston', 'Calibration', 'Caring', 'Clinic', 'Clinical', 'Code', 'Communities', 'Data', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Early Intervention', 'Electronic Health Record', 'General Population', 'Goals', 'Health system', 'Healthcare Systems', 'Inpatients', 'Intervention', 'Laboratories', 'Lead', 'Manuals', 'Measures', 'Medical', 'Medical center', 'Mental Health', 'Modeling', 'National Institute of Mental Health', 'Outcome', 'Patients', 'Pediatric Hospitals', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Primary Health Care', 'Procedures', 'Process', 'Psychotic Disorders', 'Public Health', 'Research', 'Research Personnel', 'Research Support', 'Risk', 'Risk Factors', 'Sampling', 'Screening procedure', 'Sensitivity and Specificity', 'Site', 'Specialist', 'Suicide', 'Testing', 'Time', 'Training', 'Validation', 'Work', 'World Health Organization', 'base', 'clinical care', 'cost', 'data resource', 'design', 'experience', 'first episode psychosis', 'health care settings', 'improved', 'improved outcome', 'individual patient', 'interest', 'medical schools', 'medical specialties', 'novel', 'open source', 'outpatient programs', 'predictive modeling', 'prototype', 'random forest', 'socioeconomics', 'substance abuse treatment', 'support vector machine', 'tool', 'treatment program']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,847935,0.01716294381192491
"An Electronic Health Record-Based Tool to Identify Newly Diagnosed Breast Cancer Patients at Risk of Low Social Support ABSTRACT Social support, a social determinant of health (SDoH), is a definitive predictor of breast cancer (BC) treatment and mortality outcomes. Because of the recognition that social support is critical to BC patient outcomes, clinicians within Kaiser Permanente Northern California (KPNC) have documented information on social support in the electronic health record (EHR) since the advent of Epic in 2005. However, no EHR-based social support measure currently exists to help clinicians identify patients at high risk of low social support. Such a measure has high relevance for addressing racial/ethnic disparities in BC treatment and outcomes. Therefore, we propose to develop an Electronic Health Record Social Support Patient Risk Tool (EHR-SUPPORT) that could be used to identify women with BC at risk of low social support for referral to social support resources. We propose to: 1) Identify terms in the EHR, based on theory and prior literature, and informed by KPNC stakeholders in BC care, that reflect structural and/or functional social support, and have been associated with BC treatment and outcomes; 2) Develop EHR-SUPPORT, using structured, semi-structured, and unstructured data (to include natural language processing of text) that identifies patients at risk of low social support, overall and by race/ethnicity, and validate the measure against published social support measures; and 3) Evaluate associations of EHR-SUPPORT and its component variables with BC treatment (surgery and chemotherapy delays, nonadherence to hormonal therapy) and BC-specific and total mortality, overall and by race/ethnicity in 44,348 women diagnosed with stage I-IV BC within Kaiser Permanente Northern California between 2006- 2023 including 3,450 Black, 4,441 Hispanic, 6,571 Asian women, and 28,589 non-Latina white women. In an exploratory aim, we will develop, with KP clinician stakeholders, steps to the implementation of EHR- SUPPORT. We will review 100 medical records (25 in each race/ethnic group) within two months of diagnosis, informed by investigator expertise and clinician stakeholders, to develop terms used to describe patient support. In addition to developing structured data, we will use natural language processing of text fields to further develop social support indicators (Aim 1). EHR-SUPPORT will be computed from social support indicators; we will use linear and logistic regression to validate the developed measure against established social support measures in Pathways, a well-established cohort of 4,505 women with BC and use factor analytic and confirmatory factor analytic methods as well as ROC curves to further evaluate the score (Aim 2). We will use linear, logistic, and Cox proportional hazards regression to evaluate associations in Aim 3. The unique convergence of EHR and cohort data provides the first opportunity to develop and validate an EHR- based social support measure in in diverse women with BC, adjusted for an extensive set of covariates. This work is central to identifying patients at elevated risk of low social support and to enhancing social support- cancer research needed to improve clinical care and reduce BC disparities. NARRATIVE Social support, a social determinant of health (SDoH), is a definitive predictor of breast cancer (BC) treatment and mortality outcomes and is critical to racial/ethnic disparities in breast cancer (BC) treatment and mortality outcomes. This study will develop and validate an Electronic Health Record Social Support Patient Risk Tool (EHR-SUPPORT) in 44,348 women diagnosed with BC from Kaiser Permanente Northern California. Developing this measure is central to identifying patients at risk of low social support and to enhancing social support-cancer research needed to improve clinical care and reduce BC disparities.",An Electronic Health Record-Based Tool to Identify Newly Diagnosed Breast Cancer Patients at Risk of Low Social Support,10047252,R01CA253028,"['Academy', 'Address', 'African American', 'Area', 'Asians', 'Breast Cancer Patient', 'Breast Cancer Treatment', 'California', 'Cancer Research Network', 'Caring', 'Clinical', 'Code', 'Cohort Studies', 'Data', 'Data Collection', 'Development', 'Diagnosis', 'Documentation', 'Electronic Health Record', 'Emergency Situation', 'Ethnic Origin', 'Ethnic group', 'Funding', 'Health', 'Healthcare Systems', 'Hispanics', 'Information Technology', 'Intervention', 'Language', 'Linear Regressions', 'Link', 'Literature', 'Logistic Regressions', 'Logistics', 'Marital Status', 'Measures', 'Medical', 'Medical Care Team', 'Medical Records', 'Medicine', 'Natural Language Processing', 'Newly Diagnosed', 'Not Hispanic or Latino', 'Operative Surgical Procedures', 'Outcome', 'Pacific Island Americans', 'Pathway interactions', 'Patient Care', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Perception', 'Pilot Projects', 'Population', 'Provider', 'Publishing', 'Questionnaires', 'ROC Curve', 'Race', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Services', 'Social Conditions', 'Social Network', 'Social support', 'Source', 'Structure', 'Text', 'Treatment outcome', 'Woman', 'Work', 'analytical method', 'anticancer research', 'base', 'cancer care', 'cancer health disparity', 'chemotherapy', 'clinical care', 'clinically relevant', 'cohort', 'ethnic diversity', 'ethnic minority population', 'hazard', 'health care settings', 'high risk', 'hormone therapy', 'improved', 'improved outcome', 'malignant breast neoplasm', 'mortality', 'patient response', 'racial and ethnic', 'racial and ethnic disparities', 'racial diversity', 'social', 'social computing', 'social health determinants', 'social relationships', 'social structure', 'structured data', 'theories', 'tool', 'unstructured data']",NCI,KAISER FOUNDATION RESEARCH INSTITUTE,R01,2020,585693,-0.00125235961785509
"From enrichment to insights Project Summary Most medical decisions are made without the support of rigorous evidence in large part due to the cost and complexity of performing randomized trials for most clinical situations. In practice, clinicians must use their judgement, informed by their own and the collective experience of their colleagues. The advent of the electronic health record (EHR) enables the modern practitioner to algorithmically check the records of thousands or millions of patients to rapidly find similar cases and compare outcomes. In addition to filling the inferential gap in actionable evidence, these kinds of analyses avoid issues of ethics, practicality, and generalizability that plague randomized clinical trials (RCTs). Unfortunately, identifying patients with the appropriate phenotypes, properly leveraging available data to adjust results, and matching similar patients to reduce confounding remain critical challenges in every study that uses EHR data. Overcoming these challenges to improve the accuracy of observational studies conducted with EHR data is of paramount importance. Studies using EHR data begin by defining a set of patients with specific phenotypes, analogous to amassing a cohort for a clinical trial. This process of electronic phenotyping, is typically done via a set of rules defined by experts. Machine learning approaches are increasingly used to complement consensus definitions created by experts and we propose several advances to validate and improve this practice. We will explore and quantify the effects of feature engineering choices to transform the diagnoses, procedures, medications, laboratory tests and clinical notes in the EHR into a computable feature matrix. Finally, building on recent advances, we plan to characterize the performance of existing methods and develop EHR-specific strategies for patient matching. Our work is significant because we will take on three challenging problems--electronic phenotyping, feature engineering, and patient matching--that stand in the way of generating insights via EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes. Narrative The advent of the electronic health record (EHR) enables the search of thousands or millions of patients to rapidly find similar cases and compare outcomes. We will develop methods for feature engineering, electronic phenotyping and patient matching from real-world EHR data. If we are successful, we will significantly advance our ability to generate insights from the large amounts of health data that are routinely generated as a byproduct of clinical processes.",From enrichment to insights,10000216,R01LM011369,"['Address', 'Algorithms', 'Area', 'Clinical', 'Clinical Trials', 'Code', 'Complement', 'Consensus', 'Data', 'Data Element', 'Data Set', 'Diagnosis', 'Effectiveness', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evaluation', 'Frequencies', 'Future', 'Goals', 'Health system', 'Healthcare Systems', 'Institution', 'Judgment', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Mining', 'Modality', 'Modeling', 'Modernization', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Plague', 'Procedures', 'Process', 'Randomized Clinical Trials', 'Records', 'Resources', 'Scheme', 'Source', 'Statistical Data Interpretation', 'Test Result', 'Testing', 'Time', 'Training', 'Work', 'base', 'cohort', 'cost', 'electronic data', 'experience', 'health data', 'improved', 'innovation', 'insight', 'large datasets', 'machine learning algorithm', 'novel', 'portability', 'randomized trial', 'simulation', 'treatment effect', 'vector']",NLM,STANFORD UNIVERSITY,R01,2020,643304,0.08339181344218961
"Biases introduced by filtering electronic health records for patients with ""complete data"" PROJECT SUMMARY Nationwide adoption of electronic health records (EHRs) has led to the increasing availability of large clinical datasets. With statistical modeling and machine learning, these datasets have been be used in a wide range of applications, including diagnosis, decision support, cost reduction, and personalized medicine. However, because the same patient could be treated at multiple health care institutions, data from only a single EHR might not contain the complete medical history for that patient, with critical events potentially missing. A common approach to addressing this problem is to apply data checks that filter the EHR for patients whose data appear to be more “complete”. Examples of filters include requiring at least one visit per year or ensuring that age, sex, and race are all recorded. However, in a previous study using EHR data from seven institutions, we showed that these filters can greatly reduce the sample size and introduce unexpected biases by selecting sicker patients who seek care more often and changing the demographics of the resulting cohorts. This project extends this prior research by implementing an expanded set of data completeness filters and testing their accuracy and potential biases using a combination of national claims data and EHR data from dozens of hospitals and healthcare centers across the country. This will enable us to understand how data completeness varies in different EHRs and quantify the tradeoffs of different approaches to correcting for gaps in patients' records. First, we will develop and measure the accuracy of data completeness filters using national claims data. This provides a “gold standard” of longitudinal data where patients' complete medical histories are known during the periods in which they were enrolled in the insurance plan. After partitioning the data by provider groups to model gaps in EHR data, we will test how well data completeness filters, individually and in combined machine learning models, select patients with fewer gaps. We will then test whether the filters introduce biases by selecting sicker patients (more diagnoses, more visits, etc.) or changing their demographic characteristics (age, sex, and zip code). Then, we will test the filters on EHR data, first at a single large medical center, and then across a national network of 57 institutions, representing different geographic regions, patient populations, number of years of data, and types of health care facilities. We will evaluate the filters by measuring whether they improve the performance of a machine learning model for predicting hospital admissions. Our ultimate goals are to (a) help researchers balance the need for complete data with the biases this might introduce to their models and (b) help them predict how well models trained on one EHR dataset might work on other EHRs with different data completeness profiles. PROJECT NARRATIVE Nationwide adoption of electronic health records (EHRs) has led to the increasing availability of large clinical datasets. However, because the same patient could be treated at multiple health care institutions, data from only a single EHR might not contain the complete medical history for that patient, with critical events potentially missing. This study identifies biases that are introduced by selecting patients with fewer gaps in their record.","Biases introduced by filtering electronic health records for patients with ""complete data""",10121437,R01LM013345,"['Address', 'Adopted', 'Adoption', 'Age', 'Characteristics', 'Clinical', 'Clinical Trials', 'Clinical Trials Network', 'Clinical and Translational Science Awards', 'Code', 'Computer software', 'Country', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Equilibrium', 'Event', 'Funding', 'Geographic Locations', 'Goals', 'Gold', 'Health', 'Health care facility', 'Healthcare', 'Hospitalization', 'Hospitals', 'Individual', 'Institution', 'Insurance Carriers', 'Israel', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Medical History', 'Medical center', 'Modeling', 'Ontology', 'Patients', 'Performance', 'Probability', 'Procedures', 'Provider', 'Race', 'Recording of previous events', 'Records', 'Research', 'Research Personnel', 'Sample Size', 'Site', 'Statistical Models', 'System', 'Testing', 'Training', 'United States National Institutes of Health', 'Visit', 'Weight', 'Work', 'care seeking', 'clinical database', 'cohort', 'cost', 'demographics', 'improved', 'insurance plan', 'open source', 'patient health information', 'patient population', 'personalized medicine', 'predictive modeling', 'sex']",NLM,HARVARD MEDICAL SCHOOL,R01,2020,373990,0.047456713344001644
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,9928343,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2020,160164,0.039711305588894893
"Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing The adoption of Electronic Health Record (EHR) systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format with tremendous potential but an equally large concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfill the potential for high quality healthcare, improved healthcare management, and effective clinical research. NIH expects that larger research projects share their research data in a way that protects the confidentiality of research subjects. De-identification of patient data has been proposed as a solution to both facilitate secondary use of clinical data and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes, and de-identification of clinical text is a tedious and costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for higher accuracy and much faster de- identification than manual approaches. Clinacuity, Inc. proposes to advance a text de-identification system from a prototype to an accurate, adaptable, and robust system, integrated into the research infrastructure at our implementation and testing site (Medical University of South Carolina, Charleston, SC), and ready for commercialization efforts. To accomplish this undertaking, we will focus on the following specific aims and related objectives, while continuing to prepare the commercialization of the integrated system, with detailed market analysis, commercial roadmap development, and modern media communication: 1) Enhance the text de-identification system performance, scalability, and quality to produce an enterprise-grade solution ready for deployment; 2) Enable use of structured data for enhanced text de-identification (when structured PII is available) and for complete patient records de-identification (i.e., records combining structured and unstructured data). This aim also includes implementing “one-way” pseudo-identifier cryptographic hashing to enable securely linking already de-identified patient records; 3) Integrate the text de-identification system with a research data capture and management system. This includes implementation of the de-identification system as a secure web service, with standards-based access and integration. This de-identification system has potential commercial applications in clinical research and in healthcare settings. It will improve access to richer, more detailed, and more accurate clinical data (in clinical text) for clinical researchers. It will ease research data sharing (as expected for larger NIH-funded research projects) and help healthcare organizations protect patient data confidentiality. Significant time-savings will also be offered, with a process at least 200-1000 times faster than manual de-identification. The adoption of Electronic Health Record systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format, with tremendous potential, but also equally growing concern for patient confidentiality breaches. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data and protect patient data confidentiality. This project will advance a text de-identification system from a prototype to an accurate, adaptable and robust system allowing for complete patient records de-identification, integrated in the research infrastructure at our implementation and testing site and ready for commercialization efforts. It will improve access to richer, more detailed, and more accurate clinical data for clinical researchers, ease research data sharing and help healthcare organizations protect patient data confidentiality. !",Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing,9908962,R42GM116479,"['Adoption', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Communications Media', 'Confidentiality of Patient Information', 'Data', 'Development', 'Electronic Health Record', 'Enrollment', 'Environment', 'Fast Healthcare Interoperability Resources', 'Funding', 'Growth', 'Health Insurance Portability and Accountability Act', 'Improve Access', 'Link', 'Manuals', 'Medical', 'Modernization', 'National Institute of General Medical Sciences', 'Natural Language Processing', 'Patient Care', 'Patient Data Privacy', 'Patients', 'Performance', 'Personally Identifiable Information', 'Phase', 'Privacy', 'Process', 'Records', 'Reference Standards', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Risk', 'Savings', 'Secure', 'Site', 'South Carolina', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'Universities', 'Visualization', 'base', 'commercial application', 'commercialization', 'cost', 'cryptography', 'data reuse', 'data sharing', 'health care quality', 'health care service organization', 'health care settings', 'health management', 'improved', 'large scale data', 'prototype', 'software development', 'standard measure', 'structured data', 'systems research', 'unstructured data', 'web services']",NIGMS,"CLINACUITY,INC.",R42,2020,759330,0.03587354388970616
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,9880374,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'infection risk', 'informatics infrastructure', 'informatics tool', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'risk prediction model', 'structured data', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2020,592632,0.11797991676305263
"Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort Statins among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Pleiotropic effects are unanticipated outcomes other than those for which the drug was originally developed, either therapeutic (beneficial) or detrimental (adverse drug reactions). Statin pleiotropic effects are unanticipatedly broad, including increasing the risk of developing type 2 diabetes mellitus and cataract, decreasing cancer-related mortality, and reducing dementia. Many effects are still not determined. In addition, individual responses to statins are highly variable. Genetics studies have identified loci that are significantly associated with statin response. However, it is unclear if either of the genetic variants within these regions is also associated with statin pleiotropic effects. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2.5 million individuals at Vanderbilt, including >110,000 statin exposure individuals. By linking this cohort to BioVU, the Vanderbilt de-identified DNA biobank, >10,000 of these statin exposure individuals have extant genome-wide genotyping. We argue that 1) previous inconclusive results are largely caused by inconsistent phenotype definitions, and 2) using the EHR to develop a novel, drug-based phenome-wide association studies (PheWAS) provides an ideal approach to discover unknown statin effects. The still-growing Vanderbilt de-identified EHRs allow large amounts of individuals' clinical data shared to support validation of known pleiotropic effects and to enable novel discoveries. Our previous work demonstrated our ability to develop consistent EHR-based phenotype definitions that can be deployed across multiple EHRs and institutions. We have expertise leveraging state-of-the-art informatics techniques, including natural language processing and ontologies, for pharmacogenetic studies, including for statins. We first described the PheWAS approach to not only replicate genetic associations but also discover novel, pleiotropic associations. Our informatics expertise combined with an ideal EHR/DNA population, will enable us to validate and discover statin pleiotropic effects. Accordingly, we propose the following three aims: 1. develop and test EHR-based phenotype algorithms for four controversial statin pleiotropic effects, 2. conduct a PheWAS to discover unknown statin pleiotropic effects, and 3. evaluate and discover genetic predictors of statin pleiotropic effects. Project Narrative Statins (HMG-CoA reductase inhibitors), among the most widely prescribed agents worldwide for prevention of cardiovascular diseases, produce substantial pleiotropic effects. Statin pleiotropic effects are unanticipatedly broad and the genetic variants associated with statin pleiotropic effects remain unclear. We propose to investigate statin pleiotropic effects using whole de-identified electronic health records (EHRs) of >2 million patients at Vanderbilt (including 10,000 genotyped statin recipients) to answer these questions.",Exploring Statin Pleiotropic Effects within a Very Large EHR Cohort,9881338,R01HL133786,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Breast', 'Candidate Disease Gene', 'Cataract', 'Clinic', 'Clinical', 'Clinical Data', 'Cohort Analysis', 'Colorectal', 'Conflict (Psychology)', 'DNA', 'Data', 'Dementia', 'Disease', 'Electronic Health Record', 'Epidemiologist', 'Exposure to', 'General Population', 'Genetic', 'Genetic Variation', 'Genetic study', 'Genotype', 'Hydroxymethylglutaryl-CoA Reductase Inhibitors', 'Individual', 'Informatics', 'Institution', 'Link', 'Lung', 'Lymphoma', 'Malignant Neoplasms', 'Manuals', 'Mediating', 'Methods', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Oxidoreductase', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phenotype', 'Population', 'Predictive Value', 'Prostate', 'Qi', 'Research', 'Research Personnel', 'Research Project Grants', 'Risk', 'TCF7L2 gene', 'Techniques', 'Testing', 'Therapeutic', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vascular Diseases', 'Work', 'adverse drug reaction', 'base', 'biobank', 'cancer risk', 'cardiovascular disorder prevention', 'cohort', 'data sharing', 'genetic analysis', 'genetic association', 'genetic predictors', 'genetic variant', 'genome wide association study', 'genome-wide', 'genomic locus', 'glutaryl coA', 'individual response', 'inhibitor/antagonist', 'mortality', 'novel', 'novel therapeutics', 'phenome', 'phenotyping algorithm', 'pleiotropism', 'response']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,395483,0.02962824301994994
"Advancing Quality and Outcomes Measurement in Rheumatology PROJECT SUMMARY Healthcare has changed rapidly in the last decade with the widespread use of electronic health records (EHRs) and the creation of national EHR-based data networks that aim to improve the quality of care. The American College of Rheumatology's RISE registry is a federally Qualified Clinical Data Registry that collects EHR data from the practices of almost 1000 rheumatologists nationally, analyzes these data centrally, and continuously feeds back performance on quality measures to practices via a web-based dashboard. In this K24 proposal, the applicant proposes to utilize novel methods in clinical informatics to increase the accuracy of quality measurement, while also developing and testing new EHR-based quality measures relevant to rheumatic diseases. The proposed research will leverage her strong research portfolio, including grants from the National Institute of Arthritis and Musculoskeletal and Skin Diseases and the Agency for Healthcare Research and Quality, her successful track record of achieving national endorsement for EHR-based quality measures, existing data from over 1.4 million patients in the RISE database, and the outstanding institutional environment at the University of California, San Francisco. It will also support her ongoing career development in clinical informatics methods relevant to EHR-based clinical research. For this five year K24 award proposal, she plans to increase the time spent mentoring junior investigators in the field or quality and outcomes measurement in rheumatology, with the goal of helping trainees successfully launch academic research careers in patient- oriented research. Aligned with a comprehensive mentoring plan, the proposal outlines two specific aims, including using natural language processing to increase the accuracy of EHR-based quality measurement in RISE, and developing and validating new, prototype electronic clinical quality measures to monitor and address high impact gaps in care for patients with rheumatic disease. The work will prioritize outcome measures and use eMeasurement standards, including the Quality Data Model and Health Quality Measures Format to develop, specify and test measures. Measures developed through this research and mentoring program will be candidates for nationwide dissemination across rheumatology practices to improve care for individuals with rheumatic disease. PROJECT NARRATIVE This mid-career investigator award will support a program in patient-oriented research in rheumatic diseases at the University of California, San Francisco. The award will allow the applicant to expand her research on the development and validation of health care quality measures and support her mentoring of early investigators. The proposed research aims to create quality measures that can be deployed across rheumatology practices to improve the quality of care, while training new researchers to perform innovative patient-oriented research in the area of electronic health record-based quality and outcomes measurement.",Advancing Quality and Outcomes Measurement in Rheumatology,9873905,K24AR074534,"['Address', 'Algorithms', 'American', 'Area', 'Award', 'Back', 'Benchmarking', 'California', 'Cardiovascular Diseases', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Collection', 'Computer software', 'Consensus', 'Country', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Development', 'Dictionary', 'Disease', 'Electronic Health Record', 'Environment', 'Feeds', 'Foundations', 'Funding', 'Goals', 'Gout', 'Grant', 'Growth', 'Health', 'Healthcare', 'Healthcare Systems', 'High Prevalence', 'Individual', 'Informatics', 'Infrastructure', 'Institute of Medicine (U.S.)', 'Leadership', 'Learning', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Monitor', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Osteoporosis', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patients', 'Performance', 'Physicians', 'Preventive care', 'Process', 'Public Health', 'Quality of Care', 'Registries', 'Research', 'Research Personnel', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatology', 'Role', 'Safety', 'San Francisco', 'Scientist', 'Specific qualifier value', 'Testing', 'Text', 'Time', 'Training', 'United States', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Universities', 'Validation', 'Vision', 'Work', 'base', 'career', 'career development', 'college', 'comorbidity', 'dashboard', 'data mining', 'data modeling', 'data registry', 'data standards', 'data warehouse', 'design', 'digital', 'evidence base', 'health care quality', 'improved', 'informatics infrastructure', 'innovation', 'interest', 'learning progression', 'novel', 'patient oriented', 'patient oriented research', 'patient registry', 'patient safety', 'programs', 'prototype', 'research study', 'rheumatologist', 'structured data', 'success', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K24,2020,189666,0.025019071783615912
"Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics DESCRIPTION (provided by applicant): The goal of cancer pharmacoepidemiology is to identify adverse and/or long-term effects of chemotherapeutic agents and determine the impact of drugs on cancer risk, prevention, and response to treatments. Pharmacoepidemiology studies exert strong influence on defining optimal treatments and accelerating translational research. Therefore, it is imperative for these to be done efficiently and leveraging real-world patient data such as electronic health records (EHR). Massive clinical data from EHRs are being tapped into for research in disease-gene associations, comparative effectiveness and clinical outcomes. There is however paucity in pharmacoepidemiological studies using comprehensive EHR data due to the inherent challenges that exist for data abstraction, handling and analysis. The hurdles include heterogeneity of reports, embedding of detailed clinical information in narrative text, differing EHR platforms across different sites and missing data to name a few. In this study, we propose to integrate and extend preexisting tools to build an informatics infrastructure for EHR data extraction, interpretation, management and analysis to advance cancer pharmacoepidemiology research. We will leverage existing tools of natural language processing (NLP), standardized ontologies and clinical data management systems to extract and manipulate EHR data for cancer pharmacoepidemiological research. To achieve our goal we propose four specific aims. In aim 1, we intend to develop a high-performance, user- centric information extraction framework with advanced features such as active learning (to reduce annotation cost), domain adaptation (to transfer data across multiple sites) and user-friendly interfaces (for non-technical end users). In aim 2, we plan to improve data harmonization across differing platforms, develop components for seamless data export as well as expand methodologies to address impediments inherent to EHR-based data (such as the missing data problem). In aim 3, we will conduct demonstration projects of cancer pharmacoepidemiology including pharmacovigilance and pharmacogenomics of chemotherapeutic agents to evaluate, refine and validate the broad uses of our tools. Finally in aim 4, we propose to disseminate the methods and tools developed in this project to the cancer research and pharmacoepidemiology communities. PUBLIC HEALTH RELEVANCE: In this project, we propose to integrate and extend previously developed tools to build an informatics infrastructure for electronic health records (EHR) data extraction, interpretation, management, and analysis, to advance cancer pharmacoepidemiology research. Such methods can efficiently integrate and standardize cancer pharmacoepidemiology specific information from EHRs across different sites, thus advancing research in this field.",Advancing Cancer Pharmacoepidemiology Research Through EHRs and Informatics,9994228,U24CA194215,"['Active Learning', 'Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Algorithms', 'American Association of Cancer Research', 'American Society of Clinical Oncology', 'Benefits and Risks', 'CCL4 gene', 'Cancer Intervention', 'Cancer Patient', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Communities', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Management Resources', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Drug Exposure', 'Drug usage', 'Electronic Health Record', 'Ethics', 'Face', 'Funding', 'Genes', 'Genomics', 'Goals', 'Health Policy', 'Heterogeneity', 'Hybrids', 'Individual', 'Informatics', 'Information Retrieval', 'Letters', 'Long-Term Effects', 'Malignant Neoplasms', 'Medex', 'Methodology', 'Methods', 'Names', 'Natural Language Processing', 'Nature', 'Observational Study', 'Ontology', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacoepidemiology', 'Pharmacogenomics', 'Pharmacotherapy', 'Phenotype', 'Play', 'Population', 'Prevention', 'Preventive', 'Public Health Informatics', 'Randomized Controlled Trials', 'Recurrence', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Selection Bias', 'Site', 'Smoking Status', 'Standardization', 'System', 'Text', 'Therapeutic', 'Time', 'Toxic effect', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Vision', 'anticancer research', 'base', 'cancer risk', 'cancer type', 'chemotherapeutic agent', 'clinical implementation', 'clinical practice', 'cohort', 'comparative effectiveness', 'cost', 'data exchange', 'data harmonization', 'data management', 'follow-up', 'improved', 'informatics infrastructure', 'informatics tool', 'interest', 'learning algorithm', 'longitudinal dataset', 'novel', 'open source', 'optimal treatments', 'pharmacovigilance', 'public health relevance', 'rapid growth', 'success', 'tool', 'treatment response', 'user-friendly']",NCI,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,U24,2020,618291,0.04361768583817861
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (“Bio-REP”) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (“Bio- REP”) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,10208373,R33AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Infrastructure', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'data infrastructure', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R33,2020,792718,0.021507516792962877
"5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB) The overall aim of the NIAAA-funded Consortium to improve OutcoMes in hiv/Aids, Alcohol, Aging, & multi- Substance use (COMpAAAS) is to build and disseminate the evidence needed to optimize care for HIV+ experiencing medical harm from alcohol and related substance use, through coordinated, integrated, and externally validated observational, operations research modeling, and intervention studies. Combining and integrating the complimentary expertise of informatics, biostatistics and epidemiology, we propose a U24 Resource for Informatics and Biostatistics (RIB) to support and inform the other COMpAAAS components. This resource will address the complex challenges required to maximize power and minimize bias in analyses addressing consortium-wide questions. Advanced informatics methods supported include natural language processing (NLP), ontologies, database and clinical decision support, and application of vital data management tools for secure data collection, storage, annotation, retrieval, and integration. Advanced epidemiological and statistical methods include time-updated exposure techniques, multiple imputation, propensity score techniques, measurement error correction, and competing risks regression. Routine, but essential, statistical methods include Cox proportional hazards, logistic and linear regression, goodness of fit diagnostics, and agreement/accuracy metrics (kappa, sensitivity, specificity, etc.). The RIB will further leverage the observational and interventional studies, simulation models, and well-coordinated network of cores and workgroups of COMpAAAS with advanced informatics and biostatistical techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories. Our specific aims are to provide 1) statistical and 2) informatics expertise for COMpAAAS to maximize scientific impact. To accomplish this, we will enhance the design, recruitment, and follow-up of intervention studies, support appropriate design and execution of data analyses and cross cohort collaborations, provide advanced statistical methods plus estimates of alcohol patterns for OR modeling and identify sexual/gender minority populations (CHAMP) from VACS survey data. In addition we will enhance the Consortium Web-Based Laboratory (WBL Portal) informatics infrastructure to support ongoing research design, data collection and management, development and testing of interventions such as clinical decision support and eHealth tools and enhance support for the analysis of textual data. The Resource for Informatics and Biostatistics (RIB) will extend and enhance the research capacities and productivity among investigators at the NIAAA-funded Consortium to improve OutcoMes in hiv/AIDS, Alcohol, Aging, and multi-Substance use (COMpAAAS). This resource will provide Biostatistics and Informatics expertise that will allow investigators to develop techniques tailored to the particular challenges of large scale, longitudinal data from multiple sources including electronic health records (EHR), clinical interventions, patient self-report, and tissue repositories.",5/6 COMpAAAS U24: Resource in Informatics and Biostatistics (RIB),10003116,U24AA022001,"['Acquired Immunodeficiency Syndrome', 'Address', 'Aging', 'Agreement', 'Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'Biometry', 'Biostatistics Core', 'Caring', 'Clinical', 'Collaborations', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Databases', 'Delirium', 'Development', 'Diagnostic', 'Documentation', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'HIV', 'HIV/HCV', 'Informatics', 'Information Retrieval', 'Information Technology', 'Intervention', 'Intervention Studies', 'Laboratories', 'Linear Regressions', 'Logistic Regressions', 'Measurement', 'Measures', 'Medical', 'Methods', 'Minority', 'Mission', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Observational Study', 'Online Systems', 'Ontology', 'Operations Research', 'Patient Self-Report', 'Patients', 'Pattern', 'Persons', 'Pneumonia', 'Policy Maker', 'Polypharmacy', 'Population', 'Positioning Attribute', 'Productivity', 'Research', 'Research Design', 'Research Personnel', 'Resource Informatics', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Sensitivity and Specificity', 'Sexual and Gender Minorities', 'Statistical Methods', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissue Banks', 'Update', 'Validation', 'Work', 'alcohol research', 'clinical decision support', 'cohort', 'data management', 'design', 'eHealth', 'experience', 'falls', 'follow-up', 'hazard', 'improved', 'improved outcome', 'informatics infrastructure', 'models and simulation', 'multiple data sources', 'recruit', 'therapy design', 'tool', 'treatment optimization']",NIAAA,YALE UNIVERSITY,U24,2020,279784,-0.022073069000700787
"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",Community Surveillance of Coronary Heart Disease,9838247,R01HL135219,"['Acute', 'Acute myocardial infarction', 'Address', 'Adoption', 'American', 'Area', 'Big Data', 'Caring', 'Case Fatality Rates', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Informatics', 'Clinical Treatment', 'Clinical Trials', 'Code', 'Collection', 'Communities', 'Computerized Medical Record', 'Coronary', 'Coronary heart disease', 'Data', 'Development', 'Diagnostic', 'Disease Surveillance', 'Epidemiologist', 'Fostering', 'Future', 'Guidelines', 'Harvest', 'Health Care Costs', 'Health Policy', 'Health Services', 'Hospital Administration', 'Hospitals', 'ICD-9', 'Impairment', 'Incidence', 'Information Technology', 'Inpatients', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Investigation', 'Life Expectancy', 'Manuals', 'Medical', 'Medical center', 'Medicine', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Myocardial Infarction', 'Myocardial Reperfusion', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'New England', 'Outcome', 'Participant', 'Patients', 'Periodicity', 'Physicians', 'Policy Maker', 'Population', 'Population Study', 'Practice Management', 'Prevention', 'Public Health', 'Quality of life', 'Recurrence', 'Research', 'Research Personnel', 'Research Support', 'Rural', 'Secondary Prevention', 'Source', 'Symptoms', 'System', 'Technology', 'Time', 'Update', 'Work', 'base', 'clinical epidemiology', 'clinically relevant', 'cost effective', 'electronic data', 'experience', 'functional disability', 'health disparity', 'high risk population', 'hospital readmission', 'innovation', 'insight', 'metropolitan', 'mortality', 'older patient', 'optimal treatments', 'outcome forecast', 'patient health information', 'population based', 'prevent', 'sociodemographics', 'socioeconomics', 'surveillance data', 'treatment guidelines', 'trend']",NHLBI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,R01,2020,768763,0.04888605349630882
"Addressing Bias from Missing Data in EHR Based Studies of CVD Project Summary This NHLBI K01 application supports the career development of Dr. Nrupen A. Bhavsar, PhD, an Assistant Professor of Medicine at the Duke University School of Medicine. Dr. Bhavsar is a chronic disease epidemiologist who has performed multidisciplinary studies in the epidemiology of CVD, chronic kidney disease and cancer. He is passionate about pursuing a career in clinical research at the intersection of epidemiology, informatics, and biostatistics. At the end of the award period, Dr. Bhavsar will be an independent investigator applying knowledge gained through this K01 to develop large scale EHR-based population studies that identify individuals at high risk for cardiovascular disease (CVD) events. Through training in data linkage, machine learning, and causal inference, he will apply missing data methods to conduct rigorous non-randomized studies to improve health. The topical areas of the proposed training and research are diabetes and incident CVD events in the application of data linkage, machine learning, and causal inference. Career development aim: Obtain transdisciplinary competencies within informatics, biostatistics, and population sciences to investigate methodological challenges inherent in the use of multi-health system EHR data for clinical research. The training approach will leverage didactic and experiential training complemented by analyses of data derived from a multi-health system, multi-state research collaborative. Study population: Patients who received care at one of the North Carolina or South Carolina “Carolinas Collaborative” institutions (Duke University Medical Center, UNC-CH Health System, Wake Forest Baptist Health Center, and 9 additional health systems collaborating within the Health Sciences of South Carolina institutions). Specific aims: This proposal will identify approaches to account for missing data when patients seek care across multiple health systems but EHR data is only available from a single health system. Estimating the systemic bias introduced by missing data for single institution studies and identifying methods for accounting for missing data biases may improve the ability of EHR data to be used for clinical research. Anticipated results: Through this NHLBI K01 Research Scientist Career Development Award, Dr. Bhavsar will acquire essential training and research experience to develop large scale EHR-based population studies in CVD. PROJECT NARRATIVE Data from the electronic health records (EHR) are increasingly being used for clinical research, yet there is limited information on the best approaches to address the methodological limitations of the EHR, such as missing data. In patients with diabetes at risk of cardiovascular disease events, I will examine the impact that missing data has on the ability to use the EHR for clinical research and develop approaches to address the biases resulting from missing data.",Addressing Bias from Missing Data in EHR Based Studies of CVD,9994001,K01HL140146,"['Academic Medical Centers', 'Accounting', 'Address', 'Area', 'Award', 'Baptist Church', 'Biometry', 'Cardiovascular Diseases', 'Caring', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Research', 'Cohort Studies', 'Competence', 'Complement', 'Data', 'Data Analyses', 'Data Element', 'Data Linkages', 'Data Pooling', 'Data Science', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Doctor of Philosophy', 'Electronic Health Record', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Event', 'Goals', 'Health', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitalization', 'Individual', 'Informatics', 'Institution', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Legal', 'Machine Learning', 'Medicine', 'Meta-Analysis', 'Methodology', 'Methods', 'Myocardial Infarction', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Outcome', 'Outcomes Research', 'Patient Care', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Population Sciences', 'Population Study', 'Privacy', 'Publishing', 'Renal carcinoma', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Research Priority', 'Risk', 'Risk Factors', 'Scientist', 'South Carolina', 'Stroke', 'Training', 'Universities', 'Work', 'base', 'cardiovascular disorder epidemiology', 'cardiovascular disorder risk', 'cardiovascular health', 'care seeking', 'career', 'career development', 'clinical care', 'cohort', 'comorbidity', 'data quality', 'distributed data', 'electronic data', 'epidemiologic data', 'epidemiology study', 'experience', 'forest', 'high risk', 'improved', 'medical schools', 'multidisciplinary', 'novel', 'patient population', 'population health', 'practical application', 'professor', 'randomized trial', 'skills', 'study population']",NHLBI,DUKE UNIVERSITY,K01,2020,165444,0.005662396119683093
"National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms PROJECT SUMMARY With the rapidly growing adoption of patient electronic health record systems (EHRs) due to Meaningful Use, and linkage of EHRs to research biorepositories, evaluating the suitability of EHR data for clinical and translational research is becoming ever more important, with ramifications for genomic and observational research, clinical trials, and comparative effectiveness studies. A key component for identifying patient cohorts in the EHR is to define inclusion and exclusion criteria that algorithmically select sets of patients based on stored clinical data. This process is commonly referred to, as “EHR-driven phenotyping” is time-consuming and tedious due to the lack of a widely accepted and standards-based formal information model for defining phenotyping algorithms. To address this overall challenge, the proposed project will design, build and promote an open-access community infrastructure for standards-based development and sharing of phenotyping algorithms, as well as provide tools and resources for investigators, researchers and their informatics support staff to implement and execute the algorithms on native EHR data. PROJECT NARRATIVE The identification of patient cohorts for clinical and genomic research is a costly and time-consuming process. This bottleneck adversely affects public health by delaying research findings, and in some cases by making research costs prohibitively high. To address this issue, leveraging electronic health records (EHRs) for identifying patient cohorts has become an increasingly attractive option. This proposal will investigate and implement standards based approaches for computable phenotype identification from multiple EHRs.",National Infrastructure for Standardized and Portable EHR Phenotyping Algorithms,10021669,R01GM105688,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Architecture', 'Benchmarking', 'Benign Prostatic Hypertrophy', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computerized Medical Record', 'Computing Methodologies', 'Consensus', 'Consumption', 'Data', 'Data Element', 'Data Reporting', 'Development', 'Educational workshop', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Engineering', 'Event', 'Exclusion Criteria', 'Fast Healthcare Interoperability Resources', 'Flowcharts', 'Genomics', 'Gold', 'Grant', 'Health', 'Health system', 'Healthcare Systems', 'Human', 'Informatics', 'Infrastructure', 'Intuition', 'Knowledge', 'Logic', 'Measures', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Needs Assessment', 'Observational Study', 'Outcome', 'Patients', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Process', 'Public Health', 'Public Health Informatics', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk Factors', 'Running', 'Scientist', 'Services', 'Standardization', 'Structure', 'System', 'Techniques', 'Text', 'Time', 'Translational Research', 'United States National Institutes of Health', 'University Hospitals', 'authority', 'base', 'biobank', 'clinical phenotype', 'cohort', 'comparative effectiveness study', 'computable phenotypes', 'cost', 'data modeling', 'data warehouse', 'database query', 'deep learning', 'design', 'endophenotype', 'experience', 'inclusion criteria', 'informatics training', 'information model', 'knowledge base', 'meetings', 'phenotyping algorithm', 'portability', 'precision medicine', 'repository', 'structured data', 'syntax', 'tool', 'usability']",NIGMS,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2020,706851,0.08662084124151313
"PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model Project Summary/Abstract Each year over 75,000 children develop sepsis in the United States resulting in substantial morbidity, up to 20% mortality, and billions in US health care expenditures. There have been substantial advances that demonstrate improved patient outcomes with adherence to early aggressive emergency care. However, methods to accurately, reliably, and rapidly identify children who require these resource-intensive therapies are lacking. In addition, understanding the impact of these therapies on near-term outcomes, before significant morbidity occurs, is also lacking. Current algorithms do not reliably discriminate between patients who develop sepsis and those who are clinically similar upon initial presentation but do not progress to sepsis. As a result, children requiring life-saving treatments do not receive them, or do not receive them in a timely fashion, and others may be over-treated, wasting healthcare resources and potentially diverting emergency care from those in need. With the advent of electronic health records (EHR), there are now information-enabled solutions that offer unique opportunities to identify non-biased, heterogeneous samples of children and allow us to accurately and reliably measure risk factors and near-term outcomes for sepsis. This work addresses the critical need to improve pediatric sepsis outcomes by developing methods to accurately identify at-risk children presenting for emergency care. Utilizing the infrastructure of the Pediatric Emergency Care Applied Research Network (PECARN), this proposal will innovatively capture EHR data to create a multi-center registry with the ultimate goal to improve the detection and treatment of pediatric sepsis in the ED setting. To accomplish this, we propose the following specific aims: We will develop an expanded multicenter sepsis registry for pediatric patients from merged electronic health record clinical data from different hospitals with different EHR data sources. We will automate the determination of organ dysfunction in children with sepsis directly from structured and narrative data within the multicenter EHR registry. From the registry and outcome data, we will derive and validate a prediction model of pediatric sepsis using emergency department EHR data from the first 4 hours of care that predicts subsequent organ dysfunction within 48 hours. Each of these aims works to the goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, an automated process of outcome determination, and a prediction model of risk of sepsis. We will also have a strong foundation for future projects to implement and evaluate decision support tools, improve diagnostic techniques, engage in comparative effectiveness studies, measure quality of care, establish linked bio-repositories, and guide clinical trial design. The proposed project, thus, has enormous potential to improve our ability to improve the quality of care provided to our most acutely ill children.  Project Narrative Sepsis is a leading cause of pediatric morbidity and mortality with life-saving treatment dependent on early and accurate identification. We will establish a multi-center data registry from electronic health records (EHR), identify a multi-center cohort of pediatric patients at risk for sepsis, automate sepsis-related pediatric organ dysfunction directly from the registry EHR data, and develop an emergency department based prediction model of sepsis related organ dysfunction. Each of these aims has the ultimate goal of improving the emergent care for pediatric sepsis with innovative deliverables from this project including the existence of a broad and rich EHR registry, the automated process of important proximal outcome determination, and an emergency department prediction model of risk of sepsis. ","PED Screen: Pediatric Sepsis EHR Registry, Clinical Outcomes, and Predictive Model",9864083,R01HD087363,"['Accident and Emergency department', 'Achievement', 'Acute', 'Address', 'Adherence', 'Algorithms', 'Applied Research', 'Blood Pressure', 'Caring', 'Child', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Trials Design', 'Complex', 'Data', 'Data Sources', 'Derivation procedure', 'Detection', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Early Intervention', 'Electronic Health Record', 'Emergency Care', 'Emergent care', 'Foundations', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Health Expenditures', 'Healthcare', 'Hospitals', 'Hour', 'Infrastructure', 'Inpatients', 'Intervention', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Natural Language Processing', 'Organ', 'Organ failure', 'Outcome', 'Outcome Measure', 'Patient-Focused Outcomes', 'Patients', 'Pediatric cohort', 'Positioning Attribute', 'Process', 'Quality of Care', 'Registries', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sampling', 'Savings', 'Sepsis', 'Shock', 'Site', 'Structure', 'Time', 'United States', 'United States Agency for Healthcare Research and Quality', 'Visit', 'Work', 'base', 'cohort', 'comparative effectiveness study', 'data registry', 'design', 'effective intervention', 'electronic registry', 'high risk', 'improved', 'innovation', 'member', 'mortality', 'novel', 'patient health information', 'patient registry', 'pediatric emergency', 'pediatric patients', 'predictive modeling', 'repository', 'risk prediction model', 'septic patients', 'support tools', 'wasting']",NICHD,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,611937,0.030738328843347002
"Electronic Health Record-based Surveillance of Diabetes by Type in Young Adults in Pennsylvania 1 Currently there are 4.6 million young adults (18 to 44 years of age) with diabetes in the US and the incidence  2 and prevalence are increasing in this age group. However, due to limitations of traditional surveillance  3 strategies, it remains unknown whether these increases are in type 1 or type 2 diabetes. Electronic health  4 record (EHR)-based surveillance is a relatively simple, sustainable, and timely alternative to more traditional  5 methods. Recognizing the attributes of EHR-based surveillance, the Centers for Disease Control and  6 Prevention (CDC) has funded efforts to develop, evaluate, and deploy EHR-based surveillance of diabetes,  7 including the SEARCH for Diabetes in Youth (SEARCH) study and the Diabetes in Young Adults (DiYA) Study.  8 However, the geographic coverage of these studies has been limited. The geographical gaps in these studies  9 are problematic, as there are known geographic disparities in diabetes prevalence and incidence. Moreover, 10 little is known about how the methods applied in these studies will perform in other regions of the country, in 11 rural communities, and in other health systems. The proposed study will use more than two decades of EHR 12 data and administrative claims data to develop and implement EHR-based surveillance of type 1 and type 2 13 diabetes among young adults in a large region of Pennsylvania, the state with the 5th highest prevalence of 14 diabetes in this age group. This information is essential to informing public health strategies, assessing disease 15 burden, and prioritizing type-specific health services. We will use EHR data from Geisinger, a health system 16 serving a large and diverse region of Pennsylvania, to expand the geography of existing surveillance of 17 diabetes subtypes in young adults to the Middle Atlantic, an area without prior EHR-based diabetes 18 surveillance estimates. This region includes a combination of rural and urban communities, enabling us to 19 evaluate differences in the performance of EHR-based algorithms for case ascertainment by community type. 20 In the first phase of the study, we will evaluate the validity; simplicity; and consistency of EHR-based 21 algorithms for identifying diabetes subtypes. This work will build on previously developed algorithms from the 22 SEARCH and DiYA studies. We will use manual review of clinician notes as the gold standard to determine the 23 positive predictive value, sensitivity, and specificity of these algorithms. We propose to use an innovative, 24 efficient, and rigorous validation approach that incorporates natural language processing of clinician notes. We 25 will use a secondary data source, administrative claims data, to assess data completeness and our ability to 26 distinguish between incident and prevalent cases. In the second phase, we will use the best performing 27 algorithms to report on the annual incidence and prevalence of diabetes, by type, in young adults, between 28 2014 and 2024 in 38 Pennsylvania counties. All analyses will be stratified by age, sex, race/ethnicity, insurance 29 status, and community type (rural/urban). Finally, we will coordinate with CDC and other sites to conduct joint 30 analyses of aggregated data, greatly expanding the population under study. Narrative Currently there are 4.6 million young adults (18 to 44 years of age) with diabetes in the US and the incidence and prevalence estimates in this age group have been increasing. However, due to limitations of traditional surveillance strategies, it remains unknown whether these increases are in type 1 or type 2 diabetes. The proposed research will coordinate, develop, implement, and validate electronic-record based surveillance of diabetes in young adults, by subtype, to inform type-specific public health responses, assess disease burden, and identify priorities for type-specific health services.",Electronic Health Record-based Surveillance of Diabetes by Type in Young Adults in Pennsylvania,10085078,U18DP006509,[' '],NCCDPHP,GEISINGER CLINIC,U18,2020,249631,0.023753876672443382
"Clinical and Translational Science Award PROJECT SUMMARY: COMBATCOVID The coronavirus (COVID-19) pandemic has affected every corner of the globe and has redefined healthcare throughout the United States. COVID-19 cases in the New York City tri-state area have reached an extraordinarily high number and have quickly become the epicenter region of the crisis in the United States. In New York State alone, there are over 372,000 confirmed cases as of June 1, 2020. NYU Langone Health (NYULH) has been particularly hard hit, with more than 8,100 COVID-19 hospitalizations to date. In response, the entire clinical research community is marshalling resources in an attempt to improve our understanding of how the virus spreads, how it infects various tissues in the body, which patients are more susceptible to infection and fatal outcomes, which therapeutics improve symptoms and survival, whether the immune response confers long-lasting protection against reinfection, and many other crucially important questions. The complexity of the development of this disease and unpredictability of progression into severity, as well as the variety of phenotypic outcomes observed during and post COVID-19, pose major challenges in understanding, predicting, preventing, managing and treating this disease and its sequelae. Answers to these challenges can only be achieved through the comprehensive analysis of a significantly high number of COVID cases. Given how recent and unknown this disease is, and its inherent epidemic nature, there is a limited number of cases at individual medical institutions. The limitation of number of cases per institution becomes even more relevant when isolating subpopulations with specific health conditions and across the lifespan. This proposed study will aim to overcome the above-mentioned challenges by supporting the formation of a consortium comprising multiple medical institutions in the U.S.: COMBATCOVID (Consortium for Multisite Biomedical Analytics and Trials on COVID-19). COMBATCOVID will bring together electronic health records (EHR) data from multiple participating institutions into a shared centralized database. As part of the COMBATCOVID effort, biorepository data of COVID-19 patients collected by some of the participating institutions will also be shared and linked to the respective EHR data. The COMBATCOVID consortium will be responsible for transferring EHR data pertaining to participating institutions interested in contributing EHR data to the N3C database. PROJECT NARRATIVE: COMBATCOVID The coronavirus (COVID-19) pandemic has affected every corner of the globe and has redefined healthcare throughout the United States. To adequately understand the virus much more data is needed, necessitating sharing of data across multiple institutions. The COMBATCOVID (Consortium for Multisite Biomedical Analytics and Trials on COVID-19) initiative will support regional and national efforts by forming a consortium comprising multiple medical institutions in the U.S. to create a shared centralized database of COVID-related EHR data.",Clinical and Translational Science Award,10183901,UL1TR001445,"['2019-nCoV', 'Affect', 'Area', 'COVID-19', 'COVID-19 pandemic', 'Categories', 'Cessation of life', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical and Translational Science Awards', 'Code', 'Communities', 'Coronavirus', 'Critical Care', 'Critical Illness', 'Data', 'Data Science', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Epidemic', 'Event', 'Fatal Outcome', 'Health', 'Health system', 'Healthcare', 'Hospitalization', 'Immune response', 'Individual', 'Infection', 'Inflammatory', 'Informatics', 'Institution', 'Ischemic Stroke', 'Knowledge', 'Laboratories', 'Link', 'Longevity', 'Marshal', 'Medical', 'Natural Language Processing', 'Nature', 'New York', 'New York City', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Phenotype', 'Pneumonia', 'Procedures', 'Records', 'Research Personnel', 'Resources', 'Respiratory Failure', 'Risk', 'Severities', 'Site', 'Subgroup', 'Syndrome', 'Testing', 'Text', 'Therapeutic', 'Thrombosis', 'Time', 'Tissues', 'Underrepresented Groups', 'United States', 'Upper respiratory tract', 'Venous', 'Viral Pneumonia', 'Virus', 'biobank', 'central database', 'cohort', 'coronavirus disease', 'data sharing', 'demographics', 'design', 'ethnic minority population', 'health data', 'improved', 'interest', 'medical specialties', 'meetings', 'member', 'pandemic disease', 'prevent', 'racial minority', 'response', 'structured data', 'symptomatic improvement', 'unstructured data', 'venous thromboembolism']",NCATS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,UL1,2020,768511,0.04725964417220457
"Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics PROJECT SUMMARY The widespread adoption of EHRs has enabled the collection of massive amounts of digital ophthalmic data which have great potential for secondary use in research, quality improvement, and clinical decision support. While the amount of digital ophthalmic data recorded in the EHR is substantial and could be analyzed using the latest techniques for big data, questions about the quality of the data are a barrier to its reuse. Now that the American Academy of Ophthalmology has aggregated digital ophthalmic data from the EHR into the IRIS Registry, data quality is even more imperative for reaching the potential of the registry. To date, there has not be a comprehensive evaluation of the data quality of digital ophthalmic data, nor have there been any solutions for improving its quality. These are important gaps that will limit the utility of EHR data as a tool for knowledge discovery in ophthalmology. The goal of this grant is to assess the quality of digital ophthalmic exam data in order to improve its ability to be reused for research. Our hypothesis is that studying the variability of data quality in large datasets will provide insights into improving its quality. The first aim employs an established framework for data quality analysis to assess the intrinsic quality of a single institution’s EHR data as well as its fitness for use--the ability to be applied to a particular research scenario. In this proposal, we are evaluating the data’s ability to identify patient cohorts for clinical trials and to accurately calculate outcome based clinical quality measures. The variability in data’s quality and fitness among providers, subspecialties, diagnoses, and visit types will be analyzed. The second aim validates the analysis of the first aim by repeating it for all of the ophthalmic data in the IRIS Registry. For this analysis, the differences in quality and fitness between institutions and EHR vendors will also be assessed, along with the barriers to data quality and reuse. For both aims, ophthalmology experts will review the results to make recommendations for improving data quality and utility for digital ophthalmic data. In the future, these recommendations will provide a direction for correcting these quality issues and for ultimately advancing knowledge discovery in ophthalmic care. PROJECT NARRATIVE Electronic health records (EHRs) have not yet reached their potential for transforming healthcare, particularly for reusing clinical data for research. The American Academy of Ophthalmology has aggregated ophthalmic data from the EHR into the IRIS Registry, and data quality is even more imperative to achieve to reach the potential of this registry. Using methodological data quality analysis, we will analyze the quality of a single institution’s ophthalmic data and again for multiple institutions’ ophthalmic data in the IRIS Registry, documenting barriers for data quality and reuse that will lead to improving knowledge discovery from this data.",Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics,9953684,R21EY031443,"['Academy', 'Adoption', 'Age related macular degeneration', 'American', 'Big Data', 'Big Data Methods', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Collection', 'Complex', 'Data', 'Data Discovery', 'Diabetic Retinopathy', 'Diagnosis', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Exfoliation Syndrome', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Hand', 'Health Sciences', 'Healthcare', 'Human', 'Image', 'Individual', 'Informatics', 'Institutes', 'Institution', 'Intelligence', 'Iris', 'Knowledge Discovery', 'Manuals', 'Measurement', 'Measures', 'Medical Informatics', 'Medicine', 'Methodology', 'Methods', 'Ophthalmology', 'Oregon', 'Outcome', 'Patients', 'Process', 'Provider', 'Recommendation', 'Registries', 'Research', 'Research Personnel', 'Retinopathy of Prematurity', 'Secondary to', 'Source', 'Structure', 'System', 'Techniques', 'Terminology', 'Treatment outcome', 'Universities', 'Vendor', 'Vision', 'Visit', 'base', 'clinical decision support', 'clinical encounter', 'cohort', 'data framework', 'data harmonization', 'data quality', 'data registry', 'data reuse', 'data submission', 'deep learning', 'digital', 'electronic data', 'experience', 'fitness', 'improved', 'insight', 'large datasets', 'large scale data', 'research study', 'tool', 'treatment comparison']",NEI,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2020,231000,0.028343621808806594
"Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data PROJECT SUMMARY Large electronic health record research (EHR) data integrated with -omics data from linked biorepositories have expanded opportunities for precision medicine research. These integrated datasets open opportunities for developing accurate EHR-based personalized cancer risk and progression prediction models, which can be easily incorporated into clinical practice and ultimately realize the promise of precision oncology. However, efficiently and effectively using EHR for cancer research remains challenging due to practical and methodological obstacles. For example, obtaining precise event time information such as time of cancer recurrence is a major bottleneck in using EHR for precision medicine research due to the requirement of laborious medical record review and the lack of documentation. Simple estimates of the event time based on billing or procedure codes may poorly approximate the true event time. Naive use of such estimated event times can lead to highly biased estimates due to the approximation error. Such biases impose challenges to performing pragmatic trials when the study endpoint is time to events and captured using EHR. The overall goal of this proposal is to fill these methodological gaps in risk assessment for cancer research using EHR data, which will advance our ability to achieve the promise of precision oncology. Statistical algorithms and software will be developed to (i) automatically assign event time information using longitudinally recorded EHR information; and (ii) to perform accurate risk assessment using noisy proxies of event times. The proposed tools for risk assessment using imperfect EHR data without requiring extensive manual chart review could greatly improve the utility of EHR for oncology research. PROJECT NARRATIVE This proposal addresses major methodological gaps in effectively utilizing EHR data for risk assessment due to the noisy nature of EHR data. We propose novel statistical algorithms and software to (i) efficiently annotate event time by combining multiple longitudinally recorded code information and (ii) to provide precise risk estimates using noisy proxies of event times. By drawing upon the rich albeit imperfect data from bio-repository linked EHR, our algorithms will advance our ability to use EHR data for precision oncology research.",Semi-supervised Algorithms for Risk Assessment with Noisy EHR Data,9955220,R21CA242940,"['Address', 'Adoption', 'Algorithmic Software', 'Algorithms', 'Biological', 'Boston', 'Cancer Patient', 'Clinical', 'Clinical Trials', 'Code', 'Cohort Studies', 'Data', 'Data Set', 'Diagnosis', 'Documentation', 'Electronic Health Record', 'Event', 'Genomics', 'Goals', 'Gold', 'Healthcare', 'Infrastructure', 'Label', 'Laboratories', 'Lead', 'Link', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Measurement', 'Medical Records', 'Methodology', 'Methods', 'Nature', 'Oncology', 'Patients', 'Phenotype', 'Procedures', 'Progression-Free Survivals', 'Proxy', 'Registries', 'Research', 'Risk', 'Risk Assessment', 'Risk Estimate', 'Software Tools', 'Source', 'Statistical Algorithm', 'Supervision', 'Testing', 'Time', 'adjudicate', 'anticancer research', 'base', 'biobank', 'cancer recurrence', 'cancer risk', 'clinical practice', 'cohort', 'electronic data', 'evidence base', 'genomic data', 'improved', 'large datasets', 'learning algorithm', 'multimodality', 'novel', 'patient population', 'patient subsets', 'pragmatic trial', 'precision medicine', 'precision oncology', 'predictive modeling', 'repository', 'supervised learning', 'tool', 'tumor progression', 'user friendly software', 'web site']",NCI,HARVARD SCHOOL OF PUBLIC HEALTH,R21,2020,177510,0.08580396517588129
"EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia PROJECT SUMMARY/ABSTRACT Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by elevated plasma low-density lipoprotein cholesterol (LDL-C) and a dramatically increased lifetime risk for premature atherosclerotic cardiovascular disease (ASCVD). Available data suggest substantial under treatment of individuals with FH, and it is estimated that <5% of prevalent FH cases in the US are diagnosed and treated. The proposed research will develop electronic health record (EHR)-based strategies to reduce mortality and morbidity from FH. We will develop and validate a phenotyping algorithm for rapid and efficient identification of FH cases thereby enabling EHR-based surveillance of FH. We will deploy the phenotyping algorithm in the population-based setting of Olmsted County, Minnesota, to estimate prevalence and provide hitherto unavailable data on awareness, detection and control of FH. We will develop CDS to help care providers manage FH patients and an FH-specific decision aid to facilitate shared decision making related to lipid-lowering therapy and screening of family members. To accomplish these goals, we will leverage the following resources: a) the electronic phenotyping expertise available in the electronic Medical Records and Genomics (eMERGE) network; b) the Rochester Epidemiology Project (REP), that links medical records of Olmsted County MN residents thereby capturing nearly all health care delivered to residents of the community; and c) expertise in developing and deploying CDS in the EHR and in creating decision aids for disclosing cardiovascular risk and the benefits of lipid-lowering drugs. Our specific aims are: Aim 1. Develop and validate an electronic phenotyping algorithm to rapidly identify FH cases from the EHR. Aim 2. Conduct an e- epidemiology study to obtain hitherto unknown data regarding prevalence, awareness, detection, control of FH in a population-based setting in the US. Aim 3. a) Develop EHR-based tools to help care providers manage FH and facilitate shared decision making and cascade screening and b) assess outcomes after implementation of CDS and decision aid. The proposed research will enable rapid identification of FH in EHRs, provide hitherto unavailable data on the burden of FH in the community, facilitate EHR-based strategies for early detection, increase awareness of FH among care providers, provide guidance for management of FH at point of care and help both patients and providers make informed decisions about drug therapy and screening of family members. These are critical steps for early detection and treatment of FH to reduce the burden of premature ASCVD due to this condition. PROJECT NARRATIVE Familial hypercholesterolemia (FH) is a relatively common genetic disorder characterized by high cholesterol levels and increased risk of heart attack or sudden cardiac death. The proposed research will develop electronic health record (EHR)-based strategies to prevent adverse outcomes such as heart attack in FH patients. These include methods to rapidly identify FH patients, estimate prevalence of FH and develop clinical decision support to help care providers manage FH patients. The proposed work will have a significant impact on clinical management of FH patients.",EHR-Based Strategies to Improve Outcomes in Familial Hypercholesterolemia,9938607,R01HL135879,"['Academy', 'Address', 'Algorithms', 'Atherosclerosis', 'Awareness', 'Benefits and Risks', 'Cholesterol', 'Clinic', 'Clinical', 'Clinical Management', 'Communities', 'County', 'Data', 'Data Set', 'Decision Aid', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Early treatment', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Epidemiology', 'Europe', 'Familial Hypercholesterolemia', 'Family', 'Family history of', 'Family member', 'Genetic Diseases', 'Genomics', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hereditary Disease', 'Individual', 'Infrastructure', 'Institutes', 'LDL Cholesterol Lipoproteins', 'Label', 'Laboratories', 'Learning', 'Link', 'Lipids', 'Lipoprotein (a)', 'Low-Density Lipoproteins', 'Manuals', 'Medical Records', 'Medicine', 'Methods', 'Minnesota', 'Morbidity - disease rate', 'Myocardial Infarction', 'Natural Language Processing', 'Outcome', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Plasma', 'Population Study', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Primary Prevention', 'Provider', 'Public Health', 'Recommendation', 'Recording of previous events', 'Records', 'Reporting', 'Research', 'Resources', 'Risk', 'Structure', 'Test Result', 'Time', 'Work', 'World Health Organization', 'Xanthomas', 'adverse outcome', 'base', 'cardiovascular risk factor', 'care providers', 'case-based', 'clinical decision support', 'clinical implementation', 'epidemiology study', 'evaluation/testing', 'family burden', 'genetic testing', 'implementation science', 'improved', 'improved outcome', 'inhibitor/antagonist', 'innovation', 'lifetime risk', 'mortality', 'novel therapeutics', 'phenotyping algorithm', 'point of care', 'population based', 'precision medicine', 'premature', 'prevent', 'screening', 'screening program', 'shared decision making', 'sudden cardiac death', 'tool']",NHLBI,MAYO CLINIC ROCHESTER,R01,2020,638566,0.049222846950836736
