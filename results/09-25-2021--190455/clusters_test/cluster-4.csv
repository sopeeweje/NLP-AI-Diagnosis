text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"A holistic approach to identifying functional units of tongue motion during speech PROJECT SUMMARY  Oral cancers have the seventh highest incidence, with roughly 51,540 new cases and 10,030 cancer- related deaths expected to occur in 2018. Although a variety of treatment methods are available, the death rate is higher than that for most cancers with five-year rates of about 50 percent. The most frequently used treatment method, glossectomy surgery, involves the surgical removal of tumors and surrounding tissues, and the addition of grafted tissues, often followed by radiotherapy. Although tongue cancer and its treatment have debilitating effects on speech, the impact of varying degrees of resection and reconstruction on the formation of functional units in speech has remained poorly understood. In order to produce intelligible speech, a variety of local muscle groupings of the tongue—i.e., functional units—emerge and recede rapidly and nimbly in a highly coordinated fashion. Therefore, understanding the formation of functional units that are critical for speech production can provide substantial insights into normal, pathological, and adapted motor control strategies in controls and patients with tongue cancer for novel therapeutic, surgical, and rehabilitative strategies. One of the critical challenges in pre-operative surgical and treatment planning, as well as in post- operative evaluation for tongue cancer is the difficulty in developing objective and quantitative measures and in evaluating their functional outcome predictability. To address this, in this proposal, three integrated approaches will be used in in vivo tongue motion during speech to seamlessly identify the functional units and associated quantitative measures: multimodal MRI methods, multimodal deep learning, and biomechanical simulations. This will provide a convergent approach, thereby allowing us to (1) test hypotheses about the spatiotemporal basis of muscle coordination in a consilient way, and (2) develop objective quantitative measures that are required for understanding the complex biomechanical system as well as for predicting the functional outcomes after various reconstruction methods. The first proof of concept study published by the PI and the team identified the functional units of speech tasks using the sparse non-negative matrix factorization framework, in which the magnitude and angle of displacements from tagged MRI were used as our input quantities. With these advances in place, we will further incorporate muscle fiber anatomy from diffusion MRI and motion tracking from tagged MRI into our framework to yield physiologically and anatomically meaningful functional units. In addition, we will create a completely novel and integrated way of directly relating the functional units to tongue muscle anatomy, learning joint representation via a multimodal deep learning technique, and linking them to biomechanical simulations. Furthermore, 3D and 4D atlases will be utilized to identify objective and quantitative measures based on our functional units analysis. Taken together, the successful implementation of our integrated framework will identify functional units that can be used for research on tongue motion, for surgical planning, and for diagnosis, prognosis, and rehabilitation in a range of speech-related disorders. PROJECT NARRATIVE  Tongue cancer and its treatment affect tongue structure and function, yet little is known about how the changes in tongue structure due to varying degrees of resection and reconstruction affect the formation of functional units of tongue motion during speech. We propose to use novel integrated platform tools to identify functional units seamlessly with unprecedented resolution and precision. Upon success of this proposal, our integrated framework has the potential to aid in an increased understanding of speech motor control strategies in healthy controls and the patient group, thereby benefiting patients through improved diagnosis, treatment, and rehabilitative strategies.",A holistic approach to identifying functional units of tongue motion during speech,10147030,R01DC018511,"['3-Dimensional', 'Acoustics', 'Address', 'Affect', 'Aftercare', 'Anatomy', 'Atlases', 'Behavior', 'Biomechanics', 'Cessation of life', 'Clinical', 'Complex', 'Computing Methodologies', 'Data', 'Death Rate', 'Deglutition', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Evaluation', 'Excision', 'Exhibits', 'Fiber', 'Geometry', 'Glossectomy', 'Goals', 'Grouping', 'Impairment', 'Incidence', 'Joints', 'Knowledge', 'Learning', 'Link', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Motion', 'Muscle', 'Muscle Fibers', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patients', 'Physiological', 'Postoperative Period', 'Predictive Value', 'Procedures', 'Production', 'Proxy', 'Publishing', 'Radiation therapy', 'Rehabilitation therapy', 'Research', 'Resolution', 'Speech', 'Speech Intelligibility', 'Standardization', 'Structure', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Tissue Grafts', 'Tissues', 'Tongue', 'Weight', 'Work', 'base', 'biomechanical model', 'clinical practice', 'deep learning', 'functional outcomes', 'holistic approach', 'improved', 'in vivo', 'insight', 'malignant mouth neoplasm', 'malignant tongue neoplasm', 'motor control', 'multimodality', 'muscular structure', 'novel', 'novel therapeutics', 'outcome forecast', 'outcome prediction', 'reconstruction', 'rehabilitation strategy', 'signal processing', 'spatiotemporal', 'success', 'tool', 'treatment planning', 'treatment strategy', 'tumor']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,565453
"Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech Project Summary/Abstract  This proposal aims to employ the recent advancement of coupling fiberoptic endoscopes with high-speed videoendoscopy (HSV) systems to obtain HSV recordings during connected speech. The goal is to study vocal mechanisms underlying dysphonia in patients with neurogenic voice disorders. The long-term goal of this line of research is to create clinically applicable quantitative methods for functional measurement of vocal fold vibration in connected speech using innovative laryngeal imaging, an approach that could advance clinical voice assessment and treatment practice. In Aim 1, HSV-based measures of vocal fold kinematics will be developed and the influence of these measures on voice audio-perceptual qualities in the patients will be determined. Image processing techniques will be developed to extract such measures from the HSV data in connected speech. The extracted measures will be given as inputs to the statistical models to determine the source of the differences between the normal controls and the patients for different speech phonetic contexts and words. This aim provides an unbiased HSV-based method to predict voice quality. Developing such HSV-based methodology for functional laryngeal examination in connected speech can enhance clinical voice assessment. In addition, better understanding the influence of phonetic context would lead to optimizing the protocols for functional voice assessment through laryngeal imaging in connected speech. In Aim 2, machine learning approaches will be employed to discover hidden physics and unknown laryngeal mechanisms of voice production in the dysphonic patients. The findings of this project will help make necessary adjustments in biomechanical or physiological characteristics of vocal folds to enhance voice quality in patients with neurogenic voice disorders. Therefore, the outcome of this research will aid clinicians in properly selecting, and developing new treatment strategies (therapeutic, medicinal, or surgical), which are based on the gained knowledge of laryngeal mechanisms of dysphonia. The proposed research is in harmony with multiple priority areas of the NIDCD, described in the 2017-2021 Strategic Plan. Both aims support Priority 3 (improve methods of diagnosis, treatment, and prevention) through developing objective HSV-based measures and predicting the voice quality. Comparing laryngeal mechanisms in normal and disordered voices addresses Priority 1 (deepen our understanding of the normal function of the systems of human communication). Both aims propose to study laryngeal mechanisms in patients with neurogenic and functional voice disorders, which addresses Priority 2 (increase our knowledge about conditions that alter or diminish communication and health). Project Narrative  The goal of this proposal is to determine laryngeal mechanisms underlying dysphonia in connected speech, which will lead to development of clinically applicable quantitative methods for functional laryngeal examination in connected speech using laryngeal imaging. This can potentially result in enhancement of clinical voice assessment and development of new clinical voice management strategies to better help people with voice disorders.",Studying the Laryngeal Mechanisms Underlying Dysphonia in Connected Speech,10134315,K01DC017751,"['Acoustics', 'Address', 'Age', 'Area', 'Auditory', 'Behavior', 'Biomechanics', 'Categories', 'Characteristics', 'Clinical', 'Communication', 'Coupling', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Dysphonia', 'Endoscopes', 'Evaluation', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Image', 'Knowledge', 'Larynx', 'Lead', 'Machine Learning', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Mining', 'Modeling', 'National Institute on Deafness and Other Communication Disorders', 'Operative Surgical Procedures', 'Outcome', 'Outcomes Research', 'Paralysed', 'Patients', 'Physics', 'Physiological', 'Prevention', 'Production', 'Protocols documentation', 'Research', 'Series', 'Severities', 'Source', 'Spastic Dysphonias', 'Speech', 'Speed', 'Statistical Data Interpretation', 'Statistical Models', 'Strategic Planning', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Tremor', 'Visual', 'Voice', 'Voice Disorders', 'Voice Disturbances', 'Voice Quality', 'base', 'clinical application', 'clinical development', 'clinical practice', 'clinically relevant', 'cohort', 'flexibility', 'image processing', 'imaging approach', 'improved', 'innovation', 'kinematics', 'sex', 'temporal measurement', 'time use', 'tool', 'treatment strategy', 'vibration', 'vocal cord', 'vocalization']",NIDCD,MICHIGAN STATE UNIVERSITY,K01,2021,137795
"Speech markers of cognitive impairment in Parkinson's disease ABSTRACT Dr. Kara Smith is a Movement Disorders neurologist at the University of Massachusetts Medical School (UMMS) whose goal is to become an independent investigator focused on early cognitive impairment in Parkinson disease (PD). Her long-term goal is to develop speech markers of cognitive impairment in PD. Cognitive impairment occurs in the majority of PD patients, leading to increased mortality and decreased quality of life. The current diagnostic tools are resource-intensive and have limited sensitivity. Treatments are often offered late in the course of cognitive decline and do not provide optimal benefit. Speech markers could improve detection, monitoring and treatment of cognitive impairment in PD. Speech markers could be monitored frequently and remotely via mobile technology, capturing sensitive, quantitative data about cognitive function in the context of patients’ daily life and in response to therapeutics. Dr. Smith’s role as a clinical movement disorders specialist ideally positions her to lead the application of advanced speech and language research to feasible, patient-oriented tools for real-life clinical practice and clinical trials. Dr. Smith has assembled an expert interdisciplinary mentorship team ideally suited for the goals of this innovative proposal. Dr. Smith and her team have previously shown that a) speech acoustic markers are associated with cognitive function in non-demented PD patients, and b) PD patients with mild cognitive impairment had linguistic deficits including pauses within utterances and grammaticality. Building on these results, Dr. Smith proposes to study speech and language more comprehensively in PD patients with and without mild cognitive impairment and controls to confirm these preliminary results and identify additional biomarkers. The aims of this study will be 1) to develop algorithms using speech acoustic markers to categorize by cognitive status, 2) to identify linguistic markers associated with mild cognitive impairment in PD, and 3) to assess on-line syntactic processing in PD subjects with mild cognitive impairment. The overall goal of the proposal is to identify speech and language markers of early cognitive dysfunction that can be further refined, validated and implemented using mobile technology into a larger scale, longitudinal R01 proposal. Further work will also address the underlying neurobiological mechanisms of these speech markers. Dr. Smith’s rigorous training plan includes a Master’s degree, linguistics and speech motor physiology courses, and experience in signal processing and speech acoustic analysis. Through her training goals, she will advance her knowledge and skills in patient-centered outcomes measures and instrument validation. She will gain experience in research leadership, presentation and dissemination of scientific work, and in grant writing, culminating in an R01 proposal. This K23 award will be critical for Dr. Smith to establish an independent career as a PD clinician-scientist at the unique intersection of speech and language science and cognitive impairment. PUBLIC HEALTH RELEVANCE: Speech markers have the potential to improve diagnosis, monitoring and treatment of cognitive impairment in Parkinson’s disease (PD). Although the majority of PD patients will develop cognitive impairment, the tools available to assess and treat this disabling complication are fraught with limitations. As a detailed and quantitative assessment tool, speech markers may increase sensitivity to early cognitive dysfunction and to changes over time compared with current measures. They may be automated and then implemented through mobile technology to increase patients’ access to cognitive symptom monitoring outside of the clinic setting. Dr. Smith’s proposed career development plan has potential to fill a major gap in PD research by making inexpensive and easy-to-use cognitive assessment tools accessible to patients in rural and international settings, and by fueling clinical trials to discover new therapeutics capable of slowing cognitive decline in PD.",Speech markers of cognitive impairment in Parkinson's disease,10115019,K23DC016656,"['Acoustics', 'Address', 'Algorithms', 'American', 'Area', 'Articulation', 'Assessment tool', 'Award', 'Biological Markers', 'Biomedical Engineering', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Trials', 'Cognitive', 'Cognitive Therapy', 'Cognitive deficits', 'Complication', 'Comprehension', 'Data', 'Data Analyses', 'Dementia', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Foundations', 'Future', 'Goals', 'Grant', 'Health Services Accessibility', 'Impaired cognition', 'Impairment', 'Individual', 'International', 'Knowledge', 'Language', 'Language Disorders', 'Lead', 'Leadership', 'Life', 'Linguistics', 'Location', 'Longitudinal Studies', 'Machine Learning', 'Massachusetts', 'Master&apos', 's Degree', 'Measures', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Monitor', 'Motor', 'Movement Disorders', 'Nature', 'Nerve Degeneration', 'Neurobehavioral Manifestations', 'Neurobiology', 'Neurologist', 'Neuropsychological Tests', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Parkinson Disease', 'Parkinson&apos', 's Dementia', 'Participant', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physiology', 'Population', 'Positioning Attribute', 'Production', 'Proxy', 'Quality of Care', 'Quality of life', 'Research', 'Research Personnel', 'Resources', 'Role', 'Rural', 'Science', 'Scientist', 'Severities', 'Specialist', 'Speech', 'Speech Acoustics', 'Symptoms', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Training', 'Universities', 'Validation', 'Work', 'Writing', 'career', 'career development', 'clinical movement disorder', 'clinical practice', 'cognitive change', 'cognitive control', 'cognitive function', 'cognitive impairment in Parkinson&apos', 's', 'cognitive performance', 'cognitive testing', 'common symptom', 'experience', 'handheld mobile device', 'improved', 'innovation', 'instrument', 'language processing', 'large scale data', 'lexical retrieval', 'machine learning method', 'medical schools', 'mild cognitive impairment', 'mobile computing', 'mortality', 'motor deficit', 'neurobiological mechanism', 'non-demented', 'novel', 'novel therapeutics', 'patient oriented', 'public health relevance', 'recruit', 'response', 'screening', 'signal processing', 'skills', 'syntax', 'tool']",NIDCD,UNIV OF MASSACHUSETTS MED SCH WORCESTER,K23,2021,189216
"International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL) Project Abstract This proposal requests support to convene the next three International Conferences on Advances in Quantitative Laryngology, Voice and Speech Research (AQL). During the 5 years of requested support, the 14th, 15th, and 16th AQL (2021, 2023, and 2025 respectively) will be assembled. The 14th AQL will be held in Bogota, Colombia, South America, June 9 and 10, 2021 (pre-conference workshops June 7 and 8), the 15th will be in Phoenix, AZ, USA, in April 2023, while location of the 16th AQL conference will be determined during the 2021 conference (potential locations in South Korea or Germany). AQL is a valuable scientific meeting in the field of voice research and is regarded by voice and speech science specialists as a high quality international scientific meeting. AQL fosters the exchange of theoretical, experimental, and methodological advances, thereby progressing the translational and clinical aspects of voice and speech science. This multidisciplinary conference brings together scientists, clinicians, and students from around the world in various disciplines including Engineering, Biology, Physics, Otolaryngology and Speech Pathology. This proposal will allow for conference development and continuity to ensure an equitable conference that maintains its cutting-edge focus and provide support for students and early career investigators. The continuity of support will also ensure metrics and evaluations from previous conferences to be used to guide future AQL planning. The goals of this proposal are: to promote and support the education and development of young and underrepresented investigators in the voice and speech research community, organize special sessions on emerging research areas specific to quantitative laryngology, voice and speech research, to develop and foster digital networking strategies to provide a more inclusive and equitable conference, and to establish a Steering Committee. NIH funds are requested to provide support for child/family care, conference support for students and keynote speakers, students to assist Chair/Co-Chairs with various logistic needs, before, during and after the AQL conferences, website design and management, and streaming support during the meeting. In the off- conference years, necessary activities will include: student research trainee support, maintaining AQL website, Steering Committee meetings for conference evaluation and planning. Project Narrative This proposal seeks funding for the upcoming 14th, 15th, and 16th International Conference on Advances in Quantitative Laryngology, Voice and Speech Research (AQL) and the associated workshops and pre- conference, taking place in 2021, 2023, and 2025. AQL is an important international scientific meeting specialized in translational research and methods for measurement and modeling of voice and speech. Special emphasis will be given to promoting young investigators and underrepresented populations, digital networks to support a more inclusive and equitable conference, and to develop a permanent AQL website to help disseminate AQL information.","International Conference on Advances in Quantitative Laryngology,  Voice and Speech Research (AQL)",10237766,R13DC019564,"['Area', 'Award', 'Biology', 'COVID-19 pandemic', 'Carbon', 'Caring', 'Child', 'Child Support', 'Clinical', 'Collection', 'Colombia', 'Communities', 'Development', 'Disabled Persons', 'Discipline', 'Education', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Family', 'Fees', 'Fostering', 'Funding', 'Future', 'Germany', 'Goals', 'Health', 'International', 'Leadership', 'Location', 'Logistics', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Methodology', 'Modeling', 'Occupations', 'Online Systems', 'Otolaryngology', 'Persons', 'Physics', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Methodology', 'Research Personnel', 'Safety', 'Science', 'Scientist', 'South America', 'South Korea', 'Specialist', 'Speech', 'Speech Pathology', 'Stream', 'Students', 'Translational Research', 'Travel', 'Underrepresented Populations', 'United States National Institutes of Health', 'Update', 'Voice', 'Woman', 'career', 'cost', 'design', 'digital', 'ethnic minority population', 'expectation', 'improved', 'interest', 'meeting abstracts', 'meetings', 'member', 'minority student', 'multidisciplinary', 'outreach', 'posters', 'preservation', 'programs', 'racial and ethnic', 'recruit', 'social', 'symposium', 'virtual', 'web site']",NIDCD,MAYO CLINIC ARIZONA,R13,2021,40000
"Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes The trained ear of the speech-language pathologist is the gold standard assessment tool for clinical practice in motor speech disorders. However, perceptual judgments are vulnerable to bias and their relationship with estimates of listener intelligibility – the final arbiter of speech goodness – is indeterminate. Interpretable, objective, and robust outcome measures that provide targets for treatment are urgently needed in order to provide more precise care and reliably monitor patient progress. Based on theoretical models of speech perception, in our previous grants we have developed a novel set of outcome measures that provide a multi- dimensional intelligibility profile (MIP) by using custom speech stimuli and a new coding strategy that allows us to capture the types of errors that listeners make when listening to dysarthric speech. This has led to a more complete intelligibility profile that codifies these errors at different levels of granularity, from global to discrete. Simultaneously, we have also developed a computational model for evaluation of dysarthric speech capable of reliably estimating a limited set of intelligibility measures directly from the speech acoustics. To date, both the outcome measures and the objective model have been evaluated on cross-sectional data only. In this renewal application, our principal goal is to evaluate specific hypotheses regarding expected changes in this multidimensional intelligibility profile as a result of different intervention instruction conditions (loud, clear, slow). A secondary goal of the proposal is to further refine our objective model to predict the complete intelligibility profile and to evaluate its ability to detect intelligibility changes within individual speakers. This is critical for clinicians who currently have no objective ways to assess the value of their interventions. With the aim of improving the standard of care through technology, the long-term goal of this proposal is to develop stand-alone objective outcome measures for dysarthria that can provide clinicians with reliable treatment targets. Such applications have the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury. Furthermore, these applications also have the potential to reduce health disparities by partially automating clinical intervention and providing easier access to these services to those in remote areas or in underdeveloped countries.   There is an urgent need in the field of speech-language pathology for objective outcome measures of speech intelligibility that provide clinicians with actionable information regarding treatment targets. This proposal seeks to leverage theoretical advances in speech intelligibility to evaluate the sensitivity of a novel multidimensional intelligibility profile that quantifies the perceptual effects of speech change. Using listener transcriptions of dysarthric speech, along with a suite of automated acoustic metrics, the predictive model uses machine-learning algorithms to learn the relationship between speech acoustics and listener percepts. Ultimately, this model will allow clinicians to predict the outcomes of an intervention strategy to assess its utility for a patient. This has the potential to dramatically alter the current standard of care in speech pathology for patients with neurological disease or injury.",Perception of dysarthric speech: An objective model of dysarthric speech evaluation with actionable outcomes,10087511,R01DC006859,"['Acoustics', 'Adopted', 'Affect', 'Area', 'Attention', 'Caring', 'Clinical', 'Clinical Assessment Tool', 'Code', 'Cognitive', 'Communication impairment', 'Complex', 'Computer Models', 'Country', 'Cues', 'Custom', 'Data', 'Dimensions', 'Disease Progression', 'Dysarthria', 'Ear', 'Educational Intervention', 'Evaluation', 'Frequencies', 'Genetic Transcription', 'Goals', 'Gold', 'Grant', 'Health Services Accessibility', 'Individual', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Language', 'Learning', 'Loudness', 'Measures', 'Modeling', 'Motor', 'Nervous System Trauma', 'Noise', 'Outcome', 'Outcome Measure', 'Participant', 'Pathologist', 'Patient Monitoring', 'Patients', 'Pattern', 'Perception', 'Periodicity', 'Population', 'Process', 'Research', 'Sampling', 'Severities', 'Signal Transduction', 'Source', 'Speech', 'Speech Acoustics', 'Speech Disorders', 'Speech Intelligibility', 'Speech Pathology', 'Speech Perception', 'Speech-Language Pathology', 'Stimulus', 'Stream', 'Technology', 'Testing', 'Theoretical model', 'Time', 'Training', 'Update', 'Validation', 'Work', 'base', 'clinical practice', 'health disparity', 'improved', 'lexical', 'machine learning algorithm', 'nervous system disorder', 'novel', 'optimal treatments', 'outcome prediction', 'phrases', 'predictive modeling', 'recruit', 'signal processing', 'speech in noise', 'standard of care', 'tool']",NIDCD,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2021,305399
"Speech segregation to improve intelligility of reverberant-noisy speech Project Summary Hearing loss is one of the most prevalent chronic conditions, affecting 37.5 million Americans. Although signal amplification in modern hearing aids makes sound more audible to hearing impaired listeners, speech understanding in background interference remains the biggest challenge by hearing aid wearers. The proposed research seeks a monaural (one-microphone) solution to this challenge by developing supervised speech segregation based on deep learning. Unlike traditional speech enhancement, deep learning based speech segregation is driven by training data, and three components of a deep neural network (DNN) model are features, training targets, and network architectures. Recently, deep learning has achieved tremendous successes in a variety of real world applications. Our approach builds on the progress made in the PI's previous R01 project which demonstrated, for the first time, substantial speech intelligibility improvements for hearing-impaired listeners in noise. A main focus of the proposed work in this cycle is to combat room reverberation in addition to background interference. The proposed work is designed to achieve three specific aims. The first aim is to improve intelligibility of reverberant-noisy speech for hearing- impaired listeners. To achieve this aim, we will train DNNs to perform time-frequency masking. The second aim is to improve intelligibility of reverberant speech in the presence of competing speech. To achieve this aim, we will perform DNN training to estimate two ideal masks, one for the target talker and the other for the interfering talker. The third aim is to improve intelligibility of reverberant speech in combined speech and nonspeech interference. To achieve this aim, we will develop a two-stage DNN model where the first stage will be trained to remove nonspeech interference and the second stage to remove interfering speech. Eight speech intelligibility experiments involving both hearing-impaired and normal-hearing listeners will be conducted to systematically evaluate the developed system. The proposed project is expected to substantially close the speech intelligibility gap between hearing-impaired and normal-hearing listeners in daily conditions, with the ultimate goal of removing the gap altogether. Relevance A widely acknowledged deficit of hearing loss is reduced intelligibility of reverberant-noisy speech. How to improve speech intelligibility of hearing impaired listeners in everyday environments is a major technical challenge. This project directly addresses this challenge and the results from the project are expected to yield technical methods that can be translated to hearing prosthesis, potentially benefiting millions of individuals with hearing loss.",Speech segregation to improve intelligility of reverberant-noisy speech,10064139,R01DC012048,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'American', 'Auditory', 'Auditory Prosthesis', 'Chronic', 'Complex', 'Data', 'Environment', 'Formulation', 'Frequencies', 'Goals', 'Hearing', 'Hearing Aids', 'Individual', 'Investigation', 'Laboratories', 'Masks', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neural Network Simulation', 'Noise', 'Recurrence', 'Research', 'Signal Transduction', 'Source', 'Speech', 'Speech Intelligibility', 'Structure', 'Supervision', 'Surface', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Voice', 'Work', 'base', 'combat', 'deep learning', 'deep neural network', 'design', 'digital', 'experimental study', 'hearing impairment', 'improved', 'innovation', 'microphone', 'network architecture', 'normal hearing', 'real world application', 'segregation', 'signal processing', 'sound', 'speech in noise', 'success', 'supervised learning']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,301954
"The role of amplitude modulation in perceiving speech and music Project Summary/Abstract  My career goal is to become a leading researcher on cognitive neuroscience, with a special focus on the neural mechanisms underlying auditory perception, including how humans track and perceive the fleeting audi- tory information in speech and music. In this proposal, I outline a research program to investigate the acoustic and neural distinctions between speech and music, two specialized forms of auditory signals that are closely tied to the human mind. Despite our increasingly rich understanding of the perceptual and neural mechanisms for processing speech or music, surprisingly little is known about why and how they are treated as different au- ditory signals by the human mind and brain in the first place. Investigating these distinctions is foundational for a thorough understanding of how acoustic waveforms are transformed into meaningful information. The work will provide a more solid basis for understanding cognition and communication as well as treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.  I hypothesize that the temporal structure reflected in the amplitude modulation (AM) of speech and music signals is a critical distinctive feature for the brain and engages to different processing pathways, as speech and music are known to have distinct AM rates. A series of studies, combining psychophysics, MEG (magne- toencephalography), fMRI (functional magnetic resonance imaging), and machine learning approaches, will use stimuli with AM rates across the modulation frequency ranges of speech and music to address this topic at the computational (the goals), algorithmic (the representations and operations), and implementational (neural mechanism) levels. (1) Does the AM rate of a sound affect whether it will be perceived as speech or music? (2) Does the AM rate of a stimulus optimize speech and music perceptual performance at different frequencies? (3) What are the underlying neural mechanisms and the associated brain regions implementing the differentiation of speech and music? Aim 1 investigates whether the AM rate of a sound conditions it to be processed as speech or music. By manipulating the AM rate of noise-vocoded speech and music recordings, I hypothesize that the sounds with slower or faster AM rates will likely to be perceived as music or speech, respectively, the perceptual judgment will be biased by the higher or lower spectral energy of neural oscillatory activity (meas- ured by MEG) while listening to the sounds, respectively, and the associated brain regions will be revealed by fMRI with machine learning decoding approaches. Aim 2 investigates whether the AM rate of stimuli optimizes speech and music perceptual performances at different rates. I hypothesize that the music perceptual perfor- mance is optimal at slower AM rates while the speech perceptual performance is optimal at faster AM rates, and the neural oscillatory entrainment at lower or higher frequency band has domain-specific function facilitat- ing speech or music perceptual performance. Project Narrative Speech and music are two specialized forms of auditory signal that are closely tied to human mind; however, despite our increasingly rich understanding of the perceptual and neural mechanisms of human processing of speech or music, surprisingly little is known how they are treated as different auditory signals by the human mind and brain at the first place. The current proposal aims to investigate the fundamental differences between speech and music at the acoustic, perceptual, and neural levels, by combining psychophysics, neuroimaging, and machine learning approaches. Investigating their distinctions is crucial for understanding how acoustic waveforms are transformed into meaningful information, and it will provide the basis for understanding and treating people with communicative deficits, such as people with autism, Alzheimer's disease, and aphasia.",The role of amplitude modulation in perceiving speech and music,10118008,F32DC018205,"['Acoustics', 'Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Aphasia', 'Auditory', 'Auditory Perception', 'Auditory area', 'Behavioral', 'Brain', 'Brain region', 'Cognition', 'Communication', 'Data', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Human', 'Judgment', 'Linguistics', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mind', 'Music', 'Noise', 'Participant', 'Pathway interactions', 'Perception', 'Performance', 'Periodicity', 'Process', 'Psychophysics', 'Records', 'Research', 'Research Personnel', 'Role', 'Series', 'Signal Transduction', 'Solid', 'Speech', 'Speech Perception', 'Stimulus', 'Structure', 'System', 'Testing', 'Work', 'auditory processing', 'career', 'cognitive neuroscience', 'experimental study', 'individuals with autism spectrum disorder', 'insight', 'neuroimaging', 'neuromechanism', 'non-invasive imaging', 'operation', 'programs', 'relating to nervous system', 'sound', 'spectral energy', 'speech processing']",NIDCD,NEW YORK UNIVERSITY,F32,2021,65994
"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,10201558,K24DC016312,"['3-Dimensional', 'Address', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Articulation', 'Articulators', 'Bypass', 'Cellular Phone', 'Cerebral Palsy', 'Characteristics', 'Communication', 'Complex', 'Cues', 'Data', 'Deterioration', 'Development', 'Devices', 'Disease', 'Dysarthria', 'Effectiveness', 'Electromagnetics', 'Ensure', 'Future', 'Generations', 'Goals', 'Impairment', 'Individual', 'Jaw', 'Laboratories', 'Learning', 'Lip structure', 'Machine Learning', 'Malignant neoplasm of larynx', 'Maps', 'Measures', 'Modeling', 'Modification', 'Motion', 'Motor', 'Movement', 'Multiple Sclerosis', 'Oral', 'Output', 'Parkinson Disease', 'Participant', 'Patients', 'Performance', 'Persons', 'Play', 'Quality of life', 'Questionnaires', 'Records', 'Research', 'Research Personnel', 'Running', 'Severities', 'Speech', 'Speech Intelligibility', 'Speech Sound', 'Speed', 'Stroke', 'Structure', 'Surveys', 'System', 'Tablet Computer', 'Tablets', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Time', 'Tongue', 'Traumatic Brain Injury', 'Voice', 'Work', 'base', 'brain cell', 'clear speech', 'cost', 'effectiveness testing', 'efficacy testing', 'experience', 'experimental study', 'improved', 'innovation', 'jaw movement', 'laptop', 'machine learning algorithm', 'motor impairment', 'novel', 'oral communication', 'orofacial', 'phrases', 'portability', 'spatiotemporal', 'time use', 'usability', 'virtual', 'virtual vocal tract']",NIDCD,MGH INSTITUTE OF HEALTH PROFESSIONS,K24,2021,189937
