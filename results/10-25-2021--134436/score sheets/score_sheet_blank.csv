title,text,label
Real-time Multimodal Diffuse Reflectance and Polarization Imaging Based Nerve Identification in Surgical Field of View,"Real-time Multimodal Diffuse Reflectance and Polarization Imaging Based Nerve Identification in Surgical Field of View PROJECT SUMMARY We propose to develop a novel non-contact, label-free multimodality imager that provides real-time intraoperative identification of nerves within the surgical field-of-view to facilitate the prevention of unintended nerve damage (termed iatrogenic nerve injury) during surgical procedures, as they are a major source of postsurgical complications, e.g., chronic pain. In the United States chronic pain management is a major putative contributing factor in the current opioid-related drug overdose epidemic. Annually, over 45 million surgical procedures are performed in the United States and an estimated 10% to 50% of them result in patient chronic postoperative pain outcomes. Though not all the at least 4.5 million are definitively ascribable to iatrogenic nerve injury, it nonetheless represents a significant recurring annual healthcare problem. Relatedly, analysis of large-scale nerve lesion treatment studies reveals that 25%, 60% and 94% respectively of sciatic, femoral and accessory nerve lesions addressed are caused by iatrogenic nerve injury. Additionally, iatrogenic nerve injury features prominently in post-surgical quality of life issues that range from loss of sensation and motor function, to the aforementioned chronic pain, and morbidity. Reportedly, 2-3 years post radical prostatectomy ~60% of men are still impotent as a result of damaged cavernous nerves. Likewise, 20% - 60% of mastectomy breast cancer treatment survivors suffer chronic post-surgical pain that significantly reduces their quality of life, and injury to the intercostobrachial nerve is the primary cause. Even in surgeries with minimal neural damage risk like acoustic neuroma removal (<1%), spinal scoliosis surgery (<0.6%), and thyroidectomy (<2-3.8%) the consequences of nerve damage can be severe: leading to deafness, paraplegia, and even death respectively. The associated financial implications of iatrogenic nerve damage are significant. There are direct financial costs to the individual due to loss of employment and/or income, and to the healthcare industry as nerve damage is a common source of litigation with compensation being awarded in 82% of cases of spinal accessory nerve injury, for an example. The exposure of healthcare personnel and providers to medicolegal liability is extensive as Iatrogenic nerve injuries are commonly reported on the laryngeal nerve during thyroid operations, trigeminal nerve and inferior alveolar nerve during facial and oral surgeries, intercostal nerves during thoracic surgeries, and on the spinal accessory nerves, common peroneal nerve, superficial radial nerve, and genitofemoral nerve branches during various other surgeries. Consequently, as of 2015, medicolegal litigation risk was a primary driver for a $2.2 billion global market for intraoperative nerve monitoring projected to grow annually at 4.79% until 2025. Our proposed solution targets filling both the deficiencies of currently available options and the growing demand by introducing an effective, commercially viable product. PROJECT NARRATIVE Unintended nerve damage during surgical procedures is a significant and costly public healthcare delivery problem and current methods for injury prevention via intraoperative nerve monitoring leave substantial room for improvement. The ramifications of increased healthcare costs due to associated medical-liability issues and the significant reductions in quality of life issues, including the burgeoning chronic pain management related opioid-related drug overdose epidemic, make addressing this very impactful to society. The proposed development will yield an effective, commercially viable, non-contact multimodality imager that provides real- time intraoperative identification of nerves within the surgical field-of-view to facilitate the prevention of unintended nerve damage during surgical procedures.",
Gene expression and regulation in C. elegans with single cell resolution,"Gene expression and regulation in C. elegans with single cell resolution Abstract The nematode C. elegans is unique among model organisms in having a defined lineage and known connections for all its 302 neurons. The genome sequence was completed more than 20 years ago, but knowing which genes in the genome are used in exactly which cells and what transcription factors are controlling that expression remains a major challenge. We have successfully applied single cell- (sc-)RNA-seq methods to one larval stage and three embryonic stages to measure the RNA content of individual cells across the whole animal. We also have preliminary data that indicates that we can assay chromatin accessibility at the single cell level using the assay for transposase accessible chromatin (ATAC-seq). We now propose to collect both sc-RNA-seq and ATAC-seq data at multiple stages to determine the gene expression patterns of each cell in the worm and the active regulatory sequence throughout the entire life cycle of C. elegans. In turn we will use the combined data sets along with chromatin- immunoprecipitation- (ChIP-) seq data to impute what transcription factors are controlling expression of each gene in the genome in every cell and what regulatory sequences these transcription factors recognize. The results will provide a valuable resource to scientists studying the worm and addresses a major outstanding question in the molecular biology of development. In addition, these data sets, from an animal with a “ground truth” should serve as a platform for methods development in the single cell field. Narrative The nematode C. elegans is a simple animal that as an adult has just 959 somatic cells that arise from a known and constant lineage. We propose to use single cell methods to measure in every cell the expression of each gene and the active regulatory regions throughout the life cycle. Using these data and others, we will impute how these regulatory regions and the transcription factors that bind to them control gene expression in each cell.",
Motor cortex network dynamics driving stroke recovery,"Motor cortex network dynamics driving stroke recovery PROJECT SUMMARY Ischemic stroke is the most common cause of disability in US, with motor impairment being the most common form of disability. Rehabilitation therapies remain a mainstay treatment during recovery, but are not very effective for those with moderate to severe upper extremity weakness. Physical and pharmacologic interventions could become more effective if recovery mechanisms were better understood. The studies proposed here will use cutting-edge techniques to dissect the mechanisms of post-stroke recovery at the level of cortical neuronal networks. The principal investigator (PI) is a board-certified neurologist, and has extensive training in neuroscience, stroke neurobiology, and clinical management of patients with neurological diseases. The long- term goal is to understand relationships between the cortical neural network and the motor behaviors with a focus on motor recovery. The proposed research and career development plans will provide the necessary training, mentorship and experience to launch the PI’s career as a successful, R01-funded clinician-scientist. The PI has recently developed deep learning (a branch of machine learning) tools for automated and unbiased analysis of animal behavioral imaging data. Preliminary data demonstrate that, by using these automated tools, 3D kinematics of paw movements can be obtained during a food pellet reaching task in a head-fixed mouse, distinct neural activity patterns emerge in the primary motor cortex (M1) during motor learning of the skilled reaching, and stroke induces changes in the kinematics of the reaching behavior. In the proposed studies, the following specific hypotheses will be tested: stable neuronal network activity patterns emerge in M1 during motor learning (Aim-1); these M1 activity patterns destabilize after a stroke and sensorimotor disconnection (Aim-2); and new M1 activity patterns emerge after post-stroke task-specific rehabilitation (Aim-3). The PI will use, and be further trained on state-of-the-art techniques to record neural population activity (two-photon calcium imaging), to label and silence projection neurons (retro-AAVs and designer-receptors exclusively activated by designer drugs), and to analyze the kinematics of the behavior (deep learning tools). For this purpose, he has assembled a strong mentorship team with experts in their respective fields: Primary mentor Dr. Peyman Golshani (two-photon calcium imaging and analysis in behaving animals), as well as co-mentors, Dr. S. Thomas Carmichael (stroke recovery research), Dr. Jonathan Kao (neural dynamics analysis in motor cortex), and clinically, Dr. Bruce Dobkin (translational neurorehabilitation). The mentored research will be complemented with course work on state-space methods, biostatistics, bioethics, deep learning, responsible conduct of research, and grant writing; as well as improvement of professional skills by publishing manuscripts, presenting at meetings, and participating in workshops on leadership and management. By the end of K08 award, it is expected that the PI will obtain R01 funding as a clinician-scientist and independent investigator, focused on understanding mechanisms of the neural networks that can be modulated to improve motor behavior after stroke. PROJECT NARRATIVE Understanding the mechanisms of motor recovery will ultimately lead to better therapies for stroke recovery. In the proposed research, we aim to elucidate the motor recovery process by investigating the precise activity patterns of brain cells during skilled reaching movements that will be kinematically analyzed by novel automated tools. These brain-behavior correlations will generate fundamental knowledge about stroke recovery to inform new interventions that can reduce the burden of disability caused by stroke.",
Developing a Data-Driven Management System Using Machine Learning and Mixed-Methods Research to Predict Job Turnover Among MentalHealth Professionals,"Developing a Data-Driven Management System Using Machine Learning and Mixed-Methods Research to Predict Job Turnover Among MentalHealth Professionals Project Summary/Abstract The main goal of this study is to build a data-driven, evidence-based organizational management system that can inform effective recruitment and retention strategies to prevent excessive turnover. High turnover rates (estimated 25-60% annually) are devastating for mental health care systems, affecting organizations (e.g., cost), employees (e.g., work well-being), and most critically, the quality of care. Human resource departments collect extensive employee data that can be useful predictors for turnover, but these data are not often analyzed to address turnover issues in mental health organizations. Computational methods have greatly evolved and can now access and analyze large and complex data. This pilot study will achieve three specific aims: Aim 1: build and test turnover prediction models by developing and applying machine learning algorithms to existing human resource data; Aim 2: generate critical questions to enhance turnover prediction through qualitative methods; and Aim 3: test the enhanced model in predicting turnover at 12 months. In Aim 1, using past human resource data and service encounters from [two mental health organizations (rural and urban locations)], we will develop machine learning algorithms to predict turnover. The algorithms will address turnover questions simultaneously (e.g., Who are the most likely to leave? What factors predict turnover at varying time points in employment?). In Aim 2, we will interview key informants: “leavers” (employees who voluntarily terminate employment during the study); “stayers” (employees with extreme longevity in the organization); and “predictees” (identified as likely to leave, based on our algorithms). The findings will be discussed in two focus groups in order to generate, refine, and validate 5-10 critical questions to enhance prediction of turnover. In Aim 3, we will conduct an on-line survey of all current employees to assess the 5-10 critical questions and link survey data with data from human resources and services to examine the improved precision between the theory-based model (predictors in the survey) and the data-driven model (machine learning algorithms) in predicting actual turnover 12 months later. Machine learning can model complex and dynamic variable relationships (e.g., handling a large number of variables, accounting for heterogeneity) and overcome limitations in traditional turnover research that often relies on small, cross-sectional, and convenience samples. Successful completion of this study will promote data-driven, evidence-based organizational management practices to address turnover, which is aligned with NIMH priorities of capitalizing on existing data structures and using technologies to improve mental health service quality. This study will be a critical step in developing highly adaptable machine learning algorithms to predict turnover; ultimately, we envision that this system will be partnered with future clinical interventions to reduce turnover in mental health. Project Narrative This pilot study will build a data-driven, evidence-based organizational management system to inform effective recruitment and retention strategies for preventing excessive employee turnover in mental health organizations. Successful retention of a quality workforce not only helps mental health organizations and their employees, but also directly impacts the quality of care that clients receive. In addition, a data-driven, evidence-based organizational management system could be partnered with clinical interventions to reduce turnover.",
AUTOMATION OF DNA SEQUENCE DATA ENTRY,"AUTOMATION OF DNA SEQUENCE DATA ENTRY DNA sequence determination has become a standard method for the characterization of newly isolated genes.  Recent advances in the technology for the determination of DNA sequences have allowed large amounts of data to accumulate rapidly.  However, methods for transferring that data into the computer, where it is to be analysed, are still far from ideal, in that they require considerable manual interention.  We propose to develop a highly automated system that will greatly increase the accuracy and the speed with which sequence data can be collected and analysed.  The method requires first producing a digital image of the sequencing radioautogram.  Algorithms will then be devised that are able to convert that ditigized data into a DNA sequence.  A key feature of the software for this interpretative step is that it will operate according to a set of heuristic procedures that are clearly defined and which can easily be modified and extended.  When these rules fail to provide an unambiguous interpretion then operator assistance will be requested to make a final decision.  An important consequence of the strategy is that the primary data upon which the DNA sequence depends will be available in machine-readable form.  Appropriate software will be developed to manage this primary data and to assist in the resolution of discrepancies that may arise during the course of a sequencing project.  The software tools that will be developed during the course of this project would have additional applications for the interpretation of all kinds of biological data that derive from gel electrophoretic techniques.  n/a",
Developing Smokers for Smoker (S4S): A Collective Intelligence tailoring system,"Developing Smokers for Smoker (S4S): A Collective Intelligence tailoring system DESCRIPTION (provided by applicant): Smoking is still the number one preventable cause of cancer death. New approaches are needed to engage smokers in the 21st century in smoking cessation. I propose to develop S4S (Smokers for Smoker), a next- generation patient-centered computer tailored health communication (CTHC) system. Unlike current rule- based CTHCs, S4S will replace rules with complex machine learning algorithms, and use the collective experiences of thousands of smokers engaged in a web-assisted tobacco intervention to enhance personally- relevant tailoring for new smokers entering the system. This NCI K07 will provide a mentored research experience, giving me the opportunity to acquire new competencies in cancer health communication for behavior change, research design and statistical methods underlying clinical trial implementation and evaluation. I will adapt collectiv intelligence algorithms that have been used outside healthcare by companies like Amazon and Google to enhance CTHC. Using knowledge from scientific experts, current CTHC collect baseline patient ""profiles"" and then use expert-written, rule-based systems to tailor messages to patient subsets. Such theory-based ""market segmentation has been effective in helping patients reach lifestyle goals. However, there is a natural limit in the ability of a rule-based system to truly personalize content, and adapt personalization over time. Current CTHC have reached this limit, and I propose to go beyond. My first aim is to develop the Web 2.0 ""S4S"" recommender system. My second aim is to evaluate S4S within the context of a NCI funded web-assisted tobacco intervention (Decide2Quit.org). In my efforts, I will guided by my primary mentor (Dr. Houston, MD MPH) and two other mentor teams: The Cancer Health Behavior and Communication Team (Stephenie Lemon, PhD and Kathleen Mazor, EdD), and the Clinical Trial Design and Analysis Team (Jeroan Allison, MD, MS and Arlene Ash, PhD). My comprehensive training also includes coursework, seminars, and conferences. PUBLIC HEALTH RELEVANCE: A high priority research area identified by the NIH is to understand the role of different media in increasing consumer demand for and use of effective, individually oriented tobacco cessation treatments for diverse populations. Specifically, a research focus is on understanding how to best tailor interventions. Although effective, there is a natural limit in the ability of current rle-based tailoring systems to truly personalize content, and adapt personalization over time. This NCI K07 will advance computer tailoring by adapting machine learning collective intelligence algorithms that have been used outside healthcare by companies like Amazon and Google to enhance the personal relevance of the health communication.",
"Models for synthesising molecular, clinical and epidemiological data, and transla","Models for synthesising molecular, clinical and epidemiological data, and transla DESCRIPTION (provided by applicant): A mathematical or computational model of infectious disease transmission represents the process of how an infection spreads from one person to another. Such models have a long history within infectious disease epidemiology, and are useful tools for giving insight into the dynamics of epidemics and for evaluating the potential effect of control methods. The overall objective of this project is to substantially improve the methods by which models of infectious diseases transmission are calibrated against biological and disease surveillance data. This will both improve the utility of models as tools for analyzing data on infectious disease outbreaks (for instance to provide more rapid and reliable estimates of how transmissible and lethal a new virus is to public health agencies) and also improve the reliability of models as tools for predicting the likely effect of different interventions (such as vaccines or case isolation) to help policy makers make more informed decisions about control policies. As with many areas of biology and medicine, the data landscape for infectious diseases modeling is changing rapidly. Larger and more complex datasets are becoming available that cover many different aspects of the interaction between a pathogen and the human population: clinical episode data, genetic data about fast-evolving pathogens; animal-model transmission data and community-based representative serological data. The specific aims of our project are to: (a) develop new machine-learning based methods to discover interesting patterns in complex datasets related to the transmission of infectious disease, so as to better specify subsequent mechanistic mathematical or computational models; (b) derive new approaches for using more than one type of data simultaneously to calibrate transmission models and (c) derive new methods of parameter estimation for simulations which model the spatial spread of infection or model both the transmission and genetic evolution of a pathogen. We will achieve these aims in the applied context of research on three key infections: emerging infectious diseases (such as MERS-CoV - the novel coronavirus currently spreading in the Middle East), influenza and Streptococcus pneumonia (a major bacterial pathogen). Examples of the scientific questions we will address that cannot be answered with current methods are: (i) how many unobserved cases of MERS-CoV have occurred so far (to be answered using data on case clusters data, the spatial distribution of cases and viral genetic sequences)? (ii) how many people in different age groups are infected with influenza each year and how does their immune system respond to infection (to be answered using data on case incidence and serological testing of the population)? (iii) how much is vaccination coupled with prescribing practices influencing the emergence of resistant strains of pneumococcus (to be addressed with data on antibiotic and vaccine use, case incidence and bacterial strain frequency)? PUBLIC HEALTH RELEVANCE: Mathematical and computational models of infectious disease spread can provide valuable information to aid policy-makers in the tough choices they face when trying to control infectious diseases, but models must be designed to make the best possible use of the often limited data available. As the digital footprints of our lives grow, so te datasets available for infectious disease models become larger and more complex. This project will develop new algorithms and methods to allow models to make better use of all available data and therefore better inform control policy planning for diseases such as: influenza, pneumococcal infection and novel viruses like MERS-CoV.",
ICP Elevation Alerting Based on a Predictive Model Hosting Platform,"ICP Elevation Alerting Based on a Predictive Model Hosting Platform DESCRIPTION (provided by applicant): Recurring acute ICP elevations occur frequently and unpredictably among severe brain injury patients. ICP elevation can cause cerebral ischemia and lead to deadly brain herniation if untreated. Hence, prompt recognition and treatment of rising ICP are critical in managing severe brain injury patients. However, existing protocols in most neurocritical care units are reactive where bedside nurses, in response to simple threshold-crossing alarms, have to check numerical display of ICP on monitors to manually establish whether the alarm is a true one before initiating treatment. Acute ICP elevation is accompanied by distinctive ICP pulse morphological changes. By utilizing ICP pulse morphological metrics as input, we can accurately recognize precursors to ICP elevation to alert nurses and free them from a cognitively demanding process of establishing whether a consistent ICP elevation triggers the alarm. We therefore propose to deploy a previously developed accurate ICP elevation prediction model on an open-source model hosting platform to monitor continuous ICP signals and alert bedside nurses. Using this alerting system, we will further investigate the principal physiological abnormalities associated with acute ICP elevation showing different precursory ICP patterns prior to onset of elevation. We will pursue the following three aims: 1) To develop an alerting system for ICP elevation based on a model hosting platform; 2) To investigate whether the ICP alerting system helps nurses more efficiently manage ICP. 3) To detect consistent physiological abnormalities associated with acute ICP elevation. Our long-term goal is to advance intensive care monitoring so that continuous signals from monitors are fully explored to integrate with the rest of clinical data in an electronic medical record (EMR) system to enhance clinical decision making. This project represents an effort piloting a platform-based approach towards overcoming translational barriers that impede the process of making advanced predictive analytics available at point of care. Therefore, broad impacts from this project are related to future efforts at leveraging this open model hosting platform to facilitate the translation of additional predictive models in other ICUs. Recurring acute intracranial pressure (ICP) elevation occurs frequently, up to more than 20 in a 12-hour nursing shift, and unpredictably among severe brain injury patients. These acute ICP elevations needs prompt treatment before they impair blood flow to the brain and cause deadly brain herniation. The present work is built upon our previously developed algorithm of detecting acute ICP elevation and an open software platform for hosting predictive algorithms to further develop and evaluate a real-time ICP elevation alerting system that will provide accurate alerts of impending ICP elevation. Rigorous human factor engineering principles and techniques will be adopted in developing this system and we will further leverage this real-time alerting system to investigate the principal physiological abnormalities that are associated with accurate ICP elevation.",
"Closing the loop: development of real-time, personalized brain stimulation","Closing the loop: development of real-time, personalized brain stimulation Project Summary  We are in critical need of targeted and individualized treatments for mental health disorders, which affect nearly 50% of Americans during our lifetimes. Brain stimulation treatments, including repetitive transcranial magnetic stimulation (rTMS), represent the front-line of innovative approaches to correct dysfunctional brain networks for patients suffering from mental illness. rTMS is FDA-approved for depression and obsessive- compulsive disorder (OCD) with clinical trials underway for post-traumatic stress disorder (PTSD) and substance use, among others. However, as currently administered, rTMS lacks a biomarker to individually optimize treatment and thus suffers from a poor clinical response rate (<50%). Without personalization of rTMS, we risk a one-size-fits-all treatment for all psychiatric disorders, not dissimilar to how antidepressants are administered.  Using simultaneous TMS and electroencephalography (TMS-EEG), I identified a depression severity biomarker from a double-blind randomized clinical trial treating depressed patients with one month of active or placebo rTMS. The degree of this biomarker change significantly predicted clinical improvement after rTMS treatment. Direct brain recordings further suggest that a single stimulation session is sufficient to modulate this biomarker, indicating that this brain-based biomarker can be monitored daily to support empiric treatment optimization.  With this in mind, I propose to develop the first broadly generalizable platform for real-time biomarker monitoring (Aim #1) and personalized rTMS treatment (Aims #2 & 3). I will enroll 54 depressed patients to participate in a cross-over, placebo-controlled study directly comparing personalized, adaptive rTMS to standard rTMS. Primary outcome will be target engagement and dose-response of the depression severity biomarker. Successful implementation of this work includes the early stratification of treatment responders and personalized and more effective treatments for non-responders. This approach is broadly applicable to other depression biomarkers, all psychiatric populations treated with rTMS, and other brain stimulation modalities. More generally, my goals are to establish the fundamental principles of human brain plasticity and to construct platforms for rapid biomarker development, engagement, and integration into personalized brain stimulation treatments. Project Narrative We need targeted, individualized treatments for mental health disorders, which affects nearly 50% of Americans. Brain stimulation treatments target dysfunctional brain networks with minimal side effects but are currently applied in a one-size-fits-all manner, thus limiting its efficacy. I aim to develop a non-invasive personalized brain stimulation platform for neuropsychiatric disorders; here I will create a real-time monitoring system for brain changes, evaluate the mechanism underlying these brain changes, and develop and test an adaptive stimulation paradigm to maximally drive individual brain changes and improve clinical outcome.",
KNOWLEDGE-BASED RECORDS FOR PATIENTS WITH HIV INFECTIONS,"KNOWLEDGE-BASED RECORDS FOR PATIENTS WITH HIV INFECTIONS Primary care physicians are burdened by the complexity of the care that must be delivered to patients with HIV infection, the time required for care and the difficulty of keeping abreast of a rapidly changing knowledge base that is the foundation for that care. We plan to use the computer to ease the burden of care by monitoring each patient's treatment, by suggesting alternative care plans when appropriate, and by providing an integrated information environment.  This knowledge-based medical record system for the care of patients with HIV-related illness (KBMR-HIV) will provide physician reminders, directed access to the biomedical literature, information on research protocols, information about community resources, and information about cost-effective strategies for the management of common problems. In addition, the system will collect data and information that will be of immediate use to those caring for the patients and will be of future use to those interested in aggregation of longitudinal data for the purpose of clinical, epidemiologic and policy related investigation.  Patient information from KBMR-HIV will be transferred into ClinQuery, a data management tool developed to facilitate rapid exploration of aggregate clinical data base. ClinQuery provides for confidential access to patient data while inviting exploration of this clinical data. This data base will contain information about patients who have been treated in a variety of care settings (home, ambulatory, and inpatients), by a variety of care providers (staff physician, intern, resident, and nurse practitioner), and by a variety of protocols.  We hypothesize that physicians who use KBMR-HIV will indicate they are more satisfied with the care they are giving to patients with HIV infection. We will administer a series of questionnaires to help assess their satisfaction and we will analyze clinicians' adherence to agreed upon standards of care to help assess their effectiveness. We will also evaluate the number of admissions, the interval between admissions, the total charges for hospital care, the total charges for all care (impatient and ambulatory), the number of ambulatory visits, the number of invasive procedures, the number of opportunistic infections, and other outcome measures among patients who are cared for by clinicians with access to KBMR-HIV, to assess the effect, if any, on the quality of care.  n/a",
The microbiome as a potential mediator of socio-economic disparities in preterm infant neurodevelopmental trajectories from NICU discharge to school age,"The microbiome as a potential mediator of socio-economic disparities in preterm infant neurodevelopmental trajectories from NICU discharge to school age Project Summary/Abstract The goal of neonatal intensive care unit (NICU) care is not just survival of preterm infants, but also intact neurodevelopment for these vulnerable patients. Many factors affect neurodevelopment. Identification of factors that are modifiable at a time point early enough to improve the developmental trajectory of an individual infant is needed. While preterm infants are discharged from the NICU with a certain developmental potential based on their gestational age and clinical course, socioeconomic status (SES) of the home environment can significantly alter the developmental trajectory. Poverty increases risk for neurodevelopmental deterioration, resulting in significant health disparities. The means by which poverty alters neurodevelopment are unknown. The microbiome is influenced by environment and in turn influences brain development. We hypothesize that that the microbiome is a biologic effector of the influence of SES and environment on neurodevelopment. This proposal will focus on two key time points at which the microbiome is exposed to significant environmental alteration – first 2 weeks of life in the NICU and 6-12 months of life in the home environment. Longitudinal clinical data, patient microbial samples, environmental data, and SES data will be collected on established cohorts of preterm infants from five institutions across the United States already investigating the intestinal microbiome of preterm infants. Neurodevelopmental exams will be performed to assess the functional outcome of school readiness. The goal of this proposal is to demonstrate that microbiome development influences neurodevelopment. Furthermore we will identify environmental factors associated with SES that influence the microbiome and thus neurodevelopmental outcomes. Strengths of this proposal include distinctive expertise of the interdisciplinary investigative team in neonatal care, neurodevelopment, microbiome analysis, bioinformatics, economics, and analysis of environmental features of the home environment. Advanced sequencing techniques, spatial analysis of environmental factors (geomapping), and economic modeling will be used to investigate the relationships among SES, environment, microbiome, and neurodevelopmental outcome to identify a time point and possible environmental or microbiome modification to improve outcomes. Beyond increasing social strategies, expanding effective learning models, and mitigating medical needs of at risk infants, understanding and promoting shifts in the microbiome could lead to improved understanding of health disparities and enable interventions to alter infant neurodevelopmental-trajectories in innovative ways. Project Narrative Preterm infants are at risk for poor neurodevelopmental outcome due to their degree of prematurity, hospital course, and home environment. This proposal will study the changes in the bacterial colonization patterns of the infants in the context of their home environment to identify a potentially modifiable factor that may influence brain development and thus school readiness for these vulnerable infants.",
Dynamic Brain Mechanisms of Proactive and Reactive Control in Childhood ADHD,"Dynamic Brain Mechanisms of Proactive and Reactive Control in Childhood ADHD ﻿    DESCRIPTION (provided by applicant): This is an application under the NIH K01 Mentored Research Scientist Development Award Mechanism. The overall goal of the research project is to understand brain mechanisms underlying proactive and reactive control and their relation to individual differences in behavioral symptoms associated with childhood attention deficit hyperactivity disorder (ADHD). Childhood ADHD is characterized by significant impairments in academic and social domains, and deficits in cognitive control are at the core of these impairments. Recent research suggests that cognitive control operates via two distinct modes: proactive and reactive. However, the extent to which proactive and reactive control processes influence behavioral symptoms associated with ADHD remains unknown. This proposal will address this fundamental question by assessing how imaging-defined constructs for proactive and reactive control affect inattention and impulsivity in children with and without ADHD using the NIMH Research Domain Criteria (RDoC) strategy.  The candidate will use a novel systems neuroscience approach to investigate dynamic brain mechanisms of proactive and reactive control in children and their relation to symptoms associated with ADHD. The Specific Aims of this project are: (1) To investigate dynamic causal interactions in brain networks during reactive and proactive control in children, (2) To investigate how aberrant dynamic causal interactions during reactive and proactive control affect impulsivity and inattention in children using the RDoC approach, (3) To examine whether dynamic causal interactions during reactive and proactive control can differentiate children with clinically diagnosed ADHD from typically-developing children, and (4) To explore biomarkers for symptom prediction and classification using multivariate imaging-defined constructs of reactive and proactive control. The proposed studies will deepen our understanding of fundamental brain mechanisms underlying individual differences in cognitive control in children with and without ADHD. It will also advance the use of new computational tools in clinical neuroscience research and provide a systems neuroscience framework for future studies of cognitive control in other neurodevelopmental disorders, including autism and schizophrenia. The candidate will undergo a rigorous education and training plan to increase expertise in clinical aspects of ADHD research, advanced brain network analyses and machine learning algorithms for symptom prediction. The candidate will be mentored and trained by leading experts in the fields of clinical psychology, psychiatry, developmental and cognitive neuroscience, brain network analyses and machine learning. The candidate will also gain critical experience in clinical assessments necessary for successfully working with children with ADHD. Formal coursework and attendance at seminars in psychology, psychiatry, connectomics and machine learning will assist in achieving this goal. Completing the proposed project will enable the candidate to become a successful independent investigator in the fields of clinical and developmental cognitive neuroscience. PUBLIC HEALTH RELEVANCE: Childhood ADHD is one of the most common neurodevelopmental disorders, and is characterized by pervasive deficits in cognitive control. This project seeks to uncover dynamic brain mechanisms underlying two different types of cognitive control and their relation to clinical symptoms associated with childhood ADHD. The proposed research will provide new insights into the childhood ADHD and eventually aid in the diagnosis and evaluation of treatments for this disorder.",
Machine Learning for Health Outcomes and Quality of Care in Low-Income Populations,"Machine Learning for Health Outcomes and Quality of Care in Low-Income Populations PROJECT SUMMARY: Life expectancy and other health outcomes in the United States are associated with income and socioeconomic status. Low-income populations have poorer health outcomes and, unlike high-income populations, outcomes also vary by geography. While these relationships have been described for decades in prior literature, the underlying mechanisms of these connections have not been identified. Understanding the determinants of such health disparities is critical to improving health outcomes and preventing disease. The impact of health insurance on health outcomes in low-income populations is unknown, as it has not been studied empirically on a national scale. The proposed research will be the first ever study to employ randomization of health plans in Medicaid, the government insurance program for individuals who lack resources to pay for health care. We will establish the role of insurance coverage on health outcomes in low-income populations. This will involve a novel data source containing enrollment and health care utilization information for the universe of low-income households in Massachusetts from 2006 to 2015. We are uniquely positioned to study the effect of Medicaid and type of Medicaid coverage as our data contains enrollees who were randomly assigned to plans and those who were not. These data are linked to important health outcomes, including cause of death, birth weight, and APGAR scores. We will additionally exploit our partial random assignment to examine effect modification by quality of care. Disparities exist in quality of care along income lines, and low-income populations tend to have lower quality scores. To accomplish these goals, we propose the creation of a nonparametric machine learning framework for generalizing results from experimental and quasi-experimental studies. This flexible robust methodology will be developed and tailored for our study of health disparities in order to generalize results from within-state studies to i) the full population of low-income individuals within a state and ii) populations of low-income individuals in other states. With average monthly Medicaid enrollment of over 55 million individuals across the country, this project will have significant broad impacts on low-income populations. Our findings and new analytic tools will provide foundational understanding of the role of insurance coverage on health outcomes among low-income populations, including any effect modification by quality of care. Unraveling the complicated relationships between insurance and health outcomes in low-income populations is an essential component toward improving these outcomes. The lack of randomization in most public health studies on disparities has contributed to diverging results and confusion around interpretation for health policy. The development of our machine learning framework for the generalizability of population health studies is innovative as it will revolutionize the ability of researchers to assess the effects of health exposures and interventions. PROJECT NARRATIVE: Health outcomes and quality of care in low-income populations lag behind other groups, and the impact of health insurance on these disparities among low-income individuals is currently unknown. The goal of this proposal is to examine the role of insurance coverage on health outcomes in low-income populations with rigorous new tools in partially randomized data. This will be achieved by developing a novel machine learning framework for the generalizability of experimental and quasi- experimental studies, providing population health scientists with robust methodology to assess the effects of health interventions and exposures.",
Continued development of CellProfiler cell image analysis software,"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",
Development of mosaic mouse models of HCC for genetic interspecies inference,"Development of mosaic mouse models of HCC for genetic interspecies inference DESCRIPTION (provided by applicant): Hepatocellular carcinoma (HCC) remains a menace for human health for the lack of any effective treatment. HCC is usually the end result of chronic liver diseases associated with diverse risk factors. Furthermore, non- alcoholic steatohepatitis (NASH) induced HCC, which is projected to be the leading cause of new cases, remains poorly characterized. Although many mouse models of HCC have been developed, it is unclear how well they represent different subgroups of human HCCs. This research plan proposes to transform HCC animal modeling by establishing a novel in vivo platform to accurately replicate the somatic molecular profiles of human HCC in mice. To do this, three independent HCC mouse models will be exhaustively characterized through exome sequencing and gene expression profiling. Using bioinformatics techniques including machine- learning and network analysis, these datasets will be compared with human HCC datasets from TCGA and the ICGC to identify subgroups of patients with similar somatic molecular profiles to the HCC mouse models as well as refined minimum sets of characteristic genetic aberrations. A derived transposon system will be used to generate mosaic mouse models replicating human HCC genetic subgroups faithfully. These models will enable 1) experimental dissection of the molecular mechanisms underlying distinct etiologies of HCC, 2) systematic assessment of candidate HCC therapies and 3) investigation of therapeutic resistances. This K99/R00 career development award proposal describes a two-year mentored and three-year independent research program essential for the development of Dr. Font-Burgada as an independent investigator. Dr. Font-Burgada received his PhD at University of Barcelona, Spain, for the work he performed to investigate basic chromatin regulatory and epigenetic mechanisms. He then moved to University of California, San Diego where he joined Dr. Michael Karin's laboratory to train in mouse models of cancer and signal transduction. For the accomplishment of this research proposal, Dr. Font-Burgada has designed a strong training and career development plan consisting of: 1- the continued mentorship of Dr. Michael Karin to gain additional expertise in mouse models of HCC and signal transduction, 2- Training in bioinformatics, specifically in methods to identify cancer driver genetic aberrations and network-based approaches for comparative genomic analysis of mouse and human HCCs, to be overseen by co-mentor Dr. Hannah Carter, an Assistant Professor of Medicine, at UCSD. 3- Training in application of emerging transposon vector technologies to generate mosaic mouse models for in vivo analysis of oncogenic pathways. 4- Career development courses and seminars in a supportive academic environment in the Department of Pharmacology at UCSD to complement other aspects of the training program. This training plan will be overseen by an advisory committee comprising 4 members, mentor, co-mentor, and additional experts in mouse models of cancer and bioinformatics, Inder Verma and Trey Ideker, providing key scientific insights and essential guidance in critical steps in Dr. Font-Burgada transition to independence. PUBLIC HEALTH RELEVANCE: Hepatocellular carcinoma (HCC) has a 5-year survival rate of less than 10% and leads to 700000 deaths globally each year. The genetic causes of this disease are poorly understood and the only available targeted therapy extends life expectancy by a mere 3 months. In order to improve these dismal statistics, I am developing a novel class of mouse models capable of reproducing the spectrum of mutations observed in a given human tumor, to enable study of HCC biology as well as systematic testing of therapeutic combinations.",
"Microbiota, Inflammation and Environmental Enteric Dysfunction (MiEED)","Microbiota, Inflammation and Environmental Enteric Dysfunction (MiEED) PROJECT SUMMARY In this application, I am requesting support from a career development award to support my research proposal titled “Microbiota, Inflammation and Environmental Enteric Dysfunction”. I will be undertaking this work with the mentorship of Dr. Jeffrey Gordon (Primary US mentor) at the Washington University, St Louis and Dr. Asad Ali (Primary LMIC mentor) at the Aga Khan University. This project builds on our existing studies of Environmental Enteric Dysfunction (EED), funded by the Bill and Melinda Gates Foundation. The current application aims to improve our understanding of the pathogenesis of EED by studying the evolution of gut microbial configuration in children who have clinical and histological evidence of EED. EED is common in children living in impoverished conditions with limited access to clean drinking water and sanitation. Histopathological changes of EED in small bowel mucosa include alteration in crypt to villous ratio along with lymphocytic infiltration of the villous epithelium and lamina propria. Although studies involving biopsies of small bowel mucosa are critical to study EED, these studies are uncommon because of logistic challenges involving performing endoscopies in field settings in LMICs. We have previously demonstrated in an ongoing BMGF funded study that we are able to safely obtain such biopsies, we now have a unique opportunity to study the relationship between gut microbiome evolution and EED in this cohort. The central hypothesis of the current application is that children with histological confirmation of EED have shared features of a bacterial community which is different from healthy controls and non-EED subjects, and that such changes in bacterial configuration are associated with enteric and systemic inflammation. For testing these hypotheses, evaluation of gut microbiome in healthy and stunted children will be carried out to identify the age discriminatory bacterial taxa in children with and without confirmation of EED. Dr. Gordon will be providing mentorship and experience in gut microbiome and microbiota analysis. Dr. Ali will provide the needed infrastructure of the field site and laboratory facilities, along with linking the microbiome analysis with clinical and histological outcomes of interest. The Aga Khan University is a leading regional research institute with multiple support systems for junior investigators which will be vital for my career transition as an independent scientist. My long term goal is to be the principal investigator of my own laboratory, focusing on studying the gut microbiome and its relationship with communicable and non-communicable diseases. I envision working on microbiota derived therapy for EED, and to find targets in the inflammatory pathways driven by changes in gut homeostasis. PROJECT NARRATIVE Globally, Pakistan has the third highest rate of stunting among children aged < 5 years. Environmental Enteric Dysfunction (EED) is proposed to be a critical factor responsible for chronic growth faltering in children in resource limited settings. This research utilizes an innovative approach to study a program of postnatal gut microbiome development in children and its impact on child growth. This proposal will provide an ideal training platform for a translational scientist, covering the domains of mucosal immunology, histopathology, computational analysis, microbiome analysis and host immune responses. The skills learnt from this project will be critical for the capacity development of both the LMIC institution and the candidate herself.",
Comparative Effectiveness of Treat-To-Target Approach versus Routine Care in Management of Gout,"Comparative Effectiveness of Treat-To-Target Approach versus Routine Care in Management of Gout Gout is a highly prevalent, painful inflammatory arthritis, caused by crystallization of uric acid in joint tissues. Gout flares cause impaired quality of life and physical function, leading to lost work days, disability, high healthcare costs. Patients with gout are also known to be at an increased risk of cardiovascular diseases (CVD), kidney disease, and mortality. Previous studies suggest a potential beneficial effect of urate-lowering therapy on the risk of CVD and renal function. Over the past decade, the American College of Rheumatology and the European League Against Rheumatism recommend a treat-to-target (TTT) approach that lowers serum uric acid (SUA) level below 6 mg/dl to reduce acute gout attacks, based on the upper limit of water solubility of uric acid under normal physiologic circumstances. However, the 2016 American College of Physicians (ACP)’ guidelines for gout management recommend use of urate-lowering therapy but support a ‘treat-to-avoid symptoms’ strategy without monitoring SUA rather than the TTT strategy because of ‘inconclusive’ evidence in the literature. Such discrepancies in treatment guidelines from various societies urge the need for comparative effectiveness research of the treatment strategies for gout.  Rigorous epidemiologic studies utilizing high-quality observational data from electronic health records (EHR) or insurance claims databases can be an important tool for comparative effectiveness research. The primary objective of this 3-year proposal is to provide high-quality, timely evidence on the comparative effectiveness of two different treatment strategies, TTT versus usual care, for management of gout. We will pursue this objective by utilizing the linked Partners’ EHR-Medicare database (2007-2016); this linked database includes all patients aged ≥65 years enrolled in Medicare Parts A/B/D who had ≥1 encounter at one of the Partners Healthcare hospitals. We will have longitudinal, clinically important data on patients’ demographics, body mass index, visit notes, laboratory results including SUA and serum creatinine, as well as all Medicare claims for inpatient and outpatient visits, procedures, and prescription drugs. The two specific aims of this 3-year proposal are: 1) to examine the effect of TTT strategy on the risk of gout flares versus usual care and 2) to assess the effect of TTT strategy on the risk of kidney disease and CVD versus usual care.  Given the substantial prevalence of gout, the suboptimal management of gout and lack of comparative trial of different treatment strategies, this proposed study will make an immediate, important contribution to the management of gout in clinical practice. This work will not only investigate the effects of different treatment strategies on gout flares but also on common comorbidities in patients with gout such as kidney and CVD. Furthermore, this proposed study will advance understanding of how to improve ascertainment of dynamic outcomes and control for time-varying confounding by utilizing sophisticated and innovative epidemiologic as well as bioinformatics methods in a large EHR database linked with Medicare claims. Narrative Gout is a common, painful inflammatory arthritis caused by crystallization of uric acid in joint tissues. Xanthine oxidase inhibitors, allopurinol and febuxostat, are the mainstay of urate-lowering treatment for gout. While rheumatology societies recommend a treat-to-target (TTT) approach that lowers serum uric acid below 6 mg/dl to reduce acute gout attacks, there is currently no clinical data whether TTT approach is better than urate- lowering therapy but no regular monitoring of uric acid levels (i.e., usual care); therefore, this 3-year research proposal examines the comparative effectiveness of the two different treatment strategies, TTT versus usual care, for management of chronic gout in a real-world setting.",
Develop a Dynamic Model that Incoporates Text-mining to Reconstruct Networks,"Develop a Dynamic Model that Incoporates Text-mining to Reconstruct Networks    DESCRIPTION (provided by applicant): Improved understanding of disease mechanisms and drug target identification requires better understanding of how diseases alter cellular processes from the healthy state. Our group has developed an integrative pathway search algorithm that reconstructs networks of active pathways from gene expression and phenotypic profiles. Preliminary studies illustrate that this framework is able to reconstruct networks that include those pathways that should be altered, and how they should be altered, to obtain a desired phenotype. Nevertheless, the current framework may not fully capture transients, such as cycles and feedback loops. Furthermore, cells continuously reprogram gene regulatory networks as they sense changes in their environment. To understand how cells are regulated in response to environmental alterations, time series (i.e., dynamic) data are required. Correspondingly, a dynamic model is required to uncover the mechanisms from time series data. We hypothesize that incorporating domain knowledge and metabolic data into a dynamic model would enhance the accuracy of the genes chosen and in turn improve the prediction of the reconstructed networks. Unlike previous studies that have focused on using the gene ontology information, we propose to incorporate domain knowledge retrieved from the free text. This is significant because a large portion of the genes do not have gene ontological keywords. Additionally, it is often difficult to assess the accuracy of the network structures that have been inferred from experimental data because the underlying ""true"" regulatory network is unknown or unavailable a priori. Therefore, one needs to have a known network structure that can be used to optimize and evaluate the modeling frameworks. Once so optimized, the static and dynamic models will be applied to an experimental cell culture system, which has a perturbed (transfected or silenced) gene, and assessed as to how well each model predicts the resulting, measured phenotypic responses. The cost-effectiveness of the cell culture, in contrast to in vivo animal studies, allows us to establish, with experimental data, which model produces predictions of greater confidence. Having established which model is more predictive, we will apply that model to rats that are maintained on high fat diets, so as to identify the pathways that could be altered to reduce triglyceride storage (steatosis) and inflammation in the livers of these rats. The findings could have implications for identifying potential therapies for steatosis and, perhaps, even non-alcoholic steatohepatitis (NASH). The objectives will be achieved through the following aims: 1) Develop a novel approach that incorporates domain knowledge retrieved from the free text as well as gene expression data to predict cellular or phenotypic responses. 2) Develop an optimized dynamic Bayesian Network to infer gene regulatory networks from time series data. 3) Experimentally validate the model predictions for the cell culture system. 4) Characterize the livers from rats fed high fat vs. normal diets.           n/a",
Investigating Brain Connectivity in Autism at the Whole-Brain Level,"Investigating Brain Connectivity in Autism at the Whole-Brain Level  ABSTRACT: This proposal aims to elucidate the functional organization of the whole brain in Autism Spectrum Disorders (hereafter referred to as autism), a group of neurodevelopmental disorders that affect roughly 1 in 110 individuals born today. I will test the overarching hypothesis that functional coupling between different regions of the brain in autism is generally reduced. Moreover, I will explore the prediction that such reduced connectivity is associated with abnormal behavior. While anatomical and functional evidence support reduced brain connectivity in autism, this has never been tested at the whole-brain level. In this application, I propose to acquire resting-state and stimulus-evoked Blood Oxygenation Level Dependent (BOLD) activity across the entire brain in high-functioning adults with autism and matched healthy control participants. A measure of functional connectivity will be derived from the resting-state BOLD activity, by examining the functional coupling across all regions of the brain in a pairwise manner. In each of 4 specific aims, I will test the following hypotheses: (1) that the autistic brain is generally less connected than normal, but that there is anatomical specificity to this reduction, (2) that the functional responsivity of the entire brain can be examined simultaneously in autism using complex naturalistic stimuli, and can be used to reveal which regions function abnormally in autism, (3) that abnormal resting-state functional connectivity is associated with reduced evoked activity in those same regions, and (4) that the functional properties of broadly distributed brain regions contain information that can be used to predict a diagnosis of autism. Aims 1 & 2 will be carried out during the training phase (K99) of the grant, while Aims 3 & 4 will be completed during the independent phase (R00). The training component will consist of learning state-of-the-art functional imaging methods at the Caltech Brain Imaging Center, together with statistical techniques for pattern classification. Together, these studies will provide the first comprehensive picture of brain connectivity and brain activity in autism, and set the direction for my future career.  PROJECT NARRATIVE: These studies will provide mentored training and research to help better understand brain connectivity in autism. This will be important information for guiding future diagnoses and intervention.",
High Resolution in Single Particle Reconstruction,"High Resolution in Single Particle Reconstruction DESCRIPTION (provided by applicant): The focus of this renewal application will be on the development of single particle cryo-EM structure determination methods that incorporate validation, assessment of alignment errors, and cross-validation of observed conformational variability. We will concentrate on three specific areas: (1) establishment of a well- defined goal function for structure determination, (2) structure refinement methods that incorporate validation of the outcome, and (3) quantitative analysis of conformational variability cross-validated by X-ray model-based simulations.  In (1), we will establish a goal function (a single-valued function of the 3D map and/or projection data) that would have a global extremum for the correct structure and which can be related to intuitive notion of resolution of the map. A goal function with such properties would make possible a critical evaluation of the ability of existing structure determination methods to deliver optimal structures and establish a theoretical basis for unification and rationalization of 3D-EM single particle structure determination methodology. In (2), we will introduce novel quantitative single particle cryo-EM methodology, based on jackknife-d resampling, designed to yield an estimate of alignment errors and eliminate ""reference bias"" that results in artifactual features that are indistinguishable from genuine ones in the absence of external standards. Incorporation of these developments into cryo-EM structure determination algorithms will make possible objective validation of a refined 3D map. They will provide, for the first time, a simple but robust way to eliminate artifacts and will thus increase the level of confidence in cryo-EM results. In (3), we will use our projection data resampling methodology to calculate (directly from the data) eigenvectors characterizing the conformational variability of a structure. We will then develop a deconvolution algorithm that will use this eigenvector information to eliminate from a 3D map the blurring caused by residual alignment errors. We will also use the eigenanalysis to characterize local mobility of a macromolecule and bridge the gap between experimental cryo-EM structure determination and simulations of conformational variability based on physical models. By cross-validating our methodology with the results of molecular dynamics simulations we will provide a novel tool for analyzing the energy landscape of large macromolecules.  Rather than incremental improvements, the methods we propose to develop will put single particle cryo-EM analysis on a new path towards full reliability of the results, eliminating the uncertainty that currently hinder fulfillment of cryo-EM's full potential. To assure multi-platform portability and immediate dissemination, these new methods will be implemented within the SPARX image processing package. PUBLIC HEALTH RELEVANCE: High-resolution cryo-electron microscopy (cryo-EM) has become an important tool for the structure/function determination of large macromolecular complexes. Even at limited resolution cryo-EM maps provide a wealth of structural information, eventually leading to determination of the secondary structure, as demonstrated by our work on the structure of the ribosome. In addition, cryo-EM is a unique structural technique in its ability to detect conformational variability of large molecular assemblies within one sample that may contain a mixture of complexes in various conformational states. We propose development of dedicated data processing and statistical tools for reliable cryo-EM structure determination, particularly in the absence of external information, and for studies of conformational modes of the structure, as directly obtained from the EM data.",
EHR Anticoagulants Pharmacovigilance,"EHR Anticoagulants Pharmacovigilance DESCRIPTION (provided by applicant): The timely identification of previously unknown toxicities of cardiovascular drugs is an important, unsolved problem. In the United States, 20% of the 548 drugs introduced into the market between 1975 and 1999 were either withdrawn or acquired a new ""black box"" warning during the 25-year period following initial approval by the Food and Drug Administration. Adverse drug events (ADEs) are an important cause of morbidity and mortality in patients, yet 95% of ADEs are unreported, leading to delays in the detection of previously unknown ADEs and underestimation of the risk to known ADEs. It is known that Electronic Health Record (EHR) notes and lab results contain ADE information and biomedical natural language processing (NLP) provides automated tools that facilitate chart review and thus improve patient surveillance and post-marketing pharmacovigilance. Optimal use of anticoagulants requires accurate and timely detection of ADEs from EHRs. The objectives for this proposal are to develop ""intelligent"" NLP approaches to extract disease, medication, and structured ADE information from EHRs, and then evaluate extracted ADEs for detecting known ADE types as well as clinically unrecognized or novel ADEs whose pattern or effect have not been previously identified. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: This project proposes innovative intelligent biomedical natural language process approaches to detect ADEs in patients' electronic health records (EHRs), an important step towards ADE surveillance and pharmacovigilance. The focus of this proposal will bon the national priority area of anticoagulants ADE detection, although the algorithms and systems we develop can be extended to other drug classes and diseases. It is anticipated that the data resources, algorithms, and the Anticoagulant Pharmacovigilance Toolkit (APVTK) developed will significantly enhance ADE detection, patient surveillance and post marketing pharmacovigilance.",
Joint Analysis of Microbiome and Other Genomic Data Types,"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",
Enabling Population-Scale Physical Activity Measurement on Common Mobile Phones,"Enabling Population-Scale Physical Activity Measurement on Common Mobile Phones    DESCRIPTION (provided by applicant):   The primary aim of this U01 project is the technical development, deployment, and evaluation of hardware and software technology that will enable population-scale, longitudinal measurement of physical activity using common mobile phones. Mobile phones available in Asia and soon in the U.S. already include internal accelerometers and low-power wireless communication capabilities. This study will investigate how to use these computing devices for accurate measurement of physical activity type, intensity and bout duration. By exploiting consumer expenditures on phones that many Americans will purchase, maintain, and carry, it may be possible to run large-scale studies where the physical activity of hundreds of thousands of participants is measured and remotely monitored for months or years at an affordable cost. Wireless accelerometers designed at MIT will be redesigned so that they can send data to common mobile phones available in 2011. Laboratory testing using the current version of the sensors will be used to compare the relative information gain that can be obtained by combining the phone accelerometer data and data obtained by wearing one or more wireless sensors on different convenient body locations (e.g., in a watch or bag, on a shoe, at the hip, etc.). Optimal but practical configurations of accelerometers will be determined so that software running on the mobile phone can automatically detect specific physical activities such as brisk walking, running, cycling, climbing stairs, sweeping, playing sports, etc. Technical challenges that will be addressed by the sensor and software design include, (1) obtaining practical battery life, (2) acquiring physical activity data at high temporal resolution, (3) enabling person-specific customization of the detection algorithms, (4) addressing practical end-user concerns about ergonomics, comfort, and social acceptability, (5) permitting real-time and low-cost remote monitoring and maintenance for studies with hundreds of thousands of phone users, and (4) enabling use of other off-the-shelf sensor devices, such as heart rate monitors, as they become available. A participatory design process will be employed to develop strategies for obtaining longitudinal compliance from typical phone users. After two rounds of iterative technical development, each with laboratory validation conducted at Stanford, the technology will be deployed with 50 typical phone users for 10 months. Validity relative to self report, acceptability, and longitudinal compliance will be measured.          n/a",
Neural Biomarkers of ECT Response in Schizophrenia,"Neural Biomarkers of ECT Response in Schizophrenia PROJECT SUMMARY This is an application for an NIMH Mentored Patient-Oriented Research Career Development Award (K23) entitled ""Neural Biomarkers of ECT Response in Schizophrenia."" In this application, Dr. Miklos Argyelan proposes a comprehensive plan for transitioning into an independent translational researcher focused on understanding the neural mechanisms of treatment response in schizophrenia by integrating functional neuroimaging with neuromodulatory bioelectric treatment approaches. Despite its effectiveness and intensive research, the mechanism of action for ECT remains unknown, and currently no clinical or biological biomarkers exist to predict response. In patients with schizophrenia undergoing a trial of ECT (with bitemporal electrode placement), the proposed study will use resting-state functional MRI, as well as electrical field modeling as applied to structural MRI scans, to examine the neural circuitry underlying clinical response. Patients will undergo MRI scanning at baseline, and after the 8th ECT treatment. Results of this proposal may lead to biomarkers that will optimize treatment algorithms for schizophrenia with higher efficacy. Identifying target mechanisms would not only improve the current deployment of bioelectric approaches as part of a “precision medicine” approach, but could also lead to the development of novel therapies. This line of research will be conducted under the guidance of mentors who are recognized experts in the biomarker research of schizophrenia (Anil K. Malhotra, M.D.), neuromodulation (Georgios Petrides, M.D., Marom Bikson Ph.D.), neuroimaging of ECT (Chris Abbott, M.D.) and analyzing high dimensional datasets (Jing Sui, PhD.). Concurrently, Dr Argyelan will engage in a comprehensive training program which is fully integrated with the research study in the proposal. The training plan contains three domains with corresponding goals: (1) to gain further expertise in designing and conducting clinical trials in schizophrenia, (2) to expand my knowledge in machine learning algorithms, and (3) to learn more about electrical field (EF) modeling techniques. The combination of training in clinical trials, machine learning and neuromodulation will support the planned research to provide the framework to explore and validate biomarkers of disease and treatment response. The culmination of these training activities, combined with the planned research aims under this award, will prepare Dr. Argyelan to develop into an independent translational researcher and to submit a planned R01 in personalized neuromodulation. PROJECT NARRATIVE Electroconvulsive therapy (ECT) has been consistently shown to be an effective augmentation strategy in the treatment of schizophrenia, however its mechanism of action remains unknown, and there are no clinical or biological predictors to predict response. The overall goal of this K23 proposal is to examine the functional neural circuitry that underlies successful treatment with ECT, which may lead to the identification of biomarkers that will allow for more efficient use of ECT, as well as additional treatment targets for patients with refractory illness. Simultaneously, this proposal will develop the career of the Principal Investigator, Miklos Argyelan, M.D., as an independent translational researcher.",
VASCULAR ENDOTHELIUM AND FLUID SHEAR STRESS IN VITRO,"VASCULAR ENDOTHELIUM AND FLUID SHEAR STRESS IN VITRO The structural and functional responses of vascular endothelium to fluid shear stress will be investigated in vitro using cultured endothelial cells and a special apparatus we have developed for producing controlled fluid shear stress.  The apparatus includes:  a cone-and-plate system that produces both laminar and turbulent flow with shear stress from 10-2 to 100 dynes/cm2; and a parallel- plate system under construction that is specifically designed for live-time microscopy and image analysis of endothelial layers during exposure to shear.  Controllable parameters include:  fluid shear stress level, time history, and degree of turbulence; subcellular matrix; cell preconditioning by shear; biochemcial modulators of cell function; and cell type.  A combination of live-time analysis and end-point fluorescent antibody visualization will provide data on the interrelationships of cell shape change, flow-axis alignment, and cytoskeletal reorganization in endothelial cells exposed to a range of laminar and turbulent flow conditions.  Trans-membrane stimulus-response coupling will be determined using the following assays:  (i) cytosolic ionized calcium levels, as monitored by live-time fluorescence microscopy using fura-2; (ii) intracellular pH; (iii) polyphosphoinositide metabolism; and (iv) prostacyclin metabolism.  Cell-surface-related properties to be measured are:  (i) apicalbasal polarity, as defined by cell surface-selective patterns of integral- and membrane-associated proteins; (ii) functional surface properties, as characterized by tissue factor procoagulant activity and surface adhesiveness for platelets; and (iii) receptor-mediated endocytosis, using the radiolabeled ligands alpha2-macroglobulin and insulin.  This is a collaborative research effort that draws upon the resources, expertise, and experience of the Fluid Mechanics Laboratory, Massachusetts Institute of Technology, and the Vascular Research Division, Department of Pathology, Brigham and Women's Hospital.  The research sytem used in this program, comprised of accurately-controlled fluid shear stress apparatus and well-defined cultured endothelial specimens, should yield valuable information on the mechanisms by which fluid shear stress influences vascular endothelium.  Such information would provide new insights into vascular pathology and the pathogenesis of vascular diseases such as atherosclerosis and thrombosis.  n/a",
Developing data tools to reduce CVD disparities via Health Information Exchanges,"Developing data tools to reduce CVD disparities via Health Information Exchanges ABSTRACT CVD disparities across the race/ethnic and socioeconomic gradients are exacerbated by barriers to receiving guideline-based primary or secondary preventive treatment—such as appropriate blood pressure, dyslipidemia, and type 2 diabetes treatment.1–6 Most patients not receiving guideline-based treatment are actually insured and have seen a primary care provider in the past year.1 To reduce CVD disparities by better targeting disease prevention and treatment, healthcare administrators and county departments of public health have begun pooling data resources across healthcare and public health systems—such as across clinics, emergency rooms and hospitals, pharmacies, laboratories, and administrative datasets.7–9 The idea behind pooling such datasets is to better identify persons most in need, and direct targeted interventions to them. Solano County, California, a medium-sized, diverse, low-income county, has developed one of the first, and most comprehensive health information exchanges (HIEs), including: (i) electronic health record data from all emergency rooms, hospitals, primary care and specialty clinics and care facilities in the county; (ii) labs from all laboratory service providers; (iii) prescription details from all pharmacies; (iv) validated social determinants of health surveys administered in clinics; and (v) administrative datasets, including welfare, disability, housing, and geocoded neighborhood features. While several other counties are following suit to develop large, secure HIEs across healthcare and public health systems, a key challenge remains: how to cheaply, accurately, and rapidly analyze HIEs to identify which persons should be targeted for interventions. Without reliable, user- friendly, cost-effective, and generalizable data analysis programs, counties are unable to use the massive data at their disposal to address preventable causes of morbidity and mortality. The objective of this application is to apply our unique machine-learning innovations to develop open-source programs that can enable counties to identify persons at high risk for preventable CVD events and deaths. We will test the hypothesis that electronic health record data alone are insufficient to provide accurate risk prediction for preventable CVD events and deaths. Rather, we believe that key survey and administrative data providing information on social determinants of health will improve identification of high-risk patients. To test our hypothesis, we will develop and validate open-source, generalizable programs to: (Aim 1) rapidly identify persons in need of improved primary and secondary prevention of CVD by systematically comparing the performance of three alternative machine learning approaches to read HIE data, as compared to human clinician chart reviewers; and (Aim 2) perform multi-level risk assessment by automatically calibrating and validating models of CVD event risk, utilization and cost to HIE data, to identify the added value of administrative and social determinants data as compared to clinical or claims-based data alone. Our work will produce generalizable software tools for counties across the country to analyze HIE data and reduce preventable CVD disparities. PROJECT NARRATIVE Cardiovascular disease (CVD) disparities are exacerbated by inadequate guideline-based treatment of CVD risk factors. Furthermore, risk adjustment models currently used to target interventions and pay for healthcare services only use claims-based data such as demographics and clinical diagnostic codes, ignoring social determinants of health. Our research will rigorously develop and test novel machine learning methods that incorporate social determinants data from large Health Information Exchanges, producing novel data tools that will enable health systems nationwide to better detect individuals who could use improvements in their preventive therapy for CVD, and improve risk adjustment models to identify persons at high risk for preventable healthcare utilization and cost.",
Systems Biology for Studies of Cognition in Down Syndrome,"Systems Biology for Studies of Cognition in Down Syndrome    DESCRIPTION (provided by applicant): The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50. Therefore, DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. DS is due to an extra copy of human chromosome 21 (chr21) and the increased expression of genes encoded by it. Chr21 genes impact multiple pathways; there is cross talk among the pathways and functional interactions among chr21 genes. To address these complexities in pursuit of therapeutic targets, we propose a systems approach that is: (1) Hypothesis driven: Based on the functions of chr21 proteins and our behavioral/ molecular analysis of mouse models, we hypothesize that the cognitive deficits in DS are caused by perturbations in MAPK, PI3K and calcineurin pathways and NMDA and GABAA receptor (NMDAR, GABRA) function. We will bias our assays towards specific pathway components. (2) Discovery driven: in a less biased screen, we will use Reverse Phase and antibody arrays to assay for additional perturbations in 10s to 100s of samples and targets. (3) Multidisciplinary: The PI and co-PIs provide expertise in molecular biology, mouse behavioral and pharmacological analysis, and mathematical modeling. The goals of this proposal are to test our hypothesis, to develop new hypotheses by identifying and predicting additional critical pathway perturbations, and to identify potential targets for therapeutics. To fulfill these goals, we propose the following specific aims: 1. Define basal perturbations in candidate pathways. Basal genotype-specific molecular profiles will include 48 protein measurements made in nuclear, cytoplasmic and membrane fractions, from hippocampus, cortex and cerebellum, from five DS mouse models. 2. Define perturbations, in the same pathways in the same models, after behavioral and pharmacological stimulation by exposure to Contextual Fear Conditioning and treatment with NMDAR and GABRA antagonists. Genotype/stimulation-specific molecular profiles will be correlated with behavior. 3. Describe key pathway features and predict results of novel perturbations using Fuzzy Cognitive Maps, supported by Inductive Machine Learning and Neural Networks. Data and pathways will be posted to our Chr21 Gene Function/Pathway database, http://chr21db.cudenver.edu. PUBLIC HEALTH RELEVANCE The incidence of Down syndrome (DS) is one in 700 live births, the life expectancy is now >50 years, and the average IQ is approximately 50, making DS is a significant social and medical issue. Many phenotypic features of DS, including cognitive deficits and neuroanatomical abnormalities, develop postnatally, arguing that effective therapeutics may be feasible. This application combines mouse behavior, pharmacology and molecular analyses with computational modeling. The goal is to define key abnormalities in pathways critical for learning and memory and to identify effective targets for development of potential therapeutics.          n/a",
Novel Statistical Methods for Human Gene Mapping,"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",
A New Paradigm for Hypertension in the Elderly- Beyond Age,"A New Paradigm for Hypertension in the Elderly- Beyond Age DESCRIPTION (provided by applicant): Over 60% of adults age � 65 years have high blood pressure (BP), but optimal management of high BP in the elderly remains controversial. Contrary to evidence in middle age that lowering BP is clearly beneficial, data in older adults are inconsistent and high BP may not be a risk factor in all elders. We recently reported that, among participants in the National Health and Nutrition Examination Survey age e65 years, high BP was a risk factor for all-cause and cardiovascular (CV) death only among persons in better health status (defined as fast walking of a 20-ft walk test). In contrast, high BP was not a risk factor among slow walkers. Additionally, the benefit of lowering BP in all elders remains an issue of debate; a recent meta-analysis in persons age 80 years and older reported no benefit of BP treatment on mortality, and significant heterogeneity across trials. Finally, there is growin concern for potential harms associated with treatment to lower BP. Excessive lowering of BP, particularly diastolic, has been associated with increased risk for death and cardiovascular events in some studies. In the proposed research, we propose a novel paradigm where the associations of BP with adverse outcomes in older persons are considered in the setting of the complex aging process. Our long-term goal is to reliably identify elderly persons in whom BP treatment is beneficial and those in whom treatment is ineffective or even harmful, by defining subpopulations of similar health status. Specifically, aim 1 proposes to elucidate factors from four domains (functional, cognitive/mental, self-rated health, and physiologic) that can identify elderly persons in whom high systolic BP is strongly associated with higher risk for death and CV events, and those in whom it is not, using data from three NIH-funded cohorts: Cardiovascular Health Study (CHS), Health Aging and Body Composition (Health ABC) and Sacramento Area Latino Study of Aging (SALSA). In aim 2, we will evaluate the role of diastolic BP across level of health status. Finally, based on findings from these observational cohorts, in aim 3 we will evaluate whether these factors can identify elderly persons in whom treatment to lower BP is of maximum benefit in two randomized controlled trials: the Systolic Hypertension in the Elderly (SHEP) and the Secondary Prevention of Small Subcortical Strokes (SPS3). Since participants in trials are healthier than the U.S. population, we will also evaluate the effect of treatment in the observational studies, using state-of-the-art causal inference methods, which can correct for the bias of standard analytic approaches. Completion of these aims will substantially advance our understanding of the importance of high BP in older adults; will improve our ability to identify elderly persons who will benefit from BP treatment; will allow a systematic understanding of groups in whom evidence for BP treatment is lacking; and will guide design of future trials of hypertension in elderly adults. PUBLIC HEALTH RELEVANCE: Treatment of high blood pressure in elderly persons remains controversial. This proposal focuses on developing systematic methods to understand which elderly persons benefit from lowering blood pressure. This question is of great relevance as U.S. elders are living longer than any prior generation, and the majority have high blood pressure.",
A Real-Time Feedback System For Radiological Reporting To Reduce Diagnostic Varia,"A Real-Time Feedback System For Radiological Reporting To Reduce Diagnostic Varia     DESCRIPTION (provided by applicant): Breast cancer affects 1 in 8 women in the United States. It is the second leading cause of cancer deaths amongst women, resulting in 39,000 deaths per year. As a result, much work has been done to optimize the evaluation of cancer through mammography. However, assessing mammograms is limited by variations among practitioners in practice, including deficiencies in their reporting of these imaging examinations as well as in their interpretations. Two main sources of these variations in practice are incompleteness of the radiological observations reported to characterize the abnormalities seen in images and inconsistency of these observations with respect to the radiologists' overall impression. We hypothesize that the quantification and enforcement of completeness and consistency of radiological observations will improve the positive predictive value of diagnostic mammography. We propose a decision support system that provides feedback to radiologists during the reporting of their radiological observations. We will develop this system by creating novel statistical models to link radiological observations, computational imaging features, and disease to recognize incompleteness and inconsistency in reporting. We will then harness these models to create a quantifiable metric of observation quality. We propose a research plan with the following specific aims: (1) To characterize breast lesions seen in mammography images by capturing computationally- derived (""quantitative"") imaging features and radiologist-derived observational (""semantic"") features, (2) develop a radiological Decision Support System (DSS), (3) evaluate our DSS in mammography practice. Our methods will lead not only to better diagnostic accuracy and positive predictive value of diagnostic mammography, but they will be extensible to other imaging domains and possibly to other medical domains where diagnostic reasoning is documented in dictated reports.         PUBLIC HEALTH RELEVANCE: The results of this project have the potential to impact the consistency and completeness of mammography reporting methods. This will potentially positively impact communication between referring physicians and mammography specialists as well as provide better positive predictive value of mammograms. It is relevant to better diagnosis and treatment of breast cancer.            ",
Image analytics prediction of corneal keratoplasty failure,"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",
"The Electronic Medical Records and Genomics (eMERGE) Network, Phase III","The Electronic Medical Records and Genomics (eMERGE) Network, Phase III ﻿    DESCRIPTION (provided by applicant): This application from the Group Health (GH)/University of Washington (UW) eMERGE team proposes specific aims designed to advance integration of genomic data into clinical practice with a focus on clinical discovery and implementation on Mendelian forms of colorectal cancer and/or polyposis (CRC/P) and incidental findings in other actionable genes. Our aims will also allow us to address challenges involved in bringing genomic medicine into standard medical care. Our focus on CRC/P, and quantitative traits and incidental findings (IF) in other actionable genes represents a unique opportunity to move the field forward towards the goal of bringing genomic medicine into effective, standard medical practice in an everyday community practice setting. We have 3 Aims. Aim 1: Genomic medicine discovery and implementation focused on CRC/P, Triglycerides (TG), and neutrophil count (NPC). We proposed sequencing of 1000 CRC and 1000 Asian ancestry participants, to achieve sub- aims of understanding the genetic basis of CRC, TG, and NPC. Aim 2: Integrate genomic information into GH-wide clinical care and the EMR. We will develop intuitive, comprehensive reports to return CRC and other genes deemed actionable by the American College of Medical Genetics and Genomics (ACMG). We will incorporate stakeholder input and then to implement integrated processes and tools into an integrated delivery system with a focus on CRC/P and Long QT syndrome. We will develop and evaluate educational outreach and online resources. Aim 3: Evaluate the effectiveness and economic impact of result return to patients and their families. We will implement a novel tool to increase family communication of CRC genetic results and evaluate the economic impact and cost effectiveness of this tool as well as of returning IFs. Completion of the work in this eMERGE III proposal will guarantee that the Seattle site remains an engaged and effective leader in the eMERGE network in support of NHGRI's mission to ensure that barriers to successful integration of genomic medicine in clinical care are overcome. PUBLIC HEALTH RELEVANCE: This eMERGE III proposal builds on past discoveries and research designed to translate genomic advances into clinical care involving clinicians, patients and families. This phase focuses on traits associated with preventable health concerns: colon cancer, triglycerides, and immunity. We address optimal methods to share information across families and whether other information found by genomic tests impact the care, health, and medical costs of individuals.",
ARTERY Outcomes: tAilored dRug Titration through artificial intElligence: an inteRventional studY,"ARTERY Outcomes: tAilored dRug Titration through artificial intElligence: an inteRventional studY Need: Nearly half (34 million) of all hypertension (HTN) patients have their blood pressure (BP) uncontrolled. Despite medication and life-style management, the cost of HTN-associated hospitalizations is $113 billion, or 15% of all hospital costs. HTN is the leading cause for stroke, heart failure (HF) and myocardial infarction (MI) hospitalizations. Clinical trials have shown that active pharmacological treatment management of HTN to BP goal reduces the incidence of stroke by 35-40%, MI by 15-25%, and HF by up to 64%.  Solution: In response to the national “epidemic” of uncontrolled HTN, Optima Integrated Health has developed optima4BP. optima4BP is an artificial intelligence (AI) that transforms the episodic and reactive nature of uncontrolled BP pharmacological treatment management into a process that is continuous, proactive, and personalized. The innovation was developed with the physician in mind by simulating the in-office clinical reasoning treatment decision process. optima4BP is a physician decision support aid that safely and when needed optimizes the pharmacological treatment for HTN. optima4BP is interoperable in real-time with the EpicÒ Electronic Health Record (EHR), constantly evaluating the efficacy of patients’ current treatment and the requirement for optimization. When a treatment optimization is needed, optima4BP communicates directly with the treating physician by providing a recommendation in the EHR In-Basket that can be accepted or declined.  Goal of Direct to Phase II: ARTERY Outcomes [tailored drug titration through artificial intelligence: an interventional study] is a 12 months follow-up, randomized clinical trial (n=300) that: Evaluates optima4BP’s safety and efficacy in improving HTN control [Aim 1], and Ensures Data Systems Maintenance [Aim 2].  Aim 1. Evaluate optima4BP’s safety and efficacy in improving HTN control. We propose to conduct a randomized clinical trial (ARTERY Outcomes) at UC San Francisco Medical Center (UCSF MC). We will investigate the safety and efficacy of optima4BP in improving BP control compared to standard of care (SoC). The primary end-point will examine the reduction in systolic BP (SBP) between in-office start and end of study. Milestone: optima4BP reduces SBP by >6 mmHg than SoC. The safety of using optima4BP will be investigated as a secondary outcome in the context of reported adverse events (AEs).  Aim 2. Ensure data systems maintenance (DSM). DSM is a critical activity that includes optimization, error correction, deletion of discarded features and enhancement of existing features. UCSF MC and Optima IT teams will address (1) Data Acquisition upgrades and patches of any system/component within the data flow; and (2) Surveillance management that addresses systems errors, and performs audits/upgrades on the data repository [data warehouse]. Milestone: Ensure the validity of the collected-processed-analyzed data.  Commercial Application: With a growing need for value-based care, optima4BP is strongly positioned to support this specific care coordination model. Our goal is to simplify the care management of high blood pressure (BP) with the goal of reaching BP control, demonstrated to reduce the incidence of stroke, heart failure, and myocardial infarction. We will investigate the benefits of optima4BP artificial intelligence that transforms the episodic and reactive nature of uncontrolled BP pharmacological treatment management into a process that is continuous, proactive, and personalized.",
A New Paradigm for Illness Monitoring  and Relapse Prevention in Schizophrenia,"A New Paradigm for Illness Monitoring  and Relapse Prevention in Schizophrenia DESCRIPTION (provided by applicant): Schizophrenia is a severe psychiatric disorder that is associated with staggeringly high individual and societal costs. Although the illness is typically chronic, it is not static, and the majority of people with schizophrenia vacillate between full or partial remission and episodes of symptomatic relapse. Relapses increase one's risk for major problems including homelessness, incarceration, victimization, and suicide. Moreover, patients with schizophrenia who relapse are three to four times more costly than those who do not. The goal of the proposed project is to develop and evaluate a novel paradigm for illness monitoring, detection of early warning signs, and relapse prevention in schizophrenia. Our interdisciplinary team of clinical researchers and computer scientists proposes to develop a mobile system that uses smartphone-embedded sensors (i.e. microphone, accelerometer, GPS, light sensor) coupled with computerized self-reports, to track a range of behaviors (i.e. paralinguistic aspect of speech, physical activity, location, sleep, mood, psychotic symptoms) that are relevant to relapse in schizophrenia. Using machine learning techniques, the system will leverage behavioral data and patient self-reported clinical updates to generate personalized early warning models. The models will evolve with use of the system over time, focusing on variability from one's typical behavioral patterns to calibrate a unique patient relapse signature. Treatment teams will be informed about patients' clinical status via secure website. When the mobile system ""flags"" trends that are consistent with one's relapse signature, it will trigger patient functions and provider functions (i.e. real-time notification, prompts to initiate contact, time-sensitive treatments) to help prevent progression to full psychotic relapse. In Phase 1 of the project, we will integrate multi-modal sensor, ecological momentary assessment, and machine learning technologies into a unified smartphone system that will be tested and refined in laboratory settings. In Phase 2, we will conduct field trials with individuals with schizophrenia i real-world conditions to identify and resolve technical and mechanical problems, adapt the software, and maximize system usability. In Phase 3, we will conduct a randomized 12- month trial of the monitoring and prevention system compared to treatment as usual in 150 outpatients with schizophrenia that are at high-risk for relapse. If successful, our proposed system can be rapidly made available to a population that is in dire need of more effective resources, and can serve as a template for mobile monitoring and treatment systems for a range of clinical conditions with an episodic nature. PUBLIC HEALTH RELEVANCE: An effective multi-modal mobile monitoring, early detection, and intervention system for schizophrenia could alter illness trajectory, mitigating the acute and long term impact of psychotic relapses on patients, their caretakers, and communities. A broadly available system could radically change when, how, and to what effect treatments are delivered, allowing for a paradigmatic shift from reactive to preemptive care for schizophrenia.",
Syndromic Surveillance Data Exchange and Analysis,"Syndromic Surveillance Data Exchange and Analysis DESCRIPTION (provided by applicant):   Most disasters are readily identifiable but health care disasters may not be as readily recognized, particularly early in their evolution. Syndromic surveillance, one kind of health care disaster, is the term coined for systems that use data that precede diagnosis to recognize disease outbreaks with sufficient specificity to warrant a public health response. Algorithms designed for early detection of health care disasters that rely solely on temporal trends may not be specific enough and several investigators have begun to incorporate geospatial clustering into the pattern recognition algorithms in order to improve specificity. Knowing the specific geographic location of the patient's home address would allow easy identification of a patient in many cases, however, we propose to develop and characterize pattern recognition algorithms that operate on deidentified data in order to protect patients' privacy. We will carry out this work using actual data from two different cities in order to increase the chance that the approach developed can be generalized. The overall approach would be to utilize established pattern recognition algorithms developed at Children's Hospital in Boston, and modify them as needed to accommodate use of deidentified data. Then we will compare the detection characteristics of the algorithm using identifiable data and deidentified data in order to determine the effect of using deidentified data. n/a",
Systems Biology Analysis of Cardiac Electrical Activity and Arrhythmias.,"Systems Biology Analysis of Cardiac Electrical Activity and Arrhythmias. Cardiac arrhythmias are a leading cause of morbidity and mortality in the United States. Abnormalities in heart rate, cardiac conduction (PR and QRS) and repolarization (QT) measured on the ECG predispose to the clinically important cardiac arrhythmias of atrial fibrillation (AF) and ventricular fibrillation (VF) / sudden cardiac death (SCD). We examine the genomic basis of these ECG endophenotypes in order to deconstruct arrhythmias into more proximate traits and discrete components, allowing us to better understand underlying mechanisms, provide insight into arrhythmia generation, and help target development of novel therapies.  The molecular architecture of cardiac electrical activity and arrhythmias is not fully understood, but likely involves genomic, epigenomic, and environmental influences. Over the past 10 years, we have identified numerous common loci associated with cardiac electrical activity and arrhythmias, yet these common variants account for only a portion of the heritability of electrophysiologic and arrhythmic phenotypes. The agnostic examination of genotype-phenotype associations employed in genome- wide association studies (GWAS) does not incorporate knowledge of functional genomic regions or important biologic relationships. Additionally, we currently lack an understanding of the molecular mechanisms connecting mostly intergenic and intronic GWAS signals to phenotype. We therefore hypothesize that a systems biology approach integrating genetic sequence variation with omic data (epigenomic, transcriptomic, and proteomic data) will uncover novel associations and elucidate biologic mechanisms associated with arrhythmia-related phenotypes. We further hypothesize that examining the simultaneous association between sequence variation and multiple cardiac electrophysiologic phenotypes will help uncover additional novel mechanisms associated with cardiac electrical activity and arrhythmias.  TOPMed's combination of rich phenotype data, with whole genome sequence (WGS), epigenomic, transcriptomic, and proteomic data, provides a unique opportunity to more comprehensively explore these hypotheses. We leverage sequence, omic, and phenotype data from multiple cohort studies to efficiently and cost-effectively examine and dissect association of omic factors with cardiac electrophysiology and arrhythmia risk. Our application is an ambitious yet eminently feasible effort that integrates clinical, genetic, and systems biology expertise. We aim to discover associations using omics data (Aims 1 and 2) and elucidate specific genes and biologic pathways underlying these associations (Aims 3 and 4). Our ultimate goal is to identify pathways, genes, and genetic variation that are clinically relevant, and therefore potentially the target of new therapies, diagnostics, or risk predictions. Narrative Cardiac arrhythmias are a major cause of morbidity and mortality in the United States. This proposal aims to use genomic, epigenomic, transcriptomic, and proteomic data, combined with complex systems biology and pleiotropic analyses, to better understand the underlying pathways and genes involved in normal electrophysiology and arrhythmia formation. The identification of biologic factors that influence cardiac electrical activity and arrhythmias will provide insight into the mechanisms of arrhythmia generation, and perhaps identify better targets for drug development and prevention.",
2D affinity and frequency of antigen specific Tregs,"2D affinity and frequency of antigen specific Tregs ﻿    DESCRIPTION (provided by applicant): Regulatory T cells (Tregs) are critical for proper control of the immune response and play a clear role in regulation of autoimmune disease. Further highlighting their importance, Tregs provide an antigen specific therapy that is currently being evaluated in preclinical and clinical trials. Although they are of unquestioned value, it is difficult to assess Treg specificity for antigen. In fact, many experimental protocols make use of non-specific TCR stimuli such as anti-CD3/anti-CD28 for their activation, and typical assessments of specificity such as peptide: MHC Class II tetramers and functional readouts are not especially effective when applied to Tregs. As TCR specificity and affinity are crucial to any T cell functional response, we need to understand what affinity range works best for optimal Treg use as well as for their differentiation. Our lab is in a unique position to examine questions on TCR specificity and affinity because we have developed a novel assay system based on two dimensional (2D) micropipette technology that provides the most sensitive means currently available to assess these parameters. The prevalent view of thymic derived Tregs (tTreg) in terms of affinity is that their repertoires are comprised of the highest affinity TCRs that escaped negative selection; however, our preliminary data has identified a range of affinities of tTregs specific for myelin oligodendrocyte glycoprotein (MOG). Instead of driving thymocyte negative selection, MOG supports development of thymic derived MOG specific Tregs. We propose that these Tregs will be of therapeutic use and based on our preliminary studies, propose the following two aims to track Treg specificity, location, kinetics, stability, and potency during chronic and relapsing/remitting demyelinating disease. Aim 1: To define MOG-specific Treg affinity and frequency during demyelinating disease- Aim 2: To determine Treg specificity and lineage stability for MOG- PUBLIC HEALTH RELEVANCE: Regulatory T cells control the extent of adaptive immune responses, are crucial for the prevention of autoimmune diseases, and play a defined role in human health. Our studies will address a currently unmet need by determining Treg affinity and specificity for myelin.",
Web-based Resource on Evidence-based Dentistry,"Web-based Resource on Evidence-based Dentistry    DESCRIPTION (provided by applicant):       The intent of this proposal is to develop a dental informatics resource to support evidence-based dental care. Evidence-based dentistry is an approach of integrating the scientific basis for clinical care, using the best available scientific evidence, with clinical and patient factors, to enable practitioners and their patients to make the best possible decision(s) about dental care. It is a means for disseminating scientific information to dental health care workers so that they can access the best available scientific evidence. To facilitate the implementation of evidence-based dentistry within the profession, the American Dental Association Foundation, using the personnel and support of the American Dental Association, will employ an interdisciplinary team to develop an Internet-based resource on evidence-based dentistry that will be available to all dental professionals, allied health care workers and the general public world wide. This resource will include a registry of clinical topics of interests to dental professionals, a searchable database of systematic reviews on topics related to dentistry, critical appraisal and summaries of systematic reviews written for dental professionals, and summaries of systematic reviews written for the general public. These resources will assist dental health care workers in making evidence-based dental treatment decisions and will provide evidence-based information for patients on dental treatment options.          n/a",
SAPHIRE--A CONCEPT-BASED APPROACH TO INFO RETRIEVAL,"SAPHIRE--A CONCEPT-BASED APPROACH TO INFO RETRIEVAL The major goal of this project is to develop and evaluate innovative approaches to information retrieval (IR) in the biomedical domain. Building on the initial work done by the Principal Investigator (PI) with the SAPHIRE Project and taking advantage of the efforts of the Unified Medical Language Systems (UMLS) Project, we aim to design and test new methods for automated indexing and retrieval.  The underlying thesis of the SAPHIRE approach to IR is movement of information representation from the level of terms to that of concepts.  Terms, such as MeSH entries, are surface string representations of underlying concepts.  A problem with their use in representing concepts is that they cannot account for the different ways a concept may be expressed in medical texts or information system queries.  SAPHIRE is a first step in the direction of concept-based IR, and we plan to investigate several enhancements to this approach.  The major goal will be achieved with six separate but interrelated tasks:  1. Develop methodology for evaluation of IR systems in laboratory and clinical settings.  2. Assess the utility of computational linguistic approaches to concept discovery in text using constrained natural language processing and knowledge base construction.  3. Refine strategies for automated indexing of a wide variety of textual material, including abstracts, full text of articles, textbooks, and hypertext.  4. Explore different user interfaces, aiming to allow optimal retrieval for both novice and expert users.  5. Assess the use of semantic relationships between concepts in indexing and retrieval.  6. Integrate the SAPHIRE approach with other programs, such as the CODEX system and Explorer-2, and scale up to large text collections.  In the course of the project we will create an IR system that will help meet the information needs of busy health care providers.  Such a system should have a diverse variety of content available as well as quality indexing to represent content accurately.  It should also feature retrieval capability that is fast and easy to use.  In this grant, we propose to iteratively build an IR system that utilizes concept-based probabilistic indexing and retrieval, and evaluate it each step along the way in laboratory as well as real world settings.  n/a",
Understanding the role of the Complement Proteome in progressive Diabetic Kidney Disease,"Understanding the role of the Complement Proteome in progressive Diabetic Kidney Disease PROJECT SUMMARY / ABSTRACT There is a critical need to identify novel mechanisms of diabetic kidney disease (DKD) that will provide targets for new interventions. Chronic inflammation is one plausible mechanism. Using untargeted high-throughput aptamer proteomics, our recently published study has shed new light on specific, key inflammatory drivers of DKD. This was a large prospective three-cohort study that identified a novel and extremely robust circulating signature (KRIS) associated with risk of ESRD in diabetes. Our pilot study points to the data-driven connection between circulating KRIS and urinary profiles of the Complement pathway. Our hypothesis is that the Complement involvement in the kidney is a downstream effect of the systemic inflammatory processes mediating an increased DKD risk. The overarching goal of this proposal is to provide a high-resolution view of the involvement of the Complement proteome in progressive diabetic kidney disease. Aim 1 will comprehensively evaluate the etiological role of the urinary Complement proteome in progressive DKD leading to ESRD. This evaluation will leverage a prospective two-cohort population of Joslin Kidney Study (JKS) participants with an overt DKD at baseline followed for 10 years (primary outcome – incident ESRD). Measurements will utilize an aptamer proteomic technology (SOMAscan). Aim 2 will extend generalizability of the urinary Complement proteome to earlier DKD stages. The proposed study will be conducted in participants of the Preventing Early Renal Loss (PERL) clinical trial with predominantly normal renal function at baseline followed for 3 years (primary outcome - renal slope). Aim 3 proposes to gain direct insight into the intra-renal Complement proteome by targeted and untargeted protein studies in diabetic kidney tissue (Susztaklab Biobank). This project focuses on a significant public health problem, leverages the progressiveness of the disease, employs an innovative proteomic technology and stems from strong preliminary data. Advances in this project will pinpoint missing key components of DKD etiology, thereby accelerating drug development strategies for patients with diabetes. PROJECT NARRATIVE Diabetes accounts for approximately 45% of prevalent ESRD cases in the United States, therefore new interventions to prevent or decelerate development of kidney failure are critical in order to improve the health of patients with diabetes who comprise a large sector of the US population. This study will advance our knowledge regarding the etiology of diabetic kidney complications evaluating specific components of systemic (KRIS) and local, kidney inflammation (Complement). These advances offer long-term potential for the development of new therapies that will ultimately improve clinical outcomes of patients with diabetes.",
Defining Novel Cellular Correlates of Protection Against Human Malaria by CyTOF,"Defining Novel Cellular Correlates of Protection Against Human Malaria by CyTOF Abstract Malaria remains a great public health challenge that has resisted world-wide control efforts. The malaria parasite's intracellular life-cycle inside red blood cells (RBC) and its ability for antigenic variation have thwarted vaccine development. Immunity to malaria is short-lived and requires constant exposure to the parasite. Naturally acquired immunity is gained by residents in malaria endemic areas, which protects them from severe malaria and reduces the risk of reinfection. All adaptive arms of the immune system, namely T and B cells can contribute to clinical immunity against different stages of the parasite cycle, both in humans and in mouse models of malaria. Passive transfer of serum from clinically immune individual can protect susceptible patients, establishing the importance to antibody responses in protection. Yet, how protective antibody responses are achieved is unknown. Current vaccines against the deadliest form of the malaria parasite, Plasmodium falciparum (Pf), are only partially protective and confer only limited protection over time. This proposal builds on the study of a cohort of African patients that allowed us to capture varied levels of clinical immunity. Using high throughput unsupervised analysis of peripheral blood mononuclear cells and plasma from clinically protected versus susceptible patients, we discovered the presence of an expanded subset of memory CD4+ T cells. Frequencies of these cells also correlated with higher plasma parasite-specific opsonizing Abs. We hypothesize that the memory CD4+ T cells are essential for long-lived immunity against malaria by promoting optimal protective Ab responses. The current proposal will explore the functional attributes of these memory CD4+ T cells and establish the characteristics of these highly protective Abs that develop in clinically protected patients. Public Health relevant statement This project investigates the development of natural clinical immunity against malaria, a leading cause of morbidity and mortality in humans worldwide. We propose to investigate how protective immune response against this deadly parasite develops in infected patients living in African endemic area. No good vaccine exists and very little is known on how exactly natural immunity against this parasite develops in infected patients. Thus there is a true need to understand the mechanisms accounting for these observations and how we may modulate the immune response to achieve control of this parasite in endemic area. Our studies will inform vaccine and adjunctive therapy.",
"Dynamic, real-time prediction of alcohol use lapse using mHealth technologies","Dynamic, real-time prediction of alcohol use lapse using mHealth technologies ﻿    DESCRIPTION (provided by applicant): Available psychosocial and pharmacological treatments for alcohol use disorder are effective at establishing abstinence. However, the vast majority of patients relapse within a year and often within the first few months following treatment. Patients often fail to detect dynamic changes in their relapse risk. Furthermore, the majority of patients fail to adequately sustain use of skills developed during treatment and/or through continuing care. Well-established theoretical models indicate that alcohol and other drug use lapse risk is a dynamic, non-linear function of both distal, relatively static, patient characteristics and often moment-by- moment dynamic changes in proximal, precipitating risk factors. However, comprehensive, precise assessment of dynamic risk indicators in real-time has not been possible until very recently. Furthermore, innovative methods from predictive analytics have not been applied to the lapse risk prediction problem. The broad goals of this project are to develop, validate, preliminarily optimize, and deliver a dynamic, real-time lapse risk prediction model for forecasting alcohol use among abstinent alcoholics. To pursue these goals, we propose to follow 200 patients for three months during or following completion of standard of care treatment for alcohol use disorder. We will measure well-established distal, static relapse risk indicators on study intake. More importantly, we will use innovative mHealth technology to densely sample dynamic risk indicators including patient physiology, subjective experience, and behavior daily for three months using smartphones and wearable biometric sensors. Data obtained for these static and dynamic risk indicators will provide the foundation to accomplish the following Specific Aims: 1. Assess burden (feasibility, cost, and patient acceptability) to collect innovative, densely sampled risk indicators via smartphone and wearable sensors. 2. Use machine learning methods to develop, train, and validate a real-time quantitative lapse risk prediction signal based on static and dynamic risk indicators. 3. Use innovative Markov decision process models to optimize decisions about if, when, and how to provide additional treatment or support. 4. Integrate and deliver risk prediction and decision model within the Comprehensive Health Enhancement Support System for Addiction (A-CHESS) program. These project aims position A-CHESS to make relapse prevention and recovery support, information, and risk monitoring available to patients continuously. Compared to conventional continuing care, A-CHESS will provide personalized care and be available and implemented during moments of greatest need. Integrated real-time risk prediction holds substantial promise to encourage sustained recovery through adaptive use of these continuing care services. PUBLIC HEALTH RELEVANCE: The goals of this project are to develop and deliver a dynamic, real-time model for forecasting alcohol use lapse among abstinent alcoholics. This lapse risk prediction model will be integrated into an existing validated mHealth platform to encourage sustained recovery through adaptive use of continuing care services.",
Artificial Intelligence Methods for Crystallization,"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",
A machine learning approach to identify Alzheimer's disease therapeutic targets,"A machine learning approach to identify Alzheimer's disease therapeutic targets     DESCRIPTION (provided by applicant): The ultimate goal of this project is to enable the use of molecular profiles (e.g., expression data, genetic data, and proteomic data) of Alzheimer's disease (AD) patients to facilitate to identify therapeutic targets. There is a growing availabilit of expression profiles of brain tissues from AD patients and normal subjects, which holds great promise for improving our molecular-level understanding of AD and developing new drugs. The most important step necessary to realize this goal is to identify molecular features, such as expression levels of certain genes, in these data that are predictive of AD phenotypes indicative of the disease progression, such as neuropathological and clinical phenotypes. Despite the pressing need, due to the high-dimensionality of the expression data, it is an open challenge to identify molecular features that are truly associated with a phenotype. This is a critical barrier that impedes progress in identifying therapeutic targets from high-throughput molecular profiles. To resolve this challenge, this project proposes to identify network-based features representing important molecular events in disease progression from gene expression data, and use the identified features to predict AD-related phenotypes. This approach can effectively reduce the dimensionality of the expression data by focusing on a small subset of genes that are likely relevant to AD. In particular, we focus on the following network-features: perturbed genes that have different connectivity patterns with other genes between different AD stages (Aim 1); hubs that are densely connected with other genes in the inferred network in AD (Aim 2); and common hubs (co-hubs) between AD and cardiovascular disease (Aim 2). In each aim, we will develop powerful machine learning (ML) algorithms that can jointly model interactions of genes that are present in multiple heterogeneous datasets. We will apply the identified network-based features to predict neuropathological and clinical phenotypes in the data from a densely phenotyped cohort in the Adult Changes in Thought (ACT) study. The features selected to be predictive of these phenotypes will provide us with better insights into the molecular mechanisms driving AD progression, which can lead to effective therapeutic targets. Successful completion of the proposed research will lead to the discovery of the molecular features that are informative of the disease processes and can thus guide drug development. The proposed research will lay the groundwork of an interdisciplinary team of computer scientists, a statistician, basic biologists, a internist and a neuropathologist to develop a systematic computational framework for identifying AD therapeutic targets from heterogeneous molecular and clinical profiles.         PUBLIC HEALTH RELEVANCE: The ultimate goal of the proposed research is to improve our molecular-level understanding of Alzheimer's disease (AD) and identify novel therapeutic targets. The growing availability of molecular profiles - such as DNA sequence, epigenetic data, RNA expression data and proteomic data - from AD brain tissues holds great promise to identify molecular features (e.g., expression levels of certain genes) that are informative of the disease processes and can thus guide drug development. We propose an innovative computational framework that integrates heterogeneous datasets for identifying robust molecular features from high-throughput molecular profiles.            ",
Development/Clinical Validation Markers for Prostate Ca,"Development/Clinical Validation Markers for Prostate Ca    DESCRIPTION (provided by applicant):  We have witnessed major improvements in our ability to detect and stage prostate cancer and have benefited from a sustained decrease in the death rate from this common disease due, in part, to the introduction of serum Prostate Specific Antigen (PSA) into clinical practice in the late 1970's. Now in 2004, in the wake of the ""PSA era"" discoveries, we continue to perform diagnostic biopsies unnecessarily on 75% of men with abnormal PSA levels, finding 1:4 with disease, we continue to understage nearly 30% of men with presumed localized disease, and we continue to lack additional clinically validated prostate cancer biomarkers. Also, as the ""baby boomer"" men reach their 60's, it is anticipated that the number of men over age 50 will increase greatly, reaching 80 million by year 2015. This, coupled with the fact that there are nearly 20 million men in the U.S. alone who have had one negative prostate biopsy yet still are risk for prostate cancer and can no longer rely on PSA as their biomarker of choice. Clearly further discovery, characterization and validation of potential biomarkers for the early detection of prostate cancer are greatly needed - The mission of the Early Detection Research Network. In this competitive renewal proposal we will outline our progress between 1999 and 2004 as an EDRN Clinical and Epidemiological Center. We will demonstrate our ability to accrue patients, archive an impressive and clinically valuable biorepository of specimens, take part in collaborative research within the EDRN network, Industry and non-EDRN investigators, actively take part in the governance of the EDRN and publish key biomarker findings. Within this renewal we will also outline our proposed continuation/enhancements of our biorepository, anticipated development and participation in validation studies, characterization of novel tumor markers (pre-validation), preliminary pilot studies of biomarkers, evaluation of biomarker technologies and development of multivariate tumor marker models for complex evaluation of multiple tumor markers.            n/a",
CADUCEUS:  A COMPUTER BASED DIAGNOSTIC CONSULTANT,"CADUCEUS:  A COMPUTER BASED DIAGNOSTIC CONSULTANT A new diagnostic procedure for CADUCEUS has been developed, which we believe provides a frame work for solving all of the known problems encountered in our use of INTERNIST-1.  During the five year period covered by the current proposal, we intend to puruse the following specific aims:  Revision of the structure of the CADUCEUS knowledge base will be undertaken to support the enhanced capabilities of the new diagnostic procedure.  The revised knowledge base will be expanded to encompass all of the major diseases of internal medicine, and much of neurology.  Evaluation of the new CADUCEUS system will be undetaken in two phases. First, through protocol analytic studies, we intend to study and refine the human/machine interface of CADUCEUS, exploring specifically various modes of cooperative human/machine problem solving.  Subsequently, we plan to carry out formal evaluation studies of the system in order to gauge its diagnostic accuracy, the value of its information gathering and explanatory capability, and its acceptability to a variety of potential client groups.  The overall objective  will be to bring CADUCEUS to a state of maturity that will permit its distribution for general use by medical practitioners.  n/a",
Longitudinal Analysis of Spoken Language Characteristics in the Nun Study,"Longitudinal Analysis of Spoken Language Characteristics in the Nun Study DESCRIPTION (provided by applicant): Verbal communication is one of the most complex and vital human behaviors negatively affected by neurodegenerative disease, and previous research strongly suggests that linguistic characteristics are promising as early clinical indicators. The Nun Study data set offers a rare opportunity to investigate the application of linguistic methods to the assessment of late life cognitive deficits and the development of neurodegenerative disease. We propose to investigate rate of decline in linguistic ability using previously unanalyzed spoken autobiography audio samples repeated over four waves of assessment. Aim 1 will capitalize on work already done to digitize audio recordings of the Nun Study longitudinal spoken autobiography samples. Verbatim transcripts will be produced and will be time-aligned with the audio from each speech sample. Aim 2 will use computational linguistic methods to calculate measures of syntactic complexity and propositional content, and will evaluate the rate of change on these measures over the 41/2 year follow-up period. Mean rates of change will be estimated in those sisters with repeated speech samples available, and will be compared between those sisters with and without dementia to determine if the rate of decline in linguistic ability is associated with diagnostic status. This project leverages the extensive NIH resources already invested in the Nun Study to 1) analyze an under-utilized aspect of this valuable data set, 2) expand upon the study's early findings in the application of linguistic analysis to the study of aging and disease-development, and 3) update the analysis methodology applied to the autobiography samples by making use of automated methods from the field of computational linguistics to combine information about speech content with information from the audio recording. PUBLIC HEALTH RELEVANCE: The Nun Study data set offers a rare opportunity to study speech quality in the development of dementia. This study will investigate rate of decline in linguistic ability using previously unanalyzed spoken autobiography audio samples from the Nun Study. Rate of change will be estimated for those sisters with repeated speech samples available, and will be compared between sisters with and without dementia to determine if the rate of decline in linguistic ability is associated with diagnostic status.",
Filtered Point Process Inference Framework for Modeling Neural Data,"Filtered Point Process Inference Framework for Modeling Neural Data ABSTRACT  Neuronal spike-trains and various other signals in the central nervous system have a discrete, impulsive nature that is well characterized with point process statistical models. In several neuroscience applications, such impulsive signals are transformed upon interaction with biological processes or measurement artifacts, and are consequently observed as filtered point process data. The goal of this project is to develop a principled statistical signal processing framework for filtered point processes with models and algorithms for estimation and inference, and to apply these novel methodologies to experimental data from rodent brain calcium imaging data and human neuroendocrine data. Our approach centers on a unified framework for sparse representation and dynamical systems modeling of marked point process data arising in neuroscience analyses. In addition to its novel statistical methodology, another major strength of our proposal is the application of these methods to experimental data arising in fundamental neuroscience and clinical problems, both to validate the new methods with real data and to investigate basic science questions related to the central nervous system structural and functional organization. Large-scale two-photon calcium imaging, in conjunction with spike-train deconvolution, will allow us to study the activity of over a thousand identified neurons simultaneously with single-spike resolution in a behaving animal. This will allow us to elucidate with high accuracy how the magnitude and spatial structure of signal and noise correlations across neurons vary with stimuli or behavioral tasks. It will shed light on visual encoding in the rodent brain, and neuronal architectures underlying visual perception and cognition, at an unprecedented spatiotemporal scale. Further, our modeling of pulsatile hormone secretion will apply to the release of cortisol, gonadal steroids, insulin, thyroid and growth hormones. Diseases linked to abnormal cortisol secretion include diabetes, visceral obesity and osteoporosis, disturbed memory formation and life-threatening Addisonian crisis. Hence, understanding and modeling the underlying impulsive nature of normal hormone release will aid our understanding of pathological neuroendocrine states and improve the efficacy of drugs and other interventions for treatment of hormonal disorders. Additionally, this project will combine Brown Lab’s computational expertise in point process models with Sur Lab’s experimental expertise in neuronal calcium imaging, extending our ongoing collaboration under the NIH Brain Initiative to developing novel neural population analysis techniques with unprecedented detail at single-neuron, single-spike resolution. Our research is well poised to improve significantly the state of the art and in computational and systems neuroscience tools and bridge together components from the statistical learning, signal processing and computational neuroscience communities to produce a unifying analytical framework for neural data analysis. NARRATIVE  In this project we will develop a filtered point process framework for neural data analysis, with models and algorithms for sparse recovery of spike-trains from time-series data comprising a series of pulsed waveforms. We will use this novel methodology to extract neuronal spike-trains from calcium imaging data of cortical tissue, and to estimate hormone secretion times and amounts from serum hormone levels. We will make our mathematical algorithms for neural data analysis and their software implementation freely and easily available to the neuroscience research community.",
Urinary biomarkers for prostate cancer diagnosis and risk assessment,"Urinary biomarkers for prostate cancer diagnosis and risk assessment PROJECT ABSTRACT This project aims to develop a urine-based screening tool for prostate cancer that could affect at least 13 million men in the US who receive prostate cancer screening every year. Today, serum prostate specific antigen (PSA) remains the most commonly used screening test for prostate cancer (PCa), but the lack of specificity of PSA has led to unnecessary prostate biopsies. In addition, PCa is a heterogeneous disease ranging from indolent to life threatening or clinically significant. About 20% to 50% of men who get a positive biopsy have PCa that never grows, spreads, or harms them. Thus, there is a great need to develop better alternatives that can reliably diagnose PCa and also identify men with clinically significant prostate cancer who are most likely to benefit from early diagnosis while avoiding the over-diagnosis and overtreatment of indolent cancer. Research has found that trained dogs can distinguish patients with and without PCa by sniffing their urine. In turn, we can use these odor-producing volatile organic compounds (VOCs) as biomarkers for PCa diagnosis and risk assessment. Our preliminary data have shown that VOCs in urine are significantly different (p<0.05) between prostate cancer patients and healthy subjects. We hypothesize that pathological processes of PCa can alter the production of specific VOCs that are different and distinguishable from the VOC profile of healthy individuals. We also hypothesize that certain PCa specific VOCs are conserved across different ethnic groups, and that these VOCs are highly significant for diagnosing PCa. In this proposed study, we aim to (1) develop a urinary VOC-based screening model for PCa diagnosis; (2) create a prostate cancer risk model based on urinary VOCs for differentiating indolent from clinically significant PCa, and (3) evaluate longitudinal patterns of change of urinary VOC profiles in men with and without prostate disease. The expected outcomes and impacts of the project is to develop a non-invasive urinary VOC based model that can detect PCa with over 90 % accuracy, thus providing a better alternative to the current PSA test for PCa diagnosis. Furthermore, the VOC risk model could become a revolutionary tool with high specificity for clinically significant PCa; it has the benefit of early diagnosis while preventing over-diagnosis (i.e. finding indolent PCa that will never develop into advanced deleterious PCa) and overtreatment of indolent PCa (i.e. getting unnecessary and aggressive treatment). It would directly benefit over 13 million men receiving PSA testing in the US annually, and prevent at least 2 million unnecessary biopsies and their inherent risks (pain, bleeding, infection, death), and will reduce cost (time away from work, cost of procedure and ancillary studies) and anxiety. PROJECT NARRATIVES This research is to use the organic metabolites in urine as biomarkers to diagnose prostate cancer (PCa). We expect to develop a non-invasive urinary VOC based screening model that can detect PCa with over 90 % accuracy, thus providing a better alternative to the current PSA test for PCa diagnosis. We will also develop a VOC risk model could become a revolutionary tool with high specificity for clinically significant PCa to provide the benefit of early diagnosis while preventing over-diagnosis (i.e. finding indolent PCa that will never develop into advanced deleterious PCa) and overtreatment (i.e. getting unnecessary and aggressive treatment) of indolent PCa.",
The molecular basis of receptor-ligand recognition on the immunological synapse,"The molecular basis of receptor-ligand recognition on the immunological synapse ﻿    DESCRIPTION (provided by applicant): Immunoglobulin superfamily (IgSF) proteins play important roles in protecting the human body from infectious diseases and tumorigenesis; on the other hand, their malfunction can lead to automimmune diseases. Because IgSF proteins function in immunity by specific trans-cellular noncovalent interactions between antigen-presenting cells and T cells, a molecular-level understanding of IgSF:IgSF binding interfaces would be of great aid to the design of novel immunomodulatory therapeutics. Excluding antibodies, the human proteome currently contains 477 extracellular IgSF proteins, of which only a quarter have documented binding partners. Given the volume of unexplored extracellular IgSF:IgSF interactions, a purely wet-lab approach to completing the IgSF interactome-the network of all known IgSF:IgSF interactions-would be prohibitively expensive. On the other hand, current computational molecular interaction prediction approaches are unsuitable for interactome prediction as they are either computationally intractable when attempted on large molecules such as proteins due to their inability to sample the entire conformational space or produce inaccurate results due to their inability to distinguish binding from non-binding protein pairs. Our goal is to develop a computational method that can be used to identify interacting IgSF receptor-ligand pairs. To accomplish this goal, we will first combine structural similarity-based and sequence-based approaches along with hidden Markov model profile-based functional sub-classification of the IgSF to identify the binding interfaces of IgSF proteins. Next using molecular dynamics simulations, we will sample the potential energy landscape of target receptor IgSF protein binding interfaces and design an optimal complementary ligand protein interface, which will then be evaluated to fit existing IgSF proteins. We hypothesize that each receptor interface can be characterized by a unique spatial fingerprint-an extended pharmacophore which we will call the residue-specific functional atom field (rsFAF)-which represents the energetically favorable positions of key functional atoms and can be used to identify cognate ligands. Our methods will be validated using a test set of known IgSF:IgSF complexes with available crystallographic structures.         PUBLIC HEALTH RELEVANCE: Immunoglobulin superfamily (IgSF) proteins are crucial to a great variety of biological processes, including the control of innate and adaptive immunity and the suppression of tumorigenesis; in immunity, IgSF proteins interact at the cellular interface between antigen-presenting cells and T cells known as the immunological synapse. Our goal is to develop a computational method to predict the interactions between all IgSF proteins- or at least to shortlist candidate interactions to an experimentally manageable few-by gaining a molecular- level understanding of the immunological synapse. The impact of our research will be twofold: not only will we identify unknown interactions between IgSF proteins that could be potential immunomodulatory drug targets, but we will also elucidate a molecular-level understanding of the immunological synapse that could serve as a scaffold for the process of immunomodulatory drug design itself.            ",
CHROMOSOMAL PROTEINS DURING CHEMICAL CARCINOGENESIS,"CHROMOSOMAL PROTEINS DURING CHEMICAL CARCINOGENESIS Administration of many chemical agents results in induction of malignant tumors in target tissues.  These malignancies are characterized by alterations in control of cellular function, suggesting that genomic alteration (mutation) and/or alterations in gene modulation have occurred. While a substantial body of evidence indicates that altered DNA plays a major role in this process, the role of non-DNA factors has also been demonstrated.  In this continuation, we will extend our two-dimensional gel electrophoretic study of potentially critical alterations occurring in nonhistone chromosomal proteins (NHCP) and cytosolic proteins during carcinogenesis induced by diverse acting carcinogens acetylaminofluorene (AAF) and diethylnitrosamine (DEN), and in the cancers that result.  We have demonstrated that the gel system provides a highly consistent pattern of protein separation, with extreme resolution, over long periods of time. Silver and in vitro radiolabeling techniques have been developed to permit visualization of nanogram amounts of protein(s) with applicability to computer technology.  Using these techniques, we have identified induction of tumor-associated proteins (TAP) in the total NHCP fraction as well as in the phenol-soluble fraction (phosphoproteins) of rat hepatic chromatins during AAF and DEN carcinogenesis and resulting hepatocellular carcinomas. Additionally, cytosolic AAF and DEN-TAPs have been similarly demonstrated. We will determine to what extent these changes in NHCP and cytosolic proteins characterize the general process of carcinogenesis by examining spontaneous and chemically-induced hepatic and thymus tumors in a variety of mouse inbred strains.  We will further determine the time of appearance, sub-fraction location, and in the case of NHCP, genomic distribution of TAP during chemical carcinogenesis; isolate these proteins, and produce monoclonal antibodies for use in their study, as well as determining their functional significance.  Lastly, we will continue our technological developments to assure maximum detection, and computer-assisted image-processing of the complex protein patterns that characterize normal and malignant cells in order to confirm and further detect potential hallmark proteins, whose occurrence mark malignant induction.  n/a",
Effective Treatments for Children's Emotional Disorders,"Effective Treatments for Children's Emotional Disorders    DESCRIPTION (provided by applicant): Numerous psychosocial treatments have been empirically demonstrated to reduce anxiety, depression, and other internalizing disorders in childhood. However, such empirically supported treatment (EST) programs are not as widely implemented in mental care as desirable. This gap undermines the positive impact that psychosocial treatments can have for children, and may ultimately reduce the value society will place on psychosocial treatment for mental health problems. About 13% of all school-age children have anxiety and 6% mood disorders. The long term goal of the current project, therefore, is to increase the likelihood that children receive ESTs for the mental health problems. To this end, the specific aims of the proposed Phase II work will be fully developed and make ready for commercial dissemination three products for which prototypes already exist from R&D completed in phase I. the central product is the Children's Emotional Disorders Effective Treatment Archive (CEDETA), which consists of complete kits for of all material required to implant (e.g., manual, workbooks) and evaluate each included EST. Treatments included in CEDETA were identified through a comprehensive scientific literature search and extensive evaluation by an independent Expert Panel in phase I. Access to 17 EST programs was secured in phase I, and a prototype kit for one CEDETA program was constructed and favorably evaluated by consumers. The specific aim for phase II is to make all materials for each EST program in CEDETA ready for commercial distribution by the end of the grant period. These kits will be marketed and sold to mental health practitioners, clinics, and systems. The other two products enhance the use of CEDETA by (1) facilitating the selection of the right treatment for a mental health practitioner's needs, through an online search procedure; and (2) providing professional continuing education (CE) training to the implementation of EST. specific phase II aims are to make these two ancillary products ready for commercial distribution by the end of the grant period. Technically usability testing and consumer feedback will be used extensively throughout the R&D process to ensure that all products meet the needs of mental health practitioners.  In addition, [a] randomized experiment enrolling [80] practitioners in total, will be conducted to evaluate features of these products to advance knowledge about EST as a clinical approach and inform further R&D. This experiment will test whether CEDETA and its associated products improve practitioners': (A) knowledge about, (B) general attitude towards, (C) intent to use, (D) actual use of ESTs for internalizing problems. About 13% of all school-age children have anxiety and 6% mood disorders. A minority receive treatment for these problems, and when they do, it is generally not a treatment that has been scientifically demonstrated to work. The long-term goal of the current project, therefore, is to increase the likelihood that children receive empirically supported psychosocial treatments for these mental health problems.          n/a",
Olfaction and Emotion in Depression: Behavioral Electrodermal and ERP Measures,"Olfaction and Emotion in Depression: Behavioral Electrodermal and ERP Measures    DESCRIPTION (provided by applicant):       Given the overlap of cortical and subcortical (limbic) structures involved in olfaction, emotion and depression, the study of olfaction may hold particular promise for elucidating neurophysiologic dysfunctions associated with abnormalities of emotional reactivity and anhedonia in depressed patients. There has, however, been relatively little study of olfactory function in depressed patients and existing studies have been limited by lack of neurophysiologic measures and methodological difficulties. We propose to develop a new direction of research, in which multichannel event-related brain potentials (ERPs) will be measured in depressed patients and healthy controls to pleasant and unpleasant olfactory stimuli. This will take advantage of existing methods for precise control of olfactory stimuli (olfactometer) and also new data analytic techniques in the electrophysiologic domain. Current source density (CSD; surface Laplacian) and temporal principal components analysis (PCA) are combined to yield reference-free measures of radial current sources corresponding to meaningful olfactory ERP components. Also, high and low concentrations of pleasant and unpleasant odors will be selected on the basis of psychophysiologic measurements, which will allow separate assessment of emotional valence and intensity effects. In addition to brain ERPs, bilateral electrodermal activity (EDA), which typically accompanies emotional processing, will be recorded to provide sympathetically- mediated measures of autonomic arousal to the olfactory stimuli. After preliminary psychophysical measurements, we propose to test 30 unmedicated depressed patients and 30 healthy controls matched for gender, age, handedness, smoking history, and ethnicity/race. ERP, EDA and behavioral measures will be obtained to high and low concentrations of pleasant and unpleasant odors during a detection task, which is designed to minimize cognitive-evaluative processing. Separate judgments of odor intensity/valence will also be obtained, along with standard behavioral tests for assessing odor detection thresholds and odor identification. Interviewer-based and self-ratings of psychopathology will be used to examine the relation of ERP and behavioral olfactory deficits in patients to anhedonia and other symptoms of depression. Anhedonia is a cardinal diagnostic feature of major depression. Increased understanding of its neurophysiologic basis could lead to improved identification of diagnostic subtypes and new markers for prediction of treatment response. The study of olfaction in depressed patients should provide a new window for measuring and understanding abnormalities of emotional reactivity, such as reduced experience of pleasure in depression. This could also lead to development of new methods for diagnostic assessment and treatment selection.          n/a",
Content based neuro image classification,"Content based neuro image classification    DESCRIPTION (provided by applicant): The goal of this proposal is the automated classification of imaging studies of patients with tumors. As the role of imaging becomes increasingly important in medical care, effective methods for storing and retrieving key images will become critical. Image classification and subsequent summarization proffers a method to compress imaging studies by selecting only pertinent image slices that objectively document a patient's condition, while preserving the full integrity of the original data; as such, its applications include multimedia electronic medical records, telemedicine, and teaching files.      This proposal details an innovative method to accomplish image classification based on principal component analysis.  A training set of images classified by experts will be used to generate a basis set of images that captures the variance among the images. The projection on this basis set of images, called eigenimages, is used as an image index for classification and retrieval. Two key aspects critical to the success of accurate image classification are described: normalization of both image spatial and intensity properties. A modification to this methodology is also proposed to handle images with small abnormalities: image sub-regions that are 'abnormal' are located by searching the query image for the region that best matches a training set of sub-images of 'abnormal regions'. The target domain for the proposal is MR imaging studies of patients with brain tumors; in future work, this research will be extended to cover other neurological conditions, imaging modalities, and anatomical regions. Technical evaluation will be performed by comparing the automated methods with that of experts.         n/a",
Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION),"Translational Outcomes Project: Visualizing Syndromic Information and Outcomes for Neurotrauma (TOP-VISION) PROJECT SUMMARY: Trauma to the spinal cord and brain (neurotrauma) together impact over 2.5 million people per year in the US, with economic costs of $80 billion in healthcare and loss-of-productivity. Yet precise pathophysiological processes impacting recovery remain poorly understood. This lack of knowledge limits the reliability of therapeutic development in animal models and limits translation across species and into humans. Part of the problem is that neurotrauma is intrinsically complex, involving heterogeneous damage to the central nervous system (CNS), the most complex organ system in the body. This results in a multifarious CNS syndrome spanning across heterogeneous data sources and multiple scales of analysis. Multi-scale heterogeneity makes spinal cord injury (SCI) and traumatic brain injury (TBI) difficult to understand using traditional analytical approaches that focus on a single endpoint for testing therapeutic efficacy. Single endpoint-testing provides a narrow window into the complex system of changes that describe the holistic syndromes of SCI and TBI. In this sense, complex neurotrauma is fundamentally a problem that requires big- data analytics to evaluate reproducibility in basic discovery and cross-species translation. For the proposed TOP-VISION cooperative agreement we will: 1) integrate preclinical neurotrauma data on a large-scale; 2) develop novel applications of cutting-edge multidimensional analytics to make sense of complex neurotrauma data; and 3) validate bio-functional patterns in targeted big-data-to-bench experiments in multi-PI single center (UG3 phase), and multicenter (UH3 phase) studies. The goal of the proposed project is to develop an integrated workflow for preclinical discovery, reproducibility testing, and translational discovery both within and across neurotrauma types. Our team is well-positioned to execute this project given that with prior NIH funding we built one of the largest multicenter, multispecies repositories of neurotrauma data to-date, housing detailed multidimensional outcome data on nearly N=5000 preclinical subjects and over 20,000 curated variables. We will leverage these existing data resources and apply recent innovations from data science to render complex multidimensional endpoint data into robust syndromic patterns that can be visualized and explored by researchers and clinicians for discovery, hypothesis-generation and ultimately translational outcome testing. PROJECT NARRATIVE: Multicenter, multispecies central nervous system (spinal cord and brain) injury data provides a unique and clinically-relevant opportunity to discover translational outcomes, if we can develop analytical workflows that fully harness these data. Our team has assembled one of largest repositories of such data spanning across spinal cord injury and traumatic brain injury models under prior NIH support. The proposed cooperative agreement will expand data-sharing and big-data analytical workflows to render raw neurotrauma data into novel insights to promote bench-to-bedside translation.",
"Methods, Tools and Resources for Interactive Online Virtual Screening and Lead Optimization","Methods, Tools and Resources for Interactive Online Virtual Screening and Lead Optimization Project Summary  The proposed work will accelerate the pace of drug discovery by developing, validating, and testing new methods, tools, and resources for structure-based drug design. Two fundamental challenges of structure-based drug design are the accurate scoring and ranking of protein-ligand structures, which identiﬁes active com- pounds, and the ability to efﬁciently search a large number of ligands, which ensures that active compounds are sampled. This proposal will address these challenges by developing a novel approach for protein-ligand scoring and expanding the size of the chemical space that can be efﬁciently searched during lead optimiza- tion. The methods will be validated by their prospective application toward the discovery of new anti-cancer molecules and will be made readily accessible through online resources and open-source tools.  The proposal leverages recent and signiﬁcant advances in deep learning and image recognition to develop scoring functions that accurately recognize high-afﬁnity protein-ligand interactions. This is achieved by design- ing and training convolutional neural nets on three-dimensional representations of protein-ligand structures to discriminate between binders and non-binders. Convolutional neural net training will exploit large datasets of afﬁnity and structural data to automatically extract the relevant features necessary to accurately prioritize compounds. Additionally, the proposal develops the ﬁrst means of fully integrating a convolutional neural net scoring function directly into an energy minimization and docking workﬂow.  Interactive virtual screening enables the search of millions of compounds in a few seconds so that queries can be interactively optimized. Interactivity enables the synergistic uniﬁcation of human expert knowledge and efﬁcient computational algorithms. The proposed work will dramatically expand the size of chemical space ac- cessible through interactive virtual screening. Algorithms for efﬁciently searching the chemical space of billions or trillions of compounds implicitly deﬁned by a set of reaction schemas and fragments will be created as part of a lead optimization workﬂow. Fragment-oriented search will be accelerated by a new data structure that combines pharmacophore and molecular shape information into a single sub-linear time index.  The scoring and lead optimization methods developed in this proposal will be released as open-source soft- ware and made immediately available through open-access online resources. As part of the prospective valida- tion of the proposed methods, these resources will be used to identify hit compounds and optimize leads for two targets related to cancer metabolism: serine hydroxymethyltransferase and kidney glutaminase isoform C. Successful completion of the objectives of this proposal will positively impact public health by reducing the cost and time-to-market of developing new drugs, particularly with respect to novel protein targets. Project Narrative  Researchers will be able to more quickly and accurately identify potential drug candidates using the new methods, tools, and resources for structure-based drug discovery created by this project. These tools will be readily accessible through open-access web sites and open-source software. As part of the project these tools will be used to identify new molecules that are relevant to the treatment of cancer.",
Tracing the evolution of the human mutation rate,"Tracing the evolution of the human mutation rate ﻿DESCRIPTION (provided by applicant): All genetic variation is created by mutations, changes that arise due to DNA damage or copying mistakes during DNA replication. Mutations are frequent enough that, on average, a child's 3-billion base pair genome contains 74 new genetic variants that are not present in the genome of either parent. Such new mutations confer a higher disease risk than older mutations because they have not passed the test of surviving through several generations of parents and offspring. We aim to pinpoint how the human mutation rate has evolved as humans left Africa and adapted to diverse new environments across the globe.  One specific aim will follow up on my preliminary research which showed that Europeans experienced a mutation rate change after diverging from Africans and Asians. The primary evidence for this change is that European genomes have a higher burden than African or Asian genomes of the mutation type TCC→TTC, where the trinucleotide ""TCC"" has experienced a mutation from ""C"" to ""T"" at its central site. We wish to and the genetic basis of this mutation rate change by looking at rare variants in mixed- ancestry Latino and African-American individuals. Specially, we will isolate young genetic variants that probably arose via mutation within the past 10-15 generations, after gene ow from Europe into the Americas had already begun. We will infer the genetic background (European, African, or Native American) upon which each new mutation arose and look for genomic regions where European ances- try correlates strongly with an excess of TCC→TTC mutations. These will be the regions most likely to harbor a causal allele that changed the process of mutation accumulation in Europeans. This work has the potential to yield valuable insights into melanoma, a cancer that predominantly affects individuals of European ancestry and whose somatic mutational signature is dominated by TCC→TTC.  A second specific aim is to look for other signatures of mutation rate change that have occurred within the human species or, more broadly, within the great apes. We will use a natural language processing technique called Latent Dirichlet Allocation (LDA) to identify collections of mutation types whose rates appear to be under common genetic control. A few mutation types besides TCC→TTC show weak signals of rate differentiation between populations, and we will attempt to infer how many separate mutation rate change events are necessary to explain these signals. The admixture mapping technique from Specific Aim I can also be adapted to interrogate the genetic basis of other mutation rate changes that might have occurred in the recent past. These efforts should improve our understanding of the human mutation rate's genetic architecture and how mutation rates differ between populations. PUBLIC HEALTH RELEVANCE: All genetic variation is created by mutations, the copying mistakes that occasionally happen during DNA replication. There is evidence that children born with a higher burden of new mutations are at increased risk for autism, schizophrenia, and serious congenital diseases [1, 2, 3], but it is not well understood how much the human mutation rate varies and what genetic risk factors affect the mutation rate [4]. We aim to follow up on preliminary evidence that the Europeans have a higher mutation rate than Asians or Africans [5], looking for the genetic basis of this rate difference and investigating how often the mutation rate has changed during human evolution.",
CPS: Cyber-physically assistive clothing to reduce societal incident of low back pain ,"CPS: Cyber-physically assistive clothing to reduce societal incident of low back pain  The objective of this proposal is to address core scientific challenges related to sensing, actuation and control of cyber-physically assistive clothing (CPAC). CPAC is a kind of Human-in-the-loop Cyber-Physical System (HCPS), in which actuated clothing is coordinated in unison with human body movement to enhance safety and health. We propose addressing key HCPS challenges within the context of using CPAC to reduce societal incidence of low back pain, by preventing lumbar (spine) overloading and overuse injuries. Low back pain is targeted because it is one of the leading causes of physical disability and missed work. High and/or repetitive forces on lumbar muscles and discs can occur during daily tasks, and are known to be major risk factors that can lead to back pain and injury. The long-term vision is to create smart clothing that can monitor lumbar loading, train safe movement patterns, and directly assist wearers to reduce the musculoskeletal forces that cause pain and injury. This proposed transformation of clothing is similar to how wristwatches have transformed from timepieces into health monitors; however, CPAC is even more exciting because it combines the form-factor of clothing with the assistance benefits of an exoskeleton to reduce biological tissue loading for a broad range of individuals, occupations and tasks. Thrust 1 will adapt machine learning techniques in order to monitor lumbar loading and detect excessive spine forces via portable, wearable sensors, such that timely feedback/intervention can be provided. This thrust will result in the creation of a publicly shared data set that contains synchronized, multimodal (lab-based and wearable) sensor data collected from >500 actions per subject, the largest such corpus for machine learning in this domain. Thrust 2 will model the dynamics of cyber, physical and human components of CPAC in order to develop optimal control and learning strategies. Thrust 3 will integrate sensors, fusion algorithms and portable actuation into a complete wearable prototype. A human subject experiment will be performed to objectively evaluate the function of CPAC. At the focus of this proposal is the human body; monitored, analyzed and assisted by multidisciplinary CPS technologies. The project integrates expertise in biomechanics, machine learning, sensor fusion, soft robotics, wearable assistive technology, and clinical management of low back pain to transform clothing from materials that cover the body into wearable systems that can track and protect low back health. The key scientific HCPS challenges that need to be overcome, and which are addressed in this proposed research, in order to realize the broad societal benefits of CPAC are: (1) real-time sensing and assistive control of the HCPS and its co-adaptation to different subjects and diverse environments, (2) system design and verification ensuring safe operation and that no harm is done to human subjects through unanticipated feedback, (3) selection and placement of low cost sensors aiding affordable and realistic manufacturing of CPAC, (4) integration of wearable sensors and actuators into a reliable and effective HCPS. CPAC has the potential for broad societal impact given the high prevalence of low back pain. CPAC provides a unique and potentially paradigm-shifting opportunity because it combines the assistive benefits of an exoskeleton with the lightweight and unobtrusive form-factor of everyday clothing. CPAC is expected to (1) fit seamlessly into daily life, (2) connect individuals with health info to empower them to modify their physical activity, (3) generate public health data to inform evidence-based clinical and workplace practices, (4) augment lifting biomechanics to reduce lumbar loading, (5) reduce incidence of low back pain, and costs due to health care and missed work.",
"Diabetes, Medications and the Cost-Effectiveness of Screening for Colorectal Neoplasia","Diabetes, Medications and the Cost-Effectiveness of Screening for Colorectal Neoplasia Project Summary/Abstract: The candidate's long-term career goal is to become an independent investigator with transdisciplinary expertise in cancer epidemiology, biomedical informatics, pharmacoepidemiology, and health economic modeling and evaluation. The focused didactic training, mentorship, and experiential learning through research activities proposed in this award will facilitate the development of critical skills in the pursuit of knowledge to inform and improve cancer prevention and screening. The candidate's research is motivated by the recognition that type-2 diabetes mellitus (T2DM) patients are at a 30-40% increased risk for colorectal cancer (CRC), and that anti-diabetic drugs may also alter CRC risk. Thus, this high-risk group presents an opportunity for targeted screening and early detection of CRC. Currently, CRC screening is based on age and family history, with no consideration for comorbidities, including T2DM. Building on her previous work in cancer epidemiology, the candidate seeks to determine the association between T2DM and risk of colorectal polyps: overall, by subtypes, and by lesion severity, individually reflecting different molecular pathways (Aim 1); and to examine the risk for colorectal polyps associated with anti-diabetic therapy: overall, by subtypes, and by lesion severity (Aim 2). These aims will be addressed by leveraging the rich resources of an existing colonoscopy- based cohort at the University of Washington Medical Center's (UWMC) Gastroenterology clinic established during 2003-2011. Demographics, select lifestyle factors, and detailed histopathology have been previously abstracted from UWMC's electronic medical records (EMR) database. The candidate proposes to extend this cohort through 2017 (N~38,000), and enhance it by linking existing data with diabetes-related variables from the EMR database using biomedical informatics (e.g., natural language processing, clinical text mining) to estimate the risk for colorectal neoplasia. Using these empirical estimates derived from Aims 1 and 2, the candidate will then build a microsimulation model projecting the risk for colorectal neoplasia in T2DM patients, accounting for their diabetes therapy. Alternative screening and treatment strategies, including altering the screening start-age, modifying diabetes treatment, or altering screening modality among T2DM patients, will be evaluated for their cost-effectiveness (Aim 3). This work may help inform targeted screening recommendations that could, in turn, lower the incidence and mortality of CRC among persons with T2DM, and improve the cost- effectiveness of CRC screening. The candidate has proposed a training and career development plan that builds upon her prior skills in cancer epidemiology to gain experience and proficiency in biomedical informatics, pharmacoepidemiology, and health economic modeling and evaluation, including cost-effectiveness approaches. The transdisciplinary mentorship team, comprised of national and international experts, will provide the necessary expertise to ensure the success of this proposal, as well as facilitate the candidate's transition into an independent translational investigator in the field of cancer prevention and screening. PROJECT NARRATIVE This study aims to determine the link between clinically diagnosed type-2 diabetes mellitus, use of anti-diabetic medications, and risk of colorectal polyp subtypes, including differences by lesion severity. Evaluating the cost- effectiveness of CRC screening among persons with type-2 diabetes may help inform targeted screening recommendations, which could, in turn, lower the incidence and mortality of CRC among persons with T2DM, and improve the cost-effectiveness of CRC screening.",
The behavioral microstructure of a memory-guided food-caching behavior and its relationship to hippocampal replay,"The behavioral microstructure of a memory-guided food-caching behavior and its relationship to hippocampal replay Project Summary The hippocampus is a critical site for rapid memory formation and retrieval, with extensively documented functions representing spatial and navigational variables, yet less is known of the means by which it guides behavior. Bursts of hippocampal activity identified in many species as sharp-wave ripple (SWR) events are promising neural mechanisms to link hippocampal activity and behavioral function, since during SWRs hippocampus can represent positions the animal previously experienced, or will traverse in the near future. This proposal considers the food-caching behaviors of chickadees, who use a hippocampal-dependent, one- shot memory to guide cache retrieval. This behavior is exceptionally promising to link hippocampal activity to individual experiences, which has been a barrier to determining the nature of representations during SWR and their function in previous studies. These studies will develop a comprehensive account of how chickadee behavior is affected by cache site memory, determine whether SWRs are related to memory-specific components of caching behavior, and determine whether SWRs represent individual cache sites to assist later retrieval. I hypothesize that memory-guided behavior is distinguishable from random foraging. I will use video tracking to measure the behavioral microstructure of chickadee caching behavior, including postural and gaze time series, and develop quantitative models of behavioral motifs and their temporal structure. Using these tools to compare memory-guided and random foraging behaviors, I will develop decoders that indicate precisely how and when behavior appears memory-guided. I hypothesize that SWRs occur more often, and are more predictive of behavior, when behavior is memory- guided. I will use electrophysiology in freely moving chickadees during caching to relate SWRs to the microstructural analysis of behavior and decoding of behavioral strategy. I hypothesize that SWRs reactivate representations of previous, individual caching events, and that this reactivation improves subsequent retrieval for that individual site. Using electrophysiological recordings in caching birds, I will relate reactivations to the accuracy of retrieval behavior. Using online SWR detection and suppression, I will further determine if SWRs causally affect later retrieval behavior. Project Narrative Food caching birds are a unique model system for dissecting the fundamental principles of hippocampal function. Thorough characterization and computational modeling of this behavior, and the specific contribution of hippocampal memory, will allow insight into the neural mechanisms by which hippocampal representations guide behavior. We expect the principles resulting from this study to illuminate dysfunctions of memory present in many neurological disorders.",
Advancing Quality and Outcomes Measurement in Rheumatology,"Advancing Quality and Outcomes Measurement in Rheumatology PROJECT SUMMARY Healthcare has changed rapidly in the last decade with the widespread use of electronic health records (EHRs) and the creation of national EHR-based data networks that aim to improve the quality of care. The American College of Rheumatology's RISE registry is a federally Qualified Clinical Data Registry that collects EHR data from the practices of almost 1000 rheumatologists nationally, analyzes these data centrally, and continuously feeds back performance on quality measures to practices via a web-based dashboard. In this K24 proposal, the applicant proposes to utilize novel methods in clinical informatics to increase the accuracy of quality measurement, while also developing and testing new EHR-based quality measures relevant to rheumatic diseases. The proposed research will leverage her strong research portfolio, including grants from the National Institute of Arthritis and Musculoskeletal and Skin Diseases and the Agency for Healthcare Research and Quality, her successful track record of achieving national endorsement for EHR-based quality measures, existing data from over 1.4 million patients in the RISE database, and the outstanding institutional environment at the University of California, San Francisco. It will also support her ongoing career development in clinical informatics methods relevant to EHR-based clinical research. For this five year K24 award proposal, she plans to increase the time spent mentoring junior investigators in the field or quality and outcomes measurement in rheumatology, with the goal of helping trainees successfully launch academic research careers in patient- oriented research. Aligned with a comprehensive mentoring plan, the proposal outlines two specific aims, including using natural language processing to increase the accuracy of EHR-based quality measurement in RISE, and developing and validating new, prototype electronic clinical quality measures to monitor and address high impact gaps in care for patients with rheumatic disease. The work will prioritize outcome measures and use eMeasurement standards, including the Quality Data Model and Health Quality Measures Format to develop, specify and test measures. Measures developed through this research and mentoring program will be candidates for nationwide dissemination across rheumatology practices to improve care for individuals with rheumatic disease. PROJECT NARRATIVE This mid-career investigator award will support a program in patient-oriented research in rheumatic diseases at the University of California, San Francisco. The award will allow the applicant to expand her research on the development and validation of health care quality measures and support her mentoring of early investigators. The proposed research aims to create quality measures that can be deployed across rheumatology practices to improve the quality of care, while training new researchers to perform innovative patient-oriented research in the area of electronic health record-based quality and outcomes measurement.",
Assessing the Robustness of Radiogenomic Associations using Deep Neural Networks in Glioblastoma Multiforme,"Assessing the Robustness of Radiogenomic Associations using Deep Neural Networks in Glioblastoma Multiforme Project Summary/Abstract Background: The generation of high-throughput methods in molecular biology and medical imaging has motivated the need to better understand multimodal cancer patient data. This motivation has led to the development of radiogenomics, the study of the connection between a tumor’s underlying molecular traits and its clinical and imaging phenotypes. Radiogenomic analyses provide an opportunity to identify “imaging surrogates” for inferring gene expression. This is clinically applicable for patients with glioblastoma multiforme (GBM) who routinely undergo magnetic resonance (MR) imaging. However, current radiogenomic approaches make strong algorithmic assumptions, and results are potentially biased due to the many different ways that data is preprocessed and selected. The goals of this proposal are to (1) develop new radiogenomic models for identify imaging surrogates, and (2) systematically assess the robustness of radiogenomic findings. Aim 1: To evaluate the application of deep neural networks to discover radiogenomic associations. Aim 2: To compare resultant radiogenomic associations given different model inputs. Aim 3: To determine if the use of radiomic features increases specificity of radiogenomic associations. Methods: In Aim 1, deep neural networks will be trained on public GBM data from The Cancer Genome Atlas and Ivy Glioblastoma Atlas Project (gene expression), and The Cancer Imaging Archive (paired MR images). The model will take high-dimensional gene expression data and predict semantic imaging phenotypes derived from semi-automatically segmented regions-of-interest (ROIs) on MR images. To enable learning of deep networks, the gene expression profile of each patient will be parsed into numerous sparse vectors that encode molecular pathway information. After training, “activation maxi- mization” will extract imaging surrogates from the deep neural network. In Aim 2, a set of common feature selection methods will be applied to the gene expression data. Subsequently, the altered gene data will be the input to deep network to test their ability to derive consistent imaging surrogates. In Aim 3, radiomic features such as histogram and textural features will be extracted from the same ROIs segmented in Aim 1. Instead of semantic imaging phenotypes as the target output, the deep networks will take gene expression data and predict radiomic features. The inferred genes in each imaging surrogate from Aims 1–3 will be annotated with gene set enrichment analysis (GSEA) using several major biological knowledge bases as reference gene sets. Enrichment scores will be normalized, assessed for significance using permutation testing, and corrected for multiple hypothesis testing using the Benjamini-Hochberg method. Long-term Objective: The development and systematic evaluation of radiogenomic methods will help characterize the extent of overlapping information across biological scales in multimodal cancer patient data. Relevance to Public Health The generation of high-throughput methods in molecular biology and medical imaging has motivated the need to better understand multimodal cancer patient data. This research aims to develop new models to correlate tumor gene expression and its appearance in magnetic resonance images, and to perform a systematic evaluation of radiogenomic methods to study their robustness in identifying meaningful biological mechanisms.",
Vibrational Photoacoustic Microscopy for Bond-selective Tissue Analysis,"Vibrational Photoacoustic Microscopy for Bond-selective Tissue Analysis    DESCRIPTION (provided by applicant): A long term goal of our research is pursuing new understanding of molecular functions in health and disease via development of label-free microscopy. In this R21 application, we develop a new method termed vibrational photoacoustic (VPA) microscopy for 3-D vibrational imaging of tissues with a field of view and a penetration depth both in the mm scale. Our method is based on excitation of molecular overtone vibration and acoustic detection of the resultant pressure waves in the tissue. Our approach is significant in the following aspects: (i) Overtone excitation provides chemical bond selectivity and spectroscopic information in a label-free manner. (ii) Acoustic detection eliminates the tissue scattering problem encountered in near-infrared spectroscopy and enables depth-resolved signal collection in one scan. (iii) Our method provides a tissue penetration depth of a few mm, which is not accessible with existing vibrational microscopies. By excitation of the second overtone of the C-H bond stretch around 8300 cm-1, where blood interference is minimal, we have demonstrated preliminary VPA imaging of tissue phantoms and atherosclerotic plaques in arteries with a penetration depth in mm scale. These results show the great potential of developing VPA microscopy and endoscopy for label-free molecular imaging and spectroscopic analysis of lipid-related disorders in live animals and eventually in patients. The two specific aims are (1) developing high-speed VPA microscopy for in vivo molecular imaging and quantitative analysis and (2) developing VPA spectroscopy and endoscopy for in situ, depth resolved characterization of atherosclerotic plaques. Successful development of VPA microscopy should provide a new platform enabling label-free molecular imaging and spectroscopic analysis of biological specimen ex vivo and in vivo. Towards diagnosis of diseases such as atherosclerosis, VPA spectroscopy aided with principal component analysis should allow determination of lesion stages owing to the capability of identifying different pathophysiological compositions throughout deep tissues. Furthermore, our endoscopy development is expected to push the VPA method towards intravital imaging of plaques.        (provided by applicant): Intravital imaging of vulnerable plaques in cardiovascular diseases is difficult due to limited spatial resolution and/or chemical selectivity of current imaging tools. We develop a new method termed vibrational photoacoustic microscopy for 3-D vibrational imaging of tissues with a field of view and a penetration depth both in the mm scale. Successful development of an intravascular vibrational photoacoustic probe holds the potential of detecting vulnerable plaques in a label free manner.         ",
Health Information Technology for Surveillance of Health Care-Associated Infections,"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",
Rewiring the yeast brain:  Redundancy and interference in genetic networks,"Rewiring the yeast brain:  Redundancy and interference in genetic networks    DESCRIPTION (Provided by the applicant)   Abstract: Similar to neural networks in animals, molecular networks in cells can generate bistable or oscillatory dynamics that maintain memories of previous events (e.g. epigenetic switch) or order periodic events (e.g. cell cycle), respectively. In cells, networks of genes interacting with one another through regulatory feedback implement such dynamics. Analogous to learning in brains, cells can """"learn"""" correlations in their environmental signals by encoding such correlations into their gene network dynamics through mutation, a """"re-wiring"""" process that occurs on the timescale of generations. The issue of learning the statistical regularities and correlations of environmental signals is best exemplified by the evolution of """"circadian clocks"""", which are oscillatory gene circuits that have learned to internalize the 24-hour light-dark circadian cycle. Strikingly, circadian clocks have evolved independently multiple times, which suggests there exists some selection pressure and/or evolutionary mechanism that repeatedly favor the convergent evolution of autonomous oscillation. The hypothesis of my research proposal is that certain types of loss-of-function mutations in duplicated genes (known as dominant-negative mutations) can easily generate bistability and oscillation in existing regulatory networks. Gene duplication followed by a loss-of-function mutation can generate a dominant-negative. A dominant negative mutation is a partial loss-of-function mutation that renders a gene duplicate functionally inactive, yet still capable of interacting with the original duplicate, the upstream effectors, and/or downstream targets. Thus, dominant-negatives can easily interfere with the proper regulation and activity of the original duplicate. Because both gene duplication and loss-of-function mutations occur frequently in evolution, this presents an evolutionary mechanism for rapidly generating bistability and autonomous oscillation in gene regulatory networks. My proposed research over the next five years will integrate experiment and theory to understand the extent to which gene duplication and dominant-negative mutations facilitate the evolution of epigenetic switches and circadian clocks in regulatory networks. We will use computer simulation and an experimental directed evolution approach in a tractable, model eukaryote (Saccharomyces cerevisiae) to test the ability of cells to learn the statistical regularities of their coupled environmental signals. Understanding how and why single-cell microbes and parasites have learned to predict their environment is essential for understanding their future evolution to changing host conditions.   Public Health Relevance: The ability of parasites to learn and adapt to changing host conditions and environments presents a challenge to human health. The objective of my research proposal is to understand the capacity of gene networks in single cells to learn and predict the statistical regularities of their environment. Discovering the limitations and abilities of parasites to evolve and anticipate changes in their host environment will be invaluable for the treatment of many human diseases.       n/a",
Machine Learning Development for Subtyping COPD,"Machine Learning Development for Subtyping COPD Project Summary Chronic obstructive pulmonary disease (COPD) is a heterogeneous lung condition characterized by progressive loss of lung function with subsequent increasing breathlessness and worsening quality of life. This heterogeneity makes it difficult to predict health decline and develop targeted treatments for better patient care. To date, researchers have attempted to use standard machine learning methodology to identify more meaningful subtypes of COPD, but these methods often make general assumptions about the data, limiting their ability to penetrate more complex patterns in some data sets. Thus, a meaningful reclassification of COPD subtypes that could lead to more targeted therapies and interventions has been elusive. The applicant introduces a new way of looking at the COPD subtyping problem by recasting it in terms of discovering associations of individuals to disease trajectories – i.e., grouping individuals based on their similarity in response to environmental and/or disease causing variables. The machine learning methods proposed build on the most recent advances in Bayesian nonparametrics, a collection of theoretical ideas and techniques that permit very flexible data representations. In this career development proposal, the applicant hypothesizes that these machine learning methods and extensions thereof – together with data sources not previously leveraged for COPD subtyping – will produce more biologically meaningful sub-groupings of patients, leading to a better understanding of the genetic and biological underpinnings of the disease and ultimately improved patient management. Aim 1 of this application involves evaluating the utility of CT-assessed lung mass – a potentially more discriminative measure of emphysema than conventionally used measures – for defining COPD subtypes using both K-means clustering and our disease trajectory algorithm. The goal of Aim 2 is to evaluate the utility of comorbidity data for defining COPD subtypes using our trajectory clustering algorithm. Novel computed tomography based measures of muscle wasting (cachexia) and pulmonary vascular pruning will be explored to determine their efficacy in subtype determination. Additionally, we will extend and test the trajectory algorithm in order to model discrete outputs (such as physician-diagnosed comorbidities), count data (e.g. exacerbations), and time-to-event data (death). In Aim 3, the applicant will extend our trajectory clustering algorithms to directly incorporate genetic and omics data for subtype discovery. Together, the research proposed in the aims of this award will take full advantage of the comprehensive data set available through the COPDGene study. Execution of the aims in this proposal will be possible through active collaboration with Dr. Ron Kikinis, M.D., a renowned leader in the field of medical image analysis, and Dr. Ed Silverman, an internationally recognized expert in the genetic epidemiology of COPD. Project Narrative Chronic obstructive pulmonary disease (COPD) is a heterogeneous lung condition characterized by progressive loss of lung function with subsequent increasing breathlessness and worsening quality of life. This heterogeneity makes it difficult to predict health decline and develop targeted treatments for better patient care. In carrying out the research outlined in the following proposal, we plan to develop and apply machine learning methods to better identify subpopulations of individuals who have similar forms of COPD, potentially enabling better, targeted therapies.",
A Resource for Biomedical Ontologies and Knowledge Bases,"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",
RECOVERING A DENSITY FROM INCOMPLETE TOMOGRAPHIC DATA,"RECOVERING A DENSITY FROM INCOMPLETE TOMOGRAPHIC DATA The proposed research is in the field of tomography and has direct relevence for the uses of X-ray and other radiation in clinical diagnostic medicine.  The goal of the research is to discover and implement an effective computer algorithm to recover the density of the part of the body outside of a specified region from tomographic data (line integrals) from X-ray beams that do not pass through that region.  The same question will be studied for the plane integrals that are tomographic data gotten in one type of nuclear magnetic resonance zeugmatography.  Each algorithm will be tested on mathematical phantoms and medical data.  There are a number of compelling medical reasons for such an algorithm. For example, the beating heart creates error in regular chest tomograms, and bone or metal pins can create error in tomograms.  It is important to be able to get good tomographic reconstructions of the organs around these regions.  The way to do this is to develop the proposed algorithm.  Two methods of solution are proposed, one of which is based on the singular value decomposition of Professor Quinto.  Preliminary refinements are described that demonstrate the good potential of this method.  n/a",
Molecular Signatures of Early-Onset Neonatal Sepsis in Umbilical Cord Blood,"Molecular Signatures of Early-Onset Neonatal Sepsis in Umbilical Cord Blood PROJECT SUMMARY Early-onset sepsis (EOS) due to invasive bacterial infection is a leading cause of morbidity in infants and disproportionately affects those born preterm. Accurate diagnosis of EOS remains inadequate. The low sensitivity and delayed time to culture results combined with the poor predictive values of available laboratory markers leads to our inability to rule-out EOS. Thus, infants are exposed to extended duration broad-spectrum empiric antibiotics, which have serious associated adverse consequences such as necrotizing enterocolitis, antibiotic resistant infections, and an altered microbiome. The proposed research will apply proteomics to identify gestational age-specific umbilical cord blood markers toward development of a proposed diagnostic tool with strong negative risk prediction for EOS. Cord blood is promising to identify EOS as it reflects the intrauterine environment where infection originates in preterm birth. In previous work, we found that inflammatory proteins serum amyloid A, C-reactive protein and haptoglobin are substantially elevated in cord blood of preterm infants with culture-confirmed EOS. These data inform our hypothesis that a combination of cord blood proteins provides a signature to differentiate impending EOS and uninfected states. Archived cord blood from infants in an existing longitudinal cohort will be used in a nested case-control design. Aim 1 will measure the cord blood proteome of uninfected infants (controls) across gestational ages using an untargeted proteomics approach to characterize the developmental spectrum. Aim 2(a) will then determine the cord blood proteome signatures of infants with confirmed EOS (cEOS) and culture-negative presumed sepsis (PS). cEOS will be compared to matched controls to identify differentially expressed proteins and candidate markers. PS proteomes will be analyzed to help delineate true infection versus inflammatory subtypes in this heterogeneous group. Bioinformatics pathway analysis may provide novel insights into fetal immune response. Aim 2(b) will determine the best combination of markers to exclude EOS through machine learning decision analysis of proteomics data. Paired placental proteomics in Aim 2(c) will explore origins of fetal inflammation. Aim 3(a) will quantify candidate proteins by an orthogonal immunoassay method. In a validation set of new subjects, Aim 3(b) will measure candidate markers by targeted proteomics and test application of the proposed diagnostic tool. With formal didactics and a mentorship team at Northwestern University with expertise in prematurity, sepsis, biomarker discovery, biostatistics, and decision modeling led by Patrick Seed MD Ph.D., the candidate will gain advanced translational research experience and skills in perinatal research study design, advanced immunology, proteomics, and bioinformatics to further her research agenda. The proposed research and career development will be fundamental towards achieving the candidate’s career goals to: 1) lead a clinical-translational research program on the pathophysiology and host responses of perinatal infection and 2) bring new, reliable sepsis diagnostics to clinical practice, to improve neonatal outcomes through targeted treatment of EOS and antibiotic stewardship. PROJECT NARRATIVE Invasive bacterial infections in newborns carry a high risk of complications and death, yet current diagnostic methods are inaccurate, resulting in the harmful overuse of antibiotics. The proposed work will develop a multi- factor diagnostic model for early-onset neonatal sepsis using umbilical cord blood proteins as biomarkers and enhance our understanding of fetal immune response. These are critical steps toward improving infant health outcomes through both targeted treatment of infection and reduced unnecessary early-life antibiotic exposures.",
Developing and applying information extraction resources and technology to create,"Developing and applying information extraction resources and technology to create DESCRIPTION (provided by applicant): Building on 8 years of highly productive work in technology development that included the creation of the Colorado Richly Annotated Full Text corpus (CRAFT), we hypothesize that text mining resources and methods are approaching the level of maturity required to productively process a significant proportion of the full text biomedical literature to create a well-represented formal knowledge base of molecular biology. We propose a detailed, integrated plan to achieve this long-standing goal. Success in this effort will make possible a transformative new way for the biomedical research community to identify access and integrate existing knowledge, breaking down disciplinary boundaries and other silos that have kept scientists from fully exploiting relevant prior results in their research.      Our successes in the prior funding period broadened the applicability of biomedical concept identification systems to a much wider set of tasks, demonstrating the ability to target multiple community-curated ontologies in text mining, and generate scientifically significant insights from the results. The proposed work would take advantage of the resources we produced to transcend several of the limitations of previous efforts. We propose innovative new approaches to formal knowledge representation and to characterizing relationships between textual elements and semantic content. We will design, implement and evaluate computational systems that have the potential to transform enormous text collections into semantically rich, logic-based, standards-compliant, formal representations of biomedical knowledge with clearly identified provenance. The resulting representations will express complex assertions about a very wide range of entities, processes, qualities, and, most importantly, their specific relationships with one another. Program Director/Principal Investigator (Last, First, Middle): Hunter, Lawrence E. Project narrative  This project will affect public health by increasing the access of physicians, researchers, and the general public to highly targeted information from published research and electronic health records. PHS 398/2590 (Rev. 06/09) Page Continuation Format Page",
COMPUTING TUMOR DETECTION PERFORMANCE IN MEDICAL IMAGING,"COMPUTING TUMOR DETECTION PERFORMANCE IN MEDICAL IMAGING The overall goal is to optimize the design of medical imaging systems and reconstruction algorithms for the purposes of tumor detection in humans and animals.  For imaging systems this is done by devising efficient methods to calculate the performance of ideal observers that use the noisy data from the system on realistic tumor detections tasks.  These methods make use of symmetries of the imaging system, consistency conditions on the data, and constraints on the objects to simplify the computations.  Noise models are chosen to reflect the measurement noise in the system, the background variation in the patient population, and the normal variation in tumor characteristics. Performance of ideal observers is determined by the area under the receiver operating characteristic curve.  For a given detection task, this performance is a function of the parameters in the system design.  By varying these parameters the optimal design for tumor detection is found by maximizing this figure of merit.  When the ideal observer performance is too difficult to compute, the ideal linear observer is substituted.  For reconstruction algorithms, the performance of linear mathematical observers using the reconstructed images for tumor detection tasks is computed.  These model observers are chosen to match the performance of human observers on similar tasks.  To compute the performance of these observers, the first-order and second-order statistics of the reconstructed images are calculated or approximated.  These statistical moments are then used to compute the signal-to-noise ratio for the model observer on the given tumor detection task.  Of particular interest is the role of redundant data and null functions of the imaging system in the deterministic and statistical properties of the reconstruction algorithms.  n/a",
CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI,"CLASSIFICATION METHODS FOR DETECTING DISEASE LOCI DESCRIPTION (Adapted from the Investigator's Abstract): Bold steps must be       taken to advance our understanding of the genetic and associated co-             variates affecting the inheritance of complex diseases. To that end, this        proposal will develop improved quantitative methods to detect genetic            factors contributing to increased susceptibility to complex disorders and        implement these methods in software for distribution to the research             community.                                                                                                                                                        The methods will concentrate on the use of classification techniques             applied to allele sharing data and other risk factors which affect the           trait. Allele sharing methods for mapping genes will be extended to              include the classification methods known as latent class models, cluster         analysis, and artificial neural networks, as well as a novel use of              logistic regression Co-variates such as gender, parental diagnosis, or           other concomitant factors will be systematically studied through                 applications to both stimulated and existing data sets. An additional goal       is to determine the optimal distribution of relative pairs (e.g. siblings,       first cousins) for these methods. Of great importance to this proposal is        the development of well-documented, user-friendly software and                   documentation which will be distributed to the scientific community via          the Internet. Existing software developed by the PI will be extensively          expanded for latent class models. Existing cluster analysis software will        be modified and combined for ease of use.                                                                                                                         This proposal consists of theoretical exploration, computer simulation,          data analysis, and software development. First, solutions of theoretical         questions relating to classification techniques will be pursued; second,         adaptation of computer programs to implement the analytic methods, and           investigation into alternative research strategies will be accomplished.         The new strategies will be applied to stimulated data, and finally, to           existing data sets of pedigrees in which a complex trait has been                diagnosed. Findings from this research may contribute to the ability to          locate susceptibility loci in complex traits and to the clarification of         those etiological mechanisms responsible for susceptibility.                      n/a",
Objective assessment of surgical competence in a septoplasty model,"Objective assessment of surgical competence in a septoplasty model DESCRIPTION (provided by applicant): To ensure patient safety, educators must train surgeons to set standards of competency, public health officials should put in place policies to ensure surgeons remain competent and surgeons should only perform surgeries that they are competent to perform. Measuring surgeon's technical skill is crucial part of determining if they are competent. Traditionally surgical skill is assessed most commonly during training using subjective non-validated metrics. This leads to variation in the definition of competency. Recent policies set forth by the Accreditation Council of Graduate Medical Education- the governing body for graduate medical education, mandate that technical skill be measured objectively. Currently, there are few valid objective measures available to measure technical competence. Our research will yield a set of tools and methodologies that can be deployed to across medical training programs to objectively measure surgical skill and competence. This platform is also capable of developing new objective measure of skill and competence. Specifically, first, we will develop an objective skills assessment platform, and establish standard data collection and quality assurance protocols for systematic deployment of our platform across multiple institutions. Second, our work will result in automated algorithms and analytic tools to objectivel measure skill using data captured with our platform. Third, we will establish objective methods to determine whether a surgeon is competent to perform surgery. Fourth, we will test the reliability and validity of our assessment tools. We will conduct our study using septoplasty as the prototype test-bed procedure. Septoplasty is a commonly performed procedure (more than 260,000 cases per year) and is a key index surgery by which residents in otolaryngology are evaluated. Our project lays the groundwork for subsequent research to establish national standards for objective skill and competency using data aggregated from numerous training programs in the country. PUBLIC HEALTH RELEVANCE: Policies for graduate medical education require that surgical competency be objectively determined, but currently available technology and methods do not yield objective assessments for surgical skill. Our project aims to provide educators with an integrated objective skills assessment platform and tools for objective determination of competency, which can be readily deployed across graduate surgical training programs in the country.",
KNOWLEDGE BASES FOR STRUCTURED CARDIOVASCULAR REPORTING,"KNOWLEDGE BASES FOR STRUCTURED CARDIOVASCULAR REPORTING Healthcare has lagged behind other industries in automating the storage and retrieval of information. While billing, blood testing, and other services are widely computerized, the bulk of patient clinical information is not. The central barrier to coding clinically useful data - patient historical, test, and procedural results - is the absence of effective knowledge frameworks for entry and review of clinical data. For this reason, sofiware for storage and retrieval of patient data remains suboptimal. This project focuses on methods for recording a specific subset of patient data: results of cardiovascular tests, Although only a subset of clinical knowledge, cardiovascular procedure reporting is typical of the larger problem of how knowledge is handled. Moreover, there is an unmet market demand for cardiology reportrng tools. In Phase I we will develop a methodology for creating and maintaining the knowledge bases needed for structured entry of cardiovascular data. We will apply and hone this methodology by creating two important knowledge bases: echocardiography and cardiac catheterization. Together with the methodology we use, these two developments will dovetail into a larger Phase II  project of systematically addressing knowledge-representation and structured data entry for cardiology. Beyond Phase II  we will apply our methodology to other branches of medicine. PROPOSED COMMERCIAL APPLICATION: This research will provide a means to optimize structured recording of patient test results in a computer-searchable format improving the process of procedural reporting, and facilitating implementation of an electronic medical record.  n/a",
A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis,"A Hybrid Neural-Machine Interface for Volitional Control of a Powered Lower Limb Prosthesis Project Summary  The goal of the proposed work is to develop a robust hybrid neural-machine interface (NMI), combining brain and muscle signals, to improve overall control of a lower limb prosthetic device during activities of daily living. Limb amputation affects over 600,000 individuals annually in the US, and is a major cause of physical disability that causes activities of daily living to become difficult or impossible for the amputee. The limitations of current lower-limb prostheses are associated with limited volitional control, reduced mobility, and chronic gait abnormalities, which have been linked to exhaustion from increased energy expenditure, increased risk of falling, and degenerative bone and joint disorders in both the intact and amputated limb. In this study, EMG signals from both residual and intact lower limbs and EEG signals from the cortex are leveraged to decode transitions to and from various modes of locomotion modes in able-bodied individuals and transfemoral amputees, and to provide a global understanding of movement at the cortical, muscular, and kinematic level in amputees. Specifically, time and frequency domain features are leveraged to create a prediction algorithm capable of identifying upcoming terrain transitions in advance. In lower limb amputees, this hybrid NMI paradigm translates to volitional control of a powered lower-limb prosthesis, which allows for seamless transitions between various movement conditions. The high-level of control is expected to result in significant increases in level of activity and overall improvements in gait. Previous studies have demonstrated the feasibility of EEG or EMG based NMIs for orthotic and prosthetic devices; however, no study to date has integrated EEG and EMG in a NMI for powered lower limb prostheses. This study is motivated by the need to explore advanced neural control sources for intuitive control of artificial limbs.  This project aligns directly with the Mission & Goals of the NIH, the Brain Initiative, and NIH’s Blueprint Program by expanding fundamental knowledge of neuroscience, human, health and wellness; by utilizing an innovative research strategy; and ultimately returning the knowledge to the public through the development of a highly advanced medical technology. Furthermore, the technology developed through this work has implications beyond the amputee population in the treatment of many neurological conditions and injuries, such as in neurorehabilitation after stroke. The innovation of this project lies in the novel approach of using multimodal neural signals and movement synergies as a framework for interpreting movement of the lower limb. The scientific impact is realized by a greater understanding of the neural correlates of movement after lower-limb amputation. The direct clinical significance for the patient can be measured directly through improved gait performance and walking confidence, leading to increased mobility and a reduced risk of falling, exhaustion, and bone and joint disorders. Project Narrative  The development of a hybrid neural-machine interface that incorporates muscle and brain signaling for communication with robotic systems is important to public health because it allows for robust volitional control of powered prostheses and exoskeletons during activities of daily living. This will directly benefit the amputee population by allowing better control of their prosthesis during locomotion, especially when navigating complex terrains, such as stairs and inclines. The implications of this technology can be used beyond the amputee population to further understand the effect of neurological injuries on the brain, and for improving rehabilitation paradigms associated with their treatment.",
Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers,"Evidence-based Strategy and Tool to Simplify Text for Patients and Consumers ﻿    DESCRIPTION (provided by applicant): Lifespans continue to increase, chronic disease survival rates are drastically improved, and treatments are being discovered for a variety of illnesses. This rapidly changing scenario requires patients to participate in their recovery, understand written information and directions thereby calling upon patients to have increasingly more complex health literacy. However, time availability of practitioners or other resources to explain the required information has not increased to match. As a result, finding efficient means to improving patient health literacy is an increasingly important topic in healthcare. Increased health literacy may promote healthy lifestyle behaviors and increase access to health services by the population. It has been argued that for the Patient Protection and Affordable Care Act to be successful, more effort is needed to increase the health literacy of millions of Americans. Similarly, the Healthy People 2020 statement by the Department of Health and Human Services identified improving health literacy (HC/HIT-1) as an important national goal. The broad- long term objectives of this project are to contribute to increasing the health literacy of patients and health information consumers and provide caregivers an evidence-based tool for simplifying text. The most commonly used tool for estimating the difficulty of text is the readability formula. They are not sufficient, however, because there is no evidence to support a connection between their use and decreases in difficulty. This problem is addressed by using modern resources and techniques for discovering traits that make health-related text difficult and developing a tool to guide the simplification of text. . There are four specific aims of this project: 1) Identify differentiating features of easy versus difficult texts, 2) Design a simplification strategy using computer algorithms, 3) Measure the impact of simplification on perceived and actual text difficulty with online participants and a representative community sample, 4) Create free, online software that incorporates proven features algorithmically. Corpus analysis will be conducted to compare easy and difficult texts with each other and discover lexical, grammatical, semantic, and composition and discourse features typical for each. Then, simplification algorithms will be designed and developed relying on rule-based techniques to leverage available resources, e.g., vocabularies, or on machine learning approaches for discovering the best combinations of features for simplification. A representative writer will simplify text by relying on the suggestios provided by an online that tool that uses simplification algorithms. The effect of simplification wll be tested in comprehensive user studies to evaluate the effect on both actual and perceived difficulty. Features successfully shown to decrease text difficulty will be incorporated in an onlie software program designed to reduce text difficulty. PUBLIC HEALTH RELEVANCE: Improving health literacy is an important national goal and necessary trait for a healthy population. Providing understandable information is critical but few tools exist to help write understandable text. We aim to discover features indicative of difficult text, design translation algorithms and create a free, online software tool for rewriting health-related text with demonstrated impact on perceived and actual text difficulty",
NEUROPSYCHOLOGIC ASSESSMENT-CHRONIC DRUG ABUSE EFFECTS,"NEUROPSYCHOLOGIC ASSESSMENT-CHRONIC DRUG ABUSE EFFECTS The first project objective is directed to developing a comprehensive computer interactive neuropsychologic test battery that is sensitive for detecting subtle disturbances of cerebral integrity.  This task will be accomplished accessing a panel of neuropsychologists, an expert systems specialist and a software architect.  Next, standardization will be conducted on 500 normal adolescents and adults.  This sample will be stratified by age and gender and demographically representative of the population.  Concurrent to these activities, an expert system will be created.  This latter task will enable dissemination of the final protocol to the widest possible user audience.  Finally, the interactive test battery will be used to ascertain the prevalence, types and severity of neuropsychologic deficit in samples of adolescent and adult drug abusers.  The ultimate goal of this research program is to devise a standardized, quantitative and comprehensive method for characterizing the cognitive and psychomotor capacities of drug abusers.  Computer interactive testing, because of its precision in measurement, will enable the detection of subtle or occult impairment residual to chronic drug abuse. For this reason, the battery is to be created specifically for this population.  The information obtained from such an assessment has potentially important ramifications for determining the timing of treatment, type of treatment and post-treatment vocational rehabilitation of drug abusers.  n/a",
Michigan Hepatotoxicity Clinical Research Network Renewal 2018,"Michigan Hepatotoxicity Clinical Research Network Renewal 2018 Michigan Hepatotoxicity Research Network 2018 Renewal ABSTRACT In the past 5 years, the Drug Induced Liver Injury Network (DILIN) has increased cumulative enrollment to over 2000 adult and pediatric patients in the ongoing Prospective and Retrospective registry studies. In addition, an “Acute” DILI protocol with collection of serial early biological samples for mechanistic biomarker studies was developed and implemented. Other network aims included investigation of the role of genetic polymorphisms in DILI susceptibility and outcome, development of improved causality assessment methods, and expansion of the LiverTox website. The University of Michigan team led by Dr. Fontana has played an important role in the design, implementation, and analysis of the primary and ancillary DILIN studies since its inception in 2003. Michigan has not only been a leading enroller in all of the ongoing Registry studies but also provided important leadership in multiple DILIN committees and initiatives. The Michigan team now proposes a series of novel and feasible study aims for the DILIN renewal. The PRIMARY AIM of this proposal is to continue to recruit and enroll high causality adult and pediatric DILI cases into the registry studies for genetic, immunologic, biomarker and mechanistic studies. The Michigan Hepatotoxicity Network has specific plans to increase the enrollment of ethnic minorities via the engagement of hepatologists/ collaborators in southeastern Michigan and elsewhere that care for a large number of African American, Hispanic, and Asian patients. In addition, further development of natural language processing algorithms to search the EMR at the University of Michigan are proposed to facilitate enrollment. Qualitative, quantitative and toxicological studies of the chemical constituents in the herbal and dietary supplement (HDS) products implicated in a growing proportion of DILI cases will be expanded via an ongoing collaboration with the National Center for National Products Research. The SECOND AIM of this proposal is to conduct pilot/ feasibility clinical trials to improve the outcomes of patients with severe acute DILI and those at risk for developing chronic DILI. Proposed study designs include a 12 week course of a simple and safe, orally administered anti-inflammatory or anti-oxidant agent (e.g. budesonide, SAMe, vitamin E) in selected patients with severe acute DILI at risk for adverse outcomes. In addition, 12 to 24 week studies of a safe and effective orally administered anti- cholestatic agent such as an ileal apical bile salt transport inhibitor that may reduce serum bile acids are proposed for subjects at risk of chronic DILI. Lastly, prospective studies of magnetic resonance elastography and MRCP imaging are proposed to improve our understanding of the severity and natural history of DILI. The THIRD AIM of this proposal is to further expand the LiverTox website to include additional chapters on HDS DILI, develop and implement a computerized causality assessment instrument, and assemble working committees to insure that the website content remains up to date and pertinent. Finally, additional collaborations between DILIN and the US FDA and other regulatory agencies are proposed to enhance the pharmacovigilance capabilities of DILIN for new causes of DILI and temporal changes over time. PROJECT NARRATIVE The University of Michigan Hepatotoxicity Research Network proposes to improve our understanding of the etiologies, risk factors, and outcomes of DILI via the continued enrollment of adult and pediatric patients including targeted enrollment of ethnic minority patients that will help determine if there are racial differences in DILI susceptibility and outcomes via analysis of collected biological samples, DNA, liver tissue, and clinical data. Pilot/ feasibility clinical trials of simple, safe and mechanistically based treatments for patients with severe acute DILI and those at risk for developing chronic DILI are also proposed. Finally, further development and enhancement of the LiverTox website is proposed to include additional chapters on HDS DILI, development and implementation of a computerized diagnostic instrument, and expansion of the pharmacovigilance capabilities of DILIN.",
"A Wireless, Multimode, Artificial Neural Network-Based Physical Activity Monitor","A Wireless, Multimode, Artificial Neural Network-Based Physical Activity Monitor    DESCRIPTION (provided by applicant): Accurate measurement of physical activity in children and adults is a challenging problem that is important to epidemiologists, exercise scientists, clinicians, and behavioral researchers. Although there are a number of indirect and direct methods to assess physical activity and energy expenditure, all current methods have serious, well-documented shortcomings vis-`a-vis application to free-living individuals. Recent research has shown that the most practical, objective method for measuring physical activity in free-living individuals is the use of portable activity monitors that are based on the joint monitoring of heart rate and accelerometry. Under R21 grant funding, the proposing team developed and evaluated a novel Physical Activity Monitor (the PAM-R21) for use in estimating both energy expenditure and the time spent at different activity intensity levels (e.g., sedentary/light, moderate, vigorous). Using heart rate and triaxial accelerometry, the PAM-R21, which uses artificial neural networks to convert heart rate and triaxial accelerometer data into estimates of energy expenditure, outperformed the only commercially-available integrated heart rate/acceleration activity monitor (viz., Actiheart) in terms of estimated energy expenditure, activity intensity level, and heart rate. The research proposed herein will leverage the previously-developed PAM-R21 to create and validate a low-profile, next-generation PAM-R01 monitor; validity and reliability testing will be performed in diverse populations that will include children, adults, and seniors. The PAM-R01 will also be compared with existing activity monitors in both structured and simulated free-living activities across a broad range of physical activity intensities, including the transitional periods between activities. The PAM-R01 will be small, lightweight, and unobtrusive, and will have wireless transmission capabilities; it represents an important step in the advancement of effective, accurate measurement of physical activity. PUBLIC HEALTH RELEVANCE:  Physical activity is an important behavior that is related to reduce risk of a large number of negative health outcomes. However, the prevalence of physical inactivity remains unacceptably high; reducing the prevalence of inactivity is, therefore, a major focus of public health initiatives. The proposed development of the PAM- R01 activity monitor has the potential to remove one significant barrier that restricts research on the health effects of activity: the lack of an accurate, unobtrusive, and inexpensive device for measuring physical activity in free-living individuals. It also has strong potential for application in other areas, such as gait studies, pain management, and geriatric stability assessment and fall monitoring.          n/a",
Genetic analysis fo metabolic syndrome by admixture mapping in African Americans,"Genetic analysis fo metabolic syndrome by admixture mapping in African Americans    DESCRIPTION (provided by applicant): Metabolic syndrome is a constellation of cardiovascular risk factors including abdominal obesity, atherogenic dyslipidemia, hypertension, insulin resistance, and a pro-inflammatory and pro-thrombotic state. A major risk factor for type 2 diabetes and early-onset cardiovascular disease, metabolic syndrome affects an estimated 25% of Americans. Metabolic syndrome traits differ among ethnic groups. African-Americans tend to have greater insulin-resistance and higher blood pressure than European-Americans; conversely, European- Americans have more atherogenic lipid profiles. In African-Americans, some metabolic syndrome traits correlate with African ancestry (insulin resistance, blood pressure), and others traits correlate with European ancestry (visceral fat, low HDL cholesterol, high triglycerides), suggesting that distinct genetic variants modulating these traits have been inherited from the two ancestral populations. We hypothesize that genetic loci underlying metabolic syndrome traits can be identified by admixture mapping in African- Americans. Admixture mapping is a genome-wide approach for identifying disease-associated genetic variants, which have a high allele frequency difference between ancestral populations. Admixture loci share linkage disequilibrium with ancestry-informative markers across large genomic segments and can be mapped using relatively few genetic markers, compared to genome-wide association studies. We propose to perform admixture mapping for all metabolic syndrome traits in a combined cohort of 2000 African-Americans from the Cardiovascular Health Study (CHS) and the Health, Aging and Body Composition Study (HABC). We will validate our findings via joint analyses with admixture mapping results from the Jackson Heart Study (JHS). We will perform admixture mapping for the following quantitative traits, individually and after principal component analysis: abdominal fat, obesity, fasting glucose and insulin, triglycerides, HDL and LDL cholesterol, serum inflammatory and thrombotic markers, and blood pressure. We will specifically focus on the role of abdominal visceral fat in metabolic syndrome by comparing results from mapping MetS traits with and without adjusting for visceral fat burden. Visceral fat measurement is uniquely available in HABC and JHS, and the collaboration between HABC and JHS will provide a novel and unique opportunity to identify genetic loci affecting metabolic syndrome traits independently of the profound effect of visceral fat. We will validate findings in joint analyses of the two independent cohorts. Our final goal is to perform fine mapping for the 4-6 most promising candidate loci among the traits analyzed to identify the underlying causative variants. Dissection of genetic influences on metabolic syndrome traits in a large ancestry-admixed cohort will illuminate the etiology of population differences in metabolic syndrome characteristics and prevalence and lay the foundation for research into population-specific management and treatment.  PUBLIC HEALTH RELEVANCE:  People with metabolic syndrome, an increasingly common health problem affecting a quarter of all Americans, have abdominal obesity, high blood cholesterol and glucose levels and high blood pressure, and have increased risk of diabetes, stroke and heart disease. We will identify genes related to metabolic syndrome by genetic mapping in African Americans, who have inherited different genetic variants from their African and European ancestors; these inheritance patterns make it easier to find genetic changes associated with disease. Our work will improve understanding of the effects of genes and lifestyle on the onset, progression and risks of Metabolic Syndrome in different ethnic groups, and, in the future, help develop specific disease management and treatment approaches to lessen the negative impact of Metabolic Syndrome on health.              PROJECT NARRATIVE People with metabolic syndrome, an increasingly common health problem affecting a quarter of all Americans, have abdominal obesity, high blood cholesterol and glucose levels and high blood pressure, and have increased risk of diabetes, stroke and heart disease. We will identify genes related to metabolic syndrome by genetic mapping in African Americans, who have inherited different genetic variants from their African and European ancestors; these inheritance patterns make it easier to find genetic changes associated with disease. Our work will improve understanding of the effects of genes and lifestyle on the onset, progression and risks of Metabolic Syndrome in different ethnic groups, and, in the future, help develop specific disease management and treatment approaches to lessen the negative impact of Metabolic Syndrome on health.",
Novel computer vision-based assessment of infant-caregiver synchrony as an early level II screening tool for autism,"Novel computer vision-based assessment of infant-caregiver synchrony as an early level II screening tool for autism PROJECT SUMMARY This R21 addresses a critical need for accurate and scalable screening tools able to detect autism spectrum disorder (ASD) within the first year of life. This project will pilot an innovative digital phenotyping screening method, which uses computer vision and machine learning to measure synchrony within simple infant-caregiver interactions. Synchrony refers to the tendency for infants to spontaneously and dynamically coordinate their behaviors with their caregivers in time. This critical and early-emerging developmental process may provide unique and precise information about an infant’s risk for ASD, while also offering a lens for understanding early social interaction differences at the core of ASD. Significance: This project represents a paradigm shift in ASD screening, moving beyond behavior rating scales toward methods that are better suited to capture the subtle early indicators of ASD. Caregiver rating scales lack the granularity and objectivity necessary for detecting signs of ASD that emerge slowly and subtly throughout the first year. Approach: The interdisciplinary study team will leverage cutting-edge technology to objectively and granularly measure synchrony within 5-minute, play-based infant-caregiver interactions. Markerless computer vision will be used to quantify facial movements, captured unobtrusively with small, bidirectional cameras. The dyadic synchrony among infants’ and caregivers’ facial movements will then be calculated throughout the interaction, as part of an automated machine learning pipeline. Preliminary Data: We evaluated this approach in young adults with and without ASD during brief conversational interactions with research staff members. In a machine learning analysis pipeline, synchrony features classified diagnosis with 91% accuracy - significantly better than expert clinicians assessing the same videos. The same set of synchrony features significantly predicted symptom severity in the ASD group, suggesting that this method is effective for both diagnostic classification and dimensional prediction of individual differences. Importantly, the pipeline also classified diagnosis in children with similarly high accuracy, demonstrating the reproducibility of results across age groups. Aims. This project extends these computer vision-based methods to infants, with the overarching goal of evaluating their utility as a Level II screener for ASD. Aim 1 will evaluate the concurrent validity of our computational measures of interactional synchrony by evaluating their relationships with an established clinician-administered assessment of early ASD markers. Aim 2 will assess the utility of our interactional synchrony measure as a Level II screening tool at 12 months, by testing its ability to predict future ASD diagnosis with high specificity. Impact: This R21 will provide initial validation for a novel, computer vision- based screener for ASD in infancy. By targeting the dynamics of natural infant-caregiver interactions, this method has the potential to identify very early signs of disrupted social development, even before classic ASD symptoms emerge. Moreover, this quick interaction-based screener would fit easily into the context of routine pediatric care, holding promise as a Level II screener deployable within a universal screening framework. PROJECT NARRATIVE This project tests a new method of screening for autism spectrum disorder (ASD) in infancy, leveraging computer vision and machine learning to develop a screening tool that detects alterations in the dynamic social coordination between infants and caregivers during brief, play-based interactions. There are currently no screening tools capable of reliably detecting ASD in the first year of life, and in particular, no tools based on direct measurement of behavior that can be feasibly deployed in primary care. This project addresses this critical public health challenge by examining an objective, granular, and scalable Level II screener, which has potential to lower the average age of diagnosis by identifying very early signs of disrupted social development, even before classic ASD symptoms emerge.",
"Leveraging large-scale national data to understand, reduce, and prevent benzodiazepine-related harms among older adults","Leveraging large-scale national data to understand, reduce, and prevent benzodiazepine-related harms among older adults Benzodiazepine (BZD) use in the U.S. is common and increases with age. In a recent analysis, 8.7% of adults aged 65-80 years were prescribed BZDs during one year, even though a robust set of studies have established their association with a variety of adverse outcomes in older adults, including increased risk of falls and fractures, motor vehicle accidents, impaired cognition, and pharmaceutical overdose. Patients and their providers are then reluctant to change use once started, which may account for why older adults experience the highest rates of long-term BZD use. Relatively little is known about the patient, provider, and community characteristics associated with starting and continuing BZD prescribing to older adults, yet this is critical to develop effective selective and indicated prevention strategies. In Aim 1, we will describe the patient, provider, and community characteristics associated with BZD initiation and continuation using a national 20% sample of Medicare beneficiaries (n=3.6 million) linked to provider data from the American Medical Association (AMA) Physician Masterfile and community characteristics from the Area Health Resources File (AHRF). We will extend our analysis with OptumInsight data (n=6.7 million) to gain additional insights among commercially insured adults aged 50-64 given increased substance use among the Baby Boom cohort. Those patients currently prescribed BZDs and most at risk for BZD misuse (e.g., overlapping BZD prescriptions from multiple providers) and BZD-related overdose should receive indicated prevention strategies to address this potentially harmful use. In Aim 2, among those prescribed BZD, we will determine specific risk factors associated with BZD misuse and BZD-related overdose; these data will be used to develop a misuse clinical prediction tool. Using BZD users 50+ years old identified in Medicare and Optum, we will determine characteristics of patients and their prescribed BZD (e.g., high potency) most associated with misuse and overdose. We will then use machine learning to create a simple clinical prediction tool that providers can use to identify older adults at risk for misuse in their practices. Finally, in Aim 3 we will conduct semi-structured interviews with providers and patients to package and script the use of the clinical prediction tool for providers seeking to engage high-risk BZD use patients. This aim is critical to improve the impact of our findings since psychological dependence on BZD can make reducing use a difficult topic for physicians and patients to address. We will conduct interviews with providers and older adult primary care patients (n=15 each) to obtain feedback to package and script the use of the clinical prediction tool, which we will make publicly available by website. The impact of our work will be to: 1) provide a detailed, national portrait of the factors that contribute to BZD use and misuse; 2) determine the older adults most at risk for serious adverse events; and 3) develop and package a clinical prediction tool to help providers address BZD use in their high-risk patients. Millions of older adults in the US are prescribed benzodiazepines (BZD) every year despite extensive evidence of the associated harms. This proposal will provide a detailed, national portrait of the patient, prescriber, and community characteristics that determine who receives a prescription. In addition, we will determine which patients are at risk for overdose or prescription BZD misuse and develop a simple clinical prediction tool providers can use to identify these patients in practice.",
Whole Transcriptome Studies of Patients with Transient Ischemic Attacks (TIAs),"Whole Transcriptome Studies of Patients with Transient Ischemic Attacks (TIAs) ﻿    DESCRIPTION (provided by applicant): Transient ischemic attacks (TIA) are critical to identify because prevention therapy can reduce the risk of future vascular events by > 50%. Diagnostic testing and therapeutic intervention must start as soon as possible because 10-25% of TIAs have a stroke within 90 days. Because so many patients present emergently with transient neurological events the large majority of whom do not go on to have a stroke, methods for identifying TIAs at high risk for stroke have been sought so that work up and treatment can be targeted to those who need it most to save time, money and limited resources. Though the ABCD2 score and brain Diffusion Weighted Imaging-MRI (DWI-MRI) have improved prediction of which TIAs have a stroke, their sensitivity and specificity for prediction of individual cases i poor. In this proposal we propose that peripheral blood leukocytes and platelets play pivotal roles in which TIAs go on to have a stroke and by assessing RNA in whole blood we can evaluate leukocyte and platelet function in TIA patients who go on to have stroke versus those that do not have a stroke. We hypothesize that specific coagulation and immune genes are activated in TIA patients that predispose them to have a stroke by 90 days compared to those TIA patients who do NOT have a stroke by 90 days. A subset of these leukocyte and platelet mRNA genes will predict TIAs who have a stroke by 90 days. This hypothesis is addressed by the following specific aims. Aim #1 (Derivation Cohort): Demonstrate that mRNA expression measured using RNAseq from whole blood differs in a derivation cohort of TIAs that go on to have a stroke by 90 days compared to those TIAs who do not have a stroke by 90 days. Demonstrate that most mRNA found to be regulated using RNAseq are also significantly regulated when measured using qRT-PCR. Aim #2 (Derivation Cohort): Apply machine learning algorithms to the mRNA from Aim #1 to derive an optimal subset of mRNA regulated by both RNAseq and qRT-PCR that predict which TIAs have strokes by 90 days compared to those who do not with >95% sensitivity on cross-validation. Aim #3 (Validation Cohort): Use machine/prediction learning algorithms to demonstrate that the genes from Aim #2 when measured using qRT-PCR on an independent validation cohort predict which TIAs have a stroke by 90 days with >85% sensitivity. The goal of these studies is to discover mRNA profiles in blood that predict which TIA patients go on to have strokes by 90 days. When confirmed in future studies, this will direct in depth testing to those high risk TIAs most in need in order to prevent strokes, and decrease unnecessary testing in those with low risk of stroke. Equally as important, the genes discovered to be associated with high risk of stroke in TIA patients will represent potential novel stroke prevention targets. PUBLIC HEALTH RELEVANCE: This project will examine RNA in blood using RNAseq and qRT-PCR of human subjects with Transient Ischemic Attacks (TIAs) who have a stroke by 90 days compared to TIAs who do not have a stroke. The regulated mRNA, exons and alternatively spliced transcripts in a Derivation Cohort of TIA patients will be used to predict which TIAs have a stroke by 90 days in a Validation Cohort of TIA patients.",
THEORETICAL ANALYSIS OF DNA SUPERHELICAL EQUILIBRIA,"THEORETICAL ANALYSIS OF DNA SUPERHELICAL EQUILIBRIA This research program will develop accurate theoretical methods for analyzing secondary structural equilibria in superhelical DNA molecules of kilobase length and specified sequence, in which all transitions compete to which the sequence is susceptible.  These include B-Z transitions, cruciform extrusions, B-H transitions, and strand separation.  Methods also will be developed for handling local sequence effects, known to occur in practice, that complicate the energetics of transitions and the calculation of equilibria.  Examples include chemical adducts, abasic sites or other disruptions of base pairing, and imperfect susceptible sequences such as imprecise inverted repeat symmetry or purine-pyrimidine alternation.  Methods based on Monte Carlo techniques will be developed for the analysis of superhelical secondary structural transitions at high temperatures or in extremely long DNA sequences (approximately 105 base pairs).  Monte Carlo methods also will be developed to analyze the interplay between transitions and bending deformations in superhelical  DNA molecules.  Transition state theories of the kinetics of superhelical transconformation reactions will be developed and tested against available data.  Collaborations with several experimental groups will illuminate roles that superhelical DNA conformational transitions play in normal and pathological processes. These include projects examining:  1) the role of superhelical strand separation in the initiation of replication; 2) mechanisms by which superhelicity enhances DNA sensitivity to single strand breakage by x- rays, and; 3) superhelical cruciform formation at orthopoxviral telomere sequences and its role in replication.  The analytic techniques developed in this research will be used to deduce from experimental data the values of important energetic and conformational parameters governing superhelical transitions.  The effects of sequence modifications and imperfections on the energetics of superhelical transitions will be found in several specific cases.  These will include determining the influence of violations of perfect inverted repeat symmetry on cruciform extrusion, the effects of base methylation on strand separation, and the energetics of strand separation in molecules containing abasic sites or chemical adducts.  Transition and destabilization profiles will be calculated for a variety of DNAs to determine how local susceptibilities to specific transitions correlate with regulatory regions, mutational hotspots, chromosomal breakpoints and other sites of biological activity.  n/a",
Multivariate methods for identifying multitask/multimodal brain imaging biomarkers,"Multivariate methods for identifying multitask/multimodal brain imaging biomarkers Project Summary/Abstract  The brain is extremely complex as we know, involving a complicated interplay between functional information interacting with a structural (but not static) substrate. Brain imaging technology provides a way to sample various aspects of the brain albeit incompletely, providing a rich set of multitask and multimodal information. The field has advanced significantly in its approach to multimodal data, as there are more studies correlating, e.g. func- tional and structural measures. However the vast majority of studies still ignore the joint information among two or more modalities or tasks. Such information is critical to consider as each brain imaging modality reports on a different aspect of the brain (e.g. gray matter integrity, blood flow changes, white matter integrity). The field is still striving to understand how to diagnose and treat complex mental illness, such as schizophrenia, bipolar disorder, depression, and others, and ignoring the joint information among tasks and modalities is to miss a critical, but available, part of the puzzle. Combining multimodal imaging data is not easy since, among other reasons, the combination of multiple data sets consisting of thousands of voxels or timepoints yields a very high dimensional problem, requiring appropriate data reduction strategies. In the previous phase of the project we developed approaches based on multiset canonical correlation analysis (mCCA) and joint independent compo- nent analysis (jICA) that can capture high-dimensional, linear, relationships among 2 or more modalities, and which we showed can identify both modality-unique and modality-common features that are predictive of dis- ease. In this new phase of the project we will focus on two important areas. First, we will build on our previous success by extending our models to allow for incorporation of behavioral/cognitive constraints as well as devel- oping new approaches which leverage recent advances in deep learning enabling us to capture higher order relationships embedded in multimodal and multitask data. Secondly, we will address the key challenge of inte- grating possibly thousands of multimodal features by developing a new meta-modality framework which will enable us to bring together the existing and new features in an intuitive manner. This will also enable us to capture changes in multimodal information which might not be harmful separately but which together are jointly sufficient to convey risk of illness or to identify information flow through the meta-modal space for developing potential targets for treatment. We will apply these approaches to one of the largest multimodal imaging datasets of psychosis and mood disorders. Our proposed approach will be thoroughly evaluated using this large data set which includes multiple illnesses that have overlapping symptoms and which can sometimes be misdiagnosed and treated with the wrong medications for months or years (schizophrenia, bipolar disorder, and unipolar de- pression). As before, we will provide open source tools and release data throughout the duration of the project via a web portal and the NITRIC repository, hence enabling other investigators to compare their own methods with our own as well as to apply them to a large variety of brain disorders. 36 Project Narrative  The promise of multimodal imaging is clear, and we have shown the power of linear joint N-way analysis during the previous funding period. However this is just the beginning. In this renewal, we will build on and significantly expand the goals of the original aims by incorporating additional joint information (including dynamic and potentially nonlinear factors) as well as a framework for integrating the resulting information in order to enable decision making and identification of potential targets for further study or possible treatment. We will also disseminate our approaches through software tools and interactive web-based visualization of available data. 37",
Novel mechanisms and treatment of arrhythmia during resuscitation,"Novel mechanisms and treatment of arrhythmia during resuscitation Resuscitation from sudden cardiac arrest (SCA) is typically initiated in patients with ongoing ischemia and ventricular fibrillation (VF) or tachycardia (VT) that, even if successful, is commonly followed by repeated rearrest. Despite significant efforts to improve resuscitation from SCA, survival remains poor prompting NIH to identify resuscitation as a high priority for emergency care research. Beat-to-beat alternans of cellular repolarization in the myocardium (repolarization alternans) is a substrate for arrhythmias, is rampant during resuscitation, and is manifested on the ECG as T-wave oscillations that can alternate (2:1) or as more complex oscillations. In preliminary studies, we observed in resuscitation patients and in an in vivo translational model of resuscitation from SCA, that rearrest due to VT/VF is preceded by T-wave oscillations that are complex; whereas, rearrest due to pulseless electrical activity (PEA) is preceded by increased T-wave oscillations that alternate. Accordingly, we contend that when T-wave oscillations are complex, repolarization alternans in the myocardium is spatially discordant, which is repolarization alternans occurring out-of-phase in adjacent regions and is highly arrhythmogenic. In contrast, when T-wave oscillations alternate, repolarization alternans in the myocardium is spatially in-phase (concordant), which poses no known immediate arrhythmia risk but is associated with mechanical dysfunction and, thus, PEA. Finally, in the absence of any repolarization alternans, risk of rearrest due to PEA or VT/VF is low. We hypothesize that during resuscitation rearrest due to VT/VF or PEA is strongly linked to repolarization alternans in the myocardium that is spatially discordant or not, respectively, and that specifically targeting the underlying mechanisms can prevent rearrest due to VT/VF and, possibly, PEA. In addition, the full spectrum of ECG T-wave oscillations can be utilized to predict no rearrest and rearrest from VT/VF or PEA and, thus, be used in the future as a biomarker to guide therapy and significantly improve outcomes. Our hypotheses will be tested with the following aims. 1) Determine the mechanistic relationship between cellular repolarization alternans and rearrest due to VT/VF or PEA in an in vivo model of resuscitation. 2) Determine if targeting the mechanisms of repolarization alternans can prevent rearrest during resuscitation, thereby gaining additional mechanistic insight. 3) Develop and test an ECG biomarker for predicting risk of rearrest due to VT/VF and PEA in resuscitation patients. To achieve these aims, we will utilize sophisticated instrumentation and signal processing in an in vivo translational model of resuscitation as well as in pre-hospital and in- hospital resuscitation patients. We have also established a highly translational collaboration that combines expertise in emergency medicine, cardiac arrhythmia, and clinical electrophysiology. Our scientific environment provides a unique opportunity to develop a better understanding of arrhythmia mechanisms relevant to resuscitation in order to develop novel and effective therapies. Project Narrative Sudden cardiac arrest (SCA) due to arrhythmia is a major public health problem and despite significant efforts to improve resuscitation from SCA, rearrest and survival remain poor. Consequently, improved approaches are needed, and NIH has recently identified resuscitation as a high priority for emergency care research. We propose to investigate the mechanisms of rearrest during resuscitation to develop novel and effective therapeutic strategies that improve outcomes.",
The Neural Bases of he Semantic Structure of Words and Concepts,"The Neural Bases of he Semantic Structure of Words and Concepts    DESCRIPTION (provided by applicant): This project proposes to discover the neural representation of some simple words and concepts. It uses newly developed machine learning techniques and dimension reduction methods applied to fMRI brain activation data that will be acquired in new experimental paradigms. This research approach has for the first time succeeded in identifying the content of individual human thoughts based on the pattern of brain activity. The initial published studies have demonstrated this capability in the case of concrete nouns and physical objects. This project proposes to expand the approach to a much larger set of different types of concepts and to examine the effect of the way the concept is presented (e.g. a written or spoken word, or a picture). The goal is to develop a comprehensive theory of how neural representations of meaning arise from the various brain systems that are used in interacting or considering the concept. An important secondary goal is to determine the degree of commonality of the neural representations across people.  The studies propose to examine the neural dimensions of meaning in three domains: (a) physical objects; (b) human traits, emotions, and interpersonal interactions; and (c) small numerical quantities. This set of semantic domains is expected to provide sufficient breadth to reveal some of the principle neural bases of semantic representation.  In contrast to the field of ""semantics"" (the study of the relation between words and their meanings), this project will help establish a new research area, neurosemantics, which is the study of the relation between words, thoughts, and their neural representations. The key assumption is that the underlying dimensions of meaning representation in the human brain are derived from basic neural systems. For example, one of the dimensions of representation of a physical object is how one physically interacts with or handles it. This dimension of representation is underpinned by a network of cortical areas that co-activate when one thinks about a physical object, and also when one actually handles the physical object. Other dimensions of neural representation similarly emerge when the concept is encountered. The studies will collectively identify the major dimensions of concept representation and relate them to networks of co-activating brain areas.  The cumulative knowledge from the completed project will provide the framework of a theory of how brain systems map onto the representation of the meaning of concepts. The theory will be applicable to understanding and designing therapies for neurological conditions in which the meanings of concepts are distorted, such as Alzheimer's Disease, Pick's Disease, semantic dementia, and autism. The resulting theory will be foundational in relating the representation of meaning to brain function.      PUBLIC HEALTH RELEVANCE: The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.              PROJECT NARRATIVE - RELEVANCE  The research has application to a number of neurological disorders, where the new approach is capable of (1) determining whether and how the neural representation of a particular set of concepts is distorted; (2) tracking the progressive loss of neurosemantic components in disorders affecting the representation of meaning (including Alzheimer's Disease, Pick's Disease, semantic dementia, and anomic aphasia); (3) identifying the particular neurosemantic dimensions that are affected by the disorder; and hence (4) pointing the way to the design of a therapy. More generally, as a recent review (Bray et al., 2009) indicates, the new approach provides a good match to the brain characteristics of several brain disorders, and it is beginning to be applied for health-related purposes in many domains.",
Dietary and Microbial Reprogramming of Intestinal Microbiota-Produced Metabolites,"Dietary and Microbial Reprogramming of Intestinal Microbiota-Produced Metabolites DESCRIPTION (provided by applicant): The microbes that live in the human gut microbiota possess novel and ill-defined metabolic capabilities. Many of the metabolites produced by this microbial ecosystem are absorbed by the human host and ultimately excreted by the kidneys. Such solutes accumulate when the kidneys fail and comprise a significant portion of the ""uremic"" solutes found at very high level in the plasma of patients maintained on dialysis. p-cresol sulfate (PCS), indoxyl sulfate (IS), and trimethylamine-N-oxide (TMAO) are three prominent uremic solutes that depend upon microbial metabolism of diet-derived molecules. Each exhibits inter-individual variability in the quantities produced, suggesting that microbiotas differ in their ability to produce these molecules. PCS and IS have been associated with poor outcomes in renal patients and TMAO has been linked to cardiovascular events in humans. The ultimate goal of this research is to understand how the human gut microbiota may be modulated to decrease the production of these compounds. The main objectives are to elucidate (i) the microbial genes and species that are the key contributors to PCS, IS, and TMAO production; (ii) the impact of diet on the production of these solutes; and (iii) the best method for reprogramming a high-producing microbiota to a low-producing phenotype via administration of other gut-derived species. In Aim 1 a new machine learning software, ClusterFinder, will be used to query ~900 sequenced gut microbiota genomes to predict genes and gene cassettes that contribute to PCS, IS, or TMAO generation. Predictions will be validated in pure culture and in vivo, using a gnotobiotic mouse model in single and multiple species colonizations. Gene predictions will be genetically validated using gene deletion or heterologous expression. In Aim 2 healthy omnivorous humans with stable high and low urinary TMAO, PCS and IS production will be identified. Microbiome-encoded genes and taxa associated with solute production phenotypes will be determined by analyzing stool samples for these individuals using 16S rRNA-based microbiota enumerations, metagenomics, and metatranscriptomics. Aim 3 will address whether diet affects the production of TMAO, PCS, or IS using either gnotobiotic mice colonized with bacterial consortia validated in Aim 1, and a humanized mouse model, consisting of ex-germ-free mice colonized with the human fecal microbiota identified in Aim 2 of high- and low-producers of TMAO, PCS, or IS. Diets will include high vs. low fiber, high vs. low protein, or L-carnitine supplemented vs. vegetarian. Decreases in TMAO, PCS and/or IS production will be associated with changes in microbiota composition and function. Aim 4 will identify the most effective method for microbiota reprogramming in humanized mice to decrease TMAO, PCS and IS production using transplants of an intact microbiota, donor microbiota generated culture collections, or type strain representatives. The use of antibiotics before transplant and the influence of dietary reinforcement will be tested as methods of aiding microbiota reprogramming. PUBLIC HEALTH RELEVANCE:  A vast and diverse community of microbes known as the gut microbiota colonizes the human intestine. The microbiota is largely a beneficial community, but also produces some potentially toxic compounds that can accumulate to high levels in the circulation of dialysis patients. This proposal defines how diet contributes to the production of these compounds and how the microbiota can be rationally altered to produce less of these compounds.",
Machine Learning Algorithms to Measure Physical Activity in Children with Cerebral Palsy,"Machine Learning Algorithms to Measure Physical Activity in Children with Cerebral Palsy PROJECT SUMMARY/ABSTRACT Cerebral palsy (CP) is the most common physical disability of childhood with a prevalence of 2.5 to 3.6 cases per 1000 live births. Inadequate physical activity (PA) and poor fitness are major problems impacting the health and well-being of children with CP. Moreover, low PA may contribute to the development of disabling secondary conditions such as obesity, chronic pain, fatigue, and osteoporosis. Children with CP frequently undergo therapeutic interventions and/or orthopedic surgery to improve their mobility and increase habitual PA. The primary outcome measures used pre-post interventions are typically clinical measures of gross motor function or functional capacity. None of these tests, however, measure PA performance.  Accelerometry-based motion sensors are the method of choice for assessing PA in children. Our group has shown that accelerometers provide valid and reliable assessments of ambulatory activity in youth with CP. We have developed and validated CP-specific count thresholds to estimate time spent in sedentary, light-intensity, and moderate-to-vigorous intensity PA. However, there is a knowledge gap on optimal approaches in accelerometer data processing to measure PA in children with CP especially given the misclassification error and because cut-points do not perform well in children with more severe functional limitations.  The long-term goal of this project is to improve PA measures in children with CP. The overall objective of this application is to use machine learning in accelerometer data processing to improve PA measures in children with CP. The proposed study will be the first to develop, evaluate, and deploy machine learning algorithms to measure activity type and energy expenditure in children with CP. The specific aims of this project are to: 1) Develop and test machine learning algorithms to predict PA type, walking speed, and energy expenditure in ambulant children and adolescents with CP; 2) compare the accuracy of PA intensity estimates provided by machine learning algorithms to those provided by conventional cut-point methods; and 3) evaluate the performance of the resultant CP prediction models in an independent sample of children with Acquired Brain Injury (ABI).  The proposed project is in line with the NIH mission because the resultant prediction models will enable clinicians and rehabilitation professionals to more effectively monitor the PA levels of their patients to improve health and function. Improved objective measures of PA will also enable health researchers to better understand the short-and long-term health benefits of regular PA and impact of PA on adverse health conditions associated with CP. PROJECT NARRATIVE The proposed research study is relevant to public health because it examines innovative machine learning approaches in measuring physical activity in ambulant children with cerebral palsy (CP); a condition that is the most prevalent physical disability of childhood resulting in compromised neuromuscular and musculoskeletal function with secondary co-morbidities (i.e., decreased fitness, functional mobility and physical activity), and increased health utilization and cost. Accurate, yet practical clinical physical activity measures to examine rehabilitation effectiveness for children with CP are currently unavailable, despite an emphasis on activity- based interventions to promote function and physical activity. Thus, the proposed research is relevant to the NIH's mission in that it seeks to generate new knowledge on optimal physical activity measures and contribute this knowledge to clinical applications to measure physical activity outcomes in children with CP.",
Extraction of molecular signature of HFpEF via a machine learning-empowered proteomic characterization: A study of the BCAA pathway,"Extraction of molecular signature of HFpEF via a machine learning-empowered proteomic characterization: A study of the BCAA pathway PROJECT SUMMARY Heart failure with preserved ejection fraction (HFpEF), characterized by heart failure symptoms with normal ejection fraction, is highly prevalent. However, most HFpEF patients do not respond to standard therapy for heart failure with reduced ejection fraction (HFrEF), and there are no clear and uniform diagnostic criteria to stratify and differentiate HFpEF from HFrEF. Therefore, there is a pressing unmet need for us to better understand HFpEF at the molecular and system levels. Unbiased approaches such as machine learning (ML) offer a powerful means to tease out the molecular signatures of HFpEF in relevant disease models. The emerging evidence implicates that metabolism and redox homeostasis are two significant disruptions in cellular processes evidenced by clinical symptoms of HFpEF. Previous studies have identified branched-chain amino acid (BCAA) catabolic defect as another major metabolic hallmark in heart failure as well as in metabolic disorders. Moreover, BCAA catabolic defects have been demonstrated to directly impact mitochondrial function and elevate reactive oxygen species (ROS) production, resulting in oxidative stress-sensitive post-translational modifications (O-PTMs) that govern protein function and pathways. These exciting discoveries lead to our new hypothesis that O-PTM-mediated proteome remodeling is a dynamic and pervasive molecular change in diseased hearts, affecting proteins with central function in cardiac homeostasis and pathophysiology. To investigate the unique molecular features and pathogenic mechanisms of HFpEF, we highlight a novel HFpEF mouse model that incorporates both genetic predisposition for obesity/diabetes and pressure-overload, the two major risk factors for HFpEF, by performing trans-aortic constriction (TAC) in the ob/ob mice. We have also perfected the experimental tools and data analysis platform to provide O-PTM profiling at the whole-proteome level in hearts. Accordingly, we have strategically formulated the following aims according to three phenotypic levels: At the systemic level, Aim 1 will establish and characterize in vivo mouse models of HFpEF vs. HFrEF by cardiac and mitochondrial function as well as redox status. At the organellar level, Aim 2 will conduct targeted proteomics profiling of the cardiac mitochondria and extract O-PTM signatures using ML-based methods to achieve deep phenotyping of HFpEF and HFrEF. This information will then be integrated and enriched in an O- PTM molecular atlas and knowledge graph. At the molecular level, Aim 3 will target the BCAA catabolic pathway to exhaustively scrutinize its role in HFpEF and HFrEF. A multilevel understanding of the HFpEF phenotype, from its global profiling to molecular targets, will provide valuable new insights into the disease process that can lead to potential novel diagnostic and therapeutic targets. PROJECT NARRATIVE HFpEF is highly prevalent, yet there are few effective treatments or clear criteria to differentiate it from HFrEF. We propose to extract molecular signatures unique to HFpEF and HFrEF using a novel HFpEF mouse model and machine learning-based approaches. We anticipate that a multilevel understanding of the HFpEF phenotype, from its global profiling to molecular targets, will provide valuable new insights into the disease process that can lead to potential novel diagnostic and therapeutic targets.",
Patients Perceptions of Electronic Health Record use during initial oncology outpatient clinic visits,"Patients Perceptions of Electronic Health Record use during initial oncology outpatient clinic visits Project Summary It is estimated there will be nearly 1.7 million newly diagnosed cancer patients this year in the U.S. The initial oncology visits for a newly diagnosed cancer patient represent a critical focus for provider-patient communication. This communication involves complex decision-making and emotions, which directly impact patient self-efficacy, confidence, trust, understanding of the disease process and treatment options, and ultimately choice of and adherence to treatment. It has been reported that some newly diagnosed patients leave their oncology appointments with a suboptimal understanding of their disease process, care plan and treatment options, which may influence their decision-making and adherence to recommended therapies. The use of the electronic health record (EHR) during clinic visits has changed the dynamics of patient-provider communication. Increasingly, research has focused on how to use EHR in a patient-centered way to enhance patient-provider communication and patient engagement during a clinic visit. To date, most such research has been conducted in the primary care setting. However, the primary care setting focuses on chronic disease management, acute minor illness, and healthy lifestyle/prevention. The situation is different for the initial oncology visits, where typically multiple different treatment options (some potentially toxic), their associated risks and side effects and impact on survival and disease progression or recurrence are discussed for curable to potentially rapidly fatal diseases. Therefore, it is important to extend the existing knowledge base to better understand how the EHR use in the oncology setting impact communication, trust and address patient's information needs about the specific cancer, extent of disease, treatment options and prognosis. In addition, mental workload, defined as the total amount of mental effort being used in the working memory, is a well- studied human factors phenomenon. How people process information is influenced by mental workload, which is a critical aspect of doctor-patient communication, especially in highly demanding situations, like new patient oncology visits. Using technologies such as EHRs have introduced additional cognitive workload to providers during clinic visits. However, no studies have examined the mental workload of a patient during a clinic visit. To address this gap in the literature, we propose to study the following specific aims study aims in this study: 1): Assess the patient perception of the impact of EHR use on patient-doctor communication, trust and cognitive workload in new patient oncology visits. 2): Identify and cluster patterns of doctor-patient communication with regards to EHR use in the visit using systems engineering tools. The results from our investigation will have necessary data for future funding applications that will further determine how to best incorporate and design requirements for patient-centered EHR use in outpatient oncology settings. Project Narrative This proposed pilot study addresses the perception of newly diagnosed cancer patients on their initial consultations with oncology providers. Results from these analyses will provide important patient-centered insights into determining how best to incorporate EHR use in oncology settings to improve patient-provider communication of information that is essential for delivering high-quality, patient-centered care. This pilot study will also provide important initial findings and necessary data for future funding applications that will further determine how to best incorporate and design requirements for patient-centered EHR use in outpatient oncology settings with the ultimate goal of enhancing patient-provider communication to optimize patient understanding, trust, engagement of their treatment decisions and ensure the delivery of high-quality, patient- centered cancer care.",
Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract,"Prolonging Functional Speech in Persons with Amyotrophic Lateral Sclerosis: A Real-Time Virtual Vocal Tract People with ALS eventually and inevitably experience serious speech impairment due to progressive deterioration of brain cells that control movements of the tongue, lips and jaw. Despite the devastating consequences of this speech impairment on quality of life and survival, few options are available to assist impaired oral communication, and many existing speech-generating technologies are slow to operate and cost prohibitive. This project seeks to improve quality of life for persons with impaired speech due to ALS by testing the effectiveness of a low-cost, speech-generating device (a virtual vocal tract) that could significantly prolong the ability of these patients to communicate orally. If successful, these techniques could be extended for use by patients' with a broad range of speech motor impairments. The virtual vocal track uses machine learning algorithms to predict what a person is attempting to say, in real-time, based solely on lip movements. Users of the device are able to trigger the playback of a number of predetermined phrases by simply attempting to articulate what they want to say. Our previous work has shown the feasibility of this approach using cost-prohibitive laboratory systems such as electromagnetic articulography. Recent advances in 3D depth mapping camera technology allow these techniques to be tested for the first time using technologies, which are low-cost, portable and already being integrated into consumer devices such as laptops and cellphones. To this end, the system under development will be tested in 60 patients with ALS, representing a range of speech impairment from normal to severe speech intelligibility (15 normal, 15 mild, 15 moderate, 15 severe). During testing, participants will be cued to articulate the phrases in a random order as fast as is comfortable for them. The entire session will be recorded and the following variables will be measured offline: recognition accuracy, recognition latency, task time, % completion, and communication rate (words per minute). Users will rate the usability and acceptability of the virtual vocal tract immediately following device testing, using the System Usability Scale. Results of this testing will be used to address the following specific aims: (1) Determine the accuracy and latency of real-time phrase synthesis based on dysarthric speech using the virtual vocal tract, (2) Determine the usability and acceptability of real-time phrases produced using the virtual vocal tract, and (3) Identify the articulatory and speech factors that degrade recognition accuracy. People with ALS eventually and inevitably experience serious speech impairment due to progressive bulbar motor deterioration. Despite the devastating consequences of this impairment to quality of life, few options are available to assist or prolong impaired oral communication. The goal of the proposed work is to lay the groundwork for development of a low-cost speech-generating device—a virtual vocal tract—that can prolong functional oral communication for people with bulbar motor deterioration. This project seeks to testing the efficacy of a low-cost, speech-generating device (a virtual vocal tract) that records lip movements in real-time and triggers the playback of prerecorded phrases as users articulate what they want to say. If successful, the virtual device could provide an alternative means of oral communication for the large number of persons with unintelligible speech but still able to move their oral structures.",
CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS,"CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS The overall aim of this project is to improve automated cervical smear image analysis techniques sufficiently to:  1) routinely provide additional diagnostic information to supplement that provided by human visual examination, and 2) provide accurate, cost effective prescreening capabilities.  By furnishing additional quantitative diagnostic information, such automated systems would permit the practicing cytopathologist to make more accurate and refined diagnostic judgements, which would lead to improved patient management.  By providing a practical prescreening capability, such systems would increase the efficiency and efficacy of health care delivery.  Current automated cervical smear analysis research employs only the analysis of isolated cells, and practical automated analysis is not yet a reality.  The primary contribution of this project will be the completion of development and testing of image analysis techniques that extract information from cells and other objects as seen in the context of the ""background"" of the smear.  Specifically, cells, cell clusters, bare nuclei, and cytoplasmic fragments are analyzed and the resulting contextual features, slide-averaged ""features"" and high-resolution features describing single cells are combined to produce a more complete and accurate description of the smear.  This description will provide information not obtainable by human visual analysis, which can be used, 1) directly, to ascertain diagnostic clues, and 2) indirectly to make accurate prescreening possible.  An extensive pilot study has shown that the contextual analysis provides complementary information to that provided by single cell analysis.  That is, where single cell analysis seems to have difficulty, contextual analysis is most accurate - and vice versa. Thus we expect to demonstrate that the combination of our contextual analysis techniques with single cell analysis will give automated Pap smear analysis the additional screening accuracy that is needed.  The proposed project is a followup intended to:  a) validate the techniques of the pilot study, b) to expand the study to include parameters that provide additional diagnostic and prognostic information, and c) to generate specifications for a system to accomplish the analysis in a routine clinical laboratory environment.  n/a",
Using Retrospective and Real-Time Physical Activity Tracking to Predict Risk of Sunburn in Outdoor Exercisers on Strava,"Using Retrospective and Real-Time Physical Activity Tracking to Predict Risk of Sunburn in Outdoor Exercisers on Strava Skin cancer is the most common cancer in the United States. Over 5.4 million cases of keratinocyte cancers (basal and squamous cell) are diagnosed annually and incidence of melanoma has increased 3% each year for the past 30 years. In the 2014 Call to Action to Prevent Skin Cancer, the U. S. Surgeon General included strategies for coordinating messages on sun safety and physical activity, recognizing the need for sun safety among populations that engage in physical activity outdoors. Recreational UV exposure is associated with every form of skin cancer; individuals who engage in more physical activity have a higher prevalence of sunburn. Melanoma is the only cancer with which physical activity is positively correlated. Strava, a tracking app and social networking site for athletes, is one of the most popular of mobile technologies for logging physical activity and providing social feedback on activities by other Strava users. The goal of this R21 research is to test the feasibility of interfacing with the Strava website and its mobile app to develop an algorithm that a) predicts when individuals are likely to be engaged in physical activity outdoors in the sun when ultraviolet radiation is high and b) delivers sun safety advice tailored to the time, location, and personal risk (e.g., skin sun sensitivity) of the Strava users. Concept focus groups with Strava users (n=16) and non-users (n=16) will provide input on the feasibility, content, and functions in the Strava Sun (SS) intervention. The algorithm that predicts future outdoor exercise will be developed using machine learning modeling on activity data provided by Strava users (n=1000). The SS intervention will be programmed to deliver ecologically-valid sun safety advice through Strava's open-source Applications Programming Interface (API) via email and comments in the Strava interface. The sun safety advice will be tailored to location, time, season and user's personal risk, employing advice algorithms we developed for a sun safety mobile app, sunZapp, and a social media message library in our Go Sun Smart intervention for outdoor recreation resorts. SS will be tested for usability (n=30 Strava users) prior to conducting a pilot field trial to establish feasibility of SS in practice (n=226 Strava users). The project is significant and innovative. A sun protection interface for the Strava platform will provide individuals who engage in regular physical activity personalized, ecologically-valid advice to help them practice sun safety during outdoor activities. It will contain a novel machine learning algorithm that predicts future high-risk behavior, i.e., outdoor physical activity, to provide precision prevention advice. The intervention will be delivered over an established and popular technology platform with over 42 million registered users. Recreational UV exposure is associated with every form of skin cancer and individuals who engage in more physical activity have a higher prevalence of sunburn, a proximal biomarker of melanoma risk, perhaps explaining why melanoma is the only cancer with which physical activity is positively correlated. Mobile technology for tracking physical activity has become increasingly prevalent and Strava, an activity tracking app and social networking site for athletes, is one of the most popular of these technologies. This research will test the feasibility of delivering location-based, ecologically-valid sun safety advice to Strava users at times when they are predicted to be engaged in outdoor physical activity, by utilizing Strava's public open-source Applications Programming Interface.",
Investigating the documentation of E-cigarette use in the VA EHR,"Investigating the documentation of E-cigarette use in the VA EHR PROJECT SUMMARY Electronic cigarettes were developed in China in the early 2000s and first introduced to the US market in 2007. Once established in the US, the product experienced explosive growth, with the number of electronic cigarette users doubling every year between 2008 and 2012. In 2012, it was estimated that 75% of US adults had heard of electronic cigarettes, and 8% had tried them. While electronic cigarettes have been studied over the last sev- eral years, no scientific consensus has emerged regarding either the safety of electronic cigarettes, or their po- tential as a smoking cessation aid. With this proposal, we will investigate how electronic cigarette use is documented in the Veterans Association Electronic Health Record, focusing specifically on the relationship between electronic cigarette use and com- bustible tobacco use, with the goal of understanding both how electronic cigarette use is documented in the context of the United States’ only nationwide health system, and how electronic cigarette related information can be reliably extracted from narrative clinical text using fully automated Natural Language Processing meth- ods. PROJECT NARRATIVE The proposed research focuses on the use of Natural Language Processing methods to automatically extract mentions of electronic cigarette use from the Veterans Association Electronic Health Record. The research will provide insight into important, currently unresolved questions regarding how clinicians record electronic cigarette use in the context of a nationwide health system, and whether patients report the use of electronic cigarettes as a smoking cessation aid or use the devices in conjunction with combustible tobacco.",
Defining interaction quantitative trait loci (iQTLs) in the human genome,"Defining interaction quantitative trait loci (iQTLs) in the human genome Abstract My research aims to understand the role of three-dimensional (3D) chromatin structure in gene regulation. This involves studying associations among genotype, histone modifications, transcription factor binding, non-coding RNAs, chromatin interactions and gene expression. In order to transform this genome-wide information into new biological discoveries, my laboratory develops scalable and interpretable computational methods based on statistics, graph theory and machine learning. Our recent focus is to address an important gap in the current knowledge of the role of 3D chromatin structure in gene regulation. That is, we aim to define how genotypic variation affects 3D organization of gene promoters, and in turn, their expression. To achieve this at a genome- wide scale is an ambitious goal, because it requires having at a minimum, genotype, gene expression and chromatin interaction profiles in pure populations of specific cell types from a large number of donors. However, my laboratory is uniquely positioned to perform this research because: i) we are involved in a study at the La Jolla Institute (LJI-R24AI108564) that has already genotyped ~100 donors and expression-profiled more than 15 different pure populations of human immune cell types, and we have access to the same samples for chromatin interaction mapping, ii) in collaboration with other groups at LJI, we have already discovered a prototypical example of an interaction quantitative trait locus (iQTL) that alters and rewires interactions from the promoter of a specific gene that is associated with asthma susceptibility, iii) we have the necessary expertise and proven track record in experimental design and computational analyses of various chromatin conformation capture assays. Leveraging the resources available at LJI and our expertise in the field, we will build a unique research program around the novel concept of iQTLs. The emerging set of three main questions we propose to address within the next five years are: Q1) How do we define cell-type-specific iQTLs for common genetic variants? Q2) What is the extent of overlap between iQTLs and GWAS SNPs? Q3) Can we build predictive models for the cell-type specificity of chromatin interactions and iQTLs? Although we propose to define iQTLs only in two abundant, easily accessible, and highly disease-relevant immune cell types, the concept of iQTLs is equally important in other cell types implicated in diseases with a genetic component. Hence, the proof-of-concept developed by this work, without a doubt, will open up a new field in studying a previously uncharacterized role for disease-susceptibility variants, specifically non-coding SNPs, from genome-wide association studies (GWAS) in gene regulation. Narrative Recent discoveries that allow us to look beyond the one-dimensional sequence of DNA and understand the large-scale organization principals of its three-dimensional folding have been limited when it comes to characterizing the role of fine-scale genetic variations of the DNA code in controlling important cellular processes such as gene expression. This work will employ state-of-the-art molecular biology techniques and develop novel computational methods to define the role of such genetic variants in changing three-dimensional connections made by the promoters of genes in the human genome. This systematic and unbiased genome- wide study will have important implications in changing the way we study the disease relevance of genetic variation by revealing genotype dependence of long-range chromatin interactions between genes and their distal control switches at a scale that has not been achieved to date.",
Non-Invasive System for Identifying Neural Behavior,"Non-Invasive System for Identifying Neural Behavior    DESCRIPTION (provided by applicant): This application for ""Neurotechnology Research, Development, and Enhancement"" (PA-04-006) proposes the development of innovative technologies, methodologies, and instrumentation to advance our understanding of neural control mechanisms of muscle force production through a non-invasive means of recording neuronal firing patterns. The project will develop an automatic system to accurately and quickly decompose the surface Electromyographic (sEMG) signal into its constituent action potentials and provide the timing of the firings of concurrently active motor units. The goal is to achieve an accuracy of >85% in the automatic mode and >96% with the assistance of an interactive editor. This information will enable a wide range of studies to investigate the workings of the healthy and diseased neuromuscular system by simply placing a sensor above a muscle with no assault to the CNS. The sEMG Decomposition System will replace existing technology that relies on invasive procedures to detect the EMG signal through needle or fine-wire electrodes. The proposed work includes: 1) mathematical modeling and empirical studies to develop a sEMG electrode array that maximizes shape differences of motor unit firings and thereby facilitates sEMG signal decomposition; 2) algorithm development using artificial intelligence technology of our own design combined with Principal Component Analysis techniques; and 3) data acquisition/processing software and hardware to build a portable prototype surface decomposition system. Performance testing of the system will be conducted using data collection experiments to ensure that the system is comparable in motor unit yield, processing speed, and accuracy to the current state-of-the art indwelling decomposition system. We will also prove that the signal decomposition is performed correctly by decomposing two separately collected signals and matching the results. A dissemination plan is included to make this technology available to the Motor Control community. Commercialization will be realized through Altec Inc. This technology will enable researchers in the fields of Motor Control, Aging, Exercise Physiology, Space Medicine, and Ergonomics, where it is of interest to understand how the CNS controls muscles, and how that control is altered as a consequence of aging, exercise, exposure to microgravity, fatigue, and excessive and prolonged force production. It will be useful to clinicians for assessing the degree of dysfunction in upper motoneuron diseases such as Cerebral Palsy, Parkinson's Disease, ALS, Stroke, and other disorders.              n/a",
Machine learning analysis of tandem mass spectra,"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Project summary: Mass spectrometry, the core technology in the field of proteomics, promises to enable scientists to identify and quantify the entire complement of molecules that comprise a complex biological sample. In the biological and health sciences, mass spectrometry is commonly used in a nigh-throughput fashion to identify proteins in a mixture. Currently, the primary bottleneck in this type of experiment is computational. Existing algorithms for interpreting mass spectra are slow and fail to identify a large proportion of the given spectra. We propose to apply techniques and tools from the field of machine learning to the analysis of mass spectrometry data. We will build computational models of peptide fragmentation within the mass spectrometer, as well as larger-scale models of the entire mass spectrometry process. Using these models, we will design and validate algorithms for identifying the set of proteins that best explain an observed set of spectra. Software implementations for all of the methods will be made publicly available in a user-friendly form. In practical terms, this software will enable scientists to more easily, efficiently and accurately analyze and understand their mass spectrometry data. Relevance: The applications of mass spectrometry and its promises for improvements of human health are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens.           n/a",
Statistical Genetics and Genomics for Epidemiologic Research,"Statistical Genetics and Genomics for Epidemiologic Research Project Summary/Abstract Genome-wide association studies have identified an unprecedented number of genetic variants associated with disease risk, yet molecular mechanisms and clinical implications of genetic risk alleles are largely unknown. Epidemiologic research is extending its reach to more translational and mechanistic studies, integrating genetic risk variants with environmental exposures, interventions, gene expression and epigenetics. Motivated by population-based studies for prostate cancer research, we will develop statistical methods for emerging translational topics: how to search for genotypes that predict individual and subgroup intervention effects? how to identify epigenetic alterations that may be an interface of the environment and the genome? how to assess causal mediation effect of a modifiable risk factor or a molecular alteration in relation to disease outcomes? These topics present unmet statistical challenges because of high dimensionality and complex modeling. Specific statistical methods to be developed include high-dimensional gene- treatment interaction, multi-locus regional association, mediation analyses, instrumental variable analyses, Mendelian randomization, and shrinkage and regularization.  The methodological research in this project is driven primarily by prostate cancer, the most common noncutaneous cancer and the second leading cause of cancer death in American men, a ecting one in six in his lifetime. This project nests in highly-accomplished consortium studies (PCPT/SELECT/PRACTICAL/PCPS), all of which have generated far-reaching impact on prostate cancer research. The unique feature of this project is that methodological development will be seamlessly integrated with ongoing analyses, ensuring immediate translation. Our transdisciplinary research team has been actively engaged in statistical genetics and genomics, and conducting molecular epidemiological studies. The PI brings a wealth of expertise in high-dimensional methods, molecular biomarkers, and genetic epidemiology. This project will have a far-reaching impact on methodologies in cancer etiology, prevention, and treatment outcomes. Project Narrative In this project we will develop a suite of statistical methodologies for dissecting the multi-faceted role of genetics and genomics in modern epidemiology, and perform innovative analyses in well-characterized extant populations for prostate cancer research. The methodological topics include precision prevention based on individual genetic susceptibility, epigenetic alterations as the interface of the environment and the genome, and causal inference and mediation.",
A Wireless Multiscale Distributed Interface to the Cortex,"A Wireless Multiscale Distributed Interface to the Cortex    DESCRIPTION (provided by applicant):  The development of advanced neuroprosthetic systems and brain-machine interfaces for high-capacity, real-time, bi-directional communication with the nervous system is a major challenge to the emerging neural engineering discipline.  While recent advances in the fabrication of high-density microelectrode arrays (HDMEAs) for multiunit recording and stimulation have triggered numerous neurobiological discoveries, the resulting large data throughput and the variability of cortical responses over repeated trials preclude the ability to design a wireless, adaptive, fully implantable large-scale interface to the cortex.  This severely limits the feasibility and space of experimental paradigms needed to improve our understanding of the nervous system functionality and characterize cortical responses in freely behaving subjects interacting naturally with their surroundings.  The objective of this project is to develop a wireless interface to the cortex capable of processing simultaneously recorded neural signalsfrom 64 electrode channels in real time.  The project has 3 aims:  1.  Develop advanced signal processing algorithms for sensing and decoding neuronal response properties from distributed intra-cortical neural activity:  1) Optimize our existing signal processing algorithms for hardware implementation to extract the desired neural activity early in the data stream; 2) Develop new algorithms for decoding these responses to characterize the natural behavior of awake, behaving animal models.  2.  Design low-power integrated circuits and wireless telemetry for a 64 channel system:  1) Optimize the design of a low power Neural Interface Node (NIN) module to feature wireless communication and powering capability for subcutaneous implantation; 2) Design and fabricate an extracranial Manager Interface Module (MIM) to permit:  a) wireless powering and data exchange with up to 2 implanted NIN modules; b) wireless bidirectional exchange of data and control with a central base station.  3.  Demonstrate the system functionality in vitro and vivo:  1) Build a 32 channel system and test its performance in vitro in retinal slices and in vivo in awake behaving rodents; 2) Demonstrate the real time functionality of a 64 channel system in vitro and explore its feasibility in vivo; 3) Optimize the entire system design, and benchmark it against a commercial 64 channel wired data acquisition system.  PUBLIC HEALTH RELEVANCE:  This project seeks to develop a wireless electronic microsystem to be implanted in the rat brain to continuously monitor neural signals when the rat is freely behaving in an open environment.  This system will help understand how brain cells process information.  This will help design assistive technology for people with severe paralysis.       n/a",
Reliable Human-Model Observers for Emission Tomography,"Reliable Human-Model Observers for Emission Tomography    DESCRIPTION (provided by applicant): Our overall objective is to develop numerical observers for dependable technology evaluations in emission tomography. Positron emission tomography (PET) and single-photon emission tomography (SPECT) are the primary clinical modalities for imaging many types of cancer. However, early de- tection often presents the best chances of surviving cancer whereas these imaging modalities have limited diagnostic utility for small tumors. Systematic task-based developmental assessments could facilitate early identification of promising new technology for improving the diagnostic capabilities of these modalities. Yet, assessments with human observers are generally impractical for developmental use. Moreover, available mathematical models (or numerical observers) intended to predict human performance-what we refer to as human-model observers-present significant limits, including con- straints on the types of diagnostic tasks that can be considered. Partly because of these constraints, existing human-model observers frequently require revalidation given any change to the imaging pro- cess. Our approach to observer development is founded on the concept of task equivalence, whereby the task for the numerical observer mirrors the desired clinical task as closely as possible. In this grant, we propose a novel observer framework that is influenced by descriptions of radiologists' visual-search (VS) processes, in which an initial global scan of an image identifies candidate locations deserving closer inspection. We shall use the VS paradigm to investigate the hypotheses that task equivalence i) can lead to a human-observer model that reliably generalizes to a wide range of diagnostic tasks, and ii) is necessary to ensure truly relevant task-based evaluations. We shall test these hypotheses through observer studies with fluorine-18 deoxyglucose (FDG) whole-body PET and SPECT In-111 imaging of neuroendocrine tumors (NETs). A state-of-the-art model observer for developmental stud- ies should be capable of detection-localization tasks, and our observer studies will be analyzed with jackknife FROC (JAFROC) methodology. The specific aims of this work are to: 1) determine what features of FDG-PET image slices attract initial human-observer attention; 2) develop a VS numerical observer for tumor detection-localization tasks in FDG-PET; 3) test the VS observer against humans in a JAFROC detection-localization study featuring hybrid PET images; 4) investigate generalizations of the VS observer to SPECT and 3D detection-localization tasks; and 5) compare system optimiza- tions for oncologic SPECT obtained from the VS and existing numerical observers. The application is optimization of a parallel-hole collimator design for In-111 NET imaging.      PUBLIC HEALTH RELEVANCE: Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.           Project Narrative  Functional imaging with positron emission tomography (PET) and single-photon emission tomog- raphy (SPECT) has a significant role in cancer diagnosis and management. Still, early detection offers the best chances for surviving many cancers and refining the diagnostic capabilities of these modali- ties for small tumors continues to be a major research focus. This work is focused on the development of assessment methods for assisting in the early identification of technological advances that could improve the diagnostic utility of PET and SPECT.",
Efficient Statistical Methods for Association Studies with Dense Genotypes and Family History of Disease,"Efficient Statistical Methods for Association Studies with Dense Genotypes and Family History of Disease PROJECT SUMMARY / ABSTRACT In many genetic studies, case-control samples (probands) are recruited and phenotypes in their relatives are collected through a family health history interview on the probands. In these designs with combined genome-wide association study (GWAS) data in probands and family history in relatives (GWAS+FH), family member’s dense genotypes are often not collected due to the high cost of in-person collection of blood sample or death of a relative. Discarding relatives’ phenotypes lead to waste of much useful information because by examining patterns of the phenotypes among relatives with combination of genetic factors, environmental conditions, and lifestyle choices, a GWAS+FH leads to improved power of identifying an individual at risk of disease than using probands data alone. Multilevel models are powerful tools to test for association between genetic markers and correlated phenotypes because of their ability to account for varying degrees of relatedness among individuals. Improved power is expected from increased sample size by including relatives, higher chance to detect genuine genetic associations, and better type I error control compared to probands only analyses. However, analysis is highly challenging due to missing genotypes in relatives and correlation among family members’ phenotypes. The use of mixed effects multilevel model tools is rare in genetic association studies until recently, mainly due to the bottleneck of sub-optimal computational tools that do not meet requirements to handle large-scale GWAS and large sample size. This proposal addresses these challenges by providing fast and comprehensive statistical tools to increase our ability to map genetic variants in the combined data of proband GWAS and family history in relatives. Through multilevel mixed effects models, we will achieve improved power of association testing while controlling for correlation and confounding by: (1) use dense genotypes in probands to estimate between-family genetic similarities and expected values of missing relative genotypes; and (2) combine with within-family relatedness represented by polygenic effects. We will apply our methods to analyze Washington Heights-Inwood Columbia Aging Project, which offers golden opportunities to discover genetic variants associated with the risk of Alzheimer's disease in multiple ethnicity groups (Caucasian, African American and Hispanics). The novel statistical methods will ultimately allow personalized risk estimation of disease to each individual’s unique biomarkers, and aid in important decision making including genetic testing and genetic counseling. PROJECT NARRATIVE Efficient statistical methods to estimate genotype-specific risk prediction in disease and analyze association of genetic risk variants with disease will directly impact the lives of individuals and families by providing prognostic information for subjects in relation to disease risk or onset. The novel techniques will ultimately allow personalized risk estimation of disease tailored to each patient’s unique features with information from family history, and aid in important decision making process including genetic counseling and genetic testing.",
KNOWLEDGE BASED INTERPRETATION OF CARDIAC ARRHYTHMIAS,"KNOWLEDGE BASED INTERPRETATION OF CARDIAC ARRHYTHMIAS This application proposes development of new computer algorithms for reasoning about time-varying data from underlying causal models.  The signals consist of two or more channels of events, each event having several properties including time of occurrence and event shape class.  The models can be represented as graphs in which the nodes are digital components, some of which give rise to observable events.  The arcs are physical connections associated with time delays.  The application domain is the electrocardiogram, in which the P waves and QRS complexes represent two event channels, and optional intracardiac recordings contribute additional channels.  The P waves and QRS complexes are the results of the all-or-nothing depolarization of the atria and ventricles, respectively. These cardiac structures are connected anatomically and functionally by a series of other structures, each associated with a characteristic conduction time.  The analytic approach will be a variation of the hypothesize-and-test paradigm.  A hierarchy of models will be constructed whose base is the most complex, most comprehensive model, and whose derivatives are all simpler variants.  The control loop will be based on the ""tracking"" concept used in many knowledge-based monitoring systems.  The output of the proposed system will be one or more complete causal explanations of the observed signal. Each explanation will consist of an instantiated model and event-by-event annotation of causality based on the model.  When a signal admits of more than one explanatory model, each will be developed an displayed separately.  The hypothesis to be tested is that a cardiac arrhythmia monitor constructed using knowledge-based programming methods will perform substantially better than current clinical arrhythmia monitors as measured by correct diagnoses of clinically important arrhythmias such as second degree atrioventricular block, wide complex tachycardias, and detection of subtle signs of preexcitation.  This project is attractive for two reasons.  First, it offers new knowledge-based algorithms for model-based reasoning about time-varying signals.  This is an unsolved problem in the expert systems field.  Second, current cardiac arrhythmia monitors do not perform nearly as well as do expert nurses, technicians, and physicians.  The proposed project will contribute to the development of an improved generation of models that should result in improved care of patients in intensive care settings.  n/a",
Molecular mechanisms of germline DNA repair and DNA damage response,"Molecular mechanisms of germline DNA repair and DNA damage response DESCRIPTION (provided by applicant):     PROJECT SUMMARY Failure to activate the DNA damage response (DDR) pathway allows cells with unrepaired DNA to divide and can lead to the formation and proliferation of tumors. Impaired DNA repair can increase the incidence of cancer through the formation of deletions, amplifications, and gross chromosomal rearrangements. A hallmark feature of tumor progression is aneuploidy as a result of aberrant chromosome segregation stemming from impaired DNA damage checkpoint activation and/or DNA repair. Importantly, defects in germline DNA repair and DNA damage response also lead to aneuploidy, and as a result, to miscarriages, birth defects, infertility and tumorigenesis. Despite the relevance of both DDR and DNA repair for human health, these mechanisms are not fully understood at the molecular level. Our goal is to elucidate the mechanisms involved in maintaining genomic stability at the molecular level in the nematode C. elegans, an ideal model system for germline studies, amenable to molecular, genetic, biochemical, cytological and computational biology approaches. We have recently identified HIM-20, an uncharacterized D111/Gpatch domain containing protein also present in humans. Partial depletion of HIM-20 results in sensitivity to ionizing radiation and a delay in the repair of meiotic double strand breaks. HIM-20 colocalizes and interacts with crossover promoting proteins. We propose that HIM-20 is involved in DNA repair and acts to promote crossover formation. We will determine the mechanism of function of HIM-20 in DNA repair by examining both the progression and output of recombination in him-20 mutants; the response of him-20 mutants to DNA damage; the interdependencies driving the localization pattern of HIM-20; identifying its binding partners; and determining its DNA substrate binding specificities in vitro. These studies will provide critical insight into the procss by which HIM-20 and its human ortholog promote genome stability. Through combined genetic, molecular, cytological and biochemical approaches, we will determine the mechanism of function for ZTF-8, a novel and conserved protein that our studies have shown interacts with a component of the 9-1-1 DDR complex and is required for DDR and DSB repair. These studies will shed new light on our understanding of the DDR and DSB repair pathways in the germline. Finally, we will identify the genetic interaction network required for proper chromosome segregation and apoptosis in the nematode C. elegans. We will test pair-wise combinations of genetic mutations in DNA repair and DDR genes with depletion of germline-enriched genes by RNAi in a high-throughput format designed and proven to detect chromosome missegregation and cells undergoing apoptosis. Hierarchical clustering of genetic interaction profiles associated with each query will order genes to identify those that are functionally related, predict biochemical pathways and protein complexes, assign function to uncharacterized genes, and reveal the large-scale structure of the biological network driving genome stability. Taken together, this application will provide significant new insights into the molecular mechanisms regulating genome stability. Defects in germline DNA repair and DNA damage response lead to miscarriages, birth defects, infertility and tumor formation. This application takes advantage of the ease of genetic, cytological, molecular, biochemical and computational biology analysis in the worm C. elegans to investigate the molecular mechanisms of function for DNA repair and DNA damage response proteins also present in humans. These studies will significantly contribute to our understanding of how these critical processes regulate human reproductive health and provide potential new targets for diagnosing cancer susceptibility and cancer drug therapy.",
Neural dynamics and adaption for brain machine interface control,"Neural dynamics and adaption for brain machine interface control Project Summary/Abstract  Millions of people suffer from some form of paralysis. In most of these cases the connection between the brain and the spinal cord is damaged, however, the motor cortex is healthy and intact. Thus, for these individuals, brain-machine interfaces (BMIs) hold significant promise for improving quality of life. BMIs decode an individual's intention to move by utilizing statistical models of neural activity patterns recorded from the motor cortex using implanted electrode arrays. While these methods have been encouraging in preclinical experiments and clinical trials for controlling thought-driven 2D computer cursors, they suffer from poor performance when applied to higher degrees-of-freedom (e.g., robotic limbs), and are not robust to the inevitable degradation of the electrode array. In order to address these clinical needs, this project starts from the recent observation that just as some behaviors are easier to learn, some patterns of neural activity, termed neural states, are also easier to generate. The overarching goal of this project is to elucidate if these “easy to generate” neural states can be used to robustly control a prosthetic arm. This is a significant departure from current decoding methods, which incorporate little to no information about the motor system, especially its ability to learn and adapt. The first major aim of this work is to develop experiments and analysis methods in order to find these “easy to generate” neural states in the non- human primate (i.e., rhesus monkey) motor system. Here “easy to generate” can be understood as the monkey's ability to volitionally generate that particular neural state. The second major aim of this work is to characterize the properties of the motor system that enable some states to be more easily generated than others. Prior work in our lab has shown that motor cortical population activity has well-defined structure, as predicted by dynamical system theory. These dynamics cause neural states to evolve in lawful ways through time. The work here will extend these findings by characterizing the dynamics associated with a monkey learning to generate a neural state. Finally, the third major aim of this work is to determine if neural states that monkeys can volitionally generate can be utilized for robust control of a prosthetic arm. The central hypothesis of this work is that building a model that only utilizes firing patterns that can be easily generated (as determined experimentally) will enable robust and high-performance control of a prosthetic arm. If successful, this study could have significant clinical impact by presenting a new paradigm to enable robust control of a prosthesis. Project Narrative  Millions of people worldwide suffer from neurological injuries or neurodegenerative diseases that result in considerable movement impairment. Brain machine interfaces (BMIs) hold considerable promise in drastically improving the quality of life for these individuals, who otherwise have very limited treatment options. This work will investigate the motor system's ability to learn and adapt, and directly use these insights to build robust high degree-of-freedom BMIs for clinical applications.",
The gist of the space: A space centered approach to visual scene perception,"The gist of the space: A space centered approach to visual scene perception    DESCRIPTION (provided by applicant): Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.      PUBLIC HEALTH RELEVANCE: The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.           The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.         ",
Clinical resting state fMRI software for surgical planning,"Clinical resting state fMRI software for surgical planning Abstract Classically, anatomic information provided by MRI has been essential to the neurosurgeon to maximize extent of tumor resection and, as a result, improve survival statistics. That said, it is not routine during resections to make use of similar imaging information that reflect the functional organization of the brain. Task-based fMRI has been employed as a means of pre-operatively localizing function. However, task-based fMRI depends on the patient’s ability to comply with the task paradigm, which frequently is lacking. This problem can be overcome by using the recently developed method of resting state functional magnetic resonance imaging (rsfMRI) to localize function. Moreover, rsfMRI is highly efficient, as multiple resting state networks (RSNs) associated with multiple cognitive domains can be mapped at the same time. With this in mind, the long-term goal of our research is to improve survival and quality of life after surgical resection of brain tumors by improving the identification/preservation of eloquent cortex. The current barrier that prevents the widespread use of rsfMRI is 1) the high degree of advanced imaging expertise currently necessary to create and interpret the images and 2) the necessary IT infrastructure necessary to support the analyses. To address this shortcoming, we propose to create a turnkey system for functional mapping within the brain that resides on a cloud-computing platform. At the heart of our methodology is a multi-layer perceptron (MLP) algorithm that assigns RSN membership to each locus within the brain using supervised classification of rsfMRI data. Current data demonstrate that MLP-based RSN mapping is more reliable than conventional task-based fMRI and is extremely sensitive to sites identified by cortical stimulation (the standard in intraoperative mapping). Translation of the science and techniques created at Washington University will be accomplished by a deep collaboration with Radiologics, an emerging company with strong expertise in cloud computing for clinical imaging. Towards this end, the overall objective of the proposed project is to create an imaging technology package, named Cirrus, that will integrate automatic MLP-based RSN mapping with cloud-based computing. The Specific Aims of this proposal are to 1) Create Cloud-Based rsfMRI Brain Mapping Capability - Cirrus, 2) Deploy Cloud-Based rsfMRI Capability (Cirrus Platform) to New User Host Institutions, and 3) Optimize the Clinical User Interface (UI) of Cirrus. The expected outcome of this translational strategy will be an integrated imaging/surgical presurgical mapping technology using rsfMRI with clearly defined performance capabilities, well delineated localization outputs, and a clinician friendly user experience that scales to all types of health care settings. Thus, this proposal is innovative because there currently does not exist any comparable system that integrates cutting edge image analysis tools with cloud-based capabilities. This work is significant because it will disseminate technology that fundamentally enhances the surgeon’s understanding of the functional implications of their surgical strategy, thereby enables safer, more tailored approaches to improving outcomes. Project Narrative The proposed research is an academic industry partnership that will make available, to any neurosurgical practice advanced functional MRI methodology to define critical regions in the brain. This development is relevant to public health because it has the potential to improve functional outcomes following surgical removal of brain tumors. Towards this end, we propose to create an imaging technology package that will integrate 1) advanced machine learning techniques using resting state functional magnetic resonance imaging, and 2) cloud-based computing, to perform advanced brain mapping. Thus, advanced functional localization can be standardized and acquired at any institution by being uniformly processed in the cloud and sent back to the home institution without the need for costly infrastructure. The integrated package will enable clinicians in any practice environment to efficiently and reliably visualize function on the brain’s anatomy prior to surgery.",
Combinatorial matrix-mimetic recombinant proteins as engineered nerve guidance conduits,"Combinatorial matrix-mimetic recombinant proteins as engineered nerve guidance conduits ABSTRACT Over 500,000 Americans suffer from peripheral nerve injury (PNI), and despite surgical interventions, most suffer permanent loss of motor function and sensation. Current clinical options for long nerve gap PNI include naturally- derived grafts, which provide native matrix cues to regenerate neurons but suffer from very limited supply and batch-to-batch variability, or synthetic nerve guidance conduits (NGCs), which are easy to manufacture but often fail due to lack of regenerative cues. The main challenge with using any NGC for treatment of PNI is the immense trade-off between providing the complex matrix cues necessary for optimal nerve regeneration while providing a conduit that is readily available, reproducible, and easily fabricated. To overcome this challenge, we propose an entirely new type of biomaterial: a computationally optimized, protein-engineered recombinant NGC (rNGC). This rNGC combines the reliability of synthetic NGCs with the presentation of multiple regenerative matrix cues of natural NGCs. Because current understanding of cell-matrix interactions is insufficient to enable to direct design of a fully functional rNGC, we hypothesize that the use of machine learning, computational optimization methods will allow identification of an rNGC that promotes nerve regeneration similar to the current gold standard autograft. We utilize a family of protein-engineered, elastin-like proteins (ELPs) that are reproducible, with predictable, consistent material properties, and fully chemically defined for streamlined FDA approval. Due to ELPs’ modular design, they have biomechanical (i.e. matrix stiffness) and biochemical (i.e. cell-adhesive ligand) properties that are independently tunable over a broad range. While numerous studies detail the effects of individual biomechanical or biochemical matrix cues on neurite outgrowth using single-variable approaches, their combinatorial effects have been largely unexplored as insufficient knowledge exists to make accurate predictions of their interactions a priori. This fundamentally prohibits the direct design of combinatorial matrix cues. We hypothesize that optimized presentation of biomechanical and biochemical cues will create a microenvironment that better mimics the native ECM milieu, resulting in synergistic ligand cross-talk to improve nerve regeneration. In Aim 1, we use computational optimization methods to identify the combination of ligand identities, ligand concentrations, and matrix stiffness that best enhances neurite outgrowth. We will develop and characterize a library of ELP variants with distinct cell-adhesive ligands derived from native ECM, and assess their ability to support neurite outgrowth from rat dorsal root ganglia (DRG). In Aim 2, we will validate our in vitro optimization results in a preclinical, rat sciatic nerve injury model. A core-shell, ELP-based rNGC with an inner core matrix of the optimized ELP formulation from Aim 1 will be fabricated and evaluated for its ability to enhance therapeutic outcome. Controls include reversed nerve autograft, hollow silicone conduit, and non-optimized ELP- based rNGC. This study would represent the first use of computational optimization methods to design a reproducible, reliable, recombinant biomaterial with multiple regenerative matrix cues. PROJECT NARRATIVE The main challenge with using nerve guidance conduits (NGCs) to bridge long peripheral nerve gap injuries is the immense trade-off between providing the complex matrix cues necessary for optimal nerve regeneration while providing a conduit that is readily available, reproducible, and easily fabricated. To address this challenge, here we utilize (1) computational optimization methods to identify the optimal biochemical and biomechanical matrix cues for nerve regeneration, and (2) advanced protein-engineering strategies to incorporate these cues into a recombinant NGC (rNGC). Our rNGC combines the reliability of synthetic NGCs with the matrix cues of naturally-derived NGCs to make an affordable, off-the-shelf rNGC that promotes nerve regeneration.",
The adaptive potential of translational regulation,"The adaptive potential of translational regulation Project Summary/Abstract  Our current understanding of the adaptive effects of mutation is largely limited to alterations in protein coding sequence and disruption of transcriptional cis-regulatory promoters. Very little is known about how mutations alter translation, or the role these mutations play in adaptation and evolution. This project seeks to address this gap by identifying the functional effect of mutations on translation. To accomplish this I will first identify mutations that arise from adaptation to various nutrient limited environments. I will then use expression profiling (e.g. RNA-seq, ribosome profiling, and RATE-seq) to identify the effect these mutations have on translation, as well as other levels of gene expression. This will provide insight into the magnitude of effect mutations have on translation and their relative rate. Furthermore, to fully characterize the role synonymous mutations have on fitness I will be using a deep scanning synonymous mutation library. To understand the role tRNA abundance plays in the fitness effect of a given synonymous mutations, I will also be evaluating fitness within tRNA under- and over-expression backgrounds. Because of the closely coupled nature of translation rates and mRNA decay, I will also characterize the effect synonymous mutations have on mRNA decay using RATE-seq. My analysis of the functional effects of these mutations on gene expression, particularly within the genetic background and environment in which they arose, will allow for the development of a machine learning algorithm that can use sequence and annotation features to predict the effect of a mutation on gene expression. This tool will aid future research into the effect mutations have of gene expression by allowing the identification of high-confidence candidates for further evaluation.  This project will be conducted at New York University’s Center for Genomics and Systems Biology, whose mission is to answer otherwise intractable biological questions using applied experimental and computational approaches. The Center houses numerous facilities and cores that will be instrumental in the performance of this work. The collaborative atmosphere and multi-disciplinary nature of NYU’s research communities that will enable me to stay abreast of developments in related fields and to rapidly communicate my research to interested parties. I will be trained under the guidance of Dr. David Gresham, an excellent researcher working on complementing long-term evolution experiments with gene expression studies to characterize the adaptive potential of the regulation of gene expression. Project Narrative The translation of mRNA into protein is a critical step in gene expression that is tightly regulated with mis-regulation of translation being a hallmark of many human pathologies. Understanding how mutations can alter the regulation of translation is an understudied but important aspect of adaptation and evolution. Ultimately, without an understanding of the adaptive potential of translation we have an incomplete, and imperfect, picture of the underlying genetic causes of numerous forms of cancer and genetic diseases.",
Investigating Brain Connectivity in Autism at the Whole-Brain Level,"Investigating Brain Connectivity in Autism at the Whole-Brain Level  ABSTRACT: This proposal aims to elucidate the functional organization of the whole brain in Autism Spectrum Disorders (hereafter referred to as autism), a group of neurodevelopmental disorders that affect roughly 1 in 110 individuals born today. I will test the overarching hypothesis that functional coupling between different regions of the brain in autism is generally reduced. Moreover, I will explore the prediction that such reduced connectivity is associated with abnormal behavior. While anatomical and functional evidence support reduced brain connectivity in autism, this has never been tested at the whole-brain level. In this application, I propose to acquire resting-state and stimulus-evoked Blood Oxygenation Level Dependent (BOLD) activity across the entire brain in high-functioning adults with autism and matched healthy control participants. A measure of functional connectivity will be derived from the resting-state BOLD activity, by examining the functional coupling across all regions of the brain in a pairwise manner. In each of 4 specific aims, I will test the following hypotheses: (1) that the autistic brain is generally less connected than normal, but that there is anatomical specificity to this reduction, (2) that the functional responsivity of the entire brain can be examined simultaneously in autism using complex naturalistic stimuli, and can be used to reveal which regions function abnormally in autism, (3) that abnormal resting-state functional connectivity is associated with reduced evoked activity in those same regions, and (4) that the functional properties of broadly distributed brain regions contain information that can be used to predict a diagnosis of autism. Aims 1 & 2 will be carried out during the training phase (K99) of the grant, while Aims 3 & 4 will be completed during the independent phase (R00). The training component will consist of learning state-of-the-art functional imaging methods at the Caltech Brain Imaging Center, together with statistical techniques for pattern classification. Together, these studies will provide the first comprehensive picture of brain connectivity and brain activity in autism, and set the direction for my future career.  PROJECT NARRATIVE: These studies will provide mentored training and research to help better understand brain connectivity in autism. This will be important information for guiding future diagnoses and intervention.",
Evaluating associations between trauma-related characteristics and functional recovery in individuals with spinal cord injury,"Evaluating associations between trauma-related characteristics and functional recovery in individuals with spinal cord injury Project Summary World Health Organization established that every year, around the world, between 250,000 and 500,000 people suffer a spinal cord injury (SCI). While existing research suggests links between the injury event, early care, and rehabilitation outcomes, there still remains a critical knowledge gap – about how characteristics associated with trauma and acute phases of SCI can allow us to better understand functional recovery post- SCI. In the past, this research was partly hampered due to databases that either focused on trauma-care or inpatient rehabilitation. However, using advanced analytical methods, we are now in a position to combine databases that contain trauma and acute phase-related variables with patient-level characteristics to assess longitudinal functional recovery over time. Trauma and acute phase-related variables include type of trauma, cause of injury, process of care, clinical data, and outcome data during acute care. The overall objective of this study is to use trauma and acute phase-related variables to explain the longitudinal functional recovery of individuals with SCI, from acute to post-acute to community. This will be achieved by probabilistically linking the Pennsylvania Trauma Systems Outcomes Study (PTOS) database with the National Spinal Cord Injury Model Systems (SCIMS) database. The PTOS and SCIMS databases provide complimentary information about trauma and acute phases of SCI from acute hospital to inpatient rehabilitation facility (IRF) to community. The long-term goal of our research is to identify trauma and acute phase-related variables that can be utilized during acute care and post-acute rehabilitation interventions to improve clinical decision making, which in turn enhances rehabilitation programs.The central hypothesis of this proposal is that trauma and acute phase- related variables, combined with patient-level characteristics, will significantly predict longitudinal functional recovery in individuals post-SCI. Our hypothesis is guided by prior research and our pilot work with the PTOS database. A primary objective of this proposal is to examine the association between trauma and acute phase- related variables with functional improvements during IRF in individuals with traumatic SCI using machine learning ensemble methods (Aim 1). A secondary objective of this study is to develop longitudinal trajectories of functional recovery over a period of 1-year post-SCI taking into account trauma, acute phase, and patient- level characteristics during acute, post-acute, and community living using growth curve modelling (Aim 2). The proposed study will yield novel insights about the relationship between trauma and acute phase-related variables with functional status. Project Narrative World Health Organization has reported that every year, around the world, between 250,000 and 500,000 people suffer a spinal cord injury (SCI). The overall objective of this study is to use trauma, acute, and patient- level characteristics to explain the functional recovery of individuals with SCI over time, post-injury.",
SINGLE-UNIT ZERO ORDER DRUG DELIVERY SYSTEM,"SINGLE-UNIT ZERO ORDER DRUG DELIVERY SYSTEM Many of the new drug delivery systems (DDS) are designed to deliver drug at a controlled rate over an extended period of time. This extended drug delivery results in plasma drug levels within the therapeutic range longer than expected from the biological half-life of the drug, thereby prolonging the pharmacological benefits of the drug, while minimizing ineffective or toxic concentrations.  The DDS should maintain a constant (zero-order) drug delivery rate for 10 to 14 hours, and be easily adaptable to a variety of drugs, requiring different delivery rates.  One such design involves press-coating a drug core with a rate controlling membrane.  The rate of drug delivery is modified by altering the porosity of the coating, which changes and rate of water penetration, and thus alters the core dissolution profile and rate of drug release.  To predictably modify drug delivery rate by incorporation of porosity modifiers in the coating, requires an understanding of the interplay between physical-chemical properties of the porosity modifier and the change in DDS porosity/surface area.  This proposal investigates relationships between properties of porosity modifiers and coating porosity/surface area, which are used in the design of a cost effective press-coated DDS.  Powder characteristics and compression profiles of core and coating materials are used in the selection of proper approaches to the initial DDS design.  To alter drug release, porosity modifiers of different properties are incorporated into the coating.  The dependence of the rate and extent of porosity/surface area modifications on the porosity modifier properties and subsequent influence on drug delivery rate will be studied.  The relationships will be tested by determining the accuracy with which drug delivery profile can be predicted by apriori selection of porosity modifier with cores of varying dissolution profiles.  Future studies will involve a series of drugs with different properties and the in-vivo evaluation of the DDS. The relationships developed in this investigation will allow use of the same DDS housing, which is adaptable to drugs requiring different delivery rates.  This reduces the time and cost involved in developing DDS for new drug entities.  n/a",
Early Detection of Keratoconus,"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",
Preclinical predictive markers of post-approval drug safety,"Preclinical predictive markers of post-approval drug safety    DESCRIPTION (provided by applicant): The approval and subsequent withdrawal of widely prescribed unsafe drugs affects millions of lives annually. We have recently reported that a Bayesian network model can utilize preclinical, phase I and phase II data to predict phase III safety and efficacy with 78% accuracy. Our approach exceeds pharmaceutical industry performance. Our novel preliminary data demonstrate that identifying post-marketing safety issues independent of drug class is feasible using preclinical data only. Every drug has a unique set of preclinical dose versus primary effect curves and dose versus side effect curves. Our preliminary studies show that quantifiable features of preclinical dose versus primary effect curves predict post-approval safety withdrawal with impressive accuracy. Our objective is to build and distribute preclinical pharmacologic predictive models of post-approval clinical safety. Our specific aims are (1) to identify preclinical dose-effect indicators of post- approval drug safety and (2) to build and distribute preclinical indicator machine-learning models that predict post-approval drug safety. This proposal will deliver an open source drug safety sentinel that is based solely on preclinical data. The potential benefits to society include reduced exposure to unsafe drugs, an indicator for potentially suppressed safety data, and reduced burden on the FDA Adverse Event Reporting System and other phase IV surveillance systems.    PUBLIC HEALTH RELEVANCE: The approval and subsequent withdrawal of widely prescribed unsafe drugs affects millions of lives annually. Patients affected by toxicity suffer from drug-induced morbidity and mortality, while those patients who benefited from the drug without toxicity can no longer receive it. We have recently reported that predictive models can predict efficacy and safety was accuracy. Our novel preliminary data demonstrate that predicting post-marketing safety issues independent of drug class is feasible using preclinical data only. Our objective is to build and distribute preclinical pharmacologic predictive models of post-approval clinical safety. Our goal is to deliver an open source drug safety sentinel that is based solely on preclinical data in order to reduce exposure to unsafe drugs.           Narrative The approval and subsequent withdrawal of widely prescribed unsafe drugs affects millions of lives annually. Patients affected by toxicity suffer from drug-induced morbidity and mortality, while those patients who benefited from the drug without toxicity can no longer receive it. We have recently reported that predictive models can predict efficacy and safety was accuracy. Our novel preliminary data demonstrate that predicting post-marketing safety issues independent of drug class is feasible using preclinical data only. Our objective is to build and distribute preclinical pharmacologic predictive models of post-approval clinical safety. Our goal is to deliver an open source drug safety sentinel that is based solely on preclinical data in order to reduce exposure to unsafe drugs.",
Cancer Pain Management-Decision Support Computer Program,"Cancer Pain Management-Decision Support Computer Program  DESCRIPTION (provided by applicant):  More than 80% of cancer patients experience pain during the course of their illness or treatment.  Despite widespread dissemination and adoption of standard guidelines for cancer pain management, erroneous assessments and subsequent undertreatment and mistreatment of cancer pain are still common occurrences, disproportionately affecting women and ethnic minorities.  The purpose of this study is to develop a standardized decision support computer program (DSCP) (an expert system) with self-adaptation capabilities that can be used by nurses as an assessment support tool for dealing effectively with gender and ethnic differences in cancer pain experiences based on cancer patients' own views and experiences.  The specific aims are to: a) collect data on cancer pain among four ethnic groups (Hispanic, non-Hispanic Whites, non-Hispanic African-American, and non-Hispanic Asian) in the U.S.  and determine gender and ethnic differences in cancer pain experiences; and b) develop a DCSP based on these collected data and feedback from oncology nurses.  Using theoretical triangulation, a feminist approach and fuzzy logic will guide the research process.  Innovative internet data collection methods will be used including a quantitative Internet survey among 400 cancer patients recruited through general and ethnic-specific Internet Cancer Support Groups, and qualitative online forums of 6-months duration among four ethnically different groups (30 members per group) recruited from among the Internet survey participants.  Based on these data, a DSCP will be developed including Knowledge Base Generation, Decision-Making, and Self-Adaptation Modules.  Output of this expert system will be classification of patients' pain according to gender and ethnicity with suggested pain management strategies.  Online feedback from 30 oncology nurses will be incorporated into the DSCP to increase it acceptability among potential users.  Long-term goals are to: a) extend knowledge about gender and ethnic differences in cancer pain experience; b) contribute to recognition of patients' own cancer pain experience so that health care can be planned and provided from patients' own views and perspectives; c) develop a nursing expert system that can effectively guide cancer pain assessment and management in clinical settings; and d) ultimately eliminate gender and ethnic biases and inequity in cancer pain assessment and management.   n/a",
"Modeling of infectious network dynamics for surveillance, control and prevention enhancement (MINDSCAPE)","Modeling of infectious network dynamics for surveillance, control and prevention enhancement (MINDSCAPE) PROJECT SUMMARY: Mathematical analysis, computational statistics, and machine learning are increasingly being deployed to understand and predict the dynamics of healthcare associated infections (HAI) and antimicrobial-resistant infections (ARI). However, the utility of these models to guiding clinical and health policy decisions often remains unclear. One challenge is that model calibration quickly becomes obsolete as the epidemiology of HAI and ARI changes. To address this gap, we propose to use mathematical modeling and machine learning approaches to build decision-making technologies that improve the risk assessment, prevention, and control of HAI and ARI. Our proposed technologies account for spatial and temporal dynamics, provide continuous, real-time feedback to clinicians and are robust to changes in risk factors and disease prevalence over time. We anticipate that implementation of these technological improvements will help healthcare institutions to substantially reduce the burden of HAI and ARI. We concentrate our efforts on two of the most important HAI: methicillin-resistant Staphylococcus aureus and Clostridioides difficile infections. To conduct these studies, we assembled a team of mathematical modelers, machine learning specialists, health economists, clinical informaticists, infectious disease physicians, and hospital epidemiologists based in California, New York, and Texas. Clinical, microbiological and environmental data to train our models will come from three academic quaternary medical centers and an expanding network of community hospitals. The first aim is to calculate the patient-specific risk of acquiring or transmitting a HAI or ARI. We hypothesize that the risk of acquiring an HAI or ARI is more accurately determined when data on patient movement and pathogen exposure are integrated into predictive models. This type of analysis is also expected to improve the risk assessment of automated systems used to detect HAI and ARI outbreaks. The second aim is to prevent invasive methicillin-resistant Staphylococcus aureus (MRSA) infections. One objective is to show that cost-effective reduction of invasive MRSA infections and hospital-based transmission can be achieved via personalized decisions for who should be screened for asymptomatic carriage and decolonized. Our third aim is to control the spread of Clostridioides difficile infections (CDI). We hypothesize that by calculating the number of CDI averted and the cost saved, models of disease transmission will demonstrate the benefit pre- emptive adoption of contact precautions for patients who are at high risk of transmitting CDI. We also expect to identify environmental pathways that contribute to the risk of CDI superspreading and would benefit from enhanced surveillance and decontamination. Finally, to better understand the importance of antibiotic stewardship programs, we characterize the specific role a patient's antibiotic, infection, social, exposure and colonization history plays in the personal risk of acquiring an invasive MRSA infection and CDI. PROJECT NARRATIVE We propose to use mathematical modeling, agent-based simulation and machine learning approaches to build decision-making technologies that improve the risk assessment, prevention and control of healthcare- associated infections and antibiotic-resistant infections. Our proposed technologies will account for spatial and temporal dynamics, provide continuous, real-time feedback to clinicians and are robust to changes in risk factors and disease prevalence over time. We concentrate our efforts on two of the most important healthcare- associated infections: methicillin-resistant Staphylococcus aureus and Clostridioides difficile infections.",
"Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization.","Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization. PROJECT SUMMARY / ABSTRACT Modern digital pathology departments produce a tremendous amount of whole slide image data, which is quickly growing to petabyte scale. This plethora of data presents an unprecedented treasure chest for all kinds of medical machine learning tasks, including improvements in precision medicine.  Unfortunately, the vast majority of digital slides are not annotated on the image level, so histological points of interest are not integrated with the clinical notes or genetics associated with a patient. In contrast to other disciplines, manual labeling is not only cumbersome and time-consuming, but given the decades-long training of a pathologist, it is exorbitantly expensive and, due to clinical time constraints, impractical. Moreover, the time- dependent relationship between a patient's histology and genotype is not quantitatively leveraged to recommend combination therapies. Genetics informs us of important driver mutations, but how multiple cell types interact with these mutants over time in the tumor microenvironment to become histologically evident is less clear.  Deep learning synthesizes generations of pathologist knowledge as accurate quantitative models. Given a picture of a patient's morphology, I provide a tool that in four seconds finds the top ten most similar patients with their diagnoses, to support a pathologist's diagnosis decisions under the time pressures of active surgery. Recording the pathologist inspecting a slide at the microscope automatically annotates observed slide regions with time. Not only amenable for learning models that predict whether or not a region is salient to a pathologist making a diagnosis, this also allows all slides in a hospital to be annotated to identical criteria with only a representative sample of slides. I have submitted a manuscript reporting 85.15% accuracy in this saliency prediction task. This annotation greatly simplifies machine learning tasks, which can now focus on a non-redundant set of diagnostic regions in the slide, whether the application is to (a) find similar patients by morphology for diagnosis or (b) relate diagnostic morphology to the genetics.  Statistically modeling the relationship of the genotype to the histological phenotype in cancer opens promising new avenues in precision medicine. Taking a Big Data approach, I will leverage over 18,244 paired genome-histology samples to learn this model, using transfer learning techniques to maximize the value of all 18,244 samples for each tissue type. Genotype-phenotype model in hand, I will simulate the molecular clock in cancer, incrementally mutating the genome and predicting corresponding histology at each molecular time step. Through similar Q-learning that powers Google's champion artificial intelligence ``AlphaGo'', I will learn an agent that inhibits expression of a small set of mutant genes to maximize cancer progression-free survival time, by molecular time in the simulator. This not only measures the therapy's evolutionary durability, but also leads directly to experimentally testable hypotheses in 3D cell culture. PROJECT NARRATIVE / PUBLIC HEALTH RELEVANCE STATEMENT Digitized whole slide images of cancer tissue are a ``dark matter'' in the clinic, data that are often collected but rarely used quantitatively to model cancer or personalize medicine. I will, through close collaborations with practicing pathologists at globally leading cancer research hospitals, form statistical models of the histology evident in whole slides to (i) create clinical decision support tools that find similar patients by morphology alone to disambiguate cases that are difficult for a pathologist to diagnose under the time pressures of ongoing surgery, (ii) create a tool that learns which parts of a whole slide image are salient for a pathologist at the microscope to make a diagnosis, which greatly facilitates the deep learning techniques underlying [i] and [iii] by discarding redundant histological image data, and (iii) create a system that relates genotype to histological phenotype in cancer and learns an agent which leverages this system to determine the optimal multistage combination therapy to drive the histology towards health such that cancer progression-free survival time is maximized in the patient of interest. In this way, my statistical models will transform the vast dark matter of diagnosed histology data, representing generations of pathologist knowledge at these leading hospitals, into an indispensable resource for surgery, pathology, genetics, and precision medicine.",
Quantifying Brain Abnormality by Multimodality Neuroimage Analysis,"Quantifying Brain Abnormality by Multimodality Neuroimage Analysis ﻿    DESCRIPTION (provided by applicant): Alzheimer's disease (AD) develops for an unknown and variable amount of time before its symptoms fully manifest. But, when the symptoms become clinically observable, a significant neurodegeneration has already taken place. Thus, there is a largely unmet need for technologies that can aid the effective early diagnosis and prognosis of AD in an in vivo and more objective manner. The goal of this renewal project is to develop a set of advanced machine-learning techniques for precise in vivo quantification of pathological changes of brains with multimodality neuroimaging for both early diagnosis and prognosis of AD. AD is a highly heterogeneous neurodegenerative disorder with complex pathophysiology, thus very challenging to pinpoint its subtle pathologies without any aid from advanced computational technologies. To this end, we propose the following four specific aims to identify those subtle disease-induced alterations, derive robust diagnostic conclusions, and predict future disease trajectories. Specifically, in Aim 1, we will develop a multi-view feature representation technique to robustly extract complementary information from neuroimaging data with multiple representative atlases, and then identify a small subset of most discriminative features for AD diagnosis. This novel multi-atlas technique will deviate from the conventional single-atlas approaches in feature representation, which are often susceptible to inter-subject structural variability, registration error, and atlas selection bias. In Aim 2, we will further devlop two novel multi-view feature mapping techniques for collaborative fusion of multimodality information by explicitly considering the distribution heterogeneity of different categories of features extracted from different modalities. This will significantly avoid the unnecessary complexity of feature distributions after our collaborative fusion, thus increasing the efficacy of subsequent diagnostic classifiers. Specifically, a deep learning technique (with deep multi-layered architecture) will be adopted to hierarchically mine multimodality information that resides nonlinearly both within each modality and between different modalities. In Aim 3, we will develop a novel multi-task sparse learning technique for joint prediction of diagnostic status and clinical scores (e.g., ADAS-Cog and MMSE) by considering the inherent correlations between features and between training samples. This will also allow us to exploit the latent structure underlying the data for robust estimation of these highly variable clinical scores. Finally, in Aim 4, we will jointly predict clinical scores of each given subject in multiple future time points, by developing coupled random forests that can take advantage of all training subjects with complete or even incomplete multimodality data and further enforce temporal consistency of those estimated clinical scores.  All the above-proposed techniques will be evaluated by a large image set of elderly subjects in ADNI. We expect that the successful completion of this renewal project will result in a comprehensive and effective diagnosis/prognosis framework for improving early detection of AD. The respective software tools will be released freely to the research community, as we have done with our HAMMER software, which has been downloaded by >5200 users from >20 countries. PUBLIC HEALTH RELEVANCE: The goal of this renewal project is to develop a set of advanced machine-learning techniques for precise in vivo quantification of pathological changes, afforded by multimodality neuroimaging data, for both diagnosis and prognosis of Alzheimer's diseases (AD). Specifically, we will explicitly exploit the distribution complexity and hierarchical nature of the multimodality data, for identifying subtle disease-induced alterations, deriving robust diagnostic conclusions, and predicting the future disease trajectory.",
The Center for Predictive Computational Phenotyping-1 Overall,"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",
Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis    DESCRIPTION (provided by applicant): All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This application takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.      PUBLIC HEALTH RELEVANCE: This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.           This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.         ",
WAVELET REPRESENTATIONS FOR DIAGNOSIS OF MELANOMA,"WAVELET REPRESENTATIONS FOR DIAGNOSIS OF MELANOMA A practical, digital dermoscopic imaging system will be developed for the        reliable, non-invasive, early diagnosis of melanoma. This system will            provide an objective and user-friendly tool to assist health care                providers in diagnosing melanoma. Phase 1 produced two very important            results:                                                                         1. The feasibility of a new paradigm for reliable, automatic diagnosis           of early melanoma was demonstrated. It combines wavelet-based multi-scale        statistical parameters, that quantify textures of dermoscopic images,            with other, non-wavelet parameters reported by us in the literature.             Significantly improved differentiation between early melanoma and its            benign simulants is achieved thereby.                                            2. The feasibility of using well calibrated, multispectral, dermoscopic          lesion images for automated lesion segmentation, feature extraction and          classification was established.                                                                                                                                   The specific aims of Phase 2 are:                                                (l) Further develop the image database for training and more                     comprehensive testing of our diagnostic methods.                                 (2) Analyze parametrically the dependence of performance of the proposed         lesion classification methods on the spectral illumination bands, spatial        resolution, and dynamic range of the imaging system.                             (3) Design and build six commercial prototypes.                                  (4) Clinically test these prototypes at four major clinical centers.                                                                                              PROPOSED COMMERCIAL APPLICATIONS:                                                This imaging system could become standard instrumentation in the offices         of dermatologists and health care delivery facilities for melanoma               screening, monitoring of suspicious pigmented lesions, and as an aid in          their diagnosis. Also, the database developed during Phase 2, and beyond,        will be an important medical resource for the health-care community.              n/a",
WAVELET-BASED AUTOMATED CHROMOSOME IDENTIFICATION,"WAVELET-BASED AUTOMATED CHROMOSOME IDENTIFICATION Commercial automated karyotyping instruments have improved to the point where the major factor limiting throughput is the time required for operator correction of chromosome classification errors. An improvement in chromosome classification accuracy would significantly increase the value of these instruments in cytogenetics labs. The goal of this project is to develop and commercialize significantly improved chromosome measurement and classification techniques for automated karyotyping. Currently the best-performing chromosome classification approach uses Weighted Density Distribution (WDD) features [11] to quantify the banding pattern of the chromosomes. These are computed as inner products between the banding profile and a set of WDD basis functions. The particular set of 1unctions originally proposed by Granum [11,38] has come into widespread use. In Phase I we showed that better function sets exist and that our new approach can find better WDD features than the best currently used. We have an innovative wavelet-based method for generating WDD functions and a chromosome classification testbed which supports large scale classification experiments. We propose to conduct a thorough, methodical search for better performing basis functions in Phase II. Phase III will incorporate the technology into PSI's PowerGene automated karyotyping instruments. PROPOSED COMMERCIAL APPLICATIONS: When the new chromosome classification technology is qualified for routine application, it will be incorporated into PSI's Powergene products, both in new systems sold and as an upgrade to existing systems.  n/a",
Discovery of Mental Health and Inflammation (MHAIN) Interactome,"Discovery of Mental Health and Inflammation (MHAIN) Interactome    DESCRIPTION (provided by applicant): Knowledge of protein-protein interactions (PPIs) is necessary to understand system-level aspects of organisms including that of psychiatric processes. The PPI network (interactome) acts as a vehicle for several types of biomedical research. It can be used to understand the disease mechanisms, drug targets and side effects, and genetic causes for disease. There are 1,014 human genes associated with 'brain'; for 448 of these genes not even a single PPI is known today. While it is useful to discover which pairs of proteins interact, it is also exceptionally challenging as more than 99.9% of protein pairs do not interact. The objective of this work is to carry out systematically designed computational work to discover the human mental health and inflammation (MHAIN) interactome. The MHAIN interactome refers to the network of PPIs where at least one of the two proteins is involved in either brain or inflammation. Many challenges will be addressed in discovering new protein-protein interactions towards building the interactome. Well-established algorithms from diverse computational fields, such as machine learning and signal processing will be applied to achieve the proposed goals. Further, pathways of influence of neuropsychological processes and inflammatory processes on each other will be mined from the interactome. Selected interactions will be validated by wet-lab experiments. The approaches that will be employed for predicting the MHAIN interactome are proactive-learning (to obtain the labels and features of proteins that would provide the maximum impact), transfer-learning (to transfer the knowledge of protein features and interactions from one species to another), multi-sensor fusion (to intelligently integrate output from different predictors). The predicted interactome would accelerate discovery of the biology and treatment of mental health related diseases, by serving as a central resource for biomedical research on mental health. For every protein of interest, verifiable hypothesis of its interactions will be generated that reduce the search space of interactions of that protein from about 25,000 to a few possibilities. New PPIs of proteins involved in major depressive disorder, psychosis in patients with Alzherimer's disease, and systemic inflammation (which is intricately connected to psychiatric diseases), will be put in biomedical context by co- investigators who specialize in these areas. The interactome will identify ""hub-proteins"" that are central to many pathways. It will provide hypothesis of ""functional connectivity"" of new proteins (namely, those of which nothing is currently known). Further, many diseases are found to be untreatable by suppressing a single pathway, and often require manipulating multiple pathways, and the MHAIN interactome can provide the overlap points of multiple pathways that may be used for treatment of diseases. The MHAIN interactome, which would be the outcome of the proposed research, can thus have a broad impact on our understanding of molecular basis of mental health. 1        The proposed research discovers interactions among proteins that are involved in mental health and inflammation. The knowledge of such interactions would generate hypotheses about the role of these proteins in biological functional pathways and would contribute towards the understanding of the biology of diseases and towards development of mechanisms of treatment.            ",
BRAIN RECOVERY IN REVERSIBLE THROMBOTIC STROKE,"BRAIN RECOVERY IN REVERSIBLE THROMBOTIC STROKE We propose to administer reproducible thrombotic stroke to rats, and to assess histopathologic, rheologic and physiological indicators of tissue status during ischemia and following vascular recanalization by the unique thrombolytic agent, hementin.  Of particular interest is to determine, following the ictus, the time domain for which recanalization can be achieved without inducing hemorrhage from ischemically compromised distal vascular segments. Evidence of postischemic reperfusion injury will be sought in terms of oxygen radical-stimulated tissue edema, neutrophil infiltration and lipid  peroxidation.  The degree of inhibition of these mediators of tissue destruction will be examined following administration of specifically targeted quenching agents, such as the stable prostacyclin analog iloprost, and the enzymatic scavenger of superoxide radical, superoxide dismutase in both the short-lived (in plasma) copper/zinc form and the unique long-lived manganese form.  Inasmuch as these studies encompass thrombotic stroke in the induction phase and its therapy in the recovery phase, as aided by mitigation of several deleterious aspects of reperfusion in metabolically compromise brain tissue, clinically relevant information may result.  Our models of thrombotic stroke are mediated by photoexcitation of intravenously injected rose bengal dye, either by argon ion laser irradiation of the middle cerebral artery, or by xenon arc lamp irradiation of the exposed, translucent skull and the underlying cortical microvasculature.  Occlusion(s) appear in as white thrombi containing agglutinated platelets in response to photochemically damaged endothelium.  Following hementin-induced recanalization at clinically relevant times (less than 6 hours following the ictus), edema will be assayed as brain water content, blood flow by the 14C-iodoantipyrine technique, metabolic status by oxygen tension, potassium ion activity and hydrogen clearance, lipid peroxidation by Schiff-base autofluorescence or conjugated dienes, and neutrophil content by antimyeloperoxidase staining, and fluorescent antibody or indium labeling.  In terms of these indicators of reperfusion injury, the ameliorating effect of the antioxidative and antineutrophil agents will also be assessed.  We will also investigate optical means to improve the efficiency of photochemically induced vascular occlusion; this development is projected to benefit surgery of neovasculature in the brain and eye.  n/a",
"Cell Signaling, PXR Phosphorylation & Drug Disposition","Cell Signaling, PXR Phosphorylation & Drug Disposition DESCRIPTION (PROVIDED BY APPLICANT):  Drug disposition is a highly regulated process in mammals. For example, the expression of genes encoding drug-transporting and drug-metabolizing proteins is induced by their substrates in liver and intestine. Recent research has shed new light on the molecular mechanism of this phenomenon. The pregnane X receptor (PXR) is a ligand-activated transcription factor that is expressed in liver and intestine. PXR coordinately regulates the drug-inducible expression of drug-transporting and drug-metabolizing proteins in liver and intestine. PXR binds to xenobiotic-response elements (XREs) in the promoters of its target genes as a heterodimer with the 9-cis-retinoic acid receptor (RXR). One extremely important PXR-target gene is the cytochrome P450 3A4 (CYP3A4) gene. CYP3A4 is primarily expressed in liver and intestine where it catalyzes the oxidative metabolism of nearly 60% of all clinically prescribed drugs. The hepatic expression of CYP3A4 and other PXR-target genes is rapidly suppressed in response to inflammatory cytokines, though the molecular basis of this repression is currently unknown. Repression of PXR-target gene expression occurs in people that undergo invasive surgery in response to inflammation, thereby producing altered pharmacokinetic properties of drugs in these patients. PXR is activated by a plethora of structurally diverse molecules including drugs, steroids, bile acids, and xenobiotics. Therefore, repression of PXR-target gene expression can produce potentially life-threatening drug-drug interactions. Thus, it is important to understand the molecular basis of the repression of PXR-target genes in order to predict and prevent the occurrence of drug interactions in post-operative patients. An alteration in the phosphorylation status of transcriptional regulatory proteins is a likely mechanism that mediates the repression of PXR-target gene expression following inflammation. The goals of these investigations are to (1) identify the sites of PXR phosphorylation following activation of specific cell signaling pathways, and (2) determine the effect of increased PXR phosphorylation on it's ability to (a) transactivate, (b) bind DNA, (c) translocate from the cytoplasm to the nucleus, and (d) interact with protein co-factors. Successful completion of these studies will allow us to determine the molecular basis of the repression of key drug metabolizing genes during the inflammatory response and provide increased opportunities to understand the xenobiotic response. These studies will provide additional insight into the regulation of drug disposition and drug-drug interaction. n/a",
Functional characterization of genetic and post-transcriptional variation using machine learning methods,"Functional characterization of genetic and post-transcriptional variation using machine learning methods The goal of this research proposal is to develop new in-silico approaches for accurate functional annotation of genetic and post-transcriptional variants. The rapid growth of Next-Generation Sequencing (NGS) and high- throughput -omics data have brought us one step closer towards mechanistic understanding of the complex genetic disease, such as cancer, neurological disorders, diabetes, and others at the molecular level. In particular, these data revealed that complex diseases commonly manifest changes at the genetic and post- transcriptional levels. Bot of these types of changes often affect structure and function of the corresponding genes and their products. Understanding the functional implications of the genetic and post-transcriptional variation is an important task as it can provide critical insights into the molecular mechanisms underlying the disease. Here, we propose to leverage novel machine learning paradigms to design computational methods for predicting the effect of genetic and alternative splicing variants on the macromolecular interactions. Macromolecular interactions underlie many cellular functions in a healthy organism. The disease-induced changes in the genes, such as single nucleotide variations (SNVs) and alternative splicing variations (ASVs) have been recently reported to cause the protein-protein interaction network rewiring. Unfortunately, the experimental high-throughput techniques that characterize the large-scale effects of SNVs or ASVs on PPIs are expensive, time-consuming, and far from being comprehensive. The current in-silico methods either suffer from the limited applicability, or are less accurate when compared with the experimental methods. To overcome these challenges, we will use two recent machine learning paradigms, learning under privileged information (LUPI) and semi-supervised learning. If successful, we expect for the proposed methods to provide the critical advancement in the two main challenges of the current computational approaches, the limited coverage and lower than the experimental accuracy. The methods will be freely available to the community as the stand-alone tools as well as web- servers. The goal of this proposal is to build computational tools that discover the links  between the disease-associated mutations as well as alternatively spliced protein isoforms  and the protein-protein interactions mediated by the disease proteins. The tools use advanced  machine learning methods to find such links in a fast and inexpensive way. These tools  will be useful in elucidating the molecular mechanisms implicated in the complex genetic disorders.",
fcMRI in Infants at High Risk for Autism,"fcMRI in Infants at High Risk for Autism    DESCRIPTION (provided by applicant): This ESI / New Investigator clinician-scientist brings an expert team to test the altered brain functional connectivity hypothesis of autism during infancy. We will conduct graph-theory-based network analyses on functional connectivity magnetic resonance imaging (fcMRI) data acquired in high-risk infants who are currently being studied in the multi-site, NIH-funded Autism Center of Excellence (ACE) study R01 HD055741: A Longitudinal MRI Study of Infants at Risk for Autism - Joseph Piven: PI. We will prospectively study diverging developmental trajectories for functional networks of brain regions in infants who do and do not develop an Autistic Spectrum Disorder (ASD), during a suspected period of altered brain growth in autism, and prior to symptom expression. All four ACE data collection sites and their existing Data Coordination Center will participate. These efforts will provide longitudinal fcMRI data (scans at 6, 12, and 24 months old) in up to 664 high-risk and control infants (~15% of the 544 high-risk infants will develop an ASD). All four ACE data collection sites are already (as of May, 2010) - in advance of any dedicated funding, to ensure enough fcMRI data - acquiring fcMRI data on their subjects. Interfacing with the high-risk infant ACE structural imaging study and its supplements will allow us to build on existing infrastructure, save effort and cost, standardize collections, and merge databases. It also provides the potential for future genetic-functional imaging associations. Our fcMRI approach considers the problem of autism from the perspective of alterations in the behavior of brain-wide networks and changes in strengths of functional connectivity between and within rigorously defined sub-networks of brain regions. We believe this approach is more fruitful than those which consider smaller numbers of brain regions. We will additionally use a novel cortical functional areal parcellation routine (that Co-I Steve Petersen et al. have developed) to enhance the sensitivity of the infant fcMRI data analyses. Unique insights may come from comparing our network-based fcMRI analyses to the structural MRI, diffusion tensor imaging, and extensive phenotypic data generated by the existing ACE study (fcMRI acquired in the same infants). Once diagnoses are assigned in the ACE study, we will use a machine learning, multivariate pattern classification approach (Support Vector Machine: SVM) to explore the possibility of developing a diagnostic classifier for ASD. The eventual goal would be to train an SVM to predict which infants will and will not develop ASD, based on network properties of their fcMRI data, prior to the expression of symptoms. If successful, our proposed program of research could inform the future development of pre- symptomatic diagnostic tests for ASD, increase our knowledge about the neurobiology of autism, and provide methods for studying functional brain changes in response to interventions. These approaches could be adapted for the study of other neurodevelopmental and early-onset psychiatric disorders.      PUBLIC HEALTH RELEVANCE: The proposed work is relevant to public health because autism is one of the most devastating psychiatric disorders of childhood, and disorders spanning the broader spectrum affect approximately 1/100 individuals. We propose to test the brain functional connectivity hypothesis of autism with functional connectivity magnetic resonance imaging (fcMRI) in infants who are at high risk for autism. If successful, we may contribute to the eventual development of pre-symptomatic diagnostic tests for autism that will improve early identification, which is critical for enhancing outcome in affected individuals. More broadly, our proposed studies will also increase our knowledge about autism in ways that will complement future genetic, screening, and intervention studies.           The proposed work is relevant to public health because autism is one of the most devastating psychiatric disorders of childhood, and disorders spanning the broader spectrum affect approximately 1/100 individuals. We propose to test the brain functional connectivity hypothesis of autism with functional connectivity magnetic resonance imaging (fcMRI) in infants who are at high risk for autism. If successful, we may contribute to the eventual development of pre-symptomatic diagnostic tests for autism that will improve early identification, which is critical for enhancing outcome in affected individuals. More broadly, our proposed studies will also increase our knowledge about autism in ways that will complement future genetic, screening, and intervention studies.         ",
Pharmacogenomics of serotonin-specific reuptake inhibitors,"Pharmacogenomics of serotonin-specific reuptake inhibitors     DESCRIPTION (provided by applicant): Neuropsychiatric disorders, such as depression, have not shown conclusive linkage or association study results. Today, an enormous portion of heritability for depression remains unexplained. Rather than reiterating studies attempting to identify genetic variants underlying depression pathophysiology, I propose a different approach of evaluating genetic variation in the safety and efficacy of the major class of antidepressants. I will identify patients with the quantitative and discrete phenotypes of serotonin-specific reuptake inhibitor (SSRI) response (as measured through the Patient's Health Questionnaire-9 pre- and post-SSRI treatment), and SSRI-associated serious side effects, such as abnormal bleeding and serotonin syndrome. After identification of these phenotypes from the electronic Medical Records and Genetic Epidemiology (eMERGE) consortium, I will perform a genome-wide association study (GWAS) on 50,109 subjects to identify candidate genes involved in SSRI pharmacology and then leverage overlapping exome sequence data to identify rare, potentially causative mutations. As many GWAS and rare variant studies suffer from a lack of functional validation (i.e., that the identified variant truly causes the phenotype), I will functionally valiate these identified rare mutations in the model organism Saccharomyces cerevisiae using a yeast growth-based assay as a direct measure of protein function. The P450 enzyme CYP3A4, which has been implicated in SSRI metabolism, will be used as a proof of concept for the yeast assay. Finally, I will then use this yeast growth assay to perform deep mutational scanning to create a pharmacogenomic map of all possible mutations and their effect on enzyme hydrolysis, thereby linking DNA sequence to protein function. This work will provide a unique resource for understanding SSRI pharmacology. Through completion of a GWAS on the pharmacogenomic phenotypes of SSRI response and separately, risk of SSRI-associated bleeding and serotonin syndrome, I will likely identify numerous candidate genes that may further inform on the metabolism, transport, and mechanism of action of SSRIs, thereby furthering basic science. Moreover, through functional validation and creation of a pharmacogenomic map with deep mutational scanning, I will create an invaluable resource for clinicians to interpret the likely efect of their patient's rare mutation. Through this project, I hope to further the effort to bring personalized, genomic medicine into clinical practice, to decrease the morbidity and mortality of depression, which is estimated by the Center for Disease Control to affect 1 in 10 adults in the U.S.          PUBLIC HEALTH RELEVANCE: Depression is affects 1 in 10 adults in the United States and is one of the leading causes of disability. Depression is primarily treated with serotonin-specific reuptake inhibitors (SSRIs). Understanding how mutations in genes affect SSRI response and risk of side effects forwards the implementation of personalized, genomic medicine into evidence-based clinical practice. This integration of genomic information will likely greatly decrease the morbidity of depression in the United States and globally.            ",
Post-natal development of high-level visual representation in primates,"Post-natal development of high-level visual representation in primates View-invariant object recognition is a complex cognitive task that is critical to everyday functioning. A key neural correlate of high-level object recognition is inferior temporal (IT) cortex, a brain area present in both humans and non-human primates. Recent advances in visual systems neuroscience have begun to uncover how images are encoded in the adult IT object representation, however the learning rules by which high level visual areas (especially IT) develop remain mysterious, with both the magnitude and qualitative nature of developmental changes remaining almost completely unknown — in part because, over the last thirty years, there have been practically no studies of spiking neural responses in the higher ventral cortical areas of developing primates. There is thus a significant gap in our understanding of how visual development proceeds.  This exploratory proposal aims to characterize how representation in higher primate visual cortex changes during development. We first aim (Aim 1) to implant chronic electrode arrays to record hundreds of IT neuronal sites in response to thousands of image stimuli in awake behaving juvenile macaques. These data will comprise a snapshot of the developing primate visual representation, and will be particularly powerful because we have already extensively measured adult monkey IT using the same stimuli and methods. By comparing juvenile and adult neuronal responses at both single site and population levels, we will obtain a unprecedentedly large-scale and detailed picture of the neural correlates of high-level visual development (Aim 2).  Aims 1 and 2 are exploratory, but potentially transformative – they will result in publicly available neuronal IT development benchmarks against which any proposed model of high level visual development can be rigorously tested, and will spur the development of those models in our lab and others. In that context, we will also seek (Aim 3) to improve known semi- and un-supervised learning rules from the computer vision and computational neuroscience literature, and to compare them to both recent high-performing (but biologically implausible) supervised models as well to the rich developmental measurements obtained in Aims 1 and 2.  Establishing experimental and surgical procedures for juvenile array recordings will create the future opportunity to observe changes in high level neural visual representations while experience is manipulated in early development, and will enable experiments in other sensory, motor, or decision making domains. If successful, the proposed work will yield a deeper understanding of the principles underlying visual cortex development, understanding which will in turn be helpful for treating neurodevelopmental disorders that implicate cortical circuits, including amblyopia and autism. Project narrative  Visual object recognition is fundamental to our everyday functioning. While the brain is remarkably good at accomplishing these challenging tasks, we do not yet know how it learns this ability during development. The goal of these experiments is to develop new experimental and computational tools to discover the neural learning principles that underlie that visual ability.",
Semi-Automated Processing of Interconnected Dyads Using Entity Resolution (SPIDER),"Semi-Automated Processing of Interconnected Dyads Using Entity Resolution (SPIDER) ﻿    DESCRIPTION (provided by applicant): The overarching aim of this proposal is to develop and verify a new and innovative software system that will assist researchers in more rigorously constructing social networks. During the past two decades, studies have increasingly employed social network analysis (SNA) to understand HIV and sexually transmitted infections (STI) transmission. The mapping of ""risk networks,"" in which individuals are connected by infection-spreading ties, has yielded especially valuable insight into the behavioral epidemiology of HIV and STI, and has informed promising interventions designed for people at risk for or living with HIV. However, despite these advances and the burgeoning popularity of SNA-based HIV/STI research, major methodological and technological challenges are hindering further progress in the field. SNA's ability to catalyze major epidemiologic advances relies on researchers' ability to construct valid representations of participants' networks from behavioral data. The standard protocol for constructing risk networks, or identifying direct and indirect relationships among participants and their partners, involves matching participants' names and demographics with data provided about named partners. This process of identifying and matching duplicate individuals in the network (i.e., ""entity resolution"" [ER]) is often conducted through laborious, manual cross-referencing procedures. These procedures are limited in their reproducibility and may lead to misspecification of network structure. Further complicating valid network construction is that ER criteria are: (1) not formalized; (2) specified differently across studies n various settings and populations; and (3) rarely, if ever, explained in the published literature. Semi-automated tools that combine powerful automated ER processes with capacities for customization and qualitative input have the potential to dramatically improve the speed and accuracy of risk network construction. Current tools for ER in health research tend to focus on a static subset of available ER techniques (e.g., similarity in demographics, phonetic-based matching techniques) without incorporating state- of-the-art approaches (e.g., machine learning). The proposed software, Semi-automated Processing of Interconnected Dyads using Entity Resolution (SPIDER), will provide users with a system that enables efficient, semi-automated network construction using a library of robust, statistically rigorous ER algorithms, rich desktop-based annotation tools, and secure web-based technologies. The customizability of SPIDER will allow for multi-disciplinary utility in studies using varying designs and will include innovative features that specifically respond to emerging methodological trends in HIV/STI research. The overarching goal of this project is to improve the efficiency and quality of network construction used in research, thereby improving the evidence base for network-based interventions that mitigate the spread of HIV.         PUBLIC HEALTH RELEVANCE: The overarching aim of this Phase I proposal is to develop and verify a software system that will assist researchers, interventionists, and practitioners in more rigorously constructing social networks. The software, Semi-Automated Processing of Interconnected Dyads Using Entity Resolution (SPIDER), will provide users with a system that enables efficient, semi-automated risk network construction using a library of robust, advanced entity resolution algorithms, rich desktop-based annotation tools, secure web-based technologies, and a host of innovative features that specifically respond to emerging methodological trends in HIV/STI research. The overarching goal of this project is to improve the efficiency and quality of network methods used in research and practice and to thereby improve the evidence base for network-based interventions that mitigate the spread of HIV.                ",
Development and Evaluation of an Evidence-Based Mobile Health Caregiver Intervention for FASD,"Development and Evaluation of an Evidence-Based Mobile Health Caregiver Intervention for FASD Project Summary/Abstract   Fetal alcohol spectrum disorders (FASD) represent a major public health problem that affects up to 2 to 5  percent of school-­aged children in the US. Unfortunately, only a small fraction of children with FASD and their  families can access FASD-­informed interventions due to significant systems-­ and family-­level barriers.  Research suggests that self-­directed and peer-­to-­peer interventions are acceptable to families and can lead to  significant improvements in parenting, child behavior, and resource utilization. Advancements in technology  are facilitating more accessible and interactive methods for self-­directed education and support. The proposed  project will develop and evaluate the efficacy of a novel mobile health (mHealth) application (“app”) to directly  provide caregivers with evidence-­based content and peer-­moderated support they can easily access and use  to improve outcomes for their children and families. The app, currently called “FMF Connect,” will be derived  from the scientifically-­validated Families Moving Forward (FMF) Program and will build on existing frameworks  for the development of medical apps. This project will follow a systematic approach to the development and  evaluation of the FMF Connect mHealth intervention, including a small-­scale feasibility trial (n=30), and a  larger-­scale hybrid implementation-­effectiveness trial (n=120) with caregivers raising children (ages 3-­12) with  FASD. Implementation data will aid in identifying the patterns of app usage that relate to the greatest  improvements in child and caregiver outcomes. Study hypotheses are: 1) that caregivers will find the FMF  Connect intervention acceptable, with easy to access content and encouraging support from peer-­moderators;;  2) that greater usage of specific intervention components will relate to larger improvements in child and  caregiver outcomes;; 3) that caregivers who receive the FMF Connect intervention will have larger gains on  child and caregiver outcomes relative to a waitlist comparison group;; and 4) that an increase in  neurodevelopmental attributions for behavior will mediate intervention-­related improvements in parenting  efficacy and child behavior. Project findings will guide further app development both in terms of content and  technological advances to optimize intervention effects. Results of this study will further the overall strategic  aims of the Collaborative Initiative on FASD (CIFASD), which are to inform and develop effective interventions  for FASD. This project will also benefit from resources and collaborations within CIFASD to carry out the  proposed work, including recruitment of a diverse sample, diagnostic support, and outreach and dissemination.  This is one of the first studies to empirically test an mHealth intervention delivered by parents with peer-­ moderated support. It has the potential to reach many families raising children with FASD in need and could  reduce significant barriers to care, resulting in a greater public health impact.                   Project Narrative   The vast majority of families raising children with fetal alcohol spectrum disorders (FASD) cannot access  FASD-­informed interventions due to significant systems-­ and family-­level barriers. This project will develop and  evaluate the efficacy of a mobile health application to directly provide caregivers raising children with FASD  with evidence-­based content and peer-­moderated support to improve child and caregiver outcomes.                         ",
Community Surveillance of Coronary Heart Disease,"Community Surveillance of Coronary Heart Disease Project Summary/Abstract  Preventing the onset of acute myocardial infarction (AMI) and its recurrence, and reducing the morbidity and mortality associated with AMI, remain of significant public health and clinical concern. Monitoring contemporary trends in AMI incidence, treatment, and in-hospital and long-term outcomes is of considerable importance given periodic national updates of treatment guidelines, emphasis on reducing hospital readmissions, and revised definitions and classifications of AMI. Continuously supported by the NHLBI, we have conducted more than 35 years of population-based surveillance of AMI incidence and attack rates, hospital management practices, and the in-hospital and long-term prognosis associated with AMI among residents of central MA hospitalized at all central MA medical centers. We have a highly experienced team of cardiologists, epidemiologists, clinical informatics, and health services researchers who will build on multi- decade long trends (1975-2011) in our principal study endpoints examined previously in this study to the two new study years of patients hospitalized with AMI at all central MA medical centers in 2014 and 2017.  To sustain our efforts into the era of electronic medical records (EMRs), and after implementation of the ICD-10 system in 2015, we will develop a new automated AMI surveillance system that efficiently utilizes EMRs by taking advantage of state-of-art natural language processing (NLP) methods that will be compatible with ICD-10 (Aim 1). We will use the new NLP method to streamline traditional chart review-based collection of socio-demographic, clinical, treatment, and hospital and post-discharge outcomes data in patients hospitalized with AMI at all 11 central MA medical centers in 2014 and 2017. The data extracted from NLP-streamlined chart reviews will be used to validate and refine the NLP system. Issues related to changes from ICD-9 to ICD- 10 will be carefully addressed. The new NLP-enriched EMR-based surveillance system will eventually be implemented in all participating central MA hospitals. Using the NLP-enriched and EMR-based surveillance data, we will monitor the contemporary clinical epidemiology of AMI, and out-of-hospital deaths due to coronary disease, and changing landscape, over a more than 40 year period (1975-2017) (Aim 2).  The new EMR-based and NLP-enriched system will enhance the population-based surveillance of acute coronary disease. This new system will be cost-effective, more efficient and near-real time, have greater accuracy and precision, and can be readily updated to accommodate changes in information technologies and broadly applicable to other hospital systems. It will support our continued efforts to provide unique community- based observational data on several populations that are often excluded from clinical trials, and that are increasing in numbers, namely the elderly and patients with multiple morbidities. Furthermore, it will generate critical data to inform more national clinical guidelines on the enhanced prevention and management of AMI. If successful, the system can serve as a model and be implemented statewide in MA and elsewhere in the US. Project Narrative  The results of the proposed community-based study will provide data about 40 year trends with regards to the changing magnitude of, and outcomes associated with, heart attacks in residents of a large central New England community. The results of this investigation will also provide contemporary insights on how patients who experience heart attacks in the community are treated by physicians.",
Computational methods for regional hippocampal morphometry in AD,"Computational methods for regional hippocampal morphometry in AD    DESCRIPTION (provided by applicant): The PI is a quantitative researcher with a background in computer science and a record of publications in the areas of image analysis methodology, computer vision and machine learning. His objective is to establish himself as a highly productive independent researcher of Alzheimer's disease (AD) and dementia by complimenting his strengths in quantitative analysis with a newly acquired expertise in the biomedical aspects of dementia and aging. Prof. John Detre MD, the head of Penn's Center for Functional Neuroimaging and an internationally renowned neurologist, has offered to serve as the principal mentor. The co-sponsors, Prof. John Trojanowski, MD, PhD and Prof. Murray Grossman, MD, EdD have offered to help the PI acquire expertise in the pathology and physiology of dementia as well as its impact on memory, language and thinking. The research plan involves developing an advanced framework for detecting and tracking structural and functional changes in the anatomical subregions of the hippocampus and parahippocampal gyrus using in vivo neuroimaging. Using this framework, the PI will evaluate the hypotheses that AD-related changes differ across the anatomical subregions of these temporal lobe structures and, consequently, that their morphology and physiology can be used to predict AD early and accurately. These hypotheses will be tested by mining the massive database of longitudinal MRI image data of AD patients, people at risk for AD and elderly controls, which is being generated by the ADNI initiative launched recently by the NIA/NIH. RELEVANCE. As the baby boom generation ages, the number of US families devastated by AD and the associated financial burden on the society is expected to increase dramatically. While no cure for AD is known, a sizable effort is underway in developing pharmaceutical agents that may halt or slow down the neurodegenerative processes that cause AD. To be effective, these treatments will require early detection. The Pi's career objectives, addressed by the             research proposed in this application, are to improve the accuracy of early AD diagnosis and to develop non-invasive analytic tools that would aid drug development and broaden what we know about the pathology and physiology of AD.           n/a",
Big Data and Network Analysis of Children's Health,"Big Data and Network Analysis of Children's Health Project Summary  Decades of research suggest that neighborhood socioeconomic disadvantage increases children's health risk. This proposed project seeks to address two major weaknesses in conventional neighborhood effects research and interventions: a) the assumption that residential neighborhoods function independently of each other - ignoring that risk factors in areas where people work, learn, and play away from home may interact with residential factors; and b) as importantly, insufficient understanding of neighborhood effects mechanisms and heterogeneity in effects. To systematically address these critical barriers in the field, I propose a research and training program that will enable me to learn, use, and adapt recent advancements in Big Data analytics. I plan to model hidden interdependencies among individuals and neighborhoods and operationalize mechanisms of neighborhood effects by drawing on multiple large datasets (demographic, geospatial, networks, population flows), with several hundred million observations across multiple states, cities, and years, and match them to locally and nationally representative restricted survey data. The massive volume, great variety, and unique complexity of such data, such as relational data on inter-neighborhood dependencies and interactions, pose a challenge to the standard capabilities of hardware, algorithms, and analytical methods and models of social and population science. The proposed training program in Big Data analytics and machine learning will enable me to overcome computational and conceptual challenges and uniquely position me to: a) examine the ecological inter-neighborhood networks (econetworks) to which population groups are differentially exposed to across space and time; and b) test new contextual mechanisms underlying children's exposures to health risks. Specifically, I propose to: a) develop computational models of dynamic large scale econetworks to assess population differences in exposures to health risk factors, as they commute daily between home and workplaces; b) examine heterogeneity in econetwork effects on child health using a hybrid design that links Big Data to local and national surveys; and c) model child health risk mechanisms and causal effects using natural experiments on Big Data. The proposed training program will enable me to learn and adapt Big Data analytics, draw on its strengths, but also address some of its key limitations. With the support of a unique team of distinguished mentors and advisors, established experts in Big Data analytics, spatial demography, network analysis, child development and health risk, neighborhood change, and population heterogeneity, I will embark on a training program that will uniquely enable me to address these research goals and position me to become an independent scholar and a leader in the field. Project Narrative This project contributes to advancing public health scholarship by leveraging and adapting Big Data analytical tools to overcome critical barriers in the field related to conventional assumptions about effects of neighborhood risk exposures on child health. It addresses the need to understand and model inter- neighborhood interdependencies and underlying multidimensional social capital mechanisms in order to better understand population heterogeneity in neighborhood effects on child health across space and time. The project also advances public health through an integration of rigorous social and data science methodology to create new measures and test causal hypotheses that advance our understanding of social capital forces that foster resilience to adversity and improve child health behavior and outcomes.",
"Merging Temporal Changes in Clinical Informatics, Transcriptomics, and Cytokine Profiles to Understand the Host Response to Bacteremia","Merging Temporal Changes in Clinical Informatics, Transcriptomics, and Cytokine Profiles to Understand the Host Response to Bacteremia As an ICU physician and an immunologist, I have devoted my research career to understanding sepsis,  a disease that affects nearly 2 million people annually in the USA. Sepsis is a life-threatening  condition that arises when the body's response to infection injures its own tissues. Great strides  have been made towards improving the clinical care of the septic patient, but the mortality rate  remains >20% for several reasons: First, each sepsis-causing pathogen, be it bacterial, viral, or  fungal, carries its own virulence factors that affect the host response, but unfortunately, much  research has focused on studying septic patients as a group, rather than distinguishing patients  based on microbiologic cause. Second, researchers often study patients once they manifest  sepsis-induced organ failure yet many people sustain infections due to common sepsis  pathogens, like Staphylococcus aureus, but never develop sepsis; understanding the ""appropriate""  response to a pathogen is critical to understanding the ""inappropriate"" response of  sepsis. Finally, much sepsis research occurs in silos; clinician researchers focus on the  electronic medical record, while basic scientists analyze biologic data. Too often, these  groups do not collaborate to share information, even though understanding the biologic  significance of clinical data may be of great value. To address these issues, I propose a unique  approach to understand the host response to infection that incorporates both biologic data and  clinical electronic medical record (EMR) data from patients with S. aureus bacteremia.  By limiting analysis of the host response to infections caused by a single pathogen at a single  site, we can control for the variability induced by pathogen-specific factors. In addition,  by studying all patients with S. aureus bacteremia, and not simply those patients with  sepsis, we can understand both the appropriate host response as well as the inappropriate host  response that characterizes the development of sepsis. With our bank of samples collected from S.  aureus bacteremia patients we will analyze both cellular mRNA transcripts and plasma  protein/cytokine levels, collected at different time points from each patient. We will  combine the results of these analyses with clinical data found in the EMR to provide a correlation  between the biology of the host response and its clinical manifestations. Our per-patient  data, then, will have unprecedented granularity which we can then use to apply machine learning  techniques to identify multi-faceted endotypes that predict outcomes (such as mortality). Once we  have built these endotype models, we will validate them using pilot data collected from newly  enrolled patients with either S. aureus or E. coli bacteremia. This approach will allow  us to identify factors common to the dysregulated host response across all infections, as well as  those that may be specific to the type of infection. Understanding both the  appropriate and the inappropriate host response to infection, and understanding which  aspects of the host response are pathogen-specific (and which are not) will allow development  of novel therapies for this devastating disease. The mortality rate due to severe sepsis exceeds 20%, yet in spite of 3 decades of research, we  still have a very limited understanding of the dysregulated host response that drives  this mortality. I will use my experience as a PhD-trained immunologist and ICU physician to  study the host response to the two most common causes of bacteremia in hospitalized patients, S.  aureus and E. coli. Understanding both appropriate and dysregulated host responses to infections as  manifested in both biological and clinical data will allow me to develop precision therapy to treat  this deadly disease.",
CLINICAL CORRELATIVE STUDIES OF NEUROBLASTOMA,"CLINICAL CORRELATIVE STUDIES OF NEUROBLASTOMA DESCRIPTION (Adapted from the applicant's abstract):  Neuroblastoma is the       most common extra cranial tumor of childhood, and cases are highly               heterogenous with regard to clinical behavior.  Although patient groups with     different expected survivals can be identified by clinical staging at            diagnosis, individual clinically defined risk groups include patients with       quite different outcomes.  Inter- and intra-stage diversity provides             opportunities for identifying molecular genetic and biologic properties of       tumors that are associated with treatment outcome.  Such correlations can        identify risk groups that otherwise are not recognizable, thus aiding in the     interpretation of clinical studies, and they can provide new criteria for        more appropriate therapy assignment.  They may also suggest new approaches       to therapy.  The long-term goal of the proposed studies is to develop tests      that improve definition of risk groups so that the most appropriate and          effective therapy can be given to each patient.                                                                                                                   The hypothesis of this application is that subsets of neuroblastomas can be      identified by evaluating (1) genes that are critically involved in               neuroblastoma growth, differentiation, and survival and (2) the ability of       tumor cells to grow continuously in vitro.  Plans are to build upon previous     studies of N-myc proto-oncogene expression in neuroblastoma and of the           neurotrophins (nerve growth factor, NGF, and brain derived neurotrophic          factor, BDNF) and their receptors (e.g., TrkAl), and of tumor cell growth in     vitro, which demonstrated the potential importance of these markers in           prognostication.                                                                                                                                                  The specific aims are as follows:  (1) determine if tumor phenotype defined      by MYCN gene amplification and expression, TrkA expression, telomerase RNA       expression, and growth in vitro correlates with disease progression during       or after therapy; (2) develop multivariate statistical models for predicting     outcome based upon clinical presentation (stage and age) and laboratory data     (tumor MYCN gene amplification, TrkA expression, telomerase RNA expression,      growth in vitro, and histopathology); (3) determine in a pilot study if          expression of other neurotrophins and their receptors defines risk groups.       If so, include these in the above analyses.                                                                                                                       The CCG performs phase III studies in which newly diagnosed patients receive     therapy according to risk classification, which is currently based upon          clinical stage, age, histopathology, and N-myc gene amplification status.        Approximately 200 patients are registered annually in studies for low,           intermediate, and high-risk neuroblastoma.  Tumor tissues including (in some     patients) bone marrow with tumor are obtained at diagnosis prospectively.        Tumors are tested to determine their phenotype with regard to N-myc              amplification, trk RNA expression level and pattern of expression, BDNF RNA      expression, telomerase RNA expression and activity, chromosome 1p deletions,     and tumor cell growth in vitro.  The goal is to determine if these               laboratory test results can identify clinically important but small subsets      of patients who may benefit from different therapy.  If preliminary studies      indicate that specific tests are particularly important in predicting            prognosis, large-scale studies will be conducted to better define the value      of these new tests (e.g., their ability to identify patients who will likely     fail treatment).                                                                                                                                                  It is anticipated that these studies will improve prognostication and that       they may contribute to development of novel and possibly more effective          therapies for high-risk patients, while diminishing the risks of treatment       for low risk patients.                                                            n/a",
Using a Sequence-to-Structure-to-Function Approach to Functionally Characterize Protein Coding Missense Mutations in the Human and Rat Genomes,"Using a Sequence-to-Structure-to-Function Approach to Functionally Characterize Protein Coding Missense Mutations in the Human and Rat Genomes DESCRIPTION: The goal of this BD2K K01 application is to provide Dr. Jeremy W. Prokop with the mentoring and training to be an independent investigator in big data to knowledge. Mentoring and training will be provided to Dr. Prokop in genomics, proteomics, computer science, and statistics to advance his skill to allow for independence. This will allow for further develop of his sequence-to-structure-to-function analysis for interpretation of protein coding genetic variants into a usable workflow available to other scientists. The mentoring throughout this award will be from Dr. Howard Jacob, a leader in rat/human genetics and tool development to understand variants in whole genomes. Additionally, Dr. Andrew Greene serves as a co-mentor to help advance skills in proteomics and Dr. Christina Kendziorski as a co-mentor to advance statistical tools/approaches. The Medical College of Wisconsin (MCW) is a leader in the use of whole genome sequencing in understanding human health, with a Cap/CLIA certified clinical sequencing facility, tools for identifying genetic variants from whole genomes (such as Carpe Novo), and operation of databases like the Rat Genome Database. These tools and knowledge at MCW will serve as an asset for the training and completion of the Aims in this award. Dr. Prokop's research focus in this grant is to further expand the sequence-to-structure-to-function approaches he developed during his Ph.D. and initial postdoc into a workflow and web submission server for other users. Aim 1 of the grant organizes these steps into a workflow allowing for the development of the web based submission server. To test the workflow, 75 candidate genes for cardiovascular disease will be screened. Initial use of the approach has revealed hypotheses for how genetic variants in Havcr1 and Shroom3 result in altered cardiovascular drug response or disease. Variants in these two proteins will be biochemically characterized using a novel decision tree to standardize experiments (Aim 2) and to serve as a quality control for the approaches of Aim 1. From the results of the 75 screened cardiovascular genes, the four genes with the highest confidence score will be validated using the biochemical decision tree in year four and five of this award serving as an additional quality control for the approaches in Aim 1. This grant will provide the training and support for Dr. Prokop to be integrated into the Medical College of Wisconsin's Clinical Sequencing program, allowing for additional R01 proposals for validation of genetic causes of disease, and facilitate the development of Dr. Prokop into an independent researcher in the use of big data. PUBLIC HEALTH RELEVANCE: Development of a new tool package that is able to interpret genetic variants of disease genomes into a testable hypothesis of how protein function is perturbed. This tool will allow for improved diagnostic and treatment methods for many human diseases that employ whole genome/exome sequencing such as cardiovascular, cancer, and rare diseases.",
Inflammation Genes and Lung Cancer Risk,"Inflammation Genes and Lung Cancer Risk DESCRIPTION (provided by applicant): There is accumulating evidence that chronic injury and inflammation in the respiratory tract, such as that caused by cigarette smoking, predispose to lung cancer. We therefore propose to conduct an in depth pathway-based analysis of gene variants in the inflammatory pathway using test and validation sets of cases and controls. This proposal builds on a well-annotated specimen repository of lung cancer cases and controls enrolled in an ongoing risk factor study (CA55769, Spitz, PI). Cases are frequency-matched to controls on age, gender, ethnicity and smoking status recruited from a multi-specialty physician practice. Data collected include smoking history, dietary intake, cancer family history, specific occupational exposures (e.g., asbestos, dust), and previous medical history including chronic obstructive airway disease, asthma and hay fever. Genomic DNA and rich candidate genotype and phenotype data are available. Aim 1: To identify novel genetic variants influencing lung cancer risk in a test set of 1500 cases with non-small cell lung cancer and 1500 matched controls (all Caucasian), using the Illumina iSelect Infinium chip with 8.5 to 9K SNP's. Aim 2: In a replication set of an additional 1000 cases and 1000 controls, using a GoldenGate assay, we will evaluate the top 1500 SNPs identified from Aim1 as meeting the P<0.1 criterion, or selected by a rational prioritizing approach that incorporates published results, type of SNP, evolutionary biology, physico-chemical properties and haplotype tagging SNPs. Aim 3: To perform fine mapping in the flanking regions of 50 SNPs selected by the same approach as in Aim 2, combining prior information with in silico approaches for predicting functionality. For each of these 50 SNPs, we will select an average of 10 additional SNPs per gene region to regenotype in all 2500 cases and 2500 controls. Aim 4. To extend our epidemiologic risk prediction model by incorporating established epidemiologic risk factor and gene variant data. We will apply machine-learning tools to identify gene-environment and gene-gene interactions. Covariates will include prior emphysema, asthma, hay fever, dust and asbestos exposure, smoking characteristics, family history of cancer, and anti-inflammatory drug use. The International Lung Cancer Consortium will perform external validation in a proposal to be developed. Our approach to comprehensively evaluate variants in a candidate pathway in a large well- powered study will be applicable to a variety of other cancer sites where inflammation plays an important etiologic role, as well as in non-neoplastic diseases with a strong inflammatory component such as emphysema. The public health potential of a useful risk prediction modes for lung cancer is substantial. Public Health Relevance Statement Cigarette smoking results in inflammation in the respiratory tract and there is growing evidence that chronic inflammatory processes predispose to lung cancer. However, the molecular mechanisms underlying the causal nature of this association are unclear. We propose to conduct an in depth analysis of gene variants in the inflammatory pathway as susceptibility factors for lung cancer. This proposal builds upon an existing well annotated specimen repository. We will evaluate gene variants in a test set of lung cancer cases and matched controls and validate the findings in an independent dataset. Finally we will incorporate these findings into an extended risk prediction model for lung cancer.",
Automated quantitative CT imaging of epicardial adipose tissue and risk of cardiac events,"Automated quantitative CT imaging of epicardial adipose tissue and risk of cardiac events PROJECT SUMMARY Coronary artery disease remains the leading cause of death worldwide, and more than half of the individuals suffering acute myocardial infarction have no prior symptoms. Coronary calcium scoring with non-contrast CT is increasingly used for cardiovascular risk stratification in the asymptomatic population. Epicardial adipose tissue (EAT), a local visceral fat depot surrounding the heart, has been recently reported as a significant imaging biomarker for cardiovascular risk stratification. Despite being routinely imaged noninvasively by non-contrast cardiac CT for coronary calcium scoring, EAT features are currently not measured or reported, primarily due to the absence of robust, automated quantification methods.  We propose to employ novel image processing algorithms to achieve fully automated, robust quantification of EAT features from cardiac CT, and to apply machine learning methods to efficiently combine patient clinical data, coronary calcium and EAT features into a new integrated risk score to predict future cardiac events. We will evaluate this risk score in two existing, prospective registries of asymptomatic patients with available coronary calcium scans, clinical data, and followup for cardiac events (myocardial infarction, cardiac death, late revascularization). These rich resources are: the Early Identification of Subclinical Atherosclerosis Using Non-Invasive Imaging Research [EISNER] registry (2614 patients) and the St. Francis Heart Study (4613 patients). We propose three specific aims: 1) To develop and evaluate the accuracy and reproducibility of new computational algorithms for automated quantification of EAT measures; 2) To evaluate the prognostic value of automatically-quantified EAT features, relative to atherosclerotic plaque burden and measures of obesity, for the prediction of future cardiac events in asymptomatic patients in the EISNER registry and the St. Francis Heart Study; 3) To derive and evaluate a new, integrated risk score—combining standard risk factors, coronary calcium score and EAT measures using machine learning—for the prediction of future cardiac events in the EISNER registry, and further, to additionally evaluate this risk score externally in the St. Francis Heart Study patient cohort.  This work in this proposal will provide a novel, personalized paradigm that will objectively and accurately identify asymptomatic patients undergoing coronary calcium scanning who are at increased risk for future cardiac events, without any additional imaging or risk to the patient. PROJECT NARRATIVE (lay language) CT scanning of the heart for coronary calcium scoring is a simple, widely-used, low-cost test with low radiation dose. Using these scans, the researchers propose to establish automated analysis of fat which surrounds the heart, as well as novel computerized scores that identify the patients who are at highest risk of suffering a heart attack. This new research will allow doctors to better identify patients for whom appropriate treatment could be prescribed, to avoid a heart attack or sudden cardiac death.",
Machine Learning for Improved Mammography Screening,"Machine Learning for Improved Mammography Screening    DESCRIPTION (provided by applicant):  Accurate breast cancer screening demands that radiologists maintain a balance of high sensitivity and high specificity when interpreting mammography. Subspecialty-trained breast imagers perform significantly better than general radiologists by recognizing more breast cancers and minimizing benign biopsies. An automated reasoning system called a Bayesian network (BN), has the potential to improve the performance of general radiologists, who interpret the majority of mammograms, to the level of subspecialty-trained breast radiologists, who are in short supply. A BN is a probabilistic graphical model that has been used for decision support in a variety of domains, including radiology. Machine learning provides an appealing way to create and optimize BNs to perform at high levels of sensitivity and specificity. Our research group has developed a prototype, expert-defined BN that uses imaging features and demographic risk factors to classify abnormalities on mammograms as benign or malignant. Our BN can perform at a higher level than general radiologists, but our goal is for it to perform as well or better than subspecialty-trained breast radiologists. To this end, we have compiled a structured, multi-relational dataset of mammography abnormalities and pathologic outcomes from which cutting edge machine learning techniques can construct an improved BN. In the past, BNs were trained and tested on individual abnormalities in isolation. In fact, other abnormalities on the same mammogram or previous mammograms, which necessarily appear in other rows of a relational database, can further improve BN learning. We have used basic statistical relational learning (SRL) techniques to enhance Bayesian learning algorithms to leverage this important additional data. A novel SRL capability introduced by our team within the last year, called view learning, makes it possible to incorporate this related data from other parts of the database by automatically defining new database fields. In our preliminary work, we have shown a stepwise improvement in BN performance: first, with conventional BN learning; then, with basic SRL; and finally, with view learning. We now seek support to determine whether more tightly integrated SRL and view learning will significantly improve our BN's ability to accurately diagnose breast cancer. In addition, we propose to investigate whether two other promising machine learning techniques, predicate-invention and collective-classification, can optimize the BN to perform at levels significantly better than current clinical practice.           n/a",
Developing Classification Criteria for the Uveitides,"Developing Classification Criteria for the Uveitides ﻿    DESCRIPTION (provided by applicant): The uveitides are a collection of ~30 distinct diseases characterized by intraocular infection. Each disease has its own features, course, treatment, and prognosis. Traditionally, the uveitides have been grouped by the primary anatomic site of inflammation as anterior uveitis, intermediate uveitis, posterior uveitis, and panuveitis. However, there are substantial limitations to this ""lumping"" of diseases. For example, among the posterior uveitides, some (e.g. toxoplasmic retinitis and cytomegalovirus retinitis) are infectious and require treatment with antimicrobial/antiviral agents, some are chronic, presumed immune-mediated diseases that require immunosuppression (e.g. birdshot chorioretinitis, multifocal choroiditis, serpiginous choroiditis), and a few are self-limited, spontaneously-remitting diseases with a good prognosis (e.g. acute posterior multifocal placoid pigment epitheliopathy and multiple evanescent white dot syndrome). As such precise diagnosis is critical for research, including epidemiology, translational pathogenesis research, outcomes research, and disease specific clinical trials. Classification criteria are a type of ""diagnostic"" criteria used for reserch purposes. Although classification criteria seek to optimize sensitivity and specificity, when a trade-off is required, they emphasize specificity in order to ensure that a homogeneous group of patients is being studied. A precise phenotype is required particularly for genomic risk factor studies of complex disorders and translational pathogenesis research, as inclusion of other diseases with different risk factors and disease mechanisms would confound the results. Currently there are no widely-accepted and validated classification criteria for any of the uveitides. Preliminary data indicate ""fair to moderate"" agreement at best on the independent diagnosis of any one case by uveitis experts (κ's 0.27-0.40), but the ability of committees to reach agreement on the diagnosis of >98% of cases. The goal of the ""Developing Classification Criteria for the Uveitides"" project is for the Standardization of Uveitis Nomenclature (SUN) Working Group to develop classification criteria for the 25 leading uveitides using a formal, rigorous approach. There are 4 phases to the project: 1) informatics, to develop a standardized terminology; 2) case collection, to develop a preliminary database of ~250 cases of each disease; 3) case selection, to select at least 150-200 cases of each disease that are generally accepted to be the disease (using formal consensus techniques) from the preliminary database into a final database; and 4) data analysis, using machine learning approaches, of the final database to develop a parsimonious set of criteria for each disease that minimizes misclassification. The informatics and case collection phases of the Project are complete. The case selection phase is well underway and uses online voting and consensus conference calls to achieve supermajority acceptance on all cases included in the final database. The goals of this application are to complete case selection and data analysis and develop classification criteria for the 25 of the major uveitides. These results are crucial to future clinical research i the field of uveitis. PUBLIC HEALTH RELEVANCE:  Collectively, the uveitides are the 5th leading cause of blindness in the U.S., and the cost of treating them is estimated to be similar to that of treating diabetic retinopathy. Because uveitis occurs in all age groups, including children and working-age adults, there is a greater potential for years of vision lost than with age- related diseases. Clinical research in the field of uveitis has been hampered by diagnostic imprecision and a lack of widely-accepted and validated classification criteria, the development of which is the goal of this application; these criteria are needed urgently to advance epidemiology, genomic research, translational pathogenesis research, outcomes research, and disease-specific clinical trials.",
STAR Caregivers - Virtual Training and Follow-up,"STAR Caregivers - Virtual Training and Follow-up ABSTRACT Alzheimer's Disease and related Dementias (ADRD) are debilitating conditions affecting more than 5 million Americans in 2014. It is projected that 8.4 million people with be diagnosed with ADRD over the next 15 years and health care costs attributable to ADRD are projected to be more than $1.2 trillion by 2050. Behavioral and Psychological Symptoms of Dementia (BPSD) are common and often involve aggressive behavior towards family caregivers (CG) in response to unmet needs, discomfort, or frustration. BPSD frequently lead to CG seeking medication to control patient symptoms. Antipsychotic use in persons with dementia (PWD) more than doubles mortality risk. The Choosing Wisely Guidelines from the American Psychiatric Association and American Geriatrics Society both recommend against prescribing antipsychotics as a first-line treatment for BPSD. Behavioral interventions such as STAR-Caregivers are efficacious first-line treatments for managing BPSD endorsed by the Administration on Aging. However, the programs have not been implemented widely – partly due to the intensity/cost of the programs and difficulty conducting outreach. No study has investigated CG willingness to reduce or discontinue antipsychotic use. We propose a Stage III clinical trial to ascertain the feasibility and acceptability of STAR Virtual Training and Follow-up (STAR- VTF) in which (a) training materials are delivered electronically and learning is self-directed, (b) caregivers have two in-home visits with a social worker and (c) where caregivers receive support from a social worker via secure messaging (email) within a web-based portal. We will compare outcomes in the STAR-VTF group to an attention control group (mailed material plus generic secure messages). Our specific aims are: (1) Assess the feasibility and acceptability of STAR-VTF to caregivers; (2) Assess the feasibility and acceptability of the program from the payer perspective; and (3) Test the hypotheses that (H1) caregiver participants in STAR-VTF will have lower levels of caregiver burden at 8 weeks and 6 months compared to an attention control group; and (H2) PWD participants in STAR-VTF will have lower rates of daily antipsychotic medication use at 6 months compared to attention control. We propose to recruit 100 CG-PWD dyads (50 in each arm). This will be the first study to test a low intensity, self-directed caregiver training program with secure message support from social workers. It will also be the first study to measure changes in antipsychotic medication use by PWD after CG training. The study is also innovative because it brings together leading experts in caregiver training, health information management, and care management. Third, this will be the first study to use automated data and natural language processing to identify potential caregivers in need of education/support at a time when antipsychotic medication use begins. Results of this study will inform a future multi-site trial in the Mental Health Research Network. NARRATIVE Our study evaluates the effectiveness of a caregiver outreach, training, and support program for caregivers of people with dementia who are using antipsychotic medication to manage agitation/aggression. We will conduct a randomized trial of the caregiver program compared to a control group to measure differences in caregiver burden and discontinuation of antipsychotic medication use. The results will help in expanding access to and delivery of empirically supported behavioral health services for caregivers and people with dementia.",
Role of the Hippocampal-mPFC Pathway in Social Memory Deficits in Autism,"Role of the Hippocampal-mPFC Pathway in Social Memory Deficits in Autism PROJECT SUMMARY / ABSTRACT The hippocampus is critical for the formation and consolidation of spatial memories and contributes to other cognitive tasks through its efferent projections. The goal of this project is to determine whether altered neuronal network activity in the hippocampus of an autism mouse model propagates to, and alters distal cortical regions involved in social behaviors.  One of the core symptoms of autism spectrum disorders, such as Rett syndrome (RTT), is a deficit in social interaction. In mice, similar social behavior impairments can be modeled by altering the excitation and inhibition (E/I) balance in the medial prefrontal cortex (mPFC). For RTT, knocking out the gene that is mutated in humans, Mecp2, causes hyperactivity in the ventral hippocampus (vHIP) due to an E/I imbalance driven by impaired inhibition and enhanced excitation, resulting in saturated synaptic plasticity at excitatory synapses. Intriguingly, CA1 pyramidal neurons of the vHIP project their axons to the mPFC, making direct monosynaptic connections with excitatory pyramidal neurons and inhibitory interneurons. We propose to characterize how the vHIP influences mPFC activity through this long-range monosynaptic glutamatergic projection. Importantly, we will test whether altered vHIP network activity is causal to mPFC dysfunction and deficits in social interaction. We hypothesize that atypically strong vHIP afferents alter network activity in the mPFC of Mecp2 KO mice by affecting the E/I balance and synaptic plasticity, which in turn contributes to social interaction deficits. To test this hypothesis, we will identify the cellular targets of direct vHIP afferents in the mPFC of RTT mice and characterize their function in social behaviors using a combination of optogenetics, chemogenetics, ex vivo and in vivo electrophysiology and Ca2+ imaging, anterograde and retrograde tract tracing, and unbiased machine-learning behavioral assessments.  We propose the following Specific Aims: 1) identify and characterize the cellular targets of the monosynaptic projection from the vHIP to the mPFC in Mecp2 KO mice; 2) characterize long-term synaptic plasticity of the vHIP-mPFC projection in Mecp2 KO mice; and 3) determine if chemogenetic modulation of the activity of mPFC-projecting vHIP neurons alters mPFC function and social behaviors.  These studies will provide fundamental information on the functional and structural properties of the long- range connection between the vHIP and mPFC in the developing brain. The impact of this work extends beyond RTT to other neuropsychiatric disorders in which propagation of network dysfunction from the hippocampus to the mPFC is believed to contribute to cognitive deficits. PROJECT NARRATIVE Rett syndrome is a syndromic autism-spectrum disorder that presents with deficits in social behaviors and cognitive abilities, which may result from impaired function of the prefrontal cortex and hippocampus. The proposed study is the first characterization of a long-range monosynaptic connection in Rett mice using optogenetics and chemogenetics, and will test whether hippocampal hyperactivity propagates to the medial prefrontal cortex, leading to autism-related social deficits.",
Enhancing and extending the reach of suicide surveillance in tribal communities,"Enhancing and extending the reach of suicide surveillance in tribal communities PROJECT SUMMARY The parent grant “Southwest Hub for American Indian Youth Suicide Prevention Research” (U19 MH113136-01) aims to develop and test culturally appropriate prevention strategies, conduct outreach and dissemination within and across tribal communities, and enable key stakeholders to make science-based policy and related decisions. The overall goal is to leverage a collaborative network of tribal leaders, investigators, interventionalists, service providers and service users in the Southwest region to reduce suicide in American Indian youth ages 10-24. An administrative supplement is requested in order to build on our existing data collection platform to be more scalable and efficient when used across tribal settings. In collaboration with colleagues at the Vanderbilt University School of Medicine, we will set up the data collection platform to incorporate additional sites and capitalize on preliminary machine learning work to create easily interpretable risk flags that can help case-managers prioritize cases to reach and connect to care. This work will contribute to a better understanding of how to scale community based m-health platforms for use across diverse settings and how to operationalize and implement machine learning algorithms to help improve care. PROJECT NARRATIVE By strengthening the existing m-health suicide surveillance and case-management platform in the parent grant, these supplementary activities will pave the way for scale-up and enhancement of the system with novel risk detection methods across tribal settings. This supplement will provide valuable knowledge about how to extend the reach of real-world data collection system and services, including the ability to incorporate computational modeling and data analytics in existing workflows, research that is directly in line with key research priorities (4.1.A) for NIMH’s strategic objective 4.",
Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome,"Automated Speech Analysis: A Marker of Drug Intoxication & Treatment Outcome ﻿    DESCRIPTION (provided by applicant): A major limitation of existing assessments of clinically-relevant mental states related to drug use, abuse, and treatment is that self-report measures rely on the capacity and motivation to accurately report one's internal experiences. A potential alternative is presented by emerging computer-based natural language processing methods that can extract fine-grained semantic, structural, and syntactic features from free speech1, potentially providing a unique 'window into the mind.' These methods are widely used in industry2, yet remain largely unknown in clinical research. To begin to assess the potential of these advanced analytic methods in clinical research, we recently partnered with IBM computer science researchers to test computer-based analysis of speech semantic structure. In preliminary work, we were able to demonstrate that such methods could detect acute drug intoxication3 and accurately predicted the development of psychosis in clinical risk states4. Here, we propose to build on these highly promising initial findings, conducting three secondary data analyses to rapidly and cost-effectively advance this novel direction. Projects 1 and 2 will extend our preliminary work on speech markers of mental state changes during acute drug intoxication. In Project 1, we will assess speech semantic, structural, and syntactic features as markers of mental state changes due to MDMA (0, 0.75, 1.5 mg/kg; oral). In Project 2, we will extend these findings to another drug, assessing speech markers of intoxication with LSD (0, 70 μg; intravenous). These projects are possible because we have access to existing transcripts of free speech from within-subject, controlled laboratory studies of the effects of MDMA (N = 77) and LSD (N = 19). Potential future uses for these methods could include rapid characterization of the effects of emerging drugs and, potentially, detection of acute drug intoxication in the absence of biochemical confirmation. Project 3 will assess the use of speech analysis as a prognostic marker in substance abuse treatment. Specifically, we will use speech transcripts (N = 50) from a currently ongoing study to assess whether features extracted from baseline free speech can predict treatment outcome in cocaine users undergoing 12 weeks of CBT relapse prevention. Self-report5,6 and manual coding of speech7-9 suggest that motivation to change may be a predictor of treatment outcome for substance use disorders: we expect that the fine-grained computational methods we will employ will allow the development of more accurate predictive models. The capacity to use automated methods to detect mental states from free speech has wide ranging, potentially transformative implications for addiction medicine and psychiatry more broadly4,10. Results of the proposed secondary analyses projects will efficiently advance understanding of how automated speech analysis, a non-invasive and cost- effective assessment method, could be used in clinical practice and research about drug abuse. More broadly, results may contribute to the empirical basis for the development of automated, objective, speech- based diagnostic and prognostic tests in psychiatry.         PUBLIC HEALTH RELEVANCE: Free speech, a unique `window into the mind', represents a rich source of information that can be mined for clinically-relevant information. This application proposes to apply novel computer science speech analysis methods in three secondary data analysis projects to investigate 1) speech markers of mental states during acute drug intoxication; and 2) speech as a prognostic marker in cognitive behavioral treatment for drug abuse. Results will rapidly and cost-effectively advance understanding of how automated speech analysis could be used in clinical practice and research about drug use, abuse, and treatment.            ",
Thought disorder and social cognition in clinical risk states for schizophrenia,"Thought disorder and social cognition in clinical risk states for schizophrenia Project Summary  In an effort to intervene before psychosis onset and prevent morbidity, a major recent focus in schizophrenia research has been the identification of young people during a putative prodromal period, so as to develop safe and effective interventions to modify disease course. Over the past decade, studies at Columbia and elsewhere have evaluated clinical high-risk (CHR) individuals across a wide range of cognitive processes to try to identify core deficits of schizophrenia evident before psychosis onset. Subthreshold thought disorder and impaired emotion recognition have emerged as profound deficits that predate, rather than follow, psychosis onset and thus may be indicators of schizophrenia liability, consistent with studies in other risk cohorts, including genetic high risk. Further, subthreshold thought disorder and emotion recognition deficit are significantly correlated, suggesting shared neural substrates in temporoparietal regions.  This study aims to identify the neural mechanisms that underlie subthreshold thought disorder and emotion recognition deficit in 125 CHR individuals followed prospectively for psychosis outcome. CHR cohorts are enriched with early cases of schizophrenia, as 20-25% develop schizophrenia and related psychotic disorders within 1-2 years. CHR cohorts may be optimal for studying core characteristics of illness as they otherwise have low-level symptoms, less illness chronicity and minimum exposure to antipsychotics. 25 individuals with schizophrenia and 50 healthy volunteers are included for comparison.  Subthreshold thought disorder and emotion recognition deficits will be studied across behavioral, physiological and circuit levels. For thought disorder, we will use automated speech analysis approaches developed in collaboration with IBM to identify constituent impairments in semantics and syntax, and a listening task that elicits reliable activation in language circuits. Our automated machine-learning approach to speech analysis, informed by artificial intelligence, derives the semantic meaning of words and phrases by drawing on a large corpus of text, similar to how humans assign meaning to what they read or hear. Emotion recognition will be measured using standard tasks, naturalistic tasks with dynamic face stimuli and parametric face morph tasks that discriminate between perception and appraisal; task-related BOLD activity will be used to identify relevant circuits. Associations with basic sensory impairment will be tested, including novel auditory mismatch negativity paradigms. Resting state functional connectivity (RSFC) methods will be used for circuit-level analysis of language production and emotion recognition across stages of illness, to determine unique and shared substrates of these constructs in early schizophrenia. If successful, this proposal will identify neural targets for remediation of cognitive impairments. Project Narrative Schizophrenia is an important public health concern. Core characteristics of schizophrenia that predate psychosis onset include subtle thought disorder and profound deficits in recognizing emotions in others' faces and voices. This proposal will evaluate mechanisms underlying these language and social cognitive deficits through the use of neuroimaging, electrophysiology and automated speech analysis, in order to develop new preventive strategies for schizophrenia.  ",
Automated Quantitation of 3D Echocardiograms,"Automated Quantitation of 3D Echocardiograms In Phase I we developed a method for automated border detection (ABD) of echocardiographic scans that is feasible for clinical application. The accuracy of our processes provides exceeds Phase I goals and is comparable to interobserver variability in measuring volume and ejection fraction, and in border location. For a diverse set of patients, we have achieved an accuracy of 10 ml for endocardial volume, 4% for ejection fraction, and ,2.0 mm for border position. Our processes operates in 4 min. In Phase II we propose to continue research and development to move our ABD technology closer to clinical user. Our first specific aim is to reduce the amount of manual input required even further. Our second aim is to develop a prototype system suitable for clinical evaluation. Our third aim is to perform a pilot trial to evaluate the performance of our ABD process, as a preparation for a more formal, multi-center clinical trial planned for Phase III. The proposed research is important because quantitative 3D echo provides greater accuracy and reproducibility and more comprehensive information on cardiac status than currently available imaging techniques. The significant advantages of 3D echo are not currently available for clinical practice because it is impractical without automation. PROPOSED COMMERCIAL APPLICATIONS: Automation of echocardiogram border detection enables physicians to obtain accurate, reproducible and comprehensive measurements of the heart's size, shape and function. This technology can be included in ultrasound systems or provided in workstations. The core technology can be applied to other organs and other imaging modalities. n/a",
Neural signatures of outcome in preschoolers with autism,"Neural signatures of outcome in preschoolers with autism Objective. This proposal has the important goal of furthering our understanding of the longitudinal course of autism spectrum disorder (ASD). It is motivated by the urgent need for early prognostic markers able to explain the extensive heterogeneity of ASD outcomes. To this end, we propose a longitudinal study of young children with ASD (2-3 years) to identify the neurobiological underpinnings of early developmental changes in restricted repetitive behavior/interests (RRB) – one of the most clinically impairing aspects of ASD - and their predictive contribution to later function. The proposal builds on the confluence of related findings and our own work including: 1) clinical evidence that RRB changes over the age window between ~29 and 42 months are prognostic markers of ASD adult functioning; and 2) advances in brain developmental functional connectomics that allow investigations of neural circuits in preschoolers with ASD using natural sleep MRI. We specifically aim to test 1) whether changes from 24-36 to 36-48 months-of-age (T1, T2) in the intrinsic functional connectivity (iFC) of somatomotor (SM) striatal-cortical circuitry are associated with changes in the repetitive sensory motor (RSM) subdomain of RRB; and 2) whether these early brain-behavioral changes predict later (age: 48-60 months, T3) adaptive functioning. Exploratory aims will examine the potential contributions of structural connectivity changes in striatal-cortical tracts, and test whole-brain iFC employing unbiased connectome-wide association. Finally, we will explore the value of an alternative, data-driven hierarchical clustering approach to characterizing outcomes based upon multiple clinical dimensions at T3. Methods. We anticipate obtaining complete T1 and T2 brain-behavioral data from 100 preschoolers with ASD enrolled at age 24-36 months and followed prospectively on a yearly basis. At T1 and T2, preschoolers will undergo natural sleep imaging with state-of-the-art MRI (high resolution T1- and T2-weighted structural MRI, multiband resting state fMRI (R- fMRI), and when possible, diffusion tensor) and phenotypic assessments rigorously selected to deeply phenotype a range of ASD core and associated symptoms. To examine the predictive value of iFC and RSM changes (i.e., T1-T2) to later function, children will be re-evaluated at 48-60 months (T3). A partial list of assessments includes: Autism Diagnostic Observation Schedule-2, Behavioral Observation Social Communication Checklist, Repetitive Behavior Scale-Revised, clinician and parent measures of comorbid psychopathology and adaptive functioning. Brain-behavior analyses will primarily rely on R-fMRI, and explore diffusion tensor imaging. Significance. Findings will elucidate the neural correlates of changes in RSM at the earliest practical time following clinical diagnosis. They will provide a developmentally informed understanding of the neural underpinnings of outcomes, thus bringing the field closer to a neural stratification of individuals. Such knowledge is essential for developing neuroscientifically-informed treatments. Impact is maximized by sharing de-identified data with the NDAR and ABIDE yearly to accelerate scientific progress.  NARRATIVE This proposal aims to provide means to address an important question that follows the diagnosis of autism; “what is the prognosis?” To begin to answer this question, we propose to use advanced brain imaging and clinical methods to identify the circuits responsible for early changes in restricted repetitive behaviors and their role in predicting later clinical outcomes. If we are correct, our results would support the development and improvement of new treatments.  ",
ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis,"ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis PROJECT SUMMARY Cognitive impairment, physical disability and progressive disease are common but understudied clinical outcomes that substantially impact employment and overall quality of life for individuals with multiple sclerosis (MS). We have recently developed and validated an assisted, web-based tool (ICLIC-MS) for systematic and longitudinal clinical outcomes data collection of MS-validated cognitive function measures, physical disability and progressive disease measures that are not reliably captured in the electronic health record (EHR). In response to FOA# PA-17-010, Use of Technology to Enhance Patient Outcomes and Prevent Illness, our team proposes the study of MS outcomes in a large, multi-ethnic population representative sample of more than 3,000 female and male MS cases from the Kaiser Permanente Northern California Health Plan Membership. We will integrate other EHR data such as important comorbid conditions, use of disease modifying therapy, MRI reports, as well as quality of life measures and employment histories. Our goals include: 1) comprehensively characterizing clinical outcomes in a large MS patient cohort; 2) developing and utilizing an integrated MS health report to enhance patient care; and 3) establishing a resource for clinical outcomes research in MS that also includes whole genomic and environmental exposure data. Findings from our proposed study represent an extraordinary opportunity to facilitate effective long-term management of MS, accelerate progress in the understanding of disease pathogenesis, predict patient trajectories and inform prevention strategies. We have assembled a team with strong expertise in clinical neurology/MS neurology, advanced epidemiologic methods, EHR structure and clinical care within a health maintenance organization, human genomics, biostatistics, and big data approaches. PROJECT NARRATIVE Our team has developed and validated an assisted web-based interface for longitudinal clinical data collection of cognitive function measures, physical disability and depression measures that are not reliably captured in the electronic health record (EHR) of multiple sclerosis (MS) patients. We will integrate several sources of patient data including genomic, clinical and EHR for 3,000 individuals to facilitate research and improve clinical care.",
Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",
Computational characterization of language use in autism spectrum disorder,"Computational characterization of language use in autism spectrum disorder    DESCRIPTION (provided by applicant): Atypical or impaired language is one of the core features of autism spectrum disorder (ASD). Yet, what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown. An important obstacle for the study of language in any disorder is that conventional structured instruments (i.e., instruments consisting of a sequence of items, each eliciting a - typically brief - response, such as the Clinical Evaluation of Language Fundamentals [CELF]) may not provide adequate breadth of information: Analysis of natural language samples is required  The proposed research will build on recent progress in ""Natural Language Processing"" (NLP) technology, an area of Computer Science concerned with computational analysis of text. The goal of the proposed research is to develop and validate new NLP based methods that automatically measure language characteristics of ASD based on raw (i.e., not coded) transcripts of natural language samples. The objective is to improve the analysis of natural language samples by enhancing efficiency, reliability, and richness of information extracted.  Data on three groups of children ages four to eight will be analyzed, obtained from an earlier study: ASD, SLI, and typically developing children.  If successful, the new methods will have important impacts on research and clinical practice for ASD and for other disorders in which language is affected, by enabling analysis of more representative and ecologically valid natural language samples as well as by creating opportunities for discovery of currently unknown language characteristics of ASD by the effortless extraction of numerous language features.        Although atypical or impaired language is one of the core features of autism spectrum disorder (ASD), what the precise characteristics of language are in ASD and how they differ from those in other disorders such as Specific Language Impairment (SLI) is still substantially unknown, in part due to the paucity of instruments for the analysis of natural language samples.  The goal of this project is to develop and apply Natural Language Processing technologies to automatically extract ASD-specific language characteristics from uncoded, ""raw"" transcripts of natural language samples.            ",
Developing and Evaluating In-Home Supportive Technology for Dementia Caregivers,"Developing and Evaluating In-Home Supportive Technology for Dementia Caregivers Abstract  Caring for a loved one with Alzheimer’s disease, frontotemporal dementia, or another neurodegenerative disease is a highly meaningful part of family life. However, the associated burden and strain can have adverse effects on caregivers including mental and physical health problems, reduced well-being, and increased mortality. These effects, in turn, can compromise care quality and shorten survival times for people with dementia (PWD). Research has consistently found that behavioral symptoms in PWD are most strongly associated with adverse caregiver effects, even more so than cognitive and functional symptoms. Empirically- supported interventions are needed that: (a) target mechanisms/pathways shown to connect behavioral symptoms in PWD with adverse effects in caregivers, and (b) can be disseminated successfully into larger community settings. In this SBIR Fast Track application, we will develop, refine, and evaluate People Power Caregiver (PPCg), a flexible and expandable hardware/software system designed to integrate in-home sensors and devices, emergency responding, social networking, and Internet-of-Things (i.e., devices that can be controlled and communicated with via the internet) technologies to create a more supportive and safe home environment for caregivers and PWD. PPCg monitors troublesome behaviors in PWD (e.g., wandering), and targets mechanisms (e.g., worry, social isolation) thought to link behavioral symptoms in PWD with adverse caregiver outcomes. PPCg is also designed to minimize demands on caregivers’ limited time and energy and to provide a platform for data collection that can be used by researchers and care professionals.  This application is an innovative partnership between People Power (CEO: Gene Wang, www.peoplepowerco.com) in Redwood City, California and the Berkeley Psychophysiology Laboratory (Director: Robert W. Levenson) at the University of California, Berkeley. People Power is an award-winning, established leader in home monitoring and Internet-of-Things technology and has recently started developing assistive technologies for the elderly. The Berkeley Psychophysiology Laboratory has been engaged in basic and applied research with PWD and other neurodegenerative diseases and their caregivers for the past 15 years. The proposal addresses three specific aims: Aim 1: Focus groups. In Phase I of the project, a preliminary version of PPCg will be developed and refined with input from focus groups of caregivers and in- home testing (Study 1). Aim 2: Efficacy. In the first year of Phase II of the project, the first production version of PPCg will be installed by the research team in 80 homes and evaluated in a randomized controlled efficacy trial that includes careful diagnosis and assessment of emotional functioning in PWD and caregivers (Study 2). Aim 3: Effectiveness. In the second year of Phase II of the project, working with energy industry partners, a refined and expanded second production version of PPCg will be provided to 400 homes with familial caregivers for self-installation and evaluation in a community-based effectiveness trial (Study 3). Relevance  Dementias cause profound cognitive, emotional, and functional deficits. As the disease progresses, people with dementia become increasingly dependent on caregivers, who are at heightened risk for mental and physical health problems. Applying assistive technology to monitor worrisome behaviors, improve safety, and reduce social isolation in the home environment can reduce caregiver burden and improve care in ways that have major public health benefits.",
Analysis of force developed by a AAA ATPase,"Analysis of force developed by a AAA ATPase    DESCRIPTION (provided by applicant):  The AAA ATPases family includes molecules whose roles include, but are far from limited to, biogenesis of mitochondria and multivesicular bodies, proteins in involved in gene regulation and protein transport. This project will focus on studying the activity of these machines at the single molecule level. The model protein will be ClpX - it is the part of the proteosome, a key effect of protein degradation that unfolds the proteins to prepare them for degradation. . Cellular proteins differ widely in their liability, from half-lives of minutes to days. Regulated degradation, by allowing rapid changes in the levels of cellular proteins, helps control signal transduction pathways, the cell- cycle, transcription, apoptosis, antigen processing, biological clock control, differentiation and surface receptor desensitization. The questions to be addressed are: How is work partitioned between alternative outcomes? What is the maximum work that can be performed by the system? What factors limit its efficiency in performing work? These questions have health implications: human pathological conditions are associated with failures of the degradation system and its regulation offers the potential for therapeutic intervention. Furthermore, an inhibitor of proteasome catalytic activity is in use for treatment of recurrent multiple myeloma, and proteasome inhibitors are in clinical trial for treatment of a broad spectrum of human malignancies. Thus, understanding the regulation of the half-life of proteins should provide critical insights into cell physiology and pathology. The mishandling of aberrant proteins incurs penalties throughout biology: the survival of bacteria subjected to stress depends on the effective performance of systems which deal with misfolded and structurally aberrant proteins- to either fold them properly or destroy them. The specific questions to be addressed are: How hard can the device pull to cause unfolding? How many pulls are needed to commit irreversibly? What is the limit of pulling power, and the statistical distribution of pulling power? Answers to these questions will begin to reveal not just what these machines do but the decision tree that describes how outcomes are controlled and when machine capacity may be exceeded. We want to know not just how the machine works, but how its decision tree yields alternative outcomes.      PUBLIC HEALTH RELEVANCE: The AAA ATPases family includes molecules whose roles include, but are far from limited to, biogenesis of mitochondria and multivesicular bodies, proteins in involved in gene regulation and protein transport. The model will be a protein involved in degrading other proteins. Human pathological conditions are associated with failures of the degradation system and its regulation offers the potential for therapeutic intervention. Furthermore, an inhibitor of proteasome catalytic activity is in use for treatment of recurrent multiple myeloma, and proteasome inhibitors are in clinical trial for treatment of a broad spectrum of human malignancies.              The AAA ATPases family includes molecules whose roles include, but are far from limited to, biogenesis of mitochondria and multivesicular bodies, proteins in involved in gene regulation and protein transport. The model will be a protein involved in degrading other proteins. Human pathological conditions are associated with failures of the degradation system and its regulation offers the potential for therapeutic intervention. Furthermore, an inhibitor of proteasome catalytic activity is in use for treatment of recurrent multiple myeloma, and proteasome inhibitors are in clinical trial for treatment of a broad spectrum of human malignancies.            ",
Fall Detection and Prevention for Memory Care through Real-Time Artificial Intelligence Applied to Video,"Fall Detection and Prevention for Memory Care through Real-Time Artificial Intelligence Applied to Video Abstract In the US, Alzheimer’s disease (AD) is the single most expensive disease, the only one in the top six for which the number of deaths is increasing. The greatest costs are hospitalizations, where falls are the largest culprit, and frequent need for assistance with daily life activities. A fall safety system shows the potential to reduce costs and increase quality of care by reducing the likelihood of emergency events (e.g., detecting falls before a fracture occurs, reducing the number of repeat falls). Unfortunately, no fall detection and prevention technology has been developed specifically for the needs of dementia care where individuals (1) fall more frequently and (2) often cannot tell care staff how they fell, leading to increased use of Emergency Medical Services (EMS) when falls are unwitnessed to ensure affected individuals are safe. Our goal is to perform a randomized wait-list control clinical trial (n=460) of SafelyYou Guardian, an online fall detection system with wall-mounted cameras to automatically detect falls for residents with AD and related dementias (ADRD). The automation is based on algorithms that push the frontier of deep learning, a subfield of Artificial Intelligence (AI), with a human-in-the- loop (HIL). SafelyYou Guardian is designed to primarily operate in memory care facilities (defined herein as assisted living and skilled nursing facilities providing ADRD care). Deep learning has already revolutionized several fields: robotics, self-driving cars, social networks in particular. Our approach is anchored in novel algorithms developed at the Berkeley AI Research Lab (BAIR) and extended by SafelyYou for real-time detection of rare events in video. The HIL is operating from a call center, confirms the fall detection alerts provided by our artificial intelligence algorithms, and places a call to the communities, so an intervention can happen within minutes of the fall detection. Subsequently, an Occupational Therapist (OT) working from our office in San Francisco reviews the fall videos with the front-line staff over video conference and using our web portal to make recommendations on how to re-organize the resident space (intervention) to prevent future falls. We leverage our HIL paradigm, in which our deep learning approach identifies and pre-filters falls with high sensitivity followed by a human who confirms the fall with high specificity and calls the communities in case of detected fall. This project leverages past small scale clinical and technical pilots including 87 residents from 11 partner communities, and our experience with paid commitments for 480 residents from three partner networks. Past pilots leading to this NIH Phase II proposal include:  · Pilot 1: Technical proof of concept with healthy subjects (200 acted falls).  · Pilot 2: We demonstrated acceptance of privacy/safety tradeoffs by residents, family and  staff, through the collection of 3 months of video data at WindChime of Marin, our first  partner facility; we identified 4 total hours of fall data. This led to clinical benefits  including an 80% fall reduction through the intervention of OT. · Pilot 3: We demonstrated scalability and acceptance by deploying the system in 11  communities, for 87 residents monitored by our system (offline, no HIL intervention). · Pilot 4: Small scale NIH Phase I clinical trial. We demonstrated the ability to perform real-time fall detection, with real-time intervention of the HIL through our partner company Magellan-Solutions which provides the 24/7 monitoring service for the facilities. We demonstrated that 93% of 89 falls were detected, that time on the ground was reduced by 42%, that the likelihood of EMS use was 50% lower with video available, and the that total facility falls including participants and non-participants decreased by 38%. The trial proposed for this NIH SBIR Phase II will provide clinical evidence that the preliminary trends observed experimentally (pilot 2) and at small scale (pilot 4) are true phenomena. It will use a wait-list control population (230 residents) to be compared to the population monitored with SafelyYou Guardian (230 residents). After crossover, the wait-list population will also benefit from the technology and be compared to itself before crossover. Narrative The goal of this project is to perform a randomized, wait-list controlled trial (n=460) of SafelyYou Guardian, an online fall detection and prevention system for memory care facilities (defined here as skilled nursing and assisted living facilities providing dementia care). The technology applies breakthroughs in artificial intelligence to video data collected from off- the-shelf, wall-mounted cameras to automatically detect falls from video for residents with Alzheimer’s disease and related dementias (ADRD); it enables care staff (1) to know about falls right away without requiring residents wear a device, (2) to use video review to quickly assess need for emergency medical services (EMS) after unwitnessed falls, and (3) to perform accurate incident review with support from a remote occupational therapist (OT) to assess how to reduce the risk of repeat falls. The Phase I project goal of launching this service at small scale was achieved and demonstrated with 11 memory care facilities (1) 93% of 89 falls detected, generating 1 alarm per camera per 15 days, (2) 37% reduction in EMS use through better understanding of risk when residents with dementia were found on the floor, and (3) 38% reduction in falls through reduced risk of repeat falls following OT video review.",
Regulators of Cancer Immunotherapy Response,"Regulators of Cancer Immunotherapy Response PROJECT SUMMARY Despite enormous success in treating several types of cancer, immune checkpoint blocker (ICB) therapy still only shows efficacies in a subset of patients. Identifying novel regulators of immunotherapy response as well as improving the response rate of cancer immunotherapies remain open questions. Recently, we used CRISPR screens in mouse models to investigate T-cell infiltration, proliferation, and killing efficacy, and identified PBAF of the SWI/SNF chromatin remodeling complex as one novel regulator of T-cell mediated cytotoxicity. We also developed a computational model, TIDE, to identify gene signatures of CD8 T-cell dysfunction in immune hot tumors and T-cell exclusion in immune cold tumors. The resulting signatures, computed from tumor profiles in non-immunotherapy setting, show promising results in predicting melanoma and lung cancer patient response to immune checkpoint blockade based on pre-treatment tumor expression profiles. This proposed project aims to improve the TIDE biomarkers, identify novel regulators, and elucidate their mechanisms underlying ICB response. In Aim 1, we will develop machine learning approaches on large collection of clinical tumor transcriptome profiles from non-ICB settings to refine the TIDE predictive biomarker of ICB response, and develop a web server to comprehensively evaluate different ICB response biomarkers in all the available ICB cohorts. In Aim 2, we will conduct in vivo CRISPR screens in mouse syngeneic tumor models to identify cancer-cell intrinsic regulators of ICB response, which can serve as novel targets to improve ICB response. In Aim 3, we will elucidate the mechanism underlying two novel regulators of ICB response and characterize their effects on the tumor immune microenvironment using single-cell RNA-seq, single-cell ATAC- seq, and computational modeling. Our investigative team has combined expertise in computational methodology immunotherapy. immunology and big data mining, functional genomics profiling Our proposed studies, if successfully executed, and translational benefits to cancer immunotherapy. and screening, cancer immunology and could provide new insights into cancer PROJECT NARRATIVE Cancer immunotherapies have emerged over the last decade as highly promising approaches for cancer treatment, although only subsets of patients respond to immunotherapies. We propose to integrate computational modeling with functional genomics techniques to refine the immunotherapy response biomarkers, identify novel regulators of immunotherapy response, and elucidate their underlying mechanisms, with the potential to improve immunotherapy response.",
Functional genetic variations in splicing regulation,"Functional genetic variations in splicing regulation     DESCRIPTION (provided by applicant): Recently, tremendous success has been achieved in constructing a catalog of genetic variants in disease genomes or across population. The next great challenge is to elucidate the potential function of various genetic variants in biological an disease processes. An important type of functional variants consists of those that affect gene expression in cis. Indeed, cis-regulatory variants are involved in a broad range of diseases and they showed a consistently stronger influence on gene expression than trans-acting determinants. Alternative splicing is an essential mechanism via which cis-regulatory changes may occur. Previous studies estimated that 15- 60% of point mutations that result in human genetic diseases disrupt splicing, highlighting the importance of this regulatory step. In addition to the well-known splice site signals, splicing is closely regulated by many exonic or intronic cis elements, associated with trans-acting proteins. Disruption of these cis-regulatory elements can cause aberrant splicing. Yet this crucial regulatory aspect remains largely unexplored. We propose to combine computational, genomic and molecular approaches to study splicing changes due to genetic variations. The specific aims are: (1) To globally identify exons and genes that are under differential splicing regulation by the alternative alleles of genetic variant, via bioinformatic analysis of high-throughput sequencing of transcriptome profiles (RNA-Seq). (2) To identify causal genetic variants in splicing alteration using minigene-based experiments. (3) To develop an integrative model to predict causal genetic variants in splicing alteration, using machine learning approaches, RNA- Seq data and molecular validations. This project will elucidate functional cis-regulatory genetic variants in splicing and provide significant insight ino the involvement of genetic variations in human diseases. In addition, this work will generate valuable bioinformatic tools to make full use of the increasingly available RNA-Seq data in a wide variety of cell types for identification and prediction of disease-related genetic variants.          Aberrant splicing can significantly alter gene expression and contribute to human diseases. The proposed research aims to gain a systematic understanding of the functional roles of genetic variations (e.g., mutations or polymorphisms) in the regulation of splicing. This work will provide mechanistic basis for how genetic variations may contribute to diseases, such that future interventions can target specific splicing events therapeutically.                    ",
Programmable RNA-targeting CRISPR-Cas tools to study RNA biology,"Programmable RNA-targeting CRISPR-Cas tools to study RNA biology Summary Technological advances such as next-generation sequencing and single-cell analysis have opened the flood gates for RNA analysis, revealing that the transcriptome is significantly more complex than previously thought, both with respect to the diversity of RNA transcripts, their temporal expression dynamics, and their cellular location. Moreover, thousands of dysregulated RNAs have been observed in diseases including cancer and neurodegenerative disorders. These observations underscore the dire need for new molecular tools to precisely dissect RNA function in health and disease. The goal of my research program is to harness the unprecedented power of CRISPR-Cas systems to create a versatile range of methods to precisely manipulate virtually any RNA, and to use these tools to explore fundamental knowledge gaps in RNA biology. This proposal specifically focuses on addressing the following knowledge gaps: 1) Despite the technological advances in harnessing RNA-targeting CRISPR-Cas enzymes Cas9 and Cas13 for research and clinical applications, we still do not understand the principles of gRNA selection for efficient and tunable RNA-targeting. This problem precludes the facile development of a number of RNA-targeting applications and underscores the need for a thorough interrogation of gRNA selection. Our goal here is to develop a model to predict highly-active gRNAs for Cas9/Cas13 RNA- targeting in human cells. We will use a combination of high-throughput RNA:protein interactome methods, flow- cytometry based gRNA screens and machine learning to precisely define features of highly active RNA-targeting gRNAs for RNA-binding and knockdown for Cas9 and Cas13. 2) The vast majority of human RNAs are alternatively spliced, and RNA splicing defects are common in cancers and neurological diseases. However, our understanding of the downstream functional effects of splicing in a majority of cases is rudimentary. To address this issue, we will develop a toolbox of robust, multiplexable Cas-based splicing factors to offer an unprecedented opportunity to study the functional consequences of alternative splicing. that can determine in a single step both the identity of proteins bound to a And 3) There is a paucity of methods specific RNA and their location on that RNA. The development of such an approach will enable us to determine the spatial arrangement of proteins on specific RNAs to dissect their dynamic deposition in range of RNA processes such as transcription, 3ʹ-end and micro-RNA processing, and lncRNA function. To address this issue, we propose to develop a genetically encodable Cas-based RNA proximity-labeling strategy to precisely identify proteins that bind in close proximity to a specific RNA sequence. We will then use this approach to identify protein factors involved in regulating microprocessor (Drosha/DGCR8) activity at specific primary micro-RNA loci. These research goals fully align with the NIGMS 5 Year Strategic Plan, through the development of essential research tools to study and RNA function for biomedical research. Project Narrative RNA-targeting CRISPR-Cas proteins offer an unprecedented opportunity to precisely manipulate RNA biology in ways not currently possible. We propose several innovative approaches to address critical knowledge gaps in CRISPR-Cas tool development and chart a path to use these tools to interrogate several fundamental questions in RNA biology. Our approaches will help us define the gRNA design rules for RNA-targeting Cas proteins, and develop robust new RNA-targeting Cas tools to manipulate RNA splicing and dissect protein- RNA interaction networks, and ultimately, the tools developed here will transform the way we study RNA and will broadly impact the fields of molecular and cell biology.",
Analysis of mRNA Polyadenylation across Species and Tissues,"Analysis of mRNA Polyadenylation across Species and Tissues    DESCRIPTION (provided by applicant): mRNA polyadenylation is an essential step for the maturation of almost all eukaryotic mRNAs. Altered polyadenylation activity caused by genetic mutation has been implicated in a growing number of human diseases. Over half of the human genes contain multiple polyadenylation sites [poly(A) sites] supported by cDNA/EST sequences. The polyadenylation pattern in the 3'- most exon defines the 3' UnTranslated Region (UTR), which contains various cis regulatory elements for mRNA metabolism, such as microRNA (miRNA) target sites and AU-rich elements (AUEs). In addition, a large fraction of human genes have polyadenylation events in introns, leading to mRNA variants with different protein coding sequence and indicating dynamic interplay between polyadenylation and splicing. Regulation of gene expression by polyadenylation has been characterized only for a handful of model genes, and its mechanism is poorly understood on the systems level. The long-term goal is to understand the mechanisms by which mRNA polyadenylation regulates gene expression in eukaryotic genomes. There are two specific aims in this project: 1) To accurately predict poly(A) sites across metazoan species using their corresponding cis elements; 2) To quantitatively model poly(A) site usage and selection across human and mouse tissues. We will combine computational and molecular biology techniques to address these issues. The results will improve gene annotation in metazoan species, uncover gene regulation events mediated by alternative polyadenylation, elucidate 3' UTR evolution, shed light on the mechanisms of polyadenylation, and provide valuable tools to examine human mutations and polymorphisms that affect poly(A) sites. NARRATIVE mRNA polyadenylation is an essential step for the maturation of almost all eukaryotic mRNAs. Altered polyadenylation activity caused by genetic mutation has been implicated in a growing number of human diseases. Over half of the human genes contain multiple polyadenylation sites [poly(A) sites] supported by cDNA/EST sequences. The polyadenylation pattern in the 3'- most exon defines the 3' UnTranslated Region (UTR), which contains various cis regulatory elements for mRNA metabolism, such as microRNA (miRNA) target sites and AU-rich elements (AUEs). In addition, a large fraction of human genes have polyadenylation events in introns, leading to mRNA variants with different protein coding sequence and indicating dynamic interplay between polyadenylation and splicing. Regulation of gene expression by polyadenylation has been characterized only for a handful of model genes, and its mechanism is poorly understood on the systems level. The long term goal is to understand the mechanisms by which mRNA polyadenylation regulates gene expression in eukaryotic genomes. There are two specific aims in this project: 1) To accurately predict poly(A) sites across metazoan species using their corresponding cis elements; 2) To quantitatively model poly(A) site usage and selection across human and mouse tissues. We will combine computational and molecular biology techniques to address these issues. The results will improve gene annotation in metazoan species, uncover gene regulation events mediated by alternative polyadenylation, elucidate 3' UTR evolution, shed light on the mechanisms of polyadenylation, and provide valuable tools to examine human mutations and polymorphisms that affect poly(A) sites.          n/a",
Predicting Drug Cardiotoxicity Targets Using iPSC-Derived Cardiomyocytes and Machine Learning,"Predicting Drug Cardiotoxicity Targets Using iPSC-Derived Cardiomyocytes and Machine Learning PROJECT SUMMARY Drug development and approval is a costly process with nearly $2 billion spent for each drug that is approved. One of the most significant contributors to this high cost is the expense of developing drugs that fail to pass clinical trials – only 15% of drugs that begin clinical trials are approved for use on humans. A common reason for not reaching the FDA’s criteria for approval is that the drug is classified as cardiotoxic, which cannot be detected during early stages of drug development. One way that drugs can lead to cardiotoxicity is by altering the electrical activity of ion channels that are responsible for the excitation of the heart tissue that pumps blood to the body. Understanding which ion channels, and the extent to which these ion channels are affected is central to determining the cardiotoxicity of a drug. Early-stage predictions of cardiotoxicity are based on animal studies that are poor models of human heart behavior or single-cell electrophysiological studies that falsely assume underlying pathophysiology based on action potential changes. The recent development of human induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) offers an opportunity to study drug effects on human cells in a preclinical setting. In this study, we hypothesize that fitting a computational iPSC-CM model to voltage-clamp (VC) data acquired before and after drug application provides a means of quantifying unknown drug effects on specific cardiac ion channels. We will address this hypothesis through the following Specific Aims: 1) Use machine learning to design a novel VC protocol that improves the quality of data for hiPSC-CM model fitting. 2) Quantify the change in hiPSC-CM ion channel conductances before and after drug application. We will use machine learning to develop a novel voltage clamp protocol that improves the electrophysiology data acquired from our hiPSC-CMs. The data is optimized to improve predictions of the conductances for all ion channels activated during the cardiac action potential. We can apply this voltage clamp protocol in an in vitro setting before and after drug application, then fit our computational model to each dataset. The change in ion channel conductances, predicted by the model fit, serves as an estimate of the channel-specific effects of the drug. The contributions of this proposal will be significant because it will be the first study to use human cardiac cells to produce quantitative measurements of channel-specific drug targets that may lead to lethal cardiac arrhythmias. PROJECT NARRATIVE Many promising drugs developed to treat a variety of diseases have undesirable effects on the heart, including increased risk of sudden cardiac death. Often, these drugs are not found to have adverse effects until they reach clinical trials, and failure of drugs at this stage of development is very costly. We aim to develop a method that leverages machine learning and human stem cell-derived heart cells to predict drug cardiotoxicity in a pre-clinical setting to substantially reduce the cost of the drug development process.",
Development of assistive self-care robot technologies for people with disabilities,"Development of assistive self-care robot technologies for people with disabilities Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee Overview We propose to develop a design space framework and co-design methodology for the development of assistive self-care robot technologies that are informed by the social model of disability. Our model of assistive robots in the domain of self-care considers an individual's social and environmental context, coping processes and other factors that can affect independent functioning. Our design methods utilize embedded sensing to intelligently respond to these con- siderations. We speciﬁcally focus on assistive feeding tasks, proposing a formalism that enables a robotic system to feed a person with upper-extremity disability. Our guiding principle is that human-level interaction is feasible only if the robot itself relies on human-level semantics. We im- plement this principle by relying on data to learn and develop object-dependent control policies and timing models for acquiring and transferring a bite to a user at a proper time. The system's ob- server detects world states and arbitrator invokes different control policies based on these states. The tangible result will be an intelligent assistive feeding robot whose performance can generalize to different activities, adapt to user preferences, and recover from failures. Objectives and Relevance to NIH A design framework for assistive robots would provide for- malisms that let us address the fundamental challenge of designing robots that are responsive to context of use and support assisted self-care in a variety of social settings. We combine method- ologies from human-robot interaction, cognitive science, machine learning, robotics and haptics with user studies and our formalism to address the following research questions: (Q1) Mechanics of Feeding-Control Policies: How can control policies be designed for dexterous non-prehensile manipu- lation of deformable objects such as food? (Q2) Social Aspects of Feeding-Bite Timing: How should an assistive feeding robot decide the right timing for feeding a user? (Q3) Human-in-the-Loop: How can human-directed feedback be added into the loop for an autonomous assistive feeding system?  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks. This can in turn help them increase their independence and autonomy making eating easier and more enjoyable. While we presently focus on this spe- ciﬁc application, the tools and insights we gain can generalize to the ﬁelds of robotic assistance and human-robot interaction across other activities of daily living and instrumental activities of daily living. Thus, our work is clearly motivated by the intent to improve the quality of health and life of the aging population and is very relevant to the theme of NIH. 1 Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks, potentially increasing their independence and autonomy making eating easier and more enjoyable. The long-term promise of this research is to have robots in society that are able to seamlessly and ﬂuently perform complex manipulation tasks in dynamic human environments in real homes which could impact individuals with other disabilities as well as able-bodied individuals. Through improved access to independent living and customizing to the unique needs and preferences of users, the results of this project can positively impact mil- lions of people worldwide, especially given the vast variability in our target population by being transformational in the scalability of assistive robotics for self-care. 1",
Systems Biology Approach to Redefine Susceptibility Testing and Treatment of MDR Pathogens in the Context of Host Immunity,"Systems Biology Approach to Redefine Susceptibility Testing and Treatment of MDR Pathogens in the Context of Host Immunity   Project Summary    For something as complex and multifaceted as bacterial antibiotic resistance (AR), our drug evaluation  paradigm is strikingly narrow and homogenous: MIC/MBC testing in standardized bacteriologic media. We  have shown that this drug evaluation paradigm is inadequate, even misleading, as changes in the media  conditions of the procedure lead to dramatically different results. A more holistic definition of antibiotic therapy  that centers on understanding antibiotic activity in synergy with host innate immune factors such as cationic  antimicrobial peptides (AMPs), serum and phagocytic cells (e.g. neutrophils) reveals therapeutic options  unrecognized in standard testing. The proposed U01 program represents a groundbreaking approach to use  systems biology approaches and inform more effective antibiotic utilization in the context of host innate  immunity. We propose to: 1) build an iterative systems biology workflow that integrates multiple experimental  and computational approaches to give a comprehensive assessment of AR; and 2) apply this workflow to high  priority pathogens to systematically elucidate AR mechanisms and their condition­dependency. The iterative  workflow includes: (i) omics and physiological data generation.  Clinically isolated strains of the selected  pathogens will be grown under conventional testing (bacteriologic media) and more physiologic conditions  (tissue culture media, serum, and in presence of AMPs and neutrophils) to probe for advantageous gain of  activity.  The omics data types collected are: DNA resequencing, RNAseq, and metabolomics.  (ii)  Bioinformatics and data modeling analysis involves three approaches: big data analysis for data set  dimensionality and coarse grained variable dependencies assessment, genome­scale modeling for  mechanistic elucidation and analysis, and machine learning that uses AR­related metadata to classify the  overall biological functions. This analysis will lead to understanding of AR mechanisms.  (iii) Multi­scale  validation from animal models, to laboratory evolution, to cytology, to gene expression alteration, to structural  protein analysis of putative targets. The validation thus ranges from host behavior to atomistic detail of  ligand­target interactions. The iterative loop then closes, comparing computational prediction to experimental  outcomes. False­negative and false­positive predictions are then algorithmically analyzed by a hypothesis  generating family of algorithms that then makes suggestions about what conditions to use in the next iteration  of the loop.  The pathogens that we will focus on are methicillin­resistant ​Staphylococcus aureus ​(MRSA), the  carbapenem­resistant Enterobacteriaceae (CRE) Klebsiella ​pneumoniae ​and ​Acinetobacter baumannii,​ and  Pseudomonas aeruginosa​. The team of investigators has made the foundational observations and led the  development of the technologies on which the iterative workflow is based. A multi­ and genome­scale methods  of systems biology fulfills requirements of RFA­AI­14­064 to which it responds.              Narrative    The current evaluation of antibiotic drug candidates in drug discovery and in clinical medicine is conducted in  laboratory media that ignores the actual physiologic conditions in the host and the host immune system.  We  have discovered potent antimicrobial activities of existing antibiotics against highly “drug­resistant superbugs”  that are currently ignored but revealed in synergy with the human immune system. This program proposes a  holistic and comprehensive systems biology approach to systematically discover novel treatment opportunities  and underlying mechanisms using a novel iterative data generation, analysis, and modeling workflow.       ",
Mechanistic Characterization of Pain in Temporomandibular Disorders: Does Pain Centralization Influence Responsiveness to Peripherally Targeted Treatments?,"Mechanistic Characterization of Pain in Temporomandibular Disorders: Does Pain Centralization Influence Responsiveness to Peripherally Targeted Treatments? Project Summary / Abstract Temporomandibular disorders (TMD), characterized by persistent pain in the cheek and jaw area of the face, affect approximately 1 in 10 women at some point in their lives. TMD treatments primarily focus on peripheral factors; however, many patients with TMD show no signs of peripheral damage. It is now known that many chronic pain conditions, including TMD, involve pain centralization, meaning the pain is generated and maintained by central, rather than peripheral, nervous system processes. There are currently no well accepted means through which centralized TMD pain can be identified in the clinic, and the failure to properly identify these centralized cases means that ineffective peripheral treatments are administered. The specific aims of this project are to 1) Demonstrate that structural, functional, and neurochemical abnormalities exist in TMD that are similar to those reported in other centralized pain conditions, 2) Utilize questionnaire and quantitative sensory testing measures that can accurately detect centralized pain to place patients on a continuum from peripheral to centralized, and show that the brains of centralized, but not peripheral, patients differ significantly from healthy controls, and 3) Determine the measures of centralization and brain morphology, function, and chemistry that predict lack of improvement from a peripherally targeted treatment regimen, to show that centralized TMD patients do not respond as well to treatments that fail to target their pathology. The primary goal of the mentored (K99) portion of the award is to give the candidate the additional training in neuroimaging necessary for him to obtain a tenure track faculty position and successfully run his own independent research program. The K99 phase will take place at the University of Michigan, under the mentorship of Drs. Daniel Clauw, Richard Harris, and David Williams, who are world-renowned experts in centralized pain conditions, pain neuroimaging, and pain psychometrics, respectively. Dr. William Maixner (Duke University), a world- leading expert on TMD, will also serve as a mentor; he will advise the candidate on the clinically relevant aspects of TMD and help the candidate network with other more established TMD researchers. The University of Michigan is ideal for the K99 phase of the project because of the available resources, including faculty who are committed to clinical pain research and mentoring, research-devoted magnetic resonance imaging (MRI) scanners and state-of-the-art pain testing equipment, and ample laboratory and office space at the Chronic Pain and Fatigue Research Center. Upon completing the K99 portion of the award, the candidate will be well suited to make the transition to tenure-track faculty. Project Narrative TMD, which is the most prevalent orofacial pain condition, is a public health problem that negatively impacts the quality of life and function of numerous individuals. This project addresses large gaps in our knowledge of pain centralization in TMD, building off of what is currently known from other pain conditions. Improvement in our understanding of the etiology of TMD and how it influences treatment will be crucial to bring individualized medicine to TMD patients. As a first step, we will determine what central factors make the prevailing peripheral treatments less effective. The results of this project will inform future studies of TMD by pinpointing the most promising variables to measure in longitudinal treatment studies of TMD.",
QUANTITATIVE IMAGE MODELING FOR BRAIN TUMOR ANALYSIS AND TRACKING,"QUANTITATIVE IMAGE MODELING FOR BRAIN TUMOR ANALYSIS AND TRACKING MRI images have been used for a wide variety of medical applications for a long time because they are safe and highly sensitive at detecting of tissue abnormalities that indicate cancer. MRI is generated by measuring the response of tissue components to a magnetic field. Also, based on the published statistics, brain tumor is one of the most common causes of death and early detection and monitoring is crucial for treatment. Literature and market review suggests that although extensive research exists on brain tumor detection using MRI images, MRI–based systems designed for brain tumor detection that have ultimate clinical value and use are lacking. Accordingly, we propose a new software technology that effectively detect, segment, classify and monitor brain tumor in MRI images. There have been extensive efforts on brain tumor detection in MR images because early detection has been always crucial for success of treatment. For ongoing work in our parent RO1 grant we are developing new machine learning and image analysis methods that for automatic detection and segmentation of brain tumor in MRI images, which is expected to help patients to have a much better chance of successful treatment. If successful, the proposed software technology in this project may potentially be the first that may be commercialized for brain tumor segmentation and classification on MRI images.",
Data Driven Methods for Missing Data Imputation in Surgical Disparities Research,"Data Driven Methods for Missing Data Imputation in Surgical Disparities Research Project Summary/Abstract Disparities in health and health care have been a longstanding challenge in the United States. One specific area of medical care in which racial/ethnic disparities have been identified is total joint arthroplasty (TJA), particularly total knee arthroplasty (TKA) and total hip arthroplasty (THA). Large, population based studies necessary to address healthcare disparities can be costly and difficult to perform, and may be compromised by sampling strategies and patient selection biases. Efficient alternatives are publicly-available nationally representative databases such as the HCUP State Inpatient Databases (SID) and National Inpatient Sample (NIS). The SID provide information on all patients admitted to hospitals within participating states, allowing for comparison of health care access among many vulnerable populations, across states, and over time. The NIS is the largest publicly-available all-payer inpatient health care database in the nation. It is sampled from the SID through a complex survey design, yielding national estimates of health care utilization, quality, and outcomes. A significant limitation of the NIS and the SID is the quantity of missing data. In particular, “patient race”, a key indicator for health disparities research, has a high proportion of missingness. Multiple imputation (MI) approaches have been increasingly popular for providing sound statistical methods to account for missing data. When conducting MI, it is suggested that imputation models be as general as data allow them to be, in order to accommodate a wide range of subsequent analyses of imputed data sets. This requires all relationships that are going to be investigated in any subsequent analysis, such as nonlinearities and interactions, to be included in the imputation model. Unfortunately, traditional MI methods, such as the multivariate imputation by chained equations (MICE), are built on parametric imputation models. These models are often not flexible enough to capture interactions and nonlinearities in high dimensional and large scale data settings. Unlike parametric models, machine learning techniques (MLTs) are model-free methods, and thus provide flexibility for missing data imputation. MLTs use algorithms that automatically and iteratively learn from all data to detect statistical dependencies in observations without being explicitly programmed where to look. The goal of this study is to make the two HCUP databases a more useful resource for the study of surgical disparities and other areas of medicine. Accordingly, we propose novel MI methods based on MLTs to impute missing data in the SID and the NIS, and to use the imputed datasets to measure racial disparity in TKA. Project Narrative It would be challenging to approach the goal of eliminating healthcare disparities without identifying disparities and analyzing the underlying causes using nationally representative databases such as the HCUP SID and NIS. This proposal imputes missing data for surgical disparities research using the two databases.",
"""Mechanisms of Early Bilingual Language Acquisition""","""Mechanisms of Early Bilingual Language Acquisition"" ﻿    DESCRIPTION (provided by applicant): A majority of children worldwide learn more than one language (Grosjean, 2010), yet theories of language acquisition treat monolingualism as the standard learning model. Bilingualism is highly common, but the mechanisms that drive bilingual learning are not yet well understood. In order to develop rich theories of language acquisition, it is necessary to include a full consideration of the demands of bilingual learning environments and how learners cope with these demands.  The proposed research project seeks to fill this theoretical gap by investigating bilingual statistical learning at the very early stages of languag acquisition. Statistical learning entails discovering structure by tracking patterns that are preset in the input. Statistical learning is a popular framework that has received a great deal of attention for its potential to explain how infants and children acquire many dimensions of linguistic structure. Infants are remarkably skilled at tracking regularities. However, the literatre has not yet addressed how bilingualism affects the ability to extract statistical regularities in linguistic input. The demands are substantially greater for bilinguals than for monolinguals. They must track two separate sets of regularities for every aspect of linguistic structure, from sounds to words to grammar. This research will examine two processes that are fundamental for early language acquisition, the ability to detect words in fluent speech and the ability to associate word forms with meanings. The experiments will address how dual language input affects infants' ability to perform these tasks. In addition, both monolingual and bilingual infants will participate, providing a window on how bilingual experience affects infants' tracking of regularities in dual languages. The project will also explore what cognitive processes support bilingual infants' ability to learn effectively in two immensely complex linguistic systems, focusig on how cognitive control and vocabulary composition relate to statistical learning skills in the laboratory.  In addressing a theoretical gap, the proposed research also has substantial significance for public health. This work will reveal mechanisms that infants use to learn and the conditions that support or hinder bilingual learning. These contributions have potential to affect the design and implementation of early bilingual education programs. In addition, this work will elucidate the mechanisms that typically developing infants use to acquire language, which has applied value for the study of language impairments. Understanding the underlying processes of typical development is crucial for understanding the development of populations who are not acquiring language on a typical course. It is important to know how learning typically proceeds in order to identify potential underlying deficits in learning impairments. PUBLIC HEALTH RELEVANCE: A majority of children worldwide are bilingual, yet there is limited understanding of how bilinguals learn. This work addresses a crucial gap in accounts of language acquisition and will inform programs for bilingual education. In addition, the research will support the search for underlying deficits in children with language impairments by characterizing the mechanisms that drive typical development.",
"Mechanisms of Rapid, Flexible Cognitive Control in Human Prefrontal Cortex","Mechanisms of Rapid, Flexible Cognitive Control in Human Prefrontal Cortex Humans have a remarkable ability to flexibly interact with the environment. A compelling demonstration of this cognitive flexibility is our ability to perform complex, yet previously un-practiced tasks successfully on the first attempt. We refer to this ability as `ad hoc self-programming': `ad hoc' because these new behavioral repertoires are cobbled together on the fly, based on immediate demand, and then discarded when no longer necessary; `self-programming' because the brain has to configure itself appropriately based on task demands and some combination of prior experience and/or instruction. This type of learning differs importantly from trial-and-error learning, in which responses are sculpted incrementally, based on feedback from previous attempts. In comparison to trial-and-error learning, much less is known about ad hoc self- programmed learning, but it clearly represents a fundamental feature of human intelligence. The overall goal of our research proposal is to understand the neurophysiological and computational basis for ad hoc self-programmed behavior.  There have been significant barriers to the study of this topic. Among them are the difficulty of studying these processes in animals who require training (which by definition precludes single-trial self- programming), and the lack of access to opportunities with sufficient spatiotemporal resolution to study neuronal processes in humans.  The proposed research seeks to address this gap. We leverage critical advances in neuroscience, neurosurgery, engineering, and computational modelling, including: 1) availability of a large-scale recording platform enabling simultaneous recordings of 100+ neurons from the cortical surface; 2) opportunities to record from dorsolateral prefrontal cortex (dlPFC) in human subjects engaged in a custom-designed behavioral task; 3) developments borrowed from the artificial intelligence community to create advanced neural network models of complex cognitive processes.  By applying these innovative methodologies, we focus on addressing our overall goal with three Specific Aims. In Aim 1, we determine what information about the structure of a novel, complex, instructed task is represented in human dlPFC neuronal activity. We also determine how and when this information is encoded, in terms of spiking activity, oscillatory activity, or coherence between the two. In Aim 2, we determine the relationship between these neuronal representations and behavior. We investigate how the robustness and timing of the emergence of required neural representations relates to response accuracy and reaction time. In Aim 3, we develop a computational model of ad hoc self-programmed learning. To do so, we borrow from recent insights in the AI world regarding prefrontal network structure, and also apply our developing understanding of neural representations from the previous Aims.  We expect that this innovative approach will revolutionize our understanding of this amazing capacity for immediate, configurable learning that characterizes our everyday lives. In doing so, we will develop new strategies to study mechanisms of rapid, flexible cognitive control in general. A better understanding of human cognitive control and its nuanced capacities will naturally translate into an appreciation of deficiencies in these processes, and how they manifest in the form of neuropsychiatric disorders. This appreciation can then lead to the development of rational, targeted therapies. Project Narrative In our everyday lives, we frequently encounter situations that we have never previously faced, but to which we must respond appropriately on the first attempt. The human brain's remarkable ability to rapidly reconfigure its cognitive circuitry to match new task demands and thereby enable such behavior is a fundamental feature of human intelligence. The proposed studies leverage exciting new developments in neuroscience, neurosurgery, engineering, and artificial intelligence to understand the neuronal circuitry underlying this amazing capacity.",
Understanding Action Selection in the Tool Use Network,"Understanding Action Selection in the Tool Use Network Project Summary: Skilled use of tools is a defining achievement of human cognition, and is enabled by the storage of tool-specific action memories. Many tools are associated with more than one action, and most everyday tasks are associated with more than one tool. Limb apraxia is a common, disabling, and puzzling left-hemisphere disorder characterized by prominent deficits in activating and selecting task-appropriate tool actions. Little is known about the cognitive mechanisms and brain regions enabling such selection in the neurologically intact brain, or how these processes go awry in apraxia. In several other cognitive domains, it has been suggested that appropriate response selection occurs via biased competition—that is, the prioritization of competing incoming information to enable appropriate response selection. Capitalizing on the promise of such frameworks, we have developed a new functional-neuroanatomic model of biased competition in a specific left hemisphere Tool Use network. Called “Two Action Systems Plus” (2AS+), the model generates testable hypotheses about the major principles determining tool action selection, and their deficiencies in apraxia. Specifically, we hypothesize that 1) Competition between tool actions is influenced by the graded similarity of tool action representations, as implemented primarily by the left posterior temporal cortex (pTC), 2) The outcome of the competitive process is affected by the strength and timing of activation of tool action representations, and depends on the dynamic interplay of left pTC and the parietal lobes, 3) Outcome is further influenced by a mechanism that biases competition towards the tool action that is appropriate to goals and context, as implemented by the left inferior frontal gyrus (IFG) and its connections with the supramarginal gyrus (SMG), and 4) There are two subtypes of apraxia characterized by distinct failures in the competitive selection process: an anterior subtype characterized by inability to appropriately resolve tool action competition, and a posterior subtype reflecting weakened competition. These hypotheses will be tested using a number of complementary methods with healthy and brain-lesioned participants, including voxel-based lesion symptom mapping, resting functional connectivity, fMRI with multi-voxel pattern analyses, and eyetracking. By specifying when and how visuomotor information plays a role in tool representations, the proposed experiments promise to critically constrain “embodied” cognition theories claiming that tools automatically evoke their actions. The proposed research will also advance the theoretical understanding of tool action by anchoring relevant constructs in a cognitive-neuroanatomic model, clarify how action representations are organized and activated, and improve our understanding of the mechanisms affecting errors and re-learning in apraxia, with implications for rehabilitation. Project Narrative: Apraxia, a disorder of tool use, is a common and substantially disabling consequence of left hemisphere stroke, yet is relatively rarely studied and hence poorly understood. The proposed work will clarify the brain regions that are associated with the disorder, the task factors that may improve tool use abilities, and the ability of the damaged Tool Use system to learn after stroke. This information will serve as an important building block in the development of treatment strategies.",
Deep learning-based image analysis for assessing real-time smoking risk,"Deep learning-based image analysis for assessing real-time smoking risk ABSTRACT Whereas the majority of smokers will quit in any given year, the majority of quit attempts result in relapse. One reason interventions may fail is that they teach smokers strategies for coping with craving in response to environmental triggers, but do not provide smokers with just-in-time information about their risk of smoking lapse. Such risk information could be used to alert smokers to engage in relevant coping strategies including avoidance or use of quick acting pharmacotherapies (e.g. nicotine inhaler). The overarching premise of the proposed research is that prediction of lapse risk can be enhanced by using computer vision to analyze images of everyday life. Recent findings by our team suggest that environments associated with lapse risk can be detected in real-time by coupling deep learning-based object detection with an appropriate classification model. In preliminary research, images taken by smokers of smoking and nonsmoking environments (80 subjects, 2870 images) were used to train such a model, resulting in 77.5% accuracy (0.826 AUC) distinguishing these environments on a separate test set (16 subjects, 516 images). Encouraged by this preliminary finding, we propose to refine and scale up this system by a) creating a larger and more representative image database that includes a sample of everyday environments acquired from smokers (n=60) and b) testing novel, personalized approaches for increasing smoking environment classification accuracy and assessing smoking risk across three aims. In Aim 1, we will improve smoking environment classification accuracy and prediction of smoking risk by re-training an existing deep learning model to recognize a broad set of smoking-related objects (e.g. packs of cigarettes/ashtrays). In Aim 2, we will further improve performance by fitting personalized models that account for individual differences in preferred or typical smoking environments. In Exploratory Aim 3, we will predict craving and negative affect/stress using a similar approach. The proposed research represents an innovative and critical next step in the development of a system that identifies smoking risk and/or its antecedents in real-time to support a just-in-time adaptive intervention for smoking cessation. PUBLIC HEALTH RELEVANCE: The majority of smokers relapse within one month of quitting smoking. Environments (e.g. park) and their related objects (e.g. park bench) are associated with smoking and urges to smoke and can serve as triggers to lapse and relapse. The proposed research will use state-of-the-art computer vision and object detection to identify smoking risk environments and objects with the goal of eventually developing systems that alert smokers to such risks from everyday images acquired with cameras worn by smokers. Such a system can be incorporated into more comprehensive and effective smoking cessation programs.",
Predicting Resilience in the Human Microbiome,"Predicting Resilience in the Human Microbiome     DESCRIPTION (provided by applicant): Humans have co-evolved with complex, dynamic microbial communities that play essential roles in nutrition, metabolism, immunity, and numerous other aspects of human physiology. Hence, maintenance and recovery of key beneficial services by the microbiota in the face of disturbance is fundamental to health. Yet, stability and resilience vary in, and between individuals, and are poorly understood. Our goal is to identify features of the human microbiome that predict microbial community stability and resilience following disturbance. We propose an innovative large-scale clinical study design that will generate the necessary compositional and functional data from the most relevant ecosystem, i.e., humans!  We will develop novel statistical and mathematical methods for data integration (sparse, non-linear multi-table methods), and test existing ecological theories and apply statistical learning strategies to allow data-driven investigation of ecological and clinical properties that determine and predict stability and/or resilience. The breadth and magnitude of this project's impact are significant: We envision tests to predict microbial community responses to disturbance, and procedures to stabilize or restore beneficial microbial interactions as needed. A predictive understanding of the stability and resilience of the gut microbiota will advance the rational practice of medicine. There are three key innovative aspects to our approach: 1) sequential perturbations of different types in a large number of human subjects sampled over time; 2) multiple compositional and functional measurements made on the same samples; and 3) novel data integration methods that incorporate all of the information. Aim 1. Profile the human microbiome before, during and after multiple forms of disturbance. One hundred subjects will each be sampled at 40 time points over a 34 week study period that encompasses two types of perturbation in each subject (dietary shift, and bowel cleansing or antibiotic). From each sample, we will determine taxonomic composition, genomic content, meta-transcriptome, and metabolomic profiles. Aim 2. Discover resilience: Develop non-linear approaches for complex data integration using sparse, multiple-table methods. We will develop a novel sparse, multiple-table approach for data integration and simultaneous analysis of diverse types of complex data over time. Aim 3. Explain resilience: Use statistical learning approaches to find the predictive features that characterize resilience. Using the multiple table approach, we will compare routine unperturbed dynamics within a community to the varied responses to a perturbation, define stable states, and identify common network features characteristic of resilient communities subjected to different forms of disturbance. Finally, we wil use validation techniques to confirm these candidate predictors of community resilience.         PUBLIC HEALTH RELEVANCE: Humans rely on the microbial communities that colonize the gut for a wide variety of critical functions, including nutrition, immune system maturation, protection against infection by disease-causing microbes, and detoxification of environmental chemicals. Daily life is punctuated by events, such as exposure to antibiotics or other chemicals, or changes in diet, that sometimes disturb or destabilize our microbial communities with potentially severe and sustained negative impacts on health. We propose an ambitious study in which we will monitor the microbial communities of healthy humans before, during and after several types of planned disturbance, and discover community features that predict future stability or future recovery from disturbance, with the expectation that our findings will fundamentally change the practice of medicine.                            ",
STRESS MANAGEMENT EXPERT SYSTEM FOR CANCER PREVENTION,"STRESS MANAGEMENT EXPERT SYSTEM FOR CANCER PREVENTION Stage matched interventions for stress management that are interactive and individualized, and are delivered proactively to entire populations can have unprecedented impacts. Computer based expert systems linked to self-help manuals can be as effective as Counselors but at much lower cost and greater accessibility. Stress is an important cause of cancer and other chronic and acute diseases and is one of the most costly behaviors in terms of health care, job performance and disability. Fifty million Americans do not practice effective stress management. Existing programs are action- oriented and are designed for the 30% of populations who are prepared to take action. Stage matched programs can meet the needs of all; the 45% in the Precontemplation stage and the 25% in the Contemplation stage. Phase I of this Fast-Track research will demonstrate the feasibility of recruiting 70% of at-risk populations and the acceptability of the expert system interventions. Phase II will complete recruitment of 1200 participants randomly assigned to treatment or control and can demonstrate efficacy of these interventions over six months. Follow-up over 18 months can show increasing impact long after the intervention. Effective and cost-effective stress management systems can be broadly disseminated with consistent quality and user friendly acceptability. PROPOSED COMMERCIAL APPLICATIONS: Stress is one of the most costly conditions for individuals, employees and health care systems. Fifty million Americans do not practice effective stress management. Effective and cost effective expert systems that can treat stress on a population basis have outstanding commercial impact.  n/a",
Consumer Assessment of Healthcare Providers and Systems V (CAHPS V),"Consumer Assessment of Healthcare Providers and Systems V (CAHPS V) Consumers, providers and health care purchasers need high-quality information to help them compare and evaluate their health care options. The CAHPS V project will advance the AHRQ CAHPS mission of improving patients' experiences with health care by developing and evaluating strategies for survey measurement, reporting and quality improvement (QI). We propose a 5-year effort to advance the science and practice of patient experience assessment, continue innovation to ensure relevance to health service delivery and implement best survey practices, further the science of reporting, and evaluate CAHPS QI efforts. We will develop program communication strategies, and disseminate and promote use of CAHPS products. In particular, we will develop a survey to assess patient experiences with end-of-life care; develop new items to assess shared decision-making, care coordination, patient engagement, and patient safety; test alternatives to the standard CAHPS modes of data collection), explore the feasibility of administering a short-form survey dividing CG-CAHPS composites among respondents to reduce response burden, elicit stakeholder feedback about the value of different CAHPS supplement item sets, evaluate “The Your CAHPS Survey” that was designed to help users of the CAHPS surveys compile a survey tailed to their specific needs, and evaluate existing Spanish translations of CAHPS surveys. In addition, we will gather input from stakeholders on best practices for narrative data analysis, develop an approach for using automated Natural Language Processing for analyses of narratives, and construct an algorithm approach to select representative narratives that reflect and illustrate overall provider ratings. Finally, we will evaluate the contribution of patient narratives to quality improvement efforts in hospital care for children, characterize primary care practices use of the CG-CAHPS survey and patient-centered medical home items during PCMH transformation, assess the impact of pay- for-performance for care delivered by primary and specialty care safety net providers on CAHPS survey responses, explore the value of new shared decision-making, patient engagement, communication and patient safety items for QI and identify QI strategies that improve patient experience across various settings. We will also advance analytic methods for CAHPS data. The project team is well suited to achieving the study objectives given its prior accomplishments and established working relationships. The work is innovative and designed to facilitate the use of CAHPS surveys and improve response rates to them, enhance reporting and use of CAHPS survey data, and improve health care QI efforts. PROJECT NARRATIVE This project will advance public health by developing new CAHPS survey items for end-of-life care, shared decision-making, care coordination, patient engagement, and patient safety, promoting use of CAHPS surveys by implementing and evaluating an interactive database tool designed to assist with the assembly of CAHPS surveys, creating parsimonious variants of CAHPS surveys, evaluating alternative methods of data collection designed to improve response rates, enhancing the collection and use of patient narrative data in reports about health care, and assessing the impact of CAHPS surveys and reports on quality improvement efforts and patient experiences with care.",
Using the Electronic Health Record to Identify and Promote Goals-of-Care Communication for Older Patients with Serious Illness,"Using the Electronic Health Record to Identify and Promote Goals-of-Care Communication for Older Patients with Serious Illness Although discussions that address patients' goals of care are one of the most important aspects of palliative care, this communication is often lacking in our healthcare system. Goals-of-care communication is associated with improved patient and family outcomes and reduced intensity of care at the end of life. Electronic health records (EHR) provide a key opportunity to identify patients who would benefit from these discussions and to promote these discussions, yet prior interventions have not used the EHR for this purpose.  Older adults with chronic illness, and particularly those with Alzheimer's disease and related dementias (ADRD), are especially vulnerable to inappropriately intensive end-of-life care. To address this shortcoming, we build on two of our most successful programs, one using the EHR to identify goals-of-care discussions and the other a novel intervention called Jumpstart that promotes and enhances these discussions. We will examine the effectiveness of the Jumpstart intervention for hospitalized older adults with chronic illness and specifically oversample those with ADRD to understand the effectiveness of the intervention in this key group.  We propose 2 linked, complementary randomized trials. Trial 1, a pragmatic trial, compares usual care with a clinician-facing Jumpstart for hospitalized older adults with serious illness (n=2000). Trial 2, a comparative effectiveness trial, compares this clinician-facing Jumpstart with a bi-directional, patient-specific Jumpstart based on surveys completed by patients or family members (n=400). We hypothesize that the clinician-facing Jumpstart will improve outcomes compared to usual care, and the bi-directional, patient- specific Jumpstart will improve outcomes compared to the clinician-facing Jumpstart. We use an innovative hybrid effectiveness-implementation approach to accomplish 3 aims. Aim 1 evaluates the effectiveness of the clinician-facing Jumpstart, compared with usual care, for improving quality of care; the primary outcome is EHR documentation of a goals-of-care discussion during the hospitalization. Secondary outcomes include intensity of care at the end of life. Aim 2 evaluates the effectiveness of the bi-directional, patient-specific Jumpstart compared to the clinician-facing Jumpstart; the primary outcome is the same as Trial 1. We will examine the same secondary outcomes, but also include patient- and family-reported outcomes assessed by surveys at 1 and 3 months after randomization including occurrence and quality of goals-of-care communication in the hospital, goal-concordant care, psychological symptoms, quality of life, and palliative care needs. We will also examine costs of care after accounting for costs of the interventions. In Aim 3, we conduct a mixed-methods evaluation to explore barriers and facilitators to future implementation and dissemination.  Our team has experience conducting innovative multi-center trials with patient-centered outcomes, economic analyses, and implementation science. This novel hybrid effectiveness-implementation approach addresses key knowledge gaps to improve the quality and value of care for older adults. PROJECT NARRATIVE Communication about goals of care is one of the most important aspects of palliative care for older adults, yet the lack of this communication is a major shortcoming in our healthcare system. We propose 2 linked and innovative randomized trials to evaluate a novel intervention that promotes and enhances goals-of-care discussions for hospitalized patients with serious chronic illness. We hypothesize the intervention will improve outcomes for older patients with chronic illness and their family members and will be effective in the expanding subset of these patients with Alzheimer's disease and related dementias.",
Molecular Mechanisms of Large Oncosome-Induced Prostate Cancer Progression and Metastasis,"Molecular Mechanisms of Large Oncosome-Induced Prostate Cancer Progression and Metastasis Abstract Prostate cancer (PC) is one of the most frequent tumors in men. Despite recent progress, the disease is still incurable once resistance to castration therapy occurs. Tumor progression is strongly mediated by altered molecular exchanges between cancer cells and the surrounding milieu that originate at the primary sites. However, the mechanisms regulating the response of the stroma to the tumor, which ultimately promote PC progression are still largely unknown. Our laboratory discovered a new type of tumor-derived extracellular vesicle (EV), which are referred to as “large oncosomes” (LO), can harbor more abundant molecular cargo that is distinct and more potently bioactive than that carried by exosomes. The rationale for this proposal derives from our preliminary observations in patients that LO abundance in the circulation correlates with PC progression. Our functional data demonstrate that LO can activate oncogenic signaling in fibroblasts, which respond to LO uptake by activating MYC and SPI1 and by induce a transcriptional program that promotes angiogenesis and stimulates tumor growth. The overarching goal of this project is to determine the functional role of LO in PC progression and metastasis. We hypothesize that LO functionally reprogram normal prostate-associated fibroblasts (NAF) toward a phenotype that is driven by MYC and SPI1 activation. These results strongly suggest that tumor-derived LO might activate intercellular responses that are specific to this subtype of extracellular vesicle. Our hypothesis will be tested with three Specific Aims: Aim 1: To investigate the role of LO-induced fibroblast activation in PC progression. Aim 2: To find evidence that the LO- induced transcriptional program is active in PC patients with clinically significant disease. Aim 3: To test if LO and/or Exo derived from PC patient and PDX specimens promote castration resistance and/or bone metastasis. We will use a combination of complementary in vitro and animal orthotopic models as well as focused approaches involving genome editing, molecular barcodes, and a Cre-Lox reporter in vivo system. Our study will determine if the transcriptional program induced by LO in vitro drives tumor progression and metastasis in vivo. Additionally we will determine if this transcriptional program can also be identified in patient specimens and if it indicative of tumor progression. Finally, our study will provide evidence for LO abilities to induce metastasis of indolent PC cells. PROJECT NARRATIVE In this project we will perform functional tests of a newly-identified class of tumor-derived extracellular vesicle, referred to as large oncosomes. These shed vesicles are products of metastatic prostate cancer cells and we have obtained evidence that they are potent effectors of conditioning of the tumor microenvironment in a manner that promotes disease progression. Here we will examine their potential role in stroma-supported tumor progression and metastasis and the novel molecular mechanisms underlying this process.",
Automated Assessment of Leptomeningeal Collaterals on CT Angiograms,"Automated Assessment of Leptomeningeal Collaterals on CT Angiograms Abstract  The primary goal of this study is to develop an automated scoring system of leptomeningeal collaterals based on CT angiography (CTA) as a quantitative assessment of acute ischemic stroke. Leptomeningeal collaterals provide an alternate path of blood flow in the setting of a proximal vessel occlusion. The presence and effectiveness of leptomeningeal collaterals (i.e., “collateral status”) varies significantly from patient to patient. Collateral status has been shown to be correlated with both patient outcome and risk of hemorrhagic transformation, suggesting that rapid and accurate assessment of the collaterals would provide a powerful tool for treatment evaluation. The current gold standard for collateral scoring is performed by subjective analysis of retrograde filling in invasive digital subtraction angiograms (DSA). Though CTA is more limited than DSA in the direct evaluation of collaterals, the presence of collaterals may also be evaluated in CTA by the tree-pattern of vessel filling around the site of occlusion. Several manual assessment techniques based on CTA have been proposed in the literature, but all are subjective and require significant human intervention.  During Phase I, we deployed a web-based system for automated assessment of stroke collaterals based on CTA, and we used it in a preliminary study of collateral status for stroke assessment.  In this Phase II STTR proposal, the specific aims are (1) to improve the integration of our system with clinical workflows; (2) expand the system to also compute CT perfusion stroke measures, so as to provide a unified platform for comparing and combining CTA collateral and CT perfusion assessment metrics; and (3) test the hypotheses that the combined use of CTA collateral and CT perfusion measures outperforms either method independently for treatment efficacy prediction in stroke patients. Narrative  Leptomeningeal collateral vessels provide connections between vascular territories in the brain when occlusions occur, e.g., when a person suffers a stroke. The number and connectivity of collateral vessels varies significantly from patient to patient, and they have been shown to play an important role in stroke outcomes, providing blood flow to tissue at risk. Rapid and effective patient-specific determination of the presence and connectivity of collaterals is needed in acute stroke situations to determine which treatments will be effective. We propose to develop an automated system to evaluate collateral vessel trees from computed tomography angiography (CTA) images and to offer that system as an algorithms-as-a-service (AaaS) product.",
ARTIFICIAL INTELLIGENCE AIDS FOR COMMUNICATION,"ARTIFICIAL INTELLIGENCE AIDS FOR COMMUNICATION A significant number of physically disabled, non-vocal people could benefit from access to computers, but cannot make use of a computer keyboard.  By using an eye tracking system, these individuals can painstakingly compose words and sentences letter by letter by focusing an eye on alphabetic images on a computer screen.  This process is, however, tediously slow and prone to calibration difficulties.  To overcome these problems, we propose to couple the eye tracking system with state-of-the-art neural network software to allow automatic word completion and word prediction, and self-adjustment of the eye tracker calibration mechanism.  Neural networks are a very recent outgrowth of the Artificial Intelligence field.  They offer fault tolerant, adaptable, parallel computation.  They are self-adapting to an individual user and can evolve with him over time by continuously learning his speech patterns. By predicting entire words at once, neural networks greatly increase the speed and ease of communication without artificially restricting the user to a fixed vocabulary.  The newtorks can be specialized to accommodate a wide range of activities from daily communication needs, to schoolwork, business, creative writing and computer programming.  n/a",
Molecular & Cellular Effects of Human Mutations in Cytochrome P450 Reductase,"Molecular & Cellular Effects of Human Mutations in Cytochrome P450 Reductase     DESCRIPTION (provided by applicant):  The cytochrome P450s comprise a large family of enzymes responsible for such diverse reactions as drug and xenobiotic metabolism, steroid and bile acid biosynthesis, and fatty acid and eicosanoid hydroxylation. NADPH-cytochrome P450 oxidoreductase (POR) is the sole provider of electrons to the microsomal cytochromes P450 and to heme oxygenase, which catabolizes heme degradation. Because there is no redundancy for POR in mammalian systems, sequence variants might be expected to exhibit varied and pleiotropic effects depending on the sequence location and severity of the mutation, particularly if it impacts POR interactions with some CYPs, but not others. Indeed, patients with Antley-Bixler-like syndrome, which is characterized by craniofacial dysmorphism, premature synostoses, and disordered steroidogenesis, were shown to have such variants. This proposal will investigate the question of how disruption of the redox enzyme POR affects development and function of various tissues, particularly liver and bone. It is hypothesized that these effects are mediated in part by loss of CYP metabolites that regulate downstream signaling pathways directly or indirectly, and that perturbation of the interaction between POR and particular CYPs may vary, producing different phenotypes dependent upon the affected CYPs. To address these questions, three Specific Aims are proposed as follows: Specific Aim I. Molecular Characterization. This aim will characterize the purified forms of naturally occurring POR variants in humans. A variety of biochemical and biophysical techniques will be employed to determine the physical properties and protein-protein interaction capabilities of POR and its variants, including spectral, kinetic, surface plasmon resonance, analytical ultracentrifugation, ELDOR and isothermal titration calorimetry. These studies will elucidate the molecular properties of the enzymes that cause these phenotypic changes. Specific Aim II. Effect of POR Deficiency and Mutations in Downstream Cellular Events. In this experimental aim, we will examine the effects of POR mutations on downstream cellular events. These will be determined in bone- and liver-derived cells and tissues in which POR expression has been diminished or deleted, for example, by shRNA or from tissue- specific knockout mice. These cellular events, dependent on bone or liver metabolites, may affect bone development and hepatocyte function. Specific Aim III. Liver- and Bone-Specific Effects of POR Variants and POR Knock-down. Bone development and defects will be examined in liver-specific cytochrome P450 reductase knockout mice and a newly developed (in the PI's laboratory) bone-specific knockout mouse model using micro CT, differential staining and determination of vitamin D, retinoic acid, cholesterol, steroid, and lipid serum levels in these mice. Identification of new human polymorphisms will continue to determine possible downstream biomarkers of POR deficiency is a potential outcome.         PUBLIC HEALTH RELEVANCE:: The multifaceted approach taken by this proposal addresses the consequences of human cytochrome P450 reductase (POR) deficiency in human drug metabolism and bone development. Understanding these processes is crucial for tailoring drug regimens and other possible therapeutic interventions. By searching for new genetic mutations in this enzyme, identification of relevant biomarkers for POR deficiency is also a goal.            ",
Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors,"Blending deep learning with probabilistic mechanistic models to predict and understand the evolution and function of adaptive immune receptors Project Summary Scientific understanding of adaptive immune receptors (i.e. antibodies and T cell receptors) has the potential to revolutionize prophylaxis, diagnosis, and treatment of disease. High‐throughput DNA sequencing and functional experiments have now brought the study of adaptive immune receptors into the big‐data era. To realize this potential of these data they must be matched with appropriately powerful analytical techniques. Existing probabilistic and mechanistic models are insufficient to capture the complexities of these data, while a naïve application of machine learning cannot leverage our profound existing knowledge of the immune system. The goal of this project is to blend deep learning with mechanistic modeling in order to predict and understand the evolution and function of adaptive immune receptors. Aim 1: Develop generative models of immune receptor sequences that capture the complexity of real adaptive immune receptor repertoires. These will combine deep learning along with our knowledge of VDJ recombination, and provide a rigorous platform for detailed repertoire comparison. Aim 2: Develop quantitative mechanistic models of antibody somatic hypermutation that incorporate the underlying biochemical processes. Estimate intractable likelihoods using deep learning to infer important latent variables, and validate models using knock‐out experiments in cell lines. Aim 3: Develop hybrid deep learning models to predict binding properties from sequence data, combining large experimentally‐derived binding data with even larger sets of immune sequences from human immune memory samples. Incorporate structural information via 3D convolution or distance‐based penalties. These tools will reveal the full power of immune repertoire data for medical applications. We will obtain more rigorous comparisons of repertoires via their distribution in a relevant space. These will reveal the effects of immune perturbations such as vaccination and disease, allowing us to pick out sequences that are impacted by these perturbations. We will have a greater quantitative understanding of somatic hypermutation in vivo, and statistical models that appropriately capture long‐range effects of collections of mutations. We will also have algorithms that will be able to combine repertoire data and sparse binding data to predict binding properties. Put together, these advances will enable rational vaccine design, treatment for autoimmune disease, and identification of T cells that are promising candidates for cancer immunotherapy. Project Narrative Adaptive immune receptors (i.e. antibodies and T cell receptors) enable our body to fight off disease, “remember” pathogens, and train the immune system through vaccination. Immunologists have learned via high‐throughput sequencing that adaptive immune receptors have a truly remarkable diversity. In this proposal, we develop machine‐learning methods for these sequence data, which will allow us to predict the maturation, statistical distribution, and binding properties of adaptive immune receptors, and thus to better design vaccinations, autoimmune disease treatment, and immunotherapy treatment for cancer.",
Understanding the molecular mechanisms that contribute to neuropsychiatric symptoms in Alzheimer Disease,"Understanding the molecular mechanisms that contribute to neuropsychiatric symptoms in Alzheimer Disease Neuropsychiatric symptoms (NPS) are core features of Alzheimer’s disease (AD) and related dementias that are associated with major adverse effects on daily function and quality of life, and accelerate time to institutionalization. Of all the NPS, depression is the most frequently observed symptom in people with mild cognitive impairment and early AD. As the disease progresses, agitation, delusions and hallucinations become more common, whereas apathy is the most persistent and frequent NPS throughout all the stages of AD. AD- NPS share some clinical features with serious mental illnesses (SMIs), such as schizophrenia, bipolar disorder and major depressive disorder, but whether these conditions share similar aethiopathies is unclear. Given that reliable treatments for NPS in the context of AD and other dementias do not exist, a better understanding of the molecular mechanisms and pathways underlying NPS in AD and other neuropsychiatric illnesses is a critical next step to identify reliable biomarkers that could lead to novel therapeutics.  There are two overarching goals of this proposal. First, we will identify the molecular mechanisms and neuropathological changes that are associated with the presence of NPS in patients with AD. Second, we will examine if the mechanisms of pathology associated with NPS are shared or distinct among AD and SMIs. More specifically, we propose to build multi-scale integrative models using phenomics and genomics data from 1,264 autopsy cases derived from a single brain bank. The bank includes detailed phenomics data such as well characterized NPS, clinical diagnosis (AD and other neurodegenerative or neuropsychiatric traits), severity of cognitive decline and neuropathology for each patient sample. From each case, we will apply innovative approaches that reduce the cost and technical biases associated with conventional methods, and capture gene expression signatures and epigenetic regulatory elements at the single-cell level. Novel deep-learning methods will be applied for the multi-scale integration of neuropathologic changes with genetic markers and functional genomic changes (such as changes in gene expression and enhancer sequences) within specific cell types, to predict various NPS in AD and other neuropsychiatric traits; we refer to these integrative models as genotype- marker-phenotype models. We expect that these models will enable us to assign genotypes and molecular markers to specific NPS within AD and other neuropsychiatric traits at the single-cell level, an unprecedented level of resolution. In addition, we will test the translational potential of the genotype-marker-phenotype models to predict AD-NPS using independent large-scale biobank datasets, in which genotypes and electronic health records are available. Successful completion of the proposed studies will have immediate utility by generating potential biomarkers for NPS diagnosis and prognosis and by providing predictive models for patient stratification in clinical trials. In the longer term, our models will help us create a blueprint for therapeutic strategies and interventions to treat NPS in AD. PUBLIC HEALTH STATEMENT Neuropsychiatric symptoms (NPS) are core features of Alzheimer’s disease (AD) and related dementias, that contributes to early institutionalization and causes substantial caregiving and caregiver burden. Despite decades of research, reliable treatments for NPS in the context of AD and other dementias have not been found. The proposed studies will generate and integrate high- dimensional phenomics and genomics data in human brain tissue, that will inform us about the molecular mechanisms and pathways underlying NPS in the context of AD and other neuropsychiatric illnesses.",
A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities,"A Novel Imaging Analysis Platform for Patients with Craniomaxillofacial Deformities ﻿    DESCRIPTION (provided by applicant): Our ultimate goal is to improve our ability to create and measure 3D models derived from cone-beam computed tomography (CBCT). Our main motivation is to improve quality and reduce costs in care of patients with craniomaxillofacial (CMF) deformities. The resulted innovations will also impact other fields. CMF deformities involve congenital and acquired deformities of the jaws and face. A large number of patients in the US and around the world suffered from CMF deformities. The evaluation of these patients includes an assessment of CMF form on 3D models that are traditionally generated from segmented spiral multi-slice CTs (MSCTs). These models are also used to plan their treatment. The purpose of segmentation is to separate different anatomical structures and to remove the artifacts on the CTs. Once 3D models are generated from the segmented CTs, anatomical and teeth landmarks are manually digitized for measurements. Finally, diagnosis and treatment planning are performed based on measurements. Although MSCT provides high- quality images and thus allows relatively fast and easy post processing, many concerns have been raised on excessive radiation exposure to patients. Therefore, more doctors are now using CBCT scanners in their offices. CBCT has less radiation and is inexpensive compared to the MSCT, but their use in generating 3D models is greatly limited by the poor image quality, i.e., low contrast / signal-to-noise ratio and artifacts. Thus, the existing automated segmentation algorithms developed for MSCT are incapable of practically segmenting CBCTs. The current solution to CBCT segmentation entails an arduous and lengthy process that involves labor-intensive manual editing of hundreds of slices. Besides, another arduous and inaccurate task in the assessment of CMF deformities is the digitization of anatomical landmarks on 3D models - the first step to quantify the deformities. Currently a typical 3D cephalometric and teeth analysis requires the manual digitization of more than 200 landmarks, which is time consuming and has limited accuracy. We hypothesize that the creation and measurement of high-quality 3D models can be significantly improved by developing innovative CBCT-friendly post processing tools. Therefore, in this renewal project, we propose to develop and validate a novel CBCT analysis platform to automate the process of CBCT segmentation and landmark digitization. The feasibility of our approaches has already been proven by our preliminary studies. Our innovative CBCT analysis platform will significantly improve the quality and reduce the cost of care to the individuals with CMF conditions. It will change our dental/CMF fields in effectively utilizing CBCT as a guide for on-the-fly diagnosis and treatment planning. With minimal user intervention, the computer will accurately and effectively do the work, which is currently artistically done by the labor-intensive human operators. The resulted innovations may also impact other fields in the future, e.g., orthopedic surgery and cardiovascular surgery where intraoperative whole-body CBCT is acquired for image-guided surgery and intervention. PUBLIC HEALTH RELEVANCE: Cone-beam computed tomography (CBCT) is widely used in physician's offices for orthodontics, craniomaxillofacial (CMF) surgery, facial plastic surgery and dentistry, but its segmentation and landmark digitization have to be completed artistically by human operators, which is labor-intensive and with limited accuracy.  We propose to develop and validate an innovative CBCT post processing system to automate the processes of CBCT segmentation and landmark digitization with minimal user intervention.  The proposed system will significantly improve the quality and reduce the cost of care to the individuals  with CMF conditions, and also change 1) the fields of orthodontics, CMF surgery and general dentistry in  effectively utilizing CBCT as a guide for diagnosis and treatment planning, and 2) the fields of orthopedic  surgery, general surgery, and cardiovascular surgery where the quality and the speed of intraoperative  imaging is critical.",
Evidence Extraction Systems for the Molecular Interaction Literature,"Evidence Extraction Systems for the Molecular Interaction Literature Burns, Gully A. Abstract  In primary research articles, scientists make claims based on evidence from experiments, and report both the claims and the supporting evidence in the results section of papers. However, biomedical databases de- scribe the claims made by scientists in detail, but rarely provide descriptions of any supporting evidence that a consulting scientist could use to understand why the claims are being made. Currently, the process of curating evidence into databases is manual, time-consuming and expensive; thus, evidence is recorded in papers but not generally captured in database systems. For example, the European Bioinformatics Institute's INTACT database describes how different molecules biochemically interact with each other in detail. They characterize the under- lying experiment providing the evidence of that interaction with only two hierarchical variables: a code denoting the method used to detect the molecular interaction and another code denoting the method used to detect each molecule. In fact, INTACT describes 94 different types of interaction detection method that could be used in conjunction with other experimental methodological processes that can be used in a variety of different ways to reveal different details about the interaction. This crucial information is not being captured in databases. Although experimental evidence is complex, it conforms to certain principles of experimental design: experimentally study- ing a phenomenon typically involves measuring well-chosen dependent variables whilst altering the values of equally well-chosen independent variables. Exploiting these principles has permitted us to devise a preliminary, robust, general-purpose representation for experimental evidence. In this project, We will use this representation to describe the methods and data pertaining to evidence underpinning the interpretive assertions about molecular interactions described by INTACT. A key contribution of our project is that we will develop methods to extract this evidence from scientiﬁc papers automatically (A) by using image processing on a speciﬁc subtype of ﬁgure that is common in molecular biology papers and (B) by using natural language processing to read information from the text used by scientists to describe their results. We will develop these tools for the INTACT repository but package them so that they may then also be used for evidence pertaining to other areas of research in biomedicine. Burns, Gully A. Narrative  Molecular biology databases contain crucial information for the study of human disease (especially cancer), but they omit details of scientiﬁc evidence. Our work will provide detailed accounts of experimental evidence supporting claims pertaining to the study of these diseases. This additional detail may provide scientists with more powerful ways of detecting anomalies and resolving contradictory ﬁndings.",
Evaluating the Impact of Changes in Opioid Prescribing Across Health Systems Implementing Zero Suicide,"Evaluating the Impact of Changes in Opioid Prescribing Across Health Systems Implementing Zero Suicide This timely supplement would support our goals for the current award: An Evaluation of the National Zero Suicide Model Across Learning Healthcare Systems (U01MH114087) by capitalizing on a natural experiment, the planned the national roll-out of safety planning templates in behavioral health departments across five Kaiser Permanente regions and Henry Ford Health System in 2019. Safety planning is a highly recommended practice within the Zero Suicide (ZS) framework, but little is known about the effectiveness of the individual elements that can make up a safety plan, such as lethal means assessment, identification of supportive contacts, coping skills, warning signs, and sources of distraction. The current Zero Suicide award proposes to examine the impact of safety planning and lethal means assessment using a stepped-wedged interrupted time- series (ITS) approach, measuring each as a binary variable (e.g. safety planning did or did not occur). The ITS approach requires that some sites implement safety planning (intervention sites for safety planning), while others do not (control sites for safety planning). The proposed ITS approach is now problematic without further work for two reasons: 1) All Kaiser Permanente sites and Henry Ford have decided to uniformly implement safety planning around the same time, therefore there are no control sites 2) Without control sites, metrics that can accurately measure variation in safety planning/lethal means assessment at baseline and then longitudinally thereafter would enable our evaluation to take place, but all of the documentation lives in text- based clinical narratives. In working with our health system leads on the development of Zero Suicide metrics, we have been informed that the rate for safety planning and lethal means assessment at baseline is not zero, but the actual rate is unknown. This supplement will support development of new metrics using Natural Language Processing to determine baseline rates, from which, we can quantify the change in safety planning and lethal means assessment practice longitudinally after implementation of new safety planning templates using our Zero Suicide main award. Furthermore, we propose to take advantage of the newly implemented templates to address an important mediator of the effect of safety planning on suicide outcomes, the impact of fidelity to the new templates, which we define as quality, completeness, and level of integration with ongoing care. We propose the following three specific aims for this supplemental work: 1) Identify key terms for safety planning and lethal means assessment 1.) Develop Natural Language Processing (NLP) metrics to assess the occurrence of safety planning and lethal means assessment at three Zero Suicide sites 2) Implement NLP queries for identification of safety planning and lethal means assessment and measure baseline rates 3) Upon implementation of electronic safety planning templates in medical records, develop and implement metrics using NLP for assessing fidelity (completeness, quality, integration with care) to safety planning templates. Project Narrative: This supplement to the current award: An Evaluation of the National Zero Suicide Model Across Learning Healthcare Systems (U01MH114087) will take advantage of a national roll-out for safety planning templates in the electronic medical record across 5 Kaiser Permanente regions and Henry Ford Health System. It will support the development of innovative measures using natural language processing to efficiently quantify the baseline rates of safety planning and lethal means assessment across multiple sites, which will enable a rigorous evaluation to take place upon implementation of the new electronic templates. Furthermore, we propose to take advantage of the safety planning template roll-out by measuring fidelity (quality, completeness, and level of integration with care), because it may be an important mediator of the relationship between safety planning and suicide outcomes.",
Genomic Reconstruction of Yeast Transcription Networks,"Genomic Reconstruction of Yeast Transcription Networks DESCRIPTION (provided by applicant): Organisms devote a significant fraction of their genomes to encoding regulatory information which specifies when and where different genes should be turned on or off. Such information is essential for understanding development, tissue specificity, and cellular response to the environment and has great importance for understanding the molecular basis of disease. The one dimensional regulatory programs encoded in DNA are executed by transcription factors which respond to different conditions and regulate gene expression combinatorially, leading to complex regulatory networks. The goal of the proposed research is to develop theoretical models and computational algorithms to decipher the regulatory programs and to reconstruct the transcription networks in the model organism Saccharomyces cerevisiae. The following are the specific aims: 1) to systematically map the DNA recognition sites and target genes of transcription factors in the genome, 2) to identify environmental and genetic perturbations under which each transcription factor is activated or deactivated, 3) to systematically analyze combinatorial regulation by multiple transcription factors, 4) collaborate with two experimental labs to address specific problems of transcriptional regulation and combinatorial control, and 5) to build databases and online tools for the biological community to analyze gene expression data and transcriptional regulation. We will develop methods integrating information from the genome sequences for several yeast species and genome-wide functional data, and we will combine bioinformatics analysis with mechanistic models of gene regulation. n/a",
Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration,"Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration    Description (provided by applicant): Research in the design and implementation of ""Neural ElectroMagnetic Ontologies"" (NEMO) will address a critical need for tools to support representation, storage, and sharing of brain electromagnetic data. Electro- encephalography (EEG) and event-related potentials (ERP) are venerable techniques for cognitive and clinical research on human brain function. To realize their full potential, however, it will be necessary to address some long-standing challenges in comparing results across experiments and research laboratories. NEMO will address this need by providing ERP ontologies that can be used for meta-analysis of patterns across experiment contexts and research labs. Given the widespread use of EEG and ERP methods, and their clinical as well as research applications, development of such a system is both timely and significant. System design and implementation will rest on six specific aims. The first goal is to develop rigorous procedures for classification and labeling of electrophysiological patterns (event-related potentials, or ERPs) (Aim 1). The methods and tools that are developed initially for classification and labeling of surface (sensor- level) data will then be extended to support classification of data in source (anatomical) space (Aim 2). Next, we will represent the concepts that define ERP patterns as formal logics, or ""ontologies,"" and will use those concepts to describe the ERP patterns. Relational databases will be modeled based on the ontologies to support high-level questions about the nature of ERP patterns and the relationships between patterns that are associated with different lab, experiment, and analysis contexts (Aim 3). The application domain for our project is reading and language. We have established a consortium of experts in this area who will contribute EEG and ERP data from experimental studies and will collaborate with us on the design and testing, and evaluation of the tools developed for this project. The practical scientific aim will be to conduct meta-analyses of ERP patterns in reading and language. In addition to re-analyses of existing cross-lab data, new experiment paradigms (adapted from the fBIRN project) will be carried out across research sites to calibrate data acquisition and preprocessing methods, and to test the robustness of patterns across different experiment contexts (Aim 4). Initially, we will develop a different ontology for each representational space (e.g., sensor and source space) and each analysis method. Then, we will capture the semantic mappings between different sets of patterns (different ontologies) using data mining (Aim 5). To support this work, we will develop an integrated tool environment for storage and management of EEG and ERP data and meta-data, measure generation and labeling, ontology development, and meta-analysis. This environment will be web-accessible so that partners will have shared access to the project data, analysis tools, ontologies, and meta-analysis results (Aim 6). At the end of this project, the ontologies, annotated database, tools, and technologies will be made available to the larger research community. PUBLIC HEALTH RELEVANCE The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experiment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing.            Relevance The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing. 1",
Brain Dysfunction and Alcoholism,"Brain Dysfunction and Alcoholism    DESCRIPTION (provided by applicant): Over many years, our laboratory has consistently observed significantly lower amplitudes of Event-Related Potential (ERP) components, particularly the visual P3(00), in abstinent alcoholics. In the last grant period we have identified other specific neurophysiological anomalies, notably decreased event-related frontal theta, delta and gamma band responses during cognitive tasks. Recently, we have found that some of these deficits are also predictive of relapse. We have also demonstrated that alcoholics manifest a lack of electrophysiological differentiation regardless of stimulus and task requirements for several measures, and respond more generically to different cognitive demands in a task. Most of these deficits are more related to risk (family history of alcoholism) than excessive alcohol intake, and are thus already present in high risk offspring of alcoholics prior to alcohol exposure. Our preliminary studies also indicate anomalies in neural synchrony in resting brain states in alcoholics, and impairments in synchronization during cognitive operations. We have proposed that increased Central Nervous System disinhibition may underlie these anomalies and a predisposition to develop alcohol dependence and related disorders. We have recently found that P3 amplitude is related to level of impulsivity in alcoholics, and individuals with increased impulsivity manifest reduced activation in frontal areas. Many of our results related to response inhibition strongly implicate impaired frontal lobe functioning. Our functional imaging study in high risk individuals has highlighted vulnerability in fronto- parietal circuits. The proposed project plans to further evaluate disinhibition and frontal lobe dysfunction in abstinent alcoholics by implementing novel neurophysiological paradigms that assess response activation/inhibition and their effect on course of abstinence/relapse. Novel time-frequency methods developed in our laboratory will allow us to further investigate the underlying neural oscillations and their synchrony during early and late processing during ERP tasks in several frequency bands (delta, theta, alpha, beta, and gamma), as well as their relationship to resting (baseline) EEG in alcoholics. We hypothesize that alcoholics will utilize similar/same networks for different aspects of cognitive processing, instead of specialized networks to optimize performance, and that their neural networks may not synchronize/organize effectively to produce a good signal-to-noise ratio. To further understand the biological basis of electrophysiological deficits, we propose to implement structural/functional (fMRI) imaging methods during Go/No-Go and gambling tasks and will attempt to understand the frontal circuits and localize network disruptions that are associated with response inhibition and error/outcome evaluation. Finally, we propose to use classification analyses techniques to investigate the relationships between electrophysiological measures, structural/functional indices, impulsivity and craving, that are most important in predicting relapse, and identify subgroups of alcoholics more/less likely to relapse. These findings may have important implications for cognitive, behavioral and pharmacological treatment protocols. PUBLIC HEALTH RELEVANCE R01 AA002686 The project will address important clinical challenges and basic science questions regarding the pathophysiology of cognitive and neurophysiological deficits in alcoholics that cause them to repeatedly drink despite adverse outcomes. It is of utmost importance to elucidate the underlying predisposition for the overwhelming urge to drink (craving) resulting in recidivism to inform prevention strategies. Our findings will have important implications for cognitive, behavioral and pharmacological treatment protocols.          n/a",
Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization,"Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization    DESCRIPTION (provided by applicant): The ability to sequence and identify proteins, map their sites of post-translational modification (PTM), and assess their abundances is central to modern biology. Mass spectrometry (MS) is the gold standard technology by which this information is obtained. Serving as the centerpiece, tandem MS (MS/MS) is a principal component. Electron transfer dissociation (ETD), a relatively new MS/MS dissociation method, has generated significant excitement for its compatibility with previously intractable peptide/protein classes. Five years ago m/z range, mass accuracy, and mass resolution considerably restricted the application of ETD. Our initial RO1 proposal successfully eliminated this limitation by coupling ETD to the orbitrap mass analyzer. The resulting system routinely analyzes peptides and proteins, with and without labile PTMs, with a high-fidelity readout (orbitrap). As a result, it realized many of our anticipated outcomes and created numerous unforeseen opportunities. Just in the PI's laboratory, the latter set includes data-dependent selection of dissociation method (i.e., Decision Tree), discovery of the unique chemical compositions of z-type ions, internal spectral calibration using ETD reagents, activated-ion ETD, and several biological applications. By 2008, the commercial implementation of our technology began to reach researchers across the globe-nearly 300 to date-enabling access to numerous previously intractable problems such as mapping Arg methylation sites, increasing coverage of low molecular weight proteins, providing unambiguous PTM site assignment, and screening glycopeptide libraries, among many others. We detail two new aims that build upon the high impact results of our initial funding period. Aim 1, how do we broaden the utility of ETD for biomedical research? Aim 2, what is the role of gas- phase purification in quantitative proteomics? We continue with a balance of instrumentation, method, informatic, and applied projects constructed upon the widely used ETD-orbitrap platform we described 3.5 years ago.      PUBLIC HEALTH RELEVANCE: Cutting edge MS based technology, Electron transfer dissociation (ETD), continues to be developed. This new MS/MS dissociation method enables previously intractable peptide/protein classes to be sequenced and identified, have their sites of post-translational modification (PTM) mapped, and assess their abundances. This is central to modern biology and has relevance for research ranging from human disease to evolution.            Cutting edge MS based technology, Electron transfer dissociation (ETD), continues to be developed. This new MS/MS dissociation method enables previously intractable peptide/protein classes to be sequenced and identified, have their sites of post-translational modification (PTM) mapped, and assess their abundances. This is central to modern biology and has relevance for research ranging from human disease to evolution.          ",
Effective Treatments for Children's Emotional Disorders,"Effective Treatments for Children's Emotional Disorders    DESCRIPTION (provided by applicant): Numerous psychosocial treatments have been empirically demonstrated to reduce anxiety, depression, and other internalizing disorders in childhood. However, such empirically supported treatment (EST) programs are not as widely implemented in mental care as desirable. This gap undermines the positive impact that psychosocial treatments can have for children, and may ultimately reduce the value society will place on psychosocial treatment for mental health problems. About 13% of all school-age children have anxiety and 6% mood disorders. The long term goal of the current project, therefore, is to increase the likelihood that children receive ESTs for the mental health problems. To this end, the specific aims of the proposed Phase II work will be fully developed and make ready for commercial dissemination three products for which prototypes already exist from R&D completed in phase I. the central product is the Children's Emotional Disorders Effective Treatment Archive (CEDETA), which consists of complete kits for of all material required to implant (e.g., manual, workbooks) and evaluate each included EST. Treatments included in CEDETA were identified through a comprehensive scientific literature search and extensive evaluation by an independent Expert Panel in phase I. Access to 17 EST programs was secured in phase I, and a prototype kit for one CEDETA program was constructed and favorably evaluated by consumers. The specific aim for phase II is to make all materials for each EST program in CEDETA ready for commercial distribution by the end of the grant period. These kits will be marketed and sold to mental health practitioners, clinics, and systems. The other two products enhance the use of CEDETA by (1) facilitating the selection of the right treatment for a mental health practitioner's needs, through an online search procedure; and (2) providing professional continuing education (CE) training to the implementation of EST. specific phase II aims are to make these two ancillary products ready for commercial distribution by the end of the grant period. Technically usability testing and consumer feedback will be used extensively throughout the R&D process to ensure that all products meet the needs of mental health practitioners.  In addition, [a] randomized experiment enrolling [80] practitioners in total, will be conducted to evaluate features of these products to advance knowledge about EST as a clinical approach and inform further R&D. This experiment will test whether CEDETA and its associated products improve practitioners': (A) knowledge about, (B) general attitude towards, (C) intent to use, (D) actual use of ESTs for internalizing problems. About 13% of all school-age children have anxiety and 6% mood disorders. A minority receive treatment for these problems, and when they do, it is generally not a treatment that has been scientifically demonstrated to work. The long-term goal of the current project, therefore, is to increase the likelihood that children receive empirically supported psychosocial treatments for these mental health problems.          n/a",
High throughput RNAi based functional genomics in primary cells and in vivo,"High throughput RNAi based functional genomics in primary cells and in vivo DESCRIPTION (provided by applicant): Completion of the HGP (human genome program) has opened the 'Genomic Era' in biomedical research and enables functional genomics analysis of various gene elements. The long-term goal of the ENCODE Project is to identify and functionally characterize all of the sequence-based genomic elements. Functional elements that have been studied in ENCODE include transcribed sequences, regulators of transcription, and regulators of RNA transcripts themselves. The function of more than 50% of transcribed gene sequences is unknown. Most of them are expressed in specialized cells and thus their functions can only be studied in a biologically relevant context (i.e. primary cells, in vivo). In this propoal we plan to develop and commercialize a new RNAi platform that enables gene studies in a biologically relevant context with a long term goal of building a functional map of human genome. Introduction of small interfering RNAs (siRNAs) into cells with transfection reagents results in efficient gene silencing. siRNA-based functional genomics is widely used in established cell lines in vitro, but its applicability to primary cells and in vivo target validatin has been limited because of lack of efficient and non-toxic delivery systems. In collaboration with RXi pharmaceuticals we have developed a novel class of RNAi compounds - self deliverable RNAs. These small, asymmetric, hydrophobically modified RNA compounds enter cells and tissues without requirement for delivery formulation and efficiently silence genes in vitro and in vivo, enabling functional genomics studies in primary cells, embryonic cells, tissues, ex vivo, and in vivo. The major technical hurdle, which impedes wide spread use of this platform by scientific community is the complex and costly process of compound identification, synthesis and validation. The focus of this fast-track proposal is optimization of compound discovery process (Phase I) and development of a panel of 200-1000 functionally validated sdRNAs (Phase II), Completion of this proposal will build a commercially available product platform that will revolutionize functional genomics studies in biologically relevant systems such as primary cells, stem cells, tissue and organ models and eventually in vivo. This proposal is focused on development and commercialization of a new RNAi platform that enables gene studies in a biologically relevant context with a long term goal of building a functional map of human genome. sdRNAs are small, asymmetric, hydrophobically modified compounds that enter cell and tissues without requirement for delivery formulation and efficiently silence genes in vitro and in vivo. The focus of this proposal is developing and making available to scientific community a panel of 200-1000 of sdRNA compounds to enable HTS functional genomics analysis in primary cells, stem cells, tissues and in vivo.",
Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",
Comprehensive analysis of human adaptive immune receptors to elucidate correlates of Epstein-Barr virus disease suppression,"Comprehensive analysis of human adaptive immune receptors to elucidate correlates of Epstein-Barr virus disease suppression Project Summary/Abstract This project will develop a new technological approach for the comprehensive analysis of adaptive immune responses, which holds the potential to catalyze new strategies to prevent and treat disease. Here we will apply immune profiling techniques recently invented by the PI to investigate the mechanisms of Epstein-Barr virus (EBV) adaptive immune control in clinical cohorts of infected patients. EBV is a highly prevalent pathogen infecting >90% of the world’s population. Primary EBV infection often causes infectious mononucleosis (IM) and long-term sequelae include numerous malignancies, lymphoproliferative disorders, and a strong association with multiple sclerosis. No EBV vaccine is approved to date, and the molecular mechanisms of immune protection from EBV-associated diseases are unclear. Unfortunately, prior technical barriers in high- throughput immune profiling methods have prevented a comprehensive understanding of adaptive immune protection against EBV diseases. A technological approach that identifies the critical features of EBV immune protection will advance new solutions for vaccine and therapeutic development. Therefore, we developed an experimental pipeline to enable rapid and cost-effective analysis of B- and T-cell responses to EBV that is scalable to dozens of human patients per experiment. We hypothesize that a comprehensive B- and T-cell analysis of carefully selected patient cohorts that either can or cannot suppress symptomatic infection will reveal function-based correlates of EBV control. To test this hypothesis, we will apply quantitative immune profiling technologies to analyze cryopreserved longitudinal samples from recently completed prospective clinical studies of IM. Patient samples in our cohort span pre- and post-infection through convalescence and encompass the full range of clinical IM severity scores (from 0, asymptomatic primary infection, to 6, essentially bedridden with IM). Immune profile data will be used to establish adaptive immune correlates of IM disease severity. In addition, we will analyze immune responses in apparently immunocompetent patients with chronic active EBV (CAEBV) disease, or patients who do not adequately suppress EBV infection, to gain insight regarding adaptive immune function and dysfunction in CAEBV. Finally, we will develop a new computational toolkit to rapidly identify immune correlates from high-throughput datasets. Successful completion of this project will constitute the first comprehensive functional B- and T-cell receptor analysis in a human clinical cohort. Our efforts will provide a repertoire-scale, mechanistic understanding of adaptive immunity to EBV and suggest new strategies for treatment and prevention of EBV-associated diseases. Our long-term goal is to develop human immune profiling techniques as a platform approach to accelerate the rational design of vaccines and therapeutics against pathogens of high public health importance, beginning with EBV. Project Narrative This project will apply new high-throughput immune profiling technologies to elucidate the features of effective Epstein-Barr virus (EBV) immune control. EBV causes a range of human diseases including infectious mononucleosis and several forms of cancer; however, limited EBV treatment options are available and no approved preventive EBV vaccines exist. Our long-term objective is to apply enhanced understanding of adaptive immunity to accelerate the rational development of new vaccines and therapeutics.",
NICEATM Support Contract: Base Contract,"NICEATM Support Contract: Base Contract This is a Research and Development (R&D) contract to provide scientific and administrative support for the National Toxicology Program (NTP) Interagency Center for the Evaluation of Alternative Toxicological Methods (NICEATM). NICEATM research supports activities of NTP in general, and specifically, NTP’s Biomolecular Screening Branch (BSB), the Tox21 consortium, and the Interagency Coordinating Committee on the Validation of Alternative Methods (ICCVAM). NICEATM is responsible for ensuring compliance with the duties and provisions of the ICCVAM Authorization Act of 2000 (42 U.S.C. 285l-3) - to promote the research, development, validation, evaluation, acceptance, and use of new and alternative testing methods and strategies that are more predictive of human health and ecological effects than currently available methods and strategies. NICEATM carries out its mission by performing independent R&D activities, reviewing proposed test methods, organizing workshops and meetings, and facilitating peer reviews.  The Contractor is required to acquire and apply new and existing scientific knowledge to develop, evaluate, and validate novel computational approaches that can be used for chemical hazard identification and risk assessment with direct relevance to human health. Data development, analysis, and evaluation represents a large portion of the work of this requirement. These approaches include, but are not limited to: exposure modeling, physiologically based pharmacokinetic/pharmacodynamic (PBPK/PD) modeling, reverse toxicokinetic (R-TK) modeling, Quantitative Structure-Activity Relationship (QSAR) modeling, analysis of quantitative high throughput screening (qHTS) and high content (HC) data, and development of novel Integrated Testing and Decision Strategies (ITDS) using in vivo, in vitro and/or in silico systems. The Contractor routinely utilizes information from diverse data types and multiple databases (e.g., ToxRef DB, ToxCastDB, ExpoCastDB, DSSTox, CEBS, etc.) to develop and evaluate the above listed approaches. The Contractor develops Adverse Outcome Pathways (AOPs), in accordance with guidelines proposed by the Organisation for Economic Co-operation and Development (OECD)3, for novel AOPs of interest to Federal agencies. The Contractor analyzes the performance characteristics of the proposed AOPs in the context of emerging scientific literature and novel computational approaches.  To explore the utility of alternative methods, the Contractor identifies, retrieves, and compares data generated from novel methods with extant data from traditional methods found in the published literature. Using public and proprietary databases, the Contractor gathers all relevant production, use, exposure, and toxicological information on selected chemicals and mixtures currently included in or inder consideration for inclusion in Tox21-related efforts or of interest to the NTP. The Contractor reviews and evaluates the data and information gathered from the literature searches and prepares comprehensive written reports, as needed. In order to promote the research, development, validation, acceptance, and use of new and alternative testing methods and strategies, NICEATM supports ICCVAM-coordinates evaluations of submitted and nominated test methods by drafting supporting documentation for ICCVAM review, comment, and approval. In addition, NICEATM may be called upon to coordinate validation studies for emerging alternative approaches. The contractor has the flexibility to subcontract for expertise not resident within the contract organization or to subcontract for necessary validation efforts. Flexibility to engage subcontractors and consultants when needed expertise is not resident within the contract organization is included under the base contract. n/a",
Bayesian Statistics and Algorithms for Homology Modeling,"Bayesian Statistics and Algorithms for Homology Modeling   DESCRIPTION (provided by applicant): To improve human health, a goal of the          human genome project is to translate the genome sequence into an understanding       of human biology. An important step in this process is knowledge of the              structure of human proteins and the effects of sequence polymorphisms on             structure and function. Currently, the structures of only 1000 human proteins        are known, but the structures of up to one third or so of human proteins can be      modeled based on the structures of homologous proteins in the Protein Data           Bank. This fraction will increase rapidly due to structural genomics efforts.        Unfortunately, general principles of what works in homology modeling and what        does not have remained elusive. The reasons for this are several: 1)                 insufficient benchmarking of most prediction methods; 2) reliance on                 out-of-date statistical analysis of protein structures, performed without modem      methods of statistics: 3) most modeling methods assume a relatively high level       of sequence identity (>35 percent) between template structure and sequence to        be modeled, when most proteins of unknown structure are only distantly related       to proteins of known structure. The PI proposes benchmarking, new statistical        analysis, and new algorithms for each of the three major aspects of homology         modeling: alignment, building backbone coordinates for insertiondeletion             regions, and sidechain placement. The primary tools will be Bayesian                 statistical analysis, including hierarchical models and non-parametric methods       based on the Dirichlet process. The increase in size of the sequence and             structure databases makes the new statistical analysis timely, both because of       the increased power the new data provide, and the numerous applications              afforded by more sequences and structures.                                                                                                                                n/a",
Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex,"Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex Project Summary The use of stimuli with increasingly naturalistic properties has become critical to advance our understanding of vision. Many studies demonstrate that simple artificial stimuli (e.g. sinusoidal gratings and white noise) fail to engage nonlinearities that profoundly alter responses in the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). A recent and striking example comes from the use of naturalistic ‘flow’ stimuli, which engage robust responses in V1 that are not predicted from responses to gratings. This gap in understanding motivates the development of a stimulus ensemble and analysis framework that produces a quantitative understanding of visual processing to increasingly naturalistic stimuli and the nonlinearities that they engage. Our objective is to understand how flow stimuli are processed from retina through visual cortex. To meet this goal, we will make neural population recordings in retina (Aims 1 & 3), LGN (Aims 1 & 3) and V1 (Aim 3) using matched experimental conditions and a unified theoretical/modeling framework to map the transformations that occur across these stages of visual processing. Our central hypothesis is that V1 transforms a discrete and heavily light-level-de- pendent retinal representation of natural stimuli into a continuous (uniform) representation that is relatively in- variant to changes in the mean luminance. This invariance places a strong constraint on the class of nonlineari- ties that transform retinal responses to those observed in LGN and V1. We test this hypothesis in three aims: (1) determine early visual processing (retina & LGN) of naturalistic flow stimuli; (2) develop an encoding manifold to capture the population activity at each processing stage and transforms from one stage to the next; (3) test the ability of the manifold description to predict the impact of light adaptation on processing flow stimuli from retina to V1. Aim 1 will yield a matched experimental dataset to an interesting and novel class of ecologically-relevant stimuli. Aim 2 will yield a quantitative framework by which to understand the transformations that occur between retina, LGN, and V1. Aim 3 will provide a platform for globally perturbing the output of the retina by switching from photopic to mesopic and scotopic conditions, and thereby compare predictions of our model to measured changes in LGN and V1 activity. The primary significance of this research is that it will provide a computationally and experimentally unified framework for understanding the transformations that occur in the processing of stim- uli across multiple stages of visual processing. The major innovations are (1) presenting visual stimuli for retinal recordings that are matched to eye movements and pupil dynamics in alert animals; (2) creating a novel analysis framework that captures the responses of neurons at all three levels and the inter-level transformations to in- creasingly complex stimuli; (3) utilizing light adaptation as a method of perturbing retinal output to test our model and the stability (invariance) of LGN and V1 responses to adapting retinal signals. The expected outcome is a data-driven model of the processing from retina to LGN and V1 that generalizes from starlight to sunlight. Project Narrative Restoring vision to the blind likely requires understanding how retinal signals are communicated to the brain and how these signals are transformed in the thalamocortical pathway. This project aims to acquire an understanding of these transformations in the context of complex and more naturalistic visual stimuli.",
Artificial Intelligence to Predict Outcomes in Patients with Acute Kidney Injury on Continuous Renal Replacement Therapy,"Artificial Intelligence to Predict Outcomes in Patients with Acute Kidney Injury on Continuous Renal Replacement Therapy ABSTRACT Acute kidney injury (AKI) affects up to half of critically ill patients admitted to intensive care units (ICU). In patients with AKI and hemodynamic instability, continuous renal replacement therapy (CRRT) is the preferred dialysis modality for solute and volume control. ICU mortality in this vulnerable population is high (~75%) but kidney recovery occurs in up to two-thirds of survivors. Fluid overload is a potentially modifiable risk factor associated with these outcomes. However, there are currently no universally accepted approaches for predicting kidney recovery, survival or individual response to fluid removal during CRRT. Due to recent advances in computer science and widespread big data usage, deep learning (DL) has emerged as a valuable approach. DL allows construction of risk prediction models using time-series data that incorporate thousands of variables and dynamic changes in these variables derived from multi-dimensional sources and not only static values of these variables. We propose to develop and validate innovative DL approaches to dynamically predict these outcomes using multi-modal data from electronic health records and CRRT machines. We demonstrated superiority of DL models without a-priori variable selection compared to optimized logistic regression (C-Statistic of 0.72 vs. 0.62) for prediction of RRT liberation. We also showed that mortality prediction improved by incorporating changes in clinical data within 6-hour intervals after CRRT initiation. In addition, we identified distinctive mortality risk according to quintiles of achieved net ultrafiltration rates, after adjustment by patient’s weight, duration of CRRT, and other clinical parameters: OR 8.0 (95% CI: 2.7-25.1) when the highest quintile (>36 ml/kg/day) was compared to the lowest quintile (<13 ml/kg/day). We hypothesize that innovative DL approaches integrating time- series data will generate accurate and generalizable risk prediction models that can impact CRRT delivery. We will utilize a multi-institutional dataset that encompasses clinical data and CRRT programmatic and therapy data (CRRTnet registry, n=1500 patients) for model development and an independent multi-institutional dataset for validation (n=1500 patients) to: 1) continuously predict short-term (7-day) and medium-term (28-day) liberation from RRT due to kidney recovery; 2) continuously predict 24-hour mortality; and 3) identify and validate sub- phenotypes of patients with AKI on CRRT with differing achieved net ultrafiltration rates. This innovative research will assist 1) the development of novel clinical decision support platforms for guiding informed CRRT delivery and promoting kidney recovery; 2) the identification of sub-phenotypes of patients that can benefit from precision- medicine approaches to fluid removal during CRRT; and 3) the design of interventional studies focusing on fluid removal during CRRT to impact patient-centered outcomes. PROJECT NARRATIVE Continuous renal replacement therapy (CRRT) is the preferred dialysis treatment for critically ill patients with acute kidney injury and hemodynamic instability, yet mortality is high (~75%). Presently, there are no universally accepted approaches for predicting kidney recovery, survival or individual response to fluid removal during CRRT. We propose to develop and validate innovative deep learning approaches to dynamically predict these outcomes, which could guide CRRT decision-making including intensification, de-escalation, and enrich clinical trials focusing on fluid removal during CRRT.",
Characteristics of suicide and homicide in a vulnerable population,"Characteristics of suicide and homicide in a vulnerable population PROJECT SUMMARY/ABSTRACT Lesbian, gay, bisexual, and transgender (LGBT) adolescents and adults, when compared to similar others, are at increased risk for suicide attempts and exposure to violence victimization. Suicide mortality is also elevated, especially among women, though research studies are sparse. Accordingly, NIH has formally designated sexual/gender minorities a health disparity population. Yet there remain large gaps in the scientific knowledge base that undermine development, dissemination and implementation of effective public health interventions to reduce risk in this vulnerable population. These include whether rates of homicide are similarly elevated among LGBT persons, whether suicide rates are elevated among the transgender population, what role gender and race/ethnicity play in shaping risk, as well as clarification of the contextual factors surrounding these deaths, including missed opportunities for intervention. The primary goal of the project is to identify patterns of risk and to characterize proximal factors associated with violent death due to suicide and homicide among LGBT individuals. Drawing from Minority Stress Theory and, for suicides, the `ideation-to-action' framework, we hypothesize that anti-gay stigma and discrimination creates a vulnerability for violent death among LGBT adolescents and adults. Capitalizing on new information classifying deaths for LGBT status in recent years of the National Violent Death Reporting System (NVDRS), we will make novel use of supervised machine learning techniques to recapture LGBT status among deaths in those 12 years and older in the 2003-2015 NVDRS (> 200,000 suicides, homicides, or homicide-suicides). Similar techniques will also be used to code NVDRS death narratives for co-occurring stigma-based contextual factors (e.g., gay disclosure, familial rejection), risk profiles (e.g. mental health, substance use), and recent services use in the immediate circumstances surrounding the death. This will allow us to achieve two study aims. For Aim 1, we will use NVDRS data and exogenous information estimating LGBT population size to generate state-level estimates of suicide and homicide rates, adjusted for population composition, among individuals 12 years and older. We hypothesize that LGBT population risk estimates for suicide and homicide will exceed those of non-LGBT populations. For Aim 2, we will identify sexual orientation and gender minority-linked differences in predisposing and proximal factors associated with suicide and homicide, including indicators of mental health and substance use, patterns of recent health care access, and characteristics of death circumstances, including HIV infection status. Consistent with theoretical predictions, we hypothesize that recent discrimination experiences will be strongly associated with sexual orientation and transgender status, that homicide deaths will more likely show evidence of hate-crime-related contextual factors, and that HIV-related issues will be an important though downward trending precipitant of suicide among sexual minority men. We also anticipate gender and ethnic/racial differences in these effects that will have important implications for future risk reducing interventions. Information obtained will greatly aid achieving the American Foundation for Suicide Prevention Project 2025 goal of reducing the suicide rate 20% by 2025 and NIMH's Zero Suicide efforts by providing interventionists with data to design screening and intervention efforts for the LGBT population. PROJECT NARRATIVE The proposed project addresses an important public health problem—lesbian, gay, bisexual, and transgender (LGBT) individuals likely experience higher rates of violent death, including suicide and possibly homicide, than other persons. Why this occurs has yet to be fully determined. This study investigates both predisposing and precipitating factors linked to violent death among LGBT individuals, age 12 years and older. Our goal is to identify modifiable, explanatory factors that can account for mortality disparities between LGBT and non-LGBT individuals.",
A Training and Fidelity Model to Move and Scale Evidence-based Dementia Care and Caregiver Support Programs into Practice: The Case for COPE in PACE service settings,"A Training and Fidelity Model to Move and Scale Evidence-based Dementia Care and Caregiver Support Programs into Practice: The Case for COPE in PACE service settings This NIA Stage I study is designed to address two leading barriers to implementation of evidence-based dementia care and caregiver support programs into long-term care settings: (1) lack of streamlined, user-friendly, and tested training modalities, and (2) lack of scalable, practical processes to accurately measure fidelity in “real world” settings. The aims of the study are to determine whether an online training program is the same or better in improving interventionist fidelity to an evidence based dementia program (COPE) and dementia patient outcomes when compared to a high intensity face-to-face traditional form of training. To accomplish these aims we will develop an online, principle-driven approach using state-of-the- science simulation and best practices and a scalable approach to assess fidelity to COPE by applying computational linguistics techniques. We will then conduct a noninferiority trial in Programs for All Inclusive Care for Elders (PACE) organizations randomly assigned to the training conditions. PACE staff will be evaluated post training on their fidelity outcomes. Dyads of persons with dementia and their caregivers will be evaluated at 4 months post COPE implementation on function, neuropsychiatric symptoms, quality of life, and caregiver burden. The findings from this project will lay the essential groundwork for a large scale, Stage III-IV, pragmatic trial of COPE in PACE settings throughout the US. Findings will also serve as a model for guiding the development of practical, scalable processes for training and fidelity monitoring in other long-term care settings and for other evidence-based support programs. Most persons with dementia and their caregivers do not have access to or receive beneficial and supportive evidence-based programs due to the need for scalable and reliable training and monitoring procedures for clinicians. We address this gap to developing and testing a replicable, accessible, and sustainable processes for training and monitoring clinicians in Care of Persons in the Environments (COPE) - an evidence based dementia care program - in a long-term care service setting. Study findings will yield an understanding of ways to move evidence into real-world dementia care settings and can serve as a model for guiding the development of practical, scalable processes for training and fidelity monitoring in other long-term care settings and for other evidence-based support programs.",
ABCD-USA Consortium: Research Project,"ABCD-USA Consortium: Research Project DESCRIPTION (provided by applicant): Adolescence is a critical neurodevelopmental period associated with dramatic increases in rates of substance use. Identifying the pathways to substance use and its effects on child and adolescent development is critically important, as the effects of substance use during ongoing maturation likely have long-lasting effects on brain functioning and behavioral, health, and psychological outcomes. This Research Project Site application from the University of California, San Diego and Laureate Institute for Brain Research is in response to RFA-DA-15-015 as part of the ABCD-USA Consortium (5/13), to prospectively determine the neurodevelopmental and behavioral predictors and consequences of substance use on children and adolescents. A representative community sample of 1086 9-10 year olds enriched for high- risk characteristics will be recruited, contributing to the sample of 11,111 to be collected from 11 hubs across the ABCD- USA Consortium. All participants will undergo a comprehensive baseline assessment, including state-of-the-art brain imaging, comprehensive neuropsychological testing, bioassays, mobile monitoring and careful assessment of substance use, environment, psychopathological symptoms, and social functioning every 2 years. Interim annual interviews and quarterly web-based assessments will provide refined temporal resolution of behaviors, development, and life events with minimal participant burden. These Consortium-wide data obtained during the course of this project will elucidate: 1) the effects of substance use patterns on the adolescent brain; 2) the effects of substance use on behavioral and health outcomes; 3) the bidirectional relationship between psychopathology and substance use patterns; 4) the effects of individual genetic, behavioral, neurobiological, and environmental differences on risk profiles and substance use outcomes; and 5) the ""gateway interactions"" between use of different substances. This hub's Research Project focuses on mechanisms of substance use disorder, special populations with high use prevalence, and the use of drugs other than marijuana. (1) We will determine whether individual differences in neural processing of antireward (i.e., negative reinforcement mechanisms) in amygdala, insula, and anterior cingulate are associated with increased negative emotionality and pain, predict initiation of use and problem use, and are in turn further dysregulated by substance use. (2) We will determine whether protective environment factors and ethnic identification in minority youth are linked to healthier antireward processing and better substance use outcomes. (3) We will determine whether antireward neural processing predicts increased use of illicit drugs other than MJ including misuse of prescription drugs, if such use predicts subsequent exaggerated antireward processing, and if gateway interactions exist between substances. Finally, we will use machine learning approaches to develop a youth-specific risk calculator that will enable us to identify individually- based modifiable risk factor, providing brain-based targets of future novel prevention and intervention approaches. PUBLIC HEALTH RELEVANCE: The ABCD-USA Consortium will use multimodal brain imaging, cognitive and clinical assessments, bioassays, mobile monitoring, and careful assessment of substance use, environment, psychopathological symptoms, and social functioning in 11,111 adolescents followed over 10 years to determine the effects of substance use on adolescent brain and cognitive development. Our 5/13 ABCD-USA Consortium: Research Project will recruit and assess 1086 youth age 9-10 at project entry. In addition to contributions to the overall consortium, our U01 will specifically focus on negative reinforcement mechanisms of substance use disorder, special populations with high SUD prevalence, and illicit drug and prescription medication misuse among adolescents.",
Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses,"Digital Tomosynthesis Mammography: Computer-Aided Analysis of Masses    DESCRIPTION (provided by applicant): Digital tomosynthesis mammography (DTM) is a new modality that holds the promise of improving mammographic sensitivity of breast cancer detection and diagnosis, especially for dense breasts. The main goals of the proposed research are (1) to develop a computer-aided detection (CADd) system for breast masses in DTM, (2) to develop a computer-aided diagnosis (CADx) system for classification of malignant and benign masses in DTM, and (3) to evaluate the effects of CAD (either CADd or CADx) on radiologists' interpretation of DTMs. Previous CAD systems are developed for regular projection mammograms (PMs).The proposed CAD system makes use of the 3-dimensional (3D) information in DTM to improve mass detection and characterization. The innovations in the proposed project include: (1) development of new computer-vision techniques to exploit the 3D volumetric information in DTMs, (2) evaluation of the dependence of CAD performance on reconstruction algorithms, and (3) comparison of computerized mass detection and characterization in DTMs, projection view mammograms (PVs) (the non-reconstructed mammograms taken at multiple angles during tomosynthesis imaging), and PMs. We hypothesize that detection and characterization of masses on DTMs will be more accurate than corresponding tasks on regular PMs, and that the CAD systems can improve radiologists' accuracy. 3D breast phantoms with test objects will be designed and imaged with a prototype DTM system. The dependence of DTM image quality on reconstruction algorithms and their parameters, and on image acquisition techniques will be studied. The appropriate reconstruction techniques will be selected based on phantom and patient studies. A database of DTMs and corresponding PMs with malignant and benign masses and a set of normal cases will be collected with patient informed consent. CAD systems for detection and classification of masses will be developed. Two approaches will be compared: one uses the reconstructed DTM slices and the other uses the PVs as input to the CAD systems. For the DTMs, new techniques for 3D preprocessing, image segmentation, feature extraction, and feature classification will be designed. For the PVs, our previous techniques developed for regular PMs will be adapted to these low- dose images, and information fusion methods using techniques such as neural networks or support vector machines will be developed to merge the multiple-PV information. To test our hypotheses, we will compare the CAD system performances from these two approaches and that from the corresponding regular PMs, and conduct observer ROC studies to evaluate effects of the CAD systems on radiologists' performance. CAD will be an important tool that can help accelerate the implementation of DTM in clinical practice. DTM with CAD is expected to help fully utilize the potential of this new modality to improve breast cancer detection.           n/a",
Neural mechanisms for reducing interference during episodic memory formation,"Neural mechanisms for reducing interference during episodic memory formation DESCRIPTION (provided by applicant): One of the biggest challenges to successful remembering is the potential for confusion or interference between similar memories. For every password, name, or parking space that we store in memory, there are many other passwords, names or parking spaces that we have already learned or will learn in the future. While interference is a factor in relatively benign-yet annoying-examples of 'normal' forgetting, it is aso a major factor in clinically significant examples of forgetting that occur with aging and/or dementia. Thus, there is a fundamental need to understand the neural mechanisms that support the acquisition/retrieval of similar memories while minimizing interference and corresponding forgetting. Computational models of episodic memory have proposed two core mechanisms that are thought to reduce interference-related forgetting: integration and pattern separation. Integration involves 'fusing' overlapping memories into a common representation such that the relationship between these memories is more complementary than competitive. Pattern separation involves the orthogonalization of similar memories such that differences between memories are exaggerated and the potential for interference minimized. While there is general agreement that these mechanisms are theoretically appealing and offer clear computational advantages, clear evidence for how and when these learning mechanisms are invoked- particularly in humans-remains surprisingly limited. In particular, there remains ambiguity as far as (a) the learning contexts in which each mechanism might be recruited, (b) what the corresponding neural signatures of each mechanism are, and (c) the specific behavioral consequences associated with the engagement of each mechanism. We propose a systematic investigation of the contexts in which integration and pattern separation occur with the goal of using sophisticated, cutting-edge neuroimaging (fMRI) techniques to identify distributed patterns of neural activity that are diagnostic of each mechanism. Critically, we also plan to use these observed patterns of neural activity-that is, neural evidence for integration vs. separation-to predict behavioral memory phenomena, including interference-related forgetting. The research represents a strong synthesis of psychology and neuroscience questions with an emphasis on learning mechanisms inspired by computational models and analysis approaches that draw from the fields of machine learning and data mining. PUBLIC HEALTH RELEVANCE: A primary reason we forget is because we store a vast number of memories and interference between these memories becomes inevitable. While forgetting may represent only an occasional annoyance for most people, among older adults and those with dementia-groups that are growing at a disproportionate rate memory confusions and susceptibility to interference-related forgetting can be debilitating problems. The proposed research seeks to identify neural mechanisms that reduce interference-related forgetting and will develop neurodiagnostic tools that can be used to characterize memory processes and predict susceptibility to memory confusions and forgetting.",
Intracranial EEG and Electrical Stimulation of Deactivations in the Human Brain,"Intracranial EEG and Electrical Stimulation of Deactivations in the Human Brain ﻿    DESCRIPTION (provided by applicant): The brain's ability to efficiently carry out a task relies not only on the engagement of cognitive processes relevant to the task at hand, but also on the suppression of task-irrelevant cognitive processes. The inability to suppress task-irrelevant processes not only drives lapses of attention in everyday life, but also is characteristic of many neuropsychiatric disorders. For example, many patients with severe depression are unable to turn off negative ruminations. Neuroimaging work has identified distinct brain networks engaged in externally- versus internally-directed cognition, which exhibit opposite patterns of activity during both task and rest conditions. A default-mode network (DMN) activates when subjects engage in self-referential processes such as remembering a past event or planning for the future. The DMN also deactivates when subjects engage with the external environment, and decreased deactivation is associated with worse behavioral performance on such tasks. Conversely, a dorsal attention network (DAN) activates when subjects attend to stimuli in the environment. Control networks, which are thought to configure more specialized brain networks in order to carry out a task, have been shown to selectively link with task-relevant brain regions; for example, with the DMN when retrieving a memory, or with the DAN during visual search. However, the mechanisms of task- related deactivations are still unknown; for example whether they result from direct mutual inhibition between task-relevant and -irrelevant brain regions, or are mediated by a third set of regions such as the control networks. Moreover, while correlative evidence has linked the deactivation of task-irrelevant brain regions to better behavioral performance, there is no causal evidence in support of this idea. The proposed work aims to address these gaps by using electrocorticography (ECoG) to record electrical activity directly from human cortex with high temporal and anatomic precision, from regions previously shown by our lab to activate during memory (internal cognition) versus math processing (external cognition). We will track the dynamic interactions between, and relative timing of activity in, math-selective and memory-selective brain regions, as well as control-regions, during math versus memory processes (Aim 1). We will also use electrical brain stimulation (EBS) to transiently perturb activity in the above regions during math versus memory processes, to assess the causal function of task-related deactivations on behavior, as well as on the neural activity in task-relevant brain regions (Aim 2). This work has the promise to provide the training ground best suited for my desired career in systems neurosciences and electrophysiology, and the resulting knowledge may elucidate the dysfunctional neuronal communication thought to underlie many neuropsychiatric disorders. PUBLIC HEALTH RELEVANCE: To effectively achieve a goal, we must not only engage task-relevant cognitive processes, but also suppress task-irrelevant processes, the latter of which is impaired in many neuropsychiatric disorders, such as schizophrenia, depression, and ADHD. In the proposed research, we will study the fast dynamics of the relationship between activated and deactivated brain regions in two brain networks involved in internally- directed versus externally-directed cognition. We will also directly test the causal importance of task-related deactivations on behavior by electrically stimulating deactivated brain regions while subjects perform a task.",
Multi-point and multi-locus analysis of genomic association data,"Multi-point and multi-locus analysis of genomic association data    DESCRIPTION (provided by applicant):       Genome-wide association studies (GWAS) provide a new and powerful approach to investigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learning approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases.            Principal Investigator/Program Director: Li, Jing Title: Multi-point and multi-locus analysis of genomic association data Abstract: Genome-wide association studies (GWAS) provide a new and powerful approach to inves- tigate the effect of inherited genetic variation on risks of complex diseases. With recent advances in genotyping technology, genome-wide association studies are now becoming a reality. Data from GWAS are expected in an accelerated rate. Despite tremendous efforts in developing efficient algorithms for mapping complex diseases/traits, single-locus based approaches are still the primary method for GWAS. However, it is known that usually multiple genetic factors, environmental factors as well as their interactions play an important role in the etiology of complex diseases. Novel and practical approaches to simultaneously model multiple variables and their interactions from hundreds of thousands single nucleotide polymorphisms (SNPs) are greatly needed. In this project, we propose to develop efficient algorithms and practical statistical tools to address two important problems in the context of genome- wide association studies: multi-point analysis and multi-locus analysis. For multi-point analysis, our Dynamic Hidden Chain Markov Model (DHCMM) can jointly model historical recombination and muta- tions, haplotype structures and frequencies, and associations, which is expected to be more effective than existing approaches. For multi-locus analysis, we propose to use an advanced machine learn- ing approach to jointly screen SNPs that are predictive of diseases. Our integrated software system MAVEN will facilitate management, analysis, visualization and results sharing of GWA data using cut- ting edge technologies. The true value of GWAS is pending the development of effective computational models and tools. We anticipate that this research project will greatly accelerate the understanding of the genetic architecture of complex diseases. PHS 398 Page 1",