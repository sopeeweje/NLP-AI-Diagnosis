text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7941562,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,1038804,0.22734063098988477
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7581087,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,3437506,0.22734063098988477
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8061704,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'information model', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2011,2923298,0.22734063098988477
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8138946,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,745063,0.22734063098988477
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7780085,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,3513343,0.22734063098988477
"Gene Ontology Consortium PROJECT SUMMARY Because of the staggering complexity of biological systems, biomedical research is becoming increasingly dependent on knowledge stored in a computable form. The Gene Ontology (GO) is by far the largest knowledgebase of how genes function, and has become a critical component of the computational infrastructure enabling the genomic revolution. It has become nearly indispensible in the interpretation of large- scale molecular measurements in biological research. Crucially, for human health research, GO is also one of a suite of complementary ontologies constructed in such as way to maximally promote interoperability and comparability of data sets. It represents the gene functions and biological processes that are perturbed in human disease, e.g. via the links from Human Phenotype Ontology (HPO) class abnormality of lipid metabolism, defined in relation to the GO class lipid metabolic process (GO_0006629), researchers or clinicians can find the set of genes that are known to be involved in this process. GO is a knowledge resource that can be statistically mined, either standalone or in combination with data from other knowledge resources, which enables experts to discover connections and form new hypotheses from the biological networks GO represents. All knowledge in GO is represented using semantic web technologies and so is amenable to computational integration and consistency checking. The proposed GO knowledge environment will enable a wider community of scientists to contribute to, and to utilize, a common, computable representation of biology. To ensure the knowledge environment meets the requirements of biomedical researchers, we will: a) deliver a comprehensive, detailed, computable knowledgebase of gene function, encoded in the Gene Ontology and annotations (computer-readable statements about the how specific genes function), focusing on human biology; b) provide a “hub” for a broad community of scientists to collaboratively extend, correct and improve the knowledgebase; c) ensure the GO knowledge resource is of the highest quality with regards to depth, breadth and accuracy; d) facilitate the transfer of insights obtained from studies of non-human organisms, such as the mouse and zebrafish, to human biology; and e) enable the scientific community to use the knowledgebase in analyses of large-scale genetic and -omics data. Our aims reflect the essential requirements for realizing the overarching objectives for a biomedical data resource: efficiently capturing and integrating biological knowledge and adhering to the highest possible standard for accuracy and detail; constructing and providing a robust, flexible, powerful, and extensible technological infrastructure available not only for internal use but just as easily by the wider community; and lastly, leveraging state-of-the-art social media, web services and other technologies to disseminate the GO resource to the entire biomedical research community. PUBLIC HEALTH RELEVANCE This project aims to provide a complete and integrated picture of what every single gene in a human being does, thus allowing us to better understand the genetic and cellular workings of human health and disease. We do this by developing the Gene Ontology, a computational resource that collects biological knowledge into a large network structure that connects genes with the roles they play. Researchers, clinicians, and sophisticated computer programs use this network to interpret the massive amounts of biomedical and genomic data being generated in experiments and in studies designed to gain key insights into human health.",Gene Ontology Consortium,9930119,U41HG002273,"['Animal Model', 'Area', 'Automation', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Communities', 'Community Developments', 'Computer software', 'Computers', 'Data', 'Data Set', 'Disease', 'Documentation', 'Ensure', 'Environment', 'Family', 'Family member', 'Foundations', 'Gene Family', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Individual', 'Information Resources', 'Infrastructure', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Measurement', 'Medical Research', 'Medicine', 'Metabolism', 'Modeling', 'Modification', 'Mus', 'Network-based', 'Ontology', 'Organism', 'Orthologous Gene', 'Phenotype', 'Phylogenetic Analysis', 'Play', 'Process', 'Provider', 'PubMed', 'Readability', 'Recurrence', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Standardization', 'Structure', 'Technology', 'Testing', 'Training', 'Trees', 'Update', 'Work', 'Zebrafish', 'annotation  system', 'base', 'big biomedical data', 'biological research', 'biological systems', 'biomedical ontology', 'computer based Semantic Analysis', 'computer infrastructure', 'computer program', 'computing resources', 'data resource', 'design', 'experimental study', 'flexibility', 'gene function', 'genomic data', 'human disease', 'improved', 'insight', 'interest', 'interoperability', 'knowledge base', 'lipid metabolism', 'model organisms databases', 'molecular scale', 'ontology development', 'outreach', 'prevent', 'public health relevance', 'scale up', 'social media', 'software development', 'support network', 'text searching', 'tool', 'web services']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U41,2020,412500,0.35363463351554875
"Gene Ontology Consortium PROJECT SUMMARY Because of the staggering complexity of biological systems, biomedical research is becoming increasingly dependent on knowledge stored in a computable form. The Gene Ontology (GO) is by far the largest knowledgebase of how genes function, and has become a critical component of the computational infrastructure enabling the genomic revolution. It has become nearly indispensible in the interpretation of large- scale molecular measurements in biological research. Crucially, for human health research, GO is also one of a suite of complementary ontologies constructed in such as way to maximally promote interoperability and comparability of data sets. It represents the gene functions and biological processes that are perturbed in human disease, e.g. via the links from Human Phenotype Ontology (HPO) class abnormality of lipid metabolism, defined in relation to the GO class lipid metabolic process (GO_0006629), researchers or clinicians can find the set of genes that are known to be involved in this process. GO is a knowledge resource that can be statistically mined, either standalone or in combination with data from other knowledge resources, which enables experts to discover connections and form new hypotheses from the biological networks GO represents. All knowledge in GO is represented using semantic web technologies and so is amenable to computational integration and consistency checking. The proposed GO knowledge environment will enable a wider community of scientists to contribute to, and to utilize, a common, computable representation of biology. To ensure the knowledge environment meets the requirements of biomedical researchers, we will: a) deliver a comprehensive, detailed, computable knowledgebase of gene function, encoded in the Gene Ontology and annotations (computer-readable statements about the how specific genes function), focusing on human biology; b) provide a “hub” for a broad community of scientists to collaboratively extend, correct and improve the knowledgebase; c) ensure the GO knowledge resource is of the highest quality with regards to depth, breadth and accuracy; d) facilitate the transfer of insights obtained from studies of non-human organisms, such as the mouse and zebrafish, to human biology; and e) enable the scientific community to use the knowledgebase in analyses of large-scale genetic and -omics data. Our aims reflect the essential requirements for realizing the overarching objectives for a biomedical data resource: efficiently capturing and integrating biological knowledge and adhering to the highest possible standard for accuracy and detail; constructing and providing a robust, flexible, powerful, and extensible technological infrastructure available not only for internal use but just as easily by the wider community; and lastly, leveraging state-of-the-art social media, web services and other technologies to disseminate the GO resource to the entire biomedical research community. PUBLIC HEALTH RELEVANCE This project aims to provide a complete and integrated picture of what every single gene in a human being does, thus allowing us to better understand the genetic and cellular workings of human health and disease. We do this by developing the Gene Ontology, a computational resource that collects biological knowledge into a large network structure that connects genes with the roles they play. Researchers, clinicians, and sophisticated computer programs use this network to interpret the massive amounts of biomedical and genomic data being generated in experiments and in studies designed to gain key insights into human health.",Gene Ontology Consortium,9663327,U41HG002273,"['Animal Model', 'Area', 'Automation', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Communities', 'Community Developments', 'Computer software', 'Computers', 'Data', 'Data Set', 'Disease', 'Documentation', 'Ensure', 'Environment', 'Family', 'Family member', 'Foundations', 'Gene Family', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Individual', 'Information Resources', 'Infrastructure', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Measurement', 'Medical Research', 'Medicine', 'Metabolism', 'Modeling', 'Modification', 'Mus', 'Network-based', 'Ontology', 'Organism', 'Orthologous Gene', 'Phenotype', 'Phylogenetic Analysis', 'Play', 'Process', 'Provider', 'PubMed', 'Readability', 'Recurrence', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Standardization', 'Structure', 'Technology', 'Testing', 'Training', 'Trees', 'Update', 'Work', 'Zebrafish', 'annotation  system', 'base', 'big biomedical data', 'biological research', 'biological systems', 'biomedical ontology', 'computer based Semantic Analysis', 'computer infrastructure', 'computer program', 'computing resources', 'data resource', 'design', 'experimental study', 'flexibility', 'gene function', 'genomic data', 'human disease', 'improved', 'insight', 'interest', 'interoperability', 'knowledge base', 'lipid metabolism', 'model organisms databases', 'molecular scale', 'ontology development', 'outreach', 'prevent', 'public health relevance', 'scale up', 'social media', 'software development', 'support network', 'text searching', 'tool', 'web services']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U41,2019,2668358,0.35363463351554875
"Gene Ontology Consortium PROJECT SUMMARY Because of the staggering complexity of biological systems, biomedical research is becoming increasingly dependent on knowledge stored in a computable form. The Gene Ontology (GO) is by far the largest knowledgebase of how genes function, and has become a critical component of the computational infrastructure enabling the genomic revolution. It has become nearly indispensible in the interpretation of large- scale molecular measurements in biological research. Crucially, for human health research, GO is also one of a suite of complementary ontologies constructed in such as way to maximally promote interoperability and comparability of data sets. It represents the gene functions and biological processes that are perturbed in human disease, e.g. via the links from Human Phenotype Ontology (HPO) class abnormality of lipid metabolism, defined in relation to the GO class lipid metabolic process (GO_0006629), researchers or clinicians can find the set of genes that are known to be involved in this process. GO is a knowledge resource that can be statistically mined, either standalone or in combination with data from other knowledge resources, which enables experts to discover connections and form new hypotheses from the biological networks GO represents. All knowledge in GO is represented using semantic web technologies and so is amenable to computational integration and consistency checking. The proposed GO knowledge environment will enable a wider community of scientists to contribute to, and to utilize, a common, computable representation of biology. To ensure the knowledge environment meets the requirements of biomedical researchers, we will: a) deliver a comprehensive, detailed, computable knowledgebase of gene function, encoded in the Gene Ontology and annotations (computer-readable statements about the how specific genes function), focusing on human biology; b) provide a “hub” for a broad community of scientists to collaboratively extend, correct and improve the knowledgebase; c) ensure the GO knowledge resource is of the highest quality with regards to depth, breadth and accuracy; d) facilitate the transfer of insights obtained from studies of non-human organisms, such as the mouse and zebrafish, to human biology; and e) enable the scientific community to use the knowledgebase in analyses of large-scale genetic and -omics data. Our aims reflect the essential requirements for realizing the overarching objectives for a biomedical data resource: efficiently capturing and integrating biological knowledge and adhering to the highest possible standard for accuracy and detail; constructing and providing a robust, flexible, powerful, and extensible technological infrastructure available not only for internal use but just as easily by the wider community; and lastly, leveraging state-of-the-art social media, web services and other technologies to disseminate the GO resource to the entire biomedical research community. PUBLIC HEALTH RELEVANCE This project aims to provide a complete and integrated picture of what every single gene in a human being does, thus allowing us to better understand the genetic and cellular workings of human health and disease. We do this by developing the Gene Ontology, a computational resource that collects biological knowledge into a large network structure that connects genes with the roles they play. Researchers, clinicians, and sophisticated computer programs use this network to interpret the massive amounts of biomedical and genomic data being generated in experiments and in studies designed to gain key insights into human health.",Gene Ontology Consortium,9444478,U41HG002273,"['Animal Model', 'Area', 'Automation', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Communities', 'Community Developments', 'Computer software', 'Computers', 'Data', 'Data Set', 'Disease', 'Documentation', 'Ensure', 'Environment', 'Family', 'Family member', 'Foundations', 'Gene Family', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Individual', 'Information Resources', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Measurement', 'Medical Research', 'Medicine', 'Metabolism', 'Modeling', 'Modification', 'Mus', 'Network-based', 'Ontology', 'Organism', 'Orthologous Gene', 'Phenotype', 'Phylogenetic Analysis', 'Play', 'Process', 'Provider', 'PubMed', 'Readability', 'Recurrence', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Standardization', 'Structure', 'Technology', 'Testing', 'Training', 'Trees', 'Update', 'Work', 'Zebrafish', 'annotation  system', 'base', 'biological research', 'biological systems', 'biomedical ontology', 'computer based Semantic Analysis', 'computer infrastructure', 'computer program', 'computing resources', 'data resource', 'design', 'experimental study', 'flexibility', 'gene function', 'genomic data', 'human disease', 'improved', 'insight', 'interest', 'interoperability', 'knowledge base', 'lipid metabolism', 'model organisms databases', 'molecular scale', 'ontology development', 'outreach', 'prevent', 'public health relevance', 'scale up', 'social media', 'software development', 'support network', 'text searching', 'tool', 'web services']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U41,2018,2860911,0.35363463351554875
"Gene Ontology Consortium PROJECT SUMMARY Because of the staggering complexity of biological systems, biomedical research is becoming increasingly dependent on knowledge stored in a computable form. The Gene Ontology (GO) is by far the largest knowledgebase of how genes function, and has become a critical component of the computational infrastructure enabling the genomic revolution. It has become nearly indispensible in the interpretation of large- scale molecular measurements in biological research. Crucially, for human health research, GO is also one of a suite of complementary ontologies constructed in such as way to maximally promote interoperability and comparability of data sets. It represents the gene functions and biological processes that are perturbed in human disease, e.g. via the links from Human Phenotype Ontology (HPO) class abnormality of lipid metabolism, defined in relation to the GO class lipid metabolic process (GO_0006629), researchers or clinicians can find the set of genes that are known to be involved in this process. GO is a knowledge resource that can be statistically mined, either standalone or in combination with data from other knowledge resources, which enables experts to discover connections and form new hypotheses from the biological networks GO represents. All knowledge in GO is represented using semantic web technologies and so is amenable to computational integration and consistency checking. The proposed GO knowledge environment will enable a wider community of scientists to contribute to, and to utilize, a common, computable representation of biology. To ensure the knowledge environment meets the requirements of biomedical researchers, we will: a) deliver a comprehensive, detailed, computable knowledgebase of gene function, encoded in the Gene Ontology and annotations (computer-readable statements about the how specific genes function), focusing on human biology; b) provide a “hub” for a broad community of scientists to collaboratively extend, correct and improve the knowledgebase; c) ensure the GO knowledge resource is of the highest quality with regards to depth, breadth and accuracy; d) facilitate the transfer of insights obtained from studies of non-human organisms, such as the mouse and zebrafish, to human biology; and e) enable the scientific community to use the knowledgebase in analyses of large-scale genetic and -omics data. Our aims reflect the essential requirements for realizing the overarching objectives for a biomedical data resource: efficiently capturing and integrating biological knowledge and adhering to the highest possible standard for accuracy and detail; constructing and providing a robust, flexible, powerful, and extensible technological infrastructure available not only for internal use but just as easily by the wider community; and lastly, leveraging state-of-the-art social media, web services and other technologies to disseminate the GO resource to the entire biomedical research community. PUBLIC HEALTH RELEVANCE This project aims to provide a complete and integrated picture of what every single gene in a human being does, thus allowing us to better understand the genetic and cellular workings of human health and disease. We do this by developing the Gene Ontology, a computational resource that collects biological knowledge into a large network structure that connects genes with the roles they play. Researchers, clinicians, and sophisticated computer programs use this network to interpret the massive amounts of biomedical and genomic data being generated in experiments and in studies designed to gain key insights into human health.",Gene Ontology Consortium,9209989,U41HG002273,"['Animal Model', 'Area', 'Automation', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Communities', 'Community Developments', 'Computer software', 'Computers', 'Data', 'Data Set', 'Development', 'Disease', 'Documentation', 'Ensure', 'Environment', 'Family', 'Family member', 'Foundations', 'Gene Family', 'Genes', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Human Biology', 'Individual', 'Information Resources', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Measurement', 'Medical Research', 'Medicine', 'Metabolism', 'Modeling', 'Modification', 'Mus', 'Network-based', 'Ontology', 'Organism', 'Orthologous Gene', 'Phenotype', 'Phylogenetic Analysis', 'Play', 'Process', 'Provider', 'PubMed', 'Readability', 'Recurrence', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Standardization', 'Structure', 'Technology', 'Testing', 'Training', 'Trees', 'Update', 'Work', 'Zebrafish', 'annotation  system', 'base', 'biological research', 'biological systems', 'biomedical ontology', 'computer based Semantic Analysis', 'computer infrastructure', 'computer program', 'computing resources', 'data resource', 'design', 'experimental study', 'flexibility', 'gene function', 'genomic data', 'human disease', 'improved', 'insight', 'interest', 'interoperability', 'knowledge base', 'lipid metabolism', 'model organisms databases', 'molecular scale', 'outreach', 'prevent', 'public health relevance', 'scale up', 'social media', 'software development', 'support network', 'text searching', 'tool', 'web services']",NHGRI,UNIVERSITY OF SOUTHERN CALIFORNIA,U41,2017,3053465,0.35363463351554875
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7185305,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Biology, Other', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Computer information processing', 'Data', 'Databases', 'Depth', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'functional genomics', 'genetic element', 'genome database', 'human disease', 'interest', 'model organisms databases', 'repository', 'size', 'tool']",NHGRI,JACKSON LABORATORY,P41,2007,3146180,0.22734063098988477
"Predicting gene attributes from patterns of annotations. DESCRIPTION (provided by applicant): The Gene Ontology Consortium produces a controlled vocabulary for annotation of gene functions, which has been adopted by many organism-specific gene annotation databases. This allows the prediction of gene function based on partial annotation: if two attributes are strongly correlated in a database, then the presence of one attribute is evidence for the presence of the other. Recent ideas from machine learning, such as dependency networks, may allow more complicated interdependencies between genes and their attributes to be modeled efficiently, which should enable better predictions to be made. Cross-validation will be used to assess the performance of these models, in comparison with linear models and baseline models in which attributes are assumed to be independent. This approach will also be integrated with a probabilistic model of annotation-transfer based on sequence similarity. n/a",Predicting gene attributes from patterns of annotations.,6626288,F32HG002552,"['computer data analysis', ' computer graphics /printing', ' functional /structural genomics', ' genetic models', ' mathematical model', ' model design /development', ' molecular biology information system', ' postdoctoral investigator']",NHGRI,HARVARD UNIVERSITY (MEDICAL SCHOOL),F32,2003,46420,0.14419113307905515
"Predicting gene attributes from patterns of annotations. DESCRIPTION (provided by applicant): The Gene Ontology Consortium produces a controlled vocabulary for annotation of gene functions, which has been adopted by many organism-specific gene annotation databases. This allows the prediction of gene function based on partial annotation: if two attributes are strongly correlated in a database, then the presence of one attribute is evidence for the presence of the other. Recent ideas from machine learning, such as dependency networks, may allow more complicated interdependencies between genes and their attributes to be modeled efficiently, which should enable better predictions to be made. Cross-validation will be used to assess the performance of these models, in comparison with linear models and baseline models in which attributes are assumed to be independent. This approach will also be integrated with a probabilistic model of annotation-transfer based on sequence similarity. n/a",Predicting gene attributes from patterns of annotations.,6488035,F32HG002552,"['computer data analysis', ' computer graphics /printing', ' functional /structural genomics', ' genetic models', ' mathematical model', ' model design /development', ' molecular biology information system', ' postdoctoral investigator']",NHGRI,HARVARD UNIVERSITY (MEDICAL SCHOOL),F32,2002,38320,0.14419113307905515
"Biomedical Ontology and Tools for Database Curation DESCRIPTION (provided by applicant): This proposal describes a new tool for text data mining-a biomedical language ontology and integrated natural-language-processing methods. Our long-term goal is to provide resources for biomedical knowledge discovery from text. Our immediate goal is to provide a knowledge discovery tool for the curation of organism databases such as the Genome Database (SGD). The proposed research not only serves the research needs of the SGD community, it also helps the broader biomedical community exploit the strengths of the comparative approach to biological research. The hypothesis of this proposal is that knowledge discovery from biomedical text requires a knowledge base that integrates both genomic and linguistic information. This hypothesis is based on two observations: (a) the language of biomedicine, like all natural language, is complex in structure and morphology (the basic units of meaning) and poses problems of synonymy (several terms having the same meaning), polysemy (a term having more than one meaning), hypernymy (one term being more general than another), hyponymy (one term being more specific than another), denotation (what a term refers to in contrast to what it means), and denotation and description (different ways of referring to the same thing); and (b) important biomedical knowledge sources, such as the Gene Ontology (GO), are expressed in natural language. The specific aims of the proposed project are to: 1. Extend an existing biomedical language ontology to include genomic and linguistic data from SGD; 2. Use this ontology to discover, in full-text articles made available by SGD, information about the molecular function of yeast gene products that can be inferred from direct experimental assays; 3. Evaluate the effectiveness of the new tool and methods by comparing its results to those of the SGD curators for gene products that have GO functional annotations with evidence code IDA (Inferred from Direct Assay). n/a",Biomedical Ontology and Tools for Database Curation,6885487,R43HG003600,"['computer program /software', 'computer system design /evaluation', 'fungal genetics', 'information retrieval', 'information system analysis', 'molecular biology information system', 'yeasts']",NHGRI,"CONVERSPEECH, LLC",R43,2005,99250,0.20897537538015176
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8541935,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2012,100000,0.32647528758831174
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8737919,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2014,468122,0.32647528758831174
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8541872,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2013,330290,0.32647528758831174
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8330927,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2012,246312,0.32647528758831174
"Extension of the Sequence Ontology:  Preparing for the (re) sequencing revolution    DESCRIPTION (provided by applicant): High throughput sequencing technologies have made possible both personal human genome sequencing and rapid re-sequencing of many organisms. The dramatic increase in the throughputs of these technologies demands equal progress in the technologies used to manage their outputs. Over the last decade ontologies have emerged as indispensible tools for the management of large biomedical datasets. The Sequence Ontology (SO) is world's most widely used ontology for describing sequence annotations. The advent of rapid genome re-sequencing has made it essential that SO also provide the means to describe sequence variants. This renewal submission thus has two broad goals: (1) extend SO into the realm of genomic variant annotation, and (2) harmonize SO with recent developments in the field of biomedical ontology and genomics. Both are essential if we are to meet the data management needs of researchers seeking to exchange, compare and analyze re-sequenced genomes and their variants in the context of existing gene annotations.        The gigantic datasets produced by personal human genome sequencing present daunting challenges for data management. This proposal seeks funds to extend tools for describing genome annotations, into the realm of sequence variation. Doing so will facilitate exchange, comparisons and analyses of re-sequenced genomes.         ",Extension of the Sequence Ontology:  Preparing for the (re) sequencing revolution,8462288,R01HG004341,"['Adoption', 'Animal Model', 'Biological', 'Biology', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Eye', 'Funding', 'Genes', 'Genome', 'Genomics', 'Goals', 'Human Genome', 'Information Management', 'Ontology', 'Organism', 'Output', 'Process', 'Property', 'Publications', 'Publishing', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Structure', 'Techniques', 'Technology', 'Terminology', 'Time', 'United States National Institutes of Health', 'Validation', 'Variant', 'Work', 'base', 'biomedical informatics', 'biomedical ontology', 'data management', 'file format', 'genome annotation', 'genome sequencing', 'information organization', 'meetings', 'novel', 'success', 'tool']",NHGRI,UNIVERSITY OF UTAH,R01,2013,279985,0.2011357797472828
"Extension of the Sequence Ontology:  Preparing for the (re) sequencing revolution    DESCRIPTION (provided by applicant): High throughput sequencing technologies have made possible both personal human genome sequencing and rapid re-sequencing of many organisms. The dramatic increase in the throughputs of these technologies demands equal progress in the technologies used to manage their outputs. Over the last decade ontologies have emerged as indispensible tools for the management of large biomedical datasets. The Sequence Ontology (SO) is world's most widely used ontology for describing sequence annotations. The advent of rapid genome re-sequencing has made it essential that SO also provide the means to describe sequence variants. This renewal submission thus has two broad goals: (1) extend SO into the realm of genomic variant annotation, and (2) harmonize SO with recent developments in the field of biomedical ontology and genomics. Both are essential if we are to meet the data management needs of researchers seeking to exchange, compare and analyze re-sequenced genomes and their variants in the context of existing gene annotations.        The gigantic datasets produced by personal human genome sequencing present daunting challenges for data management. This proposal seeks funds to extend tools for describing genome annotations, into the realm of sequence variation. Doing so will facilitate exchange, comparisons and analyses of re-sequenced genomes.         ",Extension of the Sequence Ontology:  Preparing for the (re) sequencing revolution,8309860,R01HG004341,"['Adoption', 'Animal Model', 'Biological', 'Biology', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Eye', 'Funding', 'Genes', 'Genome', 'Genomics', 'Goals', 'Human Genome', 'Information Management', 'Ontology', 'Organism', 'Output', 'Process', 'Property', 'Publications', 'Publishing', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Structure', 'Techniques', 'Technology', 'Terminology', 'Time', 'United States National Institutes of Health', 'Validation', 'Variant', 'Work', 'base', 'biomedical informatics', 'biomedical ontology', 'data management', 'file format', 'genome sequencing', 'information organization', 'meetings', 'novel', 'success', 'tool']",NHGRI,UNIVERSITY OF UTAH,R01,2012,294487,0.2011357797472828
"Extension of the Sequence Ontology:  Preparing for the (re) sequencing revolution    DESCRIPTION (provided by applicant): High throughput sequencing technologies have made possible both personal human genome sequencing and rapid re-sequencing of many organisms. The dramatic increase in the throughputs of these technologies demands equal progress in the technologies used to manage their outputs. Over the last decade ontologies have emerged as indispensible tools for the management of large biomedical datasets. The Sequence Ontology (SO) is world's most widely used ontology for describing sequence annotations. The advent of rapid genome re-sequencing has made it essential that SO also provide the means to describe sequence variants. This renewal submission thus has two broad goals: (1) extend SO into the realm of genomic variant annotation, and (2) harmonize SO with recent developments in the field of biomedical ontology and genomics. Both are essential if we are to meet the data management needs of researchers seeking to exchange, compare and analyze re-sequenced genomes and their variants in the context of existing gene annotations.      PUBLIC HEALTH RELEVANCE: The gigantic datasets produced by personal human genome sequencing present daunting challenges for data management. This proposal seeks funds to extend tools for describing genome annotations, into the realm of sequence variation. Doing so will facilitate exchange, comparisons and analyses of re-sequenced genomes.           The gigantic datasets produced by personal human genome sequencing present daunting challenges for data management. This proposal seeks funds to extend tools for describing genome annotations, into the realm of sequence variation. Doing so will facilitate exchange, comparisons and analyses of re-sequenced genomes.         ",Extension of the Sequence Ontology:  Preparing for the (re) sequencing revolution,8148118,R01HG004341,"['Adoption', 'Animal Model', 'Biological', 'Biology', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Eye', 'Funding', 'Genes', 'Genome', 'Genomics', 'Goals', 'Human Genome', 'Information Management', 'Ontology', 'Organism', 'Output', 'Process', 'Property', 'Publications', 'Publishing', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Structure', 'Techniques', 'Technology', 'Terminology', 'Time', 'United States National Institutes of Health', 'Validation', 'Variant', 'Work', 'base', 'biomedical informatics', 'biomedical ontology', 'data management', 'file format', 'genome sequencing', 'information organization', 'meetings', 'novel', 'success', 'tool']",NHGRI,UNIVERSITY OF UTAH,R01,2011,300000,0.16127717815028617
"Automated Integration of Biomedical Knowledge Today, ontologies are critical instruments for biomedical investigators, especially in those areas, such as cancer research, that require the command of a vast amount of information and a systemic approach to the design and interpretation of experiments. In fact, ontologies are proliferating in all areas of biomedical research, offering both challenges and opportunities. One of the principal challenges of this field stems from the fact that ontologies are developed in isolation, rendering it impossible to move, for instance, from genes to organisms, to diseases, to drugs. The National Center for Biomedical Ontology (NCBO) represents a fundamental endeavor in the collection, coordination and distribution of biomedical ontologies and offers an unparalleled opportunity to combine these biomedical ontologies into a single search space where genetic, anatomic, molecular and pharmacological information can be seamlessly explored and exploited as a holistic representation of biomedical knowledge. Unfortunately, ontology integration using standard means of manual curation is a labor intensive task, unable to scale up and keep up with the current growth rate of biomedical ontologies. We have developed a systematic framework for automated ontology engineering based on information theory, and we have successfully applied it to the analysis and engineering of Gene Ontology (GO), the development gene and protein databases, and the identification of peripheral biomarkers of disease progression and drug response. This project brings together a unique group of competences, ranging from ontology engineering, statistical signal processing, bioinformatics, cancer research, and clinical pharmacogenomics, to develop a principled method, grounded on the mathematics of information theory, to automatically combine and integrate biomedical ontologies and implement it as part of the NCBO architecture Ontologies are critical instruments for biomedical investigators especially in those areas, such as cancer research, that require a vast amount of information and a systemic approach to the design and interpretation of their experiments. In collaboration with the National Center for Biomedical Ontology (NCBO), this project will develop a principled method, grounded on the mathematics of information theory, to automatically combine biomedical ontologies. As a result, this project will integrate biomedical knowledge along dimensions that are today isolated and, in so doing, it will empower investigators with a new holistic understanding of disease, it will fast track the clinical  translation of biological discoveries, and it will change the approach to discovery, especially for those diseases that, like cancer, require a systemic view of their biological mechanisms.",Automated Integration of Biomedical Knowledge,7558468,R01HG004836,"['Anatomy', 'Architecture', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Research', 'Classification', 'Clinical', 'Collaborations', 'Collection', 'Colorectal Cancer', 'Competence', 'Complex', 'Development', 'Dimensions', 'Disease', 'Disease Progression', 'Engineered Gene', 'Engineering', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Growth', 'Human', 'Information Theory', 'Internet', 'Java', 'Knowledge', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Mathematics', 'Methods', 'Molecular', 'Ontology', 'Organism', 'Peripheral', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Proliferating', 'Protein Databases', 'Research Infrastructure', 'Research Personnel', 'Services', 'Side', 'Structure', 'Testing', 'Text', 'Tissues', 'Translations', 'anticancer research', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'computerized data processing', 'design', 'empowered', 'graphical user interface', 'insight', 'instrument', 'open source', 'programs', 'repository', 'research study', 'response', 'scale up', 'statistics', 'stem']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2009,428078,0.4157577558996275
"Automated Integration of Biomedical Knowledge Today, ontologies are critical instruments for biomedical investigators, especially in those areas, such as cancer research, that require the command of a vast amount of information and a systemic approach to the design and interpretation of experiments. In fact, ontologies are proliferating in all areas of biomedical research, offering both challenges and opportunities. One of the principal challenges of this field stems from the fact that ontologies are developed in isolation, rendering it impossible to move, for instance, from genes to organisms, to diseases, to drugs. The National Center for Biomedical Ontology (NCBO) represents a fundamental endeavor in the collection, coordination and distribution of biomedical ontologies and offers an unparalleled opportunity to combine these biomedical ontologies into a single search space where genetic, anatomic, molecular and pharmacological information can be seamlessly explored and exploited as a holistic representation of biomedical knowledge. Unfortunately, ontology integration using standard means of manual curation is a labor intensive task, unable to scale up and keep up with the current growth rate of biomedical ontologies. We have developed a systematic framework for automated ontology engineering based on information theory, and we have successfully applied it to the analysis and engineering of Gene Ontology (GO), the development gene and protein databases, and the identification of peripheral biomarkers of disease progression and drug response. This project brings together a unique group of competences, ranging from ontology engineering, statistical signal processing, bioinformatics, cancer research, and clinical pharmacogenomics, to develop a principled method, grounded on the mathematics of information theory, to automatically combine and integrate biomedical ontologies and implement it as part of the NCBO architecture Ontologies are critical instruments for biomedical investigators especially in those areas, such as cancer research, that require a vast amount of information and a systemic approach to the design and interpretation of their experiments. In collaboration with the National Center for Biomedical Ontology (NCBO), this project will develop a principled method, grounded on the mathematics of information theory, to automatically combine biomedical ontologies. As a result, this project will integrate biomedical knowledge along dimensions that are today isolated and, in so doing, it will empower investigators with a new holistic understanding of disease, it will fast track the clinical  translation of biological discoveries, and it will change the approach to discovery, especially for those diseases that, like cancer, require a systemic view of their biological mechanisms.",Automated Integration of Biomedical Knowledge,7945368,R01HG004836,"['Anatomy', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Research', 'Clinical', 'Collaborations', 'Collection', 'Colorectal Cancer', 'Communities', 'Competence', 'Complex', 'Computer software', 'Consultations', 'Controlled Vocabulary', 'Dana-Farber Cancer Institute', 'Data', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease Progression', 'Engineered Gene', 'Engineering', 'Fostering', 'Future', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Growth', 'Human', 'In Vitro', 'Information Theory', 'Internet', 'Java', 'Knowledge', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Molecular', 'National Cancer Institute', 'Nature', 'Ontology', 'Organism', 'Peripheral', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Proliferating', 'Protein Databases', 'Research Infrastructure', 'Research Personnel', 'Services', 'Structure', 'Testing', 'Text', 'Tissues', 'Translations', 'Validation', 'anticancer research', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'design', 'empowered', 'gene function', 'graphical user interface', 'information organization', 'instrument', 'interoperability', 'novel', 'open source', 'repository', 'research study', 'response', 'scale up', 'sound', 'statistics', 'stem']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2010,428079,0.4157577558996275
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,9145523,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'gene product', 'genome-wide', 'improved', 'killings', 'novel', 'novel anticancer drug', 'prediction algorithm', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2016,48576,0.41337722686475536
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,8951600,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'genome-wide', 'improved', 'killings', 'novel', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2015,39304,0.41337722686475536
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,8644512,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'genome-wide', 'improved', 'killings', 'novel', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2014,35110,0.41337722686475536
"Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration    Description (provided by applicant): Research in the design and implementation of ""Neural ElectroMagnetic Ontologies"" (NEMO) will address a critical need for tools to support representation, storage, and sharing of brain electromagnetic data. Electro- encephalography (EEG) and event-related potentials (ERP) are venerable techniques for cognitive and clinical research on human brain function. To realize their full potential, however, it will be necessary to address some long-standing challenges in comparing results across experiments and research laboratories. NEMO will address this need by providing ERP ontologies that can be used for meta-analysis of patterns across experiment contexts and research labs. Given the widespread use of EEG and ERP methods, and their clinical as well as research applications, development of such a system is both timely and significant. System design and implementation will rest on six specific aims. The first goal is to develop rigorous procedures for classification and labeling of electrophysiological patterns (event-related potentials, or ERPs) (Aim 1). The methods and tools that are developed initially for classification and labeling of surface (sensor- level) data will then be extended to support classification of data in source (anatomical) space (Aim 2). Next, we will represent the concepts that define ERP patterns as formal logics, or ""ontologies,"" and will use those concepts to describe the ERP patterns. Relational databases will be modeled based on the ontologies to support high-level questions about the nature of ERP patterns and the relationships between patterns that are associated with different lab, experiment, and analysis contexts (Aim 3). The application domain for our project is reading and language. We have established a consortium of experts in this area who will contribute EEG and ERP data from experimental studies and will collaborate with us on the design and testing, and evaluation of the tools developed for this project. The practical scientific aim will be to conduct meta-analyses of ERP patterns in reading and language. In addition to re-analyses of existing cross-lab data, new experiment paradigms (adapted from the fBIRN project) will be carried out across research sites to calibrate data acquisition and preprocessing methods, and to test the robustness of patterns across different experiment contexts (Aim 4). Initially, we will develop a different ontology for each representational space (e.g., sensor and source space) and each analysis method. Then, we will capture the semantic mappings between different sets of patterns (different ontologies) using data mining (Aim 5). To support this work, we will develop an integrated tool environment for storage and management of EEG and ERP data and meta-data, measure generation and labeling, ontology development, and meta-analysis. This environment will be web-accessible so that partners will have shared access to the project data, analysis tools, ontologies, and meta-analysis results (Aim 6). At the end of this project, the ontologies, annotated database, tools, and technologies will be made available to the larger research community. PUBLIC HEALTH RELEVANCE The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experiment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing.            Relevance The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing. 1",Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration,8269994,R01EB007684,"['Address', 'Area', 'Auditory', 'Automatic Data Processing', 'Brain', 'Brain imaging', 'Brodmann&apos', 's area', 'Calibration', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Comprehension', 'Computer software', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Electromagnetics', 'Environment', 'Equipment', 'Evaluation', 'Event-Related Potentials', 'Generations', 'Goals', 'Head', 'Health', 'Human', 'Internet', 'Knowledge', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Lead', 'Location', 'Logic', 'Maps', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Nature', 'Neuropsychology', 'Neurosciences', 'Neurosciences Research', 'Online Systems', 'Ontology', 'Pattern', 'Procedures', 'Process', 'Reading', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Resource Sharing', 'Rest', 'Scalp structure', 'Scanning', 'Semantics', 'Series', 'Simulate', 'Site', 'Solutions', 'Source', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Translations', 'Visual', 'Work', 'base', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'density', 'design', 'encephalography', 'evaluation/testing', 'information organization', 'interdisciplinary approach', 'interest', 'member', 'neurodevelopment', 'neuroinformatics', 'relating to nervous system', 'relational database', 'research study', 'sensor', 'spatiotemporal', 'success', 'task analysis', 'tool', 'tool development', 'web-accessible']",NIBIB,UNIVERSITY OF OREGON,R01,2012,487090,0.2678679876690159
"Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration    Description (provided by applicant): Research in the design and implementation of ""Neural ElectroMagnetic Ontologies"" (NEMO) will address a critical need for tools to support representation, storage, and sharing of brain electromagnetic data. Electro- encephalography (EEG) and event-related potentials (ERP) are venerable techniques for cognitive and clinical research on human brain function. To realize their full potential, however, it will be necessary to address some long-standing challenges in comparing results across experiments and research laboratories. NEMO will address this need by providing ERP ontologies that can be used for meta-analysis of patterns across experiment contexts and research labs. Given the widespread use of EEG and ERP methods, and their clinical as well as research applications, development of such a system is both timely and significant. System design and implementation will rest on six specific aims. The first goal is to develop rigorous procedures for classification and labeling of electrophysiological patterns (event-related potentials, or ERPs) (Aim 1). The methods and tools that are developed initially for classification and labeling of surface (sensor- level) data will then be extended to support classification of data in source (anatomical) space (Aim 2). Next, we will represent the concepts that define ERP patterns as formal logics, or ""ontologies,"" and will use those concepts to describe the ERP patterns. Relational databases will be modeled based on the ontologies to support high-level questions about the nature of ERP patterns and the relationships between patterns that are associated with different lab, experiment, and analysis contexts (Aim 3). The application domain for our project is reading and language. We have established a consortium of experts in this area who will contribute EEG and ERP data from experimental studies and will collaborate with us on the design and testing, and evaluation of the tools developed for this project. The practical scientific aim will be to conduct meta-analyses of ERP patterns in reading and language. In addition to re-analyses of existing cross-lab data, new experiment paradigms (adapted from the fBIRN project) will be carried out across research sites to calibrate data acquisition and preprocessing methods, and to test the robustness of patterns across different experiment contexts (Aim 4). Initially, we will develop a different ontology for each representational space (e.g., sensor and source space) and each analysis method. Then, we will capture the semantic mappings between different sets of patterns (different ontologies) using data mining (Aim 5). To support this work, we will develop an integrated tool environment for storage and management of EEG and ERP data and meta-data, measure generation and labeling, ontology development, and meta-analysis. This environment will be web-accessible so that partners will have shared access to the project data, analysis tools, ontologies, and meta-analysis results (Aim 6). At the end of this project, the ontologies, annotated database, tools, and technologies will be made available to the larger research community. PUBLIC HEALTH RELEVANCE The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experiment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing.            Relevance The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing. 1",Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration,8069619,R01EB007684,"['Address', 'Area', 'Auditory', 'Automatic Data Processing', 'Brain', 'Brain imaging', 'Brodmann&apos', 's area', 'Calibration', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Comprehension', 'Computer software', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Electromagnetics', 'Environment', 'Equipment', 'Evaluation', 'Event-Related Potentials', 'Generations', 'Goals', 'Head', 'Health', 'Human', 'Internet', 'Knowledge', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Lead', 'Location', 'Logic', 'Maps', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Nature', 'Neuropsychology', 'Neurosciences', 'Neurosciences Research', 'Online Systems', 'Ontology', 'Pattern', 'Procedures', 'Process', 'Reading', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Resource Sharing', 'Rest', 'Scalp structure', 'Scanning', 'Semantics', 'Series', 'Simulate', 'Site', 'Solutions', 'Source', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Translations', 'Visual', 'Work', 'base', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'density', 'design', 'encephalography', 'evaluation/testing', 'information organization', 'interdisciplinary approach', 'interest', 'member', 'neurodevelopment', 'neuroinformatics', 'relating to nervous system', 'relational database', 'research study', 'sensor', 'spatiotemporal', 'success', 'task analysis', 'tool', 'tool development', 'web-accessible']",NIBIB,UNIVERSITY OF OREGON,R01,2011,515495,0.2678679876690159
"Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration    Description (provided by applicant): Research in the design and implementation of ""Neural ElectroMagnetic Ontologies"" (NEMO) will address a critical need for tools to support representation, storage, and sharing of brain electromagnetic data. Electro- encephalography (EEG) and event-related potentials (ERP) are venerable techniques for cognitive and clinical research on human brain function. To realize their full potential, however, it will be necessary to address some long-standing challenges in comparing results across experiments and research laboratories. NEMO will address this need by providing ERP ontologies that can be used for meta-analysis of patterns across experiment contexts and research labs. Given the widespread use of EEG and ERP methods, and their clinical as well as research applications, development of such a system is both timely and significant. System design and implementation will rest on six specific aims. The first goal is to develop rigorous procedures for classification and labeling of electrophysiological patterns (event-related potentials, or ERPs) (Aim 1). The methods and tools that are developed initially for classification and labeling of surface (sensor- level) data will then be extended to support classification of data in source (anatomical) space (Aim 2). Next, we will represent the concepts that define ERP patterns as formal logics, or ""ontologies,"" and will use those concepts to describe the ERP patterns. Relational databases will be modeled based on the ontologies to support high-level questions about the nature of ERP patterns and the relationships between patterns that are associated with different lab, experiment, and analysis contexts (Aim 3). The application domain for our project is reading and language. We have established a consortium of experts in this area who will contribute EEG and ERP data from experimental studies and will collaborate with us on the design and testing, and evaluation of the tools developed for this project. The practical scientific aim will be to conduct meta-analyses of ERP patterns in reading and language. In addition to re-analyses of existing cross-lab data, new experiment paradigms (adapted from the fBIRN project) will be carried out across research sites to calibrate data acquisition and preprocessing methods, and to test the robustness of patterns across different experiment contexts (Aim 4). Initially, we will develop a different ontology for each representational space (e.g., sensor and source space) and each analysis method. Then, we will capture the semantic mappings between different sets of patterns (different ontologies) using data mining (Aim 5). To support this work, we will develop an integrated tool environment for storage and management of EEG and ERP data and meta-data, measure generation and labeling, ontology development, and meta-analysis. This environment will be web-accessible so that partners will have shared access to the project data, analysis tools, ontologies, and meta-analysis results (Aim 6). At the end of this project, the ontologies, annotated database, tools, and technologies will be made available to the larger research community. PUBLIC HEALTH RELEVANCE The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experiment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing.            Relevance The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing. 1",Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration,7816664,R01EB007684,"['Address', 'Area', 'Arts', 'Auditory', 'Automatic Data Processing', 'Brain', 'Brain imaging', 'Brodmann&apos', 's area', 'Calibration', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Comprehension', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Electromagnetics', 'Environment', 'Equipment', 'Evaluation', 'Event-Related Potentials', 'Generations', 'Goals', 'Head', 'Human', 'Internet', 'Knowledge', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Lead', 'Location', 'Logic', 'Maps', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Nature', 'Neuropsychology', 'Neurosciences', 'Neurosciences Research', 'Online Systems', 'Ontology', 'Pattern', 'Procedures', 'Process', 'Reading', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Resource Sharing', 'Rest', 'Scalp structure', 'Scanning', 'Semantics', 'Series', 'Simulate', 'Site', 'Solutions', 'Source', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Translations', 'Visual', 'Work', 'base', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'density', 'design', 'encephalography', 'evaluation/testing', 'information organization', 'interdisciplinary approach', 'interest', 'member', 'neurodevelopment', 'neuroinformatics', 'public health relevance', 'relating to nervous system', 'relational database', 'research study', 'sensor', 'spatiotemporal', 'success', 'task analysis', 'tool', 'tool development', 'web-accessible', 'wiki']",NIBIB,UNIVERSITY OF OREGON,R01,2010,566478,0.2678679876690159
"Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration    Description (provided by applicant): Research in the design and implementation of ""Neural ElectroMagnetic Ontologies"" (NEMO) will address a critical need for tools to support representation, storage, and sharing of brain electromagnetic data. Electro- encephalography (EEG) and event-related potentials (ERP) are venerable techniques for cognitive and clinical research on human brain function. To realize their full potential, however, it will be necessary to address some long-standing challenges in comparing results across experiments and research laboratories. NEMO will address this need by providing ERP ontologies that can be used for meta-analysis of patterns across experiment contexts and research labs. Given the widespread use of EEG and ERP methods, and their clinical as well as research applications, development of such a system is both timely and significant. System design and implementation will rest on six specific aims. The first goal is to develop rigorous procedures for classification and labeling of electrophysiological patterns (event-related potentials, or ERPs) (Aim 1). The methods and tools that are developed initially for classification and labeling of surface (sensor- level) data will then be extended to support classification of data in source (anatomical) space (Aim 2). Next, we will represent the concepts that define ERP patterns as formal logics, or ""ontologies,"" and will use those concepts to describe the ERP patterns. Relational databases will be modeled based on the ontologies to support high-level questions about the nature of ERP patterns and the relationships between patterns that are associated with different lab, experiment, and analysis contexts (Aim 3). The application domain for our project is reading and language. We have established a consortium of experts in this area who will contribute EEG and ERP data from experimental studies and will collaborate with us on the design and testing, and evaluation of the tools developed for this project. The practical scientific aim will be to conduct meta-analyses of ERP patterns in reading and language. In addition to re-analyses of existing cross-lab data, new experiment paradigms (adapted from the fBIRN project) will be carried out across research sites to calibrate data acquisition and preprocessing methods, and to test the robustness of patterns across different experiment contexts (Aim 4). Initially, we will develop a different ontology for each representational space (e.g., sensor and source space) and each analysis method. Then, we will capture the semantic mappings between different sets of patterns (different ontologies) using data mining (Aim 5). To support this work, we will develop an integrated tool environment for storage and management of EEG and ERP data and meta-data, measure generation and labeling, ontology development, and meta-analysis. This environment will be web-accessible so that partners will have shared access to the project data, analysis tools, ontologies, and meta-analysis results (Aim 6). At the end of this project, the ontologies, annotated database, tools, and technologies will be made available to the larger research community. PUBLIC HEALTH RELEVANCE The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experiment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing.            Relevance The practical goal for the NEMO project is to build an ontology database to support data sharing and meta- analysis of EEG and ERP results. The ability to describe brain electrophysiological patterns from different research laboratories and different experment contexts within a common framework will have immediate benefits for the neuroscience community, as well as long-term benefits for neuroscience research and for scientific areas with similar requirements for robust data representation and integration, and data and resources sharing. 1",Neural ElectroMagnetic Ontologies: ERP Knowledge Representation & Integration,7585137,R01EB007684,"['Address', 'Area', 'Arts', 'Auditory', 'Automatic Data Processing', 'Brain', 'Brain imaging', 'Brodmann&apos', 's area', 'Calibration', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Cognitive', 'Collaborations', 'Communities', 'Comprehension', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Electromagnetics', 'Environment', 'Equipment', 'Evaluation', 'Event-Related Potentials', 'Generations', 'Goals', 'Head', 'Human', 'Internet', 'Knowledge', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Lead', 'Location', 'Logic', 'Maps', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Nature', 'Neuropsychology', 'Neurosciences', 'Neurosciences Research', 'Online Systems', 'Ontology', 'Pattern', 'Procedures', 'Process', 'Reading', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Resource Sharing', 'Rest', 'Scalp structure', 'Scanning', 'Semantics', 'Series', 'Simulate', 'Site', 'Solutions', 'Source', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Translations', 'Visual', 'Work', 'base', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'density', 'design', 'encephalography', 'evaluation/testing', 'information organization', 'interdisciplinary approach', 'interest', 'member', 'neurodevelopment', 'neuroinformatics', 'public health relevance', 'relating to nervous system', 'research study', 'sensor', 'spatiotemporal', 'success', 'task analysis', 'tool', 'tool development', 'web-accessible', 'wiki']",NIBIB,UNIVERSITY OF OREGON,R01,2009,597692,0.2678679876690159
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,8076789,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical ontology', 'biomedical scientist', 'design', 'information organization', 'innovation', 'knowledge base', 'meetings', 'member', 'next generation', 'open source', 'repository', 'research and development', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2010,956625,0.3356457313011421
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,7660538,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical ontology', 'biomedical scientist', 'design', 'information organization', 'innovation', 'knowledge base', 'meetings', 'member', 'next generation', 'open source', 'repository', 'research and development', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2009,688362,0.3356457313011421
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,7475421,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Class', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Facility Construction Funding Category', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Numbers', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical resource', 'concept', 'design', 'information organization', 'innovation', 'knowledge base', 'member', 'next generation', 'open source', 'repository', 'research and development', 'size', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2007,160000,0.3356457313011421
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,7248464,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Class', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Facility Construction Funding Category', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Numbers', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical resource', 'concept', 'design', 'information organization', 'innovation', 'knowledge base', 'member', 'next generation', 'open source', 'repository', 'research and development', 'size', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2007,693808,0.3356457313011421
"Services to support the OBO foundry standards PROJECT SUMMARY/ABSTRACT The Open Biomedical Ontologies (OBO) Foundry is a community organized project that aims to facilitate the discovery, development, application, harmonization, interoperability and sharing of ontologies. OBO ontologies are widely used as a standard for knowledge representation in a broad range of domains relevant to the NIH basic, translational, and clinical research mission. They cover for example gene functions (Gene Ontology, GO), diseases and phenotypes (Disease Ontology, DO; Human Phenotype Ontology, HP; Uberon Anatomy Ontology), assay types (Ontology for Biomedical Investigations, OBI), and relationships connecting these entities, both within and across ontologies (Relationship Ontology, RO). For over a decade, OBO has provided a variety of widely used services to the community, including 1) the OBO registry, which collects standardized metadata for each member ontology such as domain, scope, license, point of contact, etc., thus enhancing findability of each ontology, 2) configurable Persistent URLs (PURLs), which provide an unchanging address for ontologies and ontology classes, enhancing accessibility and reuse, 3) optional content hosting for OBO ontologies that want to take advantage of centrally managed versioning, 4) standardized software tools that make it easy to follow best practices for ontology development, 5) OBO principles, guidelines and best practices, designed to enhance quality and interoperability, and 6) an outreach and coordination effort to mediate between different member ontologies with the goal to coordinate and reduce overlap, through a central email list and regular teleconferences. The present proposal will provide time-limited, catalytic support to increase robustness of existing services by upgrading critical infrastructure on which they are based, by defining and applying standards for metadata and PURL management, and by applying best practices from software engineering to increase maintainability of the codebase. Second, we will introduce new capabilities into our service infrastructure to add automated quality controls to ontologies (individually and in groups), enhance the integration between our services and standardized tools, and add monitoring and metrics. Third, we will perform outreach and training efforts to increase the ability of the community to participate in the OBO project. In accomplishing these aims we will continue to keep our operating costs extremely low, and to freely share the tools and resources we build. PROJECT NARRATIVE/PUBLIC HEALTH RELEVANCE Ontologies provide a precise language to describe scientific findings, and have successfully been used by researchers to share and compare their results. Different ontologies describe different aspects of knowledge, sometimes in an incompatible way. Here we propose to implement a set of services that allows different ontology producers to develop ontologies in a standardized fashion that will make it easier to use them together.",Services to support the OBO foundry standards,9568005,R24HG010032,"['Address', 'Anatomy', 'Basic Science', 'Biological Assay', 'Biological Process', 'Biology', 'Clinical Research', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Development', 'Disease', 'Documentation', 'Education and Outreach', 'Electronic Mail', 'Ensure', 'Funding', 'Gene Components', 'Genes', 'Goals', 'Guidelines', 'Human', 'Individual', 'Investigation', 'Investments', 'Knowledge', 'Language', 'Licensing', 'Maintenance', 'Measures', 'Mediating', 'Metadata', 'Mission', 'Molecular', 'Monitor', 'Ontology', 'Phenotype', 'Publishing', 'Quality Control', 'Registries', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Running', 'Services', 'Software Engineering', 'Software Tools', 'Standardization', 'System', 'Teleconferences', 'Testing', 'Time', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Update', 'base', 'biomedical ontology', 'cost', 'design', 'disease phenotype', 'experience', 'gene function', 'gene product', 'improved', 'information organization', 'interoperability', 'member', 'ontology development', 'open source', 'outreach', 'public health relevance', 'success', 'tool', 'volunteer']",NHGRI,LA JOLLA INSTITUTE FOR IMMUNOLOGY,R24,2018,464271,0.4492157033087422
"Services to support the OBO foundry standards PROJECT SUMMARY/ABSTRACT The Open Biomedical Ontologies (OBO) Foundry is a community organized project that aims to facilitate the discovery, development, application, harmonization, interoperability and sharing of ontologies. OBO ontologies are widely used as a standard for knowledge representation in a broad range of domains relevant to the NIH basic, translational, and clinical research mission. They cover for example gene functions (Gene Ontology, GO), diseases and phenotypes (Disease Ontology, DO; Human Phenotype Ontology, HP; Uberon Anatomy Ontology), assay types (Ontology for Biomedical Investigations, OBI), and relationships connecting these entities, both within and across ontologies (Relationship Ontology, RO). For over a decade, OBO has provided a variety of widely used services to the community, including 1) the OBO registry, which collects standardized metadata for each member ontology such as domain, scope, license, point of contact, etc., thus enhancing findability of each ontology, 2) configurable Persistent URLs (PURLs), which provide an unchanging address for ontologies and ontology classes, enhancing accessibility and reuse, 3) optional content hosting for OBO ontologies that want to take advantage of centrally managed versioning, 4) standardized software tools that make it easy to follow best practices for ontology development, 5) OBO principles, guidelines and best practices, designed to enhance quality and interoperability, and 6) an outreach and coordination effort to mediate between different member ontologies with the goal to coordinate and reduce overlap, through a central email list and regular teleconferences. The present proposal will provide time-limited, catalytic support to increase robustness of existing services by upgrading critical infrastructure on which they are based, by defining and applying standards for metadata and PURL management, and by applying best practices from software engineering to increase maintainability of the codebase. Second, we will introduce new capabilities into our service infrastructure to add automated quality controls to ontologies (individually and in groups), enhance the integration between our services and standardized tools, and add monitoring and metrics. Third, we will perform outreach and training efforts to increase the ability of the community to participate in the OBO project. In accomplishing these aims we will continue to keep our operating costs extremely low, and to freely share the tools and resources we build. PROJECT NARRATIVE/PUBLIC HEALTH RELEVANCE Ontologies provide a precise language to describe scientific findings, and have successfully been used by researchers to share and compare their results. Different ontologies describe different aspects of knowledge, sometimes in an incompatible way. Here we propose to implement a set of services that allows different ontology producers to develop ontologies in a standardized fashion that will make it easier to use them together.",Services to support the OBO foundry standards,9385259,R24HG010032,"['Address', 'Anatomy', 'Basic Science', 'Biological Assay', 'Biological Process', 'Biology', 'Clinical Research', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Development', 'Disease', 'Documentation', 'Education and Outreach', 'Electronic Mail', 'Ensure', 'Funding', 'Gene Components', 'Genes', 'Goals', 'Guidelines', 'Human', 'Individual', 'Investigation', 'Investments', 'Knowledge', 'Language', 'Licensing', 'Maintenance', 'Measures', 'Mediating', 'Metadata', 'Mission', 'Molecular', 'Monitor', 'Ontology', 'Phenotype', 'Publishing', 'Quality Control', 'Registries', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Running', 'Services', 'Software Engineering', 'Software Tools', 'Standardization', 'System', 'Teleconferences', 'Testing', 'Time', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Update', 'base', 'biomedical ontology', 'cost', 'design', 'disease phenotype', 'experience', 'gene function', 'gene product', 'improved', 'information organization', 'interoperability', 'member', 'open source', 'outreach', 'public health relevance', 'success', 'tool', 'volunteer']",NHGRI,LA JOLLA INSTITUTE FOR IMMUNOLOGY,R24,2017,484515,0.4492157033087422
"Services to support the OBO foundry standards PROJECT SUMMARY/ABSTRACT The Open Biomedical Ontologies (OBO) Foundry is a community organized project that aims to facilitate the discovery, development, application, harmonization, interoperability and sharing of ontologies. OBO ontologies are widely used as a standard for knowledge representation in a broad range of domains relevant to the NIH basic, translational, and clinical research mission. They cover for example gene functions (Gene Ontology, GO), diseases and phenotypes (Disease Ontology, DO; Human Phenotype Ontology, HP; Uberon Anatomy Ontology), assay types (Ontology for Biomedical Investigations, OBI), and relationships connecting these entities, both within and across ontologies (Relationship Ontology, RO). For over a decade, OBO has provided a variety of widely used services to the community, including 1) the OBO registry, which collects standardized metadata for each member ontology such as domain, scope, license, point of contact, etc., thus enhancing findability of each ontology, 2) configurable Persistent URLs (PURLs), which provide an unchanging address for ontologies and ontology classes, enhancing accessibility and reuse, 3) optional content hosting for OBO ontologies that want to take advantage of centrally managed versioning, 4) standardized software tools that make it easy to follow best practices for ontology development, 5) OBO principles, guidelines and best practices, designed to enhance quality and interoperability, and 6) an outreach and coordination effort to mediate between different member ontologies with the goal to coordinate and reduce overlap, through a central email list and regular teleconferences. The present proposal will provide time-limited, catalytic support to increase robustness of existing services by upgrading critical infrastructure on which they are based, by defining and applying standards for metadata and PURL management, and by applying best practices from software engineering to increase maintainability of the codebase. Second, we will introduce new capabilities into our service infrastructure to add automated quality controls to ontologies (individually and in groups), enhance the integration between our services and standardized tools, and add monitoring and metrics. Third, we will perform outreach and training efforts to increase the ability of the community to participate in the OBO project. In accomplishing these aims we will continue to keep our operating costs extremely low, and to freely share the tools and resources we build. PROJECT NARRATIVE/PUBLIC HEALTH RELEVANCE Ontologies provide a precise language to describe scientific findings, and have successfully been used by researchers to share and compare their results. Different ontologies describe different aspects of knowledge, sometimes in an incompatible way. Here we propose to implement a set of services that allows different ontology producers to develop ontologies in a standardized fashion that will make it easier to use them together.",Services to support the OBO foundry standards,9731614,R24HG010032,"['Address', 'Anatomy', 'Basic Science', 'Biological Assay', 'Biological Process', 'Biology', 'Clinical Research', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Development', 'Disease', 'Documentation', 'Education and Outreach', 'Electronic Mail', 'Ensure', 'Funding', 'Genes', 'Goals', 'Guidelines', 'Human', 'Individual', 'Infrastructure', 'Investigation', 'Investments', 'Knowledge', 'Language', 'Licensing', 'Maintenance', 'Measures', 'Mediating', 'Metadata', 'Mission', 'Molecular', 'Monitor', 'Ontology', 'Phenotype', 'Publishing', 'Quality Control', 'Registries', 'Reporting', 'Research Personnel', 'Resources', 'Running', 'Services', 'Software Engineering', 'Software Tools', 'Standardization', 'System', 'Teleconferences', 'Testing', 'Time', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Update', 'base', 'biomedical ontology', 'cost', 'design', 'disease phenotype', 'experience', 'gene function', 'gene product', 'improved', 'information organization', 'interoperability', 'member', 'ontology development', 'open source', 'outreach', 'public health relevance', 'success', 'tool', 'volunteer']",NHGRI,LA JOLLA INSTITUTE FOR IMMUNOLOGY,R24,2019,464271,0.4492157033087422
"A synthetic biology library for the Semantic Web    DESCRIPTION (provided by applicant): The goal of the proposed research is to determine the feasibility of, and create prototype software for, a library of reusable synthetic biology components using Semantic Web technologies OWL, RDF, SPARQL and SWRL. This library will dramatically increase the availability of information about reusable components for synthetic biology, including machine-readable descriptions of the semantic meaning of the components. Such information, amenable to automated reasoning, intelligent retrieval, and other services, will increase the utility of the synthetic biology library for researchers as well as for commercial vendors engaged in designing synthetic biology products. Such a library will hasten the industrialization of synthetic biology, with a host of resulting benefits to public health, including better ""living machines"" designed and manufactured more quickly and efficiently.   In order to achieve these results, in Phase I we will extend BioBricks standard biological component descriptions with semantically-rich descriptions, using OWL ontologies, to support better integration, both with other components, via model checking and verification-style analysis services, as well as with the wealth of biological background knowledge that presently exists in OWL ontology form. We will extend OWL reasoning systems to interpret these semantically rich BioBrick descriptions, including Semantic Web query support via SPARQL and rule support via SWRL. Phase I deliverables include use case and requirements from bioengineering; gap analysis between these requirements and existing technologies; a final report detailing lessons learning and preliminary designs for Phase II; and a prototype library containing OWL-extended BioBrick descriptions and OWL, SPARQL, and SWRL reasoning and query services; and a faceted BioBrick browser for intuitive interaction with the library's entries. In short, better information sharing and analysis infrastructure will provide productivity increases for synthetic biology researchers and practitioners, which will in turn hasten the widescale industrial adoption and use of synthetic biology techniques, leading to new advances in bioengineered therapeutic, energy, and food technologies.      PUBLIC HEALTH RELEVANCE: The relevance of the proposed research to public health is that a Semantic Web-enabled library for synthetic biology will increase the design quality and efficiency-via computer-aided decision support and seamless information sharing-of synthetic biology R&D and industrial activity, thus hastening the advent of industrialscale synthetic biology. That advent will directly benefit public health by way of better ""living machines"" to address therapeutics, energy, food, and other vital areas.           Project Narrative The relevance of the proposed research to public health is that a Semantic Web-enabled library for synthetic biology will increase the design quality and efficiency-via computer-aided decision support and seamless in- formation sharing-of synthetic biology R&D and industrial activity, thus hastening the advent of industrial- scale synthetic biology. That advent will directly benefit public health by way of better ""living machines"" to ad- dress therapeutics, energy, food, and other vital areas.",A synthetic biology library for the Semantic Web,7910247,R41LM010745,"['Address', 'Adoption', 'Area', 'Arts', 'Bioinformatics', 'Biological', 'Biology', 'Biomedical Engineering', 'Communities', 'Computer Assisted', 'Computer software', 'DNA', 'DNA Library', 'Databases', 'Development', 'Devices', 'Engineering', 'Feedback', 'Food Energy', 'Food Technology', 'Genes', 'Genetic', 'Goals', 'Individual', 'Industrialization', 'Industry', 'Information Management', 'Information Resources', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Life', 'Logic', 'Marketing', 'Mechanics', 'Methods', 'Modeling', 'Ontology', 'Phase', 'Process', 'Production', 'Productivity', 'Public Health', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Retrieval', 'Semantics', 'Services', 'Solutions', 'Standardization', 'Sterile coverings', 'Strigiformes', 'Structure', 'Synthetic Genes', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tweens', 'Universities', 'Validation', 'Vendor', 'Washington', 'Work', 'base', 'biological systems', 'computer based Semantic Analysis', 'computer science', 'design', 'flexibility', 'improved', 'information organization', 'innovation', 'interoperability', 'meetings', 'model design', 'models and simulation', 'prototype', 'public health relevance', 'research and development', 'synthetic biology', 'task analysis', 'tool', 'web-enabled']",NLM,"CLARK AND PARSIA, LLC",R41,2010,99967,0.13497879696162923
"HYBRID ONTOLOGY AND MACHINE LEARNING BASED METHODS USING EMR DATA FOR EFFECTIVE CLINICAL DECISION SUPPORT (CDS); A SEPSIS CASE STUDY USING ICU DATA ﻿    DESCRIPTION (provided by applicant):  Our research is focused on the use of advanced ontological models as a foundation for computerized Clinical Decision Support (CDS) systems that link hospitalized patient data routinely captured in electronic medical records (EMRs) with medical knowledge to effectively influence timely awareness and treatment choices by clinicians. Our phase 1 goal is to demonstrate how our advanced CDS technology has the potential to improve preventable mortality outcomes associated with sepsis in ICU patients. We distinguish two types of CDS algorithms available today for detecting and/or predicting sepsis using EMR data: 1) evidence-based ""knowledge-driven"" detection algorithms; and 2) data-driven ""predictive"" algorithms based on machine learning (ML) techniques. Recent studies indicate currently available CDS tools do not reduce risk of death in hospitalized patients. We believe this may be because diseases such as sepsis are time-sensitive, complex syndromes and also due to the challenges of computerized reuse of unstructured EMR data. Our sepsis ontology models this complexity to: a) provide enhanced knowledge-driven sepsis risk- stratified cohort classifications that help guide interventions; b) support accurate natural language processing (NLP) of free text clinical notes to enhance real-time sepsis risk detection; and c) improve the accuracy of data- driven prediction models when used in conjunction with ML training algorithms. Our CDS is based on proprietary cluster computing technology we call ""VFusion"" designed to efficiently deal with the generation and practical use of large, application domain-specific ontologies. Our sepsis ontology employs a family of upper level ontologies, combined with granular evidence-based domain ontologies, configurable rule sets (e.g. first order logic-based), and required components of reference terminologies. Our research will use openly available ICU patient data to establish statistical detection/prediction performance metrics using this ontology in 2 modes of use: 1) as a knowledge-based screening tool to detect subtle signs of sepsis in individualized hospitalized patients; 2) used in conjunction with ML to improve data-driven predictive performance. We will measure specificity/sensitivity, and positive/negative predictive power of our hybrid ontology-based technology to demonstrate dramatically improved performance over existing CDS algorithms. In Phase II we plan a retrospective demonstration with a much larger sample of patients to include non-ICU patients in collaboration with a major healthcare system. Our product vision is an early inpatient sepsis detection algorithm with high accuracy embodied as a ""plug-in application"" compatible with any modern EMR platform in use at a client hospital effective in both ICU and non-ICU care settings.         PUBLIC HEALTH RELEVANCE:  Even with the advent of powerful, new computer medical record technologies used in hospitals, the risk of death has not been reduced in hospitalized patients. The goal of this research effort is to combine medical record systems with advanced cognitive technologies that are commonly used today in products such as the iPhone ""Siri"" to improve clinician awareness and decisions that will dramatically reduce preventable mortality. Our initial use case will be the management of sepsis--=the leading cause of death in non-coronary intensive care units in hospitals                ",HYBRID ONTOLOGY AND MACHINE LEARNING BASED METHODS USING EMR DATA FOR EFFECTIVE CLINICAL DECISION SUPPORT (CDS); A SEPSIS CASE STUDY USING ICU DATA,9046860,R43LM012291,"['Address', 'Age', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Awareness', 'Caring', 'Case Study', 'Cause of Death', 'Cellular Phone', 'Cessation of life', 'Classification', 'Client', 'Clinical', 'Clinical Decision Support Systems', 'Code', 'Cognitive', 'Collaborations', 'Comorbidity', 'Complex', 'Computerized Medical Record', 'Computers', 'Data', 'Data Set', 'Detection', 'Diagnostic', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Early treatment', 'Family', 'Foundations', 'Generations', 'Goals', 'Healthcare Systems', 'Hospitals', 'Hour', 'Hybrids', 'Infection', 'Inpatients', 'Intensive Care Units', 'Intervention', 'Knowledge', 'Laboratories', 'Letters', 'Link', 'Logic', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Medical Records', 'Methods', 'Modeling', 'Mortality Determinants', 'Natural Language Processing', 'Ontology', 'Organ', 'Outcome', 'Patients', 'Performance', 'Phase', 'Physiological', 'Plug-in', 'Protocols documentation', 'Recording of previous events', 'Research', 'Retrospective Studies', 'Risk', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Sepsis', 'Septic Shock', 'Severities', 'Source', 'Specificity', 'Syndrome', 'System', 'Techniques', 'Technology', 'Terminology', 'Text', 'Time', 'Training', 'Validation', 'Vendor', 'Vision', 'antimicrobial', 'base', 'cluster computing', 'cohort', 'computerized', 'design', 'diagnostic accuracy', 'effective therapy', 'evidence base', 'improved', 'knowledge base', 'mortality', 'predictive modeling', 'public health relevance', 'screening', 'tool']",NLM,"COMPUTER TECHNOLOGY ASSOCIATES, INC.",R43,2015,149100,0.27403529446122443
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9979969,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Big Data Methods', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Estrogen receptor positive', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'data standards', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'ontology development', 'open source', 'practical application', 'predictive modeling', 'public repository', 'repository', 'structured data', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2020,511367,0.194129089424853
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9747967,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Big Data Methods', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'ontology development', 'open source', 'practical application', 'predictive modeling', 'repository', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2019,514129,0.194129089424853
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9527186,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Methods', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'ontology development', 'open source', 'practical application', 'predictive modeling', 'repository', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2018,516810,0.194129089424853
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9398728,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Development', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Methods', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'open source', 'practical application', 'predictive modeling', 'repository', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2017,546372,0.194129089424853
"Feasibility of a Therapeutic Intent Ontology Program Director/Principal Investigator (Last, First, Middle): Nelson, Stuart J. ABSTRACT Therapeutic intent can be thought of as the reason for commencing a therapy, not just a disease being treated, but the context in which the therapy is appropriate. We propose to investigate if it is possible to represent the therapeutic intent as seen in drug indications in the Structured Product Label approved by the FDA in a formal, computable manner, using standard controlled vocabularies and a model (an upper level application ontology). If successful, such a representation could be invaluable in clinical decision support, precision medicine, and in deepening our understanding of the uses of drugs. We propose studying the labels of 1000 RxNorm clinical drugs as a sample size, and basing a model on that sample. Then, by providing a web annotation tool, we would be able to evaluate the utility of the model by using both an internally developed set or criteria as well as outside use and review. OMB No. 0925-0001/0002 (Rev. 03/16 Approved Through 10/31/2018) Page 1 Continuation Format Page Program Director/Principal Investigator (Last, First, Middle): Nelson, Stuart J. NARRATIVE We propose to study if it is possible to represent the reasons for giving a medication in a way that a computer can process it. If possible, this should be the basis of improving decision support offered to a prescriber. It might also help us understand more about how and when to use medications. OMB No. 0925-0001/0002 (Rev. 03/16 Approved Through 10/31/2018) Page 1 Continuation Format Page",Feasibility of a Therapeutic Intent Ontology,9583840,R21LM012929,"['Anatomy', 'Awareness', 'Catalogs', 'Clinical', 'Complex', 'Computers', 'Controlled Vocabulary', 'Data', 'Development', 'Disease', 'Drug usage', 'Expert Opinion', 'FDA approved', 'Genetic', 'Goals', 'Health', 'Human', 'Information Resources Management', 'Internet', 'Label', 'Methods', 'Modeling', 'Nature', 'Ontology', 'Pain', 'Pathologic', 'Patient Care', 'Pharmaceutical Preparations', 'Physiological', 'Principal Investigator', 'Process', 'Product Labeling', 'Public Domains', 'Readability', 'Reproducibility', 'Research Infrastructure', 'Resources', 'Sample Size', 'Sampling', 'Semantics', 'Structure', 'Symptoms', 'Terminology', 'Therapeutic', 'Therapeutic Uses', 'Vocabulary', 'Work', 'Yang', 'annotation  system', 'base', 'cheminformatics', 'clinical decision support', 'digital', 'improved', 'information organization', 'precision medicine', 'programs', 'tool', 'usability', 'web site']",NLM,UNIVERSITY OF NEW MEXICO HEALTH SCIS CTR,R21,2018,48610,0.15026110311015395
"Feasibility of a Therapeutic Intent Ontology Program Director/Principal Investigator (Last, First, Middle): Nelson, Stuart J. ABSTRACT Therapeutic intent can be thought of as the reason for commencing a therapy, not just a disease being treated, but the context in which the therapy is appropriate. We propose to investigate if it is possible to represent the therapeutic intent as seen in drug indications in the Structured Product Label approved by the FDA in a formal, computable manner, using standard controlled vocabularies and a model (an upper level application ontology). If successful, such a representation could be invaluable in clinical decision support, precision medicine, and in deepening our understanding of the uses of drugs. We propose studying the labels of 1000 RxNorm clinical drugs as a sample size, and basing a model on that sample. Then, by providing a web annotation tool, we would be able to evaluate the utility of the model by using both an internally developed set or criteria as well as outside use and review. OMB No. 0925-0001/0002 (Rev. 03/16 Approved Through 10/31/2018) Page 1 Continuation Format Page Program Director/Principal Investigator (Last, First, Middle): Nelson, Stuart J. NARRATIVE We propose to study if it is possible to represent the reasons for giving a medication in a way that a computer can process it. If possible, this should be the basis of improving decision support offered to a prescriber. It might also help us understand more about how and when to use medications. OMB No. 0925-0001/0002 (Rev. 03/16 Approved Through 10/31/2018) Page 1 Continuation Format Page",Feasibility of a Therapeutic Intent Ontology,9767858,R21LM012929,"['Anatomy', 'Awareness', 'Catalogs', 'Clinical', 'Complex', 'Computers', 'Controlled Vocabulary', 'Data', 'Development', 'Disease', 'Drug usage', 'Expert Opinion', 'FDA approved', 'Genetic', 'Goals', 'Health', 'Human', 'Information Resources Management', 'Infrastructure', 'Internet', 'Label', 'Methods', 'Modeling', 'Nature', 'Ontology', 'Pain', 'Pathologic', 'Patient Care', 'Pharmaceutical Preparations', 'Physiological', 'Principal Investigator', 'Process', 'Product Labeling', 'Public Domains', 'Readability', 'Reproducibility', 'Resources', 'Sample Size', 'Sampling', 'Semantics', 'Structure', 'Symptoms', 'Terminology', 'Therapeutic', 'Therapeutic Uses', 'Vocabulary', 'Work', 'Yang', 'annotation  system', 'base', 'cheminformatics', 'clinical decision support', 'digital', 'improved', 'information organization', 'precision medicine', 'programs', 'tool', 'usability', 'web site']",NLM,GEORGE WASHINGTON UNIVERSITY,R21,2019,215325,0.15026110311015395
"Information Integration of Heterogeneous Data Sources    DESCRIPTION (provided by applicant): The wealth of biological and biomedical data constantly being generated promises dramatic advancement in the life sciences. To realize this promise, this pool of rapidly expanding information needs to be efficiently integrated, that is, combined in such a way that it can be queried to extract relevant data that can be subsequently analyzed to answer meaningful research questions. The main objective of this proposal is to develop the GeneTegra System, an information integration solution that provides a common interaction environment to query data and knowledge from multiple sources. Two main obstacles have to be overcome in order to attain an effective integration of knowledge from different data sources: syntactic heterogeneity, where data sources have different representation and access mechanisms; and semantic variability, where similar lexical terms may refer to multiple concepts or dissimilar terms refer to the same concept. The GeneTegra System addresses these obstacles through the use of Semantic Web technologies: ontologies constructed using the Web Ontology Language (OWL) as a common data and knowledge representation for data sources of diverse formats, automated mechanisms for the generation and maintenance of these ontology representations, and a robust system architecture based on reusable, service-oriented mediators. The core of the proposed system consists of general algorithms, procedures, and mechanisms developed during Phase I of this project, that enable the automatic generation of ontologies, the automated identification of semantic correspondences between ontology models, and the creation and execution of queries over these ontology- modeled, distributed, heterogeneous sources. In Phase II, the GeneTegra System will be developed, implemented, and tested as a human-centered solution building on the core components developed during Phase I, incorporating a highly usable interface for query creation and execution, a mechanism for registration, sharing, and re-use of information using Web Services standards, a mechanism for determining quality of data and query reliability, and a security and privacy subsystem that allows the construction of collaborative communities while ensuring that users are properly authenticated and authorized to access information through the system. The GeneTegra System will be designed and evaluated to specifically address the integration of sources relevant to investigations of genotype-phenotype associations and to the identification of genes responsible for human diseases and conditions. PUBLIC HEALTH RELEVANCE The GeneTegra System is an information integration solution that provides a common interaction environment to query data and knowledge from multiple heterogeneous sources. It uses ontologies as the base formulism for semantic and syntactic modeling, and contains automated mechanisms for the generation of these ontologies, and for the reuse and sharing of integration configurations. It is specifically designed to address the integrated querying of sources relevant to investigations of genotype-phenotype associations and to the identification of genes responsible for human diseases and conditions.          n/a",Information Integration of Heterogeneous Data Sources,7798074,R44RR018667,"['Access to Information', 'Address', 'Algorithms', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Characteristics', 'Code', 'Communities', 'Computer software', 'Data', 'Data Quality', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Environment', 'Evaluation', 'Extensible Markup Language', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Heterogeneity', 'Human', 'Human Genetics', 'Information Systems', 'Institution', 'Internet', 'Investigation', 'Knowledge', 'Language', 'Maintenance', 'Maps', 'Mediator of activation protein', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Ontology', 'Performance', 'Phase', 'Phenotype', 'Predisposition', 'Privacy', 'Procedures', 'Process', 'Research', 'Research Methodology', 'Research Personnel', 'Security', 'Semantics', 'Services', 'Solutions', 'Source', 'Staff Development', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'abstracting', 'base', 'computer based Semantic Analysis', 'computerized', 'design', 'human centered computing', 'human disease', 'information gathering', 'information organization', 'lexical', 'programs', 'public health relevance', 'relational database', 'syntax', 'system architecture', 'usability']",NCRR,"INFOTECH SOFT, INC.",R44,2010,507489,0.29236177734623897
"Information Integration of Heterogeneous Data Sources    DESCRIPTION (provided by applicant): The wealth of biological and biomedical data constantly being generated promises dramatic advancement in the life sciences. To realize this promise, this pool of rapidly expanding information needs to be efficiently integrated, that is, combined in such a way that it can be queried to extract relevant data that can be subsequently analyzed to answer meaningful research questions. The main objective of this proposal is to develop the GeneTegra System, an information integration solution that provides a common interaction environment to query data and knowledge from multiple sources. Two main obstacles have to be overcome in order to attain an effective integration of knowledge from different data sources: syntactic heterogeneity, where data sources have different representation and access mechanisms; and semantic variability, where similar lexical terms may refer to multiple concepts or dissimilar terms refer to the same concept. The GeneTegra System addresses these obstacles through the use of Semantic Web technologies: ontologies constructed using the Web Ontology Language (OWL) as a common data and knowledge representation for data sources of diverse formats, automated mechanisms for the generation and maintenance of these ontology representations, and a robust system architecture based on reusable, service-oriented mediators. The core of the proposed system consists of general algorithms, procedures, and mechanisms developed during Phase I of this project, that enable the automatic generation of ontologies, the automated identification of semantic correspondences between ontology models, and the creation and execution of queries over these ontology- modeled, distributed, heterogeneous sources. In Phase II, the GeneTegra System will be developed, implemented, and tested as a human-centered solution building on the core components developed during Phase I, incorporating a highly usable interface for query creation and execution, a mechanism for registration, sharing, and re-use of information using Web Services standards, a mechanism for determining quality of data and query reliability, and a security and privacy subsystem that allows the construction of collaborative communities while ensuring that users are properly authenticated and authorized to access information through the system. The GeneTegra System will be designed and evaluated to specifically address the integration of sources relevant to investigations of genotype-phenotype associations and to the identification of genes responsible for human diseases and conditions. PUBLIC HEALTH RELEVANCE The GeneTegra System is an information integration solution that provides a common interaction environment to query data and knowledge from multiple heterogeneous sources. It uses ontologies as the base formulism for semantic and syntactic modeling, and contains automated mechanisms for the generation of these ontologies, and for the reuse and sharing of integration configurations. It is specifically designed to address the integrated querying of sources relevant to investigations of genotype-phenotype associations and to the identification of genes responsible for human diseases and conditions.          n/a",Information Integration of Heterogeneous Data Sources,7614360,R44RR018667,"['Access to Information', 'Address', 'Algorithms', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Characteristics', 'Code', 'Communities', 'Computer software', 'Data', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Disease', 'Ensure', 'Environment', 'Evaluation', 'Extensible Markup Language', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Heterogeneity', 'Human', 'Human Genetics', 'Information Systems', 'Institution', 'Internet', 'Investigation', 'Knowledge', 'Language', 'Maintenance', 'Maps', 'Mediator of activation protein', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Ontology', 'Performance', 'Phase', 'Phenotype', 'Predisposition', 'Privacy', 'Procedures', 'Process', 'Research', 'Research Methodology', 'Research Personnel', 'Security', 'Semantics', 'Services', 'Solutions', 'Source', 'Staff Development', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'abstracting', 'base', 'computer based Semantic Analysis', 'computerized', 'design', 'human centered computing', 'human disease', 'information gathering', 'information organization', 'lexical', 'programs', 'public health relevance', 'syntax', 'system architecture', 'usability']",NCRR,"INFOTECH SOFT, INC.",R44,2009,505764,0.29236177734623897
"Information Integration of Heterogeneous Data Sources    DESCRIPTION (provided by applicant): The wealth of biological and biomedical data constantly being generated promises dramatic advancement in the life sciences. To realize this promise, this pool of rapidly expanding information needs to be efficiently integrated, that is, combined in such a way that it can be queried to extract relevant data that can be subsequently analyzed to answer meaningful research questions. The main objective of this proposal is to develop the GeneTegra System, an information integration solution that provides a common interaction environment to query data and knowledge from multiple sources. Two main obstacles have to be overcome in order to attain an effective integration of knowledge from different data sources: syntactic heterogeneity, where data sources have different representation and access mechanisms; and semantic variability, where similar lexical terms may refer to multiple concepts or dissimilar terms refer to the same concept. The GeneTegra System addresses these obstacles through the use of Semantic Web technologies: ontologies constructed using the Web Ontology Language (OWL) as a common data and knowledge representation for data sources of diverse formats, automated mechanisms for the generation and maintenance of these ontology representations, and a robust system architecture based on reusable, service-oriented mediators. The core of the proposed system consists of general algorithms, procedures, and mechanisms developed during Phase I of this project, that enable the automatic generation of ontologies, the automated identification of semantic correspondences between ontology models, and the creation and execution of queries over these ontology- modeled, distributed, heterogeneous sources. In Phase II, the GeneTegra System will be developed, implemented, and tested as a human-centered solution building on the core components developed during Phase I, incorporating a highly usable interface for query creation and execution, a mechanism for registration, sharing, and re-use of information using Web Services standards, a mechanism for determining quality of data and query reliability, and a security and privacy subsystem that allows the construction of collaborative communities while ensuring that users are properly authenticated and authorized to access information through the system. The GeneTegra System will be designed and evaluated to specifically address the integration of sources relevant to investigations of genotype-phenotype associations and to the identification of genes responsible for human diseases and conditions. PUBLIC HEALTH RELEVANCE The GeneTegra System is an information integration solution that provides a common interaction environment to query data and knowledge from multiple heterogeneous sources. It uses ontologies as the base formulism for semantic and syntactic modeling, and contains automated mechanisms for the generation of these ontologies, and for the reuse and sharing of integration configurations. It is specifically designed to address the integrated querying of sources relevant to investigations of genotype-phenotype associations and to the identification of genes responsible for human diseases and conditions.          n/a",Information Integration of Heterogeneous Data Sources,7481818,R44RR018667,"['Access to Information', 'Address', 'Algorithms', 'Architecture', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Characteristics', 'Code', 'Communities', 'Computer software', 'Condition', 'Data', 'Data Quality', 'Data Sources', 'Databases', 'Development', 'Disease', 'Ensure', 'Environment', 'Evaluation', 'Extensible Markup Language', 'Facility Construction Funding Category', 'Generations', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Heterogeneity', 'Human', 'Human Genetics', 'Information Systems', 'Institution', 'Internet', 'Investigation', 'Knowledge', 'Language', 'Maintenance', 'Maps', 'Mediator of activation protein', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Ontology', 'Performance', 'Phase', 'Phenotype', 'Predisposition', 'Privacy', 'Procedures', 'Process', 'Public Health', 'Purpose', 'Representations, Knowledge (Computer)', 'Research', 'Research Methodology', 'Research Personnel', 'Security', 'Semantics', 'Services', 'Solutions', 'Source', 'Staff Development', 'Standards of Weights and Measures', 'Strigiformes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'abstracting', 'base', 'computer based Semantic Analysis', 'computerized', 'concept', 'design', 'human centered computing', 'human disease', 'information gathering', 'information organization', 'lexical', 'programs', 'syntax', 'usability']",NCRR,"INFOTECH SOFT, INC.",R44,2008,473392,0.29236177734623897
"Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie     DESCRIPTION (provided by applicant): This application seeks funds to develop RegenBase - a novel information system to seamlessly integrate diverse data that are produced by neuroscientists and cell biologists studying nervous system injury, disease and cell motility with other resources, such as the Neuroscience Information Framework and the BioAssay Ontology. Over the past decade the NIH has funded the development of informatics tools and ontologies to allow the integration and interrogation of the massive and diverse data sets that have been produced by the human genome project. In the area of neuroscience the most advancement have been made in the creation and annotation of large anatomical data sets that reveal patterns of gene expression and connectivity. Genesat and the BrainMaps are excellent examples and are easily searched using the Neuroscience Information Framework (NIF) portal. But it is still surprisingly difficult to search for information related to repairing the injured nrvous system. To overcome this road block it is critical to build the essential tools that allow semantic web approaches to link diverse data repositories with ontologies that allow them to be interpreted and analyzed. The success of this initiative critically relies on an effective informatcs solution to integrate the various (current and future) data types generated by neuroscientists working on nervous system injury, as well as large-scale screening efforts (such as the Molecular Libraries Probe Center Network, MLPCN) into coherent data sets and to make them accessible, interpretable, and actionable for scientists of different backgrounds and with different objectives. We propose to develop a novel knowledge-based, extensible information system of interconnected components that leverages semantic-web technologies and domain level ontologies. This system is tentatively called RegenBase (Regeneration dataBase). Tremendous progress has been made during the last decade developing semantic web technologies with the goals of formalizing knowledge, linking information across different domains, and integrating large heterogeneous data sets from diverse sources. To develop RegenBase on a fast-track with limited resources, we will leverage technologies and tools from the National Center for Biological Onotology and the recently launched BioAssay Ontology. The long-term goal of the RegenBase system is seamless ""on-the fly"" data integration and analysis via a semantic ""Linked Data"" approach that is scalable with respect to information volume and complexity. RegenBase will incorporate biomedical domain-level ontologies, including our recently developed BioAssay Ontology (BAO), to semantically associate related data types and to provide a knowledge context of the underlying experiments and screening outcomes. The overarching goal of this proposed RegenBase system is to allow bench scientists to link data and results from studies on nervous system injury and disease to data and knowledge from other domains with an emphasis on molecular targets and the small molecules that perturb their function to speed the development of novel therapeutics.          Public and private organizations are generating diverse data sets as they attempt to develop therapies for nervous system injury and disease. One reason therapy development is slow lies in the difficulty of collecting, analyzing and displaying information from the thousands of different experiments done on nervous system injury and interpreting it based on knowledge from other areas, such as genomics, cell biology, cancer, immunology and drug discovery. We propose to develop a novel information system that will help neuroscientists working on nerve regeneration to access and use information generated by scientists around the world.                ",Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie,8839677,R01NS080145,"['Afferent Neurons', 'Area', 'Axon', 'Back', 'Biological', 'Biological Assay', 'Brain', 'Brain Diseases', 'Brain Injuries', 'Budgets', 'Cancer Immunology Science', 'Cell Death', 'Cells', 'Cellular biology', 'Chemical Structure', 'Cicatrix', 'Complementary DNA', 'Computer software', 'Corticospinal Tracts', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dendrites', 'Development', 'Disease', 'Drug Compounding', 'Evaluation', 'Family', 'Funding', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genomics', 'Goals', 'Growth', 'Healthcare Systems', 'Human Genome Project', 'Individual', 'Informatics', 'Information Systems', 'Injury', 'Investigation', 'Knowledge', 'Link', 'Literature', 'Maps', 'Methodology', 'Molecular Bank', 'Molecular Target', 'Natural regeneration', 'Nerve', 'Nerve Regeneration', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Neurosciences', 'Online Systems', 'Ontology', 'Outcome', 'Paper', 'Pattern', 'Peripheral Nerves', 'PubChem', 'Resources', 'Scientist', 'Semantics', 'Societies', 'Solutions', 'Source', 'Speed', 'Spinal cord damage', 'Spinal cord injury', 'Stroke', 'Structure of rubrospinal tract', 'System', 'Technology', 'Terminology', 'Text', 'Translational Research', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Work', 'axon growth', 'axon regeneration', 'base', 'biomedical ontology', 'cell motility', 'computer based Semantic Analysis', 'data integration', 'data mining', 'drug discovery', 'graphical user interface', 'information display', 'information framework', 'injured', 'knockout gene', 'knowledge base', 'novel', 'novel therapeutics', 'overexpression', 'painful neuropathy', 'repaired', 'research study', 'screening', 'small molecule', 'success', 'text searching', 'therapy development', 'tool', 'vector']",NINDS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2015,570144,0.22572759855441776
"Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie     DESCRIPTION (provided by applicant): This application seeks funds to develop RegenBase - a novel information system to seamlessly integrate diverse data that are produced by neuroscientists and cell biologists studying nervous system injury, disease and cell motility with other resources, such as the Neuroscience Information Framework and the BioAssay Ontology. Over the past decade the NIH has funded the development of informatics tools and ontologies to allow the integration and interrogation of the massive and diverse data sets that have been produced by the human genome project. In the area of neuroscience the most advancement have been made in the creation and annotation of large anatomical data sets that reveal patterns of gene expression and connectivity. Genesat and the BrainMaps are excellent examples and are easily searched using the Neuroscience Information Framework (NIF) portal. But it is still surprisingly difficult to search for information related to repairing the injured nrvous system. To overcome this road block it is critical to build the essential tools that allow semantic web approaches to link diverse data repositories with ontologies that allow them to be interpreted and analyzed. The success of this initiative critically relies on an effective informatcs solution to integrate the various (current and future) data types generated by neuroscientists working on nervous system injury, as well as large-scale screening efforts (such as the Molecular Libraries Probe Center Network, MLPCN) into coherent data sets and to make them accessible, interpretable, and actionable for scientists of different backgrounds and with different objectives. We propose to develop a novel knowledge-based, extensible information system of interconnected components that leverages semantic-web technologies and domain level ontologies. This system is tentatively called RegenBase (Regeneration dataBase). Tremendous progress has been made during the last decade developing semantic web technologies with the goals of formalizing knowledge, linking information across different domains, and integrating large heterogeneous data sets from diverse sources. To develop RegenBase on a fast-track with limited resources, we will leverage technologies and tools from the National Center for Biological Onotology and the recently launched BioAssay Ontology. The long-term goal of the RegenBase system is seamless ""on-the fly"" data integration and analysis via a semantic ""Linked Data"" approach that is scalable with respect to information volume and complexity. RegenBase will incorporate biomedical domain-level ontologies, including our recently developed BioAssay Ontology (BAO), to semantically associate related data types and to provide a knowledge context of the underlying experiments and screening outcomes. The overarching goal of this proposed RegenBase system is to allow bench scientists to link data and results from studies on nervous system injury and disease to data and knowledge from other domains with an emphasis on molecular targets and the small molecules that perturb their function to speed the development of novel therapeutics.          Public and private organizations are generating diverse data sets as they attempt to develop therapies for nervous system injury and disease. One reason therapy development is slow lies in the difficulty of collecting, analyzing and displaying information from the thousands of different experiments done on nervous system injury and interpreting it based on knowledge from other areas, such as genomics, cell biology, cancer, immunology and drug discovery. We propose to develop a novel information system that will help neuroscientists working on nerve regeneration to access and use information generated by scientists around the world.                ",Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie,8653627,R01NS080145,"['Afferent Neurons', 'Area', 'Axon', 'Back', 'Biological', 'Biological Assay', 'Brain', 'Brain Diseases', 'Brain Injuries', 'Budgets', 'Cancer Immunology Science', 'Cell Death', 'Cells', 'Cellular biology', 'Chemical Structure', 'Cicatrix', 'Complementary DNA', 'Computer software', 'Corticospinal Tracts', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dendrites', 'Development', 'Disease', 'Drug Compounding', 'Evaluation', 'Family', 'Funding', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genomics', 'Goals', 'Growth', 'Healthcare Systems', 'Human Genome Project', 'Individual', 'Informatics', 'Information Systems', 'Injury', 'Investigation', 'Knowledge', 'Link', 'Literature', 'Maps', 'Methodology', 'Molecular Bank', 'Molecular Target', 'Natural regeneration', 'Nerve', 'Nerve Regeneration', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Neurosciences', 'Online Systems', 'Ontology', 'Outcome', 'Paper', 'Pattern', 'Peripheral Nerves', 'PubChem', 'Resources', 'Scientist', 'Semantics', 'Societies', 'Solutions', 'Source', 'Speed', 'Spinal cord damage', 'Spinal cord injury', 'Stroke', 'Structure of rubrospinal tract', 'System', 'Technology', 'Terminology', 'Text', 'Translational Research', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Work', 'axon growth', 'axon regeneration', 'base', 'biomedical ontology', 'cell motility', 'computer based Semantic Analysis', 'data integration', 'data mining', 'drug discovery', 'graphical user interface', 'information display', 'information framework', 'injured', 'knockout gene', 'knowledge base', 'novel', 'novel therapeutics', 'overexpression', 'painful neuropathy', 'repaired', 'research study', 'screening', 'small molecule', 'success', 'text searching', 'therapy development', 'tool', 'vector']",NINDS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2014,564445,0.22572759855441776
"Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie     DESCRIPTION (provided by applicant): This application seeks funds to develop RegenBase - a novel information system to seamlessly integrate diverse data that are produced by neuroscientists and cell biologists studying nervous system injury, disease and cell motility with other resources, such as the Neuroscience Information Framework and the BioAssay Ontology. Over the past decade the NIH has funded the development of informatics tools and ontologies to allow the integration and interrogation of the massive and diverse data sets that have been produced by the human genome project. In the area of neuroscience the most advancement have been made in the creation and annotation of large anatomical data sets that reveal patterns of gene expression and connectivity. Genesat and the BrainMaps are excellent examples and are easily searched using the Neuroscience Information Framework (NIF) portal. But it is still surprisingly difficult to search for information related to repairing the injured nrvous system. To overcome this road block it is critical to build the essential tools that allow semantic web approaches to link diverse data repositories with ontologies that allow them to be interpreted and analyzed. The success of this initiative critically relies on an effective informatcs solution to integrate the various (current and future) data types generated by neuroscientists working on nervous system injury, as well as large-scale screening efforts (such as the Molecular Libraries Probe Center Network, MLPCN) into coherent data sets and to make them accessible, interpretable, and actionable for scientists of different backgrounds and with different objectives. We propose to develop a novel knowledge-based, extensible information system of interconnected components that leverages semantic-web technologies and domain level ontologies. This system is tentatively called RegenBase (Regeneration dataBase). Tremendous progress has been made during the last decade developing semantic web technologies with the goals of formalizing knowledge, linking information across different domains, and integrating large heterogeneous data sets from diverse sources. To develop RegenBase on a fast-track with limited resources, we will leverage technologies and tools from the National Center for Biological Onotology and the recently launched BioAssay Ontology. The long-term goal of the RegenBase system is seamless ""on-the fly"" data integration and analysis via a semantic ""Linked Data"" approach that is scalable with respect to information volume and complexity. RegenBase will incorporate biomedical domain-level ontologies, including our recently developed BioAssay Ontology (BAO), to semantically associate related data types and to provide a knowledge context of the underlying experiments and screening outcomes. The overarching goal of this proposed RegenBase system is to allow bench scientists to link data and results from studies on nervous system injury and disease to data and knowledge from other domains with an emphasis on molecular targets and the small molecules that perturb their function to speed the development of novel therapeutics.          Public and private organizations are generating diverse data sets as they attempt to develop therapies for nervous system injury and disease. One reason therapy development is slow lies in the difficulty of collecting, analyzing and displaying information from the thousands of different experiments done on nervous system injury and interpreting it based on knowledge from other areas, such as genomics, cell biology, cancer, immunology and drug discovery. We propose to develop a novel information system that will help neuroscientists working on nerve regeneration to access and use information generated by scientists around the world.                ",Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie,8465934,R01NS080145,"['Afferent Neurons', 'Area', 'Axon', 'Back', 'Biological', 'Biological Assay', 'Brain', 'Brain Diseases', 'Brain Injuries', 'Budgets', 'Cancer Immunology Science', 'Cell Death', 'Cells', 'Cellular biology', 'Chemical Structure', 'Cicatrix', 'Complementary DNA', 'Computer software', 'Corticospinal Tracts', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dendrites', 'Development', 'Disease', 'Drug Compounding', 'Evaluation', 'Family', 'Funding', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genomics', 'Goals', 'Growth', 'Healthcare Systems', 'Human Genome Project', 'Individual', 'Informatics', 'Information Systems', 'Injury', 'Investigation', 'Knowledge', 'Link', 'Literature', 'Maps', 'Methodology', 'Molecular Bank', 'Molecular Target', 'Natural regeneration', 'Nerve', 'Nerve Regeneration', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Neurosciences', 'Online Systems', 'Ontology', 'Outcome', 'Paper', 'Pattern', 'Peripheral Nerves', 'PubChem', 'Resources', 'Scientist', 'Semantics', 'Societies', 'Solutions', 'Source', 'Speed', 'Spinal cord damage', 'Spinal cord injury', 'Stroke', 'Structure of rubrospinal tract', 'System', 'Technology', 'Terminology', 'Text', 'Translational Research', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Work', 'axon growth', 'axon regeneration', 'base', 'biomedical ontology', 'cell motility', 'computer based Semantic Analysis', 'data integration', 'data mining', 'drug discovery', 'graphical user interface', 'information display', 'information framework', 'injured', 'knockout gene', 'knowledge base', 'novel', 'novel therapeutics', 'overexpression', 'painful neuropathy', 'repaired', 'research study', 'screening', 'small molecule', 'success', 'text searching', 'therapy development', 'tool', 'vector']",NINDS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2013,550188,0.22572759855441776
"Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie     DESCRIPTION (provided by applicant): This application seeks funds to develop RegenBase - a novel information system to seamlessly integrate diverse data that are produced by neuroscientists and cell biologists studying nervous system injury, disease and cell motility with other resources, such as the Neuroscience Information Framework and the BioAssay Ontology. Over the past decade the NIH has funded the development of informatics tools and ontologies to allow the integration and interrogation of the massive and diverse data sets that have been produced by the human genome project. In the area of neuroscience the most advancement have been made in the creation and annotation of large anatomical data sets that reveal patterns of gene expression and connectivity. Genesat and the BrainMaps are excellent examples and are easily searched using the Neuroscience Information Framework (NIF) portal. But it is still surprisingly difficult to search for information related to repairing the injured nrvous system. To overcome this road block it is critical to build the essential tools that allow semantic web approaches to link diverse data repositories with ontologies that allow them to be interpreted and analyzed. The success of this initiative critically relies on an effective informatcs solution to integrate the various (current and future) data types generated by neuroscientists working on nervous system injury, as well as large-scale screening efforts (such as the Molecular Libraries Probe Center Network, MLPCN) into coherent data sets and to make them accessible, interpretable, and actionable for scientists of different backgrounds and with different objectives. We propose to develop a novel knowledge-based, extensible information system of interconnected components that leverages semantic-web technologies and domain level ontologies. This system is tentatively called RegenBase (Regeneration dataBase). Tremendous progress has been made during the last decade developing semantic web technologies with the goals of formalizing knowledge, linking information across different domains, and integrating large heterogeneous data sets from diverse sources. To develop RegenBase on a fast-track with limited resources, we will leverage technologies and tools from the National Center for Biological Onotology and the recently launched BioAssay Ontology. The long-term goal of the RegenBase system is seamless ""on-the fly"" data integration and analysis via a semantic ""Linked Data"" approach that is scalable with respect to information volume and complexity. RegenBase will incorporate biomedical domain-level ontologies, including our recently developed BioAssay Ontology (BAO), to semantically associate related data types and to provide a knowledge context of the underlying experiments and screening outcomes. The overarching goal of this proposed RegenBase system is to allow bench scientists to link data and results from studies on nervous system injury and disease to data and knowledge from other domains with an emphasis on molecular targets and the small molecules that perturb their function to speed the development of novel therapeutics.        PUBLIC HEALTH RELEVANCE: Public and private organizations are generating diverse data sets as they attempt to develop therapies for nervous system injury and disease. One reason therapy development is slow lies in the difficulty of collecting, analyzing and displaying information from the thousands of different experiments done on nervous system injury and interpreting it based on knowledge from other areas, such as genomics, cell biology, cancer, immunology and drug discovery. We propose to develop a novel information system that will help neuroscientists working on nerve regeneration to access and use information generated by scientists around the world.                  Public and private organizations are generating diverse data sets as they attempt to develop therapies for nervous system injury and disease. One reason therapy development is slow lies in the difficulty of collecting, analyzing and displaying information from the thousands of different experiments done on nervous system injury and interpreting it based on knowledge from other areas, such as genomics, cell biology, cancer, immunology and drug discovery. We propose to develop a novel information system that will help neuroscientists working on nerve regeneration to access and use information generated by scientists around the world.                ",Regenbase: A Searchable Database to Organize Regeneration Knowledge via Ontologie,8365739,R01NS080145,"['Afferent Neurons', 'Area', 'Axon', 'Back', 'Biological', 'Biological Assay', 'Brain', 'Brain Diseases', 'Brain Injuries', 'Budgets', 'Cancer Immunology Science', 'Cell Death', 'Cells', 'Cellular biology', 'Chemical Structure', 'Cicatrix', 'Complementary DNA', 'Computer software', 'Corticospinal Tracts', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dendrites', 'Development', 'Disease', 'Drug Compounding', 'Evaluation', 'Family', 'Funding', 'Future', 'Gene Expression', 'Gene Expression Profile', 'Genes', 'Genomics', 'Goals', 'Growth', 'Healthcare Systems', 'Human Genome Project', 'Individual', 'Informatics', 'Information Systems', 'Injury', 'Investigation', 'Knowledge', 'Link', 'Literature', 'Maps', 'Methodology', 'Molecular Bank', 'Molecular Target', 'Natural regeneration', 'Nerve', 'Nerve Regeneration', 'Nervous System Trauma', 'Nervous system structure', 'Neurons', 'Neurosciences', 'Online Systems', 'Ontology', 'Outcome', 'Paper', 'Pattern', 'Peripheral Nerves', 'PubChem', 'Resources', 'Scientist', 'Screening procedure', 'Semantics', 'Societies', 'Solutions', 'Source', 'Speed', 'Spinal cord damage', 'Spinal cord injury', 'Stroke', 'Structure of rubrospinal tract', 'System', 'Technology', 'Terminology', 'Text', 'Translational Research', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Work', 'axon growth', 'axon regeneration', 'base', 'biomedical ontology', 'cell motility', 'computer based Semantic Analysis', 'data integration', 'data mining', 'drug discovery', 'graphical user interface', 'information display', 'information framework', 'injured', 'knockout gene', 'knowledge base', 'novel', 'novel therapeutics', 'overexpression', 'painful neuropathy', 'repaired', 'research study', 'small molecule', 'success', 'text searching', 'therapy development', 'tool', 'vector']",NINDS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2012,603798,0.15725484395344164
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9546737,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Models', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'FAIR principles', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Phenotype', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'flexibility', 'genome-wide', 'human disease', 'human model', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2018,688354,0.29281330675946743
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9331689,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Models', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'FAIR principles', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Phenotype', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2017,708354,0.29281330675946743
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9303592,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Maps', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Peptide Sequence Determination', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Taxon', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'disease phenotype', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2016,20000,0.29281330675946743
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9120920,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Maps', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Peptide Sequence Determination', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Taxon', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'disease phenotype', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2016,688354,0.29281330675946743
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users.         PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.            ",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,8964875,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Maps', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Peptide Sequence Determination', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Taxon', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'data integration', 'disease classification', 'disease phenotype', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2015,745136,0.29281330675946743
"PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge    DESCRIPTION (provided by applicant): Biomedical ontologies are critical tools for the accurate representation and integration of genome-scale data in biomedical and translational research. The OBO (Open Biological and Biomedical Ontologies) Foundry is a community effort to develop a systematic and coordinated framework for evidence-based ontology development on the basis of an evolving set of best practice principles. The Protein Ontology (PRO) is the reference ontology for proteins within the OBO Foundry, and is, with the Gene Ontology, one of the first six ontologies recommended by the Foundry as preferred targets for community convergence. To provide a basic ontological framework to capture protein knowledge in a systems biology context, PRO encompasses three sub-ontologies to represent (1) proteins from homologous genes based on evolutionary relatedness (ProEvo); (2) protein forms produced from a given gene, including splice isoforms, mutation variants, and co- or post-translationally modified forms (ProForm); and (3) protein-containing complexes (ProComp).  This competitive renewal grant application aims to further develop PRO in order to facilitate its semantic and computational use by the biomedical research community and thereby broaden its scientific impact for discovery and reasoning in the health sciences. The specific aims are: (i) to enhance the PRO ontological framework; (ii) to broaden the coverage of protein objects; (iii) to enhance the PRO curation platform, website and visual representation; (iv) to develop driving clinical projects; and (v) to expand the scientific impact, adoption and dissemination of PRO. The ontological framework will capture new types of protein objects and relations and connect to semantic resources and reasoning tools. PRO will broaden coverage through mappings and definitions of relations to connect protein objects in existing knowledge bases, and via semi-automated import of protein forms and complexes from curated databases. A graphical network representation will seamlessly connect protein forms and complexes across tax in biological context for disease modeling. Use cases and two specific Driving Clinical Projects-one for reasoning and hypothesis generation for Alzheimer's disease, and one for flow cytometry data representation and immune system modeling-will demonstrate knowledge integration in the OBO Foundry framework as an enabling research infrastructure for reasoning and modeling in the health sciences. We will host annual PRO Scientific Dissemination Meetings addressing the protein-related needs of the bio- and clinical informatics research communities. PRO will be disseminated via multiple websites and ontological services, as well as through reciprocal links with major knowledge resources. ID management for protein objects will include mapping of PRO terms to common database identifiers with well-defined relations and expedited creation of requested PRO terms and UIDs.  The PRO research has several unique features and its significance is multi-fold. For knowledge representation, PRO defines precise protein objects to support accurate annotation at the appropriate granularity and provides the ontological framework to connect all protein types necessary to model biology, in particular linking specific protein forms to particular complexes in biological context. For semantic data integration, PRO provides the ontological structure to connect-via specified relations- the vast amounts of protein knowledge contained in databases to support new hypothesis generation and testing. PRO therefore addresses the current gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully leveraging and complementing existing knowledge sources. The proposed research will allow the PRO Consortium to bring together the resources and expertise from several collaborating institutions to deepen and broaden PRO as a mature research infrastructure for biomedical knowledge discovery and translational science.        The PRO ontology will allow researchers to capture and accurately represent scientific knowledge of proteins, providing a research infrastructure for modeling biological systems, improving the understanding of human disease, and aiding in the identification of potential diagnostic and therapeutic targets.         ",PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge,8700422,R01GM080646,"['Address', 'Adoption', 'Alzheimer&apos', 's Disease', 'Applications Grants', 'Area', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biology', 'Biomedical Research', 'Buffaloes', 'Cells', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Communities', 'Community Outreach', 'Complement', 'Complex', 'Data', 'Databases', 'Delaware', 'Development', 'Diagnostic', 'Disease model', 'Educational workshop', 'Ensure', 'Flow Cytometry', 'Generations', 'Genes', 'Genome', 'Goals', 'Grant', 'Health Sciences', 'Homologous Gene', 'Human', 'Immune system', 'Informatics', 'Information Resources', 'Institution', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Link', 'Maps', 'Modeling', 'Molecular', 'Mus', 'Mutation', 'New York', 'Object Relations', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Protein Import', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Systems Biology', 'Taxes', 'Taxon', 'Testing', 'Training', 'Translational Research', 'Universities', 'Variant', 'Visual', 'Work', 'base', 'biological systems', 'biomedical ontology', 'data integration', 'data mining', 'drug discovery', 'evidence base', 'human disease', 'improved', 'information organization', 'knowledge base', 'meetings', 'mouse genome', 'protein complex', 'text searching', 'therapeutic target', 'tool', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,R01,2014,874165,0.27405155694075206
"PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge    DESCRIPTION (provided by applicant): Biomedical ontologies are critical tools for the accurate representation and integration of genome-scale data in biomedical and translational research. The OBO (Open Biological and Biomedical Ontologies) Foundry is a community effort to develop a systematic and coordinated framework for evidence-based ontology development on the basis of an evolving set of best practice principles. The Protein Ontology (PRO) is the reference ontology for proteins within the OBO Foundry, and is, with the Gene Ontology, one of the first six ontologies recommended by the Foundry as preferred targets for community convergence. To provide a basic ontological framework to capture protein knowledge in a systems biology context, PRO encompasses three sub-ontologies to represent (1) proteins from homologous genes based on evolutionary relatedness (ProEvo); (2) protein forms produced from a given gene, including splice isoforms, mutation variants, and co- or post-translationally modified forms (ProForm); and (3) protein-containing complexes (ProComp).  This competitive renewal grant application aims to further develop PRO in order to facilitate its semantic and computational use by the biomedical research community and thereby broaden its scientific impact for discovery and reasoning in the health sciences. The specific aims are: (i) to enhance the PRO ontological framework; (ii) to broaden the coverage of protein objects; (iii) to enhance the PRO curation platform, website and visual representation; (iv) to develop driving clinical projects; and (v) to expand the scientific impact, adoption and dissemination of PRO. The ontological framework will capture new types of protein objects and relations and connect to semantic resources and reasoning tools. PRO will broaden coverage through mappings and definitions of relations to connect protein objects in existing knowledge bases, and via semi-automated import of protein forms and complexes from curated databases. A graphical network representation will seamlessly connect protein forms and complexes across tax in biological context for disease modeling. Use cases and two specific Driving Clinical Projects-one for reasoning and hypothesis generation for Alzheimer's disease, and one for flow cytometry data representation and immune system modeling-will demonstrate knowledge integration in the OBO Foundry framework as an enabling research infrastructure for reasoning and modeling in the health sciences. We will host annual PRO Scientific Dissemination Meetings addressing the protein-related needs of the bio- and clinical informatics research communities. PRO will be disseminated via multiple websites and ontological services, as well as through reciprocal links with major knowledge resources. ID management for protein objects will include mapping of PRO terms to common database identifiers with well-defined relations and expedited creation of requested PRO terms and UIDs.  The PRO research has several unique features and its significance is multi-fold. For knowledge representation, PRO defines precise protein objects to support accurate annotation at the appropriate granularity and provides the ontological framework to connect all protein types necessary to model biology, in particular linking specific protein forms to particular complexes in biological context. For semantic data integration, PRO provides the ontological structure to connect-via specified relations- the vast amounts of protein knowledge contained in databases to support new hypothesis generation and testing. PRO therefore addresses the current gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully leveraging and complementing existing knowledge sources. The proposed research will allow the PRO Consortium to bring together the resources and expertise from several collaborating institutions to deepen and broaden PRO as a mature research infrastructure for biomedical knowledge discovery and translational science.        The PRO ontology will allow researchers to capture and accurately represent scientific knowledge of proteins, providing a research infrastructure for modeling biological systems, improving the understanding of human disease, and aiding in the identification of potential diagnostic and therapeutic targets.         ",PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge,8516051,R01GM080646,"['Address', 'Adoption', 'Alzheimer&apos', 's Disease', 'Applications Grants', 'Area', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biology', 'Biomedical Research', 'Buffaloes', 'Cells', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Communities', 'Community Outreach', 'Complement', 'Complex', 'Data', 'Databases', 'Delaware', 'Development', 'Diagnostic', 'Disease model', 'Educational workshop', 'Ensure', 'Flow Cytometry', 'Generations', 'Genes', 'Genome', 'Goals', 'Grant', 'Health Sciences', 'Homologous Gene', 'Human', 'Immune system', 'Informatics', 'Information Resources', 'Institution', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Link', 'Maps', 'Modeling', 'Molecular', 'Mus', 'Mutation', 'New York', 'Object Relations', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Protein Import', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Systems Biology', 'Taxes', 'Taxon', 'Testing', 'Training', 'Translational Research', 'Universities', 'Variant', 'Visual', 'Work', 'base', 'biological systems', 'biomedical ontology', 'data integration', 'data mining', 'drug discovery', 'evidence base', 'human disease', 'improved', 'information organization', 'knowledge base', 'meetings', 'mouse genome', 'protein complex', 'text searching', 'therapeutic target', 'tool', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,R01,2013,843962,0.27405155694075206
"PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge    DESCRIPTION (provided by applicant): Biomedical ontologies are critical tools for the accurate representation and integration of genome-scale data in biomedical and translational research. The OBO (Open Biological and Biomedical Ontologies) Foundry is a community effort to develop a systematic and coordinated framework for evidence-based ontology development on the basis of an evolving set of best practice principles. The Protein Ontology (PRO) is the reference ontology for proteins within the OBO Foundry, and is, with the Gene Ontology, one of the first six ontologies recommended by the Foundry as preferred targets for community convergence. To provide a basic ontological framework to capture protein knowledge in a systems biology context, PRO encompasses three sub-ontologies to represent (1) proteins from homologous genes based on evolutionary relatedness (ProEvo); (2) protein forms produced from a given gene, including splice isoforms, mutation variants, and co- or post-translationally modified forms (ProForm); and (3) protein-containing complexes (ProComp).  This competitive renewal grant application aims to further develop PRO in order to facilitate its semantic and computational use by the biomedical research community and thereby broaden its scientific impact for discovery and reasoning in the health sciences. The specific aims are: (i) to enhance the PRO ontological framework; (ii) to broaden the coverage of protein objects; (iii) to enhance the PRO curation platform, website and visual representation; (iv) to develop driving clinical projects; and (v) to expand the scientific impact, adoption and dissemination of PRO. The ontological framework will capture new types of protein objects and relations and connect to semantic resources and reasoning tools. PRO will broaden coverage through mappings and definitions of relations to connect protein objects in existing knowledge bases, and via semi-automated import of protein forms and complexes from curated databases. A graphical network representation will seamlessly connect protein forms and complexes across tax in biological context for disease modeling. Use cases and two specific Driving Clinical Projects-one for reasoning and hypothesis generation for Alzheimer's disease, and one for flow cytometry data representation and immune system modeling-will demonstrate knowledge integration in the OBO Foundry framework as an enabling research infrastructure for reasoning and modeling in the health sciences. We will host annual PRO Scientific Dissemination Meetings addressing the protein-related needs of the bio- and clinical informatics research communities. PRO will be disseminated via multiple websites and ontological services, as well as through reciprocal links with major knowledge resources. ID management for protein objects will include mapping of PRO terms to common database identifiers with well-defined relations and expedited creation of requested PRO terms and UIDs.  The PRO research has several unique features and its significance is multi-fold. For knowledge representation, PRO defines precise protein objects to support accurate annotation at the appropriate granularity and provides the ontological framework to connect all protein types necessary to model biology, in particular linking specific protein forms to particular complexes in biological context. For semantic data integration, PRO provides the ontological structure to connect-via specified relations- the vast amounts of protein knowledge contained in databases to support new hypothesis generation and testing. PRO therefore addresses the current gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully leveraging and complementing existing knowledge sources. The proposed research will allow the PRO Consortium to bring together the resources and expertise from several collaborating institutions to deepen and broaden PRO as a mature research infrastructure for biomedical knowledge discovery and translational science.        The PRO ontology will allow researchers to capture and accurately represent scientific knowledge of proteins, providing a research infrastructure for modeling biological systems, improving the understanding of human disease, and aiding in the identification of potential diagnostic and therapeutic targets.         ",PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge,8336867,R01GM080646,"['Address', 'Adoption', 'Alzheimer&apos', 's Disease', 'Applications Grants', 'Area', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biology', 'Biomedical Research', 'Buffaloes', 'Cells', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Communities', 'Community Outreach', 'Complement', 'Complex', 'Data', 'Databases', 'Delaware', 'Development', 'Diagnostic', 'Disease model', 'Educational workshop', 'Ensure', 'Flow Cytometry', 'Generations', 'Genes', 'Genome', 'Goals', 'Grant', 'Health Sciences', 'Homologous Gene', 'Human', 'Immune system', 'Informatics', 'Information Resources', 'Institution', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Link', 'Maps', 'Modeling', 'Molecular', 'Mus', 'Mutation', 'New York', 'Object Relations', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Protein Import', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Systems Biology', 'Taxes', 'Taxon', 'Testing', 'Training', 'Translational Research', 'Universities', 'Variant', 'Visual', 'Work', 'base', 'biological systems', 'biomedical ontology', 'data integration', 'data mining', 'drug discovery', 'evidence base', 'human disease', 'improved', 'information organization', 'knowledge base', 'meetings', 'mouse genome', 'protein complex', 'text searching', 'therapeutic target', 'tool', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,R01,2012,785773,0.27405155694075206
"PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge    DESCRIPTION (provided by applicant): Biomedical ontologies are critical tools for the accurate representation and integration of genome-scale data in biomedical and translational research. The OBO (Open Biological and Biomedical Ontologies) Foundry is a community effort to develop a systematic and coordinated framework for evidence-based ontology development on the basis of an evolving set of best practice principles. The Protein Ontology (PRO) is the reference ontology for proteins within the OBO Foundry, and is, with the Gene Ontology, one of the first six ontologies recommended by the Foundry as preferred targets for community convergence. To provide a basic ontological framework to capture protein knowledge in a systems biology context, PRO encompasses three sub-ontologies to represent (1) proteins from homologous genes based on evolutionary relatedness (ProEvo); (2) protein forms produced from a given gene, including splice isoforms, mutation variants, and co- or post-translationally modified forms (ProForm); and (3) protein-containing complexes (ProComp).  This competitive renewal grant application aims to further develop PRO in order to facilitate its semantic and computational use by the biomedical research community and thereby broaden its scientific impact for discovery and reasoning in the health sciences. The specific aims are: (i) to enhance the PRO ontological framework; (ii) to broaden the coverage of protein objects; (iii) to enhance the PRO curation platform, website and visual representation; (iv) to develop driving clinical projects; and (v) to expand the scientific impact, adoption and dissemination of PRO. The ontological framework will capture new types of protein objects and relations and connect to semantic resources and reasoning tools. PRO will broaden coverage through mappings and definitions of relations to connect protein objects in existing knowledge bases, and via semi-automated import of protein forms and complexes from curated databases. A graphical network representation will seamlessly connect protein forms and complexes across tax in biological context for disease modeling. Use cases and two specific Driving Clinical Projects-one for reasoning and hypothesis generation for Alzheimer's disease, and one for flow cytometry data representation and immune system modeling-will demonstrate knowledge integration in the OBO Foundry framework as an enabling research infrastructure for reasoning and modeling in the health sciences. We will host annual PRO Scientific Dissemination Meetings addressing the protein-related needs of the bio- and clinical informatics research communities. PRO will be disseminated via multiple websites and ontological services, as well as through reciprocal links with major knowledge resources. ID management for protein objects will include mapping of PRO terms to common database identifiers with well-defined relations and expedited creation of requested PRO terms and UIDs.  The PRO research has several unique features and its significance is multi-fold. For knowledge representation, PRO defines precise protein objects to support accurate annotation at the appropriate granularity and provides the ontological framework to connect all protein types necessary to model biology, in particular linking specific protein forms to particular complexes in biological context. For semantic data integration, PRO provides the ontological structure to connect-via specified relations- the vast amounts of protein knowledge contained in databases to support new hypothesis generation and testing. PRO therefore addresses the current gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully leveraging and complementing existing knowledge sources. The proposed research will allow the PRO Consortium to bring together the resources and expertise from several collaborating institutions to deepen and broaden PRO as a mature research infrastructure for biomedical knowledge discovery and translational science.        The PRO ontology will allow researchers to capture and accurately represent scientific knowledge of proteins, providing a research infrastructure for modeling biological systems, improving the understanding of human disease, and aiding in the identification of potential diagnostic and therapeutic targets.         ",PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge,8521853,R01GM080646,"['Address', 'Adoption', 'Alzheimer&apos', 's Disease', 'Applications Grants', 'Area', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biology', 'Biomedical Research', 'Buffaloes', 'Cells', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Communities', 'Community Outreach', 'Complement', 'Complex', 'Data', 'Databases', 'Delaware', 'Development', 'Diagnostic', 'Disease model', 'Educational workshop', 'Ensure', 'Flow Cytometry', 'Generations', 'Genes', 'Genome', 'Goals', 'Grant', 'Health Sciences', 'Homologous Gene', 'Human', 'Immune system', 'Informatics', 'Information Resources', 'Institution', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Link', 'Maps', 'Modeling', 'Molecular', 'Mus', 'Mutation', 'New York', 'Object Relations', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Protein Import', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Systems Biology', 'Taxes', 'Taxon', 'Testing', 'Training', 'Translational Research', 'Universities', 'Variant', 'Visual', 'Work', 'base', 'biological systems', 'biomedical ontology', 'data integration', 'data mining', 'drug discovery', 'evidence base', 'human disease', 'improved', 'information organization', 'knowledge base', 'meetings', 'mouse genome', 'protein complex', 'text searching', 'therapeutic target', 'tool', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,R01,2012,82863,0.27405155694075206
"PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge    DESCRIPTION (provided by applicant): Biomedical ontologies are critical tools for the accurate representation and integration of genome-scale data in biomedical and translational research. The OBO (Open Biological and Biomedical Ontologies) Foundry is a community effort to develop a systematic and coordinated framework for evidence-based ontology development on the basis of an evolving set of best practice principles. The Protein Ontology (PRO) is the reference ontology for proteins within the OBO Foundry, and is, with the Gene Ontology, one of the first six ontologies recommended by the Foundry as preferred targets for community convergence. To provide a basic ontological framework to capture protein knowledge in a systems biology context, PRO encompasses three sub-ontologies to represent (1) proteins from homologous genes based on evolutionary relatedness (ProEvo); (2) protein forms produced from a given gene, including splice isoforms, mutation variants, and co- or post-translationally modified forms (ProForm); and (3) protein-containing complexes (ProComp).  This competitive renewal grant application aims to further develop PRO in order to facilitate its semantic and computational use by the biomedical research community and thereby broaden its scientific impact for discovery and reasoning in the health sciences. The specific aims are: (i) to enhance the PRO ontological framework; (ii) to broaden the coverage of protein objects; (iii) to enhance the PRO curation platform, website and visual representation; (iv) to develop driving clinical projects; and (v) to expand the scientific impact, adoption and dissemination of PRO. The ontological framework will capture new types of protein objects and relations and connect to semantic resources and reasoning tools. PRO will broaden coverage through mappings and definitions of relations to connect protein objects in existing knowledge bases, and via semi-automated import of protein forms and complexes from curated databases. A graphical network representation will seamlessly connect protein forms and complexes across tax in biological context for disease modeling. Use cases and two specific Driving Clinical Projects-one for reasoning and hypothesis generation for Alzheimer's disease, and one for flow cytometry data representation and immune system modeling-will demonstrate knowledge integration in the OBO Foundry framework as an enabling research infrastructure for reasoning and modeling in the health sciences. We will host annual PRO Scientific Dissemination Meetings addressing the protein-related needs of the bio- and clinical informatics research communities. PRO will be disseminated via multiple websites and ontological services, as well as through reciprocal links with major knowledge resources. ID management for protein objects will include mapping of PRO terms to common database identifiers with well-defined relations and expedited creation of requested PRO terms and UIDs.  The PRO research has several unique features and its significance is multi-fold. For knowledge representation, PRO defines precise protein objects to support accurate annotation at the appropriate granularity and provides the ontological framework to connect all protein types necessary to model biology, in particular linking specific protein forms to particular complexes in biological context. For semantic data integration, PRO provides the ontological structure to connect-via specified relations- the vast amounts of protein knowledge contained in databases to support new hypothesis generation and testing. PRO therefore addresses the current gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully leveraging and complementing existing knowledge sources. The proposed research will allow the PRO Consortium to bring together the resources and expertise from several collaborating institutions to deepen and broaden PRO as a mature research infrastructure for biomedical knowledge discovery and translational science.      PUBLIC HEALTH RELEVANCE: The PRO ontology will allow researchers to capture and accurately represent scientific knowledge of proteins, providing a research infrastructure for modeling biological systems, improving the understanding of human disease, and aiding in the identification of potential diagnostic and therapeutic targets.           The PRO ontology will allow researchers to capture and accurately represent scientific knowledge of proteins, providing a research infrastructure for modeling biological systems, improving the understanding of human disease, and aiding in the identification of potential diagnostic and therapeutic targets.         ",PRO: A Protein Ontology in OBO Foundry for Integration of Biomedical Knowledge,8187900,R01GM080646,"['Address', 'Adoption', 'Alzheimer&apos', 's Disease', 'Applications Grants', 'Area', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biology', 'Biomedical Research', 'Buffaloes', 'Cells', 'Clinical', 'Clinical Informatics', 'Collaborations', 'Communities', 'Community Outreach', 'Complement', 'Complex', 'Data', 'Databases', 'Delaware', 'Development', 'Diagnostic', 'Disease model', 'Educational workshop', 'Ensure', 'Flow Cytometry', 'Generations', 'Genes', 'Genome', 'Goals', 'Grant', 'Health Sciences', 'Homologous Gene', 'Human', 'Immune system', 'Informatics', 'Information Resources', 'Institution', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Link', 'Maps', 'Modeling', 'Molecular', 'Mus', 'Mutation', 'New York', 'Object Relations', 'Ontology', 'Pathway Analysis', 'Pathway interactions', 'Protein Import', 'Protein Isoforms', 'Proteins', 'RNA Splicing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'Systems Biology', 'Taxes', 'Taxon', 'Testing', 'Training', 'Translational Research', 'Universities', 'Variant', 'Visual', 'Work', 'base', 'biological systems', 'biomedical ontology', 'data integration', 'data mining', 'drug discovery', 'evidence base', 'human disease', 'improved', 'information organization', 'knowledge base', 'meetings', 'mouse genome', 'protein complex', 'text searching', 'therapeutic target', 'tool', 'web site']",NIGMS,UNIVERSITY OF DELAWARE,R01,2011,846522,0.2857614291470945
"Ontology-based Information Network to Support Vaccine Research  Project Summary (Abstract):  Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.  Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8311060,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'abstracting', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,264994,0.26826095444197856
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8120230,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,264994,0.26826095444197856
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7935464,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2010,267671,0.26826095444197856
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7735790,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2009,270375,0.26826095444197856
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7928868,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'biomedical ontology', 'computer science', 'computerized tools', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'natural language', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2010,605009,0.4014874277425867
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7684604,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Body of uterus', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'biomedical ontology', 'computer science', 'computerized tools', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'natural language', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2009,639134,0.4014874277425867
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7502636,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Body of uterus', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Numbers', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'computer science', 'computerized tools', 'concept', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2008,640921,0.4014874277425867
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7364235,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Body of uterus', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Numbers', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'computer science', 'computerized tools', 'concept', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2007,631600,0.4014874277425867
"Modeling the Effect of Drugs in Intergomics by Linking Drug Ontology and Pathways    DESCRIPTION (provided by applicant): High throughput experiments are now frequently part of clinical trials and many institutions establish prospective biospecimen collections from routine patient populations in order to run proteomics and metabolomics experiments. Because these samples are collected from routine clinical populations with co-morbidities and on drug therapies, it is necessary to account for the drugs in the data analysis in a systematic manner. Increasingly multiple high-throughput technologies, such as proteomics and metabolomics, are being used together which requires comprehensive pathway networks that make changes in the metabolome traceable to the proteome and in turn to the gene expression profile. In this study we propose to link drug therapies found in the clinical data with biologic pathways data used for the integrated analysis of high-throughput experimental results. Specifically we will integrate formal knowledge of biological pathways with drug knowledge found in the emergent national standard for the comprehensive knowledge representation for medicinal products, including the Veteran Administrations National Drug File Reference Terminology (NDF-RT), the National Drug Codes and the RxNorm clinical drug vocabulary. The hub of these terminologies is the Structured Product Labeling (SPL) standard for drug knowledge representation. SPL is part of the HL7 version 3 standards and based on the HL7 Reference Information Model (RIM). All U.S. pharmaceutical manufacturers today submit SPL data to the Food and Drug Agency (FDA). Pharmacodynamic knowledge is represented in SPL as a using the NDF-RT mechanism of action (MoA) classes. In this project we will expand these MoA classes with their ontological definitions, and thus link to the biologic pathways described in various pathway network resources including KEGG, Reactome, and the NCI/Nature Protein Interaction Database (PID), all of which use different formats and models. Our methodology for integration consists of (1) transforming the original pathway resource into a common data schema, and (2) purpose-driven reconciliation of overlapping content, by (3) connecting the MoA classes. Because no single pathway data schema exists and because SPL is already the hub of the national federated drug terminology, we propose to integrate the pathway data into the drug knowledge base itself. The resulting integrated data will be evaluated against the frequency of drugs encountered in clinical care and research. This work will yield revisions of existing ontologies and, only where necessary, new ontologies to describe drug- pathway interactions. The project will demonstrate how the HL7/ISO Reference Information Model can represent biological entities and processes taking a realist perspective, and thus set an important precedence for cross-domain data integration between basic sciences and clinical medicine that is essential for the translational research agenda. PUBLIC HEALTH RELEVANCE: The project will combine the national drug catalog with models of the biochemical regulation and metabolism of body functions. This will allow researchers to understand better the effect which drugs have on the results of laboratory tests which measure a large number of proteins and chemicals in the body at the same time.          n/a",Modeling the Effect of Drugs in Intergomics by Linking Drug Ontology and Pathways,7558891,R01GM086302,"['Accounting', 'Affect', 'Autacoids', 'Back', 'Basic Science', 'Biochemical Pathway', 'Biological', 'Caring', 'Chemicals', 'Class', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Trials', 'Code', 'Collection', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Data Sources', 'Databases', 'Drug Catalogs', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Drug Labeling', 'Evaluation', 'Food', 'Frequencies', 'Gene Expression Profile', 'Health Services Research', 'Human', 'Hypersensitivity', 'Industry', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Manuals', 'Manufacturer Name', 'Maps', 'MeSH Thesaurus', 'Measures', 'Metabolism', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Numbers', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacodynamics', 'Pharmacologic Substance', 'Pharmacotherapy', 'Population', 'Population Research', 'Process', 'Product Labeling', 'Proteins', 'Proteome', 'Proteomics', 'Public Health', 'Purpose', 'Regulation', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Resources', 'Running', 'Safety', 'Sampling', 'Source', 'Standards of Weights and Measures', 'Structure', 'System', 'Terminology', 'Testing', 'Time', 'Today', 'Translational Research', 'United States Department of Veterans Affairs', 'Vocabulary', 'Work', 'base', 'biochemical model', 'data integration', 'data modeling', 'drug standard', 'feeding', 'high throughput analysis', 'high throughput technology', 'information organization', 'interest', 'knowledge base', 'metabolomics', 'numb protein', 'prospective', 'research study']",NIGMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2008,244127,0.14366122970972778
"Modeling the Effect of Drugs in Intergomics by Linking Drug Ontology and Pathways    DESCRIPTION (provided by applicant): High throughput experiments are now frequently part of clinical trials and many institutions establish prospective biospecimen collections from routine patient populations in order to run proteomics and metabolomics experiments. Because these samples are collected from routine clinical populations with co-morbidities and on drug therapies, it is necessary to account for the drugs in the data analysis in a systematic manner. Increasingly multiple high-throughput technologies, such as proteomics and metabolomics, are being used together which requires comprehensive pathway networks that make changes in the metabolome traceable to the proteome and in turn to the gene expression profile. In this study we propose to link drug therapies found in the clinical data with biologic pathways data used for the integrated analysis of high-throughput experimental results. Specifically we will integrate formal knowledge of biological pathways with drug knowledge found in the emergent national standard for the comprehensive knowledge representation for medicinal products, including the Veteran Administrations National Drug File Reference Terminology (NDF-RT), the National Drug Codes and the RxNorm clinical drug vocabulary. The hub of these terminologies is the Structured Product Labeling (SPL) standard for drug knowledge representation. SPL is part of the HL7 version 3 standards and based on the HL7 Reference Information Model (RIM). All U.S. pharmaceutical manufacturers today submit SPL data to the Food and Drug Agency (FDA). Pharmacodynamic knowledge is represented in SPL as a using the NDF-RT mechanism of action (MoA) classes. In this project we will expand these MoA classes with their ontological definitions, and thus link to the biologic pathways described in various pathway network resources including KEGG, Reactome, and the NCI/Nature Protein Interaction Database (PID), all of which use different formats and models. Our methodology for integration consists of (1) transforming the original pathway resource into a common data schema, and (2) purpose-driven reconciliation of overlapping content, by (3) connecting the MoA classes. Because no single pathway data schema exists and because SPL is already the hub of the national federated drug terminology, we propose to integrate the pathway data into the drug knowledge base itself. The resulting integrated data will be evaluated against the frequency of drugs encountered in clinical care and research. This work will yield revisions of existing ontologies and, only where necessary, new ontologies to describe drug- pathway interactions. The project will demonstrate how the HL7/ISO Reference Information Model can represent biological entities and processes taking a realist perspective, and thus set an important precedence for cross-domain data integration between basic sciences and clinical medicine that is essential for the translational research agenda. PUBLIC HEALTH RELEVANCE: The project will combine the national drug catalog with models of the biochemical regulation and metabolism of body functions. This will allow researchers to understand better the effect which drugs have on the results of laboratory tests which measure a large number of proteins and chemicals in the body at the same time.          n/a",Modeling the Effect of Drugs in Intergomics by Linking Drug Ontology and Pathways,7692176,R01GM086302,"['Accounting', 'Affect', 'Autacoids', 'Back', 'Basic Science', 'Biochemical Pathway', 'Biological', 'Chemicals', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Trials', 'Code', 'Collection', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Drug Catalogs', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Drug Labeling', 'Evaluation', 'Food', 'Frequencies', 'Gene Expression Profile', 'Health Services Research', 'Human', 'Hypersensitivity', 'Industry', 'Information Systems', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Manuals', 'Manufacturer Name', 'Maps', 'MeSH Thesaurus', 'Measures', 'Metabolism', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'Nature', 'Ontology', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacodynamics', 'Pharmacologic Substance', 'Pharmacotherapy', 'Population', 'Population Research', 'Process', 'Product Labeling', 'Proteins', 'Proteome', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Running', 'Safety', 'Sampling', 'Source', 'Structure', 'System', 'Terminology', 'Testing', 'Time', 'Translational Research', 'United States Department of Veterans Affairs', 'Vocabulary', 'Work', 'base', 'biochemical model', 'clinical care', 'data integration', 'data modeling', 'drug standard', 'feeding', 'high throughput analysis', 'high throughput technology', 'information organization', 'interest', 'knowledge base', 'metabolomics', 'numb protein', 'patient population', 'prospective', 'public health relevance', 'research study']",NIGMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2009,234119,0.14366122970972778
"Modeling the Effect of Drugs in Intergomics by Linking Drug Ontology and Pathways    DESCRIPTION (provided by applicant): High throughput experiments are now frequently part of clinical trials and many institutions establish prospective biospecimen collections from routine patient populations in order to run proteomics and metabolomics experiments. Because these samples are collected from routine clinical populations with co-morbidities and on drug therapies, it is necessary to account for the drugs in the data analysis in a systematic manner. Increasingly multiple high-throughput technologies, such as proteomics and metabolomics, are being used together which requires comprehensive pathway networks that make changes in the metabolome traceable to the proteome and in turn to the gene expression profile. In this study we propose to link drug therapies found in the clinical data with biologic pathways data used for the integrated analysis of high-throughput experimental results. Specifically we will integrate formal knowledge of biological pathways with drug knowledge found in the emergent national standard for the comprehensive knowledge representation for medicinal products, including the Veteran Administrations National Drug File Reference Terminology (NDF-RT), the National Drug Codes and the RxNorm clinical drug vocabulary. The hub of these terminologies is the Structured Product Labeling (SPL) standard for drug knowledge representation. SPL is part of the HL7 version 3 standards and based on the HL7 Reference Information Model (RIM). All U.S. pharmaceutical manufacturers today submit SPL data to the Food and Drug Agency (FDA). Pharmacodynamic knowledge is represented in SPL as a using the NDF-RT mechanism of action (MoA) classes. In this project we will expand these MoA classes with their ontological definitions, and thus link to the biologic pathways described in various pathway network resources including KEGG, Reactome, and the NCI/Nature Protein Interaction Database (PID), all of which use different formats and models. Our methodology for integration consists of (1) transforming the original pathway resource into a common data schema, and (2) purpose-driven reconciliation of overlapping content, by (3) connecting the MoA classes. Because no single pathway data schema exists and because SPL is already the hub of the national federated drug terminology, we propose to integrate the pathway data into the drug knowledge base itself. The resulting integrated data will be evaluated against the frequency of drugs encountered in clinical care and research. This work will yield revisions of existing ontologies and, only where necessary, new ontologies to describe drug- pathway interactions. The project will demonstrate how the HL7/ISO Reference Information Model can represent biological entities and processes taking a realist perspective, and thus set an important precedence for cross-domain data integration between basic sciences and clinical medicine that is essential for the translational research agenda. PUBLIC HEALTH RELEVANCE: The project will combine the national drug catalog with models of the biochemical regulation and metabolism of body functions. This will allow researchers to understand better the effect which drugs have on the results of laboratory tests which measure a large number of proteins and chemicals in the body at the same time.          n/a",Modeling the Effect of Drugs in Intergomics by Linking Drug Ontology and Pathways,7924784,R01GM086302,"['Accounting', 'Affect', 'Autacoids', 'Back', 'Basic Science', 'Biochemical Pathway', 'Biological', 'Chemicals', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Trials', 'Code', 'Collection', 'Comorbidity', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Drug Catalogs', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Drug Labeling', 'Evaluation', 'Food', 'Frequencies', 'Gene Expression Profile', 'Health Services Research', 'Human', 'Hypersensitivity', 'Industry', 'Information Systems', 'Institution', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Link', 'Manuals', 'Manufacturer Name', 'Maps', 'MeSH Thesaurus', 'Measures', 'Metabolism', 'Methodology', 'Modeling', 'Nature', 'Ontology', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacodynamics', 'Pharmacologic Substance', 'Pharmacotherapy', 'Population', 'Population Research', 'Process', 'Product Labeling', 'Proteins', 'Proteome', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Running', 'Safety', 'Sampling', 'Source', 'Structure', 'System', 'Terminology', 'Testing', 'Time', 'Translational Research', 'United States Department of Veterans Affairs', 'Vocabulary', 'Work', 'base', 'biochemical model', 'clinical care', 'data integration', 'data modeling', 'drug standard', 'feeding', 'high throughput analysis', 'high throughput technology', 'information organization', 'interest', 'knowledge base', 'metabolomics', 'numb protein', 'patient population', 'prospective', 'public health relevance', 'research study']",NIGMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2010,232566,0.14366122970972778
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,7565504,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computer Systems Development', 'Computers', 'Computing Methodologies', 'Conflict (Psychology)', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Life', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Outsourcing', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Source', 'Staging', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'public health relevance', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2009,529858,0.42889898155465833
"Collaborative Development of Biomedical Ontologies and Terminologies DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient. PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.",Collaborative Development of Biomedical Ontologies and Terminologies,8997510,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Craniofacial Abnormalities', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'FaceBase', 'Future', 'Generations', 'Genes', 'Goals', 'Health', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial development', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'new technology', 'novel', 'open source', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2016,510376,0.4337754019248402
"Collaborative Development of Biomedical Ontologies and Terminologies DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient. PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.",Collaborative Development of Biomedical Ontologies and Terminologies,8803385,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Craniofacial Abnormalities', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'FaceBase', 'Future', 'Generations', 'Genes', 'Goals', 'Health', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial development', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'new technology', 'novel', 'open source', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2015,523965,0.4337754019248402
"Collaborative Development of Biomedical Ontologies and Terminologies     DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient.         PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.            ",Collaborative Development of Biomedical Ontologies and Terminologies,8628132,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'FaceBase', 'Future', 'Generations', 'Genes', 'Goals', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'malformation', 'new technology', 'novel', 'open source', 'public health relevance', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2014,525880,0.4337754019248402
"Collaborative Development of Biomedical Ontologies and Terminologies     DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient.         PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.            ",Collaborative Development of Biomedical Ontologies and Terminologies,8504843,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'Future', 'Generations', 'Genes', 'Goals', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'malformation', 'new technology', 'novel', 'open source', 'public health relevance', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2013,527736,0.4337754019248402
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,8242742,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computers', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Health', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Scientist', 'Source', 'Staging', 'Systems Development', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'conflict resolution', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2012,392767,0.42889898155465833
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,8039246,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computers', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Health', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Scientist', 'Source', 'Staging', 'Systems Development', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'conflict resolution', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2011,526649,0.42889898155465833
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,7774343,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computer Systems Development', 'Computers', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Life', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Outsourcing', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Scientist', 'Source', 'Staging', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'conflict resolution', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'public health relevance', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2010,525262,0.42889898155465833
"DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE Cardiovascular disease (CVD) and its associated risk factors such as hypertension and dyslipidemia constitute a major public-health burden due to increased mortality and morbidity and rising health care costs. Massive epidemiological data are needed to detect the small effects of many individual genes and the environment on these traits. However, sample sizes needed to make powerful inferences may only be reached by integrating multiple epidemiological studies. Meaningful integration of information from multiple studies requires the development of data ontologies which make it possible to integrate information across studies in an optimum manner so as to maximize the information content and hence the statistical power for detecting small effect sizes. A second compounding problem of data integration is that software applications that manage such study data are typically non-interoperable, i.e. “silos” of data, and are incapable of being shared in a syntactically and semantically meaningful manner. Consequently, an infrastructure that integrates across studies in an interoperable manner is needed to ensure that epidemiological cardiovascular research remains a viable and major player in the biomedical informatics revolution which is currently underway. The cancer Biomedical Informatics Grid (caBIGTM) is addressing these problems in the cancer domain by developing software systems that are able to exchange information or that are syntactically interoperable by accessing metadata that is semantically annotated using controlled vocabularies. Our overarching goal is to develop ontologies for integrating cardiovascular epidemiological data from multiple studies. Specifically, we propose three Aims: First, develop cardiovascular data ontologies and vocabularies for each of three disparate multi-center epidemiological studies that facilitate data integration across the studies and data mining for various phenotypes. Second, adopt a technology infrastructure that leverages the cardiovascular data ontologies and vocabularies using Model Driven Architecture (MDA) and caBIGTM tools to facilitate the integration and widespread sharing of cardiovascular data sets. Third, facilitate seamless data sharing and promote widespread data dissemination among research communities cutting across clinical, translational and epidemiological domains, primarily through collaboration with the established CardioVascular Research Grid (CVRG). Cardiovascular disease (CVD) is a leading cause of mortality and morbidity which contributes substantially to rising health care costs and consequently constitutes a major public health burden. Therefore, understanding the genetic and environmental effects on these CVD traits is important. Massive epidemiological study data are needed to detect the small individual effects of genes and their interactions, and integration of multiple epidemiological studies are necessary for generating large sample sizes. Unfortunately, integrating information from multiple studies in a meaningful manner requires the development of data ontologies (language and grammar). Our proposal addresses this need, and does this in a way that is informative and user-friendly from the End User’s point of view.",DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE,7558424,R01HL094286,"['Address', 'Adopted', 'Architecture', 'Area', 'Belief', 'Bioinformatics', 'Biological Assay', 'Budgets', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collaborations', 'Common Data Element', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Controlled Vocabulary', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Dyslipidemias', 'Electrocardiogram', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Equipment', 'Failure', 'Family Study', 'Ferrets', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Grant', 'Health Care Costs', 'Human', 'Hypertension', 'Individual', 'Language', 'Length', 'Literature', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Ontology', 'Peer Review', 'Phenotype', 'Physiological', 'Preparation', 'Protocols documentation', 'Public Health', 'Published Comment', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sample Size', 'Scientist', 'Solutions', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Time', 'Time Study', 'Vocabulary', 'Work', 'anticancer research', 'base', 'bench to bedside', 'biomedical informatics', 'cancer Biomedical Informatics Grid', 'cardiovascular disorder risk', 'data integration', 'data mining', 'data sharing', 'design', 'experience', 'graphical user interface', 'interest', 'meetings', 'mortality', 'software development', 'software systems', 'tool', 'trait', 'user-friendly', 'working group']",NHLBI,WASHINGTON UNIVERSITY,R01,2009,488000,0.19098583293092866
"DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE Cardiovascular disease (CVD) and its associated risk factors such as hypertension and dyslipidemia constitute a major public-health burden due to increased mortality and morbidity and rising health care costs. Massive epidemiological data are needed to detect the small effects of many individual genes and the environment on these traits. However, sample sizes needed to make powerful inferences may only be reached by integrating multiple epidemiological studies. Meaningful integration of information from multiple studies requires the development of data ontologies which make it possible to integrate information across studies in an optimum manner so as to maximize the information content and hence the statistical power for detecting small effect sizes. A second compounding problem of data integration is that software applications that manage such study data are typically non-interoperable, i.e. “silos” of data, and are incapable of being shared in a syntactically and semantically meaningful manner. Consequently, an infrastructure that integrates across studies in an interoperable manner is needed to ensure that epidemiological cardiovascular research remains a viable and major player in the biomedical informatics revolution which is currently underway. The cancer Biomedical Informatics Grid (caBIGTM) is addressing these problems in the cancer domain by developing software systems that are able to exchange information or that are syntactically interoperable by accessing metadata that is semantically annotated using controlled vocabularies. Our overarching goal is to develop ontologies for integrating cardiovascular epidemiological data from multiple studies. Specifically, we propose three Aims: First, develop cardiovascular data ontologies and vocabularies for each of three disparate multi-center epidemiological studies that facilitate data integration across the studies and data mining for various phenotypes. Second, adopt a technology infrastructure that leverages the cardiovascular data ontologies and vocabularies using Model Driven Architecture (MDA) and caBIGTM tools to facilitate the integration and widespread sharing of cardiovascular data sets. Third, facilitate seamless data sharing and promote widespread data dissemination among research communities cutting across clinical, translational and epidemiological domains, primarily through collaboration with the established CardioVascular Research Grid (CVRG). Cardiovascular disease (CVD) is a leading cause of mortality and morbidity which contributes substantially to rising health care costs and consequently constitutes a major public health burden. Therefore, understanding the genetic and environmental effects on these CVD traits is important. Massive epidemiological study data are needed to detect the small individual effects of genes and their interactions, and integration of multiple epidemiological studies are necessary for generating large sample sizes. Unfortunately, integrating information from multiple studies in a meaningful manner requires the development of data ontologies (language and grammar). Our proposal addresses this need, and does this in a way that is informative and user-friendly from the End User’s point of view.",DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE,7851333,R01HL094286,"['Address', 'Adopted', 'Architecture', 'Belief', 'Bioinformatics', 'Biological Assay', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Collaborations', 'Common Data Element', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Controlled Vocabulary', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Dyslipidemias', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Equipment', 'Failure', 'Family Study', 'Ferrets', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Health Care Costs', 'Human', 'Hypertension', 'Individual', 'Language', 'Literature', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Ontology', 'Phenotype', 'Physiological', 'Protocols documentation', 'Public Health', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sample Size', 'Scientist', 'Solutions', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Time', 'Time Study', 'Vocabulary', 'Work', 'anticancer research', 'biomedical informatics', 'cancer Biomedical Informatics Grid', 'cardiovascular disorder risk', 'data integration', 'data mining', 'data sharing', 'design', 'experience', 'mortality', 'software development', 'software systems', 'tool', 'trait', 'user-friendly']",NHLBI,WASHINGTON UNIVERSITY,R01,2010,474912,0.19098583293092866
"Protege: An Ontology-Development Platform for Biomedical Scientists DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Protégé to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Protégé generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Protégé user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries. PUBLIC HEALTH RELEVANCE: Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: An Ontology-Development Platform for Biomedical Scientists,8987580,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Health', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Terminology', 'Thinking', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'light weight', 'next generation', 'novel', 'online community', 'open source', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2016,526540,0.4479460046430301
"Protege: An Ontology-Development Platform for Biomedical Scientists DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Protégé to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Protégé generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Protégé user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries. PUBLIC HEALTH RELEVANCE: Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: An Ontology-Development Platform for Biomedical Scientists,8788417,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Health', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Terminology', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'next generation', 'novel', 'open source', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2015,526540,0.4479460046430301
"Protege: An Ontology-Development Platform for Biomedical Scientists     DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Prot¿g¿ system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Prot¿g¿ users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Prot¿g¿ to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Prot¿g¿ generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Prot¿g¿ user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries.          PUBLIC HEALTH RELEVANCE: Prot�g� is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Prot�g� supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Prot�g� resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.            ",Protege: An Ontology-Development Platform for Biomedical Scientists,8597446,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Mails', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'Support System', 'System', 'Technology', 'Terminology', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'next generation', 'novel', 'open source', 'public health relevance', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2014,533554,0.4479460046430301
"Protege: An Ontology-Development Platform for Biomedical Scientists     DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Prot¿g¿ system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Prot¿g¿ users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Prot¿g¿ to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Prot¿g¿ generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Prot¿g¿ user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries.          PUBLIC HEALTH RELEVANCE: Prot�g� is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Prot�g� supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Prot�g� resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.            ",Protege: An Ontology-Development Platform for Biomedical Scientists,8438361,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Mails', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'Support System', 'System', 'Technology', 'Terminology', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'next generation', 'novel', 'open source', 'public health relevance', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2013,533554,0.4479460046430301
"Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms Project Summary The nematode worm Caenorhabditis elegans has proven valuable as a model for many high-impact medical conditions. The strength of C. elegans derives from the extensive homologies between human and nematode genes (60-80%) and the many powerful tools available to manipulate genes in C. elegans, including expressing human genes. Researchers utilizing medical models based on C. elegans have converged on two main quantifiable measures of health and disease: locomotion and feeding; the latter is the focus of this proposal. C. elegans feeds on bacteria ingested through the pharynx, a rhythmic muscular pump in the worm’s throat. Alterations in pharyngeal activity are a sensitive indicator of dysfunction in muscles and neurons, as well as the animal’s overall health and metabolic state. C. elegans neurobiologists have long recognized the utility of the elec- tropharyngeogram (EPG), a non-invasive, whole-body electrical recording analogous to an electrocardiogram (ECG), which provides a quantitative readout of feeding. However, technical barriers associated with whole- animal electrophysiology have limited its adoption to fewer than fifteen laboratories world-wide. NemaMetrix Inc. surmounted these barriers by developing a turn-key, microfluidic system for EPG acquisition and analysis called the the ScreenChip platform. The proposed research and commercialization activities significantly expand the capabilities of the ScreenChip platform in two key respects. First, they enlarge the phenotyping capabilities of the platform by incorporating high-speed video of whole animal and pharyngeal movements. Second they develop a cloud database compatible with Gene Ontology, Open Biomedical Ontologies and Worm Ontology standards, allowing data-mining of combined electrophysiological, imaging and other data modalities. The machine-readable database will be compatible with artificial intelligence and machine learning algorithms. It will be accessible to all researchers to enable discovery of relationships between genotypes, phenotypes and treatments using large-scale analysis of multidimensional phenotypic profiles. The research and commercialization efforts culminate in an unprecedented integration of genetic, cellular, and organismal levels of analysis, with minimal training and effort required by users. Going forward, we envision the PheNom platform as a gold standard for medical research using C. elegans. n/a",Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms,9671422,R44GM119906,"['Adopted', 'Adoption', 'Aging', 'Amplifiers', 'Animal Model', 'Animals', 'Artificial Intelligence', 'Bacteria', 'Biomedical Research', 'Caenorhabditis elegans', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Electrocardiogram', 'Electrodes', 'Electrophysiology (science)', 'Equipment', 'Face', 'Familiarity', 'Feeds', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Models', 'Genotype', 'Gold', 'Health', 'Health Status', 'Human', 'Image', 'Ingestion', 'Kinetics', 'Laboratories', 'Locomotion', 'Market Research', 'Measures', 'Medical', 'Medical Research', 'Metabolic', 'Metabolic dysfunction', 'Metadata', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Molecular', 'Movement', 'Muscle', 'Nematoda', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Neurons', 'Ontology', 'Optics', 'Periodicity', 'Pharyngeal structure', 'Phase', 'Phenotype', 'Physiological', 'Pre-Clinical Model', 'Pump', 'Readability', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Speed', 'Statistical Data Interpretation', 'Stream', 'Structure', 'Surveys', 'System', 'Training', 'United States National Institutes of Health', 'Video Microscopy', 'addiction', 'automated image analysis', 'base', 'biomedical ontology', 'commercialization', 'data mining', 'design', 'feeding', 'human disease', 'human model', 'machine learning algorithm', 'member', 'phenotypic data', 'prevent', 'software development', 'success', 'tool', 'trait', 'web app']",NIGMS,"NEMAMETRIX, INC.",R44,2019,475637,0.16270034618167029
"Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms Project Summary The nematode worm Caenorhabditis elegans has proven valuable as a model for many high-impact medical conditions. The strength of C. elegans derives from the extensive homologies between human and nematode genes (60-80%) and the many powerful tools available to manipulate genes in C. elegans, including expressing human genes. Researchers utilizing medical models based on C. elegans have converged on two main quantifiable measures of health and disease: locomotion and feeding; the latter is the focus of this proposal. C. elegans feeds on bacteria ingested through the pharynx, a rhythmic muscular pump in the worm’s throat. Alterations in pharyngeal activity are a sensitive indicator of dysfunction in muscles and neurons, as well as the animal’s overall health and metabolic state. C. elegans neurobiologists have long recognized the utility of the elec- tropharyngeogram (EPG), a non-invasive, whole-body electrical recording analogous to an electrocardiogram (ECG), which provides a quantitative readout of feeding. However, technical barriers associated with whole- animal electrophysiology have limited its adoption to fewer than fifteen laboratories world-wide. NemaMetrix Inc. surmounted these barriers by developing a turn-key, microfluidic system for EPG acquisition and analysis called the the ScreenChip platform. The proposed research and commercialization activities significantly expand the capabilities of the ScreenChip platform in two key respects. First, they enlarge the phenotyping capabilities of the platform by incorporating high-speed video of whole animal and pharyngeal movements. Second they develop a cloud database compatible with Gene Ontology, Open Biomedical Ontologies and Worm Ontology standards, allowing data-mining of combined electrophysiological, imaging and other data modalities. The machine-readable database will be compatible with artificial intelligence and machine learning algorithms. It will be accessible to all researchers to enable discovery of relationships between genotypes, phenotypes and treatments using large-scale analysis of multidimensional phenotypic profiles. The research and commercialization efforts culminate in an unprecedented integration of genetic, cellular, and organismal levels of analysis, with minimal training and effort required by users. Going forward, we envision the PheNom platform as a gold standard for medical research using C. elegans. n/a",Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms,9467327,R44GM119906,"['Adopted', 'Adoption', 'Aging', 'Algorithms', 'Amplifiers', 'Animal Model', 'Animals', 'Artificial Intelligence', 'Bacteria', 'Biomedical Research', 'Caenorhabditis elegans', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Electrocardiogram', 'Electrodes', 'Electrophysiology (science)', 'Equipment', 'Face', 'Familiarity', 'Feeds', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Models', 'Genotype', 'Gold', 'Health', 'Health Status', 'Human', 'Image', 'Image Analysis', 'Kinetics', 'Laboratories', 'Locomotion', 'Machine Learning', 'Market Research', 'Measures', 'Medical', 'Medical Research', 'Metabolic', 'Metabolic dysfunction', 'Metadata', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Molecular', 'Movement', 'Muscle', 'Nematoda', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Neurons', 'Ontology', 'Optics', 'Periodicity', 'Pharyngeal structure', 'Phase', 'Phenotype', 'Physiological', 'Pre-Clinical Model', 'Pump', 'Readability', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Speed', 'Statistical Data Interpretation', 'Stream', 'Structure', 'Surveys', 'System', 'Training', 'United States National Institutes of Health', 'Video Microscopy', 'addiction', 'base', 'biomedical ontology', 'commercialization', 'data mining', 'design', 'feeding', 'human disease', 'human model', 'member', 'phenotypic data', 'prevent', 'software development', 'success', 'tool', 'trait', 'web app']",NIGMS,"NEMAMETRIX, INC.",R44,2018,510448,0.16270034618167029
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9404042,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'data integration', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'natural language', 'next generation', 'ontology development', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2018,564487,0.45133127125662514
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9217457,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'clinical development', 'data integration', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'natural language', 'next generation', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2017,578512,0.45133127125662514
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9848600,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'Infrastructure', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'data integration', 'data quality', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'large datasets', 'natural language', 'next generation', 'ontology development', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2020,559088,0.45133127125662514
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9607599,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'Infrastructure', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'data integration', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'natural language', 'next generation', 'ontology development', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2019,559237,0.45133127125662514
"The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De    DESCRIPTION (provided by applicant): We propose a program of research with two interlocking, foundational goals: (1) to develop and evaluate software for information extraction from clinical text corpora using existing Open Biomedical Ontologies (OBO) and (2) to develop and evaluate software for enrichment of existing biomedical ontologies from clinical text corpora. As a result of our work we will deliver the Ontology Development and Information Extraction Toolkit (ODIE) - a set of software components integrated with GATE, Prot¿g¿ and LexGrid, that will assist researchers and ontology developers in performing these tasks. As a testbed for our work, we will focus mainly on the National Cancer Institute Thesaurus - an existing OBO ontology, but will develop many of our components to be generalizable to other OBO ontologies. We have chosen the domain of hematopathology as a test case because of the rich and varied source of clinical documents, and the potential for our software to advance translational biomedical research in this area. However the majority of the components that we develop will be domain-neutral and will generalize to other areas within and outside of Oncology. The work we propose is significant for three contributions. First, we will develop novel methods or modify existing methods for accomplishing information extraction and ontology enrichment and we will evaluate the performance of these alternatives. Second, we will develop and disseminate generic software resources for performing these tasks, which leverage the National Center for Biomedical Ontology supported tools. Third, we will contribute to the development of existing OBO ontologies. The results of this work will use OBO ontologies in fundamental ways to advance biomedicine. This grant propose to develop a set of computer tools to assist researchers in (1) extracting meaning and codifying medical documents, and (2) building formal representations of knowledge from those documents. This work would benefit the general public by increasing the speed and efficiency of determining what information is in a particular medical document and allowing automated processing of large numbers of documents. Additionally, the project would contribute to the software for developing other applications by helping researchers build more comprehensive ontologies. The results of this work may benefit both medical research and patient care.          n/a",The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De,7896739,R01CA127979,"['Address', 'Architecture', 'Area', 'Biomedical Research', 'Clinical', 'Computer software', 'Computers', 'Detection', 'Development', 'General Population', 'Generic Drugs', 'Goals', 'Grant', 'Hematologic Neoplasms', 'Hematopathology', 'Human', 'Individual', 'Lesion', 'Medical', 'Medical Research', 'Metadata', 'Methods', 'Names', 'National Cancer Institute', 'Ontology', 'Patient Care', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Source', 'Speech', 'Speed', 'Stream', 'Structure', 'Suggestion', 'Testing', 'Text', 'Thesauri', 'Translational Research', 'Visual', 'Work', 'base', 'biomedical ontology', 'information organization', 'novel', 'oncology', 'phrases', 'programs', 'software development', 'statistics', 'text searching', 'tool']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2010,427872,0.4355937731530897
"The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De    DESCRIPTION (provided by applicant): We propose a program of research with two interlocking, foundational goals: (1) to develop and evaluate software for information extraction from clinical text corpora using existing Open Biomedical Ontologies (OBO) and (2) to develop and evaluate software for enrichment of existing biomedical ontologies from clinical text corpora. As a result of our work we will deliver the Ontology Development and Information Extraction Toolkit (ODIE) - a set of software components integrated with GATE, Prot¿g¿ and LexGrid, that will assist researchers and ontology developers in performing these tasks. As a testbed for our work, we will focus mainly on the National Cancer Institute Thesaurus - an existing OBO ontology, but will develop many of our components to be generalizable to other OBO ontologies. We have chosen the domain of hematopathology as a test case because of the rich and varied source of clinical documents, and the potential for our software to advance translational biomedical research in this area. However the majority of the components that we develop will be domain-neutral and will generalize to other areas within and outside of Oncology. The work we propose is significant for three contributions. First, we will develop novel methods or modify existing methods for accomplishing information extraction and ontology enrichment and we will evaluate the performance of these alternatives. Second, we will develop and disseminate generic software resources for performing these tasks, which leverage the National Center for Biomedical Ontology supported tools. Third, we will contribute to the development of existing OBO ontologies. The results of this work will use OBO ontologies in fundamental ways to advance biomedicine. This grant propose to develop a set of computer tools to assist researchers in (1) extracting meaning and codifying medical documents, and (2) building formal representations of knowledge from those documents. This work would benefit the general public by increasing the speed and efficiency of determining what information is in a particular medical document and allowing automated processing of large numbers of documents. Additionally, the project would contribute to the software for developing other applications by helping researchers build more comprehensive ontologies. The results of this work may benefit both medical research and patient care.          n/a",The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De,7669420,R01CA127979,"['Address', 'Architecture', 'Area', 'Biomedical Research', 'Body of uterus', 'Clinical', 'Computer software', 'Computers', 'Detection', 'Development', 'General Population', 'Generic Drugs', 'Goals', 'Grant', 'Hematologic Neoplasms', 'Hematopathology', 'Human', 'Individual', 'Lesion', 'Medical', 'Medical Research', 'Metadata', 'Methods', 'Names', 'National Cancer Institute', 'Ontology', 'Patient Care', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Source', 'Speech', 'Speed', 'Stream', 'Structure', 'Suggestion', 'Testing', 'Text', 'Thesauri', 'Translational Research', 'Visual', 'Work', 'base', 'biomedical ontology', 'information organization', 'novel', 'oncology', 'phrases', 'programs', 'software development', 'statistics', 'text searching', 'tool']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2009,564761,0.4355937731530897
"The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De    DESCRIPTION (provided by applicant): We propose a program of research with two interlocking, foundational goals: (1) to develop and evaluate software for information extraction from clinical text corpora using existing Open Biomedical Ontologies (OBO) and (2) to develop and evaluate software for enrichment of existing biomedical ontologies from clinical text corpora. As a result of our work we will deliver the Ontology Development and Information Extraction Toolkit (ODIE) - a set of software components integrated with GATE, Prot¿g¿ and LexGrid, that will assist researchers and ontology developers in performing these tasks. As a testbed for our work, we will focus mainly on the National Cancer Institute Thesaurus - an existing OBO ontology, but will develop many of our components to be generalizable to other OBO ontologies. We have chosen the domain of hematopathology as a test case because of the rich and varied source of clinical documents, and the potential for our software to advance translational biomedical research in this area. However the majority of the components that we develop will be domain-neutral and will generalize to other areas within and outside of Oncology. The work we propose is significant for three contributions. First, we will develop novel methods or modify existing methods for accomplishing information extraction and ontology enrichment and we will evaluate the performance of these alternatives. Second, we will develop and disseminate generic software resources for performing these tasks, which leverage the National Center for Biomedical Ontology supported tools. Third, we will contribute to the development of existing OBO ontologies. The results of this work will use OBO ontologies in fundamental ways to advance biomedicine. This grant propose to develop a set of computer tools to assist researchers in (1) extracting meaning and codifying medical documents, and (2) building formal representations of knowledge from those documents. This work would benefit the general public by increasing the speed and efficiency of determining what information is in a particular medical document and allowing automated processing of large numbers of documents. Additionally, the project would contribute to the software for developing other applications by helping researchers build more comprehensive ontologies. The results of this work may benefit both medical research and patient care.          n/a",The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De,7500835,R01CA127979,"['Address', 'Architecture', 'Area', 'Biomedical Research', 'Body of uterus', 'Clinical', 'Compatible', 'Computer software', 'Computers', 'Detection', 'Development', 'General Population', 'Generic Drugs', 'Goals', 'Grant', 'Hematologic Neoplasms', 'Hematopathology', 'Human', 'Individual', 'Lesion', 'Medical', 'Medical Research', 'Metadata', 'Methods', 'Names', 'National Cancer Institute', 'Numbers', 'Ontology', 'Patient Care', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Source', 'Speech', 'Speed', 'Stream', 'Structure', 'Suggestion', 'Testing', 'Text', 'Thesauri', 'Translational Research', 'Visual', 'Work', 'base', 'concept', 'information organization', 'novel', 'oncology', 'programs', 'software development', 'statistics', 'text searching', 'tool']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2008,551134,0.4355937731530897
"The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De    DESCRIPTION (provided by applicant): We propose a program of research with two interlocking, foundational goals: (1) to develop and evaluate software for information extraction from clinical text corpora using existing Open Biomedical Ontologies (OBO) and (2) to develop and evaluate software for enrichment of existing biomedical ontologies from clinical text corpora. As a result of our work we will deliver the Ontology Development and Information Extraction Toolkit (ODIE) - a set of software components integrated with GATE, Prot¿g¿ and LexGrid, that will assist researchers and ontology developers in performing these tasks. As a testbed for our work, we will focus mainly on the National Cancer Institute Thesaurus - an existing OBO ontology, but will develop many of our components to be generalizable to other OBO ontologies. We have chosen the domain of hematopathology as a test case because of the rich and varied source of clinical documents, and the potential for our software to advance translational biomedical research in this area. However the majority of the components that we develop will be domain-neutral and will generalize to other areas within and outside of Oncology. The work we propose is significant for three contributions. First, we will develop novel methods or modify existing methods for accomplishing information extraction and ontology enrichment and we will evaluate the performance of these alternatives. Second, we will develop and disseminate generic software resources for performing these tasks, which leverage the National Center for Biomedical Ontology supported tools. Third, we will contribute to the development of existing OBO ontologies. The results of this work will use OBO ontologies in fundamental ways to advance biomedicine. This grant propose to develop a set of computer tools to assist researchers in (1) extracting meaning and codifying medical documents, and (2) building formal representations of knowledge from those documents. This work would benefit the general public by increasing the speed and efficiency of determining what information is in a particular medical document and allowing automated processing of large numbers of documents. Additionally, the project would contribute to the software for developing other applications by helping researchers build more comprehensive ontologies. The results of this work may benefit both medical research and patient care.          n/a",The ODIE Toolkit - Software for Information Extraction and Biomedical Ontology De,7360352,R01CA127979,"['Address', 'Architecture', 'Area', 'Biomedical Research', 'Body of uterus', 'Clinical', 'Compatible', 'Computer software', 'Computers', 'Detection', 'Development', 'General Population', 'Generic Drugs', 'Goals', 'Grant', 'Hematologic Neoplasms', 'Hematopathology', 'Human', 'Individual', 'Medical', 'Medical Research', 'Metadata', 'Methods', 'Names', 'National Cancer Institute', 'Numbers', 'Ontology', 'Patient Care', 'Performance', 'Positioning Attribute', 'Process', 'Reference Standards', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Source', 'Speech', 'Speed', 'Stream', 'Structure', 'Suggestion', 'Testing', 'Text', 'Thesauri', 'Translational Research', 'Visual', 'Work', 'base', 'concept', 'information organization', 'novel', 'oncology', 'programs', 'software development', 'statistics', 'text searching', 'tool']",NCI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2007,570418,0.4355937731530897
"A family-based framework of quality assurance for biomedical ontologies DESCRIPTION (provided by applicant):  We will develop a family-based Quality Assurance (QA) framework for biomedical ontologies. Ontology QA is critical for increasing the use of ontologies in interdisciplinary research and in electronic health records (EHRs). We will develop computational techniques for identifying concepts with high probability of errors to improve efficiency and effectiveness of ontology QA.  Biomedical ontologies are large, complex knowledge representation systems that enable the integration of knowledge from different fields. The largest, best-known ontology repository is the Bioportal of the National Center for Biomedical Ontologies, containing more than 300 ontologies and tools for editing, browsing, and visualizing these ontologies.  However, many errors have been discovered in BioPortal's ontologies. QA in BioPortal has been mostly focused on use-cases and ad hoc techniques. Our computational techniques will automatically identify sets of concepts with a high likelihood of errors to empower ontology QA.  In past research, we have designed many QA techniques for single ontologies and have shown that sets of complex and uncommonly classified concepts have significantly higher percentages of errors. The theoretical bases for our QA are Abstraction Networks (AbNs), which summarize ontologies in a compact way. Using AbNs, we identified many error-prone concepts.  In this project, we will perform QA for whole families of ontologies. We have already identified seven preliminary families, based on structural properties. If a classification of concepts yields higher than usual error rates in several ontologies of a family F then we hypothesize that this will be true for such classifications for most ontologies of F. We will build a prototype software tool (BLUOWL) for determining AbNs for each family, to support QA of its ontologies.  Our primary test beds will be seven cancer-related ontologies, e.g., the National Cancer Institute thesaurus (NCIt), with different properties and purposes. Some non-cancer ontologies will also be included. We have published preliminary QA results for four such ontologies.  In evaluation studies, we will formulate and test hypotheses, statistically expressing the error expectations for various kinds of concepts. Ontologies' curators were recruited to review the suspicious concepts we will identify as part of their regular QA efforts (outside of our budget).  In summary, we will: Identify families of BioPortal ontologies based on ontology structure and design a unified methodology for deriving their abstraction networks; Build a software tool (BLUOWL) for QA of each family; Investigate concept classifications more likely to be erroneous in each family; Perform evaluation of our QA methodologies and usability studies for BLUOWL. PUBLIC HEALTH RELEVANCE:  Biomedical ontologies are critical for interdisciplinary research and electronic health records (EHRs). The largest, best-known ontology repository is the Bioportal of the National Center for Biomedical Ontologies, containing more than 300 ontologies. However, many errors have been discovered in BioPortal's ontologies. Quality Assurance (QA) in BioPortal has been mostly focused on use-cases and ad hoc techniques. We will develop a systematic, family-based framework for QA of biomedical ontologies. The theoretical basis for our QA methods is constituted by Abstraction Networks, which summarize ontologies in a compact way. The Abstraction Networks will support the detection of sets of concepts with a high likelihood of errors, which will improve the yield of the QA activities. A prototype software tool (BLUOWL) implementing our QA theory will be built.",A family-based framework of quality assurance for biomedical ontologies,9228344,R01CA190779,"['Beds', 'Biomedical Research', 'Budgets', 'Classification', 'Clinical Research', 'Complex', 'Computational Technique', 'Derivation procedure', 'Detection', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Evaluation Studies', 'Family', 'Foundations', 'Funding', 'Interdisciplinary Study', 'Knowledge', 'Light', 'Malignant Neoplasms', 'Methodology', 'Methods', 'National Cancer Institute', 'Ontology', 'Probability', 'Process', 'Property', 'Publishing', 'Recruitment Activity', 'Research', 'Research Design', 'Research Project Grants', 'Semantics', 'Software Tools', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'War', 'Work', 'anticancer research', 'base', 'biomedical ontology', 'design', 'expectation', 'health care delivery', 'improved', 'information organization', 'innovation', 'knowledge integration', 'prototype', 'public health relevance', 'quality assurance', 'repository', 'theories', 'tool', 'usability']",NCI,NEW JERSEY INSTITUTE OF TECHNOLOGY,R01,2017,555758,0.4058516256048162
"A family-based framework of quality assurance for biomedical ontologies DESCRIPTION (provided by applicant):  We will develop a family-based Quality Assurance (QA) framework for biomedical ontologies. Ontology QA is critical for increasing the use of ontologies in interdisciplinary research and in electronic health records (EHRs). We will develop computational techniques for identifying concepts with high probability of errors to improve efficiency and effectiveness of ontology QA.  Biomedical ontologies are large, complex knowledge representation systems that enable the integration of knowledge from different fields. The largest, best-known ontology repository is the Bioportal of the National Center for Biomedical Ontologies, containing more than 300 ontologies and tools for editing, browsing, and visualizing these ontologies.  However, many errors have been discovered in BioPortal's ontologies. QA in BioPortal has been mostly focused on use-cases and ad hoc techniques. Our computational techniques will automatically identify sets of concepts with a high likelihood of errors to empower ontology QA.  In past research, we have designed many QA techniques for single ontologies and have shown that sets of complex and uncommonly classified concepts have significantly higher percentages of errors. The theoretical bases for our QA are Abstraction Networks (AbNs), which summarize ontologies in a compact way. Using AbNs, we identified many error-prone concepts.  In this project, we will perform QA for whole families of ontologies. We have already identified seven preliminary families, based on structural properties. If a classification of concepts yields higher than usual error rates in several ontologies of a family F then we hypothesize that this will be true for such classifications for most ontologies of F. We will build a prototype software tool (BLUOWL) for determining AbNs for each family, to support QA of its ontologies.  Our primary test beds will be seven cancer-related ontologies, e.g., the National Cancer Institute thesaurus (NCIt), with different properties and purposes. Some non-cancer ontologies will also be included. We have published preliminary QA results for four such ontologies.  In evaluation studies, we will formulate and test hypotheses, statistically expressing the error expectations for various kinds of concepts. Ontologies' curators were recruited to review the suspicious concepts we will identify as part of their regular QA efforts (outside of our budget).  In summary, we will: Identify families of BioPortal ontologies based on ontology structure and design a unified methodology for deriving their abstraction networks; Build a software tool (BLUOWL) for QA of each family; Investigate concept classifications more likely to be erroneous in each family; Perform evaluation of our QA methodologies and usability studies for BLUOWL. PUBLIC HEALTH RELEVANCE:  Biomedical ontologies are critical for interdisciplinary research and electronic health records (EHRs). The largest, best-known ontology repository is the Bioportal of the National Center for Biomedical Ontologies, containing more than 300 ontologies. However, many errors have been discovered in BioPortal's ontologies. Quality Assurance (QA) in BioPortal has been mostly focused on use-cases and ad hoc techniques. We will develop a systematic, family-based framework for QA of biomedical ontologies. The theoretical basis for our QA methods is constituted by Abstraction Networks, which summarize ontologies in a compact way. The Abstraction Networks will support the detection of sets of concepts with a high likelihood of errors, which will improve the yield of the QA activities. A prototype software tool (BLUOWL) implementing our QA theory will be built.",A family-based framework of quality assurance for biomedical ontologies,9027817,R01CA190779,"['Beds', 'Biomedical Research', 'Budgets', 'Classification', 'Clinical Research', 'Complex', 'Computational Technique', 'Derivation procedure', 'Detection', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Evaluation Studies', 'Family', 'Funding', 'Interdisciplinary Study', 'Knowledge', 'Light', 'Malignant Neoplasms', 'Methodology', 'Methods', 'National Cancer Institute', 'Ontology', 'Probability', 'Process', 'Property', 'Publishing', 'Recruitment Activity', 'Research', 'Research Design', 'Research Project Grants', 'Semantics', 'Software Tools', 'Structure', 'System', 'Techniques', 'Testing', 'Thesauri', 'United States', 'War', 'Work', 'anticancer research', 'base', 'biomedical ontology', 'design', 'empowered', 'expectation', 'health care delivery', 'improved', 'information organization', 'innovation', 'prototype', 'public health relevance', 'quality assurance', 'repository', 'theories', 'tool', 'usability']",NCI,NEW JERSEY INSTITUTE OF TECHNOLOGY,R01,2016,600426,0.4058516256048162
"A family-based framework of quality assurance for biomedical ontologies     DESCRIPTION (provided by applicant):  We will develop a family-based Quality Assurance (QA) framework for biomedical ontologies. Ontology QA is critical for increasing the use of ontologies in interdisciplinary research and in electronic health records (EHRs). We will develop computational techniques for identifying concepts with high probability of errors to improve efficiency and effectiveness of ontology QA.  Biomedical ontologies are large, complex knowledge representation systems that enable the integration of knowledge from different fields. The largest, best-known ontology repository is the Bioportal of the National Center for Biomedical Ontologies, containing more than 300 ontologies and tools for editing, browsing, and visualizing these ontologies.  However, many errors have been discovered in BioPortal's ontologies. QA in BioPortal has been mostly focused on use-cases and ad hoc techniques. Our computational techniques will automatically identify sets of concepts with a high likelihood of errors to empower ontology QA.  In past research, we have designed many QA techniques for single ontologies and have shown that sets of complex and uncommonly classified concepts have significantly higher percentages of errors. The theoretical bases for our QA are Abstraction Networks (AbNs), which summarize ontologies in a compact way. Using AbNs, we identified many error-prone concepts.  In this project, we will perform QA for whole families of ontologies. We have already identified seven preliminary families, based on structural properties. If a classification of concepts yields higher than usual error rates in several ontologies of a family F then we hypothesize that this will be true for such classifications for most ontologies of F. We will build a prototype software tool (BLUOWL) for determining AbNs for each family, to support QA of its ontologies.  Our primary test beds will be seven cancer-related ontologies, e.g., the National Cancer Institute thesaurus (NCIt), with different properties and purposes. Some non-cancer ontologies will also be included. We have published preliminary QA results for four such ontologies.  In evaluation studies, we will formulate and test hypotheses, statistically expressing the error expectations for various kinds of concepts. Ontologies' curators were recruited to review the suspicious concepts we will identify as part of their regular QA efforts (outside of our budget).  In summary, we will: Identify families of BioPortal ontologies based on ontology structure and design a unified methodology for deriving their abstraction networks; Build a software tool (BLUOWL) for QA of each family; Investigate concept classifications more likely to be erroneous in each family; Perform evaluation of our QA methodologies and usability studies for BLUOWL.         PUBLIC HEALTH RELEVANCE:  Biomedical ontologies are critical for interdisciplinary research and electronic health records (EHRs). The largest, best-known ontology repository is the Bioportal of the National Center for Biomedical Ontologies, containing more than 300 ontologies. However, many errors have been discovered in BioPortal's ontologies. Quality Assurance (QA) in BioPortal has been mostly focused on use-cases and ad hoc techniques. We will develop a systematic, family-based framework for QA of biomedical ontologies. The theoretical basis for our QA methods is constituted by Abstraction Networks, which summarize ontologies in a compact way. The Abstraction Networks will support the detection of sets of concepts with a high likelihood of errors, which will improve the yield of the QA activities. A prototype software tool (BLUOWL) implementing our QA theory will be built.            ",A family-based framework of quality assurance for biomedical ontologies,8802486,R01CA190779,"['Beds', 'Biomedical Research', 'Budgets', 'Classification', 'Clinical Research', 'Complex', 'Computational Technique', 'Derivation procedure', 'Detection', 'Effectiveness', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Evaluation Studies', 'Family', 'Funding', 'Interdisciplinary Study', 'Knowledge', 'Light', 'Malignant Neoplasms', 'Methodology', 'Methods', 'National Cancer Institute', 'Ontology', 'Probability', 'Process', 'Property', 'Publishing', 'Recruitment Activity', 'Research', 'Research Design', 'Research Project Grants', 'Semantics', 'Software Tools', 'Structure', 'System', 'Techniques', 'Testing', 'Thesauri', 'United States', 'War', 'Work', 'anticancer research', 'base', 'biomedical ontology', 'design', 'empowered', 'expectation', 'health care delivery', 'improved', 'information organization', 'innovation', 'prototype', 'public health relevance', 'quality assurance', 'repository', 'theories', 'tool', 'usability']",NCI,NEW JERSEY INSTITUTE OF TECHNOLOGY,R01,2015,598037,0.4058516256048162
