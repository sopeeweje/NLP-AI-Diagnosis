text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Genomic sequencing to aid diagnosis in pediatric and prenatal practice: Examining clinical utility, ethical implications, payer coverage, and data integration in a diverse population. PROJECT SUMMARY I propose to gain experience in what are becoming the next big topics in genomic medicine – the integration of “big data” using data science in order to achieve “precision health” – what could be summed up as “data science of the future”. These topics emerge from - but go beyond - the narrower concept of “precision medicine” as the use of genetic information for treatment decisions. The goal is to develop experience in data science and precision health so that my work can serve as a bridge between my field of economics and these fields - and begin to prepare for the future challenges as they emerge. PROJECT NARRATIVE Both data science and precision health will be critical components of future health care interventions and impact patients, providers, and society. “Big Data” using data science includes the aggregation and analysis of data across platforms (includes information from, e.g. genetic testing, biosensors, wearables, and electronic health records, with such data analyzed using, e.g. artificial intelligence and machine learning). Precision Health uses a “big data” approach to focus on disease prevention and detection throughout one’s lifetime.","Genomic sequencing to aid diagnosis in pediatric and prenatal practice: Examining clinical utility, ethical implications, payer coverage, and data integration in a diverse population.",9929780,U01HG009599,"['Artificial Intelligence', 'Big Data', 'Biosensor', 'Childhood', 'Clinical', 'Data Analyses', 'Data Science', 'Detection', 'Diagnosis', 'Economics', 'Electronic Health Record', 'Ethics', 'Future', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Healthcare', 'Intervention', 'Machine Learning', 'Patients', 'Population Heterogeneity', 'Precision Health', 'Provider', 'Societies', 'Source', 'Sum', 'Work', 'data integration', 'disorder prevention', 'experience', 'formal learning', 'genetic information', 'informal learning', 'precision medicine', 'prenatal']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2019,166973,0.18466751062145337
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9729464,R25MD010396,"['Address', 'Articulation', 'Base Pairing', 'Big Data', 'Big Data Methods', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development Plans', 'Discipline', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Illinois', 'Informatics', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Program Development', 'Proteomics', 'Reading', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'Systems Biology', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Training and Education', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'computerized tools', 'data acquisition', 'data sharing', 'deep learning', 'experience', 'faculty research', 'individualized medicine', 'informatics\xa0tool', 'innovation', 'minority scientist', 'posters', 'programs', 'public health relevance', 'recruit', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool development', 'undergraduate research', 'undergraduate student']",NIMHD,FISK UNIVERSITY,R25,2019,216000,0.30084241724890537
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9503633,R25MD010396,"['Address', 'Articulation', 'Base Pairing', 'Big Data', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development Plans', 'Discipline', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Illinois', 'Informatics', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Program Development', 'Proteomics', 'Reading', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'Systems Biology', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Training and Education', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'deep learning', 'experience', 'faculty research', 'individualized medicine', 'innovation', 'minority scientist', 'posters', 'programs', 'public health relevance', 'recruit', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool', 'tool development', 'undergraduate research', 'undergraduate student']",NIMHD,FISK UNIVERSITY,R25,2018,216000,0.30084241724890537
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9303203,R25MD010396,"['Address', 'Articulation', 'Base Pairing', 'Big Data', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development Plans', 'Discipline', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Illinois', 'Informatics', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Program Development', 'Proteomics', 'Reading', 'Recruitment Activity', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'Systems Biology', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Training and Education', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'experience', 'faculty research', 'individualized medicine', 'innovation', 'minority scientist', 'posters', 'programs', 'public health relevance', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool', 'tool development', 'undergraduate research', 'undergraduate student']",NIMHD,FISK UNIVERSITY,R25,2017,216000,0.30084241724890537
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9150655,R25MD010396,"['Address', 'Base Pairing', 'Big Data', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Data Analyses', 'Development Plans', 'Discipline', 'Diving', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Health', 'Illinois', 'Informatics', 'Joints', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Proteomics', 'Reading', 'Recruitment Activity', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Skills Development', 'Students', 'System', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'education research', 'experience', 'faculty research', 'individualized medicine', 'innovation', 'minority scientist', 'posters', 'programs', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool', 'tool development', 'undergraduate research']",NIMHD,FISK UNIVERSITY,R25,2016,204941,0.30084241724890537
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.   PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9049946,R25MD010396,"['Address', 'Base Pairing', 'Big Data', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development', 'Development Plans', 'Discipline', 'Diving', 'Doctor of Philosophy', 'Education', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Health', 'Illinois', 'Informatics', 'Joints', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Minority', 'Molecular Biology', 'Oral', 'Participant', 'Pathway interactions', 'Program Development', 'Proteomics', 'Reading', 'Recruitment Activity', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'System', 'Technology', 'Time', 'Training', 'Training Programs', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'experience', 'individualized medicine', 'innovation', 'posters', 'programs', 'responsible research conduct', 'skills', 'tool', 'tool development', 'undergraduate research']",NIMHD,FISK UNIVERSITY,R25,2015,168294,0.30084241724890537
"An Integrative Approach to Drug Repositioning Using Decision Tree Based Machine Learning PROJECT SUMMARY/ABSTRACT Despite recent advances in life sciences and technology, the amount of money spent developing a single drug has stayed drastically expensive. Overall efficiencies have caused drug development to stay the same, with an average cost of $2.6 billion and 15 years to develop a single drug. Considering these challenges, there is an increased need for drug repositioning, in which new indications are found for existing or unapproved drugs. Here we introduce an approach that integrates only drug similarity metrics, such as side effect, structure, and target similarities, to identify novel indications for drugs. By focusing on drug similarity metrics, our proposed method allows for applications towards orphan molecules that presently have no primary indication. To improve upon the current methods of drug repurposing, we propose the developing of a computational approach that utilizes multiple data types within a machine-learning framework in order to predict indications a drug may treat. Based on the observations that similar drugs are used for similar indications, this method utilizes publicly available databases to identify associations between drugs, and integrates drug similarity data, as well as drug-target specific information, into a machine-learning framework in order to accurately predict indications for these drugs. Altogether, our method provides a novel, broadly applicable strategy that can identify novel indications, allowing for an accelerated and more efficient method for future drug development and repositioning efforts. PROJECT NARRATIVE Bringing a drug to market requires an enormous amount of time and money, so our proposed research is designed to address this unmet need to streamline the drug discovery process. Using big data analysis, we are developing a computational method to utilize drug similarity information to predict novel diseases that drugs can treat.",An Integrative Approach to Drug Repositioning Using Decision Tree Based Machine Learning,9873823,F31LM013058,"['Address', 'Big Data', 'Biological Sciences', 'Computing Methodologies', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Decision Trees', 'Disease', 'Drug Targeting', 'Drug Utilization', 'Drug usage', 'Encyclopedias', 'Future', 'Genes', 'Genome', 'Institutes', 'Investigation', 'Literature', 'Machine Learning', 'Methodology', 'Methods', 'Mind', 'Modeling', 'Molecular', 'Orphan', 'Pharmaceutical Preparations', 'Process', 'Research', 'Risk', 'Source', 'Speed', 'Structure', 'Technology', 'Testing', 'Time', 'Toxic effect', 'United States Food and Drug Administration', 'Validation', 'Viagra', 'Voting', 'Work', 'base', 'clinically relevant', 'cost', 'design', 'drug candidate', 'drug development', 'drug discovery', 'improved', 'machine learning method', 'multiple data types', 'novel', 'novel therapeutics', 'side effect']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,F31,2020,45520,0.08763652469785628
"An Integrative Approach to Drug Repositioning Using Decision Tree Based Machine Learning PROJECT SUMMARY/ABSTRACT Despite recent advances in life sciences and technology, the amount of money spent developing a single drug has stayed drastically expensive. Overall efficiencies have caused drug development to stay the same, with an average cost of $2.6 billion and 15 years to develop a single drug. Considering these challenges, there is an increased need for drug repositioning, in which new indications are found for existing or unapproved drugs. Here we introduce an approach that integrates only drug similarity metrics, such as side effect, structure, and target similarities, to identify novel indications for drugs. By focusing on drug similarity metrics, our proposed method allows for applications towards orphan molecules that presently have no primary indication. To improve upon the current methods of drug repurposing, we propose the developing of a computational approach that utilizes multiple data types within a machine-learning framework in order to predict indications a drug may treat. Based on the observations that similar drugs are used for similar indications, this method utilizes publicly available databases to identify associations between drugs, and integrates drug similarity data, as well as drug-target specific information, into a machine-learning framework in order to accurately predict indications for these drugs. Altogether, our method provides a novel, broadly applicable strategy that can identify novel indications, allowing for an accelerated and more efficient method for future drug development and repositioning efforts. PROJECT NARRATIVE Bringing a drug to market requires an enormous amount of time and money, so our proposed research is designed to address this unmet need to streamline the drug discovery process. Using big data analysis, we are developing a computational method to utilize drug similarity information to predict novel diseases that drugs can treat.",An Integrative Approach to Drug Repositioning Using Decision Tree Based Machine Learning,9682615,F31LM013058,"['Address', 'Big Data', 'Biological Sciences', 'Computing Methodologies', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Decision Trees', 'Disease', 'Drug Targeting', 'Drug Utilization', 'Drug usage', 'Encyclopedias', 'Future', 'Genes', 'Genome', 'Institutes', 'Investigation', 'Literature', 'Machine Learning', 'Methodology', 'Methods', 'Mind', 'Modeling', 'Molecular', 'Orphan', 'Pharmaceutical Preparations', 'Process', 'Research', 'Risk', 'Source', 'Speed', 'Structure', 'Technology', 'Testing', 'Time', 'Toxic effect', 'United States Food and Drug Administration', 'Validation', 'Viagra', 'Voting', 'Work', 'base', 'clinically relevant', 'cost', 'design', 'drug candidate', 'drug development', 'drug discovery', 'improved', 'learning strategy', 'novel', 'novel therapeutics', 'side effect']",NLM,WEILL MEDICAL COLL OF CORNELL UNIV,F31,2019,45016,0.08763652469785628
"Modernizing Emergency Department Nurse Triage via Big Data Analytics PROJECT SUMMARY/ ABSTRACT Emergency department (ED) nurses triage over 136 million patients each year in the United States. The goal of triage is to assess and identify clinical conditions in order to prioritize those with the most significant risk of morbidity and mortality. Current practice uses the Emergency Severity Index (ESI) score to group patients by resource utilization. ESI has significant limitations including: racial bias, poor relation to patient-centered outcomes, subjectivity, and failure to differentiate acute patients (poor specificity). As such, the ESI tool fails to identify patient-specific factors, that are present at the time of triage, to accurately predict critical conditions requiring life-saving treatments. Due to its time sensitivity, complex symptomology, variable outcomes, and a national cost burden of $21 billion, acute coronary syndrome (ACS) will be used as an exemplar time-sensitive condition to develop a new predictive machine learning algorithm to be used for ED triage. Of 800,000 new annual ACS cases in the United States, nurses fail to identify approximately 50% during triage. This suggests an urgent need to develop triage tools, specifically ones that correctly identify ACS early, which could potentially reduce mortality by 10%-20%. This project proposes to use big data analytics to address the critical gaps of the ESI tool and nurse failure to identify ACS at triage. A large cohort of patients presenting to 17 different EDs with symptoms suspicious of ACS will be used to create a multidimensional database, extracting routinely collected patient factors from the electronic health record data acquired at initial nurse triage. This project will use state-of-the-art machine learning approaches that incorporate the complex interactions between patient factors to identify patients with true critical coronary occlusion that require time dependent treatment. The innovation of this study stems from having access to a world renowned academic medical center that is able to conduct full-scale studies using electronic health records of over 4.2 million patient encounters. This project aligns with the NINR’s strategic vision for nurses to use emerging technologies (big data) to predict patient trajectories, inform interventions and support real time clinical decision making. By using advanced machine learning concepts, we will translate our final machine model into a robust clinical tool to assist nurses in making real time clinical decisions to accurately identity ACS events and initiate timely treatment, thereby improving patient outcomes. Study findings have potential to change the paradigm of ED nurse triage to be more objective and data-driven, thereby recognizing critical conditions at initial triage and eliminating unnecessary morbidity and mortality. PROJECT NARRATIVE Emergency department nurses triage over 136 million patients a year, using the Emergency Severity Index score that has significant limitations and often fails to identify patients with critical time-sensitive conditions such as acute coronary syndrome (ACS) approximately 50% of the time. To address these gaps, this project aims to develop a predictive algorithm using state-of-the-art machine learning concepts that incorporates the complex interactions between medical data available at nurse triage in order to identify patients with true critical coronary occlusion that requires time dependent treatment. Such a model can be translated into a robust clinical decision support tool to assist nurses in making real time clinical decisions to accurately identify ACS events and initiate timely treatment, thereby improving patient outcomes.",Modernizing Emergency Department Nurse Triage via Big Data Analytics,10051328,F31NR018589,"['Academic Medical Centers', 'Accident and Emergency department', 'Acute', 'Address', 'Algorithms', 'Area', 'Area Under Curve', 'Big Data', 'Big Data Methods', 'Chest Pain', 'Clinical', 'Complex', 'Coronary Occlusions', 'Data', 'Data Aggregation', 'Data Science', 'Data Set', 'Databases', 'Dyspepsia', 'Dyspnea', 'Electronic Health Record', 'Emergency Medicine', 'Emergency Nursing', 'Emergency Situation', 'Emerging Technologies', 'Event', 'Failure', 'Goals', 'Hospitalization', 'Interdisciplinary Study', 'Intervention', 'Life', 'Machine Learning', 'Manuals', 'Medical', 'Medical History', 'Medical center', 'Methods', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Nature', 'Nausea and Vomiting', 'Nurses', 'Nursing Models', 'Outcome', 'Outcome Study', 'Output', 'Palpitations', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physicians', 'ROC Curve', 'Research', 'Resources', 'Retrospective cohort', 'Risk', 'Sampling', 'Savings', 'Severities', 'Specificity', 'Suggestion', 'Symptoms', 'Syncope', 'Techniques', 'Time', 'Training', 'Translating', 'Triage', 'United States', 'Universities', 'Validation', 'Vision', 'Work', 'acute coronary syndrome', 'advanced analytics', 'base', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'follow-up', 'health record', 'improved', 'indexing', 'innovation', 'machine learning algorithm', 'mathematical model', 'mortality', 'pain patient', 'prediction algorithm', 'predictive modeling', 'primary outcome', 'racial bias', 'routine care', 'stem', 'support tools', 'symptomatology', 'tool']",NINR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F31,2020,14320,0.06694777300028691
"Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems DESCRIPTION (provided by applicant): Abstract Biomedical science, higher education, software and technology are simultaneously undergoing tectonic shifts. The amazing pace of software and technological development are driving equally amazing advances in the ability to acquire massive data sets in the biomedical sciences. These new Big Biomedical data sets come in the form of complex measurements, such as that of the brain, genome, proteome and human biome or massive databases, such as with electronic health records. Big Data issues, such as reproducibility of processing, measurement and analysis techniques, are increasingly complex, and crucial. Across all domains there is a knowledge gap of researchers to analyze and interpret these new data sets and the current higher education model cannot meet the insatiable demand for this training. We propose to make substantial progress on these issues in two domains. Specifically, we propose to use Massive Open Online Courses (MOOCs) to create two series, one in neuroimaging and one in genomics. These series will allow for flexible, student paced, low cost scalable training for tens of thousands of students. Along with these series, we propose the creation of modular Big Data biostatistical content that can be used by students as well as teachers. This effort will be parallel to work on an intelligent tutoring syste called swirl. This application proposes to use swirl to create rich, gamified learning environments for students. All of the material created from this grant will be open access and free. PUBLIC HEALTH RELEVANCE:  Project narrative: We propose two Massive Open Online Course series in neuroimaging and genomic Big Data analysis as well as the creation of modular Big Data statistics content and content creation for an intelligent tutoring system.","Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems",9061684,R25EB020378,"['Adopted', 'Amaze', 'Area', 'Attention', 'Automobile Driving', 'Big Data', 'Biological', 'Biology', 'Brain', 'Clinical Trials', 'Communities', 'Complex', 'Computer software', 'Cost Analysis', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Discipline', 'Drops', 'Education', 'Educational Curriculum', 'Educational Models', 'Educational process of instructing', 'Electronic Health Record', 'Enrollment', 'Environment', 'Generations', 'Genes', 'Genome', 'Genomics', 'Grant', 'Head', 'Health', 'Human', 'Image', 'Knowledge', 'Laboratories', 'Learning Module', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medicine', 'Modeling', 'Molecular Biology', 'Molecular Medicine', 'Multivariate Analysis', 'Persons', 'Population', 'Principal Investigator', 'Problem Sets', 'Proteome', 'Public Health', 'Public Health Nurses', 'Public Health Nursing', 'Race', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Series', 'Services', 'Statistical Data Interpretation', 'Stream', 'Students', 'System', 'Systems Biology', 'Teacher Professional Development', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Touch sensation', 'Training', 'Training Activity', 'Training Programs', 'Universities', 'Work', 'abstracting', 'big biomedical data', 'contrast enhanced', 'cost', 'course module', 'density', 'educational atmosphere', 'flexibility', 'hands-on learning', 'higher education', 'instructor', 'learning materials', 'lectures', 'massive open online courses', 'meetings', 'multidisciplinary', 'neuroimaging', 'new technology', 'novel strategies', 'open source', 'operation', 'process repeatability', 'programs', 'research study', 'skills', 'statistics', 'teacher', 'tutoring']",NIBIB,JOHNS HOPKINS UNIVERSITY,R25,2016,209444,0.16113678347462793
"Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems DESCRIPTION (provided by applicant): Abstract Biomedical science, higher education, software and technology are simultaneously undergoing tectonic shifts. The amazing pace of software and technological development are driving equally amazing advances in the ability to acquire massive data sets in the biomedical sciences. These new Big Biomedical data sets come in the form of complex measurements, such as that of the brain, genome, proteome and human biome or massive databases, such as with electronic health records. Big Data issues, such as reproducibility of processing, measurement and analysis techniques, are increasingly complex, and crucial. Across all domains there is a knowledge gap of researchers to analyze and interpret these new data sets and the current higher education model cannot meet the insatiable demand for this training. We propose to make substantial progress on these issues in two domains. Specifically, we propose to use Massive Open Online Courses (MOOCs) to create two series, one in neuroimaging and one in genomics. These series will allow for flexible, student paced, low cost scalable training for tens of thousands of students. Along with these series, we propose the creation of modular Big Data biostatistical content that can be used by students as well as teachers. This effort will be parallel to work on an intelligent tutoring syste called swirl. This application proposes to use swirl to create rich, gamified learning environments for students. All of the material created from this grant will be open access and free. PUBLIC HEALTH RELEVANCE:  Project narrative: We propose two Massive Open Online Course series in neuroimaging and genomic Big Data analysis as well as the creation of modular Big Data statistics content and content creation for an intelligent tutoring system.","Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems",8935788,R25EB020378,"['Adopted', 'Amaze', 'Area', 'Attention', 'Automobile Driving', 'Big Data', 'Biological', 'Biology', 'Brain', 'Clinical Trials', 'Communities', 'Complex', 'Computer software', 'Cost Analysis', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Discipline', 'Drops', 'Education', 'Educational Curriculum', 'Educational Models', 'Educational process of instructing', 'Electronic Health Record', 'Enrollment', 'Environment', 'Generations', 'Genes', 'Genome', 'Genomics', 'Grant', 'Head', 'Health', 'Human', 'Image', 'Knowledge', 'Laboratories', 'Learning', 'Learning Module', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medicine', 'Modeling', 'Molecular Biology', 'Molecular Medicine', 'Multivariate Analysis', 'Persons', 'Population', 'Principal Investigator', 'Proteome', 'Public Health', 'Public Health Nurses', 'Public Health Nursing', 'Race', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Series', 'Services', 'Solutions', 'Stream', 'Students', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Touch sensation', 'Training', 'Training Programs', 'Universities', 'Work', 'abstracting', 'contrast enhanced', 'cost', 'density', 'flexibility', 'instructor', 'lectures', 'meetings', 'multidisciplinary', 'neuroimaging', 'new technology', 'novel strategies', 'open source', 'operation', 'process repeatability', 'programs', 'research study', 'skills', 'statistics', 'teacher']",NIBIB,JOHNS HOPKINS UNIVERSITY,R25,2015,212771,0.16113678347462793
"Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems     DESCRIPTION (provided by applicant): Abstract Biomedical science, higher education, software and technology are simultaneously undergoing tectonic shifts. The amazing pace of software and technological development are driving equally amazing advances in the ability to acquire massive data sets in the biomedical sciences. These new Big Biomedical data sets come in the form of complex measurements, such as that of the brain, genome, proteome and human biome or massive databases, such as with electronic health records. Big Data issues, such as reproducibility of processing, measurement and analysis techniques, are increasingly complex, and crucial. Across all domains there is a knowledge gap of researchers to analyze and interpret these new data sets and the current higher education model cannot meet the insatiable demand for this training. We propose to make substantial progress on these issues in two domains. Specifically, we propose to use Massive Open Online Courses (MOOCs) to create two series, one in neuroimaging and one in genomics. These series will allow for flexible, student paced, low cost scalable training for tens of thousands of students. Along with these series, we propose the creation of modular Big Data biostatistical content that can be used by students as well as teachers. This effort will be parallel to work on an intelligent tutoring syste called swirl. This application proposes to use swirl to create rich, gamified learning environments for students. All of the material created from this grant will be open access and free.         PUBLIC HEALTH RELEVANCE:  Project narrative: We propose two Massive Open Online Course series in neuroimaging and genomic Big Data analysis as well as the creation of modular Big Data statistics content and content creation for an intelligent tutoring system.            ","Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems",8829370,R25EB020378,"['Adopted', 'Amaze', 'Area', 'Attention', 'Automobile Driving', 'Big Data', 'Biological', 'Biology', 'Brain', 'Clinical Trials', 'Communities', 'Complex', 'Computer software', 'Cost Analysis', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Discipline', 'Drops', 'Education', 'Educational Curriculum', 'Educational Models', 'Educational process of instructing', 'Electronic Health Record', 'Enrollment', 'Environment', 'Generations', 'Genes', 'Genome', 'Genomics', 'Grant', 'Head', 'Human', 'Image', 'Knowledge', 'Laboratories', 'Learning', 'Learning Module', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medicine', 'Modeling', 'Molecular Biology', 'Molecular Medicine', 'Multivariate Analysis', 'Persons', 'Population', 'Principal Investigator', 'Proteome', 'Public Health', 'Public Health Nurses', 'Public Health Nursing', 'Race', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Series', 'Services', 'Solutions', 'Stream', 'Students', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Touch sensation', 'Training', 'Training Programs', 'Universities', 'Work', 'abstracting', 'cost', 'density', 'flexibility', 'instructor', 'lectures', 'meetings', 'multidisciplinary', 'neuroimaging', 'new technology', 'novel strategies', 'open source', 'operation', 'process repeatability', 'programs', 'public health relevance', 'research study', 'skills', 'statistics', 'teacher']",NIBIB,JOHNS HOPKINS UNIVERSITY,R25,2014,216000,0.16113678347462793
"Summer Institute for Statistics of Big Data DESCRIPTION:  Funding is sought for the Summer Institute for Statistics of Big Data (SISBID) at the University of Washington. This program will provide workshops on the statistical and computational skills needed to access, process, manage, and analyze large biomedical data sets. It will be co-directed by Ali Shojaie and Daniela Witten, faculty in the Department of Biostatistics at University of Washington.  The SISBID program will consist of five 2.5-day in-person courses, or modules, taught at the University of Washington each July. An individual participant can register for whichever set of modules he or she chooses. The five modules are as follows: (1) Accessing Biomedical Big Data; (2) Data Visualization; (3) Supervised Methods for Statistical Machine Learning; (4) Unsupervised Methods for Statistical Machine Learning; (5) Reproducible Research for Biomedical Big Data. Each module will consist of a combination of formal lectures and hands-on computing labs. Participants will work together in teams in order to apply the skills that they develop in each module to important problems drawn from relevant case studies.  The primary audience for SISBID will consist of biomedical scientists who would like to develop the statistical and computational training needed to make use of Biomedical Big Data. The secondary audience will consist of individuals with stronger statistical or computational backgrounds but little exposure to biology, who will learn how to apply their skills to problems associated with Biomedical Big Data. Participants will include advanced undergraduates, graduate students, post-doctoral fellows, and researchers, and will be drawn from industry, government, and academia. In order to ensure that all participants are able to fully engage in the program, participants will be expected to already have some prior background in R programming and statistical inference, which can be obtained by taking two free online courses before the program begins.  Each of the five modules will be co-taught by two instructors. The ten instructors will be drawn from top universities and research centers across the U.S., such as the University of Washington, Rice University, University of Iowa, Johns Hopkins University, MD Anderson Cancer Research Center, Fred Hutchinson Cancer Research Center, and University of North Carolina. They have been selected based on research expertise and excellence in teaching.  Lecture videos and slides will be made freely available online so that individuals who are unable to attend SISBID in person can still benefit from the program.  This proposal specifically requests funds for 55 student / postdoctoral fellow travel scholarships per year, 130 student / postdoctoral fellow registration scholarships per year, instructor travel and stipends, teaching assistant stipends, and PI salary support. PUBLIC HEALTH RELEVANCE:   In recent years, the biomedical sciences have been inundated by Big Data, such as DNA sequence data and electronic medical records. In principle, it should be possible to use such data for a variety of tasks, such as predicting an individual's risk of developing diabetes or cancer, and tailoring therapies to an individual should he or she become ill. The Summer Institute for Statistics of Big Data will provide biomedical researchers with the computational and statistical training needed in order to take advantage of Big Data, so that they can more effectively use it to understand human diseases and to improve human health.",Summer Institute for Statistics of Big Data,9063061,R25EB020380,"['Academia', 'Applied Skills', 'Area', 'Big Data', 'Biology', 'Biomedical Research', 'Biometry', 'Cancer Center', 'Case Study', 'Collection', 'Computer software', 'Computerized Medical Record', 'DNA Sequence', 'Data', 'Data Set', 'Diabetes Mellitus', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Exposure to', 'Faculty', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Government', 'Health', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Iowa', 'Knowledge', 'Learning', 'Learning Module', 'Machine Learning', 'Malignant Neoplasms', 'NCI Center for Cancer Research', 'North Carolina', 'Participant', 'Persons', 'Postdoctoral Fellow', 'Process', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rice', 'Risk', 'Running', 'Scholarship', 'Science', 'Slide', 'Statistical Computing', 'Statistical Methods', 'Students', 'Training', 'Training Activity', 'Training Programs', 'Travel', 'United States', 'Universities', 'Videotape', 'Wages', 'Washington', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'data visualization', 'graduate student', 'human disease', 'improved', 'instructor', 'learning materials', 'lectures', 'massive open online courses', 'member', 'online course', 'open source', 'programs', 'skills', 'statistics', 'summer institute', 'teacher', 'teaching assistant', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R25,2016,159605,0.2833312364835838
"Summer Institute for Statistics of Big Data DESCRIPTION:  Funding is sought for the Summer Institute for Statistics of Big Data (SISBID) at the University of Washington. This program will provide workshops on the statistical and computational skills needed to access, process, manage, and analyze large biomedical data sets. It will be co-directed by Ali Shojaie and Daniela Witten, faculty in the Department of Biostatistics at University of Washington.  The SISBID program will consist of five 2.5-day in-person courses, or modules, taught at the University of Washington each July. An individual participant can register for whichever set of modules he or she chooses. The five modules are as follows: (1) Accessing Biomedical Big Data; (2) Data Visualization; (3) Supervised Methods for Statistical Machine Learning; (4) Unsupervised Methods for Statistical Machine Learning; (5) Reproducible Research for Biomedical Big Data. Each module will consist of a combination of formal lectures and hands-on computing labs. Participants will work together in teams in order to apply the skills that they develop in each module to important problems drawn from relevant case studies.  The primary audience for SISBID will consist of biomedical scientists who would like to develop the statistical and computational training needed to make use of Biomedical Big Data. The secondary audience will consist of individuals with stronger statistical or computational backgrounds but little exposure to biology, who will learn how to apply their skills to problems associated with Biomedical Big Data. Participants will include advanced undergraduates, graduate students, post-doctoral fellows, and researchers, and will be drawn from industry, government, and academia. In order to ensure that all participants are able to fully engage in the program, participants will be expected to already have some prior background in R programming and statistical inference, which can be obtained by taking two free online courses before the program begins.  Each of the five modules will be co-taught by two instructors. The ten instructors will be drawn from top universities and research centers across the U.S., such as the University of Washington, Rice University, University of Iowa, Johns Hopkins University, MD Anderson Cancer Research Center, Fred Hutchinson Cancer Research Center, and University of North Carolina. They have been selected based on research expertise and excellence in teaching.  Lecture videos and slides will be made freely available online so that individuals who are unable to attend SISBID in person can still benefit from the program.  This proposal specifically requests funds for 55 student / postdoctoral fellow travel scholarships per year, 130 student / postdoctoral fellow registration scholarships per year, instructor travel and stipends, teaching assistant stipends, and PI salary support. PUBLIC HEALTH RELEVANCE:   In recent years, the biomedical sciences have been inundated by Big Data, such as DNA sequence data and electronic medical records. In principle, it should be possible to use such data for a variety of tasks, such as predicting an individual's risk of developing diabetes or cancer, and tailoring therapies to an individual should he or she become ill. The Summer Institute for Statistics of Big Data will provide biomedical researchers with the computational and statistical training needed in order to take advantage of Big Data, so that they can more effectively use it to understand human diseases and to improve human health.",Summer Institute for Statistics of Big Data,8935790,R25EB020380,"['Academia', 'Area', 'Big Data', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Biometry', 'Cancer Center', 'Case Study', 'Collection', 'Computer software', 'Computerized Medical Record', 'DNA Sequence', 'Data', 'Data Set', 'Diabetes Mellitus', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Exposure to', 'Faculty', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Government', 'Health', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Iowa', 'Knowledge', 'Learning', 'Learning Module', 'Machine Learning', 'Malignant Neoplasms', 'NCI Center for Cancer Research', 'North Carolina', 'Participant', 'Persons', 'Postdoctoral Fellow', 'Process', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rice', 'Risk', 'Running', 'Scholarship', 'Science', 'Slide', 'Statistical Computing', 'Statistical Methods', 'Students', 'Training', 'Training Activity', 'Training Programs', 'Travel', 'United States', 'Universities', 'Videotape', 'Wages', 'Washington', 'Work', 'base', 'biomedical scientist', 'data visualization', 'graduate student', 'human disease', 'improved', 'instructor', 'lectures', 'member', 'open source', 'programs', 'skills', 'statistics', 'teacher', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R25,2015,159605,0.2833312364835838
"Summer Institute for Statistics of Big Data     DESCRIPTION:  Funding is sought for the Summer Institute for Statistics of Big Data (SISBID) at the University of Washington. This program will provide workshops on the statistical and computational skills needed to access, process, manage, and analyze large biomedical data sets. It will be co-directed by Ali Shojaie and Daniela Witten, faculty in the Department of Biostatistics at University of Washington.  The SISBID program will consist of five 2.5-day in-person courses, or modules, taught at the University of Washington each July. An individual participant can register for whichever set of modules he or she chooses. The five modules are as follows: (1) Accessing Biomedical Big Data; (2) Data Visualization; (3) Supervised Methods for Statistical Machine Learning; (4) Unsupervised Methods for Statistical Machine Learning; (5) Reproducible Research for Biomedical Big Data. Each module will consist of a combination of formal lectures and hands-on computing labs. Participants will work together in teams in order to apply the skills that they develop in each module to important problems drawn from relevant case studies.  The primary audience for SISBID will consist of biomedical scientists who would like to develop the statistical and computational training needed to make use of Biomedical Big Data. The secondary audience will consist of individuals with stronger statistical or computational backgrounds but little exposure to biology, who will learn how to apply their skills to problems associated with Biomedical Big Data. Participants will include advanced undergraduates, graduate students, post-doctoral fellows, and researchers, and will be drawn from industry, government, and academia. In order to ensure that all participants are able to fully engage in the program, participants will be expected to already have some prior background in R programming and statistical inference, which can be obtained by taking two free online courses before the program begins.  Each of the five modules will be co-taught by two instructors. The ten instructors will be drawn from top universities and research centers across the U.S., such as the University of Washington, Rice University, University of Iowa, Johns Hopkins University, MD Anderson Cancer Research Center, Fred Hutchinson Cancer Research Center, and University of North Carolina. They have been selected based on research expertise and excellence in teaching.  Lecture videos and slides will be made freely available online so that individuals who are unable to attend SISBID in person can still benefit from the program.  This proposal specifically requests funds for 55 student / postdoctoral fellow travel scholarships per year, 130 student / postdoctoral fellow registration scholarships per year, instructor travel and stipends, teaching assistant stipends, and PI salary support.         PUBLIC HEALTH RELEVANCE:   In recent years, the biomedical sciences have been inundated by Big Data, such as DNA sequence data and electronic medical records. In principle, it should be possible to use such data for a variety of tasks, such as predicting an individual's risk of developing diabetes or cancer, and tailoring therapies to an individual should he or she become ill. The Summer Institute for Statistics of Big Data will provide biomedical researchers with the computational and statistical training needed in order to take advantage of Big Data, so that they can more effectively use it to understand human diseases and to improve human health.            ",Summer Institute for Statistics of Big Data,8829422,R25EB020380,"['Academia', 'Area', 'Big Data', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Biometry', 'Cancer Center', 'Case Study', 'Collection', 'Computer software', 'Computerized Medical Record', 'DNA Sequence', 'Data', 'Data Set', 'Diabetes Mellitus', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Exposure to', 'Faculty', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Government', 'Health', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Iowa', 'Knowledge', 'Learning', 'Learning Module', 'Machine Learning', 'Malignant Neoplasms', 'NCI Center for Cancer Research', 'North Carolina', 'Participant', 'Persons', 'Postdoctoral Fellow', 'Process', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rice', 'Risk', 'Running', 'Scholarship', 'Science', 'Slide', 'Statistical Computing', 'Statistical Methods', 'Students', 'Training', 'Training Activity', 'Training Programs', 'Travel', 'United States', 'Universities', 'Videotape', 'Wages', 'Washington', 'Work', 'base', 'biomedical scientist', 'graduate student', 'human disease', 'improved', 'instructor', 'lectures', 'member', 'open source', 'programs', 'public health relevance', 'skills', 'statistics', 'teacher', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R25,2014,160523,0.2833312364835838
"Big Data Coursework for Computational Medicine DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications. PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.",Big Data Coursework for Computational Medicine,9129718,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentorship', 'Methods', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Patient-Focused Outcomes', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Activity', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'career development', 'collaborative environment', 'comparative effectiveness', 'computer science', 'data access', 'data mining', 'education research', 'effectiveness research', 'experience', 'faculty mentor', 'improved', 'improved outcome', 'information organization', 'instrument', 'laboratory experience', 'laboratory module', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'skills', 'statistics', 'student training', 'success', 'tool', 'training opportunity', 'working group']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R25,2016,150010,0.3469501434218473
"Big Data Coursework for Computational Medicine DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications. PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.",Big Data Coursework for Computational Medicine,9242970,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentorship', 'Methods', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Patient-Focused Outcomes', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Activity', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'career development', 'collaborative environment', 'comparative effectiveness', 'computer science', 'data access', 'data mining', 'education research', 'effectiveness research', 'experience', 'faculty mentor', 'improved', 'improved outcome', 'information organization', 'instrument', 'laboratory experience', 'laboratory module', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'skills', 'statistics', 'student training', 'success', 'tool', 'training opportunity', 'working group']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R25,2016,68279,0.3469501434218473
"Big Data Coursework for Computational Medicine DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications. PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.",Big Data Coursework for Computational Medicine,8935791,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laboratories', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'career', 'career development', 'collaborative environment', 'comparative effectiveness', 'computer science', 'data mining', 'effectiveness research', 'experience', 'improved', 'information organization', 'instrument', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'skills', 'statistics', 'success', 'tool', 'working group']",NIBIB,MAYO CLINIC ROCHESTER,R25,2015,22575,0.3469501434218473
"Big Data Coursework for Computational Medicine     DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications.         PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.            ",Big Data Coursework for Computational Medicine,8827881,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Environment', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laboratories', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Metric', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'career', 'career development', 'comparative effectiveness', 'computer science', 'data mining', 'effectiveness research', 'experience', 'improved', 'information organization', 'instrument', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'public health relevance', 'skills', 'statistics', 'success', 'tool', 'working group']",NIBIB,MAYO CLINIC ROCHESTER,R25,2014,153437,0.3469501434218473
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9517179,U54EB020403,"['AIDS/HIV problem', 'Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'connectome', 'diagnostic biomarker', 'hackathon', 'high dimensionality', 'imaging study', 'innovation', 'multidisciplinary', 'multimodality', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'organizational structure', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2017,81900,0.1949591094253941
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9517044,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'connectome', 'diagnostic biomarker', 'hackathon', 'high dimensionality', 'imaging study', 'innovation', 'multidisciplinary', 'multimodality', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'organizational structure', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2018,790391,0.1949591094253941
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9302420,U54EB020403,"['AIDS/HIV problem', 'Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'connectome', 'diagnostic biomarker', 'hackathon', 'high dimensionality', 'imaging study', 'innovation', 'multidisciplinary', 'multimodality', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'organizational structure', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2017,2369482,0.1949591094253941
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",9108710,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Big Data to Knowledge', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Science', 'Data Set', 'Diagnosis', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'cluster merger', 'computer science', 'connectome', 'diagnostic biomarker', 'innovation', 'multidisciplinary', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'web portal', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2016,2369463,0.1949591094253941
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",8935792,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Internet', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'cluster merger', 'computer science', 'innovation', 'multidisciplinary', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2015,2366897,0.1949591094253941
"ENIGMA Center for Worldwide Medicine, Imaging & Genomics     DESCRIPTION (provided by applicant): The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort bringing together 287 scientists and all their vast biomedical datasets, to work on 9 major human brain diseases: schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images, genomes, connectomes and biomarkers on an unprecedented scale, with new kinds of computation for integration, clustering, and learning from complex biodata types. ENIGMA, founded in 2009, performed the largest brain imaging studies in history (N>26,000 subjects; Stein +207 authors, Nature Genetics, 2012) screening genomes and images at 125 institutions in 20 countries. Responding to the BD2K RFA, ENIGMA'S Working Groups target key programmatic goals of BD2K  funders across the NIH, including NIMH, NIBIB, NICHD, NIA, NINDS, NIDA, NIAAA, NHGRI and FIC. ENIGMA creates novel computational algorithms and a new model for Consortium Science to revolutionize the way Big Data is handled, shared and optimized. We unleash the power of sparse machine learning, and high dimensional combinatorics, to cluster and inter-relate genomes, connectomes, and multimodal brain images to discover diagnostic and prognostic markers. The sheer computational power and unprecedented collaboration advances distributed computation on Big Data leveraging US and non-US infrastructure, talents and data. Our projects will better identify factors that resist and promote brain disease, that help diagnosis and prognosis, and identify new mechanisms and drug targets. Our Data Science Research Cores create new algorithms to handle Big Data from (1) Imaging Genomics, (2) Connectomics, and (3) Machine Learning & Clinical Prediction. Led by world leaders in the field who developed major software packages (e.g., Jieping  Ye/SLEP), we prioritize trillions of computations for gene-image clustering, distributed multi-task machine  learning, and new approaches to screen brain connections based on the Partition Problem in mathematics.  Our ENIGMA Training Program offers a world class Summer School coordinated with other BD2K Centers, worldwide scientific exchanges. Challenge-based Workshops and hackathons to stimulate innovation, and Web Portals to disseminate tools and engage scientists in Big Data science.         PUBLIC HEALTH RELEVANCE: The ENIGMA Center for Worldwide Medicine, Imaging and Genomics is an unprecedented global effort uniting 287 scientists from 125 institutions and all their vast biomedical data, to work on 9 major human brain diseases:  schizophrenia, bipolar disorder, major depression, ADHD, OCD, autism, 22q deletion syndrome, HIV/AIDS and addictions. ENIGMA integrates images from multiple modalities, genomes, connectomes and biomarkers on an unimaginable scale, with new computations to integrate, cluster, and learn from complex biodata types.            ","ENIGMA Center for Worldwide Medicine, Imaging & Genomics",8774373,U54EB020403,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Big Data', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical', 'Collaborations', 'Combinatorics', 'Complex', 'Computational algorithm', 'Computer software', 'Country', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug Targeting', 'Educational workshop', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'HIV', 'Human', 'Image', 'Institution', 'Internet', 'Joints', 'Learning', 'Machine Learning', 'Major Depressive Disorder', 'Mathematics', 'Medicine', 'Modality', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Biomedical Imaging and Bioengineering', 'National Institute of Child Health and Human Development', 'National Institute of Drug Abuse', 'National Institute of Mental Health', 'National Institute of Neurological Disorders and Stroke', 'National Institute on Alcohol Abuse and Alcoholism', 'Nature', 'Obsessive-Compulsive Disorder', 'Prognostic Marker', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Schizophrenia', 'Schools', 'Science', 'Scientist', 'Talents', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Work', 'addiction', 'base', 'chromosome 22q deletion syndrome', 'computer science', 'innovation', 'multidisciplinary', 'multitask', 'neuroimaging', 'novel', 'novel strategies', 'outcome forecast', 'public health relevance', 'screening', 'success', 'tool', 'working group']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,U54,2014,2087641,0.1949591094253941
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9542295,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Overweight', 'Pathology', 'Personal Satisfaction', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'online resource', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'social', 'social model', 'societal costs', 'surgery outcome', 'tool', 'visiting scholar', 'wearable device']",NIBIB,STANFORD UNIVERSITY,U54,2018,955747,0.1244081649524465
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9333122,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'online resource', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'sensor', 'social', 'social model', 'tool', 'visiting scholar']",NIBIB,STANFORD UNIVERSITY,U54,2017,68981,0.1244081649524465
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9103879,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Mental Depression', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'big biomedical data', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'sensor', 'social', 'social model', 'tool', 'visiting scholar']",NIBIB,STANFORD UNIVERSITY,U54,2016,401742,0.1244081649524465
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,8935802,U54EB020405,"['Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Science', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Visit', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'industry partner', 'insight', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'role model', 'sensor', 'social', 'social model', 'tool']",NIBIB,STANFORD UNIVERSITY,U54,2015,68981,0.1244081649524465
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,8775015,U54EB020405,"['Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Science', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Visit', 'Walking', 'Work', 'base', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'improved', 'industry partner', 'insight', 'models and simulation', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'role model', 'sensor', 'social', 'social model', 'tool']",NIBIB,STANFORD UNIVERSITY,U54,2014,209258,0.1244081649524465
"Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.",Transforming Analytical Learning in the Era of Big Data,9325011,R25EB022363,"['Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Kidney Diseases', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Positioning Attribute', 'Prevention', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Social Behavior', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'high dimensionality', 'instructor', 'interest', 'lectures', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'posters', 'programs', 'public health relevance', 'response', 'signal processing', 'skills', 'statistics', 'success', 'summer institute', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2017,161633,0.29890740143161126
"Administrative Supplement Request for Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.",Administrative Supplement Request for Transforming Analytical Learning in the Era of Big Data,9243811,R25EB022363,"['Administrative Supplement', 'Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Behavioral Sciences', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Kidney Diseases', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Positioning Attribute', 'Prevention', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'instructor', 'interest', 'lectures', 'meetings', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'posters', 'programs', 'response', 'signal processing', 'skills', 'statistics', 'success', 'summer institute', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2016,159359,0.29890740143161126
"Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.",Transforming Analytical Learning in the Era of Big Data,9149238,R25EB022363,"['Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Behavioral Sciences', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Kidney Diseases', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Positioning Attribute', 'Prevention', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'instructor', 'interest', 'lectures', 'meetings', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'posters', 'programs', 'response', 'signal processing', 'skills', 'statistics', 'success', 'summer institute', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2016,160479,0.29890740143161126
"Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world.         PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.            ",Transforming Analytical Learning in the Era of Big Data,9044118,R25EB022363,"['Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Behavioral Sciences', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Institutes', 'Kidney Diseases', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Prevention', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'graduate student', 'instructor', 'interest', 'lectures', 'meetings', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'open source', 'personalized medicine', 'posters', 'programs', 'public health relevance', 'response', 'signal processing', 'skills', 'statistics', 'success', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2015,159359,0.29890740143161126
"The Big DIPA: Data Image Processing and Analysis ﻿    DESCRIPTION (provided by applicant): This proposal aims to establish a national short course in Big Data Image Processing & Analysis (BigDIPA) intended to increase the number and overall skills of competent research scientists now encountering large, complex image data sources derived from cutting edge biological/biomedical research approaches. Extraction of knowledge from these imaging sources requires specialized skills and an interdisciplinary mindset. Yet effective training opportunities of this sector of the ""Big Data"" science community are glaringly underappreciated and underserved compared to other big data fields such as omics. UC Irvine is ideally suited to host a short course to address this thematic training deficit on account of the synergistic colocalization between multiple facilities, renowned for development of numerous advanced imaging techniques, and the outstanding instructional environment provided by faculty with collaborative expertise in biological image processing and computer vision, bioinformatics and high performance computational approaches.  Specifically, our BigDIPA proposal assembles an interdisciplinary alliance of faculty experts that can leverage the preeminent imaging resource facilities, such as the Laboratory of Fluorescence Dynamics (LFD) and the Beckman Laser Institute, and fuse these to ongoing campus big data initiatives, e.g. UCI's Data Science Initiative, to create a top-rated training course designed for senior graduate students, postdoctoral researchers, faculty and industry scientists from diverse scientific disciplines who have nascent interests and needs to handle BIG DATA sources beyond their current level of competency.  The course theme is focused to utilize discreet examples drawn from the analysis of complex data acquired from different microscopy imaging modalities employed to investigate dynamics in cellular and tissue processes, including signal transduction networks, development, neuroscience and biomedical applications, and that hereto where hidden or inaccessible to standard methods of analysis. Participants will be guided along the complete acquisition- processing-analysis pipeline through exposure to a coherent progression of topics and issues typically encountered when handling BIG DATA. We believe this training approach will therefore be attractive to a broad and significant untapped pool of researchers from the biological disciplines, biomedical engineering, systems biology, math, biophysics, computer science, bioinformatics and statistics who possess some, but not all, of the requisite competencies to effectively traverse the BD2K landscape. We have designed the course such that skills and experience gained by trainees will be transferable to their own research interests.  The BigDIPA course format will combine didactic lectures on the theory and foundational frameworks that underpin each step, with practical instruction on implementation and hands-on tutorials in image acquisition, large data handling, basic scripting of computational tools, image processing on high performance computing architectures, as well as feature extraction, evaluation and visualization of results. The course is designed to offer an intense learning experience delivered in a compact time frame, and opportunities to foster interdisciplinary interactions through small team exercises. Participants will also be encouraged to take advantage of pre-courses - separate and distinct training opportunities not funded by this proposal - that will be coordinated to directly precede our course. This unique format provides multiple benefits: it provides an efficient mechanism to address individual participant training deficiencies to permit a more productive experience in the BigDIPA course, adds no-cost mutual benefits to independent but synergistic programs, and facilitates recruitment of applicants who frequently feel interested but intimidated due to a perceived lack of prior adequate training.  Beyond providing an intensive on-site training course, all course materials (lecture notes, video lectures and tutorials), tutorial exercises, open source software resources and sample datasets will be made freely available through on-line distribution to maximize outreach and encourage additional contributions of curated training resources solicited from the community. PUBLIC HEALTH RELEVANCE: We propose to train and expand the cadre of researchers capable of effectively using the deluge of complex BIG DATA being generated by advanced biomedical imaging approaches. These data sources represent a rich source of complex information relevant to many scientific areas of inquiry, and are informative at multiple scales ranging from fundamental biological processes at the cellular level to patient diagnostics for diseases such as cancer or neurological disorders.",The Big DIPA: Data Image Processing and Analysis,9295026,R25EB022366,"['Address', 'Architecture', 'Area', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophysics', 'Communities', 'Competence', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Education', 'Educational Curriculum', 'Educational workshop', 'Environment', 'Evaluation', 'Exercise', 'Exposure to', 'Faculty', 'Fluorescence', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Information Sciences', 'Institutes', 'Instruction', 'Interdisciplinary Communication', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Modality', 'Modernization', 'NIH Program Announcements', 'National Institute of General Medical Sciences', 'Neurosciences', 'Participant', 'Patients', 'Performance', 'Problem Solving', 'Process', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Schools', 'Scientist', 'Signal Transduction', 'Site', 'Software Tools', 'Source', 'Stream', 'Systems Biology', 'Talents', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'big biomedical data', 'bioimaging', 'biological systems', 'biomedical scientist', 'computer science', 'computerized tools', 'cost', 'course implementation', 'data acquisition', 'data format', 'demographics', 'design', 'experience', 'flexibility', 'graduate student', 'image processing', 'imaging approach', 'imaging modality', 'interdisciplinary collaboration', 'interest', 'learning materials', 'lecture notes', 'lectures', 'microscopic imaging', 'nervous system disorder', 'open source', 'outreach', 'programs', 'public health relevance', 'repository', 'skill acquisition', 'skills', 'statistics', 'theories', 'training opportunity']",NIBIB,UNIVERSITY OF CALIFORNIA-IRVINE,R25,2017,161997,0.20752553935649262
"The Big DIPA: Data Image Processing and Analysis ﻿    DESCRIPTION (provided by applicant): This proposal aims to establish a national short course in Big Data Image Processing & Analysis (BigDIPA) intended to increase the number and overall skills of competent research scientists now encountering large, complex image data sources derived from cutting edge biological/biomedical research approaches. Extraction of knowledge from these imaging sources requires specialized skills and an interdisciplinary mindset. Yet effective training opportunities of this sector of the ""Big Data"" science community are glaringly underappreciated and underserved compared to other big data fields such as omics. UC Irvine is ideally suited to host a short course to address this thematic training deficit on account of the synergistic colocalization between multiple facilities, renowned for development of numerous advanced imaging techniques, and the outstanding instructional environment provided by faculty with collaborative expertise in biological image processing and computer vision, bioinformatics and high performance computational approaches.  Specifically, our BigDIPA proposal assembles an interdisciplinary alliance of faculty experts that can leverage the preeminent imaging resource facilities, such as the Laboratory of Fluorescence Dynamics (LFD) and the Beckman Laser Institute, and fuse these to ongoing campus big data initiatives, e.g. UCI's Data Science Initiative, to create a top-rated training course designed for senior graduate students, postdoctoral researchers, faculty and industry scientists from diverse scientific disciplines who have nascent interests and needs to handle BIG DATA sources beyond their current level of competency.  The course theme is focused to utilize discreet examples drawn from the analysis of complex data acquired from different microscopy imaging modalities employed to investigate dynamics in cellular and tissue processes, including signal transduction networks, development, neuroscience and biomedical applications, and that hereto where hidden or inaccessible to standard methods of analysis. Participants will be guided along the complete acquisition- processing-analysis pipeline through exposure to a coherent progression of topics and issues typically encountered when handling BIG DATA. We believe this training approach will therefore be attractive to a broad and significant untapped pool of researchers from the biological disciplines, biomedical engineering, systems biology, math, biophysics, computer science, bioinformatics and statistics who possess some, but not all, of the requisite competencies to effectively traverse the BD2K landscape. We have designed the course such that skills and experience gained by trainees will be transferable to their own research interests.  The BigDIPA course format will combine didactic lectures on the theory and foundational frameworks that underpin each step, with practical instruction on implementation and hands-on tutorials in image acquisition, large data handling, basic scripting of computational tools, image processing on high performance computing architectures, as well as feature extraction, evaluation and visualization of results. The course is designed to offer an intense learning experience delivered in a compact time frame, and opportunities to foster interdisciplinary interactions through small team exercises. Participants will also be encouraged to take advantage of pre-courses - separate and distinct training opportunities not funded by this proposal - that will be coordinated to directly precede our course. This unique format provides multiple benefits: it provides an efficient mechanism to address individual participant training deficiencies to permit a more productive experience in the BigDIPA course, adds no-cost mutual benefits to independent but synergistic programs, and facilitates recruitment of applicants who frequently feel interested but intimidated due to a perceived lack of prior adequate training.  Beyond providing an intensive on-site training course, all course materials (lecture notes, video lectures and tutorials), tutorial exercises, open source software resources and sample datasets will be made freely available through on-line distribution to maximize outreach and encourage additional contributions of curated training resources solicited from the community. PUBLIC HEALTH RELEVANCE: We propose to train and expand the cadre of researchers capable of effectively using the deluge of complex BIG DATA being generated by advanced biomedical imaging approaches. These data sources represent a rich source of complex information relevant to many scientific areas of inquiry, and are informative at multiple scales ranging from fundamental biological processes at the cellular level to patient diagnostics for diseases such as cancer or neurological disorders.",The Big DIPA: Data Image Processing and Analysis,9150564,R25EB022366,"['Accounting', 'Address', 'Architecture', 'Area', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophysics', 'Cell physiology', 'Communities', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Educational Curriculum', 'Educational workshop', 'Environment', 'Evaluation', 'Exercise', 'Exposure to', 'Faculty', 'Fluorescence', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Information Sciences', 'Institutes', 'Instruction', 'Interdisciplinary Communication', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Modality', 'NIH Program Announcements', 'National Institute of General Medical Sciences', 'Neurosciences', 'Participant', 'Patients', 'Performance', 'Problem Solving', 'Process', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Schools', 'Scientist', 'Senior Scientist', 'Signal Transduction', 'Site', 'Skills Development', 'Software Tools', 'Source', 'Staging', 'Stream', 'Systems Biology', 'TNFRSF5 gene', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'bioimaging', 'biological systems', 'biomedical scientist', 'computer science', 'computerized tools', 'cost', 'course implementation', 'data acquisition', 'data format', 'demographics', 'design', 'education research', 'experience', 'flexibility', 'graduate student', 'image processing', 'imaging modality', 'interdisciplinary collaboration', 'interest', 'learning materials', 'lecture notes', 'lectures', 'meetings', 'microscopic imaging', 'nervous system disorder', 'open source', 'outreach', 'programs', 'repository', 'skill acquisition', 'skills', 'statistics', 'theories', 'tissue processing', 'training opportunity']",NIBIB,UNIVERSITY OF CALIFORNIA-IRVINE,R25,2016,161997,0.20752553935649262
"The Big DIPA: Data Image Processing and Analysis ﻿    DESCRIPTION (provided by applicant): This proposal aims to establish a national short course in Big Data Image Processing & Analysis (BigDIPA) intended to increase the number and overall skills of competent research scientists now encountering large, complex image data sources derived from cutting edge biological/biomedical research approaches. Extraction of knowledge from these imaging sources requires specialized skills and an interdisciplinary mindset. Yet effective training opportunities of this sector of the ""Big Data"" science community are glaringly underappreciated and underserved compared to other big data fields such as omics. UC Irvine is ideally suited to host a short course to address this thematic training deficit on account of the synergistic colocalization between multiple facilities, renowned for development of numerous advanced imaging techniques, and the outstanding instructional environment provided by faculty with collaborative expertise in biological image processing and computer vision, bioinformatics and high performance computational approaches.  Specifically, our BigDIPA proposal assembles an interdisciplinary alliance of faculty experts that can leverage the preeminent imaging resource facilities, such as the Laboratory of Fluorescence Dynamics (LFD) and the Beckman Laser Institute, and fuse these to ongoing campus big data initiatives, e.g. UCI's Data Science Initiative, to create a top-rated training course designed for senior graduate students, postdoctoral researchers, faculty and industry scientists from diverse scientific disciplines who have nascent interests and needs to handle BIG DATA sources beyond their current level of competency.  The course theme is focused to utilize discreet examples drawn from the analysis of complex data acquired from different microscopy imaging modalities employed to investigate dynamics in cellular and tissue processes, including signal transduction networks, development, neuroscience and biomedical applications, and that hereto where hidden or inaccessible to standard methods of analysis. Participants will be guided along the complete acquisition- processing-analysis pipeline through exposure to a coherent progression of topics and issues typically encountered when handling BIG DATA. We believe this training approach will therefore be attractive to a broad and significant untapped pool of researchers from the biological disciplines, biomedical engineering, systems biology, math, biophysics, computer science, bioinformatics and statistics who possess some, but not all, of the requisite competencies to effectively traverse the BD2K landscape. We have designed the course such that skills and experience gained by trainees will be transferable to their own research interests.  The BigDIPA course format will combine didactic lectures on the theory and foundational frameworks that underpin each step, with practical instruction on implementation and hands-on tutorials in image acquisition, large data handling, basic scripting of computational tools, image processing on high performance computing architectures, as well as feature extraction, evaluation and visualization of results. The course is designed to offer an intense learning experience delivered in a compact time frame, and opportunities to foster interdisciplinary interactions through small team exercises. Participants will also be encouraged to take advantage of pre-courses - separate and distinct training opportunities not funded by this proposal - that will be coordinated to directly precede our course. This unique format provides multiple benefits: it provides an efficient mechanism to address individual participant training deficiencies to permit a more productive experience in the BigDIPA course, adds no-cost mutual benefits to independent but synergistic programs, and facilitates recruitment of applicants who frequently feel interested but intimidated due to a perceived lack of prior adequate training.  Beyond providing an intensive on-site training course, all course materials (lecture notes, video lectures and tutorials), tutorial exercises, open source software resources and sample datasets will be made freely available through on-line distribution to maximize outreach and encourage additional contributions of curated training resources solicited from the community.         PUBLIC HEALTH RELEVANCE: We propose to train and expand the cadre of researchers capable of effectively using the deluge of complex BIG DATA being generated by advanced biomedical imaging approaches. These data sources represent a rich source of complex information relevant to many scientific areas of inquiry, and are informative at multiple scales ranging from fundamental biological processes at the cellular level to patient diagnostics for diseases such as cancer or neurological disorders.            ",The Big DIPA: Data Image Processing and Analysis,9044533,R25EB022366,"['Accounting', 'Address', 'Architecture', 'Area', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophysics', 'Cell physiology', 'Communities', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Education', 'Educational Curriculum', 'Educational workshop', 'Environment', 'Evaluation', 'Exercise', 'Exposure to', 'Faculty', 'Fluorescence', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Information Sciences', 'Institutes', 'Instruction', 'Interdisciplinary Communication', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Microscopy', 'Modality', 'NIH Program Announcements', 'National Institute of General Medical Sciences', 'Neurosciences', 'Participant', 'Patients', 'Performance', 'Problem Solving', 'Process', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Schools', 'Science', 'Scientist', 'Senior Scientist', 'Signal Transduction', 'Site', 'Software Tools', 'Source', 'Staging', 'Stream', 'Systems Biology', 'TNFRSF5 gene', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'bioimaging', 'biological systems', 'biomedical scientist', 'citizen science', 'computer science', 'computerized tools', 'cost', 'data acquisition', 'data format', 'demographics', 'design', 'experience', 'flexibility', 'graduate student', 'image processing', 'imaging modality', 'interdisciplinary collaboration', 'interest', 'lecture notes', 'lectures', 'meetings', 'nervous system disorder', 'open source', 'outreach', 'programs', 'public health relevance', 'repository', 'skills', 'statistics', 'theories', 'tissue processing']",NIBIB,UNIVERSITY OF CALIFORNIA-IRVINE,R25,2015,161997,0.20752553935649262
"QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine  The purpose of this proposal is to develop a combination of innovative statistical and data visualization approaches using patient-generated health data, including mobile health (mHealth) data from wearable devices and smartphones, and patient-reported outcomes, to improve outcomes for patients with Inflammatory Bowel Diseases (IBDs). This research will offer new insights into how to process and transform patient-generated health data into precise lifestyle recommendations to help achieve remission of symptoms. The specific aims of this research are: 1) To develop new preprocessing methods for publicly available, heterogeneous, time-varied mHealth data to develop a high quality mHealth dataset; 2) To develop and apply novel machine learning methods to obtain accurate predictions and formal statistical inference for the influence of lifestyle features on disease activity in IBDs; and 3) To design and develop innovative, interactive data visualization tools for knowledge discovery. The methods developed in the areas of preprocessing of mHealth data, calibration for mHealth devices, machine learning, and interactive data visualization will be broadly applicable to other mHealth data, chronic conditions beyond IBDs, and other fields in which the data streams are highly variable, intermittent, and periodic. This work is highly relevant to the mission of the NIH BD2K initiative which supports the development of innovative and transformative approaches and tools to accelerate the integration of Big Data and data science into biomedical research. This project will also enhance training in the development and use of methods for biomedical Big Data science and mentor the next generation of multidisciplinary scientists. The proposed research is relevant to public health by seeking to improve symptoms for patients with inflammatory bowel diseases, which are chronic, life-long conditions with waxing and waning symptoms. Developing novel statistical and visualization methods to provide a more nuanced understanding of the precise relationship between physical activity and sleep to disease activity is relevant to BD2K's mission.",QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine ,9741121,R01EB025024,"['Adrenal Cortex Hormones', 'Adult', 'Affect', 'Americas', 'Area', 'Behavior', 'Big Data', 'Big Data to Knowledge', 'Biomedical Research', 'Calibration', 'Caring', 'Cellular Phone', 'Characteristics', 'Chronic', 'Crohn&apos', 's disease', 'Data', 'Data Science', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Outcome', 'Disease remission', 'Dose', 'Effectiveness', 'Flare', 'Foundations', 'Functional disorder', 'Funding', 'Imagery', 'Immunosuppression', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Institute of Medicine (U.S.)', 'Knowledge Discovery', 'Life', 'Life Style', 'Life Style Modification', 'Longitudinal Surveys', 'Longitudinal cohort study', 'Machine Learning', 'Mathematics', 'Measures', 'Mentors', 'Methods', 'Mission', 'Moderate Activity', 'Morbidity - disease rate', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Periodicity', 'Phenotype', 'Physical activity', 'Precision therapeutics', 'Process', 'Public Health', 'Quality of life', 'Recommendation', 'Reporting', 'Research', 'Research Institute', 'Schools', 'Scientist', 'Sleep', 'Sleep disturbances', 'Stream', 'Symptoms', 'Therapeutic', 'Time', 'Training', 'Ulcerative Colitis', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Visualization software', 'Waxes', 'Work', 'base', 'big biomedical data', 'clinical remission', 'comparative effectiveness', 'cost', 'data visualization', 'design', 'disorder risk', 'effectiveness research', 'health data', 'improved', 'improved outcome', 'individual patient', 'innovation', 'insight', 'large bowel Crohn&apos', 's disease', 'learning strategy', 'lifestyle factors', 'mHealth', 'member', 'multidisciplinary', 'next generation', 'novel', 'precision medicine', 'side effect', 'sleep quality', 'symptomatic improvement', 'tool', 'wearable device']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2019,281932,0.11448524662882861
"QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine  The purpose of this proposal is to develop a combination of innovative statistical and data visualization approaches using patient-generated health data, including mobile health (mHealth) data from wearable devices and smartphones, and patient-reported outcomes, to improve outcomes for patients with Inflammatory Bowel Diseases (IBDs). This research will offer new insights into how to process and transform patient-generated health data into precise lifestyle recommendations to help achieve remission of symptoms. The specific aims of this research are: 1) To develop new preprocessing methods for publicly available, heterogeneous, time-varied mHealth data to develop a high quality mHealth dataset; 2) To develop and apply novel machine learning methods to obtain accurate predictions and formal statistical inference for the influence of lifestyle features on disease activity in IBDs; and 3) To design and develop innovative, interactive data visualization tools for knowledge discovery. The methods developed in the areas of preprocessing of mHealth data, calibration for mHealth devices, machine learning, and interactive data visualization will be broadly applicable to other mHealth data, chronic conditions beyond IBDs, and other fields in which the data streams are highly variable, intermittent, and periodic. This work is highly relevant to the mission of the NIH BD2K initiative which supports the development of innovative and transformative approaches and tools to accelerate the integration of Big Data and data science into biomedical research. This project will also enhance training in the development and use of methods for biomedical Big Data science and mentor the next generation of multidisciplinary scientists. The proposed research is relevant to public health by seeking to improve symptoms for patients with inflammatory bowel diseases, which are chronic, life-long conditions with waxing and waning symptoms. Developing novel statistical and visualization methods to provide a more nuanced understanding of the precise relationship between physical activity and sleep to disease activity is relevant to BD2K's mission.",QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine ,9572992,R01EB025024,"['Adrenal Cortex Hormones', 'Adult', 'Adverse effects', 'Affect', 'Americas', 'Area', 'Behavior', 'Big Data', 'Big Data to Knowledge', 'Biomedical Research', 'Calibration', 'Caring', 'Cellular Phone', 'Characteristics', 'Chronic', 'Crohn&apos', 's disease', 'Data', 'Data Science', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Outcome', 'Disease remission', 'Dose', 'Effectiveness', 'Flare', 'Foundations', 'Functional disorder', 'Funding', 'Imagery', 'Immunosuppression', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Institute of Medicine (U.S.)', 'Knowledge Discovery', 'Life', 'Life Style', 'Life Style Modification', 'Longitudinal Surveys', 'Longitudinal cohort study', 'Machine Learning', 'Mathematics', 'Measures', 'Mentors', 'Methods', 'Mission', 'Moderate Activity', 'Morbidity - disease rate', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Periodicity', 'Phenotype', 'Physical activity', 'Precision therapeutics', 'Process', 'Public Health', 'Quality of life', 'Recommendation', 'Reporting', 'Research', 'Research Institute', 'Schools', 'Scientist', 'Sleep', 'Sleep disturbances', 'Stream', 'Symptoms', 'Therapeutic', 'Time', 'Training', 'Ulcerative Colitis', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Visualization software', 'Waxes', 'Work', 'base', 'big biomedical data', 'clinical remission', 'comparative effectiveness', 'cost', 'data visualization', 'design', 'disorder risk', 'effectiveness research', 'health data', 'improved', 'improved outcome', 'individual patient', 'innovation', 'insight', 'large bowel Crohn&apos', 's disease', 'learning strategy', 'lifestyle factors', 'mHealth', 'member', 'multidisciplinary', 'next generation', 'novel', 'precision medicine', 'sleep quality', 'symptomatic improvement', 'tool', 'wearable device']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,297237,0.11448524662882861
"QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine  The purpose of this proposal is to develop a combination of innovative statistical and data visualization approaches using patient-generated health data, including mobile health (mHealth) data from wearable devices and smartphones, and patient-reported outcomes, to improve outcomes for patients with Inflammatory Bowel Diseases (IBDs). This research will offer new insights into how to process and transform patient-generated health data into precise lifestyle recommendations to help achieve remission of symptoms. The specific aims of this research are: 1) To develop new preprocessing methods for publicly available, heterogeneous, time-varied mHealth data to develop a high quality mHealth dataset; 2) To develop and apply novel machine learning methods to obtain accurate predictions and formal statistical inference for the influence of lifestyle features on disease activity in IBDs; and 3) To design and develop innovative, interactive data visualization tools for knowledge discovery. The methods developed in the areas of preprocessing of mHealth data, calibration for mHealth devices, machine learning, and interactive data visualization will be broadly applicable to other mHealth data, chronic conditions beyond IBDs, and other fields in which the data streams are highly variable, intermittent, and periodic. This work is highly relevant to the mission of the NIH BD2K initiative which supports the development of innovative and transformative approaches and tools to accelerate the integration of Big Data and data science into biomedical research. This project will also enhance training in the development and use of methods for biomedical Big Data science and mentor the next generation of multidisciplinary scientists. The proposed research is relevant to public health by seeking to improve symptoms for patients with inflammatory bowel diseases, which are chronic, life-long conditions with waxing and waning symptoms. Developing novel statistical and visualization methods to provide a more nuanced understanding of the precise relationship between physical activity and sleep to disease activity is relevant to BD2K's mission.",QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine ,9394127,R01EB025024,"['Adrenal Cortex Hormones', 'Adult', 'Adverse effects', 'Affect', 'Americas', 'Area', 'Behavior', 'Behavior Therapy', 'Big Data', 'Big Data to Knowledge', 'Biomedical Research', 'Calibration', 'Caring', 'Cellular Phone', 'Characteristics', 'Chronic', 'Crohn&apos', 's disease', 'Data', 'Data Science', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Outcome', 'Disease remission', 'Dose', 'Effectiveness', 'Flare', 'Foundations', 'Functional disorder', 'Funding', 'Health Care Research', 'Imagery', 'Immunosuppression', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Institute of Medicine (U.S.)', 'Knowledge Discovery', 'Life', 'Life Style', 'Longitudinal Surveys', 'Longitudinal cohort study', 'Machine Learning', 'Mathematics', 'Measures', 'Mentors', 'Methods', 'Mission', 'Moderate Activity', 'Morbidity - disease rate', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Periodicity', 'Phenotype', 'Physical activity', 'Precision therapeutics', 'Process', 'Public Health', 'Quality of life', 'Recommendation', 'Reporting', 'Research', 'Research Institute', 'Schools', 'Scientist', 'Sleep', 'Sleep disturbances', 'Stream', 'Symptoms', 'Therapeutic', 'Time', 'Training', 'Ulcerative Colitis', 'United States National Institutes of Health', 'Visualization software', 'Waxes', 'Work', 'base', 'big biomedical data', 'clinical remission', 'comparative effectiveness', 'cost', 'data visualization', 'design', 'disorder risk', 'effectiveness research', 'health care quality', 'health data', 'improved', 'improved outcome', 'individual patient', 'innovation', 'insight', 'large bowel Crohn&apos', 's disease', 'learning strategy', 'lifestyle factors', 'mHealth', 'member', 'multidisciplinary', 'next generation', 'novel', 'precision medicine', 'symptomatic improvement', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2017,338637,0.11448524662882861
"Developing Cloud-based tools for Big Neural Data DESCRIPTION (provided by applicant): Big data has the potential to dramatically advance the electrophysiology biodata sciences in similar ways that it has transformed Genetics. Differences between these two areas dictate separate approaches to apply Big Data tools, and methods in order to provide successful assets to the research community. For one, neural datasets are very heterogeneous by nature. The data is difficult to interpret without knowing specifics about the data acquisition protocol, the experimental paradigm and the physiological state of the recorded subject. Many neural datasets are complemented with complex meta-data sets, which should be an integral component in any effort to integrate and share these data with other researchers. The goal of this project is to develop novel, generalizable Big Data tools to facilitate cloud-base analysis of complex multi-scale neural data. Epilepsy research will be used as a specific use case to guide the development of the tools. A cohort of established senior investigators performing epilepsy research will use and validate these tools in their laboratories. Epilepsy research is currently limited by its narrow focus on single models (animal or human) in individual centers and laboratories. Just as Genetics was revolutionized through Big Data techniques, so too can Epilepsy research be transformed through novel approaches to standardize, share, and mine data across groups of investigators. Over the past several years I have co-developed a NINDS funded cloud-based data platform, ://ieeg.org, giving me a central role in developing Big Data solutions for neural data, such as customized data sharing, large-scale cloud-based data analysis, and search and interrogation techniques for complex data and metadata. My scientific objectives for this project are: (1) to develop generalizable tools to curate, analyze, and interrogate multi-scale neural data, and (2) to create a platform that will galvanize a research community focused on sharing data, and methods to advance Big Data research in the basic and translational neurosciences. Equally important to this proposal, I present a training plan to prepare me for an academic career focused on Big Data in the neurosciences. This plan supplements my background in bioengineering and statistical modeling of neural data with broader data-science expertise in data integration and machine learning, and deeper domain knowledge of the clinical neurosciences. I have assembled a group of collaborators, basic investigators and clinician scientists, who will use the tools developed in this project to analyze and validate their data and methods. I will use the results of this project as the foundation for a R01 Grant application, in which I will expand the developed platform and tools to target other research domains (TBI, Emergency Care, Cardiac), as well as integrate other data-modalities such as Imaging, and Genomics. OMB No. 0925-0001/0002 (Rev. 08/12 Approved Through 8/31/2015) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: The goal of this proposal is to advance Big Data research in the neurosciences by developing tools and techniques to interrogate electrophysiology data sets from animal models of human neurological disorders. Development of these tools requires close collaboration between domain experts in Neuroscience, Machine Learning, Statistics and Computer Science. When developed, this platform and these tools will allow investigators to share, collaborate, annotate, standardize and analyze large, complex, multiscale data sets that are a crucial first step in advancing this field.",Developing Cloud-based tools for Big Neural Data,8935817,K01ES025436,"['Animal Model', 'Applications Grants', 'Area', 'Big Data', 'Biomedical Engineering', 'Cardiac', 'Clinical', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Electrophysiology (science)', 'Emergency Care', 'Epilepsy', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Incentives', 'Individual', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Metadata', 'Methods', 'Mining', 'Modality', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Neurosciences', 'Organism', 'Performance', 'Physiological', 'Process', 'Protocols documentation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Series', 'Solutions', 'Standardization', 'Statistical Models', 'Techniques', 'Time', 'Training', 'base', 'career', 'cloud based', 'cohort', 'comparative', 'computer science', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'improved', 'nervous system disorder', 'novel', 'novel strategies', 'relating to nervous system', 'statistics', 'tool', 'tool development', 'translational neuroscience']",NIEHS,UNIVERSITY OF PENNSYLVANIA,K01,2015,192201,0.2988025676903311
"Developing Cloud-based tools for Big Neural Data     DESCRIPTION (provided by applicant): Big data has the potential to dramatically advance the electrophysiology biodata sciences in similar ways that it has transformed Genetics. Differences between these two areas dictate separate approaches to apply Big Data tools, and methods in order to provide successful assets to the research community. For one, neural datasets are very heterogeneous by nature. The data is difficult to interpret without knowing specifics about the data acquisition protocol, the experimental paradigm and the physiological state of the recorded subject. Many neural datasets are complemented with complex meta-data sets, which should be an integral component in any effort to integrate and share these data with other researchers. The goal of this project is to develop novel, generalizable Big Data tools to facilitate cloud-base analysis of complex multi-scale neural data. Epilepsy research will be used as a specific use case to guide the development of the tools. A cohort of established senior investigators performing epilepsy research will use and validate these tools in their laboratories. Epilepsy research is currently limited by its narrow focus on single models (animal or human) in individual centers and laboratories. Just as Genetics was revolutionized through Big Data techniques, so too can Epilepsy research be transformed through novel approaches to standardize, share, and mine data across groups of investigators. Over the past several years I have co-developed a NINDS funded cloud-based data platform, ://ieeg.org, giving me a central role in developing Big Data solutions for neural data, such as customized data sharing, large-scale cloud-based data analysis, and search and interrogation techniques for complex data and metadata. My scientific objectives for this project are: (1) to develop generalizable tools to curate, analyze, and interrogate multi-scale neural data, and (2) to create a platform that will galvanize a research community focused on sharing data, and methods to advance Big Data research in the basic and translational neurosciences. Equally important to this proposal, I present a training plan to prepare me for an academic career focused on Big Data in the neurosciences. This plan supplements my background in bioengineering and statistical modeling of neural data with broader data-science expertise in data integration and machine learning, and deeper domain knowledge of the clinical neurosciences. I have assembled a group of collaborators, basic investigators and clinician scientists, who will use the tools developed in this project to analyze and validate their data and methods. I will use the results of this project as the foundation for a R01 Grant application, in which I will expand the developed platform and tools to target other research domains (TBI, Emergency Care, Cardiac), as well as integrate other data-modalities such as Imaging, and Genomics. OMB No. 0925-0001/0002 (Rev. 08/12 Approved Through 8/31/2015) Page Continuation Format Page         PUBLIC HEALTH RELEVANCE: The goal of this proposal is to advance Big Data research in the neurosciences by developing tools and techniques to interrogate electrophysiology data sets from animal models of human neurological disorders. Development of these tools requires close collaboration between domain experts in Neuroscience, Machine Learning, Statistics and Computer Science. When developed, this platform and these tools will allow investigators to share, collaborate, annotate, standardize and analyze large, complex, multiscale data sets that are a crucial first step in advancing this field.            ",Developing Cloud-based tools for Big Neural Data,8830141,K01ES025436,"['Animal Model', 'Applications Grants', 'Area', 'Big Data', 'Biomedical Engineering', 'Cardiac', 'Clinical', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Electrophysiology (science)', 'Emergency Care', 'Epilepsy', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Incentives', 'Individual', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Metadata', 'Methods', 'Mining', 'Modality', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Neurosciences', 'Organism', 'Performance', 'Physiological', 'Process', 'Protocols documentation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Series', 'Solutions', 'Standardization', 'Statistical Models', 'Techniques', 'Time', 'Training', 'base', 'career', 'cloud based', 'cohort', 'comparative', 'computer science', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'improved', 'nervous system disorder', 'novel', 'novel strategies', 'relating to nervous system', 'statistics', 'tool', 'tool development', 'translational neuroscience']",NIEHS,UNIVERSITY OF PENNSYLVANIA,K01,2014,192201,0.2988025676903311
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,9523223,K01ES025442,"['Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Competence', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Variant', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'exhaustion', 'experience', 'experimental study', 'human model', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'learning strategy', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'public health relevance', 'relating to nervous system', 'response', 'reward anticipation', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2018,144298,0.14142144143185245
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,9310000,K01ES025442,"['Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Competence', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impairment', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Variant', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'exhaustion', 'experience', 'experimental study', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'learning strategy', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'public health relevance', 'relating to nervous system', 'response', 'reward anticipation', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2017,144298,0.14142144143185245
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,9099840,K01ES025442,"['Accounting', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Applied Skills', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Health', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'experience', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'learning strategy', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'reward anticipation', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2016,144298,0.14142144143185245
"Nonparametric Bayes Methods for Big Data in Neuroscience DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond. PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.",Nonparametric Bayes Methods for Big Data in Neuroscience,8935820,K01ES025442,"['Accounting', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Health', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'emotion regulation', 'experience', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2015,146944,0.14142144143185245
"Nonparametric Bayes Methods for Big Data in Neuroscience     DESCRIPTION (provided by applicant): I am applying for mentored career development through the BD2K initiative to gain the skills and expertise necessary to transition to an independent research career developing methods for the analysis of ""big data"" in systems and cognitive neuroscience. Following my Ph.D. training in theoretical physics, I transitioned into computational neuroscience, where I have focused on problems in the neurophysiology of reward and decision-making, particularly models of reinforcement learning and choice behavior. For the last five years, I have also gained extensive experience in electrophysiological recording in both human surgical patients and non-human primates, deepening my appreciation of the difficulties involved in analyzing real neuroscience data. During this time, I have become convinced that the single most pressing challenge for neuroscience in the next decade will be the problem of how we process, analyze, and synthesize the rapidly expanding volumes of data made available by new technologies, and as I transition to the faculty level, I am seeking to orient my own research program toward these goals. To do so, I will need to complement my strong quantitative background and electrophysiological recording skills with specific training in machine learning, signal processing, and analysis of data from functional magnetic resonance imaging (fMRI). I am focusing on the first because the statistics of data analysis are an essential core competency for any big data researcher; on the second because understanding the methods by which we process and acquire data are as essential as how we analyze them; and on the third because not only are fMRI data among the most readily available large datasets, but effective analysis of fMRI data will have immediate clinical applications. For this project, I have assembled a team of mentors with strong and overlapping expertise in these three areas. These mentors have committed to support my transition to a focus on big data research, an approach that builds on multiple existing collaborations I have with laboratories at Duke. My ultimate goal is to head a lab in which I apply the skills and training I acquire during the award period to developing computational methods that will harness the power of big data to answer fundamental questions in cognitive and translational neuroscience. Environment. Duke University is home to outstanding resources in both neuroscience and big data research. Its interdisciplinary big data effort, the Information Initiative at Duke, brings together researchers from statistics, computer science, and electrical engineering with those in genetics, neuroscience, and social science to facilitate collaboration across the disciplines. The Duke Institute for Brain Sciences, with which I am affiliated, comprises over 150 faculty across the brain sciences at Duke, from clinicians to biomedical engineers. I will be mentored by Dr. David Dunson, a recognized leader in Bayesian statistical methods for machine learning, along with Dr. Lawrence Carin and Dr. Guillermo Sapiro, experts in signal and image processing and machine learning and frequent collaborators with Dr. Dunson. In addition Dr. Scott Huettel, an expert in fMRI and author of a leading neuroimaging textbook, will oversee my training in fMRI data analysis. Moreover, I will have access to data from a large and diverse pool of laboratories at Duke, including one of the largest neuroimaging datasets in the country. Most importantly, Duke is fully committed to supporting me with the resources and time necessary to pursue the training outlined in this career development award. Research. Each year, one in four adults suffers from a diagnosable mental disorder, with 1 in 25 suffering from a serious mental illness. Yet our ability to anticipate the onset of mental illness - even our ability to understand its effets within the brain - has been limited by the recognition that these diseases are not primarily disorders of independent units, but patterns of pathological brain activation. However, we currently lack a meaningful characterization of patterns of activity within neural networks, and thus the ability to discuss, discover, and treat them effectively. Yet an improvement in our abilit to characterize and detect these patterns would result in major clinical impact. Therefore, under the guidance of my mentoring team, I propose to characterize patterns of network activity in neuroscience datasets using methods from machine learning. Because many mental illnesses are typified either by a pathological relationship between sufferers and stimuli in the world (post traumatic stress disorder, eating disorders) or intrinsic patterns of disordered thought (major depression, obsessive-compulsive disorder), I focus on three key questions for pattern detection: 1) How does the brain encode complex, unstructured stimuli? 2) What are the basic building blocks of healthy and diseased patterns of intrinsic brain activity? 3) How do patterns of brain activity change in response to changes in behavioral state? My approach makes use of recent advances in Bayesian nonparametric methods, as well as fast variational inference approaches that scale well to large datasets. In addition, because the datasets I will use, fMRI and electrophysiology data, are particular examples of the much larger class of multichannel time series data, the results will apply more broadly to other types of data, in neuroscience and beyond.         PUBLIC HEALTH RELEVANCE: Recent evidence suggests that most mental illnesses result from disruptions in normal patterns of brain activity. Yet discovering, detecting, and describing these patterns of activity has proven difficult to do in conventional experiments. This project wil develop computer algorithms for pattern detection that can be applied to the scientific study and early diagnosis of mental illness.            ",Nonparametric Bayes Methods for Big Data in Neuroscience,8830000,K01ES025442,"['Accounting', 'Adult', 'Affect', 'Animal Model', 'Animals', 'Area', 'Award', 'Bayesian Method', 'Behavioral', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biomedical Engineering', 'Brain', 'Brain region', 'Calcium', 'Choice Behavior', 'Clinical', 'Collaborations', 'Commit', 'Complement', 'Complex', 'Computational algorithm', 'Computer Simulation', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Early treatment', 'Eating Disorders', 'Electrical Engineering', 'Electroencephalography', 'Electrophysiology (science)', 'Emotional', 'Environment', 'Event', 'Exhibits', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Genetic', 'Goals', 'Head', 'Heterogeneity', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Impulsivity', 'Institutes', 'K-Series Research Career Programs', 'Laboratories', 'Machine Learning', 'Major Depressive Disorder', 'Mental disorders', 'Mentors', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Physics', 'Population', 'Post-Traumatic Stress Disorders', 'Process', 'Psychological reinforcement', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Rewards', 'Schizophrenia', 'Science', 'Series', 'Signal Transduction', 'Social Sciences', 'Stimulus', 'Structure', 'System', 'Textbooks', 'Time', 'Training', 'Universities', 'Vertebral column', 'Work', 'base', 'career', 'career development', 'clinical application', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'experience', 'image processing', 'imaging modality', 'independent component analysis', 'interest', 'learned behavior', 'neuroimaging', 'neurophysiology', 'new technology', 'nonhuman primate', 'novel', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'severe mental illness', 'signal processing', 'skills', 'skills training', 'social', 'statistics', 'translational neuroscience']",NIEHS,DUKE UNIVERSITY,K01,2014,151804,0.14142144143185245
"Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data ﻿    DESCRIPTION (provided by applicant)    My goal in seeking a K01 Award is to acquire the necessary training to become an independently funded investigator focused on exploiting the power of biomedical Big Data Science to improve outcome following severe injury. I am a trauma surgeon at San Francisco General Hospital, one of the Nation's leading trauma centers, and an Assistant Professor of Surgery at the University of California San Francisco (UCSF). UCSF has recently entered into collaboration with the National Laboratories to study the use of biomedical Big Data in complex clinical conditions and my main mentor, Dr. Mitchell J. Cohen is the lead investigator at UCSF for this collaboration. I believe that given the complexity of the factors that likely affect traum outcome including patient injury patterns, medical co-morbidities, patient biology, and the system of care, trauma provides a solid foundation to study the utility of Big Data Science for solving complex medical questions. To facilitate my growth as an expert in this field, I am proposing to develop a framework for integrating multiple data sources necessary to forecast patient outcomes following trauma. These novel datasets combined with biologic and metadata will then be utilized to create improved metrics that better predict complication risk from modifiable and non-modifiable factors. The net result of this work is a new approach to data ascertainment for measuring outcome, leveraging new data types to improve prediction of patient trajectory, and creating a platform to interface with existing information technology to ultimately be used for an early warning detection system for patients at risk of complications. The future long-term goal of this work would be to identify early patients predicted to do more poorly and then apply refinements to the process of care to minimize complication development. The creation of early warning detection systems has significant theoretic potential to improve quality and ultimately decrease costs. Nearly $30 billion per year in the US is spent on care for the traumatically injured and the development of post-traumatic complications is believed to be major contributor to the overall costs of care. The ability to report performance has been hampered by a lack of standard definitions, reporting bias, access to datasets, and the analysis techniques that fail to account for the highly confounded relationships contributing to patient outcome. This K01 award will provide me with the support necessary to accomplish the following goals: (1) to become an expert in applying biologic big data to trauma care (2) to elucidate the relationship of modifiable factors affecting complication development (3) to gain experience with advanced biostatistical techniques and bioinformatics; and (4) to develop an independent clinical research career. To achieve these goals, I have assembled a multidisciplinary team including Dr. Cohen, a National expert in trauma systems biology and biologic big data, and two co-mentors: Dr. Michael Matthay, a translational research expert in complications after severe illness, and Dr. Alan Hubbard, an expert in advanced biostatistical techniques including biologic big data analysis. PUBLIC HEALTH RELEVANCE    In the US, trauma is the leading cause of death for those under 45 years old and many of the patients who survive their initial injuries develop complications such as blood clots or pneumonia that contribute to both death and the long-term effects of the trauma. Through leveraging the power of biomedical Big Data, an integrated approach to measuring outcome will be developed utilizing biologic, clinical, and electronic medical record (EMR) data. The goal of this project is to lay the ground work for developing integrated EMR early warning detection systems that could identify those at risk of complications early with the intent to ultimately refie the process of care for this group to minimize complication development.",Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data,9147595,K01ES026834,"['Accounting', 'Address', 'Affect', 'Age', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Bioinformatics', 'Biology', 'Biometry', 'Blood coagulation', 'California', 'Caring', 'Cause of Death', 'Cellular Phone', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Research', 'Collaborations', 'Comorbidity', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Data Analyses', 'Data Element', 'Data Science', 'Data Set', 'Data Sources', 'Demographic Aging', 'Detection', 'Development', 'Effectiveness', 'Foundations', 'Funding', 'Future', 'General Hospitals', 'Geographic Locations', 'Goals', 'Growth', 'Health', 'High Performance Computing', 'Hospitalization', 'Hospitals', 'Hybrids', 'Informatics', 'Information Technology', 'Injury', 'Knowledge', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Medical', 'Mentored Research Scientist Development Award', 'Mentors', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Myocardial Ischemia', 'Operative Surgical Procedures', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Play', 'Pneumonia', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'San Francisco', 'Severities', 'Socioeconomic Status', 'Solid', 'Source', 'Statistical Methods', 'Surgeon', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Trauma', 'Trauma patient', 'Traumatic injury', 'Universities', 'Work', 'base', 'big biomedical data', 'care systems', 'career', 'cloud based', 'cost', 'disability', 'experience', 'follow-up', 'improved', 'improved outcome', 'individual patient', 'injured', 'modifiable risk', 'mortality', 'multidisciplinary', 'novel', 'novel strategies', 'prediction algorithm', 'professor', 'trauma care', 'trauma centers']",NIEHS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K01,2016,222942,0.2785363998488628
"Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data ﻿    DESCRIPTION (provided by applicant)    My goal in seeking a K01 Award is to acquire the necessary training to become an independently funded investigator focused on exploiting the power of biomedical Big Data Science to improve outcome following severe injury. I am a trauma surgeon at San Francisco General Hospital, one of the Nation's leading trauma centers, and an Assistant Professor of Surgery at the University of California San Francisco (UCSF). UCSF has recently entered into collaboration with the National Laboratories to study the use of biomedical Big Data in complex clinical conditions and my main mentor, Dr. Mitchell J. Cohen is the lead investigator at UCSF for this collaboration. I believe that given the complexity of the factors that likely affect traum outcome including patient injury patterns, medical co-morbidities, patient biology, and the system of care, trauma provides a solid foundation to study the utility of Big Data Science for solving complex medical questions. To facilitate my growth as an expert in this field, I am proposing to develop a framework for integrating multiple data sources necessary to forecast patient outcomes following trauma. These novel datasets combined with biologic and metadata will then be utilized to create improved metrics that better predict complication risk from modifiable and non-modifiable factors. The net result of this work is a new approach to data ascertainment for measuring outcome, leveraging new data types to improve prediction of patient trajectory, and creating a platform to interface with existing information technology to ultimately be used for an early warning detection system for patients at risk of complications. The future long-term goal of this work would be to identify early patients predicted to do more poorly and then apply refinements to the process of care to minimize complication development. The creation of early warning detection systems has significant theoretic potential to improve quality and ultimately decrease costs. Nearly $30 billion per year in the US is spent on care for the traumatically injured and the development of post-traumatic complications is believed to be major contributor to the overall costs of care. The ability to report performance has been hampered by a lack of standard definitions, reporting bias, access to datasets, and the analysis techniques that fail to account for the highly confounded relationships contributing to patient outcome. This K01 award will provide me with the support necessary to accomplish the following goals: (1) to become an expert in applying biologic big data to trauma care (2) to elucidate the relationship of modifiable factors affecting complication development (3) to gain experience with advanced biostatistical techniques and bioinformatics; and (4) to develop an independent clinical research career. To achieve these goals, I have assembled a multidisciplinary team including Dr. Cohen, a National expert in trauma systems biology and biologic big data, and two co-mentors: Dr. Michael Matthay, a translational research expert in complications after severe illness, and Dr. Alan Hubbard, an expert in advanced biostatistical techniques including biologic big data analysis. PUBLIC HEALTH RELEVANCE    In the US, trauma is the leading cause of death for those under 45 years old and many of the patients who survive their initial injuries develop complications such as blood clots or pneumonia that contribute to both death and the long-term effects of the trauma. Through leveraging the power of biomedical Big Data, an integrated approach to measuring outcome will be developed utilizing biologic, clinical, and electronic medical record (EMR) data. The goal of this project is to lay the ground work for developing integrated EMR early warning detection systems that could identify those at risk of complications early with the intent to ultimately refie the process of care for this group to minimize complication development.",Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data,9530647,K01ES026834,"['Address', 'Affect', 'Age', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Bioinformatics', 'Biology', 'Biometry', 'Blood coagulation', 'California', 'Caring', 'Cause of Death', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Research', 'Collaborations', 'Comorbidity', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Data Analyses', 'Data Element', 'Data Science', 'Data Set', 'Data Sources', 'Deltastab', 'Detection', 'Development', 'Effectiveness', 'Foundations', 'Funding', 'Future', 'General Hospitals', 'Geographic Locations', 'Goals', 'Growth', 'High Performance Computing', 'Hospitalization', 'Hospitals', 'Hybrids', 'Informatics', 'Information Technology', 'Injury', 'Knowledge', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Medical', 'Mentored Research Scientist Development Award', 'Mentors', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Myocardial Ischemia', 'Operative Surgical Procedures', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Play', 'Pneumonia', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'San Francisco', 'Severities', 'Socioeconomic Status', 'Solid', 'Source', 'Standardization', 'Statistical Methods', 'Surgeon', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Trauma', 'Trauma patient', 'Traumatic injury', 'Universities', 'Work', 'base', 'big biomedical data', 'care costs', 'care systems', 'career', 'cloud based', 'cost', 'demographics', 'disability', 'experience', 'follow-up', 'improved', 'improved outcome', 'individual patient', 'injured', 'modifiable risk', 'mortality', 'multidisciplinary', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'predictive modeling', 'professor', 'public health relevance', 'smartphone Application', 'trauma care', 'trauma centers']",NIEHS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K01,2018,221740,0.2785363998488628
"Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data ﻿    DESCRIPTION (provided by applicant)    My goal in seeking a K01 Award is to acquire the necessary training to become an independently funded investigator focused on exploiting the power of biomedical Big Data Science to improve outcome following severe injury. I am a trauma surgeon at San Francisco General Hospital, one of the Nation's leading trauma centers, and an Assistant Professor of Surgery at the University of California San Francisco (UCSF). UCSF has recently entered into collaboration with the National Laboratories to study the use of biomedical Big Data in complex clinical conditions and my main mentor, Dr. Mitchell J. Cohen is the lead investigator at UCSF for this collaboration. I believe that given the complexity of the factors that likely affect traum outcome including patient injury patterns, medical co-morbidities, patient biology, and the system of care, trauma provides a solid foundation to study the utility of Big Data Science for solving complex medical questions. To facilitate my growth as an expert in this field, I am proposing to develop a framework for integrating multiple data sources necessary to forecast patient outcomes following trauma. These novel datasets combined with biologic and metadata will then be utilized to create improved metrics that better predict complication risk from modifiable and non-modifiable factors. The net result of this work is a new approach to data ascertainment for measuring outcome, leveraging new data types to improve prediction of patient trajectory, and creating a platform to interface with existing information technology to ultimately be used for an early warning detection system for patients at risk of complications. The future long-term goal of this work would be to identify early patients predicted to do more poorly and then apply refinements to the process of care to minimize complication development. The creation of early warning detection systems has significant theoretic potential to improve quality and ultimately decrease costs. Nearly $30 billion per year in the US is spent on care for the traumatically injured and the development of post-traumatic complications is believed to be major contributor to the overall costs of care. The ability to report performance has been hampered by a lack of standard definitions, reporting bias, access to datasets, and the analysis techniques that fail to account for the highly confounded relationships contributing to patient outcome. This K01 award will provide me with the support necessary to accomplish the following goals: (1) to become an expert in applying biologic big data to trauma care (2) to elucidate the relationship of modifiable factors affecting complication development (3) to gain experience with advanced biostatistical techniques and bioinformatics; and (4) to develop an independent clinical research career. To achieve these goals, I have assembled a multidisciplinary team including Dr. Cohen, a National expert in trauma systems biology and biologic big data, and two co-mentors: Dr. Michael Matthay, a translational research expert in complications after severe illness, and Dr. Alan Hubbard, an expert in advanced biostatistical techniques including biologic big data analysis. PUBLIC HEALTH RELEVANCE    In the US, trauma is the leading cause of death for those under 45 years old and many of the patients who survive their initial injuries develop complications such as blood clots or pneumonia that contribute to both death and the long-term effects of the trauma. Through leveraging the power of biomedical Big Data, an integrated approach to measuring outcome will be developed utilizing biologic, clinical, and electronic medical record (EMR) data. The goal of this project is to lay the ground work for developing integrated EMR early warning detection systems that could identify those at risk of complications early with the intent to ultimately refie the process of care for this group to minimize complication development.",Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data,9320947,K01ES026834,"['Address', 'Affect', 'Age', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Bioinformatics', 'Biology', 'Biometry', 'Blood coagulation', 'California', 'Caring', 'Cause of Death', 'Cellular Phone', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Research', 'Collaborations', 'Comorbidity', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Data Analyses', 'Data Element', 'Data Science', 'Data Set', 'Data Sources', 'Deltastab', 'Detection', 'Development', 'Effectiveness', 'Foundations', 'Funding', 'Future', 'General Hospitals', 'Geographic Locations', 'Goals', 'Growth', 'High Performance Computing', 'Hospitalization', 'Hospitals', 'Hybrids', 'Informatics', 'Information Technology', 'Injury', 'Knowledge', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Medical', 'Mentored Research Scientist Development Award', 'Mentors', 'Metadata', 'Methods', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Myocardial Ischemia', 'Operative Surgical Procedures', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Play', 'Pneumonia', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'San Francisco', 'Severities', 'Socioeconomic Status', 'Solid', 'Source', 'Standardization', 'Statistical Methods', 'Surgeon', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Trauma', 'Trauma patient', 'Traumatic injury', 'Universities', 'Work', 'base', 'big biomedical data', 'care systems', 'career', 'cloud based', 'cost', 'demographics', 'disability', 'experience', 'follow-up', 'improved', 'improved outcome', 'individual patient', 'injured', 'modifiable risk', 'mortality', 'multidisciplinary', 'novel', 'novel strategies', 'portability', 'prediction algorithm', 'professor', 'public health relevance', 'trauma care', 'trauma centers']",NIEHS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K01,2017,221780,0.2785363998488628
"Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data ﻿    DESCRIPTION (provided by applicant)    My goal in seeking a K01 Award is to acquire the necessary training to become an independently funded investigator focused on exploiting the power of biomedical Big Data Science to improve outcome following severe injury. I am a trauma surgeon at San Francisco General Hospital, one of the Nation's leading trauma centers, and an Assistant Professor of Surgery at the University of California San Francisco (UCSF). UCSF has recently entered into collaboration with the National Laboratories to study the use of biomedical Big Data in complex clinical conditions and my main mentor, Dr. Mitchell J. Cohen is the lead investigator at UCSF for this collaboration. I believe that given the complexity of the factors that likely affect traum outcome including patient injury patterns, medical co-morbidities, patient biology, and the system of care, trauma provides a solid foundation to study the utility of Big Data Science for solving complex medical questions. To facilitate my growth as an expert in this field, I am proposing to develop a framework for integrating multiple data sources necessary to forecast patient outcomes following trauma. These novel datasets combined with biologic and metadata will then be utilized to create improved metrics that better predict complication risk from modifiable and non-modifiable factors. The net result of this work is a new approach to data ascertainment for measuring outcome, leveraging new data types to improve prediction of patient trajectory, and creating a platform to interface with existing information technology to ultimately be used for an early warning detection system for patients at risk of complications. The future long-term goal of this work would be to identify early patients predicted to do more poorly and then apply refinements to the process of care to minimize complication development. The creation of early warning detection systems has significant theoretic potential to improve quality and ultimately decrease costs. Nearly $30 billion per year in the US is spent on care for the traumatically injured and the development of post-traumatic complications is believed to be major contributor to the overall costs of care. The ability to report performance has been hampered by a lack of standard definitions, reporting bias, access to datasets, and the analysis techniques that fail to account for the highly confounded relationships contributing to patient outcome. This K01 award will provide me with the support necessary to accomplish the following goals: (1) to become an expert in applying biologic big data to trauma care (2) to elucidate the relationship of modifiable factors affecting complication development (3) to gain experience with advanced biostatistical techniques and bioinformatics; and (4) to develop an independent clinical research career. To achieve these goals, I have assembled a multidisciplinary team including Dr. Cohen, a National expert in trauma systems biology and biologic big data, and two co-mentors: Dr. Michael Matthay, a translational research expert in complications after severe illness, and Dr. Alan Hubbard, an expert in advanced biostatistical techniques including biologic big data analysis.         PUBLIC HEALTH RELEVANCE    In the US, trauma is the leading cause of death for those under 45 years old and many of the patients who survive their initial injuries develop complications such as blood clots or pneumonia that contribute to both death and the long-term effects of the trauma. Through leveraging the power of biomedical Big Data, an integrated approach to measuring outcome will be developed utilizing biologic, clinical, and electronic medical record (EMR) data. The goal of this project is to lay the ground work for developing integrated EMR early warning detection systems that could identify those at risk of complications early with the intent to ultimately refie the process of care for this group to minimize complication development.                ",Advancing Outcome Metrics in Trauma Surgery Through Utilization of Big Data,9043721,K01ES026834,"['Accounting', 'Address', 'Affect', 'Age', 'Algorithms', 'American', 'Benchmarking', 'Big Data', 'Bioinformatics', 'Biology', 'Biometry', 'Blood coagulation', 'California', 'Caring', 'Cause of Death', 'Cellular Phone', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Research', 'Collaborations', 'Comorbidity', 'Complex', 'Complication', 'Computerized Medical Record', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Data Sources', 'Demographic Aging', 'Detection', 'Development', 'Effectiveness', 'Foundations', 'Funding', 'Future', 'General Hospitals', 'Geographic Locations', 'Goals', 'Growth', 'High Performance Computing', 'Hospitalization', 'Hospitals', 'Hybrids', 'Individual', 'Informatics', 'Information Technology', 'Injury', 'Knowledge', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Medical', 'Mentored Research Scientist Development Award', 'Mentors', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Myocardial Ischemia', 'Operative Surgical Procedures', 'Outcome', 'Outcome Measure', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Play', 'Pneumonia', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'San Francisco', 'Science', 'Severities', 'Socioeconomic Status', 'Solid', 'Source', 'Statistical Methods', 'Surgeon', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Trauma', 'Trauma patient', 'Universities', 'Work', 'base', 'care systems', 'career', 'cloud based', 'cost', 'disability', 'experience', 'follow-up', 'improved', 'injured', 'modifiable risk', 'mortality', 'multidisciplinary', 'novel', 'novel strategies', 'professor', 'public health relevance', 'trauma care', 'trauma centers']",NIEHS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K01,2015,222898,0.2785363998488628
"New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis ﻿    DESCRIPTION (provided by applicant)    Maha R Farhat, MD is an Instructor of Medicine at Harvard Medical School on the tenure track and a staff physician in the Department of Pulmonary and Critical Care Medicine at Massachusetts General Hospital. She is completing a masters of biostatistics at the Harvard School of Public Health in 5/2015. She has spent the last 4.5 years acquiring skills in Mycobacterium tuberculosis biology, epidemiology, bioinformatics and biostatistics. She has experience in the analysis of whole genome sequence data, drug resistance data and patient clinical outcome data with the focus of identifying Mycobacterium tuberculosis genetic determinants of drug resistance. She has also developed new methods in this area. Dr. Farhat has 11 publications 5 of which are first author including high impact and highly cited work in the journals Nature Genetics, Genome Medicine and the International Journal of Tuberculosis and Lung Disease. The short term goals of this K01 award are to provide training for Dr. Farhat in critical aspects of data science, computational and evolutionary biology, advanced biostatistics and network science. Dr. Farhat's long term goal is to become a leader in the field of Big Data analysis for infectious diseases. The proposed research as well as the training activities outlined in the proposal will successfully position Dr. Farhat for her first R01 and an independent career as a physician scientist. Environment: Dr. Farhat will perform the interdisciplinary work outlined in this proposal at the distinguished Harvard Departments of Global Health Social Medicine, Biostatistics, Evolutionary biology and the Institute for Quantitative Social Sciences. Dr. Farhat' mentorship team will include two world renowned leaders in the fields of infectious diseases and Big Data, Dr. Megan Murray and Dr. Gary King; and two rising stars in the fields of network Science and evolutionary Biology, Dr. JP Onnela and Dr. Michael Desai. Dr. Murray, the principal mentor on this proposal has mentored over 38 trainees, 9 of which have went on to have independent research careers, and 6 competed successfully for K awards. She is also PI on two recently awarded NIH/NIAID grants a CETR U19 and a TBRU U19 and has over 350 peer reviewed publications. To complement the expertise of her mentors Dr. Farhat will be advised by Dr. Christiani a practicing pulmonary and critical care physician and world renowned researcher in the field of lung and environmental genetics. She will also collaborate and consult with Dr. Merce Crosas, a data scientist, and Dr. Pardis Sabeti, a computational biologist. She will rotate through Dr. Soumya Raychaudhuri's bioinformatics laboratory to diversify her exposure to biomedical Big Data. In addition, she will receive formal training in evolutionary biology, Bayesian and mixed-model biostatistics, computer science, leadership skills and grant writing. The collaborative opportunities, intellectual environment and resources available to Dr. Farhat are outstanding. Research: Infectious diseases continue to be a major cause of morbidity and mortality. Despite the availability of effective antimicrobials, pathogens are successfully evolving new disease phenotypes that allow them to resist killing by these drugs or in other instances cause more severe disease manifestations or wider chains of transmission. Drug resistance (DR) is now common and some bacteria have even become resistant to multiple types or classes of antibiotics6. A key strategy in the fight against emerging pathogen phenotypes in infectious diseases is surveillance, and early personalized therapy to prevent transmission and propagation of these strains. The timely initiation of antibiotic therapy to which the pathogen is sensitive has been shown to be the key factor influencing treatment outcome for a diverse array of infections. Molecular tests that rely on the detection of microbial genetic mutations are particularly promising for surveillance and diagnosis of these pathogen phenotypes but rely on a comprehensive understanding of how mutations associate with these pathogen phenotypes. Currently there is an explosion of data on pathogen whole genome sequences (WGS) that is increasingly generated from clinical laboratories. Data on disease phenotype may also be available, but methods for the analysis and interpretation of these Big Data are lagging. Here I propose tools to aid in this analysis leveraging Big Data sets from Mycobacterium tuberculosis (MTB) and my prior work. Specifically I propose to (1) develop a web-based public interface to several analysis tools, including a statistical learning model that can predict the MTB DR phenotype from its genomic sequence, (2) to develop and study an MTB gene-gene network, based on WGS data, to improve our understanding of the effect of mutation-mutation interactions on the DR phenotype, and (3) study the performance of methods in current use for the association of genotype and phenotype in pathogens, and develop a generalizable power calculator for the best performing method. PUBLIC HEALTH RELEVANCE    Infectious agents of disease are successfully evolving drug resistance and other adaptations that threaten human health. Understanding the genetic mutations that underlie these disease phenotypes can inform surveillance and diagnostic strategies to combat this threat. Here I propose to develop accessible tools for pathogen genomic analysis that will help identify which genetic mutations are relevant to disease.",New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis,9747894,K01ES026835,"['Affect', 'Antibiotic Therapy', 'Antibiotics', 'Area', 'Award', 'Bacteria', 'Big Data', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Cessation of life', 'Clinical', 'Collaborations', 'Communicable Diseases', 'Complement', 'Consult', 'Critical Care', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Science', 'Data Scientist', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug resistance', 'Drug resistance in tuberculosis', 'Drug-sensitive', 'Environment', 'Epidemiology', 'Explosion', 'Exposure to', 'Future', 'Gene Structure', 'General Hospitals', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Epistasis', 'Genome', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Grant', 'Health', 'Heritability', 'Human', 'Infection', 'Infectious Agent', 'Infectious Diseases Research', 'Institutes', 'International', 'Journals', 'K-Series Research Career Programs', 'Laboratories', 'Leadership', 'Low income', 'Lung', 'Lung diseases', 'Machine Learning', 'Massachusetts', 'Measures', 'Medical Genetics', 'Medicine', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microbial Genetics', 'Modeling', 'Molecular', 'Monitor', 'Morbidity - disease rate', 'Mutation', 'Mycobacterium tuberculosis', 'National Institute of Allergy and Infectious Disease', 'Nature', 'Network-based', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Phylogeny', 'Physicians', 'Population', 'Positioning Attribute', 'Public Health', 'Public Health Schools', 'Publications', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Science', 'Scientist', 'Severity of illness', 'Social Medicine', 'Social Sciences', 'Standardization', 'Statistical Data Interpretation', 'Structural Genes', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Tuberculosis', 'United States National Institutes of Health', 'Variant', 'Virulent', 'Work', 'Writing', 'analytical tool', 'antimicrobial', 'base', 'big biomedical data', 'burden of illness', 'career', 'combat', 'computer science', 'design', 'disease phenotype', 'experience', 'fight against', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'global health', 'human pathogen', 'improved', 'instructor', 'medical schools', 'microbial', 'microbial genome', 'mortality', 'pathogen', 'pathogen genome', 'pathogen genomics', 'personalized medicine', 'prevent', 'prospective', 'public health relevance', 'simulation', 'skills', 'tenure track', 'tool', 'transmission process', 'whole genome']",NIEHS,HARVARD MEDICAL SCHOOL,K01,2019,215352,0.1436705678517429
"New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis ﻿    DESCRIPTION (provided by applicant)    Maha R Farhat, MD is an Instructor of Medicine at Harvard Medical School on the tenure track and a staff physician in the Department of Pulmonary and Critical Care Medicine at Massachusetts General Hospital. She is completing a masters of biostatistics at the Harvard School of Public Health in 5/2015. She has spent the last 4.5 years acquiring skills in Mycobacterium tuberculosis biology, epidemiology, bioinformatics and biostatistics. She has experience in the analysis of whole genome sequence data, drug resistance data and patient clinical outcome data with the focus of identifying Mycobacterium tuberculosis genetic determinants of drug resistance. She has also developed new methods in this area. Dr. Farhat has 11 publications 5 of which are first author including high impact and highly cited work in the journals Nature Genetics, Genome Medicine and the International Journal of Tuberculosis and Lung Disease. The short term goals of this K01 award are to provide training for Dr. Farhat in critical aspects of data science, computational and evolutionary biology, advanced biostatistics and network science. Dr. Farhat's long term goal is to become a leader in the field of Big Data analysis for infectious diseases. The proposed research as well as the training activities outlined in the proposal will successfully position Dr. Farhat for her first R01 and an independent career as a physician scientist. Environment: Dr. Farhat will perform the interdisciplinary work outlined in this proposal at the distinguished Harvard Departments of Global Health Social Medicine, Biostatistics, Evolutionary biology and the Institute for Quantitative Social Sciences. Dr. Farhat' mentorship team will include two world renowned leaders in the fields of infectious diseases and Big Data, Dr. Megan Murray and Dr. Gary King; and two rising stars in the fields of network Science and evolutionary Biology, Dr. JP Onnela and Dr. Michael Desai. Dr. Murray, the principal mentor on this proposal has mentored over 38 trainees, 9 of which have went on to have independent research careers, and 6 competed successfully for K awards. She is also PI on two recently awarded NIH/NIAID grants a CETR U19 and a TBRU U19 and has over 350 peer reviewed publications. To complement the expertise of her mentors Dr. Farhat will be advised by Dr. Christiani a practicing pulmonary and critical care physician and world renowned researcher in the field of lung and environmental genetics. She will also collaborate and consult with Dr. Merce Crosas, a data scientist, and Dr. Pardis Sabeti, a computational biologist. She will rotate through Dr. Soumya Raychaudhuri's bioinformatics laboratory to diversify her exposure to biomedical Big Data. In addition, she will receive formal training in evolutionary biology, Bayesian and mixed-model biostatistics, computer science, leadership skills and grant writing. The collaborative opportunities, intellectual environment and resources available to Dr. Farhat are outstanding. Research: Infectious diseases continue to be a major cause of morbidity and mortality. Despite the availability of effective antimicrobials, pathogens are successfully evolving new disease phenotypes that allow them to resist killing by these drugs or in other instances cause more severe disease manifestations or wider chains of transmission. Drug resistance (DR) is now common and some bacteria have even become resistant to multiple types or classes of antibiotics6. A key strategy in the fight against emerging pathogen phenotypes in infectious diseases is surveillance, and early personalized therapy to prevent transmission and propagation of these strains. The timely initiation of antibiotic therapy to which the pathogen is sensitive has been shown to be the key factor influencing treatment outcome for a diverse array of infections. Molecular tests that rely on the detection of microbial genetic mutations are particularly promising for surveillance and diagnosis of these pathogen phenotypes but rely on a comprehensive understanding of how mutations associate with these pathogen phenotypes. Currently there is an explosion of data on pathogen whole genome sequences (WGS) that is increasingly generated from clinical laboratories. Data on disease phenotype may also be available, but methods for the analysis and interpretation of these Big Data are lagging. Here I propose tools to aid in this analysis leveraging Big Data sets from Mycobacterium tuberculosis (MTB) and my prior work. Specifically I propose to (1) develop a web-based public interface to several analysis tools, including a statistical learning model that can predict the MTB DR phenotype from its genomic sequence, (2) to develop and study an MTB gene-gene network, based on WGS data, to improve our understanding of the effect of mutation-mutation interactions on the DR phenotype, and (3) study the performance of methods in current use for the association of genotype and phenotype in pathogens, and develop a generalizable power calculator for the best performing method.         PUBLIC HEALTH RELEVANCE    Infectious agents of disease are successfully evolving drug resistance and other adaptations that threaten human health. Understanding the genetic mutations that underlie these disease phenotypes can inform surveillance and diagnostic strategies to combat this threat. Here I propose to develop accessible tools for pathogen genomic analysis that will help identify which genetic mutations are relevant to disease.                ",New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis,9044227,K01ES026835,"['Affect', 'Antibiotic Therapy', 'Antibiotics', 'Area', 'Award', 'Bacteria', 'Big Data', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Cessation of life', 'Clinical', 'Collaborations', 'Communicable Diseases', 'Complement', 'Computational Science', 'Consult', 'Critical Care', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug resistance', 'Drug resistance in tuberculosis', 'Drug-sensitive', 'Environment', 'Epidemiology', 'Explosion', 'Exposure to', 'Future', 'Gene Structure', 'General Hospitals', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Epistasis', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Health', 'Human', 'Infection', 'Infectious Agent', 'Infectious Diseases Research', 'Institutes', 'International', 'Journals', 'K-Series Research Career Programs', 'Laboratories', 'Leadership', 'Low income', 'Lung', 'Lung diseases', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical Genetics', 'Medicine', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microbial Genetics', 'Modeling', 'Molecular', 'Monitor', 'Morbidity - disease rate', 'Mutation', 'Mycobacterium tuberculosis', 'National Institute of Allergy and Infectious Disease', 'Nature', 'Network-based', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Phylogeny', 'Physicians', 'Population', 'Positioning Attribute', 'Public Health', 'Public Health Schools', 'Publications', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Science', 'Scientist', 'Severity of illness', 'Social Medicine', 'Social Sciences', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Tuberculosis', 'United States National Institutes of Health', 'Variant', 'Virulent', 'Work', 'Writing', 'analytical tool', 'antimicrobial', 'base', 'burden of illness', 'career', 'combat', 'computer science', 'design', 'disease phenotype', 'experience', 'fight against', 'gene interaction', 'genome sequencing', 'genome-wide', 'global health', 'improved', 'instructor', 'killings', 'medical schools', 'microbial', 'microbial genome', 'mortality', 'pathogen', 'personalized medicine', 'prevent', 'prospective', 'public health relevance', 'simulation', 'skills', 'tool', 'transmission process']",NIEHS,MASSACHUSETTS GENERAL HOSPITAL,K01,2015,230806,0.1436705678517429
"New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis ﻿    DESCRIPTION (provided by applicant)    Maha R Farhat, MD is an Instructor of Medicine at Harvard Medical School on the tenure track and a staff physician in the Department of Pulmonary and Critical Care Medicine at Massachusetts General Hospital. She is completing a masters of biostatistics at the Harvard School of Public Health in 5/2015. She has spent the last 4.5 years acquiring skills in Mycobacterium tuberculosis biology, epidemiology, bioinformatics and biostatistics. She has experience in the analysis of whole genome sequence data, drug resistance data and patient clinical outcome data with the focus of identifying Mycobacterium tuberculosis genetic determinants of drug resistance. She has also developed new methods in this area. Dr. Farhat has 11 publications 5 of which are first author including high impact and highly cited work in the journals Nature Genetics, Genome Medicine and the International Journal of Tuberculosis and Lung Disease. The short term goals of this K01 award are to provide training for Dr. Farhat in critical aspects of data science, computational and evolutionary biology, advanced biostatistics and network science. Dr. Farhat's long term goal is to become a leader in the field of Big Data analysis for infectious diseases. The proposed research as well as the training activities outlined in the proposal will successfully position Dr. Farhat for her first R01 and an independent career as a physician scientist. Environment: Dr. Farhat will perform the interdisciplinary work outlined in this proposal at the distinguished Harvard Departments of Global Health Social Medicine, Biostatistics, Evolutionary biology and the Institute for Quantitative Social Sciences. Dr. Farhat' mentorship team will include two world renowned leaders in the fields of infectious diseases and Big Data, Dr. Megan Murray and Dr. Gary King; and two rising stars in the fields of network Science and evolutionary Biology, Dr. JP Onnela and Dr. Michael Desai. Dr. Murray, the principal mentor on this proposal has mentored over 38 trainees, 9 of which have went on to have independent research careers, and 6 competed successfully for K awards. She is also PI on two recently awarded NIH/NIAID grants a CETR U19 and a TBRU U19 and has over 350 peer reviewed publications. To complement the expertise of her mentors Dr. Farhat will be advised by Dr. Christiani a practicing pulmonary and critical care physician and world renowned researcher in the field of lung and environmental genetics. She will also collaborate and consult with Dr. Merce Crosas, a data scientist, and Dr. Pardis Sabeti, a computational biologist. She will rotate through Dr. Soumya Raychaudhuri's bioinformatics laboratory to diversify her exposure to biomedical Big Data. In addition, she will receive formal training in evolutionary biology, Bayesian and mixed-model biostatistics, computer science, leadership skills and grant writing. The collaborative opportunities, intellectual environment and resources available to Dr. Farhat are outstanding. Research: Infectious diseases continue to be a major cause of morbidity and mortality. Despite the availability of effective antimicrobials, pathogens are successfully evolving new disease phenotypes that allow them to resist killing by these drugs or in other instances cause more severe disease manifestations or wider chains of transmission. Drug resistance (DR) is now common and some bacteria have even become resistant to multiple types or classes of antibiotics6. A key strategy in the fight against emerging pathogen phenotypes in infectious diseases is surveillance, and early personalized therapy to prevent transmission and propagation of these strains. The timely initiation of antibiotic therapy to which the pathogen is sensitive has been shown to be the key factor influencing treatment outcome for a diverse array of infections. Molecular tests that rely on the detection of microbial genetic mutations are particularly promising for surveillance and diagnosis of these pathogen phenotypes but rely on a comprehensive understanding of how mutations associate with these pathogen phenotypes. Currently there is an explosion of data on pathogen whole genome sequences (WGS) that is increasingly generated from clinical laboratories. Data on disease phenotype may also be available, but methods for the analysis and interpretation of these Big Data are lagging. Here I propose tools to aid in this analysis leveraging Big Data sets from Mycobacterium tuberculosis (MTB) and my prior work. Specifically I propose to (1) develop a web-based public interface to several analysis tools, including a statistical learning model that can predict the MTB DR phenotype from its genomic sequence, (2) to develop and study an MTB gene-gene network, based on WGS data, to improve our understanding of the effect of mutation-mutation interactions on the DR phenotype, and (3) study the performance of methods in current use for the association of genotype and phenotype in pathogens, and develop a generalizable power calculator for the best performing method. PUBLIC HEALTH RELEVANCE    Infectious agents of disease are successfully evolving drug resistance and other adaptations that threaten human health. Understanding the genetic mutations that underlie these disease phenotypes can inform surveillance and diagnostic strategies to combat this threat. Here I propose to develop accessible tools for pathogen genomic analysis that will help identify which genetic mutations are relevant to disease.",New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis,9147601,K01ES026835,"['Affect', 'Antibiotic Therapy', 'Antibiotics', 'Area', 'Award', 'Bacteria', 'Big Data', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Cessation of life', 'Clinical', 'Collaborations', 'Communicable Diseases', 'Complement', 'Consult', 'Critical Care', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug resistance', 'Drug resistance in tuberculosis', 'Drug-sensitive', 'Environment', 'Epidemiology', 'Explosion', 'Exposure to', 'Future', 'Gene Structure', 'General Hospitals', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Epistasis', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Grant', 'Health', 'Human', 'Infection', 'Infectious Agent', 'Infectious Diseases Research', 'Institutes', 'International', 'Journals', 'K-Series Research Career Programs', 'Laboratories', 'Leadership', 'Low income', 'Lung', 'Lung diseases', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical Genetics', 'Medicine', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microbial Genetics', 'Modeling', 'Molecular', 'Monitor', 'Morbidity - disease rate', 'Mutation', 'Mycobacterium tuberculosis', 'National Institute of Allergy and Infectious Disease', 'Nature', 'Network-based', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Phylogeny', 'Physicians', 'Population', 'Positioning Attribute', 'Public Health', 'Public Health Schools', 'Publications', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Science', 'Scientist', 'Severity of illness', 'Social Medicine', 'Social Sciences', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Tuberculosis', 'United States National Institutes of Health', 'Variant', 'Virulent', 'Work', 'Writing', 'analytical tool', 'antimicrobial', 'base', 'big biomedical data', 'burden of illness', 'career', 'combat', 'computer science', 'design', 'disease phenotype', 'experience', 'fight against', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'global health', 'improved', 'instructor', 'killings', 'medical schools', 'microbial', 'microbial genome', 'mortality', 'pathogen', 'pathogen genome', 'personalized medicine', 'power analysis', 'prevent', 'prospective', 'simulation', 'skills', 'tenure track', 'tool', 'transmission process', 'whole genome']",NIEHS,MASSACHUSETTS GENERAL HOSPITAL,K01,2016,49355,0.1436705678517429
"New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis ﻿    DESCRIPTION (provided by applicant)    Maha R Farhat, MD is an Instructor of Medicine at Harvard Medical School on the tenure track and a staff physician in the Department of Pulmonary and Critical Care Medicine at Massachusetts General Hospital. She is completing a masters of biostatistics at the Harvard School of Public Health in 5/2015. She has spent the last 4.5 years acquiring skills in Mycobacterium tuberculosis biology, epidemiology, bioinformatics and biostatistics. She has experience in the analysis of whole genome sequence data, drug resistance data and patient clinical outcome data with the focus of identifying Mycobacterium tuberculosis genetic determinants of drug resistance. She has also developed new methods in this area. Dr. Farhat has 11 publications 5 of which are first author including high impact and highly cited work in the journals Nature Genetics, Genome Medicine and the International Journal of Tuberculosis and Lung Disease. The short term goals of this K01 award are to provide training for Dr. Farhat in critical aspects of data science, computational and evolutionary biology, advanced biostatistics and network science. Dr. Farhat's long term goal is to become a leader in the field of Big Data analysis for infectious diseases. The proposed research as well as the training activities outlined in the proposal will successfully position Dr. Farhat for her first R01 and an independent career as a physician scientist. Environment: Dr. Farhat will perform the interdisciplinary work outlined in this proposal at the distinguished Harvard Departments of Global Health Social Medicine, Biostatistics, Evolutionary biology and the Institute for Quantitative Social Sciences. Dr. Farhat' mentorship team will include two world renowned leaders in the fields of infectious diseases and Big Data, Dr. Megan Murray and Dr. Gary King; and two rising stars in the fields of network Science and evolutionary Biology, Dr. JP Onnela and Dr. Michael Desai. Dr. Murray, the principal mentor on this proposal has mentored over 38 trainees, 9 of which have went on to have independent research careers, and 6 competed successfully for K awards. She is also PI on two recently awarded NIH/NIAID grants a CETR U19 and a TBRU U19 and has over 350 peer reviewed publications. To complement the expertise of her mentors Dr. Farhat will be advised by Dr. Christiani a practicing pulmonary and critical care physician and world renowned researcher in the field of lung and environmental genetics. She will also collaborate and consult with Dr. Merce Crosas, a data scientist, and Dr. Pardis Sabeti, a computational biologist. She will rotate through Dr. Soumya Raychaudhuri's bioinformatics laboratory to diversify her exposure to biomedical Big Data. In addition, she will receive formal training in evolutionary biology, Bayesian and mixed-model biostatistics, computer science, leadership skills and grant writing. The collaborative opportunities, intellectual environment and resources available to Dr. Farhat are outstanding. Research: Infectious diseases continue to be a major cause of morbidity and mortality. Despite the availability of effective antimicrobials, pathogens are successfully evolving new disease phenotypes that allow them to resist killing by these drugs or in other instances cause more severe disease manifestations or wider chains of transmission. Drug resistance (DR) is now common and some bacteria have even become resistant to multiple types or classes of antibiotics6. A key strategy in the fight against emerging pathogen phenotypes in infectious diseases is surveillance, and early personalized therapy to prevent transmission and propagation of these strains. The timely initiation of antibiotic therapy to which the pathogen is sensitive has been shown to be the key factor influencing treatment outcome for a diverse array of infections. Molecular tests that rely on the detection of microbial genetic mutations are particularly promising for surveillance and diagnosis of these pathogen phenotypes but rely on a comprehensive understanding of how mutations associate with these pathogen phenotypes. Currently there is an explosion of data on pathogen whole genome sequences (WGS) that is increasingly generated from clinical laboratories. Data on disease phenotype may also be available, but methods for the analysis and interpretation of these Big Data are lagging. Here I propose tools to aid in this analysis leveraging Big Data sets from Mycobacterium tuberculosis (MTB) and my prior work. Specifically I propose to (1) develop a web-based public interface to several analysis tools, including a statistical learning model that can predict the MTB DR phenotype from its genomic sequence, (2) to develop and study an MTB gene-gene network, based on WGS data, to improve our understanding of the effect of mutation-mutation interactions on the DR phenotype, and (3) study the performance of methods in current use for the association of genotype and phenotype in pathogens, and develop a generalizable power calculator for the best performing method. PUBLIC HEALTH RELEVANCE    Infectious agents of disease are successfully evolving drug resistance and other adaptations that threaten human health. Understanding the genetic mutations that underlie these disease phenotypes can inform surveillance and diagnostic strategies to combat this threat. Here I propose to develop accessible tools for pathogen genomic analysis that will help identify which genetic mutations are relevant to disease.",New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis,9530648,K01ES026835,"['Affect', 'Antibiotic Therapy', 'Antibiotics', 'Area', 'Award', 'Bacteria', 'Big Data', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Cessation of life', 'Clinical', 'Collaborations', 'Communicable Diseases', 'Complement', 'Consult', 'Critical Care', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug resistance', 'Drug resistance in tuberculosis', 'Drug-sensitive', 'Environment', 'Epidemiology', 'Explosion', 'Exposure to', 'Future', 'Gene Structure', 'General Hospitals', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Epistasis', 'Genome', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Grant', 'Health', 'Heritability', 'Human', 'Infection', 'Infectious Agent', 'Infectious Diseases Research', 'Institutes', 'International', 'Journals', 'K-Series Research Career Programs', 'Laboratories', 'Leadership', 'Low income', 'Lung', 'Lung diseases', 'Machine Learning', 'Massachusetts', 'Measures', 'Medical Genetics', 'Medicine', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microbial Genetics', 'Modeling', 'Molecular', 'Monitor', 'Morbidity - disease rate', 'Mutation', 'Mycobacterium tuberculosis', 'National Institute of Allergy and Infectious Disease', 'Nature', 'Network-based', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Phylogeny', 'Physicians', 'Population', 'Positioning Attribute', 'Public Health', 'Public Health Schools', 'Publications', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Science', 'Scientist', 'Severity of illness', 'Social Medicine', 'Social Sciences', 'Standardization', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Tuberculosis', 'United States National Institutes of Health', 'Variant', 'Virulent', 'Work', 'Writing', 'analytical tool', 'antimicrobial', 'base', 'big biomedical data', 'burden of illness', 'career', 'combat', 'computer science', 'design', 'disease phenotype', 'experience', 'fight against', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'global health', 'improved', 'instructor', 'medical schools', 'microbial', 'microbial genome', 'mortality', 'pathogen', 'pathogen genome', 'personalized medicine', 'prevent', 'prospective', 'public health relevance', 'simulation', 'skills', 'tenure track', 'tool', 'transmission process', 'whole genome']",NIEHS,HARVARD MEDICAL SCHOOL,K01,2018,220530,0.1436705678517429
"New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis ﻿    DESCRIPTION (provided by applicant)    Maha R Farhat, MD is an Instructor of Medicine at Harvard Medical School on the tenure track and a staff physician in the Department of Pulmonary and Critical Care Medicine at Massachusetts General Hospital. She is completing a masters of biostatistics at the Harvard School of Public Health in 5/2015. She has spent the last 4.5 years acquiring skills in Mycobacterium tuberculosis biology, epidemiology, bioinformatics and biostatistics. She has experience in the analysis of whole genome sequence data, drug resistance data and patient clinical outcome data with the focus of identifying Mycobacterium tuberculosis genetic determinants of drug resistance. She has also developed new methods in this area. Dr. Farhat has 11 publications 5 of which are first author including high impact and highly cited work in the journals Nature Genetics, Genome Medicine and the International Journal of Tuberculosis and Lung Disease. The short term goals of this K01 award are to provide training for Dr. Farhat in critical aspects of data science, computational and evolutionary biology, advanced biostatistics and network science. Dr. Farhat's long term goal is to become a leader in the field of Big Data analysis for infectious diseases. The proposed research as well as the training activities outlined in the proposal will successfully position Dr. Farhat for her first R01 and an independent career as a physician scientist. Environment: Dr. Farhat will perform the interdisciplinary work outlined in this proposal at the distinguished Harvard Departments of Global Health Social Medicine, Biostatistics, Evolutionary biology and the Institute for Quantitative Social Sciences. Dr. Farhat' mentorship team will include two world renowned leaders in the fields of infectious diseases and Big Data, Dr. Megan Murray and Dr. Gary King; and two rising stars in the fields of network Science and evolutionary Biology, Dr. JP Onnela and Dr. Michael Desai. Dr. Murray, the principal mentor on this proposal has mentored over 38 trainees, 9 of which have went on to have independent research careers, and 6 competed successfully for K awards. She is also PI on two recently awarded NIH/NIAID grants a CETR U19 and a TBRU U19 and has over 350 peer reviewed publications. To complement the expertise of her mentors Dr. Farhat will be advised by Dr. Christiani a practicing pulmonary and critical care physician and world renowned researcher in the field of lung and environmental genetics. She will also collaborate and consult with Dr. Merce Crosas, a data scientist, and Dr. Pardis Sabeti, a computational biologist. She will rotate through Dr. Soumya Raychaudhuri's bioinformatics laboratory to diversify her exposure to biomedical Big Data. In addition, she will receive formal training in evolutionary biology, Bayesian and mixed-model biostatistics, computer science, leadership skills and grant writing. The collaborative opportunities, intellectual environment and resources available to Dr. Farhat are outstanding. Research: Infectious diseases continue to be a major cause of morbidity and mortality. Despite the availability of effective antimicrobials, pathogens are successfully evolving new disease phenotypes that allow them to resist killing by these drugs or in other instances cause more severe disease manifestations or wider chains of transmission. Drug resistance (DR) is now common and some bacteria have even become resistant to multiple types or classes of antibiotics6. A key strategy in the fight against emerging pathogen phenotypes in infectious diseases is surveillance, and early personalized therapy to prevent transmission and propagation of these strains. The timely initiation of antibiotic therapy to which the pathogen is sensitive has been shown to be the key factor influencing treatment outcome for a diverse array of infections. Molecular tests that rely on the detection of microbial genetic mutations are particularly promising for surveillance and diagnosis of these pathogen phenotypes but rely on a comprehensive understanding of how mutations associate with these pathogen phenotypes. Currently there is an explosion of data on pathogen whole genome sequences (WGS) that is increasingly generated from clinical laboratories. Data on disease phenotype may also be available, but methods for the analysis and interpretation of these Big Data are lagging. Here I propose tools to aid in this analysis leveraging Big Data sets from Mycobacterium tuberculosis (MTB) and my prior work. Specifically I propose to (1) develop a web-based public interface to several analysis tools, including a statistical learning model that can predict the MTB DR phenotype from its genomic sequence, (2) to develop and study an MTB gene-gene network, based on WGS data, to improve our understanding of the effect of mutation-mutation interactions on the DR phenotype, and (3) study the performance of methods in current use for the association of genotype and phenotype in pathogens, and develop a generalizable power calculator for the best performing method. PUBLIC HEALTH RELEVANCE    Infectious agents of disease are successfully evolving drug resistance and other adaptations that threaten human health. Understanding the genetic mutations that underlie these disease phenotypes can inform surveillance and diagnostic strategies to combat this threat. Here I propose to develop accessible tools for pathogen genomic analysis that will help identify which genetic mutations are relevant to disease.",New Tools for the interpretation of Pathogen Genomic Data with a focus on Mycobacterium tuberculosis,9326841,K01ES026835,"['Affect', 'Antibiotic Therapy', 'Antibiotics', 'Area', 'Award', 'Bacteria', 'Big Data', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Cessation of life', 'Clinical', 'Collaborations', 'Communicable Diseases', 'Complement', 'Consult', 'Critical Care', 'DNA Sequence Alteration', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Drug resistance', 'Drug resistance in tuberculosis', 'Drug-sensitive', 'Environment', 'Epidemiology', 'Explosion', 'Exposure to', 'Future', 'Gene Structure', 'General Hospitals', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Epistasis', 'Genome', 'Genomics', 'Genotype', 'Geography', 'Goals', 'Grant', 'Health', 'Heritability', 'Human', 'Infection', 'Infectious Agent', 'Infectious Diseases Research', 'Institutes', 'International', 'Journals', 'K-Series Research Career Programs', 'Laboratories', 'Leadership', 'Low income', 'Lung', 'Lung diseases', 'Machine Learning', 'Massachusetts', 'Measures', 'Medical Genetics', 'Medicine', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microbial Genetics', 'Modeling', 'Molecular', 'Monitor', 'Morbidity - disease rate', 'Mutation', 'Mycobacterium tuberculosis', 'National Institute of Allergy and Infectious Disease', 'Nature', 'Network-based', 'Online Systems', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Phylogeny', 'Physicians', 'Population', 'Positioning Attribute', 'Public Health', 'Public Health Schools', 'Publications', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Resources', 'Science', 'Scientist', 'Severity of illness', 'Social Medicine', 'Social Sciences', 'Standardization', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Training Activity', 'Treatment outcome', 'Tuberculosis', 'United States National Institutes of Health', 'Variant', 'Virulent', 'Work', 'Writing', 'analytical tool', 'antimicrobial', 'base', 'big biomedical data', 'burden of illness', 'career', 'combat', 'computer science', 'design', 'disease phenotype', 'experience', 'fight against', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'global health', 'improved', 'instructor', 'killings', 'medical schools', 'microbial', 'microbial genome', 'mortality', 'pathogen', 'pathogen genome', 'personalized medicine', 'prevent', 'prospective', 'public health relevance', 'simulation', 'skills', 'tenure track', 'tool', 'transmission process', 'whole genome']",NIEHS,HARVARD MEDICAL SCHOOL,K01,2017,225549,0.1436705678517429
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9752624,K01ES026839,"['Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Biomedical Engineering', 'Biophysics', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Excision', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Impairment', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Energy', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinical translation', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'patient variability', 'physical science', 'programs', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'sleep physiology', 'spatial temporal variation', 'standard of care', 'statistics', 'surgery outcome', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2019,148964,0.14483928188635714
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9534672,K01ES026839,"['Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Biophysics', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Excision', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Impairment', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Energy', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinical translation', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'patient variability', 'physical science', 'programs', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'spatial temporal variation', 'standard of care', 'statistics', 'surgery outcome', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2018,148964,0.14483928188635714
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9322204,K01ES026839,"['Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Biophysics', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Excision', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Impairment', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Energy', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinical translation', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'physical science', 'programs', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'spatial temporal variation', 'standard of care', 'statistics', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2017,148964,0.14483928188635714
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals. PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9147594,K01ES026839,"['Accounting', 'Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'Health', 'High Frequency Oscillation', 'Hybrids', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resected', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Vocational Guidance', 'Work', 'base', 'big biomedical data', 'career', 'career development', 'clinical practice', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'improved outcome', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'physical science', 'programs', 'relating to nervous system', 'scientific computing', 'signal processing', 'sleep epilepsy', 'spatial temporal variation', 'standard of care', 'statistics', 'terabyte', 'tool', 'training opportunity', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2016,148644,0.14483928188635714
"Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy ﻿    DESCRIPTION (provided by applicant)     A new electrical biomarker has been identified in high resolution, intracranial electroencephalogram (iEEG) recordings, called a high frequency oscillation (HFO). Studies have suggested this biomarker has great promise to identify seizure networks and improve surgical outcomes for patients with refractory epilepsy. However, translation of HFOs to clinical practice is hampered by many factors such as spatial, temporal and inter-patient variation in HFO detection rates, false positive and false negative detections, and significant background noise. Big data approaches using large numbers of HFOs acquired from many patients are needed to quantify these effects and allow clinical usage of HFOs. This project details a plan in which the candidate's experience quantifying measurement and detection bias in massive high energy nuclear physics datasets will be combined with a multidisciplinary mentor team to address this problem. The combination of training in computational neuroscience, big data network analysis, and translational neural engineering research will be critical to approach this problem and provide a career trajectory for the candidate. The specific aims of this proposal address three specific confounding factors: 1) the false negative HFO detection rate, 2) variations in HFO features not due to epilepsy, and 3) effects of the state of vigilance on HFOs. Each of these aims involve novel big data methods and/or applications generalizable to other situations: 1) estimating false positive detection rates using a combined experimental/simulated data approach, 2) clustering and classification of distributions of data points, rather than of the data points directly, and 3) a general disambiguation statistic to assess meaningful (rather than statistical) difference between distributions.  The applicant's career goal is to become an academic researcher in the analysis and modeling of intracranial EEG data with a focus on translational epilepsy and sleep physiology research. With the rapid advancement in the resolution of clinical EEG, there is already a strong need for this type of research expertise. Thi grant will provide didactic coursework, formal research and methods training, and career guidance from an expert mentor team. The three mentors have appointments spanning Neurology, Anesthesiology, Mathematics, Statistics, Biomedical Engineering, and Electrical Engineering and Computer Science. The candidate will also build and mentor a research team and establish external collaborations.  The University of Michigan is a premier research university with strong programs and training opportunities in biomedical and physical sciences, engineering, translational and academic research, and advanced research computing. This proposal makes extensive use of the University's large computer cluster. The mentor team and an external collaborator will provide candidate access to prerecorded, deidentified data from over 150 patients, estimated to have over 40 million HFOs. The environment and mentor team will provide the training, facilities, and data for the candidate to successfully complete the proposed goals.         PUBLIC HEALTH RELEVANCE    Recent advances in epilepsy research are generating very large datasets in the search for better ways to identify the region of brain responsible for generating seizures. A particular signa known as High Frequency Oscillations found in high resolution intracranial EEG shows great promise for identifying these regions, but clinicians are unable to use the signal due to confounding biases. This project combines big data processing expertise from particle physics, computer science and machine learning to address these confounds, providing a more accurate process to enable clinical translation of this new biomarker and potentially improve clinical outcomes.                ",Epileptic biomarkers and big data: identifying brain regions to resect in patients with refractory epilepsy,9041723,K01ES026839,"['Accounting', 'Address', 'Algorithms', 'Anesthesiology', 'Appointment', 'Area', 'Big Data', 'Biological Markers', 'Biomedical Engineering', 'Brain', 'Brain region', 'Chronic', 'Classification', 'Clinical', 'Collaborations', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Electrical Engineering', 'Electroencephalogram', 'Engineering', 'Environment', 'Epilepsy', 'Event', 'Funding', 'Future', 'Goals', 'Grant', 'Graph', 'High Frequency Oscillation', 'Hybrids', 'Individual', 'Literature', 'Machine Learning', 'Manpower and Training', 'Mathematics', 'Measurement', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Modeling', 'Motivation', 'Neurology', 'Neurosciences', 'Noise', 'Nuclear Physics', 'Operative Surgical Procedures', 'Outcome', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Physics', 'Physiological', 'Physiology', 'Population', 'Process', 'Refractory', 'Research', 'Research Methodology', 'Research Personnel', 'Resected', 'Resolution', 'Sampling', 'Seizures', 'Signal Transduction', 'Sleep', 'Solutions', 'Statistical Methods', 'Techniques', 'Technology', 'Training', 'Training Programs', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Variant', 'Work', 'base', 'career', 'career development', 'clinical practice', 'clinically relevant', 'computational neuroscience', 'computer cluster', 'computer science', 'computerized data processing', 'detector', 'expectation', 'experience', 'improved', 'innovation', 'multidisciplinary', 'nervous system disorder', 'novel', 'particle physics', 'patient population', 'physical science', 'public health relevance', 'relating to nervous system', 'scientific computing', 'signal processing', 'sleep epilepsy', 'spatial temporal variation', 'standard of care', 'statistics', 'tool', 'vigilance']",NIEHS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K01,2015,138213,0.14483928188635714
"Big data convergence of pathology and omics for disease prognosis ﻿    DESCRIPTION (provided by applicant)    There is a pressing need for improved means of interrogating cancer biology in order to identify markers associated with disease aggressiveness and patient outcome. While for a number of cancers, pathologic grade (morphologic appearance of cancerous tissue as assessed by a pathologist) has been found to be highly correlated with disease outcome, pathologic grade tends to suffer from significant inter-observer variability. Additionally pathologic grade alone is not useful in scenarios where two tumors may have subtle differences in their morphologic phenotype but significantly different behavior and outcome. Additionally while a number of molecular, gene expression based assays have been proposed for predicting outcome in cancers, the relatively poor to at best moderate success for these assays suggests that a solely ""omics"" driven approach for prognosis is not an optimal strategy. For most cancers, no single biomarker to date has been identified that is able to accurately and consistently stratify disease risk. This suggests a strong need for analytic and computational tools for quantitatively mining and integrating histologic image and molecular biomarkers to create fused predictors of disease risk and outcome. Such a unified approach is especially needed in cases where molecularly or morphologically similar tumors might have significantly different outcomes. This project will focus on the development of novel big data tools for processing of two key large scale data streams: 1) the high resolution (gigabyte-sized) digital images which capture pathology architecture and tissue morphology, and 2) a large set (up to tens of thousands) of molecular markers (e.g. NF-kB/p65/RelA, p-Akt (Ser473), periostin, cacna1d, ezh2, her2neu, ki67, propsa, and propsa2) found within the disease site. The ability to mine this information via innovative big data tools will allow for the creation of fused predictors of outcome and disease aggressiveness. A central hypothesis of this project is that the combination of quantitative histomorphometric and molecular features will yield a more predictive assay for evaluating disease aggressiveness compared to any single biomarker. This project will develop and evaluate the big data analysis and fusion tools in the context of evaluating disease aggressiveness for prostate cancer. Our over-arching goal is to translate big data tools to process and integrate imaging and molecular markers extracted from diseased tissue outlined by the following aims, Aim 1: Computer vision and machine learning tools for mining sub- visual image features associated with disease aggressiveness, Aim 2: Creating a fused predictor of disease aggressiveness by combining quantitative histomorphometric and molecular measurements, Aim 3: Evaluating the tools developed in Aims 1 and 2 for distinguishing between indolent and aggressive prostate cancer on data acquired from patients from across the leading urology institutions in the US including Johns Hopkins, The Cleveland Clinic, University Hospitals at CWRU, and University of Pennsylvania.         PUBLIC HEALTH RELEVANCE    Each year, 15,000 prostate cancer patients fail curative radical prostatectomy treatment within 5 years. In this proposal, we will develop an integrated diagnostic tool using both computational analysis of high resolution prostate tissue images and the molecular profile of the tumor in order to identify patients most at risk for disease recurrence. This research will provide innovation for the development of novel image analysis tools, data integration algorithms, and fused imaging-molecular predictors which may significantly reduce cancer morbidity and mortalities via improved accuracy of diagnosis.                ",Big data convergence of pathology and omics for disease prognosis,9044354,K01ES026841,"['Address', 'Algorithms', 'Appearance', 'Architecture', 'Big Data', 'Biochemical', 'Biological Assay', 'Biological Markers', 'Cancer Biology', 'Cancer Patient', 'Cancerous', 'Categories', 'Cell Nucleus', 'Cell Proliferation', 'Cell-Cell Adhesion', 'Cessation of life', 'Clinic', 'Cohort Studies', 'Collaborations', 'Complement', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outcome', 'Disease Progression', 'Early identification', 'Epithelial Cells', 'Gene Expression', 'Gland', 'Goals', 'Healthcare', 'Heterogeneity', 'Histologic', 'Histopathology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Interobserver Variability', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modality', 'Molecular', 'Molecular Profiling', 'Morbidity - disease rate', 'Morphology', 'NF-kappa B', 'Nomograms', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Pathologist', 'Pathology', 'Patients', 'Pennsylvania', 'Performance', 'Phenotype', 'Play', 'Process', 'Prostate', 'Prostate-Specific Antigen', 'Publications', 'Radical Prostatectomy', 'Recurrence', 'Research', 'Resolution', 'Role', 'Shapes', 'Specimen', 'Staining method', 'Stains', 'Stream', 'Testing', 'Texture', 'Tissue Microarray', 'Tissues', 'Training', 'Translating', 'Treatment outcome', 'Universities', 'University Hospitals', 'Urology', 'Validation', 'Visual', 'Work', 'base', 'behavioral outcome', 'computerized tools', 'data integration', 'diagnostic accuracy', 'digital', 'digital imaging', 'disorder risk', 'follow-up', 'improved', 'innovation', 'medical schools', 'men', 'molecular imaging', 'molecular marker', 'molecular pathology', 'molecular phenotype', 'mortality', 'novel', 'outcome forecast', 'p65', 'periostin', 'personalized medicine', 'prognostic', 'public health relevance', 'repository', 'success', 'tool', 'tumor', 'validation studies']",NIEHS,CASE WESTERN RESERVE UNIVERSITY,K01,2015,80841,0.048022456895309866
"Big Omics Data Engine 2 Supercomputer Computational and data science has transformed biomedical scientific discovery: its approaches are embedded into a wide range of workflows for diseases such as schizophrenia, depression, Alzheimer's, epilepsy, influenza, autism, drug addiction, pediatric cardiac care, Inflammatory Bowel Disease, prostate cancer and multiple myleloma. Sixty-one basic and translational researchers at Mount Sinai representing over $100 million in NIH funding, along with their collaborators from 75 external institutions, have utilized the Big Omics Data Engine (BODE) supercomputer to elucidate significant scientific findings in over 167 publications, including high impact journals such as Nature and Science, with 2,427 citations in three years. These researchers have also shared the data generated on BODE throughout their consortia and into national data sharing repositories. BODE is nearing the end of its vendor maintainable life, and researchers need increased computational throughput and storage space. To empower researchers to not only continue their inquiries, but to also tackle more complex scientific questions with decreased time to solution, we propose the Big Omics Data Engine 2 Supercomputer (BODE2). BODE2 will contain a total of 3,200 Intel Cascade Lake cores with 15 terabytes of memory and 14 petabytes of raw storage, and will leverage an existing 250 terabytes of SSDs. An instrument of this size is not available elsewhere affordably. With the proposed instrument, researchers will be able to take advantage of three major benefits: (1) the ability to receive results faster for overall greater scientific throughput; (2) the ability to increase the fidelity of their simulations and analyses; and (3) the ability to migrate research applications seamlessly to the software environment for greater scientific productivity. As with data produced on BODE, BODE2 data products will also be shared with the broader scientific community. BODE2 will provide the critical infrastructure needed by the wide range of researchers and clinicians for the genetics and population analysis, gene expression, machine learning and structural and chemical biology approaches used to make advances in these diseases. A specialized Big Omics Data Engine 2 Supercomputer instrument will provide necessary computational and data science infrastructure for 61 research projects with 75 collaborating institutions in diverse areas such as Alzheimer's, autism, schizophrenia, drug addiction, influenza, pediatric cardiac care, depression, epilepsy, prostate cancer and multiple myeloma. Data generated from this instrument will be shared in national databases.",Big Omics Data Engine 2 Supercomputer,9708160,S10OD026880,"['Alzheimer&apos', 's Disease', 'Biology', 'Cardiac', 'Caring', 'Chemicals', 'Childhood', 'Communities', 'Complex', 'Computational Science', 'Computer software', 'Data', 'Data Science', 'Disease', 'Drug Addiction', 'Environment', 'Epilepsy', 'Funding', 'Gene Expression', 'Inflammatory Bowel Diseases', 'Influenza', 'Infrastructure', 'Institution', 'Journals', 'Life', 'Machine Learning', 'Malignant neoplasm of prostate', 'Memory', 'Mental Depression', 'Nature', 'Population Analysis', 'Productivity', 'Publications', 'Research', 'Research Personnel', 'Schizophrenia', 'Science', 'Structure', 'Time', 'United States National Institutes of Health', 'Vendor', 'autism spectrum disorder', 'data sharing', 'genetic analysis', 'instrument', 'petabyte', 'repository', 'simulation', 'supercomputer', 'terabyte', 'translational scientist']",OD,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,S10,2019,1998264,0.02234938030290181
"Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers PROJECT SUMMARY As a computational biologist, my long-term goal is to develop methods and tools to discover new or better therapeutics for cancers. In the past few years, I have identified drug-repositioning candidates for a number of primary cancers using Big Data approaches. These candidates have been validated successfully in preclinical mouse models. To maximize the utility of Big Data, I plan to translate the findings into therapeutics; therefore, I propose to develop methods to utilize transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers. Current preclinical and clinical approaches including the NCI MATCH trial select therapies primarily based on actionable mutations, yet patients may have no actionable mutations or multiple actionable mutations that are hard to prioritize, suggesting the need for other different types of molecular biomarkers. The recent efforts have enabled the large-scale identification of various types of molecular biomarkers through correlating drug sensitivity with molecular profiles of pre-treatment cancer cell lines. Computational methods to match these biomarkers to individual patients to inform therapy in the clinic are thus in high demand. The objective of this award is therefore to develop computational approaches to identify therapeutics for individual patients by leveraging large-scale biomarkers identified from cancer cell lines. Through conducing this research, I expect to expand my knowledge in cancer clinical trials, cancer genomics, cancer biology, and statistics. To achieve the goal, I have gathered seven renowned experts from different fields related to Big Data Science as mentors/advisors/collaborators: Primary Mentor Dr. Atul Butte in translational bioinformatics from UCSF, Co-mentor Dr. Samuel So in cancer biology from Stanford University, Co-mentor Dr. Mark Segal in statistics from UCSF, Advisor Dr. Andrei Goga in cancer biology from UCSF, Advisor Dr. Laura Esserman in breast cancer trials from UCSF, Collaborator Dr. John Gordan in liver cancer trials from UCSF and Collaborator Dr. Xin Chen in cancer biology from UCSF. With the support from my world- class mentors, advisors and collaborators, this award will prepare me to be a leader in developing big data methods that are broadly impactful. PROJECT NARRATIVE One goal of the precision medicine initiative is to select optimal therapies for individual cancer patients based on their molecular and clinical profiles. Current preclinical and clinical approaches select therapies primarily based on actionable mutations. This work is expected to employ the protein/gene expression based biomarkers computed from public databases to inform individualized cancer therapy.","Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers",9925076,K01ES028047,"['Address', 'Adopted', 'Antineoplastic Agents', 'Award', 'Basal cell carcinoma', 'Big Data', 'Big Data Methods', 'Bioinformatics', 'Biological Markers', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cell Line', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Computing Methodologies', 'Consumption', 'Data', 'Data Set', 'Databases', 'Disease', 'Ewings sarcoma', 'Expression Profiling', 'Gene Expression', 'Gene Proteins', 'Genomic Data Commons', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Mentors', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Mus', 'Mutation', 'Non-Malignant', 'Normal tissue morphology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Precision Medicine Initiative', 'Primary carcinoma of the liver cells', 'Probability', 'Proteomics', 'Research', 'Resources', 'Sampling', 'Scientist', 'Source', 'System', 'Therapeutic', 'Time', 'Tissue Sample', 'Translating', 'Treatment outcome', 'Tumor Tissue', 'Universities', 'Validation', 'Work', 'Xenograft procedure', 'actionable mutation', 'base', 'big-data science', 'c-myc Genes', 'cancer cell', 'cancer clinical trial', 'cancer genomics', 'cancer therapy', 'data sharing', 'drug candidate', 'drug efficacy', 'drug sensitivity', 'efficacy testing', 'genetic signature', 'individual patient', 'individualized medicine', 'learning classifier', 'malignant breast neoplasm', 'molecular marker', 'mouse model', 'novel', 'oncotype', 'optimal treatments', 'personalized cancer therapy', 'personalized medicine', 'pre-clinical', 'predictive marker', 'protein expression', 'response', 'statistics', 'tool', 'transcriptomics', 'triple-negative invasive breast carcinoma', 'tumor']",NIEHS,MICHIGAN STATE UNIVERSITY,K01,2020,169087,0.11382557091304236
"Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers PROJECT SUMMARY As a computational biologist, my long-term goal is to develop methods and tools to discover new or better therapeutics for cancers. In the past few years, I have identified drug-repositioning candidates for a number of primary cancers using Big Data approaches. These candidates have been validated successfully in preclinical mouse models. To maximize the utility of Big Data, I plan to translate the findings into therapeutics; therefore, I propose to develop methods to utilize transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers. Current preclinical and clinical approaches including the NCI MATCH trial select therapies primarily based on actionable mutations, yet patients may have no actionable mutations or multiple actionable mutations that are hard to prioritize, suggesting the need for other different types of molecular biomarkers. The recent efforts have enabled the large-scale identification of various types of molecular biomarkers through correlating drug sensitivity with molecular profiles of pre-treatment cancer cell lines. Computational methods to match these biomarkers to individual patients to inform therapy in the clinic are thus in high demand. The objective of this award is therefore to develop computational approaches to identify therapeutics for individual patients by leveraging large-scale biomarkers identified from cancer cell lines. Through conducing this research, I expect to expand my knowledge in cancer clinical trials, cancer genomics, cancer biology, and statistics. To achieve the goal, I have gathered seven renowned experts from different fields related to Big Data Science as mentors/advisors/collaborators: Primary Mentor Dr. Atul Butte in translational bioinformatics from UCSF, Co-mentor Dr. Samuel So in cancer biology from Stanford University, Co-mentor Dr. Mark Segal in statistics from UCSF, Advisor Dr. Andrei Goga in cancer biology from UCSF, Advisor Dr. Laura Esserman in breast cancer trials from UCSF, Collaborator Dr. John Gordan in liver cancer trials from UCSF and Collaborator Dr. Xin Chen in cancer biology from UCSF. With the support from my world- class mentors, advisors and collaborators, this award will prepare me to be a leader in developing big data methods that are broadly impactful. PROJECT NARRATIVE One goal of the precision medicine initiative is to select optimal therapies for individual cancer patients based on their molecular and clinical profiles. Current preclinical and clinical approaches select therapies primarily based on actionable mutations. This work is expected to employ the protein/gene expression based biomarkers computed from public databases to inform individualized cancer therapy.","Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers",9741127,K01ES028047,"['Address', 'Adopted', 'Antineoplastic Agents', 'Award', 'Basal cell carcinoma', 'Big Data', 'Big Data Methods', 'Bioinformatics', 'Biological Markers', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cell Line', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Computing Methodologies', 'Consumption', 'Data', 'Data Science', 'Data Set', 'Databases', 'Disease', 'Ewings sarcoma', 'Expression Profiling', 'Gene Expression', 'Gene Proteins', 'Genomic Data Commons', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Mentors', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Mus', 'Mutation', 'Non-Malignant', 'Normal tissue morphology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Precision Medicine Initiative', 'Primary carcinoma of the liver cells', 'Probability', 'Proteomics', 'Research', 'Resources', 'Sampling', 'Scientist', 'Source', 'System', 'Therapeutic', 'Time', 'Tissue Sample', 'Translating', 'Treatment outcome', 'Tumor Tissue', 'Universities', 'Validation', 'Work', 'Xenograft procedure', 'actionable mutation', 'base', 'c-myc Genes', 'cancer cell', 'cancer clinical trial', 'cancer genomics', 'cancer therapy', 'data sharing', 'drug candidate', 'drug efficacy', 'drug sensitivity', 'efficacy testing', 'genetic signature', 'individual patient', 'individualized medicine', 'malignant breast neoplasm', 'molecular marker', 'mouse model', 'novel', 'optimal treatments', 'personalized cancer therapy', 'personalized medicine', 'pre-clinical', 'predictive marker', 'protein expression', 'response', 'statistics', 'tool', 'transcriptomics', 'triple-negative invasive breast carcinoma', 'tumor']",NIEHS,MICHIGAN STATE UNIVERSITY,K01,2019,170187,0.11382557091304236
"Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers PROJECT SUMMARY As a computational biologist, my long-term goal is to develop methods and tools to discover new or better therapeutics for cancers. In the past few years, I have identified drug-repositioning candidates for a number of primary cancers using Big Data approaches. These candidates have been validated successfully in preclinical mouse models. To maximize the utility of Big Data, I plan to translate the findings into therapeutics; therefore, I propose to develop methods to utilize transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers. Current preclinical and clinical approaches including the NCI MATCH trial select therapies primarily based on actionable mutations, yet patients may have no actionable mutations or multiple actionable mutations that are hard to prioritize, suggesting the need for other different types of molecular biomarkers. The recent efforts have enabled the large-scale identification of various types of molecular biomarkers through correlating drug sensitivity with molecular profiles of pre-treatment cancer cell lines. Computational methods to match these biomarkers to individual patients to inform therapy in the clinic are thus in high demand. The objective of this award is therefore to develop computational approaches to identify therapeutics for individual patients by leveraging large-scale biomarkers identified from cancer cell lines. Through conducing this research, I expect to expand my knowledge in cancer clinical trials, cancer genomics, cancer biology, and statistics. To achieve the goal, I have gathered seven renowned experts from different fields related to Big Data Science as mentors/advisors/collaborators: Primary Mentor Dr. Atul Butte in translational bioinformatics from UCSF, Co-mentor Dr. Samuel So in cancer biology from Stanford University, Co-mentor Dr. Mark Segal in statistics from UCSF, Advisor Dr. Andrei Goga in cancer biology from UCSF, Advisor Dr. Laura Esserman in breast cancer trials from UCSF, Collaborator Dr. John Gordan in liver cancer trials from UCSF and Collaborator Dr. Xin Chen in cancer biology from UCSF. With the support from my world- class mentors, advisors and collaborators, this award will prepare me to be a leader in developing big data methods that are broadly impactful. PROJECT NARRATIVE One goal of the precision medicine initiative is to select optimal therapies for individual cancer patients based on their molecular and clinical profiles. Current preclinical and clinical approaches select therapies primarily based on actionable mutations. This work is expected to employ the protein/gene expression based biomarkers computed from public databases to inform individualized cancer therapy.","Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers",9324471,K01ES028047,"['Address', 'Adopted', 'Alpha Cell', 'Antineoplastic Agents', 'Award', 'Basal cell carcinoma', 'Big Data', 'Bioinformatics', 'Biological Markers', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cell Line', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Databases', 'Disease', 'Ewings sarcoma', 'Gene Expression', 'Gene Proteins', 'Genomic Data Commons', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Mentors', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Mus', 'Mutation', 'Non-Malignant', 'Normal tissue morphology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Precision Medicine Initiative', 'Primary carcinoma of the liver cells', 'Probability', 'Proteomics', 'Research', 'Resources', 'Sampling', 'Scientist', 'Source', 'System', 'Therapeutic', 'Time', 'Tissue Sample', 'Translating', 'Treatment outcome', 'Tumor Tissue', 'Universities', 'Validation', 'Work', 'Xenograft procedure', 'actionable mutation', 'base', 'c-myc Genes', 'cancer cell', 'cancer clinical trial', 'cancer genomics', 'cancer therapy', 'data sharing', 'drug candidate', 'drug efficacy', 'drug sensitivity', 'efficacy testing', 'genetic signature', 'individual patient', 'malignant breast neoplasm', 'molecular marker', 'mouse model', 'novel', 'personalized cancer therapy', 'personalized medicine', 'pre-clinical', 'predictive marker', 'protein expression', 'response', 'statistics', 'tool', 'transcriptomics', 'triple-negative invasive breast carcinoma', 'tumor']",NIEHS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K01,2017,171216,0.11382557091304236
"Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers PROJECT SUMMARY As a computational biologist, my long-term goal is to develop methods and tools to discover new or better therapeutics for cancers. In the past few years, I have identified drug-repositioning candidates for a number of primary cancers using Big Data approaches. These candidates have been validated successfully in preclinical mouse models. To maximize the utility of Big Data, I plan to translate the findings into therapeutics; therefore, I propose to develop methods to utilize transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers. Current preclinical and clinical approaches including the NCI MATCH trial select therapies primarily based on actionable mutations, yet patients may have no actionable mutations or multiple actionable mutations that are hard to prioritize, suggesting the need for other different types of molecular biomarkers. The recent efforts have enabled the large-scale identification of various types of molecular biomarkers through correlating drug sensitivity with molecular profiles of pre-treatment cancer cell lines. Computational methods to match these biomarkers to individual patients to inform therapy in the clinic are thus in high demand. The objective of this award is therefore to develop computational approaches to identify therapeutics for individual patients by leveraging large-scale biomarkers identified from cancer cell lines. Through conducing this research, I expect to expand my knowledge in cancer clinical trials, cancer genomics, cancer biology, and statistics. To achieve the goal, I have gathered seven renowned experts from different fields related to Big Data Science as mentors/advisors/collaborators: Primary Mentor Dr. Atul Butte in translational bioinformatics from UCSF, Co-mentor Dr. Samuel So in cancer biology from Stanford University, Co-mentor Dr. Mark Segal in statistics from UCSF, Advisor Dr. Andrei Goga in cancer biology from UCSF, Advisor Dr. Laura Esserman in breast cancer trials from UCSF, Collaborator Dr. John Gordan in liver cancer trials from UCSF and Collaborator Dr. Xin Chen in cancer biology from UCSF. With the support from my world- class mentors, advisors and collaborators, this award will prepare me to be a leader in developing big data methods that are broadly impactful. PROJECT NARRATIVE One goal of the precision medicine initiative is to select optimal therapies for individual cancer patients based on their molecular and clinical profiles. Current preclinical and clinical approaches select therapies primarily based on actionable mutations. This work is expected to employ the protein/gene expression based biomarkers computed from public databases to inform individualized cancer therapy.","Integrating transcriptomic, proteomic and pharmacogenomic data to inform individualized therapy in cancers",9675371,K01ES028047,"['Address', 'Adopted', 'Antineoplastic Agents', 'Award', 'Basal cell carcinoma', 'Big Data', 'Bioinformatics', 'Biological Markers', 'Cancer Biology', 'Cancer Patient', 'Cancer cell line', 'Cell Line', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Communities', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Databases', 'Disease', 'Ewings sarcoma', 'Expression Profiling', 'Gene Expression', 'Gene Proteins', 'Genomic Data Commons', 'Goals', 'Individual', 'Knowledge', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of liver', 'Mentors', 'Meta-Analysis', 'Methods', 'Molecular', 'Molecular Profiling', 'Mus', 'Mutation', 'Non-Malignant', 'Normal tissue morphology', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Precision Medicine Initiative', 'Primary carcinoma of the liver cells', 'Probability', 'Proteomics', 'Research', 'Resources', 'Sampling', 'Scientist', 'Source', 'System', 'Therapeutic', 'Time', 'Tissue Sample', 'Translating', 'Treatment outcome', 'Tumor Tissue', 'Universities', 'Validation', 'Work', 'Xenograft procedure', 'actionable mutation', 'base', 'c-myc Genes', 'cancer cell', 'cancer clinical trial', 'cancer genomics', 'cancer therapy', 'data sharing', 'drug candidate', 'drug efficacy', 'drug sensitivity', 'efficacy testing', 'genetic signature', 'individual patient', 'individualized medicine', 'malignant breast neoplasm', 'molecular marker', 'mouse model', 'novel', 'optimal treatments', 'personalized cancer therapy', 'personalized medicine', 'pre-clinical', 'predictive marker', 'protein expression', 'response', 'statistics', 'tool', 'transcriptomics', 'triple-negative invasive breast carcinoma', 'tumor']",NIEHS,MICHIGAN STATE UNIVERSITY,K01,2018,171217,0.11382557091304236
"Tracking brain arousal fluctuations for fMRI Big Data discovery Recent years have seen rapid growth in the availability of large, complex functional magnetic resonance imaging (fMRI) datasets of the human brain. However, the potential of this fMRI Big Data is presently limited by our understanding of the neural sources that contribute to fMRI signals. Fluctuations in arousal (i.e., in the level wakefulness and alertness) are known to modulate cognitive and behavioral processes and to display prominent alterations in neuropsychiatric disorders. Yet, since the vast majority of fMRI datasets lack neurophysiological or behavioral indices of arousal, fMRI Big Data cannot be readily harnessed to understand human brain arousal in health and disease. Recent data-driven approaches attempt to fill this gap but have limitations. The overall goal of this proposal is to increase the transformative potential of fMRI Big Data for human neuroscience through a novel analytic framework for detecting arousal fluctuations from fMRI data alone. We will accomplish this goal by developing and disseminating tools for modeling arousal fluctuations based on powerful statistical learning methods (Specific Aim 1). We will apply these models to large fMRI databases of healthy aging and Alzheimer’s Disease, both of which are associated with altered arousal (Specific Aims 2 and 3). We will capitalize on these databases to determine how knowledge of brain arousal fluctuations improves neuroimaging biomarkers of aging- and neurodegenerative disease-related changes in human brain function, and the extent to which arousal itself constitutes an informative biomarker of these states. This research would, moreover, increase the reliability and translational potential of fMRI studies more broadly by providing the ability to account for these major neural (arousal) state changes. These immediate research goals form a strong bridge with my long-term research objective of understanding principles of brain function by developing and innovatively adapting methods for the analysis of large and complex neuroimaging datasets. This objective is enabled by the mentored training plan, where I will (i) develop expertise in cutting-edge machine learning techniques and (ii) apply these techniques to multimodal neuroimaging data. The two co-mentors have complementary expertise that align, respectively, with these two training components. Aims 1 and 2 will span the mentored phase and part of the independent phase, while Aim 3 (application to the Alzheimer’s Disease Neuroimaging Initiative data) will be performed in the independent phase. The mentored environment of the NIH Intramural Research Program provides the resources for all planned data acquisition, as well as a rich community of neuroscience investigators and seminars. Interaction with the extramural (Columbia University) co-mentor will occur through frequent video conferences and several visits, with opportunities to engage with the Columbia data science community. Developing models of brain arousal fluctuations in fMRI data would contribute to our understanding of arousal mechanisms and its alteration with a variety of brain disorders, including Alzheimer’s Disease. Further, the ability to account for arousal fluctuations in fMRI data analysis would broadly improve the sensitivity of fMRI for neuroscience and clinical research, and may be critical for developing reliable, noninvasive biomarkers for diagnosis and treatment.",Tracking brain arousal fluctuations for fMRI Big Data discovery,9982966,K22ES028048,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Arousal', 'Behavior', 'Behavioral', 'Big Data', 'Biological Availability', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Discovery', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Electroencephalography', 'Environment', 'Extramural Activities', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'Health', 'Human', 'Intramural Research Program', 'Knowledge', 'Longevity', 'Machine Learning', 'Measures', 'Mental disorders', 'Mentors', 'Methods', 'Modeling', 'Neurodegenerative Disorders', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Participant', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Software Tools', 'Source', 'Space Models', 'Techniques', 'Training', 'United States National Institutes of Health', 'Universities', 'Visit', 'Wakefulness', 'Work', 'age related', 'aged', 'alertness', 'base', 'behavior measurement', 'big-data science', 'brain dysfunction', 'career', 'clinical database', 'cohort', 'data acquisition', 'dimensional analysis', 'experience', 'flexibility', 'healthy aging', 'high dimensionality', 'human data', 'imaging study', 'improved', 'indexing', 'innovation', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'nervous system disorder', 'neuroimaging', 'neuroimaging marker', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'rapid growth', 'recurrent neural network', 'relating to nervous system', 'specific biomarkers', 'statistical learning', 'statistics', 'symposium', 'tool', 'usability', 'visual tracking']",NIEHS,VANDERBILT UNIVERSITY,K22,2020,202463,0.1047015277899229
"Tracking brain arousal fluctuations for fMRI Big Data discovery Recent years have seen rapid growth in the availability of large, complex functional magnetic resonance imaging (fMRI) datasets of the human brain. However, the potential of this fMRI Big Data is presently limited by our understanding of the neural sources that contribute to fMRI signals. Fluctuations in arousal (i.e., in the level wakefulness and alertness) are known to modulate cognitive and behavioral processes and to display prominent alterations in neuropsychiatric disorders. Yet, since the vast majority of fMRI datasets lack neurophysiological or behavioral indices of arousal, fMRI Big Data cannot be readily harnessed to understand human brain arousal in health and disease. Recent data-driven approaches attempt to fill this gap but have limitations. The overall goal of this proposal is to increase the transformative potential of fMRI Big Data for human neuroscience through a novel analytic framework for detecting arousal fluctuations from fMRI data alone. We will accomplish this goal by developing and disseminating tools for modeling arousal fluctuations based on powerful statistical learning methods (Specific Aim 1). We will apply these models to large fMRI databases of healthy aging and Alzheimer’s Disease, both of which are associated with altered arousal (Specific Aims 2 and 3). We will capitalize on these databases to determine how knowledge of brain arousal fluctuations improves neuroimaging biomarkers of aging- and neurodegenerative disease-related changes in human brain function, and the extent to which arousal itself constitutes an informative biomarker of these states. This research would, moreover, increase the reliability and translational potential of fMRI studies more broadly by providing the ability to account for these major neural (arousal) state changes. These immediate research goals form a strong bridge with my long-term research objective of understanding principles of brain function by developing and innovatively adapting methods for the analysis of large and complex neuroimaging datasets. This objective is enabled by the mentored training plan, where I will (i) develop expertise in cutting-edge machine learning techniques and (ii) apply these techniques to multimodal neuroimaging data. The two co-mentors have complementary expertise that align, respectively, with these two training components. Aims 1 and 2 will span the mentored phase and part of the independent phase, while Aim 3 (application to the Alzheimer’s Disease Neuroimaging Initiative data) will be performed in the independent phase. The mentored environment of the NIH Intramural Research Program provides the resources for all planned data acquisition, as well as a rich community of neuroscience investigators and seminars. Interaction with the extramural (Columbia University) co-mentor will occur through frequent video conferences and several visits, with opportunities to engage with the Columbia data science community. Developing models of brain arousal fluctuations in fMRI data would contribute to our understanding of arousal mechanisms and its alteration with a variety of brain disorders, including Alzheimer’s Disease. Further, the ability to account for arousal fluctuations in fMRI data analysis would broadly improve the sensitivity of fMRI for neuroscience and clinical research, and may be critical for developing reliable, noninvasive biomarkers for diagnosis and treatment.",Tracking brain arousal fluctuations for fMRI Big Data discovery,9783829,K22ES028048,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Alzheimer’s disease biomarker', 'Arousal', 'Behavior', 'Behavioral', 'Big Data', 'Biological Availability', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Discovery', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Electroencephalography', 'Environment', 'Extramural Activities', 'Eye', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'Health', 'Human', 'Intramural Research Program', 'Knowledge', 'Longevity', 'Machine Learning', 'Measures', 'Mental disorders', 'Mentors', 'Methods', 'Modeling', 'Neurodegenerative Disorders', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Participant', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Software Tools', 'Source', 'Space Models', 'Techniques', 'Training', 'United States National Institutes of Health', 'Universities', 'Visit', 'Wakefulness', 'Work', 'age related', 'aged', 'alertness', 'base', 'behavior measurement', 'brain dysfunction', 'career', 'clinical database', 'cohort', 'data acquisition', 'dimensional analysis', 'experience', 'flexibility', 'healthy aging', 'high dimensionality', 'human data', 'imaging study', 'improved', 'indexing', 'innovation', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'nervous system disorder', 'neuroimaging', 'neuroimaging marker', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'rapid growth', 'recurrent neural network', 'relating to nervous system', 'specific biomarkers', 'statistics', 'symposium', 'tool', 'usability']",NIEHS,VANDERBILT UNIVERSITY,K22,2019,202477,0.1047015277899229
"Tracking brain arousal fluctuations for fMRI Big Data discovery Recent years have seen rapid growth in the availability of large, complex functional magnetic resonance imaging (fMRI) datasets of the human brain. However, the potential of this fMRI Big Data is presently limited by our understanding of the neural sources that contribute to fMRI signals. Fluctuations in arousal (i.e., in the level wakefulness and alertness) are known to modulate cognitive and behavioral processes and to display prominent alterations in neuropsychiatric disorders. Yet, since the vast majority of fMRI datasets lack neurophysiological or behavioral indices of arousal, fMRI Big Data cannot be readily harnessed to understand human brain arousal in health and disease. Recent data-driven approaches attempt to fill this gap but have limitations. The overall goal of this proposal is to increase the transformative potential of fMRI Big Data for human neuroscience through a novel analytic framework for detecting arousal fluctuations from fMRI data alone. We will accomplish this goal by developing and disseminating tools for modeling arousal fluctuations based on powerful statistical learning methods (Specific Aim 1). We will apply these models to large fMRI databases of healthy aging and Alzheimer’s Disease, both of which are associated with altered arousal (Specific Aims 2 and 3). We will capitalize on these databases to determine how knowledge of brain arousal fluctuations improves neuroimaging biomarkers of aging- and neurodegenerative disease-related changes in human brain function, and the extent to which arousal itself constitutes an informative biomarker of these states. This research would, moreover, increase the reliability and translational potential of fMRI studies more broadly by providing the ability to account for these major neural (arousal) state changes. These immediate research goals form a strong bridge with my long-term research objective of understanding principles of brain function by developing and innovatively adapting methods for the analysis of large and complex neuroimaging datasets. This objective is enabled by the mentored training plan, where I will (i) develop expertise in cutting-edge machine learning techniques and (ii) apply these techniques to multimodal neuroimaging data. The two co-mentors have complementary expertise that align, respectively, with these two training components. Aims 1 and 2 will span the mentored phase and part of the independent phase, while Aim 3 (application to the Alzheimer’s Disease Neuroimaging Initiative data) will be performed in the independent phase. The mentored environment of the NIH Intramural Research Program provides the resources for all planned data acquisition, as well as a rich community of neuroscience investigators and seminars. Interaction with the extramural (Columbia University) co-mentor will occur through frequent video conferences and several visits, with opportunities to engage with the Columbia data science community. Developing models of brain arousal fluctuations in fMRI data would contribute to our understanding of arousal mechanisms and its alteration with a variety of brain disorders, including Alzheimer’s Disease. Further, the ability to account for arousal fluctuations in fMRI data analysis would broadly improve the sensitivity of fMRI for neuroscience and clinical research, and may be critical for developing reliable, noninvasive biomarkers for diagnosis and treatment.",Tracking brain arousal fluctuations for fMRI Big Data discovery,9774474,K22ES028048,"['Address', 'Advanced Development', 'Aging', 'Alzheimer&apos', 's Disease', 'Arousal', 'Behavior', 'Behavioral', 'Big Data', 'Biological Availability', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Clinical Research', 'Cognitive', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Discovery', 'Data Science', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Dimensions', 'Disease', 'Disease Progression', 'Electroencephalography', 'Environment', 'Extramural Activities', 'Eye', 'Functional Magnetic Resonance Imaging', 'Goals', 'Growth', 'Health', 'Human', 'Intramural Research Program', 'Knowledge', 'Longevity', 'Machine Learning', 'Measures', 'Mental disorders', 'Mentors', 'Methods', 'Modeling', 'Neurodegenerative Disorders', 'Neurosciences', 'Neurosciences Research', 'Outcome', 'Participant', 'Phase', 'Physiologic Monitoring', 'Physiological', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Software Tools', 'Source', 'Space Models', 'Techniques', 'Training', 'United States National Institutes of Health', 'Universities', 'Visit', 'Wakefulness', 'Work', 'age related', 'aged', 'alertness', 'base', 'behavior measurement', 'biomarker development', 'brain dysfunction', 'career', 'cohort', 'data acquisition', 'dimensional analysis', 'experience', 'flexibility', 'healthy aging', 'high dimensionality', 'human data', 'imaging study', 'improved', 'indexing', 'innovation', 'learning strategy', 'mild cognitive impairment', 'multimodality', 'nervous system disorder', 'neuroimaging', 'neuroimaging marker', 'neurophysiology', 'neuropsychiatric disorder', 'novel', 'rapid growth', 'recurrent neural network', 'relating to nervous system', 'specific biomarkers', 'statistics', 'symposium', 'tool', 'usability']",NIEHS,VANDERBILT UNIVERSITY,K22,2018,200616,0.1047015277899229
"A hybrid artificial intelligence framework for glaucoma monitoring Glaucoma is a complex neurodegenerative disease that results in degeneration of retinal ganglion cells and their axons. With older people making up the fastest growing part of the US population, glaucoma will become even more prevalent in the US in the coming decades. Due to the complex interaction of multiple factors in glaucoma, better structural and functional predictors are needed for its progression. The main impediments are massive health record data and sophisticated computational models. Our overall goal is to leverage the power of big data and rapidly evolving machine learning approaches. The NEI's “Big Data to Knowledge (BD2K)” initiative and the American Academy of Ophthalmology Intelligent Research in Sight (IRIS) registry are all efforts to exploit the power of data and to better understand diseases and to provide improved prevention and treatment.  In this multi-PI proposal, we offer to assemble over 1 million optical coherence tomography (OCT) and visual fields (VFs) from the glaucoma research network (GRN). We propose to develop a hybrid artificial intelligence (AI) algorithm that synthesizes Gaussian mixture model expectation maximization (GEM) and archetypal machine learning approach to identify glaucoma progression and its monitoring using VFs and retinal nerve fiber layer (RNFL) thickness measurements. We will make these tools openly available to the vision and ophthalmology research communities.  Our proposed studies could offer substantial improvements in the prognosis of glaucoma as well as potentially providing OCT and joint VF/OCT surrogate endpoints to be used in glaucoma clinical trials. Leveraging big data in eye care is challenging. This study uses big functional and structural glaucoma data and develops hybrid machine learning models to identify glaucoma progression and its monitoring. Results could offer substantial improvements in prognosis of glaucoma and may provide surrogate endpoints for use in glaucoma clinical trials.",A hybrid artificial intelligence framework for glaucoma monitoring,9892013,R21EY030142,"['Academy', 'Address', 'American', 'Artificial Intelligence', 'Axon', 'Bayesian Modeling', 'Big Data', 'Big Data to Knowledge', 'Blindness', 'Caring', 'Clinical', 'Clinical Trials', 'Communities', 'Complex', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Detection', 'Devices', 'Disease', 'Disease Progression', 'Evolution', 'Eye', 'Gaussian model', 'Glaucoma', 'Goals', 'Hybrids', 'Institutes', 'Intelligence', 'Joints', 'Judgment', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Neurodegenerative Disorders', 'Ophthalmology', 'Optic Nerve', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Pattern', 'Population', 'Prevention', 'Public Health', 'Registries', 'Research', 'Retina', 'Severity of illness', 'Source', 'Structural Models', 'Structure', 'Surrogate Endpoint', 'Testing', 'Thick', 'Thinness', 'Time', 'Training', 'Vision', 'Visual Fields', 'analytical method', 'archetypal analysis', 'clinical Diagnosis', 'data space', 'design', 'diagnostic accuracy', 'early onset', 'evidence base', 'expectation', 'field study', 'health record', 'high dimensionality', 'improved', 'intelligent algorithm', 'machine learning algorithm', 'multidimensional data', 'novel', 'open source', 'optical imaging', 'outcome forecast', 'programs', 'retinal ganglion cell degeneration', 'retinal nerve fiber layer', 'tool']",NEI,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R21,2020,220808,0.16850213005082879
"A hybrid artificial intelligence framework for glaucoma monitoring Glaucoma is a complex neurodegenerative disease that results in degeneration of retinal ganglion cells and their axons. With older people making up the fastest growing part of the US population, glaucoma will become even more prevalent in the US in the coming decades. Due to the complex interaction of multiple factors in glaucoma, better structural and functional predictors are needed for its progression. The main impediments are massive health record data and sophisticated computational models. Our overall goal is to leverage the power of big data and rapidly evolving machine learning approaches. The NEI's “Big Data to Knowledge (BD2K)” initiative and the American Academy of Ophthalmology Intelligent Research in Sight (IRIS) registry are all efforts to exploit the power of data and to better understand diseases and to provide improved prevention and treatment.  In this multi-PI proposal, we offer to assemble over 1 million optical coherence tomography (OCT) and visual fields (VFs) from the glaucoma research network (GRN). We propose to develop a hybrid artificial intelligence (AI) algorithm that synthesizes Gaussian mixture model expectation maximization (GEM) and archetypal machine learning approach to identify glaucoma progression and its monitoring using VFs and retinal nerve fiber layer (RNFL) thickness measurements. We will make these tools openly available to the vision and ophthalmology research communities.  Our proposed studies could offer substantial improvements in the prognosis of glaucoma as well as potentially providing OCT and joint VF/OCT surrogate endpoints to be used in glaucoma clinical trials. Leveraging big data in eye care is challenging. This study uses big functional and structural glaucoma data and develops hybrid machine learning models to identify glaucoma progression and its monitoring. Results could offer substantial improvements in prognosis of glaucoma and may provide surrogate endpoints for use in glaucoma clinical trials.",A hybrid artificial intelligence framework for glaucoma monitoring,9723609,R21EY030142,"['Academy', 'Address', 'Algorithms', 'American', 'Artificial Intelligence', 'Axon', 'Bayesian Modeling', 'Big Data', 'Big Data to Knowledge', 'Blindness', 'Caring', 'Clinical', 'Clinical Trials', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Detection', 'Devices', 'Disease', 'Disease Progression', 'Evolution', 'Eye', 'Gaussian model', 'Glaucoma', 'Goals', 'Hybrids', 'Institutes', 'Intelligence', 'Joints', 'Judgment', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Neurodegenerative Disorders', 'Ophthalmology', 'Optic Nerve', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Pattern', 'Population', 'Prevention', 'Public Health', 'Registries', 'Research', 'Retinal', 'Severity of illness', 'Source', 'Structural Models', 'Structure', 'Surrogate Endpoint', 'Testing', 'Thick', 'Thinness', 'Time', 'Training', 'Vision', 'Visual Fields', 'analytical method', 'clinical Diagnosis', 'data space', 'design', 'diagnostic accuracy', 'early onset', 'evidence base', 'expectation', 'field study', 'health record', 'high dimensionality', 'improved', 'machine learning algorithm', 'multidimensional data', 'novel', 'open source', 'optical imaging', 'outcome forecast', 'programs', 'retinal ganglion cell degeneration', 'retinal nerve fiber layer', 'tool']",NEI,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,R21,2019,278421,0.16850213005082879
"Multidimensional MRI-based Big Data Analytics to Study Osteoarthritis ABSTRACT This project outlines technical medical image processing and machine learning developments to study the pathogenesis and natural history of osteoarthritis (OA). In the past few years, the availability of public datasets that collect data such as plain radiographs, MRI genomics and patients reported outcomes has allowed the study of disease etiology, potential treatment pathways and predictors of long-range outcomes, showing an increasingly important role of the MRI. Moreover, recent advances in quantitative MRI and medical image processing allow for the extraction of extraordinarily rich arrays of heterogeneous information on the musculoskeletal system, including cartilage and bone morphology, bone shape features, biomechanics, and cartilage biochemical composition.  Osteoarthritis, being a polygenic and multifactorial disease characterized by several phenotypes, seems the perfect candidate for multidimensional analysis and precision medicine. However, accomplish this ambitious task, will require complex analytics and multifactorial data-integration from diverse assessments spanning morphological, biochemical, and biomechanical features. In this project, we propose to fill this gap developing automatic post-processing algorithms to examine cartilage biochemical compositional and morphological features and to apply new multidimensional machine learning to study OA  This “Pathway to Independence” award application includes a mentored career development plan to transition the candidate, Dr. Valentina Pedoia, into an independent investigator position, as well as an accompanying research plan describing the proposed technical developments for the application of big data analytics to the study of OA. The primary mentor, Dr. Sharmila Majumdar, is a leading expert in the field of quantitative MRI for the study of OA, and the co-mentors, Dr. Adam Ferguson and Dr. Ramakrishna Akella, have extensive experience in the application of machine learning and topological data analysis to big data. The diversified plan of training and the complementary background of these mentors will allow the candidate to develop a unique interdisciplinary profile in the field of musculoskeletal imaging.  The candidate, Dr. Valentina Pedoia, is currently in a post-doctoral level position (Associated Specialist) at the University of California at San Francisco (UCSF), developing MR image post-processing algorithms. The mentoring and career development plan will supplement her image processing background with valuable exposure to machine learning, big data analysis, epidemiological study design, and interdisciplinary collaboration to facilitate her transition to a medical imaging and data scientist independent investigator position. Ultimately, she aims to become a faculty member in a radiology or bioengineering institute, where she can further research technical biomedical imaging and machine learning developments applied to the musculoskeletal system. PROJECT NARRATIVE Morphological and compositional MRI quantifications are widely used tools to detect early cartilage degeneration and to study disease progression of osteoarthritis, a complex and multifactorial disorder. In this project, we propose to develop a fully automatic image post-processing pipeline and multidimensional big data analyses based on machine learning techniques, with the aim to uncover latent information from complex dataset and with the ultimate goal of setting up a platform for OA precision medicine",Multidimensional MRI-based Big Data Analytics to Study Osteoarthritis,9385849,K99AR070902,"['Algorithms', 'Atlases', 'Award', 'Big Data', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Biomedical Engineering', 'California', 'Cartilage', 'Chronology', 'Clinical', 'Complex', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Development Plans', 'Diagnostic radiologic examination', 'Dimensions', 'Discipline', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elements', 'Etiology', 'Event', 'Exposure to', 'Faculty', 'Gait', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imagery', 'Institutes', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Learning', 'Lesion', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medical Imaging', 'Mentors', 'Modeling', 'Morphology', 'Musculoskeletal System', 'Natural History', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patient Outcomes Assessments', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Radiology Specialty', 'Relaxation', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Role', 'San Francisco', 'Scanning', 'Sex Characteristics', 'Shapes', 'Source', 'Specialist', 'Statistical Data Interpretation', 'Symptoms', 'Syndrome', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Variant', 'arthropathies', 'base', 'bioimaging', 'bone', 'career development', 'cartilage degradation', 'connectome', 'data integration', 'design', 'epidemiology study', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging biomarker', 'imaging scientist', 'interdisciplinary collaboration', 'kinematics', 'member', 'modifiable risk', 'morphometry', 'musculoskeletal imaging', 'parallel processing', 'precision medicine', 'quantitative imaging', 'racial difference', 'repository', 'shape analysis', 'soft tissue', 'three-dimensional modeling', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K99,2017,94041,0.24235249442019938
"Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis ABSTRACT This project outlines technical medical image processing and machine learning developments to study the pathogenesis and natural history of osteoarthritis (OA). In the past few years, the availability of public datasets that collect data such as plain radiographs, MRI genomics and patients reported outcomes has allowed the study of disease etiology, potential treatment pathways and predictors of long-range outcomes, showing an increasingly important role of the MRI. Moreover, recent advances in quantitative MRI and medical image processing allow for the extraction of extraordinarily rich arrays of heterogeneous information on the musculoskeletal system, including cartilage and bone morphology, bone shape features, biomechanics, and cartilage biochemical composition.  Osteoarthritis, being a polygenic and multifactorial disease characterized by several phenotypes, seems the perfect candidate for multidimensional analysis and precision medicine. However, accomplish this ambitious task, will require complex analytics and multifactorial data-integration from diverse assessments spanning morphological, biochemical, and biomechanical features. In this project, we propose to fill this gap developing automatic post-processing algorithms to examine cartilage biochemical compositional and morphological features and to apply new multidimensional machine learning to study OA  This “Pathway to Independence” award application includes a mentored career development plan to transition the candidate, Dr. Valentina Pedoia, into an independent investigator position, as well as an accompanying research plan describing the proposed technical developments for the application of big data analytics to the study of OA. The primary mentor, Dr. Sharmila Majumdar, is a leading expert in the field of quantitative MRI for the study of OA, and the co-mentors, Dr. Adam Ferguson and Dr. Ramakrishna Akella, have extensive experience in the application of machine learning and topological data analysis to big data. The diversified plan of training and the complementary background of these mentors will allow the candidate to develop a unique interdisciplinary profile in the field of musculoskeletal imaging.  The candidate, Dr. Valentina Pedoia, is currently in a post-doctoral level position (Associated Specialist) at the University of California at San Francisco (UCSF), developing MR image post-processing algorithms. The mentoring and career development plan will supplement her image processing background with valuable exposure to machine learning, big data analysis, epidemiological study design, and interdisciplinary collaboration to facilitate her transition to a medical imaging and data scientist independent investigator position. Ultimately, she aims to become a faculty member in a radiology or bioengineering institute, where she can further research technical biomedical imaging and machine learning developments applied to the musculoskeletal system. PROJECT NARRATIVE Morphological and compositional MRI quantifications are widely used tools to detect early cartilage degeneration and to study disease progression of osteoarthritis, a complex and multifactorial disorder. In this project, we propose to develop a fully automatic image post-processing pipeline and multidimensional big data analyses based on machine learning techniques, with the aim to uncover latent information from complex dataset and with the ultimate goal of setting up a platform for OA precision medicine",Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis,9934128,R00AR070902,"['3-Dimensional', 'Algorithms', 'Atlases', 'Award', 'Big Data', 'Big Data Methods', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Biomedical Engineering', 'California', 'Cartilage', 'Chronology', 'Clinical', 'Complex', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Scientist', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Development Plans', 'Diagnostic radiologic examination', 'Dimensions', 'Discipline', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elements', 'Etiology', 'Event', 'Exposure to', 'Faculty', 'Gait', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Institutes', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medical Imaging', 'Mentors', 'Modeling', 'Morphology', 'Musculoskeletal System', 'Natural History', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patient Outcomes Assessments', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Radiology Specialty', 'Relaxation', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Role', 'San Francisco', 'Scanning', 'Sex Differences', 'Shapes', 'Source', 'Specialist', 'Statistical Data Interpretation', 'Symptoms', 'Syndrome', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Variant', 'Visualization', 'algorithm development', 'arthropathies', 'base', 'bioimaging', 'bone', 'career development', 'cartilage degradation', 'connectome', 'data integration', 'deep learning', 'design', 'epidemiology study', 'experience', 'feature extraction', 'heterogenous data', 'image processing', 'image registration', 'imaging Segmentation', 'imaging biomarker', 'imaging scientist', 'interdisciplinary collaboration', 'kinematics', 'member', 'modifiable risk', 'morphometry', 'multidimensional data', 'musculoskeletal imaging', 'parallel processing', 'precision medicine', 'quantitative imaging', 'racial difference', 'repository', 'shape analysis', 'soft tissue', 'three-dimensional modeling', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R00,2020,249000,0.19927937770702295
"Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis ABSTRACT This project outlines technical medical image processing and machine learning developments to study the pathogenesis and natural history of osteoarthritis (OA). In the past few years, the availability of public datasets that collect data such as plain radiographs, MRI genomics and patients reported outcomes has allowed the study of disease etiology, potential treatment pathways and predictors of long-range outcomes, showing an increasingly important role of the MRI. Moreover, recent advances in quantitative MRI and medical image processing allow for the extraction of extraordinarily rich arrays of heterogeneous information on the musculoskeletal system, including cartilage and bone morphology, bone shape features, biomechanics, and cartilage biochemical composition.  Osteoarthritis, being a polygenic and multifactorial disease characterized by several phenotypes, seems the perfect candidate for multidimensional analysis and precision medicine. However, accomplish this ambitious task, will require complex analytics and multifactorial data-integration from diverse assessments spanning morphological, biochemical, and biomechanical features. In this project, we propose to fill this gap developing automatic post-processing algorithms to examine cartilage biochemical compositional and morphological features and to apply new multidimensional machine learning to study OA  This “Pathway to Independence” award application includes a mentored career development plan to transition the candidate, Dr. Valentina Pedoia, into an independent investigator position, as well as an accompanying research plan describing the proposed technical developments for the application of big data analytics to the study of OA. The primary mentor, Dr. Sharmila Majumdar, is a leading expert in the field of quantitative MRI for the study of OA, and the co-mentors, Dr. Adam Ferguson and Dr. Ramakrishna Akella, have extensive experience in the application of machine learning and topological data analysis to big data. The diversified plan of training and the complementary background of these mentors will allow the candidate to develop a unique interdisciplinary profile in the field of musculoskeletal imaging.  The candidate, Dr. Valentina Pedoia, is currently in a post-doctoral level position (Associated Specialist) at the University of California at San Francisco (UCSF), developing MR image post-processing algorithms. The mentoring and career development plan will supplement her image processing background with valuable exposure to machine learning, big data analysis, epidemiological study design, and interdisciplinary collaboration to facilitate her transition to a medical imaging and data scientist independent investigator position. Ultimately, she aims to become a faculty member in a radiology or bioengineering institute, where she can further research technical biomedical imaging and machine learning developments applied to the musculoskeletal system. PROJECT NARRATIVE Morphological and compositional MRI quantifications are widely used tools to detect early cartilage degeneration and to study disease progression of osteoarthritis, a complex and multifactorial disorder. In this project, we propose to develop a fully automatic image post-processing pipeline and multidimensional big data analyses based on machine learning techniques, with the aim to uncover latent information from complex dataset and with the ultimate goal of setting up a platform for OA precision medicine",Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis,9742424,R00AR070902,"['3-Dimensional', 'Algorithms', 'Atlases', 'Award', 'Big Data', 'Big Data Methods', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Biomedical Engineering', 'California', 'Cartilage', 'Chronology', 'Clinical', 'Complex', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Scientist', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Development Plans', 'Diagnostic radiologic examination', 'Dimensions', 'Discipline', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elements', 'Etiology', 'Event', 'Exposure to', 'Faculty', 'Gait', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imagery', 'Institutes', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medical Imaging', 'Mentors', 'Modeling', 'Morphology', 'Musculoskeletal System', 'Natural History', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patient Outcomes Assessments', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Radiology Specialty', 'Relaxation', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Role', 'San Francisco', 'Scanning', 'Sex Differences', 'Shapes', 'Source', 'Specialist', 'Statistical Data Interpretation', 'Symptoms', 'Syndrome', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Variant', 'arthropathies', 'base', 'bioimaging', 'bone', 'career development', 'cartilage degradation', 'connectome', 'data integration', 'deep learning', 'design', 'epidemiology study', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging biomarker', 'imaging scientist', 'interdisciplinary collaboration', 'kinematics', 'member', 'modifiable risk', 'morphometry', 'multidimensional data', 'musculoskeletal imaging', 'parallel processing', 'precision medicine', 'quantitative imaging', 'racial difference', 'repository', 'shape analysis', 'soft tissue', 'three-dimensional modeling', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R00,2019,249000,0.19927937770702295
"Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis ABSTRACT This project outlines technical medical image processing and machine learning developments to study the pathogenesis and natural history of osteoarthritis (OA). In the past few years, the availability of public datasets that collect data such as plain radiographs, MRI genomics and patients reported outcomes has allowed the study of disease etiology, potential treatment pathways and predictors of long-range outcomes, showing an increasingly important role of the MRI. Moreover, recent advances in quantitative MRI and medical image processing allow for the extraction of extraordinarily rich arrays of heterogeneous information on the musculoskeletal system, including cartilage and bone morphology, bone shape features, biomechanics, and cartilage biochemical composition.  Osteoarthritis, being a polygenic and multifactorial disease characterized by several phenotypes, seems the perfect candidate for multidimensional analysis and precision medicine. However, accomplish this ambitious task, will require complex analytics and multifactorial data-integration from diverse assessments spanning morphological, biochemical, and biomechanical features. In this project, we propose to fill this gap developing automatic post-processing algorithms to examine cartilage biochemical compositional and morphological features and to apply new multidimensional machine learning to study OA  This “Pathway to Independence” award application includes a mentored career development plan to transition the candidate, Dr. Valentina Pedoia, into an independent investigator position, as well as an accompanying research plan describing the proposed technical developments for the application of big data analytics to the study of OA. The primary mentor, Dr. Sharmila Majumdar, is a leading expert in the field of quantitative MRI for the study of OA, and the co-mentors, Dr. Adam Ferguson and Dr. Ramakrishna Akella, have extensive experience in the application of machine learning and topological data analysis to big data. The diversified plan of training and the complementary background of these mentors will allow the candidate to develop a unique interdisciplinary profile in the field of musculoskeletal imaging.  The candidate, Dr. Valentina Pedoia, is currently in a post-doctoral level position (Associated Specialist) at the University of California at San Francisco (UCSF), developing MR image post-processing algorithms. The mentoring and career development plan will supplement her image processing background with valuable exposure to machine learning, big data analysis, epidemiological study design, and interdisciplinary collaboration to facilitate her transition to a medical imaging and data scientist independent investigator position. Ultimately, she aims to become a faculty member in a radiology or bioengineering institute, where she can further research technical biomedical imaging and machine learning developments applied to the musculoskeletal system. PROJECT NARRATIVE Morphological and compositional MRI quantifications are widely used tools to detect early cartilage degeneration and to study disease progression of osteoarthritis, a complex and multifactorial disorder. In this project, we propose to develop a fully automatic image post-processing pipeline and multidimensional big data analyses based on machine learning techniques, with the aim to uncover latent information from complex dataset and with the ultimate goal of setting up a platform for OA precision medicine",Multidimensional MRI-based Non-Euclidean Deep Learning to Study Osteoarthritis,9723310,R00AR070902,"['Algorithms', 'Atlases', 'Award', 'Big Data', 'Biochemical', 'Biochemistry', 'Biomechanics', 'Biomedical Engineering', 'California', 'Cartilage', 'Chronology', 'Clinical', 'Complex', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Degenerative polyarthritis', 'Development', 'Development Plans', 'Diagnostic radiologic examination', 'Dimensions', 'Discipline', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Elements', 'Etiology', 'Event', 'Exposure to', 'Faculty', 'Gait', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imagery', 'Institutes', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lesion', 'Longitudinal Studies', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Medical', 'Medical Imaging', 'Mentors', 'Modeling', 'Morphology', 'Musculoskeletal System', 'Natural History', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Patient Outcomes Assessments', 'Phase', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Radiology Specialty', 'Relaxation', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Role', 'San Francisco', 'Scanning', 'Sex Characteristics', 'Shapes', 'Source', 'Specialist', 'Statistical Data Interpretation', 'Symptoms', 'Syndrome', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Variant', 'arthropathies', 'base', 'bioimaging', 'bone', 'career development', 'cartilage degradation', 'connectome', 'data integration', 'deep learning', 'design', 'epidemiology study', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging biomarker', 'imaging scientist', 'interdisciplinary collaboration', 'kinematics', 'member', 'modifiable risk', 'morphometry', 'musculoskeletal imaging', 'parallel processing', 'precision medicine', 'quantitative imaging', 'racial difference', 'repository', 'shape analysis', 'soft tissue', 'three-dimensional modeling', 'tool']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R00,2018,249000,0.19927937770702295
"Statistical Methods for Ultrahigh-dimensional Biomedical Data This proposal develops novel statistics and machine learning methods for distributed analysis of big data in biomedical studies and precision medicine and for selecting a small group of molecules that are associated with biological and clinical outcomes from high-throughput data such as microarray, proteomic, and next generation sequence from biomedical research, especially for autism studies and Alzheimer’s disease research. It focuses on developing efficient distributed statistical methods for Big Data computing, storage, and communication, and for solving distributed health data collected at different locations that are hard to aggregate in meta-analysis due to privacy and ownership concerns. It develops both computationally and statistically efficient methods and valid statistical tools for exploring heterogeneity of big data in precision medicine, for studying associations of genomics and genetic information with clinical and biological outcomes, and for feature selection and model building in presence of errors-in- variables, endogeneity, and heavy-tail error distributions, and for predicting clinical outcomes and understanding molecular mechanisms. It introduces more robust and powerful statistical tests for selection of significant genes, SNPs, and proteins in presence of dependence of data, valid control of false discovery rate for dependent test statistics, and evaluation of treatment effects on a group of molecules. The strength and weakness of each proposed method will be critically analyzed via theoretical investigations and simulation studies. Related software will be developed for free dissemination. Data sets from ongoing autism research, Alzheimer’s disease, and other biomedical studies will be analyzed by using the newly developed methods and the results will be further biologically confirmed and investigated. The research findings will have strong impact on statistical analysis of high throughput big data for biomedical research and on understanding heterogeneity for precision medicine and molecular mechanisms of autism, Alzheimer’s disease, and other diseases. This proposal develops novel statistical machine learning methods and bioinformatic tools for finding genes, proteins, and SNPs that are associated with clinical outcomes and discovering heterogeneity for precision medicine. Data sets from ongoing autism research, Alzheimer’s disease and other biomedical studies will be critically analyzed using the newly developed statistical methods, and the results will be further biologically confirmed and investigated. The research findings will have strong impact on developing therapeutic targets and understanding heterogeneity for precision and molecular mechanisms of autism, Alzheimer’s diseases, and other diseases. !",Statistical Methods for Ultrahigh-dimensional Biomedical Data,9448918,R01GM072611,"['Address', 'Alzheimer&apos', 's Disease', 'Autistic Disorder', 'Big Data', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Classification', 'Clinical', 'Communication', 'Computer software', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Databases', 'Dependence', 'Dimensions', 'Disease', 'Disease Progression', 'Evaluation', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genomics', 'Heterogeneity', 'Internet', 'Investigation', 'Learning', 'Linear Models', 'Location', 'Machine Learning', 'Meta-Analysis', 'Methods', 'Molecular', 'Outcome', 'Ownership', 'Patients', 'Polynomial Models', 'Principal Component Analysis', 'Privacy', 'Proteins', 'Proteomics', 'Research', 'Role', 'Statistical Data Interpretation', 'Statistical Methods', 'Tail', 'Techniques', 'Testing', 'Time', 'big biomedical data', 'cell type', 'computing resources', 'genetic information', 'health data', 'high dimensionality', 'high throughput analysis', 'improved', 'learning strategy', 'macrophage', 'model building', 'next generation', 'novel', 'precision medicine', 'predict clinical outcome', 'simulation', 'statistics', 'therapeutic target', 'tool', 'transcriptome sequencing', 'treatment effect']",NIGMS,PRINCETON UNIVERSITY,R01,2018,308503,0.09664396252042674
"Statistical Methods for Ultrahigh-dimensional Biomedical Data This proposal develops novel statistics and machine learning methods for distributed analysis of big data in biomedical studies and precision medicine and for selecting a small group of molecules that are associated with biological and clinical outcomes from high-throughput data such as microarray, proteomic, and next generation sequence from biomedical research, especially for autism studies and Alzheimer’s disease research. It focuses on developing efficient distributed statistical methods for Big Data computing, storage, and communication, and for solving distributed health data collected at different locations that are hard to aggregate in meta-analysis due to privacy and ownership concerns. It develops both computationally and statistically efficient methods and valid statistical tools for exploring heterogeneity of big data in precision medicine, for studying associations of genomics and genetic information with clinical and biological outcomes, and for feature selection and model building in presence of errors-in- variables, endogeneity, and heavy-tail error distributions, and for predicting clinical outcomes and understanding molecular mechanisms. It introduces more robust and powerful statistical tests for selection of significant genes, SNPs, and proteins in presence of dependence of data, valid control of false discovery rate for dependent test statistics, and evaluation of treatment effects on a group of molecules. The strength and weakness of each proposed method will be critically analyzed via theoretical investigations and simulation studies. Related software will be developed for free dissemination. Data sets from ongoing autism research, Alzheimer’s disease, and other biomedical studies will be analyzed by using the newly developed methods and the results will be further biologically confirmed and investigated. The research findings will have strong impact on statistical analysis of high throughput big data for biomedical research and on understanding heterogeneity for precision medicine and molecular mechanisms of autism, Alzheimer’s disease, and other diseases. This proposal develops novel statistical machine learning methods and bioinformatic tools for finding genes, proteins, and SNPs that are associated with clinical outcomes and discovering heterogeneity for precision medicine. Data sets from ongoing autism research, Alzheimer’s disease and other biomedical studies will be critically analyzed using the newly developed statistical methods, and the results will be further biologically confirmed and investigated. The research findings will have strong impact on developing therapeutic targets and understanding heterogeneity for precision and molecular mechanisms of autism, Alzheimer’s diseases, and other diseases. !",Statistical Methods for Ultrahigh-dimensional Biomedical Data,9900790,R01GM072611,"['Address', 'Alzheimer&apos', 's Disease', 'Big Data', 'Big Data Methods', 'Biological', 'Biomedical Research', 'Brain', 'Classification', 'Clinical', 'Communication', 'Computer software', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Databases', 'Dependence', 'Dimensions', 'Disease', 'Disease Progression', 'Evaluation', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genomics', 'Heterogeneity', 'Internet', 'Investigation', 'Learning', 'Linear Models', 'Location', 'Meta-Analysis', 'Methods', 'Molecular', 'Outcome', 'Ownership', 'Patients', 'Polynomial Models', 'Principal Component Analysis', 'Privacy', 'Proteins', 'Proteomics', 'Research', 'Role', 'Statistical Data Interpretation', 'Statistical Methods', 'Tail', 'Techniques', 'Testing', 'Time', 'autism spectrum disorder', 'big biomedical data', 'bioinformatics tool', 'cell type', 'computing resources', 'feature selection', 'genetic information', 'health data', 'high dimensionality', 'high throughput analysis', 'improved', 'machine learning method', 'macrophage', 'model building', 'next generation', 'novel', 'precision medicine', 'predict clinical outcome', 'simulation', 'statistical and machine learning', 'statistics', 'therapeutic target', 'tool', 'transcriptome sequencing', 'treatment effect']",NIGMS,PRINCETON UNIVERSITY,R01,2020,293003,0.09664396252042674
"Statistical Methods for Ultrahigh-dimensional Biomedical Data This proposal develops novel statistics and machine learning methods for distributed analysis of big data in biomedical studies and precision medicine and for selecting a small group of molecules that are associated with biological and clinical outcomes from high-throughput data such as microarray, proteomic, and next generation sequence from biomedical research, especially for autism studies and Alzheimer’s disease research. It focuses on developing efficient distributed statistical methods for Big Data computing, storage, and communication, and for solving distributed health data collected at different locations that are hard to aggregate in meta-analysis due to privacy and ownership concerns. It develops both computationally and statistically efficient methods and valid statistical tools for exploring heterogeneity of big data in precision medicine, for studying associations of genomics and genetic information with clinical and biological outcomes, and for feature selection and model building in presence of errors-in- variables, endogeneity, and heavy-tail error distributions, and for predicting clinical outcomes and understanding molecular mechanisms. It introduces more robust and powerful statistical tests for selection of significant genes, SNPs, and proteins in presence of dependence of data, valid control of false discovery rate for dependent test statistics, and evaluation of treatment effects on a group of molecules. The strength and weakness of each proposed method will be critically analyzed via theoretical investigations and simulation studies. Related software will be developed for free dissemination. Data sets from ongoing autism research, Alzheimer’s disease, and other biomedical studies will be analyzed by using the newly developed methods and the results will be further biologically confirmed and investigated. The research findings will have strong impact on statistical analysis of high throughput big data for biomedical research and on understanding heterogeneity for precision medicine and molecular mechanisms of autism, Alzheimer’s disease, and other diseases. This proposal develops novel statistical machine learning methods and bioinformatic tools for finding genes, proteins, and SNPs that are associated with clinical outcomes and discovering heterogeneity for precision medicine. Data sets from ongoing autism research, Alzheimer’s disease and other biomedical studies will be critically analyzed using the newly developed statistical methods, and the results will be further biologically confirmed and investigated. The research findings will have strong impact on developing therapeutic targets and understanding heterogeneity for precision and molecular mechanisms of autism, Alzheimer’s diseases, and other diseases. !",Statistical Methods for Ultrahigh-dimensional Biomedical Data,9634069,R01GM072611,"['Address', 'Alzheimer&apos', 's Disease', 'Big Data', 'Big Data Methods', 'Biological', 'Biomedical Research', 'Brain', 'Classification', 'Clinical', 'Communication', 'Computer software', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Databases', 'Dependence', 'Dimensions', 'Disease', 'Disease Progression', 'Evaluation', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genomics', 'Heterogeneity', 'Internet', 'Investigation', 'Learning', 'Linear Models', 'Location', 'Machine Learning', 'Meta-Analysis', 'Methods', 'Molecular', 'Outcome', 'Ownership', 'Patients', 'Polynomial Models', 'Principal Component Analysis', 'Privacy', 'Proteins', 'Proteomics', 'Research', 'Role', 'Statistical Data Interpretation', 'Statistical Methods', 'Tail', 'Techniques', 'Testing', 'Time', 'autism spectrum disorder', 'big biomedical data', 'bioinformatics tool', 'cell type', 'computing resources', 'genetic information', 'health data', 'high dimensionality', 'high throughput analysis', 'improved', 'learning strategy', 'macrophage', 'model building', 'next generation', 'novel', 'precision medicine', 'predict clinical outcome', 'simulation', 'statistics', 'therapeutic target', 'tool', 'transcriptome sequencing', 'treatment effect']",NIGMS,PRINCETON UNIVERSITY,R01,2019,293003,0.09664396252042674
"ORS-ISFR 17th Biennial Conference: Thinking big on fracture repair Abstract Bone fractures occur in more than 25 million Americans per year, and a significant percentage of those fractures fail to heal. Fractures that show delayed or failed progression to heal account for the majority of patient disability and costs. Thus, there is an urgent need to better understand the biology of bone healing, and to use that knowledge to develop new diagnostics and therapeutics. We are seeking support for the 17th Biennial conference of the International Section of Fracture Repair (ISFR). The ISFR recently became incorporated as a section within the Orthopaedic Research Society (ORS) thereby leveraging the outreach of the largest scientific organization in the world dedicated to orthopaedic research. The ISFR is dedicated to the advancement and exchange of the most current scientific ideas and research findings on fracture repair and its application to the improvement of patient care. Our mission is be the premier forum to integrate and present cutting-edge ideas related to clinical, translational, and basic science research of fracture healing. The central theme for this conference is “Thinking Big”. We will present the use of -omics approaches to solve the most significant research problems in the field and large-scale data management and advanced computational approaches to solve intractable clinical concerns. The meeting is organized around seven scientific sessions, and also includes an embedded symposium conducted with the Orthopaedic Trauma Association (OTA) focused on non-unions and a collaborative session on proximal humeral fractures conducted with the Bone and Joint Institute of the University of Western Ontario (BJI). The scientific sessions will each have a series of speakers, selected from submitted abstracts, and each will have an eminent keynote invited speaker. The sessions include: Stem Cells in Fracture; Artificial Intelligence, Machine Learning and Big data; Fracture induced pain management; Fracture repair basic research; Fracture repair clinical perspectives; Bone repair with polytrauma; and Outcomes. There will also be a short session for poster oral presentations (poster teasers), a session on how to communicate science, a practicum on data management, and an ORS Presidential Guest Speaker. Following the ISFR 17th biennial conference there will be an associated ISFR/BJI consensus workshop, which will develop a consensus white-paper on the best evidence-based treatment for proximal humeral fractures. The meeting will present the most up to date research on fracture healing basic biology, translational research and prospective clinical studies. The Program and Scientific Committees will be highly focused on fostering an inclusive environment. Surgeons, biologists, engineers, and policy makers will attend the meeting, and be drawn from academia, government, and industry. A variety of activities will be focused on career development and networking for trainees in the bone healing field. Narrative The 17th Biennial Conference of the ORS/ISFR titled, “Thinking big on fracture repair” will be held in December of 2020. The goal of the event is to foster growth and innovation in the field of fracture-induced pain management, artificial learning/machine learning/smart technology, polytrauma and stem cells, and outcomes research. Scientists, industry partners, researchers, policy makers, post-doctoral fellows and graduate students will attend the meeting to discuss the most pressing questions in the field of fracture repair, and to consider bold approaches to solving those problems.",ORS-ISFR 17th Biennial Conference: Thinking big on fracture repair,10066004,R13AR077963,"['Academia', 'American', 'Area', 'Artificial Intelligence', 'Basic Science', 'Big Data', 'Biological Process', 'Biology', 'Bone Injury', 'Bone Pain', 'Bone Regeneration', 'Canada', 'Career Mobility', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Consensus', 'Consensus Workshop', 'Development', 'Discipline', 'Engineering', 'Ensure', 'Environment', 'Event', 'Evidence based treatment', 'Exposure to', 'Fostering', 'Fracture', 'Fracture Healing', 'Germany', 'Goals', 'Government', 'Growth', 'Industry', 'Institutes', 'International', 'Japan', 'Joints', 'Knowledge', 'Laboratories', 'Logistics', 'Machine Learning', 'Mission', 'Musculoskeletal', 'Ontario', 'Oral', 'Orthopedics', 'Outcome', 'Outcome Study', 'Outcomes Research', 'Pain management', 'Paper', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Policy Maker', 'Postdoctoral Fellow', 'Recording of previous events', 'Registries', 'Regulation', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Series', 'Shoulder Fractures', 'Societies', 'Surgeon', 'Technology', 'Thinking', 'Translational Research', 'Trauma', 'Universities', 'Work', 'base', 'bone', 'bone healing', 'career development', 'career networking', 'cost', 'data management', 'disability', 'graduate student', 'healing', 'humerus', 'industry partner', 'innovation', 'interest', 'large scale data', 'meetings', 'novel diagnostics', 'novel therapeutics', 'outreach', 'population based', 'posters', 'programs', 'prospective', 'repaired', 'scientific organization', 'stem cells', 'success', 'symposium', 'translational physician']",NIAMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R13,2020,15000,0.051645298392645485
"Big Data and Network Analysis of Children's Health Project Summary  Decades of research suggest that neighborhood socioeconomic disadvantage increases children's health risk. This proposed project seeks to address two major weaknesses in conventional neighborhood effects research and interventions: a) the assumption that residential neighborhoods function independently of each other - ignoring that risk factors in areas where people work, learn, and play away from home may interact with residential factors; and b) as importantly, insufficient understanding of neighborhood effects mechanisms and heterogeneity in effects. To systematically address these critical barriers in the field, I propose a research and training program that will enable me to learn, use, and adapt recent advancements in Big Data analytics. I plan to model hidden interdependencies among individuals and neighborhoods and operationalize mechanisms of neighborhood effects by drawing on multiple large datasets (demographic, geospatial, networks, population flows), with several hundred million observations across multiple states, cities, and years, and match them to locally and nationally representative restricted survey data. The massive volume, great variety, and unique complexity of such data, such as relational data on inter-neighborhood dependencies and interactions, pose a challenge to the standard capabilities of hardware, algorithms, and analytical methods and models of social and population science. The proposed training program in Big Data analytics and machine learning will enable me to overcome computational and conceptual challenges and uniquely position me to: a) examine the ecological inter-neighborhood networks (econetworks) to which population groups are differentially exposed to across space and time; and b) test new contextual mechanisms underlying children's exposures to health risks. Specifically, I propose to: a) develop computational models of dynamic large scale econetworks to assess population differences in exposures to health risk factors, as they commute daily between home and workplaces; b) examine heterogeneity in econetwork effects on child health using a hybrid design that links Big Data to local and national surveys; and c) model child health risk mechanisms and causal effects using natural experiments on Big Data. The proposed training program will enable me to learn and adapt Big Data analytics, draw on its strengths, but also address some of its key limitations. With the support of a unique team of distinguished mentors and advisors, established experts in Big Data analytics, spatial demography, network analysis, child development and health risk, neighborhood change, and population heterogeneity, I will embark on a training program that will uniquely enable me to address these research goals and position me to become an independent scholar and a leader in the field. Project Narrative This project contributes to advancing public health scholarship by leveraging and adapting Big Data analytical tools to overcome critical barriers in the field related to conventional assumptions about effects of neighborhood risk exposures on child health. It addresses the need to understand and model inter- neighborhood interdependencies and underlying multidimensional social capital mechanisms in order to better understand population heterogeneity in neighborhood effects on child health across space and time. The project also advances public health through an integration of rigorous social and data science methodology to create new measures and test causal hypotheses that advance our understanding of social capital forces that foster resilience to adversity and improve child health behavior and outcomes.",Big Data and Network Analysis of Children's Health,9767837,K01HD093863,"['Address', 'Alcohol consumption', 'Area', 'Big Data', 'Big Data Methods', 'Businesses', 'Censuses', 'Child', 'Child Behavior', 'Child Development', 'Child Health', 'Child Rearing', 'Cities', 'Collaborations', 'Commuting', 'Computational Technique', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Demography', 'Dependence', 'Dimensions', 'Distress', 'Drug usage', 'Exposure to', 'Fostering', 'Goals', 'Graph', 'Health', 'Health Resources', 'Health behavior outcomes', 'Heterogeneity', 'Home environment', 'Hybrids', 'Individual', 'Infrastructure', 'Intervention', 'Learning', 'Link', 'Location', 'Longitudinal Surveys', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Modeling', 'Natural experiment', 'Neighborhoods', 'Outcome', 'Parents', 'Participant', 'Pathway Analysis', 'Pharmaceutical Preparations', 'Play', 'Population', 'Population Group', 'Population Heterogeneity', 'Population Sciences', 'Positioning Attribute', 'Poverty', 'Pregnancy in Adolescence', 'Public Health', 'Records', 'Research', 'Research Training', 'Risk', 'Risk Behaviors', 'Risk Factors', 'Sampling', 'Scholarship', 'Schools', 'Smoking', 'Social Sciences', 'Social Work', 'Social support', 'Socioeconomic Status', 'Stress and Coping', 'Surveys', 'Testing', 'Time', 'Training Programs', 'Victimization', 'Work', 'Workplace', 'algorithmic methodologies', 'analytical method', 'analytical tool', 'base', 'boys', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'low socioeconomic status', 'neighborhood disadvantage', 'population health', 'programs', 'resilience', 'social capital', 'socioeconomic disadvantage', 'theories', 'violence exposure']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,K01,2019,138258,0.14565871205667938
"Big Data and Network Analysis of Children's Health Project Summary  Decades of research suggest that neighborhood socioeconomic disadvantage increases children's health risk. This proposed project seeks to address two major weaknesses in conventional neighborhood effects research and interventions: a) the assumption that residential neighborhoods function independently of each other - ignoring that risk factors in areas where people work, learn, and play away from home may interact with residential factors; and b) as importantly, insufficient understanding of neighborhood effects mechanisms and heterogeneity in effects. To systematically address these critical barriers in the field, I propose a research and training program that will enable me to learn, use, and adapt recent advancements in Big Data analytics. I plan to model hidden interdependencies among individuals and neighborhoods and operationalize mechanisms of neighborhood effects by drawing on multiple large datasets (demographic, geospatial, networks, population flows), with several hundred million observations across multiple states, cities, and years, and match them to locally and nationally representative restricted survey data. The massive volume, great variety, and unique complexity of such data, such as relational data on inter-neighborhood dependencies and interactions, pose a challenge to the standard capabilities of hardware, algorithms, and analytical methods and models of social and population science. The proposed training program in Big Data analytics and machine learning will enable me to overcome computational and conceptual challenges and uniquely position me to: a) examine the ecological inter-neighborhood networks (econetworks) to which population groups are differentially exposed to across space and time; and b) test new contextual mechanisms underlying children's exposures to health risks. Specifically, I propose to: a) develop computational models of dynamic large scale econetworks to assess population differences in exposures to health risk factors, as they commute daily between home and workplaces; b) examine heterogeneity in econetwork effects on child health using a hybrid design that links Big Data to local and national surveys; and c) model child health risk mechanisms and causal effects using natural experiments on Big Data. The proposed training program will enable me to learn and adapt Big Data analytics, draw on its strengths, but also address some of its key limitations. With the support of a unique team of distinguished mentors and advisors, established experts in Big Data analytics, spatial demography, network analysis, child development and health risk, neighborhood change, and population heterogeneity, I will embark on a training program that will uniquely enable me to address these research goals and position me to become an independent scholar and a leader in the field. Project Narrative This project contributes to advancing public health scholarship by leveraging and adapting Big Data analytical tools to overcome critical barriers in the field related to conventional assumptions about effects of neighborhood risk exposures on child health. It addresses the need to understand and model inter- neighborhood interdependencies and underlying multidimensional social capital mechanisms in order to better understand population heterogeneity in neighborhood effects on child health across space and time. The project also advances public health through an integration of rigorous social and data science methodology to create new measures and test causal hypotheses that advance our understanding of social capital forces that foster resilience to adversity and improve child health behavior and outcomes.",Big Data and Network Analysis of Children's Health,10003037,K01HD093863,"['Address', 'Alcohol consumption', 'Area', 'Big Data', 'Big Data Methods', 'Businesses', 'Censuses', 'Child', 'Child Behavior', 'Child Development', 'Child Health', 'Child Rearing', 'Cities', 'Collaborations', 'Commuting', 'Computational Technique', 'Computer Models', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Demography', 'Dependence', 'Dimensions', 'Distress', 'Drug usage', 'Exposure to', 'Fostering', 'Goals', 'Graph', 'Health', 'Health Resources', 'Health behavior outcomes', 'Heterogeneity', 'Home environment', 'Hybrids', 'Individual', 'Infrastructure', 'Intervention', 'Learning', 'Link', 'Location', 'Longitudinal Surveys', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Modeling', 'Natural experiment', 'Neighborhoods', 'Outcome', 'Parents', 'Participant', 'Pathway Analysis', 'Pharmaceutical Preparations', 'Play', 'Population', 'Population Group', 'Population Heterogeneity', 'Population Sciences', 'Positioning Attribute', 'Poverty', 'Pregnancy in Adolescence', 'Public Health', 'Records', 'Research', 'Research Training', 'Risk', 'Risk Behaviors', 'Risk Factors', 'Sampling', 'Scholarship', 'Schools', 'Smoking', 'Social Sciences', 'Social Work', 'Social support', 'Socioeconomic Status', 'Stress and Coping', 'Surveys', 'Testing', 'Time', 'Training Programs', 'Victimization', 'Work', 'Workplace', 'algorithmic methodologies', 'analytical method', 'analytical tool', 'base', 'boys', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'large datasets', 'large scale data', 'low socioeconomic status', 'neighborhood disadvantage', 'population health', 'programs', 'resilience', 'social capital', 'socioeconomic disadvantage', 'theories', 'violence exposure']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,K01,2020,137660,0.14565871205667938
"Big Data and Network Analysis of Children's Health Project Summary  Decades of research suggest that neighborhood socioeconomic disadvantage increases children's health risk. This proposed project seeks to address two major weaknesses in conventional neighborhood effects research and interventions: a) the assumption that residential neighborhoods function independently of each other - ignoring that risk factors in areas where people work, learn, and play away from home may interact with residential factors; and b) as importantly, insufficient understanding of neighborhood effects mechanisms and heterogeneity in effects. To systematically address these critical barriers in the field, I propose a research and training program that will enable me to learn, use, and adapt recent advancements in Big Data analytics. I plan to model hidden interdependencies among individuals and neighborhoods and operationalize mechanisms of neighborhood effects by drawing on multiple large datasets (demographic, geospatial, networks, population flows), with several hundred million observations across multiple states, cities, and years, and match them to locally and nationally representative restricted survey data. The massive volume, great variety, and unique complexity of such data, such as relational data on inter-neighborhood dependencies and interactions, pose a challenge to the standard capabilities of hardware, algorithms, and analytical methods and models of social and population science. The proposed training program in Big Data analytics and machine learning will enable me to overcome computational and conceptual challenges and uniquely position me to: a) examine the ecological inter-neighborhood networks (econetworks) to which population groups are differentially exposed to across space and time; and b) test new contextual mechanisms underlying children's exposures to health risks. Specifically, I propose to: a) develop computational models of dynamic large scale econetworks to assess population differences in exposures to health risk factors, as they commute daily between home and workplaces; b) examine heterogeneity in econetwork effects on child health using a hybrid design that links Big Data to local and national surveys; and c) model child health risk mechanisms and causal effects using natural experiments on Big Data. The proposed training program will enable me to learn and adapt Big Data analytics, draw on its strengths, but also address some of its key limitations. With the support of a unique team of distinguished mentors and advisors, established experts in Big Data analytics, spatial demography, network analysis, child development and health risk, neighborhood change, and population heterogeneity, I will embark on a training program that will uniquely enable me to address these research goals and position me to become an independent scholar and a leader in the field. Project Narrative This project contributes to advancing public health scholarship by leveraging and adapting Big Data analytical tools to overcome critical barriers in the field related to conventional assumptions about effects of neighborhood risk exposures on child health. It addresses the need to understand and model inter- neighborhood interdependencies and underlying multidimensional social capital mechanisms in order to better understand population heterogeneity in neighborhood effects on child health across space and time. The project also advances public health through an integration of rigorous social and data science methodology to create new measures and test causal hypotheses that advance our understanding of social capital forces that foster resilience to adversity and improve child health behavior and outcomes.",Big Data and Network Analysis of Children's Health,9569278,K01HD093863,"['Address', 'Alcohol consumption', 'Area', 'Big Data', 'Businesses', 'Censuses', 'Child', 'Child Behavior', 'Child Development', 'Child Health', 'Child Rearing', 'Cities', 'Collaborations', 'Commuting', 'Computational Technique', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Demography', 'Dependence', 'Dimensions', 'Distress', 'Drug usage', 'Exposure to', 'Fostering', 'Goals', 'Graph', 'Health', 'Health Resources', 'Health behavior outcomes', 'Heterogeneity', 'Home environment', 'Hybrids', 'Individual', 'Intervention', 'Learning', 'Link', 'Location', 'Longitudinal Surveys', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Modeling', 'Natural experiment', 'Neighborhoods', 'Outcome', 'Parents', 'Participant', 'Pathway Analysis', 'Pharmaceutical Preparations', 'Play', 'Population', 'Population Group', 'Population Heterogeneity', 'Population Sciences', 'Positioning Attribute', 'Poverty', 'Pregnancy in Adolescence', 'Public Health', 'Records', 'Research', 'Research Infrastructure', 'Research Training', 'Risk', 'Risk Behaviors', 'Risk Factors', 'Sampling', 'Scholarship', 'Schools', 'Smoking', 'Social Sciences', 'Social Work', 'Social support', 'Socioeconomic Status', 'Stress and Coping', 'Surveys', 'Testing', 'Time', 'Training Programs', 'Victimization', 'Work', 'Workplace', 'algorithmic methodologies', 'analytical method', 'analytical tool', 'base', 'boys', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'low socioeconomic status', 'neighborhood disadvantage', 'population health', 'programs', 'resilience', 'social capital', 'socioeconomic disadvantage', 'theories', 'violence exposure']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,K01,2018,139005,0.14565871205667938
"Big Data and Network Analysis of Children's Health Project Summary  Decades of research suggest that neighborhood socioeconomic disadvantage increases children's health risk. This proposed project seeks to address two major weaknesses in conventional neighborhood effects research and interventions: a) the assumption that residential neighborhoods function independently of each other - ignoring that risk factors in areas where people work, learn, and play away from home may interact with residential factors; and b) as importantly, insufficient understanding of neighborhood effects mechanisms and heterogeneity in effects. To systematically address these critical barriers in the field, I propose a research and training program that will enable me to learn, use, and adapt recent advancements in Big Data analytics. I plan to model hidden interdependencies among individuals and neighborhoods and operationalize mechanisms of neighborhood effects by drawing on multiple large datasets (demographic, geospatial, networks, population flows), with several hundred million observations across multiple states, cities, and years, and match them to locally and nationally representative restricted survey data. The massive volume, great variety, and unique complexity of such data, such as relational data on inter-neighborhood dependencies and interactions, pose a challenge to the standard capabilities of hardware, algorithms, and analytical methods and models of social and population science. The proposed training program in Big Data analytics and machine learning will enable me to overcome computational and conceptual challenges and uniquely position me to: a) examine the ecological inter-neighborhood networks (econetworks) to which population groups are differentially exposed to across space and time; and b) test new contextual mechanisms underlying children's exposures to health risks. Specifically, I propose to: a) develop computational models of dynamic large scale econetworks to assess population differences in exposures to health risk factors, as they commute daily between home and workplaces; b) examine heterogeneity in econetwork effects on child health using a hybrid design that links Big Data to local and national surveys; and c) model child health risk mechanisms and causal effects using natural experiments on Big Data. The proposed training program will enable me to learn and adapt Big Data analytics, draw on its strengths, but also address some of its key limitations. With the support of a unique team of distinguished mentors and advisors, established experts in Big Data analytics, spatial demography, network analysis, child development and health risk, neighborhood change, and population heterogeneity, I will embark on a training program that will uniquely enable me to address these research goals and position me to become an independent scholar and a leader in the field. Project Narrative This project contributes to advancing public health scholarship by leveraging and adapting Big Data analytical tools to overcome critical barriers in the field related to conventional assumptions about effects of neighborhood risk exposures on child health. It addresses the need to understand and model inter- neighborhood interdependencies and underlying multidimensional social capital mechanisms in order to better understand population heterogeneity in neighborhood effects on child health across space and time. The project also advances public health through an integration of rigorous social and data science methodology to create new measures and test causal hypotheses that advance our understanding of social capital forces that foster resilience to adversity and improve child health behavior and outcomes.",Big Data and Network Analysis of Children's Health,9431875,K01HD093863,"['Address', 'Alcohol consumption', 'Area', 'Big Data', 'Businesses', 'Censuses', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Child health care', 'Cities', 'Collaborations', 'Commuting', 'Computational Technique', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Demography', 'Dependency', 'Dimensions', 'Distress', 'Drug usage', 'Exposure to', 'Fostering', 'Goals', 'Graph', 'Health', 'Health Resources', 'Health behavior outcomes', 'Heterogeneity', 'Home environment', 'Hybrids', 'Individual', 'Intervention', 'Learning', 'Link', 'Location', 'Longitudinal Surveys', 'Machine Learning', 'Measures', 'Mentors', 'Methodology', 'Modeling', 'Natural experiment', 'Neighborhoods', 'Outcome', 'Parents', 'Participant', 'Pathway Analysis', 'Pharmaceutical Preparations', 'Play', 'Population', 'Population Group', 'Population Heterogeneity', 'Population Sciences', 'Positioning Attribute', 'Poverty', 'Pregnancy in Adolescence', 'Public Health', 'Records', 'Research', 'Research Infrastructure', 'Research Training', 'Risk', 'Risk Behaviors', 'Risk Factors', 'Sampling', 'Scholarship', 'Schools', 'Smoking', 'Social Sciences', 'Social Work', 'Social support', 'Socioeconomic Status', 'Stress and Coping', 'Surveys', 'Testing', 'Time', 'Training Programs', 'Victimization', 'Violence', 'Work', 'Workplace', 'algorithmic methodologies', 'analytical method', 'analytical tool', 'base', 'boys', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'low socioeconomic status', 'neighborhood disadvantage', 'population health', 'programs', 'resilience', 'social capital', 'socioeconomic disadvantage', 'theories']",NICHD,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,K01,2017,139492,0.14565871205667938
"Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools ﻿    DESCRIPTION (provided by applicant): Epilepsy is one of the world's most prevalent diseases, yet the rate of uncontrolled seizures has not changed in decades. One of the reasons for this is our limited understanding of seizure mechanisms, and so one of the main goals of epilepsy research is to identify new biomarkers to help us understand the nature of the disease. Recent technological advancements now allow us to monitor brain activity with much higher resolution, which have led to the identification of promising potential biomarkers such as High Frequency Oscillations (HFOs). Unfortunately, clinicians still have not determined how to utilize this information under clinical conditions. There are three main obstacles to implementing HFOs in practice: 1) it is unclear how to acquire them in a practical way; 2) it is unclear how to ascertain which HFOs are truly related to epilepsy; and 3) it is unclear how to use the HFO data in a prospective fashion to improve clinical care. The purpose of this project is overcome each of these obstacles. The first Aim validates a universal computer algorithm that can identify HFOs automatically, then tests how to use HFO rate as method to identify where seizures will start. This method improves upon past work by improving the precision of HFO detection and determining how to avoid false predictions that would lead to unnecessary surgery. The second Aim addresses a major unsolved problem in HFO research: HFOs are seen in normal brain as well as in epilepsy. This Aim will use state-of-the- art machine learning tools to process a vast dataset of HFO collected from over 100 patients to determine how to distinguish epileptic from normal HFOs. The third Aim will analyze how HFOs change over time, a largely unexplored characteristic of HFOs that cannot be evaluated without very large datasets. These Aims together serve as the framework to establish HFOs as a clinically viable biomarker of seizures, allowing their translation into clinical epilepsy care and leading to future prospective clinical studies identifying the location and timing of seizure onset. PUBLIC HEALTH RELEVANCE: The goal of this project is to characterize a novel biomarker of seizures using advanced computer algorithms that monitor brainwaves in real time. These biomarkers, known as High Frequency Oscillations, have been recognized for some time but their research has been restricted to very short datasets within a handful of centers worldwide. This project will use Big Data tools to help translate these biomarkers into widespread use while exploring several novel ways in which they will help clinicians identify seizures.",Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools,9702876,R01NS094399,"['Address', 'Adoption', 'Algorithms', 'Basic Science', 'Benchmarking', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Brain', 'Brain region', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Computational algorithm', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Devices', 'Diagnosis', 'Disease', 'Electroencephalography', 'Epilepsy', 'Frequencies', 'Future', 'Goals', 'High Frequency Oscillation', 'Hour', 'Human', 'Lead', 'Literature', 'Location', 'Machine Learning', 'Manuals', 'Methods', 'Michigan', 'Monitor', 'Morphologic artifacts', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Outcome', 'Output', 'Pathologic', 'Patients', 'Process', 'Research', 'Resolution', 'Seizures', 'Slow-Wave Sleep', 'Specificity', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Universities', 'Unnecessary Surgery', 'Work', 'analytical method', 'base', 'clinical application', 'clinical care', 'clinical translation', 'data mining', 'design', 'detector', 'improved', 'novel', 'novel marker', 'potential biomarker', 'prediction algorithm', 'prospective', 'public health relevance', 'response', 'surgery outcome', 'tool']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,328340,0.15594436456861532
"Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools ﻿    DESCRIPTION (provided by applicant): Epilepsy is one of the world's most prevalent diseases, yet the rate of uncontrolled seizures has not changed in decades. One of the reasons for this is our limited understanding of seizure mechanisms, and so one of the main goals of epilepsy research is to identify new biomarkers to help us understand the nature of the disease. Recent technological advancements now allow us to monitor brain activity with much higher resolution, which have led to the identification of promising potential biomarkers such as High Frequency Oscillations (HFOs). Unfortunately, clinicians still have not determined how to utilize this information under clinical conditions. There are three main obstacles to implementing HFOs in practice: 1) it is unclear how to acquire them in a practical way; 2) it is unclear how to ascertain which HFOs are truly related to epilepsy; and 3) it is unclear how to use the HFO data in a prospective fashion to improve clinical care. The purpose of this project is overcome each of these obstacles. The first Aim validates a universal computer algorithm that can identify HFOs automatically, then tests how to use HFO rate as method to identify where seizures will start. This method improves upon past work by improving the precision of HFO detection and determining how to avoid false predictions that would lead to unnecessary surgery. The second Aim addresses a major unsolved problem in HFO research: HFOs are seen in normal brain as well as in epilepsy. This Aim will use state-of-the- art machine learning tools to process a vast dataset of HFO collected from over 100 patients to determine how to distinguish epileptic from normal HFOs. The third Aim will analyze how HFOs change over time, a largely unexplored characteristic of HFOs that cannot be evaluated without very large datasets. These Aims together serve as the framework to establish HFOs as a clinically viable biomarker of seizures, allowing their translation into clinical epilepsy care and leading to future prospective clinical studies identifying the location and timing of seizure onset. PUBLIC HEALTH RELEVANCE: The goal of this project is to characterize a novel biomarker of seizures using advanced computer algorithms that monitor brainwaves in real time. These biomarkers, known as High Frequency Oscillations, have been recognized for some time but their research has been restricted to very short datasets within a handful of centers worldwide. This project will use Big Data tools to help translate these biomarkers into widespread use while exploring several novel ways in which they will help clinicians identify seizures.",Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools,9511925,R01NS094399,"['Address', 'Adoption', 'Algorithms', 'Basic Science', 'Benchmarking', 'Big Data', 'Biological Markers', 'Brain', 'Brain region', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Computational algorithm', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Devices', 'Diagnosis', 'Disease', 'Electroencephalography', 'Epilepsy', 'Frequencies', 'Future', 'Goals', 'High Frequency Oscillation', 'Hour', 'Human', 'Lead', 'Literature', 'Location', 'Machine Learning', 'Manuals', 'Methods', 'Michigan', 'Monitor', 'Morphologic artifacts', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Outcome', 'Output', 'Pathologic', 'Patients', 'Process', 'Research', 'Resolution', 'Seizures', 'Slow-Wave Sleep', 'Specificity', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Universities', 'Unnecessary Surgery', 'Work', 'analytical method', 'base', 'clinical application', 'clinical care', 'clinical translation', 'data mining', 'design', 'detector', 'improved', 'novel', 'novel marker', 'potential biomarker', 'prediction algorithm', 'prospective', 'public health relevance', 'response', 'surgery outcome', 'tool']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,328340,0.15594436456861532
"Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools ﻿    DESCRIPTION (provided by applicant): Epilepsy is one of the world's most prevalent diseases, yet the rate of uncontrolled seizures has not changed in decades. One of the reasons for this is our limited understanding of seizure mechanisms, and so one of the main goals of epilepsy research is to identify new biomarkers to help us understand the nature of the disease. Recent technological advancements now allow us to monitor brain activity with much higher resolution, which have led to the identification of promising potential biomarkers such as High Frequency Oscillations (HFOs). Unfortunately, clinicians still have not determined how to utilize this information under clinical conditions. There are three main obstacles to implementing HFOs in practice: 1) it is unclear how to acquire them in a practical way; 2) it is unclear how to ascertain which HFOs are truly related to epilepsy; and 3) it is unclear how to use the HFO data in a prospective fashion to improve clinical care. The purpose of this project is overcome each of these obstacles. The first Aim validates a universal computer algorithm that can identify HFOs automatically, then tests how to use HFO rate as method to identify where seizures will start. This method improves upon past work by improving the precision of HFO detection and determining how to avoid false predictions that would lead to unnecessary surgery. The second Aim addresses a major unsolved problem in HFO research: HFOs are seen in normal brain as well as in epilepsy. This Aim will use state-of-the- art machine learning tools to process a vast dataset of HFO collected from over 100 patients to determine how to distinguish epileptic from normal HFOs. The third Aim will analyze how HFOs change over time, a largely unexplored characteristic of HFOs that cannot be evaluated without very large datasets. These Aims together serve as the framework to establish HFOs as a clinically viable biomarker of seizures, allowing their translation into clinical epilepsy care and leading to future prospective clinical studies identifying the location and timing of seizure onset. PUBLIC HEALTH RELEVANCE: The goal of this project is to characterize a novel biomarker of seizures using advanced computer algorithms that monitor brainwaves in real time. These biomarkers, known as High Frequency Oscillations, have been recognized for some time but their research has been restricted to very short datasets within a handful of centers worldwide. This project will use Big Data tools to help translate these biomarkers into widespread use while exploring several novel ways in which they will help clinicians identify seizures.",Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools,9275549,R01NS094399,"['Address', 'Adoption', 'Algorithms', 'Basic Science', 'Benchmarking', 'Big Data', 'Biological Markers', 'Brain', 'Brain region', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Computational algorithm', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Devices', 'Diagnosis', 'Disease', 'Electroencephalography', 'Epilepsy', 'Frequencies', 'Future', 'Goals', 'High Frequency Oscillation', 'Hour', 'Human', 'Lead', 'Literature', 'Location', 'Machine Learning', 'Manuals', 'Methods', 'Michigan', 'Monitor', 'Morphologic artifacts', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Pathologic', 'Patients', 'Process', 'Research', 'Resolution', 'Seizures', 'Slow-Wave Sleep', 'Specificity', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Universities', 'Unnecessary Surgery', 'Work', 'analytical method', 'base', 'clinical application', 'clinical care', 'clinical translation', 'data mining', 'design', 'detector', 'improved', 'novel', 'novel marker', 'potential biomarker', 'prediction algorithm', 'prospective', 'public health relevance', 'response', 'tool']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2017,330348,0.15594436456861532
"Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools ﻿    DESCRIPTION (provided by applicant): Epilepsy is one of the world's most prevalent diseases, yet the rate of uncontrolled seizures has not changed in decades. One of the reasons for this is our limited understanding of seizure mechanisms, and so one of the main goals of epilepsy research is to identify new biomarkers to help us understand the nature of the disease. Recent technological advancements now allow us to monitor brain activity with much higher resolution, which have led to the identification of promising potential biomarkers such as High Frequency Oscillations (HFOs). Unfortunately, clinicians still have not determined how to utilize this information under clinical conditions. There are three main obstacles to implementing HFOs in practice: 1) it is unclear how to acquire them in a practical way; 2) it is unclear how to ascertain which HFOs are truly related to epilepsy; and 3) it is unclear how to use the HFO data in a prospective fashion to improve clinical care. The purpose of this project is overcome each of these obstacles. The first Aim validates a universal computer algorithm that can identify HFOs automatically, then tests how to use HFO rate as method to identify where seizures will start. This method improves upon past work by improving the precision of HFO detection and determining how to avoid false predictions that would lead to unnecessary surgery. The second Aim addresses a major unsolved problem in HFO research: HFOs are seen in normal brain as well as in epilepsy. This Aim will use state-of-the- art machine learning tools to process a vast dataset of HFO collected from over 100 patients to determine how to distinguish epileptic from normal HFOs. The third Aim will analyze how HFOs change over time, a largely unexplored characteristic of HFOs that cannot be evaluated without very large datasets. These Aims together serve as the framework to establish HFOs as a clinically viable biomarker of seizures, allowing their translation into clinical epilepsy care and leading to future prospective clinical studies identifying the location and timing of seizure onset. PUBLIC HEALTH RELEVANCE: The goal of this project is to characterize a novel biomarker of seizures using advanced computer algorithms that monitor brainwaves in real time. These biomarkers, known as High Frequency Oscillations, have been recognized for some time but their research has been restricted to very short datasets within a handful of centers worldwide. This project will use Big Data tools to help translate these biomarkers into widespread use while exploring several novel ways in which they will help clinicians identify seizures.",Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools,9134899,R01NS094399,"['Address', 'Adoption', 'Algorithms', 'Basic Science', 'Benchmarking', 'Big Data', 'Biological Markers', 'Brain', 'Brain region', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Computational algorithm', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Devices', 'Diagnosis', 'Disease', 'Electroencephalography', 'Epilepsy', 'Frequencies', 'Future', 'Goals', 'Health', 'High Frequency Oscillation', 'Hour', 'Human', 'Lead', 'Literature', 'Location', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Michigan', 'Mining', 'Monitor', 'Morphologic artifacts', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Process', 'Research', 'Resolution', 'Seizures', 'Slow-Wave Sleep', 'Specificity', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Universities', 'Unnecessary Surgery', 'Work', 'analytical method', 'base', 'clinical application', 'clinical care', 'data mining', 'design', 'detector', 'improved', 'novel', 'novel marker', 'potential biomarker', 'prediction algorithm', 'prospective', 'response', 'tool']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2016,334212,0.15594436456861532
"Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools ﻿    DESCRIPTION (provided by applicant): Epilepsy is one of the world's most prevalent diseases, yet the rate of uncontrolled seizures has not changed in decades. One of the reasons for this is our limited understanding of seizure mechanisms, and so one of the main goals of epilepsy research is to identify new biomarkers to help us understand the nature of the disease. Recent technological advancements now allow us to monitor brain activity with much higher resolution, which have led to the identification of promising potential biomarkers such as High Frequency Oscillations (HFOs). Unfortunately, clinicians still have not determined how to utilize this information under clinical conditions. There are three main obstacles to implementing HFOs in practice: 1) it is unclear how to acquire them in a practical way; 2) it is unclear how to ascertain which HFOs are truly related to epilepsy; and 3) it is unclear how to use the HFO data in a prospective fashion to improve clinical care. The purpose of this project is overcome each of these obstacles. The first Aim validates a universal computer algorithm that can identify HFOs automatically, then tests how to use HFO rate as method to identify where seizures will start. This method improves upon past work by improving the precision of HFO detection and determining how to avoid false predictions that would lead to unnecessary surgery. The second Aim addresses a major unsolved problem in HFO research: HFOs are seen in normal brain as well as in epilepsy. This Aim will use state-of-the- art machine learning tools to process a vast dataset of HFO collected from over 100 patients to determine how to distinguish epileptic from normal HFOs. The third Aim will analyze how HFOs change over time, a largely unexplored characteristic of HFOs that cannot be evaluated without very large datasets. These Aims together serve as the framework to establish HFOs as a clinically viable biomarker of seizures, allowing their translation into clinical epilepsy care and leading to future prospective clinical studies identifying the location and timing of seizure onset.         PUBLIC HEALTH RELEVANCE: The goal of this project is to characterize a novel biomarker of seizures using advanced computer algorithms that monitor brainwaves in real time. These biomarkers, known as High Frequency Oscillations, have been recognized for some time but their research has been restricted to very short datasets within a handful of centers worldwide. This project will use Big Data tools to help translate these biomarkers into widespread use while exploring several novel ways in which they will help clinicians identify seizures.            ",Characterizing High Frequency Oscillations as an epilepsy biomarker with Big Data tools,9004826,R01NS094399,"['Address', 'Adoption', 'Algorithms', 'Basic Science', 'Benchmarking', 'Big Data', 'Biological Markers', 'Brain', 'Brain region', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Computational algorithm', 'Computer Simulation', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Devices', 'Diagnosis', 'Disease', 'Electroencephalography', 'Epilepsy', 'Frequencies', 'Future', 'Goals', 'High Frequency Oscillation', 'Hour', 'Human', 'Lead', 'Literature', 'Location', 'Machine Learning', 'Manuals', 'Maps', 'Methods', 'Michigan', 'Mining', 'Monitor', 'Morphologic artifacts', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Process', 'Research', 'Resolution', 'Seizures', 'Slow-Wave Sleep', 'Specificity', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Tissues', 'Translating', 'Translations', 'Universities', 'Unnecessary Surgery', 'Work', 'analytical method', 'base', 'clinical application', 'clinical care', 'data mining', 'design', 'detector', 'improved', 'novel', 'prospective', 'public health relevance', 'response', 'tool']",NINDS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2015,319087,0.15594436456861532
"BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO)     DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's.              n/a",BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO),8840825,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Beds', 'Benchmarking', 'Big Data', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Child health care', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Development', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Names', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'data visualization', 'design', 'emergency service responder', 'experience', 'genetic variant', 'genome analysis', 'genome sequencing', 'improved', 'indexing', 'interoperability', 'medical information system', 'novel', 'open source', 'parallel processing', 'performance tests', 'processing speed', 'repository', 'research study', 'response', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R01,2015,529458,0.049640209962192025
"Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictio DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to  explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index  patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's. n/a",Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictio,8599828,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Beds', 'Benchmarking', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Child', 'Child health care', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Development', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Mutation', 'Names', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Relative (related person)', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'design', 'emergency service responder', 'experience', 'genome analysis', 'genome sequencing', 'improved', 'indexing', 'interoperability', 'medical information system', 'novel', 'open source', 'parallel processing', 'performance tests', 'processing speed', 'repository', 'research study', 'response', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual']",NIGMS,UNIVERSITY OF UTAH,R01,2013,568249,0.049640209962192025
"BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO) DESCRIPTION (provided by applicant): An unsolved problem in health informatics is how to apply the past experiences of patients, stored in large-scale medical records systems, to predict the outcomes of patients and to individualize care. One approach to prediction, heretofore impractical, is rapidly finding a patient cohort ""similar enough"" to an index case that the health experiences and outcomes of this cohort are informative for prediction. This task is formidable because of large variability of the vast numbers of patient attributes with the added complexity of sequences of patient encounters evolving over time. Epidemiological considerations such as confounding by indication for treatment also come into play. The objective of this research effort is to (1) create a modular test bed that uses a ""big data"" systems architecture to support research in rapid individualized prediction of outcomes from large clinical repositories and (2) to explore various approaches to making ""pragmatic"" near-term predictions of outcomes. Using the Department of Veterans Affairs' (VA) Informatics and Computing Infrastructure database (VINCI), a research database with records of tens of millions of patients, we will explore two synergistic strategies for rapidly finding a cohort of patients that are similar enough to an index patient to predict near-term treatment response and/or adverse effects in an elastic cloud environment: 1) use of temporal alignment of critical events including use of gene sequence alignment methods to relax requirements for exact temporal matching; and, 2) use of conceptual distance metrics to model the degree of content similarity of case records. The initial domain of application will be treatment of Type 2 diabetes. The approach will apply open source ""big data"" methodologies, including Hadoop and Accumulo, to store and filter ""medical log"" files. The content of these ""logs"" will be processed by a combination with strategies including conceptual markup of events using natural language processing tools, matching of event streams, and statistical data mining methods to rapidly retrieve and identify patients that are sufficiently similar to an index case to be able to make personalized yet pragmatic clinical predictions of outcomes. RELEVANCE (See instructions): This proposal studies how to use experience of past patients, stored in electronic medical records systems, to help clinicians make practical decisions on the care of complex patients with type 1 diabetes. Research applies methods adapted from Internet search engines and from studies of the human genome to determine what it means for one patient's disease experiences to be similar to and relevant to another's. n/a",BIGDATA: Mid-Scale: DA: Techniques to Integrate Disparate Data: Clinical Personalized Pragmatic Predictions of Outcomes (C3PO),9066173,R01GM108346,"['Address', 'Adoption', 'Adverse effects', 'Algorithms', 'Assessment tool', 'Beds', 'Benchmarking', 'Big Data', 'Biological', 'Biological Models', 'Biosensing Techniques', 'Budgets', 'Caring', 'Cataloging', 'Catalogs', 'Centers for Disease Control and Prevention (U.S.)', 'Childhood', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cluster Analysis', 'Collaborations', 'Complex', 'Computer Systems', 'Computerized Medical Record', 'Coupled', 'Critical Care', 'Data', 'Data Analyses', 'Data Element', 'Data Set', 'Databases', 'Development', 'Disasters', 'Disease', 'Environment', 'Epidemiology', 'Event', 'Exclusion', 'Extensible Markup Language', 'Funding', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Germ-Line Mutation', 'Goals', 'Health', 'Health system', 'Human Genome', 'Imagery', 'Informatics', 'Information Systems', 'Institutes', 'Instruction', 'Insulin-Dependent Diabetes Mellitus', 'Internet', 'Language', 'Letters', 'Location', 'Logical Observation Identifiers Names and Codes', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Medical', 'Medical Records', 'Medicine', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Names', 'National Institute of Child Health and Human Development', 'Natural Language Processing', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oncogenes', 'Ontology', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Play', 'Privacy', 'Process', 'Public Health Informatics', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Role', 'Sequence Alignment', 'Somatic Mutation', 'Source', 'Specialist', 'Stream', 'Structure', 'System', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Text', 'Time', 'Translational Research', 'Triage', 'United States National Library of Medicine', 'Variant', 'Veterans', 'Visualization software', 'Vocabulary', 'Wireless Technology', 'Work', 'base', 'bench to bedside', 'cancer type', 'clinical care', 'clinical practice', 'cohort', 'data integration', 'data mining', 'data visualization', 'design', 'emergency service responder', 'experience', 'genetic variant', 'genome analysis', 'genome sequencing', 'genomic data', 'improved', 'indexing', 'interoperability', 'learning strategy', 'medical information system', 'novel', 'open source', 'outcome prediction', 'parallel processing', 'performance tests', 'personalized care', 'predict clinical outcome', 'processing speed', 'reference genome', 'repository', 'research study', 'response', 'search engine', 'sugar', 'system architecture', 'tool', 'treatment response', 'tumor', 'tumor progression', 'virtual', 'whole genome']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R01,2016,507805,0.049640209962192025
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,9065764,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Crowding', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Science', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'data management', 'data modeling', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2015,183520,0.24483808922688652
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,9298691,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Dimensions', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Intuition', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Mining', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Analysis', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Scientist', 'Structure', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'big biomedical data', 'clinical phenotype', 'clinical predictors', 'cohort', 'computerized data processing', 'computerized tools', 'crowdsourcing', 'data management', 'data mining', 'data modeling', 'data resource', 'data to knowledge', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'learning strategy', 'molecular scale', 'multiple omics', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'support tools', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2017,47140,0.24483808922688652
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,9087292,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Science', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'big biomedical data', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'crowdsourcing', 'data management', 'data modeling', 'data to knowledge', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'learning strategy', 'multiple omics', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'support tools', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2016,31510,0.24483808922688652
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,8935858,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Crowding', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Science', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'data management', 'data modeling', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2015,133604,0.24483808922688652
"A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform     DESCRIPTION (provided by applicant): The inception of the BD2K Initiative is a testament to the foresight of NIH and our community. Clearly, the future of biomedicine rests on our collective ability to transform Big Data into intelligible scientific facts. In line with the BD2K objectives,our goal is to revolutionize how we address the universal challenge to discern meaning from unruly data. Capitalizing on our investigators' complementary strengths in computational biology and cardiovascular medicine, we will present a fusion of cutting-edge innovations that are grounded in a cardiovascular research focus, encompassing: (i) on-the-cloud data processing, (ii) crowd sourcing and text-mining data annotation, (iii) protein spatiotemporal dynamics, (iv) multi-omic integration, and (v) multiscale clinical data modeling. Drawing from our decade of experience in creating and refining bioinformatics tools, we propose to amalgamate established Big Data resources into a generalizable model for data annotation and collaborative research, through a new query system and cloud infrastructure for accessing multiple omics repositories, and through computational-supported crowdsourcing initiatives for mining the biomedical literature. We propose to interweave diverse data types for revealing biological networks that coalesce from molecular entities at multiple scales, through machine learning methods for structuring molecular data and defining relationships with drugs and diseases, and through novel algorithms for on-the-cloud integration and pathway visualization of multi-dimensional molecular data. Moreover, we propose to innovate advanced modeling tools to resolve protein dynamics and spatiotemporal molecular mechanisms, through mechanistic modeling of protein properties and 3D protein expression maps, and through Bayesian algorithms that correlate patient phenotypes, health histories, and multi-scale molecular profiles. The utility and customizability o our tools to the broader research population is clearly demonstrated using three archetypical workflows that enable annotations of large lists of genes, transcripts, proteins, or metabolites; powerful analysis of complex protein datasets acquired over time; and seamless aQoregation of diverse molecular, textual and literature data. These workflows will be rigorously validated using data from two significant clinical cohorts, the Jackson Heart Study and the Healthy Elderly Longevity (Wellderly). In parallel, a multifaceted strategy will be implemented to educate and train biomedical investigators, and to engage the public for promoting the overall BD2K initiative. We are convinced that a community-driven BD2K initiative will best realize its scientific potential and transform the research culture in a sustainable manner, exhibiting lasting success beyond the current funding period.         PUBLIC HEALTH RELEVANCE:  The challenges of biomedical Big Data are multifaceted. Biomedical investigators face daunting tasks of storing, analyzing, and distributing large-scale omics data, and aggregating all information to discern mechanistic insights. A coherent effort is required to harness disarrayed Big Data and transform them into intelligible scientific facts, whil engaging the global community via education and outreach programs. This Big Data Science Research proposal is designed to address these challenges by formulating a federated architecture of community-supported tools for enhancing data management, integration and analysis.            ",A Community Effort to Translate Protein Data to Knowledge: An Integrated Platform,8774362,U54GM114833,"['Achievement', 'Address', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Awareness', 'Big Data', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Communities', 'Computational Biology', 'Crowding', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Disease', 'Education and Outreach', 'Elderly', 'Environment', 'Exhibits', 'Face', 'Funding', 'Future', 'Gene Proteins', 'General Population', 'Generations', 'Genes', 'Goals', 'Half-Life', 'Harvest', 'Health', 'Human', 'Imagery', 'Jackson Heart Study', 'Knowledge', 'Literature', 'Longevity', 'Machine Learning', 'Maps', 'Medicine', 'Methods', 'Mining', 'Modeling', 'Modification', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Organ', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Population Research', 'Property', 'Protein Dynamics', 'Proteins', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Proposals', 'Resources', 'Rest', 'Science', 'Scientist', 'Structure', 'Support System', 'System', 'Time', 'Training', 'Training and Education', 'Transcript', 'Translating', 'United States National Institutes of Health', 'clinical phenotype', 'cohort', 'computerized data processing', 'computerized tools', 'data management', 'data modeling', 'design', 'experience', 'improved', 'innovation', 'insight', 'interest', 'novel', 'operation', 'outreach program', 'protein complex', 'protein expression', 'protein metabolite', 'protein protein interaction', 'public health relevance', 'repository', 'spatiotemporal', 'success', 'text searching', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U54,2014,1979000,0.24483808922688652
"SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data Abstract Over 30 million people in the US suffer from genetic diseases or cancers caused by mutations of which ~15% disrupt the regulation of splicing. Alternative splicing (AS) errors have been reported in literature to drive 370 genetic diseases out of ~800 described to date. In addition, due to the recent success of FDA-approved splicing modulators like Nusinersen, along with fascinating pre- clinical results underlining the importance of AS as therapeutic targets; splicing research has become of major interest to pharmaceutical companies. Envisagenics is developing SpliceCoreTM, an innovative cloud-based software platform using biomedical big data for AS analysis to discover new therapies and biomarkers for complex diseases. Our breakthrough platform combines algorithms and databases developed and experimentally validated at Cold Spring Harbor Laboratory (CSHL): SpliceTrapTM, for the detection of splicing activity using RNA-seq data; SpliceDuoTM, for the identification of significant splicing variation across biological samples; SpliceImpact2TM, for the prioritization of biologically relevant AS variants with therapeutic potential; and TXdbTM, a splicing isoform database that connects client’s proprietary data to public repositories such as the Cancer Genome Atlas (TCGA). Thanks to the Phase I award SpliceCore was adapted as a cloud-based software, accelerating scalability and adaptation to the fast- evolving market of biomedical Big Data. We now have deployed SpliceCore’s back-end on three cloud-service providers, increased its overall run-time by a factor of 12, developed tools to discover disease-specific AS isoforms, finalized and tested a machine-learning algorithm to predict the biological impact of AS, and experimentally validated some of our new predictions with a success rate of 82.5%. The goal for Phase II is to accelerate client acquisition through the development of user-interactive applications informed from client’s feedback by substantially expanding the platform’s knowledgebase and predictive functions with novel AS isoforms extracted from ~37,000 public datasets. Thus, a new version of SpliceCore will be developed to predict regulatory interactions between RNA-binding proteins and their RNA targets to assist in the interpretation of aberrant splicing factors through a collaboration with world renowned HHMI Professor Dr. Tom Tuschl from Rockefeller University and developer of Nusinersen, Professor Dr. Adrian Krainer from CSHL. Envisagenics is targeting the global bioinformatics market valued at $4 billion in 2014 with a CAGR of over 21%. SpliceCore could capture ~10% of the market, identify novel drug targets, and design RNA therapeutics from aberrant splicing events prevalent in cancer and a multitude of genetic diseases while increasing the efficiency of R&D in biopharma. Project Narrative In this SBIR Phase II, Envisagenics will advance the development of SpliceCoreTM, a cloud-based software platform for the discovery of drug-targets and biomarkers using biomedical big data. Therapeutic screens are increasingly focusing on Alternative Splicing (AS), a biological process that regulates gene-product structure and function. Strikingly, 50% of genetic diseases described in literature can be triggered by AS errors. The recent FDA approval of RNA-therapeutic compounds to correct AS errors, combined with increasingly available big datasets and groundbreaking cloud-computing provide a unique opportunity for computerized discovery of AS therapeutics. Envisagenics’ technology will help biomedical researchers to translate basic science into new therapeutic products for cancer and genetic diseases. By the completion of this project, we will deploy a user-friendly, secured and scalable SpliceCore software, with new functionalities ready for integration into biopharmaceutical Research & Development workflows.",SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data,9677178,R44GM116478,"['Achievement', 'Advanced Development', 'Affect', 'Algorithms', 'Alternative Splicing', 'Amyotrophic Lateral Sclerosis', 'Award', 'Back', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Products', 'Cancer Etiology', 'Client', 'Cloud Computing', 'Cloud Service', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Databases', 'Defect', 'Detection', 'Development', 'Disease', 'Drops', 'Drug Targeting', 'Dysmyelopoietic Syndromes', 'Ensure', 'Event', 'FDA approved', 'Face', 'Failure', 'Feedback', 'Food and Drug Administration Drug Approval', 'Frequencies', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Imagery', 'Immunoprecipitation', 'Infrastructure', 'Laboratories', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Meta-Analysis', 'Methods', 'Mutation', 'Nucleotides', 'Pathway interactions', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Predictive Analytics', 'Prevalence', 'Price', 'Privatization', 'Probability', 'Protein Binding Domain', 'Protein Isoforms', 'Protein Splicing', 'RNA', 'RNA Splicing', 'RNA-Binding Protein FUS', 'RNA-Binding Proteins', 'Regulation', 'Reporting', 'Research', 'Research Personnel', 'Ribonucleosides', 'Risk', 'Running', 'SRSF2 gene', 'Sampling', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Specificity', 'Spinal Muscular Atrophy', 'Structure', 'System', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Universities', 'Validation', 'Variant', 'Work', 'big biomedical data', 'cancer genetics', 'case control', 'cloud based', 'commercial application', 'computerized', 'cost', 'crosslink', 'data mining', 'data warehouse', 'design', 'drug discovery', 'experimental study', 'fascinate', 'flexibility', 'gene product', 'human disease', 'improved', 'innovation', 'interest', 'knowledge base', 'learning strategy', 'machine learning algorithm', 'new therapeutic target', 'novel', 'novel therapeutics', 'petabyte', 'pre-clinical', 'preclinical study', 'predictive modeling', 'professor', 'repository', 'research and development', 'service providers', 'success', 'system architecture', 'targeted biomarker', 'therapeutic RNA', 'therapeutic target', 'tool', 'transcriptome sequencing', 'user-friendly']",NIGMS,"ENVISAGENICS, INC.",R44,2019,517226,0.13308848762008318
"SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data Abstract Over 30 million people in the US suffer from genetic diseases or cancers caused by mutations of which ~15% disrupt the regulation of splicing. Alternative splicing (AS) errors have been reported in literature to drive 370 genetic diseases out of ~800 described to date. In addition, due to the recent success of FDA-approved splicing modulators like Nusinersen, along with fascinating pre- clinical results underlining the importance of AS as therapeutic targets; splicing research has become of major interest to pharmaceutical companies. Envisagenics is developing SpliceCoreTM, an innovative cloud-based software platform using biomedical big data for AS analysis to discover new therapies and biomarkers for complex diseases. Our breakthrough platform combines algorithms and databases developed and experimentally validated at Cold Spring Harbor Laboratory (CSHL): SpliceTrapTM, for the detection of splicing activity using RNA-seq data; SpliceDuoTM, for the identification of significant splicing variation across biological samples; SpliceImpact2TM, for the prioritization of biologically relevant AS variants with therapeutic potential; and TXdbTM, a splicing isoform database that connects client’s proprietary data to public repositories such as the Cancer Genome Atlas (TCGA). Thanks to the Phase I award SpliceCore was adapted as a cloud-based software, accelerating scalability and adaptation to the fast- evolving market of biomedical Big Data. We now have deployed SpliceCore’s back-end on three cloud-service providers, increased its overall run-time by a factor of 12, developed tools to discover disease-specific AS isoforms, finalized and tested a machine-learning algorithm to predict the biological impact of AS, and experimentally validated some of our new predictions with a success rate of 82.5%. The goal for Phase II is to accelerate client acquisition through the development of user-interactive applications informed from client’s feedback by substantially expanding the platform’s knowledgebase and predictive functions with novel AS isoforms extracted from ~37,000 public datasets. Thus, a new version of SpliceCore will be developed to predict regulatory interactions between RNA-binding proteins and their RNA targets to assist in the interpretation of aberrant splicing factors through a collaboration with world renowned HHMI Professor Dr. Tom Tuschl from Rockefeller University and developer of Nusinersen, Professor Dr. Adrian Krainer from CSHL. Envisagenics is targeting the global bioinformatics market valued at $4 billion in 2014 with a CAGR of over 21%. SpliceCore could capture ~10% of the market, identify novel drug targets, and design RNA therapeutics from aberrant splicing events prevalent in cancer and a multitude of genetic diseases while increasing the efficiency of R&D in biopharma. Project Narrative In this SBIR Phase II, Envisagenics will advance the development of SpliceCoreTM, a cloud-based software platform for the discovery of drug-targets and biomarkers using biomedical big data. Therapeutic screens are increasingly focusing on Alternative Splicing (AS), a biological process that regulates gene-product structure and function. Strikingly, 50% of genetic diseases described in literature can be triggered by AS errors. The recent FDA approval of RNA-therapeutic compounds to correct AS errors, combined with increasingly available big datasets and groundbreaking cloud-computing provide a unique opportunity for computerized discovery of AS therapeutics. Envisagenics’ technology will help biomedical researchers to translate basic science into new therapeutic products for cancer and genetic diseases. By the completion of this project, we will deploy a user-friendly, secured and scalable SpliceCore software, with new functionalities ready for integration into biopharmaceutical Research & Development workflows.",SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data,9747570,R44GM116478,"['Achievement', 'Advanced Development', 'Affect', 'Algorithms', 'Alternative Splicing', 'Amyotrophic Lateral Sclerosis', 'Award', 'Back', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Products', 'Cancer Etiology', 'Client', 'Cloud Computing', 'Cloud Service', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Databases', 'Defect', 'Detection', 'Development', 'Disease', 'Drops', 'Drug Targeting', 'Dysmyelopoietic Syndromes', 'Ensure', 'Event', 'FDA approved', 'Face', 'Failure', 'Feedback', 'Food and Drug Administration Drug Approval', 'Frequencies', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Imagery', 'Immunoprecipitation', 'Laboratories', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Meta-Analysis', 'Methods', 'Mutation', 'Nucleotides', 'Pathway interactions', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Predictive Analytics', 'Prevalence', 'Price', 'Privatization', 'Probability', 'Protein Binding Domain', 'Protein Isoforms', 'Protein Splicing', 'RNA', 'RNA Splicing', 'RNA-Binding Protein FUS', 'RNA-Binding Proteins', 'Regulation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Ribonucleosides', 'Risk', 'Running', 'SRSF2 gene', 'Sampling', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Specificity', 'Spinal Muscular Atrophy', 'Structure', 'System', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Universities', 'Validation', 'Variant', 'Work', 'big biomedical data', 'cancer genetics', 'case control', 'cloud based', 'commercial application', 'computerized', 'cost', 'crosslink', 'data mining', 'data warehouse', 'design', 'drug discovery', 'experimental study', 'fascinate', 'flexibility', 'gene product', 'human disease', 'improved', 'innovation', 'interest', 'knowledge base', 'learning strategy', 'new therapeutic target', 'novel', 'novel therapeutics', 'petabyte', 'pre-clinical', 'preclinical study', 'predictive modeling', 'professor', 'repository', 'research and development', 'service providers', 'success', 'system architecture', 'targeted biomarker', 'therapeutic RNA', 'therapeutic target', 'tool', 'transcriptome sequencing', 'user-friendly']",NIGMS,"ENVISAGENICS, INC.",R44,2018,125000,0.13308848762008318
"SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data Abstract Over 30 million people in the US suffer from genetic diseases or cancers caused by mutations of which ~15% disrupt the regulation of splicing. Alternative splicing (AS) errors have been reported in literature to drive 370 genetic diseases out of ~800 described to date. In addition, due to the recent success of FDA-approved splicing modulators like Nusinersen, along with fascinating pre- clinical results underlining the importance of AS as therapeutic targets; splicing research has become of major interest to pharmaceutical companies. Envisagenics is developing SpliceCoreTM, an innovative cloud-based software platform using biomedical big data for AS analysis to discover new therapies and biomarkers for complex diseases. Our breakthrough platform combines algorithms and databases developed and experimentally validated at Cold Spring Harbor Laboratory (CSHL): SpliceTrapTM, for the detection of splicing activity using RNA-seq data; SpliceDuoTM, for the identification of significant splicing variation across biological samples; SpliceImpact2TM, for the prioritization of biologically relevant AS variants with therapeutic potential; and TXdbTM, a splicing isoform database that connects client’s proprietary data to public repositories such as the Cancer Genome Atlas (TCGA). Thanks to the Phase I award SpliceCore was adapted as a cloud-based software, accelerating scalability and adaptation to the fast- evolving market of biomedical Big Data. We now have deployed SpliceCore’s back-end on three cloud-service providers, increased its overall run-time by a factor of 12, developed tools to discover disease-specific AS isoforms, finalized and tested a machine-learning algorithm to predict the biological impact of AS, and experimentally validated some of our new predictions with a success rate of 82.5%. The goal for Phase II is to accelerate client acquisition through the development of user-interactive applications informed from client’s feedback by substantially expanding the platform’s knowledgebase and predictive functions with novel AS isoforms extracted from ~37,000 public datasets. Thus, a new version of SpliceCore will be developed to predict regulatory interactions between RNA-binding proteins and their RNA targets to assist in the interpretation of aberrant splicing factors through a collaboration with world renowned HHMI Professor Dr. Tom Tuschl from Rockefeller University and developer of Nusinersen, Professor Dr. Adrian Krainer from CSHL. Envisagenics is targeting the global bioinformatics market valued at $4 billion in 2014 with a CAGR of over 21%. SpliceCore could capture ~10% of the market, identify novel drug targets, and design RNA therapeutics from aberrant splicing events prevalent in cancer and a multitude of genetic diseases while increasing the efficiency of R&D in biopharma. Project Narrative In this SBIR Phase II, Envisagenics will advance the development of SpliceCoreTM, a cloud-based software platform for the discovery of drug-targets and biomarkers using biomedical big data. Therapeutic screens are increasingly focusing on Alternative Splicing (AS), a biological process that regulates gene-product structure and function. Strikingly, 50% of genetic diseases described in literature can be triggered by AS errors. The recent FDA approval of RNA-therapeutic compounds to correct AS errors, combined with increasingly available big datasets and groundbreaking cloud-computing provide a unique opportunity for computerized discovery of AS therapeutics. Envisagenics’ technology will help biomedical researchers to translate basic science into new therapeutic products for cancer and genetic diseases. By the completion of this project, we will deploy a user-friendly, secured and scalable SpliceCore software, with new functionalities ready for integration into biopharmaceutical Research & Development workflows.",SpliceCore: A Cloud-Based Software Platform to Translate Alternative Splicing Events into Therapeutic Targets Using RNA-seq Data,9465337,R44GM116478,"['Achievement', 'Advanced Development', 'Affect', 'Algorithms', 'Alternative Splicing', 'Amyotrophic Lateral Sclerosis', 'Award', 'Back', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Products', 'Cancer Etiology', 'Client', 'Cloud Computing', 'Cloud Service', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Databases', 'Defect', 'Detection', 'Development', 'Disease', 'Drops', 'Drug Targeting', 'Dysmyelopoietic Syndromes', 'Ensure', 'Event', 'FDA approved', 'Face', 'Failure', 'Feedback', 'Food and Drug Administration Drug Approval', 'Frequencies', 'Genetic Diseases', 'Genotype-Tissue Expression Project', 'Goals', 'Growth', 'Imagery', 'Immunoprecipitation', 'Laboratories', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Memorial Sloan-Kettering Cancer Center', 'Meta-Analysis', 'Methods', 'Mutation', 'Nucleotides', 'Pathway interactions', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Predictive Analytics', 'Prevalence', 'Price', 'Privatization', 'Probability', 'Protein Binding Domain', 'Protein Isoforms', 'Protein Splicing', 'RNA', 'RNA Splicing', 'RNA-Binding Protein FUS', 'RNA-Binding Proteins', 'Regulation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Ribonucleosides', 'Risk', 'Running', 'SRSF2 gene', 'Sampling', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Specificity', 'Spinal Muscular Atrophy', 'Structure', 'System', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Universities', 'Validation', 'Variant', 'Work', 'big biomedical data', 'cancer genetics', 'case control', 'cloud based', 'commercial application', 'computerized', 'cost', 'crosslink', 'data mining', 'data warehouse', 'design', 'drug discovery', 'experimental study', 'fascinate', 'flexibility', 'gene product', 'human disease', 'improved', 'innovation', 'interest', 'knowledge base', 'learning strategy', 'new therapeutic target', 'novel', 'novel therapeutics', 'petabyte', 'pre-clinical', 'preclinical study', 'predictive modeling', 'professor', 'repository', 'research and development', 'service providers', 'success', 'system architecture', 'targeted biomarker', 'therapeutic RNA', 'therapeutic target', 'tool', 'transcriptome sequencing', 'user-friendly']",NIGMS,"ENVISAGENICS, INC.",R44,2018,982774,0.13308848762008318
"Data-driven approaches to identify biomarkers from multimodal imaging big data 1. PROJECT SUMMARY/ABSTRACT  The study of translational biomarkers in brain disorders is a very challenging and fruitful approach, which will empower a better understanding of healthy and diseased brains. This project will promote the translation of advanced engineering solutions and mathematic tools to novel neuroimaging applications in psychiatric disorders including major depression disorder (MDD), bipolar disorder (BD) and schizophrenia (SZ), allowing sophisticated and powerful analyses on highly complex datasets. To date, the unifying syndrome classification (ICD-9/10;DSM-IV/5) for these mental disorders obscures our knowledge of underlying pathophysiology and cannot guide optimal treatments. For example, there is no biomarker that is able to precisely predict response of MDD to some treatments. One reason for this is that most neuroimaging prediction studies to date have used a single imaging measure or reported simple correlation relationships, without considering multimodal cross- information, nonlinear relationships, or multi-site cross-validation. Hence, developing novel data mining techniques such as deep learning, fusion with reference, and sparse regression can complement and exploit the richness of neuroimaging data, providing promising avenues to identify objective biomarkers and going beyond a descriptive use of brain imaging as traditionally used in studies of brain disease to individualized prediction. We will facilitate the translational biomarker identification by developing 3 novel data-driven methods: 1) A supervised fusion model that can provide insight on how cognitive impairment may affect covarying brain function and structure in mental disorder, by using different clinical measures as a reference to guide multimodal MRI fusion; 2) A cutting-edge prediction framework with aggregated feature selection techniques that is able to estimate clinical outcome more precisely, e.g., remission/relapse status of individual MDD patient after electroconvulsive treatment(ECT) using baseline brain imaging and demographic measures of 3) We will draw on advances and ideas from deep learning combined with layer-wise relevance propagation (LRP) or attention modules, to classify multiple groups of psychiatric disorders by incorporating dynamic functional measures. The proposed (Deep/Recurrent/Convolutional Neural Network, DNN/RNN/CNN) models will have enhanced interpretability that is able to trace back and discover the most predictive functional networks from input. All above proposed methods will be applied to big data containing both multimodal imaging and behavioral information (n~5000) pooled from existing studies, and our developed open-source toolboxes will be shared publicly. This pioneering study may provide an urgently-needed paradigm shift in the treatment and diagnosis of psychiatric disorders, thereby guiding personalized clinical care. Accomplishment of this project has great potential to discover neuroimaging biomarkers that have been missed by existing approaches, leading to earlier and more effective interventions, and laying the groundwork for a significant translational impact. Project Narrative Psychiatric imaging is struggling with identifying robust biomarkers. Existing approaches do not fully leverage the power of multimodal data, despite evidence that such information is highly informative. We will draw on advances and ideas from fields of deep learning, supervised learning and functional dynamics, to capture rich information from multimodal imaging big data, and to identify precise biomarkers that are able to predict clinical measures for new individuals and help for intervention. We will pool big data from ongoing projects in multiple cohorts, consisting of a big data with imaging and behavioral info to apply clinical applications that will have profound translational medicine impact on schizophrenia, bipolar disorder and major depressive disorders.",Data-driven approaches to identify biomarkers from multimodal imaging big data,9999673,R01MH117107,"['Address', 'Affect', 'Age', 'Algorithms', 'Anterior', 'Antidepressive Agents', 'Area', 'Attention', 'Back', 'Behavioral', 'Benchmarking', 'Big Data', 'Biological', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cell Nucleus', 'Classification', 'Clinical', 'Clinical Data', 'Cognitive', 'Cognitive deficits', 'Collaborations', 'Communities', 'Complement', 'Complex', 'DSM-IV', 'Data', 'Data Pooling', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease remission', 'Electroconvulsive Therapy', 'Engineering', 'Functional disorder', 'Gender', 'Goals', 'ICD-9', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'International', 'Intervention', 'Joints', 'Judgment', 'Knowledge', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Manic', 'Mathematics', 'Measures', 'Medical Care Costs', 'Mental disorders', 'Methods', 'Mining', 'Modality', 'Modeling', 'Moods', 'Multimodal Imaging', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Play', 'Precision Medicine Initiative', 'Probability', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychotic Disorders', 'Recording of previous events', 'Records', 'Recurrence', 'Relapse', 'Reporting', 'Research Personnel', 'Role', 'Schizophrenia', 'Severities', 'Site', 'Structure', 'Supervision', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Translations', 'Treatment Efficacy', 'Treatment outcome', 'Validation', 'Work', 'base', 'biomarker identification', 'cingulate cortex', 'clinical application', 'clinical care', 'clinical practice', 'clinical predictors', 'cognitive ability', 'cohort', 'convolutional neural network', 'data mining', 'data sharing', 'deep field survey', 'deep learning', 'demographics', 'depressed patient', 'disease classification', 'effective intervention', 'feature selection', 'flexibility', 'gray matter', 'high dimensionality', 'improved', 'innovation', 'insight', 'learning strategy', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroimaging marker', 'novel', 'open source', 'optimal treatments', 'outcome forecast', 'outcome prediction', 'patient subsets', 'personalized care', 'personalized predictions', 'predicting response', 'supervised learning', 'tool', 'translational impact', 'translational medicine', 'treatment response', 'white matter']",NIMH,GEORGIA STATE UNIVERSITY,R01,2020,395331,0.15616976188861872
"Data-driven approaches to identify biomarkers from multimodal imaging big data 1. PROJECT SUMMARY/ABSTRACT  The study of translational biomarkers in brain disorders is a very challenging and fruitful approach, which will empower a better understanding of healthy and diseased brains. This project will promote the translation of advanced engineering solutions and mathematic tools to novel neuroimaging applications in psychiatric disorders including major depression disorder (MDD), bipolar disorder (BD) and schizophrenia (SZ), allowing sophisticated and powerful analyses on highly complex datasets. To date, the unifying syndrome classification (ICD-9/10;DSM-IV/5) for these mental disorders obscures our knowledge of underlying pathophysiology and cannot guide optimal treatments. For example, there is no biomarker that is able to precisely predict response of MDD to some treatments. One reason for this is that most neuroimaging prediction studies to date have used a single imaging measure or reported simple correlation relationships, without considering multimodal cross- information, nonlinear relationships, or multi-site cross-validation. Hence, developing novel data mining techniques such as deep learning, fusion with reference, and sparse regression can complement and exploit the richness of neuroimaging data, providing promising avenues to identify objective biomarkers and going beyond a descriptive use of brain imaging as traditionally used in studies of brain disease to individualized prediction. We will facilitate the translational biomarker identification by developing 3 novel data-driven methods: 1) A supervised fusion model that can provide insight on how cognitive impairment may affect covarying brain function and structure in mental disorder, by using different clinical measures as a reference to guide multimodal MRI fusion; 2) A cutting-edge prediction framework with aggregated feature selection techniques that is able to estimate clinical outcome more precisely, e.g., remission/relapse status of individual MDD patient after electroconvulsive treatment(ECT) using baseline brain imaging and demographic measures of 3) We will draw on advances and ideas from deep learning combined with layer-wise relevance propagation (LRP) or attention modules, to classify multiple groups of psychiatric disorders by incorporating dynamic functional measures. The proposed (Deep/Recurrent/Convolutional Neural Network, DNN/RNN/CNN) models will have enhanced interpretability that is able to trace back and discover the most predictive functional networks from input. All above proposed methods will be applied to big data containing both multimodal imaging and behavioral information (n~5000) pooled from existing studies, and our developed open-source toolboxes will be shared publicly. This pioneering study may provide an urgently-needed paradigm shift in the treatment and diagnosis of psychiatric disorders, thereby guiding personalized clinical care. Accomplishment of this project has great potential to discover neuroimaging biomarkers that have been missed by existing approaches, leading to earlier and more effective interventions, and laying the groundwork for a significant translational impact. Project Narrative Psychiatric imaging is struggling with identifying robust biomarkers. Existing approaches do not fully leverage the power of multimodal data, despite evidence that such information is highly informative. We will draw on advances and ideas from fields of deep learning, supervised learning and functional dynamics, to capture rich information from multimodal imaging big data, and to identify precise biomarkers that are able to predict clinical measures for new individuals and help for intervention. We will pool big data from ongoing projects in multiple cohorts, consisting of a big data with imaging and behavioral info to apply clinical applications that will have profound translational medicine impact on schizophrenia, bipolar disorder and major depressive disorders.",Data-driven approaches to identify biomarkers from multimodal imaging big data,9818198,R01MH117107,"['Address', 'Affect', 'Age', 'Algorithms', 'Anterior', 'Antidepressive Agents', 'Area', 'Attention', 'Back', 'Behavioral', 'Benchmarking', 'Big Data', 'Biological', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Cell Nucleus', 'Classification', 'Clinical', 'Clinical Data', 'Cognitive', 'Cognitive deficits', 'Collaborations', 'Communities', 'Complement', 'Complex', 'DSM-IV', 'Data', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease remission', 'Electroconvulsive Therapy', 'Engineering', 'Functional disorder', 'Gender', 'Goals', 'ICD-9', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'International', 'Intervention', 'Joints', 'Judgment', 'Knowledge', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Manic', 'Mathematics', 'Measures', 'Medical Care Costs', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Mining', 'Modality', 'Modeling', 'Moods', 'Multimodal Imaging', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Play', 'Precision Medicine Initiative', 'Probability', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychotic Disorders', 'Recording of previous events', 'Records', 'Recurrence', 'Relapse', 'Reporting', 'Research Personnel', 'Role', 'Schizophrenia', 'Severities', 'Site', 'Structure', 'Supervision', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Translations', 'Treatment Efficacy', 'Treatment outcome', 'Validation', 'Work', 'base', 'biomarker identification', 'cingulate cortex', 'clinical application', 'clinical care', 'clinical practice', 'clinical predictors', 'cognitive ability', 'cohort', 'convolutional neural network', 'data mining', 'data sharing', 'deep field survey', 'deep learning', 'demographics', 'depressed patient', 'disease classification', 'effective intervention', 'flexibility', 'gray matter', 'high dimensionality', 'improved', 'innovation', 'insight', 'learning strategy', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroimaging marker', 'novel', 'open source', 'optimal treatments', 'outcome forecast', 'outcome prediction', 'patient subsets', 'personalized care', 'personalized predictions', 'predicting response', 'supervised learning', 'tool', 'translational impact', 'translational medicine', 'treatment response', 'white matter']",NIMH,GEORGIA STATE UNIVERSITY,R01,2019,399485,0.15616976188861872
"Data-driven approaches to identify biomarkers from multimodal imaging big data 1. PROJECT SUMMARY/ABSTRACT  The study of translational biomarkers in brain disorders is a very challenging and fruitful approach, which will empower a better understanding of healthy and diseased brains. This project will promote the translation of advanced engineering solutions and mathematic tools to novel neuroimaging applications in psychiatric disorders including major depression disorder(MDD), bipolar disorders(BD) and schizophrenia(SZ), allowing sophisticated and powerful analyses on highly complex datasets. To date, the unifying syndrome classification (ICD-9/10;DSM-IV/5) for these mental disorders obscures our knowledge of underlying pathophysiology and cannot guide optimal treatments. For example, there is no biomarker that is able to precisely predict response of MDD to some treatments. One reason lies in that most neuroimaging “prediction” studies to date have used a single imaging measure or reported simple “correlation” relationships, without considering multimodal cross- information, or lack of multi-site validation. Hence, developing novel data mining techniques such as deep learning, fusion with references, and sparse regression etc. can complement and exploit the richness of neuroimaging data, which can be promising avenues to identify objective biomarkers, which goes beyond a more descriptive use of brain imaging as traditionally used in studies of brain diseases. We will develop 3 novel data- driven methods: 1) A supervised fusion model that can provide insight on how cognitive impairment(in SZ) or epigenetic factors (miR-132 dysregulation in MDD) may affect covarying brain function and structure, which uses different clinical measures as reference to guide multimodal MRI fusion; 2) A cutting-edge prediction model that is able to identify imaging biomarkers for precise, individualized prediction of clinical outcomes, e.g., remission status of MDD patients after Electroconvulsive Treatment(ECT). 3) We will draw on advances and ideas from deep neural networks(DNN) combined with layer-wise relevance propagation (LRP), to classify multiple group of psychiatric disorders by using functional connectivity measures, and to trace back the most predictive functional networks from the black box of deep learning by LRP. All above proposed methods will be applied to the big data containing multimodal imaging and behavioral information(n=5000) pooled from existing studies, to investigate biomarkers that can help solve specific clinical difficulties. This pioneering study may provide an urgently-needed paradigm shift in the treatment and diagnosis of psychiatric disorders, thereby guiding personalized clinical care. Accomplishment of this project has great potential to discover neuroimaging biomarkers that have been missed by existing approaches, lead to earlier and more effective interventions, suggesting a significant translational impact. Project Narrative Psychiatric imaging is struggling with identifying robust biomarkers. Existing approaches do not fully leverage the power of multimodal data, despite evidence that such information is highly informative. We will draw on advances and ideas from fields of deep neural networks, supervised learning and dynamic functional information, to capture rich information from multimodal imaging big data, thus identify replicable and precise biomarkers that are able to predict individual clinical measures and help for intervention. We will pool big data from ongoing projects in multiple cohorts, consisting a large imaging and behavioral dataset (n~5000) to apply clinical applications that will have profound translational medicine impact on schizophrenia, bipolar disorder and major depressive disorders.",Data-driven approaches to identify biomarkers from multimodal imaging big data,9733448,R56MH117107,"['Address', 'Affect', 'Anatomy', 'Anterior', 'Antidepressive Agents', 'Area', 'Attention', 'Back', 'Behavior', 'Behavioral', 'Benchmarking', 'Big Data', 'Biological', 'Biological Markers', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'CREB1 gene', 'Classification', 'Clinical', 'Clinical Data', 'Cognitive', 'Cognitive deficits', 'Communities', 'Complement', 'Complex', 'Computer software', 'DSM-IV', 'Data', 'Data Set', 'Decision Making', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease remission', 'Electroconvulsive Therapy', 'Engineering', 'Epigenetic Process', 'Evolution', 'Functional disorder', 'Genes', 'Goals', 'ICD-9', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Individual Differences', 'Intervention', 'Joints', 'Judgment', 'Knowledge', 'Lead', 'Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Manic', 'Mathematics', 'Measures', 'Medical Care Costs', 'Mental Depression', 'Mental disorders', 'Methods', 'Methyl-CpG-Binding Protein 2', 'Modality', 'Modeling', 'Moods', 'Multimodal Imaging', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacology', 'Play', 'Precision Medicine Initiative', 'Prediction of Response to Therapy', 'Psyche structure', 'Psychiatric Diagnosis', 'Psychiatry', 'Psychotic Disorders', 'Recording of previous events', 'Records', 'Relapse', 'Reporting', 'Research Personnel', 'Role', 'Schizoaffective Disorders', 'Schizophrenia', 'Severities', 'Site', 'Structure', 'Supervision', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Translations', 'Treatment Efficacy', 'Validation', 'Work', 'base', 'cingulate cortex', 'clinical application', 'clinical care', 'cohort', 'data mining', 'data sharing', 'deep field survey', 'deep learning', 'deep neural network', 'depressed patient', 'disease classification', 'effective intervention', 'gray matter', 'high dimensionality', 'imaging biomarker', 'imaging modality', 'improved', 'innovation', 'insight', 'multimodality', 'neuroimaging', 'neuroimaging marker', 'novel', 'open source', 'optimal treatments', 'outcome forecast', 'personalized care', 'personalized medicine', 'personalized predictions', 'predict clinical outcome', 'predicting response', 'predictive modeling', 'reduce symptoms', 'relating to nervous system', 'social', 'therapy development', 'tool', 'translational impact', 'translational medicine', 'treatment response']",NIMH,THE MIND RESEARCH NETWORK,R56,2018,453304,0.12419974879862343
"Adapting the Berkeley Big Data Analytics Stack to Genomics and Health Project Summary We propose building a computational platform based on the high performance Berkeley Big Data Analytics Stack (BDAS) to support a new ecosystem of Clinical Decision Support (CDS) applications. This platform will make it faster, easier, and less expensive to develop molecular Clinical Decision Support Systems. These systems require real-time queries of globally distributed data, efficient machine learning on large genomic datasets, and must be secure, fault-tolerant and scalable. BDAS and associated technologies are designed to help us meet these challenges and are therefore ideal building blocks to help us create our computational platform. To encourage the adoption of standards for the querying and sharing of large genomic datasets, we will adapt the BDAS stack to support the standards of the Global Alliance for Genomics and Health (GA4GH). Project Narrative Funding this work will help establish a production quality FOSS implementation of the important Global Alliance for Genomics and Health standards. Without such open-source implementations, a fragmented and proprietary platform ecosystem would slow down innovation as well as divert resources away from the practice of medicine.",Adapting the Berkeley Big Data Analytics Stack to Genomics and Health,9566212,R44GM119858,"['Adoption', 'Algorithms', 'Apache', 'Big Data', 'Big Data to Knowledge', 'Businesses', 'Capital', 'Clinical Decision Support Systems', 'Cloud Computing', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Contractor', 'Data', 'Data Analytics', 'Data Set', 'Distributed Systems', 'Ecosystem', 'Ensure', 'Feedback', 'Funding', 'Genome', 'Genomics', 'Health', 'Individual', 'Industrialization', 'Industry', 'Ingestion', 'Institutes', 'International', 'Leadership', 'Letters', 'Machine Learning', 'Maintenance', 'Measures', 'Medicine', 'Molecular', 'Performance', 'Phase', 'Phenotype', 'Policies', 'Production', 'Provider', 'Publications', 'Resources', 'Running', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'System', 'Technology', 'Time', 'Training', 'Variant', 'Work', 'base', 'clinical decision support', 'cloud platform', 'cluster computing', 'commercialization', 'design', 'distributed data', 'genomic data', 'health care delivery', 'individual patient', 'innovation', 'open source', 'operation', 'petabyte', 'precision medicine', 'symposium', 'web services', 'whole genome']",NIGMS,"CUROVERSE INNOVATIONS, INC.",R44,2018,1069680,0.16104396732516635
"Adapting the Berkeley Big Data Analytics Stack to Genomics and Health Project Summary We propose building a computational platform based on the high performance Berkeley Big Data Analytics Stack (BDAS) to support a new ecosystem of Clinical Decision Support (CDS) applications. This platform will make it faster, easier, and less expensive to develop molecular Clinical Decision Support Systems. These systems require real-time queries of globally distributed data, efficient machine learning on large genomic datasets, and must be secure, fault-tolerant and scalable. BDAS and associated technologies are designed to help us meet these challenges and are therefore ideal building blocks to help us create our computational platform. To encourage the adoption of standards for the querying and sharing of large genomic datasets, we will adapt the BDAS stack to support the standards of the Global Alliance for Genomics and Health (GA4GH). Project Narrative Funding this work will help establish a production quality FOSS implementation of the important Global Alliance for Genomics and Health standards. Without such open-source implementations, a fragmented and proprietary platform ecosystem would slow down innovation as well as divert resources away from the practice of medicine.",Adapting the Berkeley Big Data Analytics Stack to Genomics and Health,9466681,R44GM119858,"['Adoption', 'Algorithms', 'Apache', 'Big Data', 'Big Data to Knowledge', 'Businesses', 'Capital', 'Clinical', 'Clinical Decision Support Systems', 'Cloud Computing', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Contractor', 'Data', 'Data Analytics', 'Data Set', 'Distributed Systems', 'Ecosystem', 'Ensure', 'Feedback', 'Funding', 'Genome', 'Genomics', 'Health', 'Individual', 'Industrialization', 'Industry', 'Ingestion', 'Institutes', 'International', 'Leadership', 'Letters', 'Machine Learning', 'Maintenance', 'Measures', 'Medicine', 'Molecular', 'Performance', 'Phase', 'Phenotype', 'Policies', 'Production', 'Provider', 'Publications', 'Resources', 'Running', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'System', 'Technology', 'Time', 'Training', 'Variant', 'Work', 'base', 'cloud platform', 'cluster computing', 'commercialization', 'design', 'distributed data', 'genomic data', 'health care delivery', 'individual patient', 'innovation', 'open source', 'operation', 'petabyte', 'precision medicine', 'symposium', 'web services', 'whole genome']",NIGMS,"CUROVERSE INNOVATIONS, INC.",R44,2017,1086725,0.16104396732516635
"Big Data, Big Models, and Big Bias?: A decision making framework for vital rate estimates based on extrapolation Project Summary/Abstract The past decades have seen a flurry of methods that use extrapolation, smoothing, and other forms of information sharing to compensate for limited and incomplete data. In places without comprehensive vital registration or public health monitoring systems, extrapolation and information sharing techniques are particularly appealing, since there typically is simply not enough data available to produce estimates with sufficient temporal or spatial resolution to influence public health decision making. This proposal reframes uncertainty in extrapolated estimates of vital rates in terms of decision-making. A decision-making framework (i) is grounded in familiar language for policymakers and public health officials, (ii)characterizes consequential and inconsequential model decisions based on variability in outcomes, and (iii) in- corporates both extrapolation and sampling uncertainty. A cornerstone of this project is a novel collaboration with researchers and policymakers at the World Bank. Through this collaboration, we will pilot the proposed decision-making tools and conduct experiments with local and national policymakers in realistic settings. Project Narrative Predictions based on machine learning models are increasingly common inputs into decision making processes across scientific domains. In this proposal I develop and evaluate strategies for making public health decisions based on predicted vital rates, particularly in places without full coverage civil registration. Results from the project will improve strategies for allocating resources for disease surveillance and health monitoring in scarce resource settings.","Big Data, Big Models, and Big Bias?: A decision making framework for vital rate estimates based on extrapolation",9780910,DP2MH122405,"['Big Data', 'Collaborations', 'Consequentialism', 'Data', 'Decision Making', 'Disease Surveillance', 'Health', 'Language', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Process', 'Public Health', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'System', 'Techniques', 'Uncertainty', 'World Bank', 'base', 'experimental study', 'improved', 'novel', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,DP2,2019,2332500,0.11474198699553156
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9929599,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophagus', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'complex data ', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'immunoregulation', 'improved', 'in vivo', 'lymph nodes', 'machine learning method', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'random forest', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2020,347834,0.207612715074111
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9706046,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'random forest', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2019,347834,0.207612715074111
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9547466,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2018,347834,0.207612715074111
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9383718,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2017,359872,0.207612715074111
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9856493,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'data exchange', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual machine', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,339098,0.165303687204334
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9693030,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,36510,0.165303687204334
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9827788,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,33190,0.165303687204334
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9625823,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,343157,0.165303687204334
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9422475,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2018,356646,0.165303687204334
"Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data Big data is now ubiquitous in every field of modern scientific research. Many contemporary applications, such as the recent national microbiome initiative (NMI), greatly demand highly flexible statistical machine learning methods that can produce both interpretable and reproducible results. Thus, it is of paramount importance to identify crucial causal factors that are responsible for the response from a large number of available covariates, which can be statistically formulated as the false discovery rate (FDR) control in general high-dimensional nonlinear models. Despite the enormous applications of shotgun metagenomic studies, most existing investigations concentrate on the study of bacterial organisms. However, viruses and virus-host interactions play important roles in controlling the functions of the microbial communities. In addition, viruses have been shown to be associated with complex diseases. Yet, investigations into the roles of viruses in human diseases are significantly underdeveloped. The objective of this proposal is to develop mathematically rigorous and computationally efficient approaches to deal with highly complex big data and the applications of these approaches to solve fundamental and important biological and biomedical problems. There are four interrelated aims. In Aim 1, we will theoretically investigate the power of the recently proposed model-free knockoffs (MFK) procedure, which has been theoretically justified to control FDR in arbitrary models and arbitrary dimensions. We will also theoretically justify the robustness of MFK with respect to the misspecification of covariate distribution. These studies will lay the foundations for our developments in other aims. In Aim 2, we will develop deep learning approaches to predict viral contigs with higher accuracy, integrate our new algorithm with MFK to achieve FDR control for virus motif discovery, and investigate the power and robustness of our new procedure. In Aim 3, we will take into account the virus-host motif interactions and adapt our algorithms and theories in Aim 2 for predicting virus-host infectious interaction status. In Aim 4, we will apply the developed methods from the first three aims to analyze the shotgun metagenomics data sets in ExperimentHub to identify viruses and virus-host interactions associated with several diseases at some target FDR level. Both the algorithms and results will be disseminated through the web. The results from this study will be important for metagenomics studies under a variety of environments. Big data is ubiquitous in biological research. Identifying causal factors associated with complex diseases or traits from big data is highly important and challenging. New statistical and computational tools will be developed to control False Discovery Rate (FDR) for molecular sequence data based on the novel model-free knockoffs framework. They will be used to detect sequence motifs for viruses and motif-pairs for virus-host interactions, and to analyze multiple metagenomics data sets related to complex diseases.",Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data,9923688,R01GM131407,"['Address', 'Algorithms', 'Archaea', 'Attention', 'Bacteria', 'Big Data', 'Biological', 'Bypass', 'Cells', 'Colorectal Cancer', 'Complex', 'Computer software', 'Consult', 'Coupled', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Effectiveness', 'Environment', 'Foundations', 'Frequencies', 'Gaussian model', 'Genes', 'Genetic Materials', 'Genomics', 'Healthcare', 'Human', 'Internet', 'Investigation', 'Joints', 'Length', 'Linear Regressions', 'Literature', 'Liver Cirrhosis', 'Mathematics', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Sequence Data', 'Mutation', 'Neurosciences', 'Non-Insulin-Dependent Diabetes Mellitus', 'Non-linear Models', 'Obesity', 'Organism', 'Performance', 'Planet Earth', 'Play', 'Procedures', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Sampling Studies', 'Shotguns', 'Social Sciences', 'Testing', 'Theoretical Studies', 'Tissues', 'Training', 'Viral', 'Virus', 'Visualization software', 'Work', 'base', 'biological research', 'computerized tools', 'contig', 'dark matter', 'deep learning', 'deep learning algorithm', 'design', 'flexibility', 'high dimensionality', 'human disease', 'human tissue', 'improved', 'interest', 'learning strategy', 'machine learning method', 'metagenomic sequencing', 'microbial community', 'microbiome', 'microbiome research', 'model design', 'model development', 'new technology', 'novel', 'power analysis', 'response', 'simulation', 'statistical and machine learning', 'theories', 'trait', 'user-friendly', 'virus host interaction', 'virus identification']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,276700,0.24543223087527163
"Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data Big data is now ubiquitous in every field of modern scientific research. Many contemporary applications, such as the recent national microbiome initiative (NMI), greatly demand highly flexible statistical machine learning methods that can produce both interpretable and reproducible results. Thus, it is of paramount importance to identify crucial causal factors that are responsible for the response from a large number of available covariates, which can be statistically formulated as the false discovery rate (FDR) control in general high-dimensional nonlinear models. Despite the enormous applications of shotgun metagenomic studies, most existing investigations concentrate on the study of bacterial organisms. However, viruses and virus-host interactions play important roles in controlling the functions of the microbial communities. In addition, viruses have been shown to be associated with complex diseases. Yet, investigations into the roles of viruses in human diseases are significantly underdeveloped. The objective of this proposal is to develop mathematically rigorous and computationally efficient approaches to deal with highly complex big data and the applications of these approaches to solve fundamental and important biological and biomedical problems. There are four interrelated aims. In Aim 1, we will theoretically investigate the power of the recently proposed model-free knockoffs (MFK) procedure, which has been theoretically justified to control FDR in arbitrary models and arbitrary dimensions. We will also theoretically justify the robustness of MFK with respect to the misspecification of covariate distribution. These studies will lay the foundations for our developments in other aims. In Aim 2, we will develop deep learning approaches to predict viral contigs with higher accuracy, integrate our new algorithm with MFK to achieve FDR control for virus motif discovery, and investigate the power and robustness of our new procedure. In Aim 3, we will take into account the virus-host motif interactions and adapt our algorithms and theories in Aim 2 for predicting virus-host infectious interaction status. In Aim 4, we will apply the developed methods from the first three aims to analyze the shotgun metagenomics data sets in ExperimentHub to identify viruses and virus-host interactions associated with several diseases at some target FDR level. Both the algorithms and results will be disseminated through the web. The results from this study will be important for metagenomics studies under a variety of environments. Big data is ubiquitous in biological research. Identifying causal factors associated with complex diseases or traits from big data is highly important and challenging. New statistical and computational tools will be developed to control False Discovery Rate (FDR) for molecular sequence data based on the novel model-free knockoffs framework. They will be used to detect sequence motifs for viruses and motif-pairs for virus-host interactions, and to analyze multiple metagenomics data sets related to complex diseases.",Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data,9753295,R01GM131407,"['Address', 'Algorithms', 'Archaea', 'Attention', 'Bacteria', 'Big Data', 'Biological', 'Bypass', 'Cells', 'Colorectal Cancer', 'Complex', 'Computer software', 'Consult', 'Coupled', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Effectiveness', 'Environment', 'Foundations', 'Frequencies', 'Gaussian model', 'Genes', 'Genetic Materials', 'Genomics', 'Healthcare', 'Human', 'Internet', 'Investigation', 'Joints', 'Length', 'Linear Regressions', 'Literature', 'Liver Cirrhosis', 'Machine Learning', 'Marines', 'Mathematics', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Sequence Data', 'Mutation', 'Neurosciences', 'Non-Insulin-Dependent Diabetes Mellitus', 'Non-linear Models', 'Obesity', 'Organism', 'Performance', 'Planet Earth', 'Play', 'Procedures', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Sampling Studies', 'Shotguns', 'Social Sciences', 'Testing', 'Theoretical Studies', 'Tissues', 'Training', 'Viral', 'Virus', 'Visualization software', 'Work', 'base', 'biological research', 'computerized tools', 'contig', 'dark matter', 'deep learning', 'deep learning algorithm', 'design', 'flexibility', 'high dimensionality', 'human disease', 'human tissue', 'improved', 'interest', 'learning strategy', 'metagenomic sequencing', 'microbial community', 'microbiome', 'microbiome research', 'model design', 'model development', 'new technology', 'novel', 'power analysis', 'response', 'simulation', 'theories', 'trait', 'user-friendly', 'virus host interaction', 'virus identification']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,279949,0.24543223087527163
"Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data Big data is now ubiquitous in every field of modern scientific research. Many contemporary applications, such as the recent national microbiome initiative (NMI), greatly demand highly flexible statistical machine learning methods that can produce both interpretable and reproducible results. Thus, it is of paramount importance to identify crucial causal factors that are responsible for the response from a large number of available covariates, which can be statistically formulated as the false discovery rate (FDR) control in general high-dimensional nonlinear models. Despite the enormous applications of shotgun metagenomic studies, most existing investigations concentrate on the study of bacterial organisms. However, viruses and virus-host interactions play important roles in controlling the functions of the microbial communities. In addition, viruses have been shown to be associated with complex diseases. Yet, investigations into the roles of viruses in human diseases are significantly underdeveloped. The objective of this proposal is to develop mathematically rigorous and computationally efficient approaches to deal with highly complex big data and the applications of these approaches to solve fundamental and important biological and biomedical problems. There are four interrelated aims. In Aim 1, we will theoretically investigate the power of the recently proposed model-free knockoffs (MFK) procedure, which has been theoretically justified to control FDR in arbitrary models and arbitrary dimensions. We will also theoretically justify the robustness of MFK with respect to the misspecification of covariate distribution. These studies will lay the foundations for our developments in other aims. In Aim 2, we will develop deep learning approaches to predict viral contigs with higher accuracy, integrate our new algorithm with MFK to achieve FDR control for virus motif discovery, and investigate the power and robustness of our new procedure. In Aim 3, we will take into account the virus-host motif interactions and adapt our algorithms and theories in Aim 2 for predicting virus-host infectious interaction status. In Aim 4, we will apply the developed methods from the first three aims to analyze the shotgun metagenomics data sets in ExperimentHub to identify viruses and virus-host interactions associated with several diseases at some target FDR level. Both the algorithms and results will be disseminated through the web. The results from this study will be important for metagenomics studies under a variety of environments. Big data is ubiquitous in biological research. Identifying causal factors associated with complex diseases or traits from big data is highly important and challenging. New statistical and computational tools will be developed to control False Discovery Rate (FDR) for molecular sequence data based on the novel model-free knockoffs framework. They will be used to detect sequence motifs for viruses and motif-pairs for virus-host interactions, and to analyze multiple metagenomics data sets related to complex diseases.",Adaptive Reproducible High-Dimensional Nonlinear Inference for Big Biological Data,9674585,R01GM131407,"['Address', 'Algorithms', 'Archaea', 'Attention', 'Bacteria', 'Big Data', 'Biological', 'Bypass', 'Cells', 'Colorectal Cancer', 'Complex', 'Computer software', 'Consult', 'Coupled', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Ecosystem', 'Effectiveness', 'Environment', 'Foundations', 'Frequencies', 'Gaussian model', 'Genes', 'Genetic Materials', 'Genomics', 'Healthcare', 'Human', 'Internet', 'Investigation', 'Joints', 'Length', 'Linear Regressions', 'Literature', 'Liver Cirrhosis', 'Machine Learning', 'Marines', 'Mathematics', 'Metagenomics', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Sequence Data', 'Mutation', 'Neurosciences', 'Non-Insulin-Dependent Diabetes Mellitus', 'Non-linear Models', 'Obesity', 'Organism', 'Performance', 'Planet Earth', 'Play', 'Procedures', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Sampling Studies', 'Shotguns', 'Social Sciences', 'Testing', 'Theoretical Studies', 'Tissues', 'Training', 'Viral', 'Virus', 'Visualization software', 'Work', 'base', 'biological research', 'computerized tools', 'dark matter', 'deep learning', 'design', 'flexibility', 'high dimensionality', 'human disease', 'human tissue', 'improved', 'interest', 'learning strategy', 'metagenomic sequencing', 'microbial community', 'microbiome', 'microbiome research', 'model design', 'model development', 'new technology', 'novel', 'power analysis', 'response', 'simulation', 'theories', 'trait', 'user-friendly', 'virus host interaction', 'virus identification']",NIGMS,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,289700,0.24543223087527163
"Characterizing patients at risk for sepsis through Big Data Characterizing Patients at Risk for Sepsis Through Big Data SUMMARY The goal of this KL2 research proposal is create an extension of an existing data-driven sepsis algorithm, the artificial intelligence sepsis expert (AISE), by forecasting the type and sequence of sepsis-specific organ failure using clinical data from the electronic medical record, then identifying the incremental benefit received by adding high-resolution data derived from cardiovascular waveforms (arterial waveform and electrocardiographic waves), and small molecule metabolite data over time to provide some mechanistic context. The most important data (features) used in real-time from AISE will be used as inputs for a fuzzy k- means clustering algorithm (“Saving Organs from Sepsis”, or SOS) using retrospectively-collected data, designed to better characterize patients at risk for sepsis by their organ failure. I have selected three organs in particular: shock, acute respiratory failure, and acute kidney injury (AKI). Principal component analyses (PCA) data from 2,375 ICU patients with sepsis will be projected onto a novel visual representation for patient phenotyping based on risk of (trajectory toward) different types of organ failure. I will identify if this SOS algorithm can accurately forecast new organ failure within 12 hours based on SOS. To better understand the impact of specific features on organ failure, I will test the ability of each high- resolution features, and metabolomics data to forecast septic shock. Among those who develop septic shock, I will measure all nine high-resolution features from the beginning of the ICU stay up to shock onset and compare those changes to those who develop sepsis but not septic shock, and those who do not develop sepsis. I will then see if the collective addition of high-resolution data improves performance of septic shock forecasting. Finally, I will conduct a prospective observational study to collect metabolomic information in a 60- patient study to identify the incremental improvement of adding metabolomics data to SOS for predicting septic shock, over SOS with just EMR and waveform data. The results of this work will provide preliminary data for further career development and NIH-funding. The long-term goal would be to build a model that optimizes the timing of appropriate therapy, thus decreasing the incidence of sepsis and associated organ failure. As a K23 candidate, I will use this award to acquire formal didactic training and more hands-on experience in machine learning, signal processing, metabolomics analysis. I will seek focused training that will complement my experience as a clinical trialist so that I can design high-quality studies to contribute to Big Data analytics in critical care research and practice. My overarching career goal is to become a leader in the application of Big Data analysis of critically ill patients to predict progression of disease, specifically sepsis. The Emory environment is an ideal place to develop these capabilities. Emory Healthcare houses over 200 medical, surgical, and subspecialty ICU beds, many of which are “wired” to store streaming data. In addition to the physical resources, my development will be enhanced by my superb mentorship team, led by Dr. Greg Martin. PROJECT NARRATIVE Sepsis, the body’s response to a life-threatening infection that causes damage to itself, is a leading cause of death in the U.S. and around the world, and failure of vital organs is one of the biggest contributors. This project is designed to predict organ failure specific to sepsis using cutting-edge artificial intelligence technology using readily-available information, and experimental blood tests. The goal is to one day prevent sepsis from happening before it can do permanent, life-threatening damage to patients.",Characterizing patients at risk for sepsis through Big Data,9953611,K23GM137182,"['Acetylcarnitine', 'Acute Renal Failure with Renal Papillary Necrosis', 'Acute respiratory failure', 'Algorithms', 'Arginine', 'Artificial Intelligence', 'Award', 'Beds', 'Big Data', 'Big Data Methods', 'Biological Markers', 'Blood Tests', 'Cardiovascular system', 'Caring', 'Cause of Death', 'Citrulline', 'Classification', 'Clinical', 'Clinical Data', 'Cluster Analysis', 'Complement', 'Computerized Medical Record', 'Critical Care', 'Critical Illness', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Discrimination', 'Disease Progression', 'Early Diagnosis', 'Early treatment', 'Endothelium', 'Environment', 'Etiology', 'Failure', 'Fatty Change', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heart Rate', 'Hospitals', 'Hour', 'Immune', 'Incidence', 'Infection', 'Intensive Care Units', 'Intervention', 'Kynurenine', 'Life', 'Liquid substance', 'Lysophosphatidylcholines', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Medical', 'Mentorship', 'Metabolic', 'Modeling', 'Molecular', 'Morbidity - disease rate', 'N,N-dimethylarginine', 'Nitric Oxide Synthase', 'Observational Study', 'Operative Surgical Procedures', 'Organ', 'Organ failure', 'Outcome', 'Patients', 'Performance', 'Persons', 'Phenotype', 'Physiological', 'Physiology', 'Plasma', 'Prevention', 'Principal Component Analysis', 'Prospective cohort', 'Pulse Pressure', 'Research', 'Research Proposals', 'Resolution', 'Resources', 'Risk', 'Savings', 'Science', 'Sepsis', 'Septic Shock', 'Shock', 'Son of Sevenless Proteins', 'Technology', 'Testing', 'Time', 'Training', 'Troponin', 'United States National Institutes of Health', 'Visual', 'Work', 'amino acid metabolism', 'base', 'blood pressure variability', 'career', 'career development', 'cohort', 'cost', 'data streams', 'data warehouse', 'design', 'experience', 'fatty acid oxidation', 'improved', 'inorganic phosphate', 'machine learning algorithm', 'metabolomics', 'mortality', 'multidisciplinary', 'novel', 'prediction algorithm', 'pressure', 'prevent', 'primary outcome', 'prospective', 'response', 'signal processing', 'skills', 'small molecule', 'specific biomarkers']",NIGMS,EMORY UNIVERSITY,K23,2020,175768,0.09304325942938707
"Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data PROJECT SUMMARY An estimated 47% of Americans 65 years of age and older take statins, which are highly effective in lowering low-density lipoprotein (LDL) cholesterol, preventing atherosclerotic cardiovascular disease (ASCVD), and reducing all-cause mortality. Unfortunately, ~50% of patients prescribed statins do not obtain these critical benefits because they discontinue use within 1 year of treatment initiation. There, Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with ASCVD. In clinical practice, statin-associated symptoms (SAS) often result in dose reduction or discontinuation of these life-saving medications. Currently, physicians employ reactive strategies to manage SAS concerns after they manifest, such as offering an alternative statin treatment plan (e.g., reducing dosage or changing medication) or a `statin holiday'. However, with numerous statin treatment strategies available and no means of optimizing their match to a given patient, physician decision-making is based on minimal patient data elements. Moreover, using a single patient's data to identify the optimal statin regimen and treatment plan is inadequate to ensure that the harms of statin use are minimized and the benefits are maximized. A decision- support system, by contrast, can use a vast number of variables from a large number of patients (“big data”) to match an optimal statin treatment plan to an individual patient prospectively. We propose to use complex patient information to develop and test an effective predictive model and tool, the personalized statin treatment plan (PSTP) platform, which could be used by physicians to optimize personalized statin treatment to minimize harms (SAS and statin discontinuation) while at the same time maximizing benefits (LDL reduction). The proposed study leverages data from the OptumLabs Data Warehouse (which includes more than 20 years of insurance claims and electronic health records data from more than 150 million patients across the United States), as well as clinical trial simulations, for model development, validation, and evaluation. We will address the following specific aims: 1) Develop and validate a deep-learning model to predict both SAS and statin discontinuation using linked insurance claims and EHR data; 2) Develop and validate the PSTP platform to identify statin treatment plans that optimize both LDL reduction (benefit) and SAS and statin discontinuation (harm) for a given patient profile; and 3) Evaluate the PSTP relative to current and guideline-driven practices using CTS to assess clinical benefits and harms. The proposed study will produce a precision-medicine tool to empower physicians to make proactive clinical decisions regarding statin treatment planning (i.e., selecting the statin drug and dosage optimized for a particular patient to maximize LDL reduction and minimize statin discontinuation and SAS) before any statin is prescribed. The implementation of such a tool would substantially improve public health by reducing statin discontinuation and sub-optimal clinical outcomes inherent in current reactive statin-prescribing strategies based on non-personalized statin treatment plans. PROJECT NARRATIVE About 50% of patients prescribed statins do not obtain critical benefits in lowering low-density lipoprotein cholesterol, preventing atherosclerotic cardiovascular disease, and reducing all-cause mortality because they discontinue use within 1 year of treatment initiation largely due to statin-associated symptoms. Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with atherosclerotic cardiovascular disease. The proposed study will produce a personalized (“precision”)-medicine tool using big data to empower physicians to make proactive clinical decisions for prescribing statins that will maximize LDL reduction and minimize statin discontinuation and statin-associated symptoms.",Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data,9869932,R01HL143390,"['Address', 'Adverse event', 'Age-Years', 'Algorithms', 'American', 'Atherosclerosis', 'Big Data', 'Blood', 'Cardiology', 'Characteristics', 'Cholesterol', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Data Element', 'Data Set', 'Decision Making', 'Decision Support Systems', 'Dose', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Evaluation', 'Goals', 'Guidelines', 'Harm Reduction', 'Health Care Costs', 'Holidays', 'Individual', 'Internet', 'LDL Cholesterol Lipoproteins', 'Life', 'Link', 'Low-Density Lipoproteins', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Physicians', 'Positioning Attribute', 'Preventive', 'Public Health', 'Regimen', 'Research', 'Savings', 'Surveys', 'Testing', 'Time', 'Treatment Protocols', 'United States', 'Validation', 'Work', 'associated symptom', 'base', 'clinical practice', 'cohort', 'comorbidity', 'data warehouse', 'deep learning', 'dosage', 'experience', 'improved', 'individual patient', 'insurance claims', 'model development', 'mortality', 'novel', 'personalized intervention', 'personalized medicine', 'precision medicine', 'predictive modeling', 'predictive tools', 'prevent', 'profiles in patients', 'prospective', 'response', 'simulation', 'success', 'tool', 'treatment guidelines', 'treatment planning', 'treatment strategy']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2020,758900,0.06711906451304311
"Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data PROJECT SUMMARY An estimated 47% of Americans 65 years of age and older take statins, which are highly effective in lowering low-density lipoprotein (LDL) cholesterol, preventing atherosclerotic cardiovascular disease (ASCVD), and reducing all-cause mortality. Unfortunately, ~50% of patients prescribed statins do not obtain these critical benefits because they discontinue use within 1 year of treatment initiation. There, Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with ASCVD. In clinical practice, statin-associated symptoms (SAS) often result in dose reduction or discontinuation of these life-saving medications. Currently, physicians employ reactive strategies to manage SAS concerns after they manifest, such as offering an alternative statin treatment plan (e.g., reducing dosage or changing medication) or a `statin holiday'. However, with numerous statin treatment strategies available and no means of optimizing their match to a given patient, physician decision-making is based on minimal patient data elements. Moreover, using a single patient's data to identify the optimal statin regimen and treatment plan is inadequate to ensure that the harms of statin use are minimized and the benefits are maximized. A decision- support system, by contrast, can use a vast number of variables from a large number of patients (“big data”) to match an optimal statin treatment plan to an individual patient prospectively. We propose to use complex patient information to develop and test an effective predictive model and tool, the personalized statin treatment plan (PSTP) platform, which could be used by physicians to optimize personalized statin treatment to minimize harms (SAS and statin discontinuation) while at the same time maximizing benefits (LDL reduction). The proposed study leverages data from the OptumLabs Data Warehouse (which includes more than 20 years of insurance claims and electronic health records data from more than 150 million patients across the United States), as well as clinical trial simulations, for model development, validation, and evaluation. We will address the following specific aims: 1) Develop and validate a deep-learning model to predict both SAS and statin discontinuation using linked insurance claims and EHR data; 2) Develop and validate the PSTP platform to identify statin treatment plans that optimize both LDL reduction (benefit) and SAS and statin discontinuation (harm) for a given patient profile; and 3) Evaluate the PSTP relative to current and guideline-driven practices using CTS to assess clinical benefits and harms. The proposed study will produce a precision-medicine tool to empower physicians to make proactive clinical decisions regarding statin treatment planning (i.e., selecting the statin drug and dosage optimized for a particular patient to maximize LDL reduction and minimize statin discontinuation and SAS) before any statin is prescribed. The implementation of such a tool would substantially improve public health by reducing statin discontinuation and sub-optimal clinical outcomes inherent in current reactive statin-prescribing strategies based on non-personalized statin treatment plans. PROJECT NARRATIVE About 50% of patients prescribed statins do not obtain critical benefits in lowering low-density lipoprotein cholesterol, preventing atherosclerotic cardiovascular disease, and reducing all-cause mortality because they discontinue use within 1 year of treatment initiation largely due to statin-associated symptoms. Statin discontinuation has been identified as a major public-health concern due to increased morbidity, mortality, and healthcare costs associated with atherosclerotic cardiovascular disease. The proposed study will produce a personalized (“precision”)-medicine tool using big data to empower physicians to make proactive clinical decisions for prescribing statins that will maximize LDL reduction and minimize statin discontinuation and statin-associated symptoms.",Personalized Statin Treatment Plan to Optimize Clinical Outcomes Using Big Data,9684080,R01HL143390,"['Address', 'Adverse event', 'Age-Years', 'Algorithms', 'American', 'Atherosclerosis', 'Big Data', 'Blood', 'Cardiology', 'Characteristics', 'Cholesterol', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Comorbidity', 'Complex', 'Data', 'Data Element', 'Data Set', 'Decision Making', 'Decision Support Systems', 'Dose', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Evaluation', 'Goals', 'Guidelines', 'Harm Reduction', 'Health Care Costs', 'Holidays', 'Individual', 'Internet', 'LDL Cholesterol Lipoproteins', 'Life', 'Link', 'Low-Density Lipoproteins', 'Machine Learning', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Physicians', 'Positioning Attribute', 'Preventive', 'Public Health', 'Regimen', 'Research', 'Savings', 'Surveys', 'Testing', 'Time', 'Treatment Protocols', 'United States', 'Validation', 'Work', 'associated symptom', 'base', 'clinical practice', 'cohort', 'data warehouse', 'deep learning', 'dosage', 'experience', 'improved', 'individual patient', 'insurance claims', 'model development', 'mortality', 'novel', 'personalized intervention', 'personalized medicine', 'precision medicine', 'predictive modeling', 'predictive tools', 'prevent', 'profiles in patients', 'prospective', 'response', 'simulation', 'success', 'tool', 'treatment guidelines', 'treatment planning', 'treatment strategy']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2019,782736,0.06711906451304311
"Transforming Analytical Learning in the Era of Big Data PROJECT SUMMARY In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio)statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field of health big data. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offers and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will primarily draw from the expertise and experience of faculty from three different departments within three different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science, Medicine, Population Health, Social and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including statistical modeling, data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high- dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and medical imaging. The diseases and conditions they study include obesity, diabetes, cardiovascular disease, cancer, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and success with the current summer program on Big Data led by this team with 164 students trained in the last 4 years (2015-2018) including 90 female students and 30 students from underrepresented minority groups. Fourteen of these participants from the last three years are currently graduate students in Michigan Biostatistics. The ongoing program has gained traction in the national landscape of summer research programs with 20% rate of admission and 80% rate of acceptance among those who are offered this opportunity. The program has consistently received very strong evaluation and our past alumni have become brand ambassadors and advocates for our program. We plan to build on the success and legacy of this program in the next three year funding cycle of this grant (2019-2021). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 45 undergraduates nationally and internationally, with 20 domestic students supported by the requested SIBS funding mechanism and others supported by supplementary institutional and foundation support. We propose to expose the trainees to diverse techniques, skills and problems in the field of health Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. They will engage in mentored research projects in three primary areas of health big data: Electronic Health Records/Medical Claims, Genomics and Imaging. Some of the projects will be defined in the area of cardiovascular precision medicine, defined by a team of highly quantitative researchers engaged in cardiovascular research that uses big data. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by U-M researchers, outside guests and a professional development workshop to prepare the students for graduate school. We propose an inter-SIBS collaboration with Dordt College summer program trainees who will attend this concluding symposium. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. We will offer multiple professional development opportunities and resources for graduate school preparation to our trainees so that they can reflect and plan beyond their senior year. All of our proposed activities are reflected through our three specific aims: Teaching, Mentoring and Dissemination. PROJECT NARRATIVE We propose a six week long undergraduate summer institute: “Transforming Analytical Learning in the Era of Big Data” to be held at the Department of Biostatistics, University of Michigan (U-M), Ann Arbor, with a group of approximately 45 undergraduate students recruited nationally and internationally, from 2019-2021. Funding is requested for 20 domestic students with supplementary funding expected to be garnered through institutional resources and private foundation support. The program builds on the success of our existing Big Data Summer Institute (BDSI) supported by a NIH BD2K Courses and Skills grant award that is ending in 2018. We plan to expose program students to diverse techniques, skills and problems in the field of Big Data and Human Health. We enhance our ongoing summer program structure in the current proposal by involving a team of researchers working at the intersection of cardiovascular research and data science with a focus on cardiovascular precision medicine where some of the new mentored research projects will be defined. We primarily focus on three genres of health Big Data arising in Electronic Health Records/Medical Claims, Genomics and Imaging. The trainees will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Computational Medicine and Bioinformatics, Statistics, Computer Science and Engineering, Information Sciences, Epidemiology and Medicine, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by (U-M) researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm and engage them in influential research related to human health.",Transforming Analytical Learning in the Era of Big Data,9888408,R25HL147207,"['Admission activity', 'Adverse drug effect', 'Advocate', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Award', 'Basic Science', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Sciences', 'Code', 'Collaborations', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Epidemiology', 'Epigenetic Process', 'Evaluation', 'Exposure to', 'Faculty', 'Female', 'Foundations', 'Funding', 'Funding Mechanisms', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Human', 'Image', 'Influentials', 'Information Sciences', 'Injury', 'International', 'Kidney Diseases', 'Learning', 'Literature', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical Records', 'Medicine', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Minority Groups', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Prevention', 'Privatization', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'STEM program', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Social Behavior', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Structure', 'Student recruitment', 'Students', 'Talents', 'Techniques', 'Traction', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'base', 'big-data science', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'data visualization', 'design', 'experience', 'graduate school preparation', 'graduate student', 'heterogenous data', 'high dimensionality', 'instructor', 'interest', 'lectures', 'medical schools', 'member', 'metabolomics', 'nervous system disorder', 'network models', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'population health', 'posters', 'precision medicine', 'programs', 'recruit', 'signal processing', 'skills', 'statistical and machine learning', 'statistics', 'student training', 'success', 'summer institute', 'summer program', 'summer research', 'symposium', 'tool', 'undergraduate student', 'underrepresented minority student', 'wiki']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2020,250974,0.25678550448117465
"Transforming Analytical Learning in the Era of Big Data PROJECT SUMMARY In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio)statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field of health big data. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offers and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will primarily draw from the expertise and experience of faculty from three different departments within three different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science, Medicine, Population Health, Social and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including statistical modeling, data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high- dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and medical imaging. The diseases and conditions they study include obesity, diabetes, cardiovascular disease, cancer, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and success with the current summer program on Big Data led by this team with 164 students trained in the last 4 years (2015-2018) including 90 female students and 30 students from underrepresented minority groups. Fourteen of these participants from the last three years are currently graduate students in Michigan Biostatistics. The ongoing program has gained traction in the national landscape of summer research programs with 20% rate of admission and 80% rate of acceptance among those who are offered this opportunity. The program has consistently received very strong evaluation and our past alumni have become brand ambassadors and advocates for our program. We plan to build on the success and legacy of this program in the next three year funding cycle of this grant (2019-2021). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 45 undergraduates nationally and internationally, with 20 domestic students supported by the requested SIBS funding mechanism and others supported by supplementary institutional and foundation support. We propose to expose the trainees to diverse techniques, skills and problems in the field of health Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. They will engage in mentored research projects in three primary areas of health big data: Electronic Health Records/Medical Claims, Genomics and Imaging. Some of the projects will be defined in the area of cardiovascular precision medicine, defined by a team of highly quantitative researchers engaged in cardiovascular research that uses big data. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by U-M researchers, outside guests and a professional development workshop to prepare the students for graduate school. We propose an inter-SIBS collaboration with Dordt College summer program trainees who will attend this concluding symposium. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. We will offer multiple professional development opportunities and resources for graduate school preparation to our trainees so that they can reflect and plan beyond their senior year. All of our proposed activities are reflected through our three specific aims: Teaching, Mentoring and Dissemination. PROJECT NARRATIVE We propose a six week long undergraduate summer institute: “Transforming Analytical Learning in the Era of Big Data” to be held at the Department of Biostatistics, University of Michigan (U-M), Ann Arbor, with a group of approximately 45 undergraduate students recruited nationally and internationally, from 2019-2021. Funding is requested for 20 domestic students with supplementary funding expected to be garnered through institutional resources and private foundation support. The program builds on the success of our existing Big Data Summer Institute (BDSI) supported by a NIH BD2K Courses and Skills grant award that is ending in 2018. We plan to expose program students to diverse techniques, skills and problems in the field of Big Data and Human Health. We enhance our ongoing summer program structure in the current proposal by involving a team of researchers working at the intersection of cardiovascular research and data science with a focus on cardiovascular precision medicine where some of the new mentored research projects will be defined. We primarily focus on three genres of health Big Data arising in Electronic Health Records/Medical Claims, Genomics and Imaging. The trainees will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Computational Medicine and Bioinformatics, Statistics, Computer Science and Engineering, Information Sciences, Epidemiology and Medicine, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by (U-M) researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm and engage them in influential research related to human health.",Transforming Analytical Learning in the Era of Big Data,9733542,R25HL147207,"['Admission activity', 'Adverse drug effect', 'Advocate', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Award', 'Basic Science', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Sciences', 'Code', 'Collaborations', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Epidemiology', 'Epigenetic Process', 'Evaluation', 'Exposure to', 'Faculty', 'Female', 'Foundations', 'Funding', 'Funding Mechanisms', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Human', 'Image', 'Influentials', 'Information Sciences', 'Injury', 'International', 'Kidney Diseases', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical Records', 'Medicine', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Minority Groups', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Prevention', 'Privatization', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'STEM program', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Social Behavior', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Structure', 'Student recruitment', 'Students', 'Talents', 'Techniques', 'Traction', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'data visualization', 'design', 'experience', 'graduate school preparation', 'graduate student', 'high dimensionality', 'instructor', 'interest', 'lectures', 'medical schools', 'member', 'metabolomics', 'nervous system disorder', 'network models', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'population health', 'posters', 'precision medicine', 'programs', 'recruit', 'signal processing', 'skills', 'statistics', 'student training', 'success', 'summer institute', 'summer program', 'summer research', 'symposium', 'tool', 'undergraduate student', 'underrepresented minority student', 'wiki']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2019,250974,0.25678550448117465
"Big Data Predictive Phylogenetics with Bayesian Learning Big Data Predictive Phylogenetics with Bayesian Learning Abstract Andrew Holbrook, Ph.D., is a Bayesian statistician with a broad background in applied, theoretical and compu- tational data science. His proposed research Big Data Predictive Phylogenetics with Bayesian Learning tackles viral outbreak forecasting by combining Bayesian phylogenetic modeling with ﬂexible, `self-exciting' stochastic process models. The development and publication of open-source, high-performance computing software for his models will facilitate fast epidemiological ﬁeld response in a big data setting. Dr. Holbrook will apply his method- ology to the reconstruction of the 2015-2016 Zika virus epidemic in the Americas, focusing on identifying key geographical routes of transmission and phylogenetic clades with enhanced infectiousness.  Candidate: Dr. Holbrook is Postdoctoral Scholar at the UCLA Department of Human Genetics. He earned his Ph.D. in Statistics from the Department of Statistics at UC Irvine, during which time he completed his dissertation Geometric Bayes, an investigation into Bayesian modeling and computing on abstract mathematical spaces, and simultaneously participated in scientiﬁc collaborations at the UC Irvine Alzheimer's Disease Research Center. The proposed career development plan will establish Dr. Holbrook as an independent leader in data intensive viral epidemiology by 1) facilitating coursework to build biological domain knowledge, 2) affording Dr. Holbrook the opportunity to lead his own project while remaining under the expert oversight of UCLA Prof. Marc Suchard, M.D., Ph.D., and 3) allowing Dr. Holbrook to continue his focus on quantitative viral epidemiology once he has moved to a faculty commitment.  Mentors: During the ﬁrst three years of the award period, Dr. Holbrook will work closely with Prof. Suchard, continuing their current schedule of weekly meetings. Prof. Suchard is a leading expert in both Bayesian phylo- genetics and high-performance statistical computing; and with his medical background, Prof. Suchard will advise Dr. Holbrook in his expansion of domain knowledge in viral epidemiology. As secondary mentor, Prof. Kristian Andersen, Ph.D., of the Scripps Institute will advise Dr. Holbrook in the impactful application of his statistical and computational methodologies to the 2015-2016 Zika virus epidemic. Dr. Holbrook and Profs. Suchard and Andersen will maintain their collaborations after the postdoctoral period.  Research: Bayesian phylogenetics successfully reconstructs evolutionary histories but fails to predict viral spread. Self-exciting point processes are devoid of biological insight and fail to account for geographic networks of diffusion. Aim 1 addresses deﬁciencies in these two complementary viral epidemiological modeling techniques by innovating a combined model where the phylogenetic and self-excitatory components support each other. Aim 2 makes widespread adoption a reality by publishing open-source, massively parallel computing software suitable for big data analysis. Aim 3 reconstructs the 2015-2016 Zika epidemic, learns key geographical routes of transmission and identiﬁes phylogenetic clades with enhanced infectiousness. Project Narrative Tracking and predicting viral outbreaks remains an open epidemiological problem with deadly consequences. Dr. Holbrook will attack the problem with his Bayesian phylogenetic Hawkes processes, a class of models tailored to simultaneously reconstruct evolutionary histories and predict viral diffusion dynamics. With the mentorship of Profs. Marc Suchard (primary) and Kristian Andersen (secondary), Dr. Holbrook will develop open-source, high-performance computing software and apply his statistical computing methodology to the analysis of the 2015-2016 Zika virus epidemic of the Americas, learning key routes of transmission and identifying phylogenetic clades with enhanced infectiousness.",Big Data Predictive Phylogenetics with Bayesian Learning,10039150,K25AI153816,"['Accounting', 'Address', 'Adoption', 'Air', 'Alzheimer&apos', 's Disease', 'Americas', 'Award', 'Bayesian Modeling', 'Bayesian learning', 'Behavior', 'Big Data', 'Biological', 'Biology', 'Collaborations', 'Complex', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Dangerousness', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Development Plans', 'Diffusion', 'Disease Outbreaks', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evolution', 'Faculty', 'Failure', 'Free Will', 'Generations', 'Geography', 'Goals', 'Health', 'Herd Immunity', 'High Performance Computing', 'Human Genetics', 'Individual', 'Influenza', 'Institutes', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Mathematics', 'Medical', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Process', 'Publications', 'Publishing', 'Recording of previous events', 'Research', 'Route', 'Schedule', 'Scientist', 'Ships', 'Speed', 'Statistical Computing', 'Stochastic Processes', 'Structure', 'Techniques', 'Testing', 'Time', 'Travel', 'Viral', 'Viral Epidemiology', 'Viral Physiology', 'Work', 'ZIKA', 'Zika Virus', 'blind', 'career development', 'epidemiological model', 'flexibility', 'innovation', 'insight', 'meetings', 'novel', 'open source', 'parallel computer', 'pathogen', 'reconstruction', 'response', 'statistics', 'transmission process']",NIAID,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2020,106467,0.28099743061988885
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,9015770,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'genomic data', 'heuristics', 'mathematical analysis']",NCI,BROWN UNIVERSITY,R01,2016,71329,0.06523638344779022
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,8825472,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'heuristics', 'mathematical analysis', 'transcriptome sequencing']",NCI,BROWN UNIVERSITY,R01,2015,71329,0.06523638344779022
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8840551,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'genetic variant', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,219004,0.1587114173378298
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8642168,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,207764,0.1587114173378298
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8599826,R01CA180777,"['Bees', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,214832,0.1587114173378298
"From Terabytes of Pixels to Intuitive Brain Networks ﻿    DESCRIPTION (provided by applicant): In the midst of a connectomics zeitgeist, microscopy images are collected at an unprecedented rate. The amount of data collected is so overwhelming that it is a challenge for researchers to extract the organizational information of the neural networks embedded within. Developing software that provides researchers intuitive visual representations of their connections of interest would greatly aid them to generate testable hypotheses regarding the functional significance of neural networks -- the impetus for creating the mammalian connectome in the first place. The primary and initial challenge toward developing such a visualization system is the daunting task of thoroughly and reliably quantifying the enormous amount of image data. Achieving this without significant computational aid is intractable. Although algorithms for registering images and automatically reconstructing neuronal processes and axonal pathways for analysis of data exist, they are not efficient for connectivity Big Data given their protracted processing times. Utilizing the data fro the Mouse Connectome Project (MCP) at USC, we developed a beta version of Connection Lens, an innovative informatics pipeline for efficiently and expediently warping, segmenting, and quantifying connectivity data. We have successfully applied Connection Lens toward a limited set of our microscopy image data and we propose to extend its functionality to process our entire archive. Furthermore, leveraging our Connection Lens quantified data we propose to develop a complementary visualization web application. Called Projection Lens, it will render publishable visualizations of user specified connections of interest as connectivity maps, adjacency matrices, network graphs, and flatmaps. Similar to a roadmap, the program will be equipped to show all possible routes between two regions of interest and illustrate how a dysfunctioning node will affect overall information flow within the network. These features will empower researchers to quickly browse, comprehend, and publish fundamental findings regarding functionally distinct neural networks, thereby maximizing the utility of connectomics data nested in terabytes of microscopy scans. The web-based interface of Projection Lens will grant easy access to scientists world-wide. In addition, the code developed for the Connection/Projection Lens (C/PL) framework will be published freely online, and released via an open source license enabling other laboratories to quantify and visualize their data. PUBLIC HEALTH RELEVANCE: As the BRAIN Initiative gains momentum, brain connectivity data is being generated at an unprecedented rate, compiling overwhelming archives of microscopy images embedded with valuable information regarding brain network organization. Our innovative software, Connection/Projection Lens, will reliably and efficiently quantify and visualize these connectivity Big Data, leading to testable hypotheses regarding the functional significance of brain networks. Consequently, this software will facilitate our understanding of how information is processed within specific neural circuits and how this influences cognition and behavior under conditions of health and disease.",From Terabytes of Pixels to Intuitive Brain Networks,9277436,U01CA198932,"['Affect', 'Algorithms', 'Archives', 'Atlases', 'BRAIN initiative', 'Behavior', 'Big Data', 'Biological Neural Networks', 'Brain', 'Code', 'Cognition', 'Communities', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Electronic Mail', 'Goals', 'Grant', 'Graph', 'Health', 'Image', 'Imagery', 'Informatics', 'Information Networks', 'Intuition', 'Investigation', 'Laboratories', 'Lens development', 'Lesion', 'Licensing', 'Maps', 'Methods', 'Microscopy', 'Mus', 'Neurons', 'Online Systems', 'Outcome', 'Output', 'Pathway Analysis', 'Pathway interactions', 'Phase', 'Process', 'Production', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Route', 'Scanning', 'Science', 'Scientist', 'Semantics', 'Specific qualifier value', 'Structure', 'System', 'Time', 'Visual', 'base', 'big biomedical data', 'connectome', 'data visualization', 'design', 'image archival system', 'improved', 'indexing', 'information organization', 'innovation', 'interest', 'lens', 'light microscopy', 'microscopic imaging', 'neural circuit', 'open source', 'programs', 'public health relevance', 'reconstruction', 'response', 'software development', 'terabyte', 'web app', 'web based interface']",NCI,UNIVERSITY OF SOUTHERN CALIFORNIA,U01,2017,494506,0.07238868445225242
"Drug Repurposing for Cancer Therapy: From Man to Molecules to Man Abstract This project aims to develop and implement multiple but integrated computational tools for drug repurposing by exploiting complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records), electronic databases of chemical-biological interactions and pathways, and laboratory data (biological screening of chemical libraries). We expect that tools to be developed in this project will be useful for repurposing observational textual data for research projects (addressing the second challenge of the underlying RFA). In addition, the envisioned translation of this data into a format amenable to quantitative modeling of drug effects will also enable integration of textual and laboratory data to create minable metadata (cf. the third challenge). Project Narrative  This project aims to develop and implement computational tools for drug repurposing by exploiting two complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records) and laboratory data (biological screening of chemical libraries). The proposed tools and underlying computational framework will employ observational human data together with experimental bioactivity data to discover and validate novel therapeutic applications of existing drugs, i.e., following the knowledge discovery path from man to molecules to man.",Drug Repurposing for Cancer Therapy: From Man to Molecules to Man,9548186,U01CA207160,"['Address', 'Adverse drug effect', 'Animal Cancer Model', 'Big Data', 'Biological', 'Biological Assay', 'Biological Models', 'Cancer Patient', 'Cells', 'Chemicals', 'Clinical Trials', 'Collection', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Disease', 'Docking', 'Drug Modelings', 'Drug Targeting', 'Electronic Health Record', 'Generations', 'Goals', 'Human', 'In Vitro', 'Internet', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Link', 'Literature', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Names', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Physicians', 'PubChem', 'PubMed', 'Publications', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Research Project Grants', 'Semantics', 'Source', 'Stream', 'Structure', 'Technology', 'Text', 'Therapeutic Effect', 'Translations', 'Validation', 'base', 'cancer therapy', 'cognitive computing', 'computer based Semantic Analysis', 'computer framework', 'computer studies', 'computerized tools', 'drug candidate', 'genomic data', 'health record', 'high reward', 'human data', 'in vivo', 'man', 'molecular modeling', 'new therapeutic target', 'novel', 'novel therapeutics', 'pre-clinical', 'repository', 'screening', 'small molecule libraries', 'social media', 'text searching', 'tool', 'virtual']",NCI,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2018,335618,0.06638118039077473
"Drug Repurposing for Cancer Therapy: From Man to Molecules to Man Abstract This project aims to develop and implement multiple but integrated computational tools for drug repurposing by exploiting complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records), electronic databases of chemical-biological interactions and pathways, and laboratory data (biological screening of chemical libraries). We expect that tools to be developed in this project will be useful for repurposing observational textual data for research projects (addressing the second challenge of the underlying RFA). In addition, the envisioned translation of this data into a format amenable to quantitative modeling of drug effects will also enable integration of textual and laboratory data to create minable metadata (cf. the third challenge). Project Narrative  This project aims to develop and implement computational tools for drug repurposing by exploiting two complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records) and laboratory data (biological screening of chemical libraries). The proposed tools and underlying computational framework will employ observational human data together with experimental bioactivity data to discover and validate novel therapeutic applications of existing drugs, i.e., following the knowledge discovery path from man to molecules to man.",Drug Repurposing for Cancer Therapy: From Man to Molecules to Man,9337383,U01CA207160,"['Address', 'Adverse drug effect', 'Animal Cancer Model', 'Big Data', 'Biological', 'Biological Assay', 'Biological Models', 'Cancer Patient', 'Cells', 'Chemicals', 'Clinical Trials', 'Cognitive', 'Collection', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Disease', 'Docking', 'Drug Modelings', 'Drug Targeting', 'Electronic Health Record', 'Generations', 'Goals', 'Human', 'In Vitro', 'Internet', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Link', 'Literature', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Models', 'Names', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Physicians', 'PubChem', 'PubMed', 'Publications', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Research Project Grants', 'Semantics', 'Source', 'Stream', 'Structure', 'Technology', 'Text', 'Therapeutic Effect', 'Translations', 'Validation', 'base', 'cancer therapy', 'computer based Semantic Analysis', 'computer framework', 'computer studies', 'computerized tools', 'drug candidate', 'genomic data', 'health record', 'high reward', 'human data', 'in vivo', 'man', 'new therapeutic target', 'novel', 'novel therapeutics', 'pre-clinical', 'repository', 'screening', 'small molecule libraries', 'social media', 'text searching', 'tool', 'virtual']",NCI,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2017,417119,0.06638118039077473
"Drug Repurposing for Cancer Therapy: From Man to Molecules to Man Abstract This project aims to develop and implement multiple but integrated computational tools for drug repurposing by exploiting complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records), electronic databases of chemical-biological interactions and pathways, and laboratory data (biological screening of chemical libraries). We expect that tools to be developed in this project will be useful for repurposing observational textual data for research projects (addressing the second challenge of the underlying RFA). In addition, the envisioned translation of this data into a format amenable to quantitative modeling of drug effects will also enable integration of textual and laboratory data to create minable metadata (cf. the third challenge). Project Narrative  This project aims to develop and implement computational tools for drug repurposing by exploiting two complimentary big data streams, i.e., unstructured texts (social media networks, published biomedical literature, and electronic health records) and laboratory data (biological screening of chemical libraries). The proposed tools and underlying computational framework will employ observational human data together with experimental bioactivity data to discover and validate novel therapeutic applications of existing drugs, i.e., following the knowledge discovery path from man to molecules to man.",Drug Repurposing for Cancer Therapy: From Man to Molecules to Man,9161354,U01CA207160,"['Address', 'Adverse drug effect', 'Animal Cancer Model', 'Antineoplastic Agents', 'Big Data', 'Biological', 'Biological Assay', 'Cancer Patient', 'Cells', 'Chemicals', 'Clinical Trials', 'Cognitive', 'Collection', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Disease', 'Docking', 'Drug Targeting', 'Electronic Health Record', 'Electronics', 'Generations', 'Goals', 'Human', 'In Vitro', 'Internet', 'Knowledge Discovery', 'Label', 'Laboratories', 'Language', 'Link', 'Literature', 'Malignant Childhood Neoplasm', 'Malignant Neoplasms', 'Medical', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Models', 'Names', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase II Clinical Trials', 'Physicians', 'PubChem', 'PubMed', 'Publications', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Research Project Grants', 'Semantics', 'Source', 'Stream', 'Structure', 'Technology', 'Text', 'Therapeutic Effect', 'Translations', 'Validation', 'abstracting', 'base', 'cancer therapy', 'computer based Semantic Analysis', 'computer framework', 'computer studies', 'computerized tools', 'drug candidate', 'genomic data', 'health record', 'high reward', 'human data', 'in vivo', 'man', 'molecular modeling', 'new therapeutic target', 'novel', 'novel therapeutics', 'pre-clinical', 'repository', 'screening', 'small molecule libraries', 'social media', 'text searching', 'tool', 'virtual']",NCI,UNIV OF NORTH CAROLINA CHAPEL HILL,U01,2016,437810,0.06638118039077473
"A Big Data Approach to BCR ABL Leukemias BCR-ABL1 positive leukemias account for a substantial portion of adult leukemia. Tyrosine kinase  inhibitors (TKIs) have dramatically changed survival outlook. However, current protocols recommend  patients receive TKI chemotherapy agents indefinitely, causing long-term toxicity and substantive  quality of life deficits, leading to decreased TKI compliance. Moreover, >50% of patients who stop  TKIs ultimately relapse and are not as responsive to post-relapse treatment; additionally, mutation  resistance is becoming an increasing issue with TKIs as patients live longer. It is hypothesized  patient heterogeneity within BCR-ABL1 leukemias are a major driving factor on outcome and strongly  influences optimal TKI selection and cessation. However, small cohort size and disease rarity has  impacted large, pragmatic clinical trials, necessitating a big data approach. The overall goal is  to quilt together individual studies to produce a comprehensive view of BCR-ABL1 leukemias that  includes epidemiology, etiology, assessment, and therapy, as well their inter-relationships. With  a comprehensive view, personalized, predictive medicine becomes possible. This project utilizes  literature mining and “big data” techniques to analyze four major categories: epidemiology (who  gets BCR-ABL1 leukemias, how response correlates to patient characteristics, etc.); etiology (what  factors trigger mutation, mechanisms to improve TKI specificity, preclinical model metrics,  prognostic indicators of recurrence/relapse, etc.); assessment (identifying new  diagnostic/prognostic metrics, improving polymerase chain reaction (PCR) protocols, objective  staging criteria); and treatment (aggregate effect sizes among different therapies, short and  long-term side effect profiles, TKI selection protocols, adjunctive and combination therapies,  criteria for TKI cessation, etc.). The specific aims of the project include: 1) prototype a data  path and construct infrastructure for BCR-ABL1 data curation from literature and/or clinical  sources; 2) construct literature ontological field map to quantify topic depth, aggregate data, and  identify relationships within and between categories; 3) perform exploratory analysis to assess  aggregate statistical power and prototype predictive models for TKI optimization. In summary, the  present project delivers a 21st century, big data approach for BCR-ABL1 leukemia to optimize  clinical management and expedite basic preclinical research. This project is highly relevant to public health as it enables a comprehensive view of BCR ABL  positive leukemia(s) that can optimize clinical management and expedite preclinical research.",A Big Data Approach to BCR ABL Leukemias,9869875,R21CA232249,"['ABL1 gene', 'Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Animal Model', 'Automobile Driving', 'Award', 'Big Data', 'Cancer Etiology', 'Case Study', 'Categories', 'Cessation of life', 'Characteristics', 'Chronic', 'Chronic Myeloid Leukemia', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Trials', 'Cohort Studies', 'Combined Modality Therapy', 'Complex', 'Cytogenetics', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Set', 'Databases', 'Decision Modeling', 'Dimensions', 'Engineering', 'Epidemiology', 'Etiology', 'Foundations', 'Frequencies', 'Functional disorder', 'Future', 'Goals', 'Heterogeneity', 'Human Resources', 'Individual', 'Informatics', 'Infrastructure', 'Institutes', 'Kidney', 'Life', 'Literature', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Medicine', 'Meta-Analysis', 'Modeling', 'Mutation', 'Oncogenes', 'Ontology', 'Outcome', 'Pancreas', 'Patient-Focused Outcomes', 'Patients', 'Polymerase Chain Reaction', 'Pragmatic clinical trial', 'Pre-Clinical Model', 'Prognostic Marker', 'Protocols documentation', 'Public Health', 'Publishing', 'Quadriplegia', 'Quality of life', 'Rare Diseases', 'Recurrence', 'Relapse', 'Research Personnel', 'Resistance', 'Retrospective Studies', 'Risk Assessment', 'Sample Size', 'Semantics', 'Source', 'Specificity', 'Staging', 'Techniques', 'Time', 'Toxic effect', 'Tyrosine Kinase Inhibitor', 'Universities', 'Wheelchairs', 'adult leukemia', 'base', 'cancer type', 'chemotherapy', 'cohort', 'comparative', 'compliance behavior', 'data curation', 'data mining', 'database schema', 'disability', 'disorder risk', 'drug intolerance', 'epidemiology study', 'experience', 'improved', 'innovation', 'leukemia', 'lexical', 'novel', 'novel diagnostics', 'personalized predictions', 'population based', 'pre-clinical', 'pre-clinical research', 'predictive modeling', 'prognostic', 'prototype', 'rare cancer', 'relational database', 'resistance mutation', 'response', 'side effect', 'text searching', 'treatment duration']",NCI,GEORGIA INSTITUTE OF TECHNOLOGY,R21,2020,190454,0.15688994957451854
"A Big Data Approach to BCR ABL Leukemias BCR-ABL1 positive leukemias account for a substantial portion of adult leukemia. Tyrosine kinase  inhibitors (TKIs) have dramatically changed survival outlook. However, current protocols recommend  patients receive TKI chemotherapy agents indefinitely, causing long-term toxicity and substantive  quality of life deficits, leading to decreased TKI compliance. Moreover, >50% of patients who stop  TKIs ultimately relapse and are not as responsive to post-relapse treatment; additionally, mutation  resistance is becoming an increasing issue with TKIs as patients live longer. It is hypothesized  patient heterogeneity within BCR-ABL1 leukemias are a major driving factor on outcome and strongly  influences optimal TKI selection and cessation. However, small cohort size and disease rarity has  impacted large, pragmatic clinical trials, necessitating a big data approach. The overall goal is  to quilt together individual studies to produce a comprehensive view of BCR-ABL1 leukemias that  includes epidemiology, etiology, assessment, and therapy, as well their inter-relationships. With  a comprehensive view, personalized, predictive medicine becomes possible. This project utilizes  literature mining and “big data” techniques to analyze four major categories: epidemiology (who  gets BCR-ABL1 leukemias, how response correlates to patient characteristics, etc.); etiology (what  factors trigger mutation, mechanisms to improve TKI specificity, preclinical model metrics,  prognostic indicators of recurrence/relapse, etc.); assessment (identifying new  diagnostic/prognostic metrics, improving polymerase chain reaction (PCR) protocols, objective  staging criteria); and treatment (aggregate effect sizes among different therapies, short and  long-term side effect profiles, TKI selection protocols, adjunctive and combination therapies,  criteria for TKI cessation, etc.). The specific aims of the project include: 1) prototype a data  path and construct infrastructure for BCR-ABL1 data curation from literature and/or clinical  sources; 2) construct literature ontological field map to quantify topic depth, aggregate data, and  identify relationships within and between categories; 3) perform exploratory analysis to assess  aggregate statistical power and prototype predictive models for TKI optimization. In summary, the  present project delivers a 21st century, big data approach for BCR-ABL1 leukemia to optimize  clinical management and expedite basic preclinical research. This project is highly relevant to public health as it enables a comprehensive view of BCR ABL  positive leukemia(s) that can optimize clinical management and expedite preclinical research.",A Big Data Approach to BCR ABL Leukemias,9728205,R21CA232249,"['ABL1 gene', 'Acute Lymphocytic Leukemia', 'Acute Myelocytic Leukemia', 'Animal Model', 'Automobile Driving', 'Award', 'Big Data', 'Cancer Etiology', 'Case Study', 'Categories', 'Cessation of life', 'Characteristics', 'Chronic', 'Chronic Myeloid Leukemia', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Trials', 'Cohort Studies', 'Combined Modality Therapy', 'Complex', 'Cytogenetics', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Set', 'Databases', 'Decision Modeling', 'Dimensions', 'Engineering', 'Epidemiology', 'Etiology', 'Foundations', 'Frequencies', 'Functional disorder', 'Future', 'Goals', 'Heterogeneity', 'Human Resources', 'Individual', 'Informatics', 'Infrastructure', 'Institutes', 'Kidney', 'Life', 'Literature', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Medicine', 'Meta-Analysis', 'Modeling', 'Mutation', 'Oncogenes', 'Ontology', 'Outcome', 'Pancreas', 'Patient-Focused Outcomes', 'Patients', 'Polymerase Chain Reaction', 'Pragmatic clinical trial', 'Pre-Clinical Model', 'Prognostic Marker', 'Protocols documentation', 'Public Health', 'Publishing', 'Quadriplegia', 'Quality of life', 'Rare Diseases', 'Recurrence', 'Relapse', 'Research Personnel', 'Resistance', 'Retrospective Studies', 'Risk Assessment', 'Sample Size', 'Semantics', 'Source', 'Specificity', 'Staging', 'Techniques', 'Time', 'Toxic effect', 'Tyrosine Kinase Inhibitor', 'Universities', 'Wheelchairs', 'adult leukemia', 'base', 'cancer type', 'chemotherapy', 'cohort', 'comparative', 'compliance behavior', 'data mining', 'database schema', 'disability', 'disorder risk', 'drug intolerance', 'drug intolerant', 'epidemiology study', 'experience', 'improved', 'innovation', 'leukemia', 'lexical', 'novel', 'novel diagnostics', 'personalized predictions', 'population based', 'pre-clinical', 'pre-clinical research', 'predictive modeling', 'prognostic', 'prototype', 'rare cancer', 'relational database', 'resistance mutation', 'response', 'side effect', 'text searching', 'treatment duration']",NCI,GEORGIA INSTITUTE OF TECHNOLOGY,R21,2019,167262,0.15688994957451854
