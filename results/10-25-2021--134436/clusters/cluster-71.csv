text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Automated image-based biomarker computation tools for diabetic retinopathy    DESCRIPTION (provided by applicant): In this STTR project, we present EyeMark, a set of tools for automated computation of biomarkers for diabetic retinopathy using retinal image photographs. Specifically, we will develop tools for computation of microaneurysm (MA) appearance and disappearance rates (jointly known as turnover rates) for use as a biomarker in monitoring progression of diabetic retinopathy (DR). The availability of a reliable image-based biomarker will have high positive influence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research. There is ample published evidence that MA turnover rates are a good predictor of likelihood of progression to more severe retinopathy, establishing MA turnover as an excellent biomarker for diabetic retinopathy. Measuring this quantity involves two steps: careful alignment of current and baseline images, and marking of individual MAs. This process is very time consuming and prone to error, if done by entirely by human graders. The primary goal of this project is to overcome the above limitations by automating both the steps involved in MA turnover measurement: accurate image registration, and MA detection. We will develop end-too-end desktop software for automated computation of MA turnover and also provide intuitive visualization tools for clinicians to more effectively monitor diabetic retinopathy progression.      PUBLIC HEALTH RELEVANCE: The proposed tool will greatly enhance the clinical care available to diabetic retinopathy patients by providing an automated tool for computation of a biomarker in a non-invasive manner. This will enable identification of patients who are more likely to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.              The proposed tool will greatly enhance the clinical care available to diabetic retinopathy patients by providing an automated tool for computation of a biomarker in a non-invasive manner. This will enable identification of patients who are more likely to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.            ",Automated image-based biomarker computation tools for diabetic retinopathy,8252674,R41TR000377,"['Address', 'Adoption', 'Algorithms', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Blindness', 'California', 'Caring', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Color', 'Computer Vision Systems', 'Computer software', 'Consultations', 'County', 'Descriptor', 'Detection', 'Development', 'Diabetic Retinopathy', 'Early identification', 'Eye', 'Face', 'Fundus', 'Future', 'Goals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Joints', 'Lesion', 'Longitudinal Studies', 'Los Angeles', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Measures', 'Medical center', 'Methods', 'Microaneurysm', 'Monitor', 'Ophthalmic examination and evaluation', 'Optic Disk', 'Optometry', 'Patients', 'Pattern Recognition', 'Phase', 'Process', 'Publishing', 'Reading', 'Research', 'Retinal', 'Retinal Diseases', 'Screening procedure', 'Small Business Technology Transfer Research', 'Software Engineering', 'Software Tools', 'Time', 'Universities', 'Vision', 'Visit', 'base', 'clinical application', 'clinical care', 'clinical practice', 'clinically significant', 'cohort', 'design', 'diabetic patient', 'drug discovery', 'experience', 'image processing', 'image registration', 'macular edema', 'member', 'prevent', 'professor', 'success', 'tool', 'user-friendly']",NCATS,"EYENUK, INC.",R41,2012,260857,0.0832928977699315
"Vision in Natural Tasks Summary/Abstract  In the context of natural behavior, humans make continuous sequences of sensory-motor decisions to satisfy current behavioral goals, and vision must provide the information needed to achieve those goals. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks in natural locomotion, or the requisite information, and the proposal attempts to specify these.  in the context of natural gait, the patterns of optic flow are unexpectedly complex, raising questions about its role. The patterns of motion on the retina during locomotion depend critically on both eye and body motion, and these in turn depend on behavioral goals. Our first Aim is therefore to comprehensively describe the statistics of retinal motion patterns in a variety of terrains and task contexts. We will measure binocular eye and body movements while walking in outdoor terrains of varying roughness, crossing a busy intersection, and making coffee. These contexts will induce different gaze patterns. We will provide a comprehensive description of the motion stimulus in natural locomotion and help separate out self-motion signals from externally generated motion. These data will allow a more precise specification of the response patterns in cortical motion sensitive areas. Because of the complexity of natural motion patterns, we will re-examine the influence of optic flow on walking direction in a virtual reality environment and test alternative explanations for the role of flow.  A central task in walking is foot placement, and we will focus on identifying the image properties that make a good foothold. Stereo, structure from motion, and spatial image structure are all likely contenders. We directly investigate the role of stereo in foothold selection by examining gait patterns in stereo-deficient subjects in terrains with varying degrees of roughness. Using a different strategy, we will attempt to predict gaze locations and footholds in rough terrain using convolution neural nets (CNN’s) to identify potential search templates for footholds in rough terrain. We will describe fixation patterns from crosswalk and sidewalk navigation and attempt to make inferences about their purpose, and use Modular Inverse Reinforcement Learning (MIRL) to predict direction decisions and decompose the behavior into sub-tasks.  The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists The work will be strengthened by the investigation of stereo- deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available. Project Narrative  The central goal of this work is to understand vision in its natural context. This is very important information in order to devise suitable vision aids and rehabilitation strategies for individuals with visual impairments, and it is becoming increasingly accessible because of developments in technology for monitoring eye and body movements. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks and requisite information in natural locomotion, and the proposal attempts to specify these. The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists. The work will be strengthened by the investigation of stereo-deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available.",Vision in Natural Tasks,10004035,R01EY005729,"['Affect', 'Area', 'Behavior', 'Behavioral', 'Binocular Vision', 'Cells', 'Characteristics', 'Coffee', 'Collection', 'Complex', 'Cues', 'Data', 'Data Set', 'Development', 'Distant', 'Environment', 'Eye', 'Eye Movements', 'Gait', 'Goals', 'Grant', 'Head', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Link', 'Location', 'Locomotion', 'Machine Learning', 'Measures', 'Monitor', 'Motion', 'Motor', 'Movement', 'Pattern', 'Psychological reinforcement', 'Retina', 'Rewards', 'Robot', 'Robotics', 'Role', 'Sampling', 'Seminal', 'Sensory', 'Signal Transduction', 'Speed', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Visit', 'Visual', 'Visual Fields', 'Visual impairment', 'Walkers', 'Walking', 'Work', 'base', 'convolutional neural network', 'cost', 'experimental study', 'foot', 'gaze', 'imaging properties', 'innovation', 'kinematics', 'novel', 'optic flow', 'rehabilitation strategy', 'response', 'sample fixation', 'statistics', 'virtual reality environment', 'vision aid', 'vision development', 'vision rehabilitation', 'visual information']",NEI,"UNIVERSITY OF TEXAS, AUSTIN",R01,2020,381743,0.025056019040424784
"Vision in Natural Tasks Summary/Abstract  In the context of natural behavior, humans make continuous sequences of sensory-motor decisions to satisfy current behavioral goals, and vision must provide the information needed to achieve those goals. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks in natural locomotion, or the requisite information, and the proposal attempts to specify these.  in the context of natural gait, the patterns of optic flow are unexpectedly complex, raising questions about its role. The patterns of motion on the retina during locomotion depend critically on both eye and body motion, and these in turn depend on behavioral goals. Our first Aim is therefore to comprehensively describe the statistics of retinal motion patterns in a variety of terrains and task contexts. We will measure binocular eye and body movements while walking in outdoor terrains of varying roughness, crossing a busy intersection, and making coffee. These contexts will induce different gaze patterns. We will provide a comprehensive description of the motion stimulus in natural locomotion and help separate out self-motion signals from externally generated motion. These data will allow a more precise specification of the response patterns in cortical motion sensitive areas. Because of the complexity of natural motion patterns, we will re-examine the influence of optic flow on walking direction in a virtual reality environment and test alternative explanations for the role of flow.  A central task in walking is foot placement, and we will focus on identifying the image properties that make a good foothold. Stereo, structure from motion, and spatial image structure are all likely contenders. We directly investigate the role of stereo in foothold selection by examining gait patterns in stereo-deficient subjects in terrains with varying degrees of roughness. Using a different strategy, we will attempt to predict gaze locations and footholds in rough terrain using convolution neural nets (CNN’s) to identify potential search templates for footholds in rough terrain. We will describe fixation patterns from crosswalk and sidewalk navigation and attempt to make inferences about their purpose, and use Modular Inverse Reinforcement Learning (MIRL) to predict direction decisions and decompose the behavior into sub-tasks.  The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists The work will be strengthened by the investigation of stereo- deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available. Project Narrative  The central goal of this work is to understand vision in its natural context. This is very important information in order to devise suitable vision aids and rehabilitation strategies for individuals with visual impairments, and it is becoming increasingly accessible because of developments in technology for monitoring eye and body movements. The proposed work examines gaze and walking decisions in locomotion in outdoor environments, taking advantage of our novel system for measuring combined eye and body movements in these contexts. Currently we have only limited understanding of the constituent tasks and requisite information in natural locomotion, and the proposal attempts to specify these. The collection of integrated gaze, body kinematics, and scene images in a range of natural environments is innovative, as little comparable data exists. The work will be strengthened by the investigation of stereo-deficient subjects for whom there is almost no integrated eye and body data. Since much of the work in robotics has no visual input at all this should help in development of visual guidance for robots and also help better define the necessary information for individuals with impaired vision. The data set will be made publicly available.",Vision in Natural Tasks,9830977,R01EY005729,"['Affect', 'Area', 'Behavior', 'Behavioral', 'Binocular Vision', 'Cells', 'Characteristics', 'Coffee', 'Collection', 'Complex', 'Cues', 'Data', 'Data Set', 'Development', 'Distant', 'Environment', 'Eye', 'Eye Movements', 'Gait', 'Goals', 'Grant', 'Head', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Link', 'Location', 'Locomotion', 'Machine Learning', 'Measures', 'Monitor', 'Motion', 'Motor', 'Movement', 'Pattern', 'Psychological reinforcement', 'Retina', 'Retinal', 'Rewards', 'Robot', 'Robotics', 'Role', 'Sampling', 'Seminal', 'Sensory', 'Signal Transduction', 'Speed', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Visit', 'Visual', 'Visual Fields', 'Visual impairment', 'Walkers', 'Walking', 'Work', 'base', 'convolutional neural network', 'cost', 'experimental study', 'foot', 'gaze', 'imaging properties', 'innovation', 'kinematics', 'novel', 'optic flow', 'rehabilitation strategy', 'response', 'sample fixation', 'statistics', 'virtual reality', 'vision aid', 'vision development', 'vision rehabilitation', 'visual information']",NEI,"UNIVERSITY OF TEXAS, AUSTIN",R01,2019,369009,0.025056019040424784
"ION CURRENT ANALYSIS IN THE CORNEA The transport system of the corneal endothelium maintains the cornea at          the low level of hydration required for transparency and good vision. If         this transport system does not function properly then permanent corneal          edema, loss of transparency, and eventual blindness may occur.                                                                                                    Our long term objective is to understand how this transport system               functions under normal conditions and how it changes in aged, injured, and       diseased corneas.                                                                                                                                                 Ion channel proteins in the cell membrane are an essential component of          this transport system. We will study the dynamics of how these proteins          function as ""molecular machines"".                                                                                                                                 The specific aims for this project period are:                                                                                                                    1) to perform patch clamp experiments to measure and compare the                 properties of ion channels from freshly excised and cultured corneal             endothelial cells,                                                                                                                                                2) to develop and apply new mathematical methods, including powerful new         methods of fractals and nonlinear dynamics (chaos) to analyze this data,         and                                                                                                                                                               3) to determine the properties of different types of dynamical models to         understand the molecular mechanisms responsible for the channel                  properties.                                                                       n/a",ION CURRENT ANALYSIS IN THE CORNEA,6073746,R01EY006234,"['aging', ' artificial intelligence', ' computer data analysis', ' computer program /software', ' cornea disorder', ' corneal endothelium', ' electrophysiology', ' eye injury', ' ion transport', ' laboratory rabbit', ' mathematical model', ' membrane channels', ' membrane transport proteins', ' model design /development', ' molecular biology', ' molecular dynamics', ' personal computers', ' tissue /cell culture', ' voltage /patch clamp']",NEI,FLORIDA ATLANTIC UNIVERSITY,R01,1999,109869,0.10506277370545855
"ION CURRENT ANALYSIS IN THE CORNEA The transport system of the corneal endothelium maintains the cornea at          the low level of hydration required for transparency and good vision. If         this transport system does not function properly then permanent corneal          edema, loss of transparency, and eventual blindness may occur.                                                                                                    Our long term objective is to understand how this transport system               functions under normal conditions and how it changes in aged, injured, and       diseased corneas.                                                                                                                                                 Ion channel proteins in the cell membrane are an essential component of          this transport system. We will study the dynamics of how these proteins          function as ""molecular machines"".                                                                                                                                 The specific aims for this project period are:                                                                                                                    1) to perform patch clamp experiments to measure and compare the                 properties of ion channels from freshly excised and cultured corneal             endothelial cells,                                                                                                                                                2) to develop and apply new mathematical methods, including powerful new         methods of fractals and nonlinear dynamics (chaos) to analyze this data,         and                                                                                                                                                               3) to determine the properties of different types of dynamical models to         understand the molecular mechanisms responsible for the channel                  properties.                                                                       n/a",ION CURRENT ANALYSIS IN THE CORNEA,2833074,R01EY006234,"['aging', ' artificial intelligence', ' computer data analysis', ' computer program /software', ' cornea disorder', ' corneal endothelium', ' electrophysiology', ' eye injury', ' ion transport', ' laboratory rabbit', ' mathematical model', ' membrane channels', ' membrane transport proteins', ' model design /development', ' molecular biology', ' molecular dynamics', ' tissue /cell culture', ' voltage /patch clamp']",NEI,FLORIDA ATLANTIC UNIVERSITY,R01,1998,106670,0.10506277370545855
"ION CURRENT ANALYSIS IN THE CORNEA The transport system of the corneal endothelium maintains the cornea at          the low level of hydration required for transparency and good vision. If         this transport system does not function properly then permanent corneal          edema, loss of transparency, and eventual blindness may occur.                                                                                                    Our long term objective is to understand how this transport system               functions under normal conditions and how it changes in aged, injured, and       diseased corneas.                                                                                                                                                 Ion channel proteins in the cell membrane are an essential component of          this transport system. We will study the dynamics of how these proteins          function as ""molecular machines"".                                                                                                                                 The specific aims for this project period are:                                                                                                                    1) to perform patch clamp experiments to measure and compare the                 properties of ion channels from freshly excised and cultured corneal             endothelial cells,                                                                                                                                                2) to develop and apply new mathematical methods, including powerful new         methods of fractals and nonlinear dynamics (chaos) to analyze this data,         and                                                                                                                                                               3) to determine the properties of different types of dynamical models to         understand the molecular mechanisms responsible for the channel                  properties.                                                                       n/a",ION CURRENT ANALYSIS IN THE CORNEA,2444291,R01EY006234,"['aging', ' artificial intelligence', ' computer data analysis', ' computer program /software', ' cornea disorder', ' corneal endothelium', ' electrophysiology', ' eye injury', ' ion transport', ' laboratory rabbit', ' mathematical model', ' membrane channels', ' membrane transport proteins', ' model design /development', ' molecular biology', ' molecular dynamics', ' tissue /cell culture', ' voltage /patch clamp']",NEI,FLORIDA ATLANTIC UNIVERSITY,R01,1997,138993,0.10506277370545855
"ION CURRENT ANALYSIS IN THE CORNEA The transport system of the corneal endothelium maintains the cornea at the low level of hydration required for transparency and good vision. If this transport system does not function properly then permanent corneal edema, loss of transparency, and eventual blindness may occur.  Our long term objective is to understand how this transport system functions under normal conditions and how it changes in aged, injured, and diseased corneas.  Ion channel proteins in the cell membrane are an essential component of this transport system. We will study the dynamics of how these proteins function as ""molecular machines"".  The specific aims for this project period are:  1) to perform patch clamp experiments to measure and compare the properties of ion channels from freshly excised and cultured corneal endothelial cells,  2) to develop and apply new mathematical methods, including powerful new methods of fractals and nonlinear dynamics (chaos) to analyze this data, and  3) to determine the properties of different types of dynamical models to understand the molecular mechanisms responsible for the channel properties.  n/a",ION CURRENT ANALYSIS IN THE CORNEA,2159816,R01EY006234,"['aging', ' artificial intelligence', ' computer data analysis', ' computer program /software', ' cornea disorder', ' corneal endothelium', ' electrophysiology', ' eye injury', ' ion transport', ' laboratory rabbit', ' mathematical model', ' membrane channels', ' membrane transport proteins', ' model design /development', ' molecular biology', ' molecular dynamics', ' tissue /cell culture', ' voltage /patch clamp']",NEI,FLORIDA ATLANTIC UNIVERSITY,R01,1994,169271,0.10506277370545855
"SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS In this Phase l proposal we plan to develop and test a new vision technology to locat and read general informational signs (street names, building directories, office door plates) and location and directional signs (EXIT, Information, aisle signs in supermarkets). To strengthen feasibility, we will target a restricted class of signs: those consisting primarily of one- color text on a different one-color background, and whose shape falls within a prescribed set. The intended market is for people who are blind or whose sight is impaired and hence cannot read these signs unaided. Our approach makes extensive use of recently developed computer vision recognition algorithms. We also make use of the Smith-Kettlewell's Rehabilitation Engineering Research Center's expertise for determining what the potential users will require from such a system. The ultimate goal, for Phase II, is to build and test a highly portable PC- based device implementing this vision technology using a CCD camera as input and a voice-generator as output. The user would scan/point the device at a scene and it would locate and read one or more signs. Given the pace of increase in power and decrease in size of computing devices, a hand-held Sign-Finder system may be plausible to build entirely with commercial, off-the-shelf hardware in two to three years. PROPOSED COMMERCIAL APPLICATION: The potential utility to blind and visually impaired individuals is great; a commercial product could have a market potential of 500,000.  n/a",SIGN FINDER: COMPUTER VISION TO FIND AND READ SIGNS,2720318,R43EY011821,"['artificial intelligence', ' blind aid', ' charge coupled device camera', ' computer graphics /printing', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' information display', ' portable biomedical equipment', ' symbolism', ' technology /technique development', ' vision aid']",NEI,BLINDSIGHT CORPORATION,R43,2000,100000,0.16165946204945947
"Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1 Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at certain stages of the disease severity spectrum, specifically in the early stage and in advanced disease. These difficulties are due to a variety of causes that change over the course of the disease, including large between-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we build on our long-standing contribution to ocular imaging and propose novel and sensitive means to detect glaucoma and its progression that are optimized to the various stages of disease severity. We will use information gathered from visual fields (functional information) and a leading ocular imaging technology – optical coherence tomography (OCT; structural information) to map the capability of detecting changes across the entire disease severity spectrum to identify optimal parameters for each stage of the disease. Both commonly used parameters provided by the technologies and newly developed parameters with good diagnostic potential will be analyzed. We will use state-of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. We will also utilize a new imaging technology, the visible light OCT, to generate retinal images with outstanding resolution to extract information about the oxygen saturation of the tissue. This will provide in-vivo, real time, and noninvasive insight into tissue functionality. Taken together, this program will advance the use of structural and functional information with a substantial impact on the clinical management of subjects with glaucoma Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies that will substantially improve detection of glaucoma and its progression monitoring in order to prevent blindness.",Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1,10019553,R01EY013178,"['3-Dimensional', 'Blindness', 'Characteristics', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Data', 'Detection', 'Development', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Floor', 'Future', 'Glaucoma', 'Health', 'Human', 'Image', 'Imaging technology', 'Inner Plexiform Layer', 'Knowledge', 'Laboratories', 'Lead', 'Light', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Oxygen Consumption', 'Oxygen saturation measurement', 'Pathology', 'Research Proposals', 'Resolution', 'Retina', 'Retinal Diseases', 'Scanning', 'Severities', 'Severity of illness', 'Signal Transduction', 'Source', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Technology', 'Thick', 'Time', 'Tissue Extracts', 'Tissues', 'Translating', 'Visible Radiation', 'Vision', 'Visual Fields', 'Width', 'advanced disease', 'analytical method', 'base', 'clinical practice', 'cohort', 'computerized', 'deep learning', 'density', 'ganglion cell', 'improved', 'in vivo', 'innovation', 'innovative technologies', 'insight', 'instrument', 'invention', 'knowledge base', 'longitudinal dataset', 'machine learning method', 'macula', 'mathematical methods', 'new technology', 'novel', 'novel strategies', 'ocular imaging', 'preservation', 'prevent', 'programs', 'research study', 'retinal imaging', 'retinal nerve fiber layer', 'tissue oxygenation', 'tool']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,687519,0.05293879393683525
"Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1 Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at certain stages of the disease severity spectrum, specifically in the early stage and in advanced disease. These difficulties are due to a variety of causes that change over the course of the disease, including large between-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we build on our long-standing contribution to ocular imaging and propose novel and sensitive means to detect glaucoma and its progression that are optimized to the various stages of disease severity. We will use information gathered from visual fields (functional information) and a leading ocular imaging technology – optical coherence tomography (OCT; structural information) to map the capability of detecting changes across the entire disease severity spectrum to identify optimal parameters for each stage of the disease. Both commonly used parameters provided by the technologies and newly developed parameters with good diagnostic potential will be analyzed. We will use state-of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. We will also utilize a new imaging technology, the visible light OCT, to generate retinal images with outstanding resolution to extract information about the oxygen saturation of the tissue. This will provide in-vivo, real time, and noninvasive insight into tissue functionality. Taken together, this program will advance the use of structural and functional information with a substantial impact on the clinical management of subjects with glaucoma Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies that will substantially improve detection of glaucoma and its progression monitoring in order to prevent blindness.",Novel Glaucoma Diagnostics for Structure and Function  - Renewal - 1,9819321,R01EY013178,"['3-Dimensional', 'Blindness', 'Characteristics', 'Clinical', 'Clinical Management', 'Clinical Research', 'Complex', 'Data', 'Detection', 'Development', 'Diagnostic', 'Discrimination', 'Disease', 'Disease Progression', 'Early Diagnosis', 'Evaluation', 'Eye', 'Floor', 'Future', 'Glaucoma', 'Health', 'Human', 'Image', 'Imaging technology', 'Inner Plexiform Layer', 'Knowledge', 'Laboratories', 'Lead', 'Light', 'Machine Learning', 'Maps', 'Measurable', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Optic Disk', 'Optical Coherence Tomography', 'Outcome', 'Oxygen Consumption', 'Oxygen saturation measurement', 'Pathology', 'Research Proposals', 'Resolution', 'Retinal', 'Retinal Diseases', 'Scanning', 'Severities', 'Severity of illness', 'Signal Transduction', 'Source', 'Structure', 'Structure-Activity Relationship', 'System', 'Techniques', 'Technology', 'Thick', 'Time', 'Tissue Extracts', 'Tissues', 'Translating', 'Visible Radiation', 'Vision', 'Visual Fields', 'Width', 'advanced disease', 'analytical method', 'base', 'clinical practice', 'cohort', 'computerized', 'deep learning', 'density', 'ganglion cell', 'improved', 'in vivo', 'innovation', 'innovative technologies', 'insight', 'instrument', 'invention', 'knowledge base', 'learning strategy', 'longitudinal dataset', 'macula', 'mathematical methods', 'new technology', 'novel', 'novel strategies', 'ocular imaging', 'preservation', 'prevent', 'programs', 'research study', 'retinal imaging', 'retinal nerve fiber layer', 'tissue oxygenation', 'tool']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,715489,0.05293879393683525
"Advanced Vision Intervention Algorithm(AVIA)   Description (from the investigator's abstract): The objective of this                application is to implement an iterative, nine-step advanced vision                  intervention algorithm (AVIA) in software to optimize the predictability of          virtually any current or anticipated customized human vision intervention            method. The software program will use the investigator's Visual Optics class         library, as well as new software for the ray transfer element, database              analysis routines, and the ray tracing surface optimization algorithm. The           program will allow, but not require, exam data from commercially available           ophthalmic instruments such as corneal topography and wavefront aberration for       input in the optical modeling of an individual's eye. This algorithm is, to the      investigator's knowledge, the only formal framework designed specifically to         optimize the predictability of surgical and non-surgical correction methods. It      is not only a technological innovation in its own right, it also makes the most      of the current and future vision correction methods to which it is applied.          PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",Advanced Vision Intervention Algorithm(AVIA),6403968,R43EY013666,"['artificial intelligence', ' computer assisted patient care', ' computer program /software', ' computer system design /evaluation', ' eye surgery', ' laser therapy', ' ophthalmoscopy', ' statistics /biometry', ' vision disorders']",NEI,"SARVER AND ASSOCIATES, INC.",R43,2001,99785,0.17216918366614797
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6995047,R43EY014487,"['artificial intelligence', 'biomedical equipment development', 'clinical research', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'data collection', 'digital imaging', 'functional ability', 'human subject', 'image processing', 'medical rehabilitation related tag', 'patient oriented research', 'portable biomedical equipment', 'questionnaires', 'vision aid', 'vision disorders', 'visual fields', 'visual perception', 'visual threshold', 'visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2005,144106,0.174377867847276
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6665322,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,245656,0.174377867847276
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6710523,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2003,139234,0.174377867847276
"A Smart Telescope for Low Vision    DESCRIPTION (provided by applicant): This is a proposal to test the feasibility of a ""Smart Telescope"" for use to improve the ability of visually impaired persons in tasks such as travel, navigation and social interactions. Advances in low-power high-speed portable computers combined with novel computer vision algorithms enable us to build an affordable, portable, and cosmetically acceptable digital telescope that can enable visually impaired persons to perform these tasks with greater ease than with current telescopes.        The computer vision algorithms first detect regions of interest in an image where targets are likely to be, even if these targets occupy only a small portion of the visual field, obviating the need for a user to scan or search a scene as would be necessary with an ordinary telescope. Next, novel object-specific super-resolution enhancement algorithms use target-specific knowledge to magnify and enhance these regions so that users can interpret them, similar to pointing a telescope at those regions. Algorithms can then track the targets as the observer moves, and indicate their relative locations. Finally, like today's digital telescopes for   the low vision community, the Smart Telescope will output either to a monocular viewfinder display or to a bioptic display.      The project process involves: (1) Data collection and analysis (Iow-vision persons will be used to collect image data); (2) Detection, enhancement and tracking algorithm development; (3) Integration of algorithms with user interface, and (4) Testing human factors.      Our field prototypes will range in cost from approximately $3,000 to $5,000 each, while the target cost of a commercial version is under $1,000. Our price estimates are conservative, and we anticipate that the rapid development of computer technology will lower these costs substantially in the next few years.         n/a",A Smart Telescope for Low Vision,6580977,R43EY014487,"['artificial intelligence', ' biomedical equipment development', ' clinical research', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' functional ability', ' human subject', ' image processing', ' medical rehabilitation related tag', ' patient oriented research', ' portable biomedical equipment', ' questionnaires', ' vision aid', ' vision disorders', ' visual fields', ' visual perception', ' visual threshold', ' visual tracking']",NEI,BLINDSIGHT CORPORATION,R43,2002,246164,0.174377867847276
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,9133939,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Awareness', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Conscious', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Foundations', 'GTP-Binding Protein alpha Subunits, Gs', 'Hand functions', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'Subconscious', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'robot control', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2017,133916,0.17647422114789685
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning. PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8914675,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Health', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2015,100000,0.17647422114789685
"NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair     DESCRIPTION (provided by applicant):         The aim of this proposal is to conduct research on the foundational models and algorithms in computer vision and machine learning for an egocentric vision based active learning co-robot wheelchair system to improve the quality of life of elders and disabled who have limited hand functionality or no hand functionality at all, and rely on wheelchairs for mobility. In this co-robt system, the wheelchair users wear a pair of egocentric camera glasses, i.e., the camera is capturing the users' field-of-the-views. This project help reduce the patients' reliance on care-givers. It fits NINR's mission in addressing key issues raised by the Nation's aging population and shortages of healthcare workforces, and in supporting patient-focused research that encourage and enable individuals to become guardians of their own well-beings.  The egocentric camera serves two purposes. On one hand, from vision based motion sensing, the system can capture unique head motion patterns of the users to control the robot wheelchair in a noninvasive way. Secondly, it serves as a unique environment aware vision sensor for the co-robot system as the user will naturally respond to the surroundings by turning their focus of attention, either consciously or subconsciously. Based on the inputs from the egocentric vision sensor and other on-board robotic sensors, an online learning reservoir computing network is exploited, which not only enables the robotic wheelchair system to actively solicit controls from the users when uncertainty is too high for autonomous operation, but also facilitates the robotic wheelchair system to learn from the solicited user controls. This way, the closed- loop co-robot wheelchair system will evolve and be more capable of handling more complicated environment overtime.  The aims ofthe project include: 1) develop an method to harness egocentric computer vision-based sensing of head movements as an alternative method for wheelchair control; 2) develop a method leveraging visual motion from the egocentric camera for category independent moving obstacle detection; and 3) close the loop of the active learning co-robot wheelchair system through uncertainty based active online learning.          PUBLIC HEALTH RELEVANCE:          The project will improve the quality of life of those elders and disabled who rely on wheelchairs for mobility, and reduce their reliance on care-givers. It builds an intelligent wheelchair robot system that can adapt itself to the personalized behavior of the user. The project addresses the need of approximately 1 % of our world's population, including millions of Americans, who rely on wheelchair for mobility.             ",NRI: An Egocentric Computer Vision based Active Learning Co-Robot Wheelchair,8838311,R01NR015371,"['Active Learning', 'Address', 'Algorithms', 'American', 'Attention', 'Behavior', 'Build-it', 'Caregivers', 'Categories', 'Computer Vision Systems', 'Detection', 'Disabled Persons', 'E-learning', 'Elderly', 'Environment', 'Glass', 'Hand', 'Head', 'Head Movements', 'Healthcare', 'Individual', 'Learning', 'Machine Learning', 'Methods', 'Mission', 'Modeling', 'Motion', 'Motivation', 'Patients', 'Pattern', 'Population', 'Principal Investigator', 'Quality of life', 'Reliance', 'Research', 'Robot', 'Robotics', 'System', 'Uncertainty', 'Vision', 'Visual Motion', 'Wheelchairs', 'aging population', 'base', 'improved', 'operation', 'programs', 'public health relevance', 'sensor']",NINR,STEVENS INSTITUTE OF TECHNOLOGY,R01,2014,100000,0.17647422114789685
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,8142000,R01EY016093,"['Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Peripheral', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2011,1141143,0.2531936671429239
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7904837,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2010,1196495,0.2531936671429239
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7668573,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,1187062,0.2531936671429239
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7922310,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'efficacy testing', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'meetings', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2009,152260,0.2531936671429239
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7500697,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2008,1146026,0.2531936671429239
"Mid-Level Vision Systems for Low Vision    DESCRIPTION (provided by applicant): Low vision is a significant reduction of visual function that cannot be fully corrected by ordinary lenses, medical treatment, or surgery. Aging, injuries, and diseases can cause low vision. Its leading causes and those of blindness, include cataracts and age-related macular degeneration (AMD), both of which are more prevalent in the elderly population. Our overarching goal is to develop devices to aid people with low vision. We propose to use techniques of computer vision and computational neuroscience to build systems that enhance natural images. We plan test these systems on normal people and visually impaired older adults, with and without AMD. We have three milestones to reach: 1) Our first milestone will be to develop a system for low-noise image-contrast enhancement, which should help with AMD, because it causes lower contrast sensitivity. 2) Our second milestone will be a system that extracts the main contours of images in a cortical-like manner. Superimposing these contours on images should help with contrast-sensitivity problems at occlusion boundaries. Diffusing regions inside contours should help with crowding problems prominent in AMD. 3) Our third milestone is to probe whether these systems can help people with low vision people. For this purpose, we plan to use a battery of search and recognition psychophysical tests tailor-made for AMD. We put together an interdisciplinary team. The Principal Investigator is Dr. Norberto Grzywacz from Biomedical Engineering at USC. Drs. Gerard Medioni from Computer Science and Bartlett Mel from Biomedical Engineering at USC will lead the efforts in Specific Aims 1 and 2 respectively. Drs. Bosco Tjan from USC Psychology, Susana Chung from the University of Houston, and Eli Peli from Harvard Medical School will lead Specific Aim 3. Other scientists are from USC. They include Dr. Irving Biederman from Psychology, an object-recognition expert and Dr. Mark Humayun, from Ophthalmology, an AMD expert. They also include Dr. lone Fine, from Ophthalmology, an expert in people who recover vision after a prolonged period without it and Dr. Zhong-Lin Lu, an expert on motion perception and perceptual learning.           n/a",Mid-Level Vision Systems for Low Vision,7172503,R01EY016093,"['Age', 'Age related macular degeneration', 'Aging', 'Algorithms', 'Biological', 'Biomedical Engineering', 'Blindness', 'California', 'Cataract', 'Clutterings', 'Cognitive', 'Color Visions', 'Complex', 'Computer Vision Systems', 'Consultations', 'Contrast Sensitivity', 'Crowding', 'Development', 'Devices', 'Diffuse', 'Disease', 'Effectiveness', 'Elderly', 'Engineering', 'Esthetics', 'Evaluation', 'Face', 'Faculty', 'Goals', 'Human', 'Image', 'Image Analysis', 'Inferior', 'Injury', 'Lead', 'Learning', 'Machine Learning', 'Masks', 'Measurement', 'Medical', 'Minor', 'Modeling', 'Motion Perception', 'Nature', 'Noise', 'Operative Surgical Procedures', 'Ophthalmology', 'Optometry', 'Patients', 'Perceptual learning', 'Population', 'Principal Investigator', 'Property', 'Psychologist', 'Psychology', 'Psychophysiology', 'Purpose', 'Range', 'Reading', 'Retina', 'Schools', 'Scientist', 'Shapes', 'Skiing', 'Surface', 'Surface Properties', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Universities', 'Vision', 'Visual', 'Visual Acuity', 'Visual Aid', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Work', 'computational neuroscience', 'computer science', 'fovea centralis', 'human subject', 'improved', 'lens', 'medical schools', 'member', 'object recognition', 'symposium', 'tool', 'vision science', 'visual performance']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2007,1159531,0.2531936671429239
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,9336584,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2016,28000,0.07061268144220231
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering. PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8920573,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Health', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'rehabilitation engineering', 'robot rehabilitation', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2015,3412,0.07061268144220231
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8704450,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'High School Student', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2014,51689,0.07061268144220231
"NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired     DESCRIPTION (provided by applicant): The project's objective is to develop enabling technology for a co-robotic navigation aid, called a Co-Robotic Cane (CRC), for the visually impaired. The CRC is able to collaborate with its user via intuitive Human-Device Interaction (HDl) mechanisms for effective navigation in 3D environments. The CRCs navigational functions include device position estimation, wayfinding, obstacle detection/avoidance, and object recognition. The use of the CRC will improve the visually impaired's independent mobility and thus their quality of life. The proposal's educational plan is to involve graduate, undergraduate and high school students in the project, and use the project's activities to recruit and retain engineering students. The proposal's Intellectual Merit is the development of new computer vision methods that support accurate blind navigation in 3D environments and intuitive HDl interfaces for effective use of device. These methods include: (1) a new robotic pose estimation method that provides accurate device pose by integrating egomotion estimation and visual feature tracking; (2) a pattern recognition method based on the Gaussian Mixture Model that may recognize indoor structures and objects for wayfinding and obstacle manipulation/ avoidance; (3) an innovative mechanism for intuitive conveying of the desired travel direction; and (4) a human intent detection interface for automatic device mode switching. The GPU implementation of the computer vision methods will make real-time execution possible. The proposed blind navigation solution will endow the CRC with advanced navigational functions that are currently unavailable in the existing blind navigation aids. The PI's team has performed proof of concept studies for the computer vision methods and the results are promising. The broader impacts include: (1) the methods' near term applications will impact the large visually impaired community; (2) the methods will improve the autonomy of small robots and portable robotic devices that have a myriad of applications in military surveillance, law enforcement, and search and rescue; and (3) the project will improve the research infrastructure of the Pi's university and train graduate and undergraduate students for their future careers in science and engineering.         PUBLIC HEALTH RELEVANCE:  The co-robotic navigation aid and the related technology address a growing public health care issue -- visual impairment and target improving the life quality of the blind. The research fits well into the Rehabilitation Engineering Program ofthe NIBIB that includes robotics rehabilitation. The proposed research addresses to the NlBlB's mission through developing new computer vision and HDl technologies for blind navigation.            ",NRI: Small: A Co-Robotic Navigation Aid for the Visually Impaired,8650411,R01EB018117,"['Address', 'Canes', 'Communities', 'Computer Vision Systems', 'Detection', 'Development', 'Devices', 'Engineering', 'Environment', 'Future', 'Healthcare', 'Human', 'Law Enforcement', 'Methods', 'Military Personnel', 'Mission', 'Modeling', 'National Institute of Biomedical Imaging and Bioengineering', 'Pattern Recognition', 'Positioning Attribute', 'Public Health', 'Quality of life', 'Recruitment Activity', 'Rehabilitation therapy', 'Research', 'Research Infrastructure', 'Robot', 'Robotics', 'Science', 'Solutions', 'Structure', 'Students', 'Technology', 'Time', 'Training', 'Travel', 'Universities', 'Visual', 'Visual impairment', 'base', 'blind', 'career', 'graduate student', 'high school', 'improved', 'innovation', 'navigation aid', 'object recognition', 'programs', 'public health relevance', 'rehabilitation engineering', 'robotic device', 'undergraduate student', 'way finding']",NIBIB,UNIVERSITY OF ARKANSAS AT LITTLE ROCK,R01,2013,81362,0.07061268144220231
"Keratoconus eye model bank for virtual clinical trials and medical educations    DESCRIPTION (provided by applicant): The capability to provide accurate predictions of vision performance and ophthalmic diagnostics of healthy and diseased eyes is desired. If this computational capability existed, dramatic changes could result in ocular instrument design and development, ophthalmic medical education, and ocular telemedicine. Physics and mathematical models of the eye would then be used with computational methods to simulate and predict accurately ocular characteristics and responses. The paradigm of clinical trials could conceivably be revised to achieve faster deployment of diagnostic instrumentation if demographically representative ocular responses were confidently known at the outset of the development. Similar advances are possible in medical training if realistic diagnostic device behavior could be demonstrated for students using computed images of disease and conditions. Finally, opportunities in telemedicine and expert system-based diagnostic and referral decisions become possible and practical. The major obstacles to this capability are two-fold: 1) the absence of demographically specific characteristics of the ocular model of health and diseased eyes and 2) the verification that such a data-base of ocular characteristics can be used in computations to provide accurate predictions. This proposed effort is the initial step in addressing these problems. Development of an optically functional and analytical eye-model bank to represent a diversity of human eyes is proposed. The integrative eye bank embodies population-based ocular statistics and preserves the correlations between ocular parameters and patients' demographic features. Advanced ophthalmic technologies have enabled access to the ""fingerprints"" of an eye with cornea topography, wavefront aberration, and ocular biometry. In the first half of this project, novel optical eye modeling techniques will be integrated with contemporary biometric and detailed clinic data to provide realistic and anatomically-accurate models including emmetropic, ammetropic, and diseased keratoconic eyes. During the latter 12 months, the eye bank applications will be demonstrated in (1) medical education, (2) patient consultation, and (3) virtual clinical trials for instrumentation. PUBLIC HEALTH RELEVANCE: Physical, medical, and computational scientists will collaboratively establish an anatomically accurate digital optical eye bank of advanced clinical personalized data to represent both healthy and diseased eyes. Optical computations will be performed to demonstrate prospective applications for the prediction of patient vision and the simulation of ophthalmic biomedical instrument measurements for medical training and novel device construction.           Project Narrative  Physical, medical, and computational scientists will collaboratively establish an anatomically accurate digital optical eye bank of advanced clinical personalized data to represent both healthy and diseased eyes. Optical computations will be performed to demonstrate prospective applications for the prediction of patient vision and the simulation of ophthalmic biomedical instrument measurements for medical training and novel device construction.",Keratoconus eye model bank for virtual clinical trials and medical educations,7915333,R21EY018935,"['Address', 'Anterior', 'Behavior', 'Biomedical Research', 'Biometry', 'Budgets', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Collection', 'Computing Methodologies', 'Consultations', 'Control Groups', 'Cornea', 'Corneal Topography', 'Corneal dystrophy', 'Data', 'Databases', 'Development', 'Device Designs', 'Devices', 'Diagnostic', 'Disease', 'Distant', 'Early Diagnosis', 'Education', 'Elements', 'Expert Systems', 'Eye', 'Eye Banks', 'Fingerprint', 'Goals', 'Guidelines', 'Health', 'Health Personnel', 'Human', 'Image', 'Intervention', 'Keratoconus', 'Letters', 'Light', 'Maps', 'Measurement', 'Medical', 'Medical Education', 'Microscopic', 'Modeling', 'Optics', 'Patients', 'Performance', 'Physics', 'Pupil', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Retinoscopy', 'Scientist', 'Sensitivity and Specificity', 'Simulate', 'Source', 'Staging', 'Structure', 'Students', 'Surface', 'Techniques', 'Technology', 'Telemedicine', 'Thick', 'Training', 'Vision', 'Visual Acuity', 'base', 'design', 'detector', 'digital', 'flexibility', 'gaze', 'human subject', 'instrument', 'instrumentation', 'mathematical model', 'novel', 'operation', 'population based', 'prospective', 'public health relevance', 'research clinical testing', 'response', 'simulation', 'statistics', 'tool', 'virtual']",NEI,UNIVERSITY OF TENNESSEE SPACE INSTITUTE,R21,2010,222750,0.07932309570062553
"Keratoconus eye model bank for virtual clinical trials and medical educations    DESCRIPTION (provided by applicant): The capability to provide accurate predictions of vision performance and ophthalmic diagnostics of healthy and diseased eyes is desired. If this computational capability existed, dramatic changes could result in ocular instrument design and development, ophthalmic medical education, and ocular telemedicine. Physics and mathematical models of the eye would then be used with computational methods to simulate and predict accurately ocular characteristics and responses. The paradigm of clinical trials could conceivably be revised to achieve faster deployment of diagnostic instrumentation if demographically representative ocular responses were confidently known at the outset of the development. Similar advances are possible in medical training if realistic diagnostic device behavior could be demonstrated for students using computed images of disease and conditions. Finally, opportunities in telemedicine and expert system-based diagnostic and referral decisions become possible and practical. The major obstacles to this capability are two-fold: 1) the absence of demographically specific characteristics of the ocular model of health and diseased eyes and 2) the verification that such a data-base of ocular characteristics can be used in computations to provide accurate predictions. This proposed effort is the initial step in addressing these problems. Development of an optically functional and analytical eye-model bank to represent a diversity of human eyes is proposed. The integrative eye bank embodies population-based ocular statistics and preserves the correlations between ocular parameters and patients' demographic features. Advanced ophthalmic technologies have enabled access to the ""fingerprints"" of an eye with cornea topography, wavefront aberration, and ocular biometry. In the first half of this project, novel optical eye modeling techniques will be integrated with contemporary biometric and detailed clinic data to provide realistic and anatomically-accurate models including emmetropic, ammetropic, and diseased keratoconic eyes. During the latter 12 months, the eye bank applications will be demonstrated in (1) medical education, (2) patient consultation, and (3) virtual clinical trials for instrumentation. PUBLIC HEALTH RELEVANCE: Physical, medical, and computational scientists will collaboratively establish an anatomically accurate digital optical eye bank of advanced clinical personalized data to represent both healthy and diseased eyes. Optical computations will be performed to demonstrate prospective applications for the prediction of patient vision and the simulation of ophthalmic biomedical instrument measurements for medical training and novel device construction.           Project Narrative  Physical, medical, and computational scientists will collaboratively establish an anatomically accurate digital optical eye bank of advanced clinical personalized data to represent both healthy and diseased eyes. Optical computations will be performed to demonstrate prospective applications for the prediction of patient vision and the simulation of ophthalmic biomedical instrument measurements for medical training and novel device construction.",Keratoconus eye model bank for virtual clinical trials and medical educations,7739613,R21EY018935,"['Address', 'Anterior', 'Behavior', 'Biomedical Research', 'Biometry', 'Budgets', 'Characteristics', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Collection', 'Computing Methodologies', 'Consultations', 'Control Groups', 'Cornea', 'Corneal Topography', 'Corneal dystrophy', 'Data', 'Databases', 'Development', 'Device Designs', 'Devices', 'Diagnostic', 'Disease', 'Distant', 'Early Diagnosis', 'Education', 'Elements', 'Expert Systems', 'Eye', 'Eye Banks', 'Fingerprint', 'Goals', 'Guidelines', 'Health', 'Health Personnel', 'Human', 'Image', 'Intervention', 'Keratoconus', 'Letters', 'Light', 'Maps', 'Measurement', 'Medical', 'Medical Education', 'Microscopic', 'Modeling', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Performance', 'Physics', 'Pupil', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Retinoscopy', 'Scientist', 'Sensitivity and Specificity', 'Simulate', 'Source', 'Staging', 'Structure', 'Students', 'Surface', 'Techniques', 'Technology', 'Telemedicine', 'Thick', 'Training', 'Vision', 'Visual Acuity', 'base', 'design', 'detector', 'digital', 'flexibility', 'gaze', 'human subject', 'instrument', 'instrumentation', 'mathematical model', 'novel', 'population based', 'prospective', 'public health relevance', 'research clinical testing', 'response', 'simulation', 'statistics', 'tool', 'virtual']",NEI,UNIVERSITY OF TENNESSEE SPACE INSTITUTE,R21,2009,187500,0.07932309570062553
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,7940934,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Arts', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'public health relevance', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2010,356202,0.16589580611220262
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,7730229,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Arts', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'public health relevance', 'response']",NEI,WEILL MEDICAL COLL OF CORNELL UNIV,R01,2009,391450,0.16589580611220262
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8541017,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'elastography', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response', 'screening']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2013,328138,0.16589580611220262
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8320255,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2012,345408,0.16589580611220262
"Early Detection of Keratoconus    DESCRIPTION (provided by applicant):  Keratoconus is the most common degenerative disease affecting the cornea. This condition tends to develop around puberty and to progress over the next few decades, but its clinical history can be quite variable. As keratoconus develops, the cornea thins and bulges. Eventually, a corneal transplant may be needed to maintain vision. In its earliest stages, the disease is particularly difficult to detect, even using state-of-the-art diagnostic techniques such as anterior/posterior surface topography. This is of great importance to the corneal refractive surgeon because surgical treatment of an occult keratoconic cornea will weaken it and greatly accelerate the occurrence of symptoms. Because of the difficulty in differentiating early keratoconus from atypical normal corneas, many normal eyes deemed 'suspicious' are denied treatment. At the same time, some keratoconic eyes are missed and operated upon, with disastrous consequences. Early detection of keratoconus may also benefit patients because of the recent development of methods for strengthening the corneal stroma and preventing disease progression. We have developed a technique based on the use of high resolution ultrasound for imaging the cornea and measuring the thickness of its component layers, including the epithelium (about 50 microns in thickness) and the stroma (about 500 microns in thickness). We have shown that the epithelium, which is the surface layer of the cornea, will remodel itself to smooth out underlying irregularities. In early keratoconus, as the anterior stromal surface begins to bulge forward, the epithelium will thin above the apex of the bulge and thicken around it, to maintain a smooth anterior surface. This compensatory mechanism prevents anterior surface topography from detecting keratoconus in its early stages. We have also developed methods for characterizing the elastic properties of the cornea by inducing and measuring surface displacements in response to a pulse of acoustic radiation force. We will further develop and test this technique and apply it clinically in conjunction with the Ocular Response Analyzer, an instrument that causes a similar effect by use of an air pressure pulse. This proposal will involve analysis of topographic and pachymetric patterns and elastic properties in normal, keratoconus and keratoconus-suspicious eyes. We will develop an index based on multivariate analysis of these patterns based on unambiguously classified cases, and validate the risk index on suspicious cases based on clinical documentation of disease progression. Our goal is to reduce the percentage of screened cases deemed keratoconus- suspicious by at least a factor of two by allowing an unambiguous diagnosis of early keratoconus. PUBLIC HEALTH RELEVANCE: Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.           PROJECT NARRATIVE Keratoconus (KC) is a corneal dystrophy will in many cases ultimately require corneal transplantation to maintain vision. Early detection, which is not possible with current technology, would allow early treatment and prevent sever damage to KC corneas inadvertently operated upon for correction of vision. Our aim is to combine measurements of corneal elasticity, topography and epithelial thickness to develop means for early detection of KC.",Early Detection of Keratoconus,8138459,R01EY019055,"['Acoustics', 'Affect', 'Air Pressure', 'Algorithms', 'Anterior', 'Biological Preservation', 'Characteristics', 'Clinical', 'Cornea', 'Corneal Stroma', 'Corneal dystrophy', 'Data', 'Defect', 'Degenerative Disorder', 'Descriptor', 'Detection', 'Diagnosis', 'Diagnostic Procedure', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Early treatment', 'Elasticity', 'Epithelial', 'Epithelium', 'Eye', 'Frequencies', 'Goals', 'Health', 'Keratoconus', 'Keratoplasty', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Multivariate Analysis', 'Operative Surgical Procedures', 'Optics', 'Patients', 'Pattern', 'Physiologic pulse', 'Procedures', 'Property', 'Puberty', 'ROC Curve', 'Radiation', 'Recording of previous events', 'Resolution', 'Risk', 'Screening procedure', 'Staging', 'Stomas', 'Surface', 'Surgeon', 'Symptoms', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissues', 'Translating', 'Ultrasonography', 'Vision', 'Visual Acuity', 'artemis', 'base', 'case-based', 'crosslink', 'expectation', 'human subject', 'improved', 'indexing', 'instrument', 'instrumentation', 'method development', 'prevent', 'response']",NEI,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2011,345408,0.16589580611220262
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability.         PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.        ",Capti Screen Reading Assistant for Goal Directed Web Browsing,9048176,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Learning', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'empowered', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2016,500000,0.11367979430458844
"Capti Screen Reading Assistant for Goal Directed Web Browsing ﻿    DESCRIPTION (provided by applicant): Web browsing with assistive technologies such as screen readers and magnifiers can often be a frustrating and challenging experience for people with vision impairments, because it entails a lot of searching for content, forms, and links that are required for doing online tasks such as shopping, bill-payment, reservations, etc. This SBIR Phase II project will build on Phase I results and will continue the development and eventual deployment of Capti Screen Reading Assistant - a next-generation assistive technology, enabling goal- directed web browsing for people with visual impairments. With Capti Assistant, users will be able to stay focused on their high-level browsing goals that are expressed in natural language (spoken or typed). The Assistant will lead the users step-by-step towards the fulfillment of these goals by offering suggestions on what action to take at every step of the way and automatically executing the chosen action on behalf of the user. Suggested actions will include operations such as form filling, activating controls (e.g., clicking buttons and links), et. Capti Assistant will dramatically reduce the time spent by people with visual impairments on performing tasks online. The Assistant will significantly improve the speed and efficiency with which they can interact with the Web, thereby, making people with disabilities more productive in today's web-based economy. Given a user browsing goal, expressed in a natural-language form, Capti Assistant will utilize a predictive model to guide the user toward the goal. The unique aspect of the Assistant is that its suggestions will be automatically learned from the user's own history of browsing actions and commands, as well as from the user's demonstration of how to accomplish browsing tasks that have not been done before. The Assistant will process user commands and present the suggested browsing actions to the user on demand, giving the user a choice between following the suggestions or continue browsing normally without accepting the suggestions. The functionality offered by the Assistant will go far beyond popular personal assistant applications such as Siri, which have not been designed specifically for people with vision impairments, and which cannot be used for ad hocweb browsing. Capti Assistant will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the Web. For them, the Assistant will usher in a new era of independence and employability in our global web-based economy. Thus, from a broader perspective, goal- directed browsing will exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", i.e. anyone should be able to reap the benefits of the Web without being constrained by any disability. PUBLIC HEALTH RELEVANCE: This SBIR Project seeks to do Research and Development on goal-directed web browsing - the next generation accessible technology that will empower people with vision impairments to stay focused on their high-level browsing goals, while the browser will do low-level operations (such as clicking on links and filling forms) necessary to fulfill these goals. Goal-directed browsing will go a long way towards bridging the growing web accessibility divide between the ways people with and without vision impairments browse the web, thus improving independence and employability of the former in our global Web-based economy. From a broader perspective, goal-directed browsing will facilitate rehabilitation of people with disabilities and exemplify the vision of the Universally Accessible Web whose thesis is ""equal access for all"", enabling anyone to reap the benefits of the Web without being constrained by any disability.",Capti Screen Reading Assistant for Goal Directed Web Browsing,9199231,R44EY021962,"['Automation', 'Blindness', 'Budgets', 'Businesses', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disabled Persons', 'Ensure', 'Environment', 'Evaluation', 'FarGo', 'Focus Groups', 'Generations', 'Goals', 'Human Resources', 'In Situ', 'Information Retrieval', 'Internet', 'Internships', 'Laboratory Study', 'Lead', 'Legal patent', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mining', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Pattern', 'Phase', 'Probability', 'Process', 'Productivity', 'Publications', 'Publishing', 'Reader', 'Reading', 'Recording of previous events', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Reservations', 'Resources', 'Schedule', 'Scheme', 'Seasons', 'Self-Help Devices', 'Small Business Innovation Research Grant', 'Speed', 'Suggestion', 'System', 'Technology', 'Time', 'Universities', 'Vision', 'Visual impairment', 'Work', 'base', 'collaborative environment', 'commercial application', 'commercialization', 'computer human interaction', 'design', 'disability', 'educational atmosphere', 'experience', 'improved', 'innovation', 'member', 'natural language', 'next generation', 'novel strategies', 'operation', 'payment', 'predictive modeling', 'public health relevance', 'quality assurance', 'query optimization', 'research and development', 'response', 'success', 'technological innovation', 'tool', 'usability', 'web page', 'web-accessible']",NEI,"CHARMTECH LABS, LLC",R44,2017,500000,0.11367979430458844
"Video-based Speech Enhancement for Vision and Hearing Impairment     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Vision and Hearing Impairment,8659442,R21EY022200,"['Accounting', 'Acoustics', 'Activities of Daily Living', 'Address', 'Adult', 'Age', 'Age-Years', 'Aging-Related Process', 'Algorithms', 'Amplifiers', 'Area', 'Auditory', 'Blindness', 'Communication', 'Comprehension', 'Computer Vision Systems', 'Cues', 'Dependence', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Effectiveness', 'Elderly', 'Environment', 'Facial Expression', 'Feedback', 'Grant', 'Hearing Aids', 'Human', 'Laboratories', 'Lead', 'Learning', 'Life', 'Lip structure', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modality', 'Modeling', 'Noise', 'Output', 'Performance', 'Persons', 'Play', 'Population', 'Presbycusis', 'Process', 'Quality of life', 'Research', 'Role', 'Self-Help Devices', 'Sensory', 'Sensory Aids', 'Shapes', 'Signal Transduction', 'Societies', 'Source', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Staging', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Vision', 'Visual', 'Visual impairment', 'Voice', 'base', 'design', 'hearing impairment', 'improved', 'interest', 'novel strategies', 'performance tests', 'prototype', 'public health relevance', 'research study', 'signal processing', 'social', 'sound', 'speech recognition', 'tool development', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2014,230945,-0.0076809018193853724
"Video-based Speech Enhancement for Persons with Vision and Hearing Loss     DESCRIPTION (provided by applicant):  Video-based Speech Enhancement for Persons with Hearing and Vision Loss Project Summary It is estimated that by 2030, the number of people in the United States over the age of 65 will account for over 20% of the total population.  Hearing and vision loss naturally accompanies the aging process.  Persons with hearing loss can benefit from observing the visual cues from a speaker such as the shape of the lips and facial expression to greatly improve their ability to comprehend speech.  However, persons with vision loss cannot make use of these visual cues, and have a harder time understanding speech, especially in noisy environments.  Furthermore, people with normal vision can use visual information to identify a speaker in a group, which allows them to focus on this person.  This can greatly benefit a person with hearing loss who may be using a device such as a sound amplifier or a hearing aid.  A user with vision loss, however, needs to be provided with this speaker information to make optimal use of such devices.  We propose developing a prototype device that will clean the speech signal from a target speaker and improve speech comprehension for persons with hearing and vision loss in everyday situations.  In order to accomplish this task, we need to harness the visual cues that have so far largely been ignored in the design of assistive technolo- gies for persons with hearing loss.  Our first aim is to learn speaker-independent visual cues that are associated with the target speech signal, and use these audio-visual cues to design speech enhancement algorithms that perform much better in noisy everyday environment than current methods which only utilize the audio signal.  We will utilize a video camera and computer vision methods to design advanced digital signal processing techniques to enhance the target speech signals recorded through a microphone.  Our second aim is to use the video and audio signals to detect and efficiently localize the visible speaker.  The information regarding the location of the speaker of interest can then be used to efficiently perform speaker separation, as well as be provided to the user.  Finally, we aim to implement these developed algorithms on a portable prototype system.  We will test the performance of this system and improve the user-interface through user experiments in real-world situations as well as laboratory conditions.  The end product will show the feasibility and importance of incorporating multiple modalities into sensory assistive devices, and set the stage for future research and development efforts.         PUBLIC HEALTH RELEVANCE:  It is estimated that by 2030, more than one in five people in the United States will be over the age of 65.  Age- related hearing and vision loss is considered a natural consequence of the aging process, yet current assistive technology approaches do little to address this type of sensory loss.  The proposed research will test the feasibility of incorporating visual information in hearing aids, which is expected to improve speech perception for persons with hearing and vision loss in everyday situations, greatly enhancing their ability to lead independent lives, remain employable, and maintain active participation in society.                ",Video-based Speech Enhancement for Persons with Vision and Hearing Loss,8443624,R21EY022200,"['Accounting', 'Acoustics', 'Activities of Daily Living', 'Address', 'Adult', 'Age', 'Age-Years', 'Aging-Related Process', 'Algorithms', 'Amplifiers', 'Area', 'Auditory', 'Blindness', 'Communication', 'Comprehension', 'Computer Vision Systems', 'Cues', 'Dependence', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Effectiveness', 'Elderly', 'Environment', 'Facial Expression', 'Feedback', 'Grant', 'Hearing Aids', 'Human', 'Laboratories', 'Lead', 'Learning', 'Life', 'Lip structure', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modality', 'Modeling', 'Noise', 'Output', 'Performance', 'Persons', 'Play', 'Population', 'Presbycusis', 'Process', 'Quality of life', 'Research', 'Role', 'Self-Help Devices', 'Sensory', 'Sensory Aids', 'Shapes', 'Signal Transduction', 'Societies', 'Source', 'Speech', 'Speech Intelligibility', 'Speech Perception', 'Staging', 'System', 'Techniques', 'Testing', 'Time', 'United States', 'Vision', 'Visual', 'Visual impairment', 'Voice', 'base', 'computerized data processing', 'design', 'hearing impairment', 'improved', 'interest', 'novel strategies', 'performance tests', 'prototype', 'public health relevance', 'research study', 'social', 'sound', 'speech recognition', 'tool development', 'visual information']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R21,2013,198801,-0.003982588432164908
"Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor Summary The principal goal of this proposal is to increase the accuracy and precision of a low-cost autorefraction device called the QuickSee, in order to improve access to refractive eye care for underserved populations. Poor vision due to a lack of eyeglasses is highly prevalent in low-resource settings throughout the world and significantly reduces quality of life, education, and productivity. The existing QuickSee only extracts the lower- order aberration information contained within a wavefront profile of the eye, to roughly estimate an eyeglass prescription. This proposal will further improve the accuracy of the QuickSee device by exploiting both the lower- and higher-order aberrations contained within the complete wavefront. To realize this goal, we will enroll 300 subjects (600 eyes) in Baltimore, MD, and will obtain subjective refraction and visual acuity (VA) measurements and will use machine learning on this large dataset of wavefront profiles to optimize the wavefront-to-refraction algorithm of the QuickSee device. The main output of this project will be a robust and improved-accuracy next-generation QuickSee device that will increase efficiency of and decrease the training requirements of eye care professionals, and potentially dispense refractive correction that provides similar or better VA than correction from an eye care professional. Successful completion of this work will be an important step towards dramatically improving eyeglass accessibility for health disparity populations in the USA and internationally in low-resource settings. Upon completion of this proposal, we will apply for a Phase II award proposing to work with Wilmer Eye Institute research faculty to assess widespread deployment of the next-generation QuickSee with minimally-trained personnel in order to accurately and reliably provide thousands of pairs of low-cost corrective eyeglasses to underserved communities. Project Narrative This project proposal seeks to develop a novel technology that will disruptively increase the accessibility of refractive eye care for health disparity populations in low-resource settings. Specifically, sophisticated algorithms will be developed that improve the accuracy of the QuickSee device so that it can improve the efficiency of and reduce the training barriers for eye care professionals, and potentially provide refractive correction without the need for refinement by a trained eye care professional. Our goal is to develop a low- cost, easy-to-use, scalable solution to increase accessibility to vision correction globally.","Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor",9711194,R43EB024299,"['Algorithms', 'Award', 'Baltimore', 'Brazil', 'Businesses', 'Caliber', 'Calibration', 'Caring', 'Communities', 'Country', 'Data', 'Data Set', 'Developed Countries', 'Developing Countries', 'Development', 'Devices', 'Diagnostic', 'Education', 'Educational Status', 'Enrollment', 'Eye', 'Eyeglasses', 'Feedback', 'Geometry', 'Goals', 'Gold', 'Guatemala', 'Hospitals', 'Human Resources', 'Impairment', 'Improve Access', 'Income', 'India', 'Institutes', 'International', 'Machine Learning', 'Mali', 'Measurement', 'Measures', 'Modeling', 'Noise', 'Ophthalmic examination and evaluation', 'Optometrist', 'Output', 'Patient Schedules', 'Patients', 'Phase', 'Population', 'Prevalence', 'Procedures', 'Productivity', 'Pupil', 'Quality of life', 'Refractive Errors', 'Research Institute', 'Resources', 'Spottings', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Validation', 'Vision', 'Visual Acuity', 'Work', 'base', 'cost', 'faculty research', 'health care disparity', 'health disparity', 'improved', 'lens', 'new technology', 'next generation', 'novel strategies', 'success', 'vector']",NIBIB,"PLENOPTIKA, INC.",R43,2018,99914,0.08284499418604978
"Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor Summary The principal goal of this proposal is to increase the accuracy and precision of a low-cost autorefraction device called the QuickSee, in order to improve access to refractive eye care for underserved populations. Poor vision due to a lack of eyeglasses is highly prevalent in low-resource settings throughout the world and significantly reduces quality of life, education, and productivity. The existing QuickSee only extracts the lower- order aberration information contained within a wavefront profile of the eye, to roughly estimate an eyeglass prescription. This proposal will further improve the accuracy of the QuickSee device by exploiting both the lower- and higher-order aberrations contained within the complete wavefront. To realize this goal, we will enroll 300 subjects (600 eyes) in Baltimore, MD, and will obtain subjective refraction and visual acuity (VA) measurements and will use machine learning on this large dataset of wavefront profiles to optimize the wavefront-to-refraction algorithm of the QuickSee device. The main output of this project will be a robust and improved-accuracy next-generation QuickSee device that will increase efficiency of and decrease the training requirements of eye care professionals, and potentially dispense refractive correction that provides similar or better VA than correction from an eye care professional. Successful completion of this work will be an important step towards dramatically improving eyeglass accessibility for health disparity populations in the USA and internationally in low-resource settings. Upon completion of this proposal, we will apply for a Phase II award proposing to work with Wilmer Eye Institute research faculty to assess widespread deployment of the next-generation QuickSee with minimally-trained personnel in order to accurately and reliably provide thousands of pairs of low-cost corrective eyeglasses to underserved communities. Project Narrative This project proposal seeks to develop a novel technology that will disruptively increase the accessibility of refractive eye care for health disparity populations in low-resource settings. Specifically, sophisticated algorithms will be developed that improve the accuracy of the QuickSee device so that it can improve the efficiency of and reduce the training barriers for eye care professionals, and potentially provide refractive correction without the need for refinement by a trained eye care professional. Our goal is to develop a low- cost, easy-to-use, scalable solution to increase accessibility to vision correction globally.","Improving access to vision correction for health disparity populations with the QuickSee: an accurate, low-cost, easy-to-use objective refractor",9312420,R43EB024299,"['Algorithms', 'Award', 'Baltimore', 'Brazil', 'Businesses', 'Caliber', 'Calibration', 'Caring', 'Communities', 'Country', 'Data', 'Data Set', 'Developed Countries', 'Developing Countries', 'Development', 'Devices', 'Diagnostic', 'Education', 'Educational Status', 'Enrollment', 'Eye', 'Eyeglasses', 'Feedback', 'Geometry', 'Goals', 'Gold', 'Guatemala', 'Hospitals', 'Human Resources', 'Impairment', 'Improve Access', 'Income', 'India', 'Institutes', 'International', 'Machine Learning', 'Mali', 'Measurement', 'Measures', 'Modeling', 'Noise', 'Ophthalmic examination and evaluation', 'Optometrist', 'Output', 'Patient Schedules', 'Patients', 'Phase', 'Population', 'Prevalence', 'Procedures', 'Productivity', 'Pupil', 'Quality of life', 'Refractive Errors', 'Research Institute', 'Resources', 'Spottings', 'Testing', 'Time', 'Training', 'Underserved Population', 'Universities', 'Validation', 'Vision', 'Visual Acuity', 'Work', 'base', 'cost', 'faculty research', 'health care disparity', 'health disparity', 'improved', 'lens', 'new technology', 'next generation', 'novel strategies', 'success', 'vector']",NIBIB,"PLENOPTIKA, INC.",R43,2017,200225,0.08284499418604978
"Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure Abstract The burden of blindness and visual impairment in the United States is expected to double between 2015 and 2050 to 8.96 million people. Blacks, Hispanics and older individuals will be disproportionally affected, further accentuating the disparate impact of vision disorders. Although low vision rehabilitation (LVR) has been shown to improve the functioning of patients, considerable opportunities remain to better understand and overcome functional limitations due to low vision. Specifically, the effectiveness of LVR for patients with peripheral field loss (PFL) has not been well-studied, though 15-20% of patients presenting for LVR have glaucoma or a retinal degeneration, two important causes of PFL. In order to evaluate and compare interventions for this population, a highly relevant measure of functioning is needed. The proposed project will address this through the development and validation of a patient-reported outcome measure, the Low Vision Severely Constricted Peripheral Eyesight (LV-SCOPE) Assessment. In Aim 1 of this proposal, focus groups with patients, caretakers and vision providers will identify the impairments and LVR goals associated with severe PFL. Since PFL often exists in combination with visual acuity loss, patients with PFL and a range of visual acuities will be included. We anticipate that PFL will preferentially impact known functions of the dorsal visual processing stream, as this pathway depends on peripheral vision for spatial awareness and motor behavior. In Aim 2, focus group data will guide the selection of survey items for the outcome measure. In Aim 3, psychometric evaluations will test the validity, reliability and precision of the LV-SCOPE. Once validated, the LV-SCOPE may be an optimal outcome measure to evaluate and identify targeted LVR strategies for patients with PFL, a sizable understudied population. This project directly addresses the National Eye Institute's low vision priority research area “to create and validate vision tests relevant for the tasks of daily living.” Dr. Ehrlich's long-term career goal is to improve the vision-dependent functioning of patients with low vision. He will achieve this through coursework, mentorship and research to improve the measurement of functional impairment and facilitate the evaluation of targeted LVR strategies. The applicant's training plan is a natural progression from his background in ophthalmology, clinical research and public health. He will acquire knowledge and expertise in outcome measure development and psychometrics, low vision and rehabilitation, mixed-methods analyses and clinical trials. Dr. Ehrlich has devised a plan of pertinent coursework, individualized mentorship, and directed self-study to achieve his training and research goals. Dr. Ehrlich's career development will benefit from the vast resources of the University of Michigan and the support of his mentors, including Drs. Noelle Carlozzi, Paul Lee, Robert Massof and Joan Stelmack. This proposal demonstrates Dr. Ehrlich's commitment to gaining the necessary skills to become an independent investigator and to addressing a pressing public health need. Project Narrative The permanent loss of vision has been shown to adversely affect day-to-day functioning, and quality of life. Vision rehabilitation may improve patients' functional abilities through the use of assistive devices and educational strategies. However, the effectiveness of rehabilitation options for patients with peripheral vision loss is poorly known since most prior research has focused on patients with central vision loss. In order to evaluate and compare the effectiveness of low vision rehabilitation strategies for patients with peripheral vision loss, a valid and reliable method for measuring vision-dependent functioning is needed. The proposed research will use the insights of patients, their caregivers and their vision care providers to develop a patient- reported outcome measure that assesses functioning in patients with low vision due to severe peripheral vision loss and can be used in future clinical trials of low vision interventions for this population. This project is relevant to the mission of the National Eye Institute, as it aims to address visual impairment and improve quality of life.",Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure,9770881,K23EY027848,"['Activities of Daily Living', 'Address', 'Affect', 'Area', 'Attenuated', 'Awareness', 'Behavior', 'Blindness', 'Caregivers', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Consensus', 'Data', 'Development', 'Dorsal', 'Effectiveness', 'Ensure', 'Evaluation', 'Focus Groups', 'Future', 'Glaucoma', 'Goals', 'Hispanics', 'Impairment', 'Individual', 'Institutes', 'Intervention', 'Journals', 'Knowledge', 'Life', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Motion Perception', 'Motor', 'National Eye Institute', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Outcomes Assessments', 'Patient-Focused Outcomes', 'Patients', 'Peripheral', 'Population', 'Population Intervention', 'Prevalence', 'Principal Component Analysis', 'Provider', 'Psychometrics', 'Public Health', 'Quality of life', 'Randomized Controlled Trials', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Priority', 'Retinal Degeneration', 'Review Literature', 'Self-Direction', 'Self-Help Devices', 'Stream', 'Surveys', 'Testing', 'Training', 'United States', 'University resources', 'Validation', 'Validity and Reliability', 'Vision', 'Vision Disorders', 'Vision Tests', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'blind', 'care providers', 'career', 'career development', 'cognitive interview', 'compare effectiveness', 'design', 'functional disability', 'improved', 'improved functioning', 'insight', 'instrument', 'patient oriented', 'programs', 'rehabilitation strategy', 'response', 'skills', 'spatial vision', 'systematic review', 'theories', 'vision rehabilitation', 'visual information', 'visual processing']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K23,2019,232558,0.24855960958189116
"Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure Abstract The burden of blindness and visual impairment in the United States is expected to double between 2015 and 2050 to 8.96 million people. Blacks, Hispanics and older individuals will be disproportionally affected, further accentuating the disparate impact of vision disorders. Although low vision rehabilitation (LVR) has been shown to improve the functioning of patients, considerable opportunities remain to better understand and overcome functional limitations due to low vision. Specifically, the effectiveness of LVR for patients with peripheral field loss (PFL) has not been well-studied, though 15-20% of patients presenting for LVR have glaucoma or a retinal degeneration, two important causes of PFL. In order to evaluate and compare interventions for this population, a highly relevant measure of functioning is needed. The proposed project will address this through the development and validation of a patient-reported outcome measure, the Low Vision Severely Constricted Peripheral Eyesight (LV-SCOPE) Assessment. In Aim 1 of this proposal, focus groups with patients, caretakers and vision providers will identify the impairments and LVR goals associated with severe PFL. Since PFL often exists in combination with visual acuity loss, patients with PFL and a range of visual acuities will be included. We anticipate that PFL will preferentially impact known functions of the dorsal visual processing stream, as this pathway depends on peripheral vision for spatial awareness and motor behavior. In Aim 2, focus group data will guide the selection of survey items for the outcome measure. In Aim 3, psychometric evaluations will test the validity, reliability and precision of the LV-SCOPE. Once validated, the LV-SCOPE may be an optimal outcome measure to evaluate and identify targeted LVR strategies for patients with PFL, a sizable understudied population. This project directly addresses the National Eye Institute's low vision priority research area “to create and validate vision tests relevant for the tasks of daily living.” Dr. Ehrlich's long-term career goal is to improve the vision-dependent functioning of patients with low vision. He will achieve this through coursework, mentorship and research to improve the measurement of functional impairment and facilitate the evaluation of targeted LVR strategies. The applicant's training plan is a natural progression from his background in ophthalmology, clinical research and public health. He will acquire knowledge and expertise in outcome measure development and psychometrics, low vision and rehabilitation, mixed-methods analyses and clinical trials. Dr. Ehrlich has devised a plan of pertinent coursework, individualized mentorship, and directed self-study to achieve his training and research goals. Dr. Ehrlich's career development will benefit from the vast resources of the University of Michigan and the support of his mentors, including Drs. Noelle Carlozzi, Paul Lee, Robert Massof and Joan Stelmack. This proposal demonstrates Dr. Ehrlich's commitment to gaining the necessary skills to become an independent investigator and to addressing a pressing public health need. Project Narrative The permanent loss of vision has been shown to adversely affect day-to-day functioning, and quality of life. Vision rehabilitation may improve patients' functional abilities through the use of assistive devices and educational strategies. However, the effectiveness of rehabilitation options for patients with peripheral vision loss is poorly known since most prior research has focused on patients with central vision loss. In order to evaluate and compare the effectiveness of low vision rehabilitation strategies for patients with peripheral vision loss, a valid and reliable method for measuring vision-dependent functioning is needed. The proposed research will use the insights of patients, their caregivers and their vision care providers to develop a patient- reported outcome measure that assesses functioning in patients with low vision due to severe peripheral vision loss and can be used in future clinical trials of low vision interventions for this population. This project is relevant to the mission of the National Eye Institute, as it aims to address visual impairment and improve quality of life.",Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure,9549107,K23EY027848,"['Activities of Daily Living', 'Address', 'Affect', 'Area', 'Attenuated', 'Awareness', 'Behavior', 'Blindness', 'Caregivers', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Consensus', 'Data', 'Development', 'Dorsal', 'Effectiveness', 'Ensure', 'Evaluation', 'Focus Groups', 'Future', 'Glaucoma', 'Goals', 'Hispanics', 'Impairment', 'Individual', 'Institutes', 'Intervention', 'Interview', 'Journals', 'Knowledge', 'Life', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Motion Perception', 'Motor', 'National Eye Institute', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Outcomes Assessments', 'Patient-Focused Outcomes', 'Patients', 'Peripheral', 'Population', 'Population Intervention', 'Prevalence', 'Principal Component Analysis', 'Provider', 'Psychometrics', 'Public Health', 'Quality of life', 'Randomized Controlled Trials', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Priority', 'Retinal Degeneration', 'Review Literature', 'Self-Direction', 'Self-Help Devices', 'Stream', 'Surveys', 'Testing', 'Training', 'United States', 'University resources', 'Validation', 'Validity and Reliability', 'Vision', 'Vision Disorders', 'Vision Tests', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'blind', 'care providers', 'career', 'career development', 'compare effectiveness', 'design', 'functional disability', 'improved', 'improved functioning', 'insight', 'instrument', 'patient oriented', 'programs', 'rehabilitation strategy', 'response', 'skills', 'spatial vision', 'systematic review', 'theories', 'vision rehabilitation', 'visual information', 'visual processing']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K23,2018,232271,0.24855960958189116
"Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure Abstract The burden of blindness and visual impairment in the United States is expected to double between 2015 and 2050 to 8.96 million people. Blacks, Hispanics and older individuals will be disproportionally affected, further accentuating the disparate impact of vision disorders. Although low vision rehabilitation (LVR) has been shown to improve the functioning of patients, considerable opportunities remain to better understand and overcome functional limitations due to low vision. Specifically, the effectiveness of LVR for patients with peripheral field loss (PFL) has not been well-studied, though 15-20% of patients presenting for LVR have glaucoma or a retinal degeneration, two important causes of PFL. In order to evaluate and compare interventions for this population, a highly relevant measure of functioning is needed. The proposed project will address this through the development and validation of a patient-reported outcome measure, the Low Vision Severely Constricted Peripheral Eyesight (LV-SCOPE) Assessment. In Aim 1 of this proposal, focus groups with patients, caretakers and vision providers will identify the impairments and LVR goals associated with severe PFL. Since PFL often exists in combination with visual acuity loss, patients with PFL and a range of visual acuities will be included. We anticipate that PFL will preferentially impact known functions of the dorsal visual processing stream, as this pathway depends on peripheral vision for spatial awareness and motor behavior. In Aim 2, focus group data will guide the selection of survey items for the outcome measure. In Aim 3, psychometric evaluations will test the validity, reliability and precision of the LV-SCOPE. Once validated, the LV-SCOPE may be an optimal outcome measure to evaluate and identify targeted LVR strategies for patients with PFL, a sizable understudied population. This project directly addresses the National Eye Institute's low vision priority research area “to create and validate vision tests relevant for the tasks of daily living.” Dr. Ehrlich's long-term career goal is to improve the vision-dependent functioning of patients with low vision. He will achieve this through coursework, mentorship and research to improve the measurement of functional impairment and facilitate the evaluation of targeted LVR strategies. The applicant's training plan is a natural progression from his background in ophthalmology, clinical research and public health. He will acquire knowledge and expertise in outcome measure development and psychometrics, low vision and rehabilitation, mixed-methods analyses and clinical trials. Dr. Ehrlich has devised a plan of pertinent coursework, individualized mentorship, and directed self-study to achieve his training and research goals. Dr. Ehrlich's career development will benefit from the vast resources of the University of Michigan and the support of his mentors, including Drs. Noelle Carlozzi, Paul Lee, Robert Massof and Joan Stelmack. This proposal demonstrates Dr. Ehrlich's commitment to gaining the necessary skills to become an independent investigator and to addressing a pressing public health need. Project Narrative The permanent loss of vision has been shown to adversely affect day-to-day functioning, and quality of life. Vision rehabilitation may improve patients' functional abilities through the use of assistive devices and educational strategies. However, the effectiveness of rehabilitation options for patients with peripheral vision loss is poorly known since most prior research has focused on patients with central vision loss. In order to evaluate and compare the effectiveness of low vision rehabilitation strategies for patients with peripheral vision loss, a valid and reliable method for measuring vision-dependent functioning is needed. The proposed research will use the insights of patients, their caregivers and their vision care providers to develop a patient- reported outcome measure that assesses functioning in patients with low vision due to severe peripheral vision loss and can be used in future clinical trials of low vision interventions for this population. This project is relevant to the mission of the National Eye Institute, as it aims to address visual impairment and improve quality of life.",Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure,9294683,K23EY027848,"['Activities of Daily Living', 'Address', 'Affect', 'Area', 'Attenuated', 'Awareness', 'Behavior', 'Blindness', 'Caregivers', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Consensus', 'Data', 'Development', 'Dorsal', 'Effectiveness', 'Ensure', 'Evaluation', 'Focus Groups', 'Future', 'Glaucoma', 'Goals', 'Hispanics', 'Impairment', 'Individual', 'Institutes', 'Intervention', 'Interview', 'Journals', 'Knowledge', 'Life', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Motion Perception', 'Motor', 'National Eye Institute', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Outcomes Assessments', 'Patient-Focused Outcomes', 'Patients', 'Peripheral', 'Population', 'Population Intervention', 'Prevalence', 'Principal Component Analysis', 'Provider', 'Psychometrics', 'Public Health', 'Quality of life', 'Randomized Controlled Trials', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Priority', 'Retinal Degeneration', 'Review Literature', 'Self-Direction', 'Self-Help Devices', 'Stream', 'Surveys', 'Testing', 'Training', 'United States', 'University resources', 'Validation', 'Validity and Reliability', 'Vision', 'Vision Disorders', 'Vision Tests', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'blind', 'career', 'career development', 'compare effectiveness', 'design', 'functional disability', 'improved', 'improved functioning', 'information processing', 'insight', 'instrument', 'patient oriented', 'programs', 'rehabilitation strategy', 'response', 'skills', 'spatial vision', 'systematic review', 'theories', 'vision rehabilitation', 'visual processing']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K23,2017,224478,0.24855960958189116
"Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure Abstract The burden of blindness and visual impairment in the United States is expected to double between 2015 and 2050 to 8.96 million people. Blacks, Hispanics and older individuals will be disproportionally affected, further accentuating the disparate impact of vision disorders. Although low vision rehabilitation (LVR) has been shown to improve the functioning of patients, considerable opportunities remain to better understand and overcome functional limitations due to low vision. Specifically, the effectiveness of LVR for patients with peripheral field loss (PFL) has not been well-studied, though 15-20% of patients presenting for LVR have glaucoma or a retinal degeneration, two important causes of PFL. In order to evaluate and compare interventions for this population, a highly relevant measure of functioning is needed. The proposed project will address this through the development and validation of a patient-reported outcome measure, the Low Vision Severely Constricted Peripheral Eyesight (LV-SCOPE) Assessment. In Aim 1 of this proposal, focus groups with patients, caretakers and vision providers will identify the impairments and LVR goals associated with severe PFL. Since PFL often exists in combination with visual acuity loss, patients with PFL and a range of visual acuities will be included. We anticipate that PFL will preferentially impact known functions of the dorsal visual processing stream, as this pathway depends on peripheral vision for spatial awareness and motor behavior. In Aim 2, focus group data will guide the selection of survey items for the outcome measure. In Aim 3, psychometric evaluations will test the validity, reliability and precision of the LV-SCOPE. Once validated, the LV-SCOPE may be an optimal outcome measure to evaluate and identify targeted LVR strategies for patients with PFL, a sizable understudied population. This project directly addresses the National Eye Institute's low vision priority research area “to create and validate vision tests relevant for the tasks of daily living.” Dr. Ehrlich's long-term career goal is to improve the vision-dependent functioning of patients with low vision. He will achieve this through coursework, mentorship and research to improve the measurement of functional impairment and facilitate the evaluation of targeted LVR strategies. The applicant's training plan is a natural progression from his background in ophthalmology, clinical research and public health. He will acquire knowledge and expertise in outcome measure development and psychometrics, low vision and rehabilitation, mixed-methods analyses and clinical trials. Dr. Ehrlich has devised a plan of pertinent coursework, individualized mentorship, and directed self-study to achieve his training and research goals. Dr. Ehrlich's career development will benefit from the vast resources of the University of Michigan and the support of his mentors, including Drs. Noelle Carlozzi, Paul Lee, Robert Massof and Joan Stelmack. This proposal demonstrates Dr. Ehrlich's commitment to gaining the necessary skills to become an independent investigator and to addressing a pressing public health need. Project Narrative The permanent loss of vision has been shown to adversely affect day-to-day functioning, and quality of life. Vision rehabilitation may improve patients' functional abilities through the use of assistive devices and educational strategies. However, the effectiveness of rehabilitation options for patients with peripheral vision loss is poorly known since most prior research has focused on patients with central vision loss. In order to evaluate and compare the effectiveness of low vision rehabilitation strategies for patients with peripheral vision loss, a valid and reliable method for measuring vision-dependent functioning is needed. The proposed research will use the insights of patients, their caregivers and their vision care providers to develop a patient- reported outcome measure that assesses functioning in patients with low vision due to severe peripheral vision loss and can be used in future clinical trials of low vision interventions for this population. This project is relevant to the mission of the National Eye Institute, as it aims to address visual impairment and improve quality of life.",Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure,9699116,K23EY027848,"['Activities of Daily Living', 'Address', 'Affect', 'Area', 'Attenuated', 'Awareness', 'Behavior', 'Blindness', 'Caregivers', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Consensus', 'Data', 'Development', 'Dorsal', 'Effectiveness', 'Ensure', 'Evaluation', 'Focus Groups', 'Future', 'Glaucoma', 'Goals', 'Hispanics', 'Impairment', 'Individual', 'Institutes', 'Intervention', 'Interview', 'Journals', 'Knowledge', 'Life', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Motion Perception', 'Motor', 'National Eye Institute', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Outcomes Assessments', 'Patient-Focused Outcomes', 'Patients', 'Peripheral', 'Population', 'Population Intervention', 'Prevalence', 'Principal Component Analysis', 'Provider', 'Psychometrics', 'Public Health', 'Quality of life', 'Randomized Controlled Trials', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Priority', 'Retinal Degeneration', 'Review Literature', 'Self-Direction', 'Self-Help Devices', 'Stream', 'Surveys', 'Testing', 'Training', 'United States', 'University resources', 'Validation', 'Validity and Reliability', 'Vision', 'Vision Disorders', 'Vision Tests', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'blind', 'care providers', 'career', 'career development', 'compare effectiveness', 'design', 'functional disability', 'improved', 'improved functioning', 'insight', 'instrument', 'patient oriented', 'programs', 'rehabilitation strategy', 'response', 'skills', 'spatial vision', 'systematic review', 'theories', 'vision rehabilitation', 'visual information', 'visual processing']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K23,2018,7784,0.24855960958189116
"Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure Abstract The burden of blindness and visual impairment in the United States is expected to double between 2015 and 2050 to 8.96 million people. Blacks, Hispanics and older individuals will be disproportionally affected, further accentuating the disparate impact of vision disorders. Although low vision rehabilitation (LVR) has been shown to improve the functioning of patients, considerable opportunities remain to better understand and overcome functional limitations due to low vision. Specifically, the effectiveness of LVR for patients with peripheral field loss (PFL) has not been well-studied, though 15-20% of patients presenting for LVR have glaucoma or a retinal degeneration, two important causes of PFL. In order to evaluate and compare interventions for this population, a highly relevant measure of functioning is needed. The proposed project will address this through the development and validation of a patient-reported outcome measure, the Low Vision Severely Constricted Peripheral Eyesight (LV-SCOPE) Assessment. In Aim 1 of this proposal, focus groups with patients, caretakers and vision providers will identify the impairments and LVR goals associated with severe PFL. Since PFL often exists in combination with visual acuity loss, patients with PFL and a range of visual acuities will be included. We anticipate that PFL will preferentially impact known functions of the dorsal visual processing stream, as this pathway depends on peripheral vision for spatial awareness and motor behavior. In Aim 2, focus group data will guide the selection of survey items for the outcome measure. In Aim 3, psychometric evaluations will test the validity, reliability and precision of the LV-SCOPE. Once validated, the LV-SCOPE may be an optimal outcome measure to evaluate and identify targeted LVR strategies for patients with PFL, a sizable understudied population. This project directly addresses the National Eye Institute's low vision priority research area “to create and validate vision tests relevant for the tasks of daily living.” Dr. Ehrlich's long-term career goal is to improve the vision-dependent functioning of patients with low vision. He will achieve this through coursework, mentorship and research to improve the measurement of functional impairment and facilitate the evaluation of targeted LVR strategies. The applicant's training plan is a natural progression from his background in ophthalmology, clinical research and public health. He will acquire knowledge and expertise in outcome measure development and psychometrics, low vision and rehabilitation, mixed-methods analyses and clinical trials. Dr. Ehrlich has devised a plan of pertinent coursework, individualized mentorship, and directed self-study to achieve his training and research goals. Dr. Ehrlich's career development will benefit from the vast resources of the University of Michigan and the support of his mentors, including Drs. Noelle Carlozzi, Paul Lee, Robert Massof and Joan Stelmack. This proposal demonstrates Dr. Ehrlich's commitment to gaining the necessary skills to become an independent investigator and to addressing a pressing public health need. Project Narrative The permanent loss of vision has been shown to adversely affect day-to-day functioning, and quality of life. Vision rehabilitation may improve patients' functional abilities through the use of assistive devices and educational strategies. However, the effectiveness of rehabilitation options for patients with peripheral vision loss is poorly known since most prior research has focused on patients with central vision loss. In order to evaluate and compare the effectiveness of low vision rehabilitation strategies for patients with peripheral vision loss, a valid and reliable method for measuring vision-dependent functioning is needed. The proposed research will use the insights of patients, their caregivers and their vision care providers to develop a patient- reported outcome measure that assesses functioning in patients with low vision due to severe peripheral vision loss and can be used in future clinical trials of low vision interventions for this population. This project is relevant to the mission of the National Eye Institute, as it aims to address visual impairment and improve quality of life.",Addressing Low Vision due to Severe Peripheral Field Loss: Development and Validation of a Patient-Centered Outcome Measure,10003258,K23EY027848,"['Activities of Daily Living', 'Address', 'Affect', 'Area', 'Attenuated', 'Awareness', 'Blindness', 'Caregivers', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Consensus', 'Data', 'Development', 'Dorsal', 'Effectiveness', 'Ensure', 'Evaluation', 'Focus Groups', 'Future', 'Glaucoma', 'Goals', 'Hispanics', 'Impairment', 'Individual', 'Institutes', 'Intervention', 'Journals', 'Knowledge', 'Life', 'Measurement', 'Measures', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Michigan', 'Mission', 'Modeling', 'Motion Perception', 'National Eye Institute', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Outcome Measure', 'Outcomes Research', 'Pathway interactions', 'Patient Outcomes Assessments', 'Patient-Focused Outcomes', 'Patients', 'Peripheral', 'Population', 'Population Intervention', 'Prevalence', 'Principal Component Analysis', 'Provider', 'Psychometrics', 'Public Health', 'Quality of life', 'Randomized Controlled Trials', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Priority', 'Retinal Degeneration', 'Review Literature', 'Self-Direction', 'Self-Help Devices', 'Stream', 'Surveys', 'Testing', 'Training', 'United States', 'University resources', 'Validation', 'Validity and Reliability', 'Vision', 'Vision Disorders', 'Vision Tests', 'Visual Acuity', 'Visual Fields', 'Visual impairment', 'Work', 'blind', 'care providers', 'career', 'career development', 'cognitive interview', 'compare effectiveness', 'comparison intervention', 'design', 'functional disability', 'improved', 'improved functioning', 'insight', 'instrument', 'motor behavior', 'patient oriented', 'programs', 'rehabilitation strategy', 'response', 'skills', 'spatial vision', 'systematic review', 'theories', 'vision rehabilitation', 'visual information', 'visual processing']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,K23,2020,232894,0.24855960958189116
"The Human Foveal Connectome The complex relationship of cone photoreceptor cells with retinal circuits, Müller glia, and retinal pigment epithelial (RPE) cells is essential to normal vision. Yet for the cones in the very center of the fovea that mediate peak visual acuity these relationships are poorly characterized. A longstanding barrier to a comprehensive understanding of cellular and subcellular foveal structure is the myriad interactions among a great diversity of cell types embedded and miniaturized within a complex three-dimensional architecture. The broad long-term objective of this new research program is to elucidate foveal microstructure directly by application of new methods of volume electron microscopy (connectomics). We will utilize retinal tissue acquired from an innovative organ donor program that will permit pre-recovery optical coherence tomography (OCT) imaging to assess retinal health status and foveal pit morphology and to guide connectomic reconstruction. Preliminary data from two donor eyes demonstrates feasibility of complete reconstructions of foveal cones and their associated synaptic pathways, Müller cells, and RPE cells. The first reconstructions of cone microcircuits from an adult born preterm indicate that the critical cells and synaptic pathways for foveal vision differ dramatically in structure and localization anticipated from previous work on non-human primates. Therefore in Aim 1 we propose to localize, identify and reconstruct quantitatively the synaptic visual pathways that arise from the central-most foveal cones. We will characterize all of the bipolar and ganglion cell circuits arising from these cones and test the new hypothesis that the dominant “midget” pathway subserving spatial acuity may be highly variable across individuals in both circuitry and pit localization. We will further test the hypothesis that beyond the midget circuit the foveal center gives rise to over twenty distinct but as yet uncharacterized visual pathways. The first reconstructions of Müller cells revealed the intimate wrapping of cone axons and abundance of processes in the plexiform layer and foveal floor. In Aim 2 we propose complete reconstructions of Müller cells to test the hypotheses that the foveal floor contains a novel Müller cell type restricted to inner retina and that morphology of individual Müller cells and their foveal distribution accounts for the macular pigment distribution. The first reconstructions of RPE cells provided new insights on the distribution of organelles important in clinical OCT and autofluorescence imaging. Therefore, in Aim 3 we propose to reconstruct and enumerate organelles in RPE cells in the cone-only fovea and the mixed rod-cone perifovea. We will directly test the hypothesis that RPE organelle content and distribution differs between cone-only fovea and rod-rich perifovea, accounting for the appearance of OCT bands and for topography of autofluorescence signal in clinical imaging. This proposal combines expertise and innovation in neurobiology, pathology, imaging, and connectomics. Outcomes will impact retinal neurobiology, clinical image interpretation, and pathophysiology of macular diseases, especially age-related macular degeneration. The human fovea is essential for best vision but understanding the crucial cellular interactions among photoreceptors, neural circuits and supporting non-neural cells in the foveal center is limited because the extremely miniaturized and complex three-dimensional structure and synaptic organization of this region is difficult to untangle with conventional methods. The proposed project will apply new methods of volume electron microscopy (“connectomics”) to reconstruct the human fovea for the first time. Outcomes will have broad significance for retinal neuroscience, clinical image interpretation, and the pathophysiology of macular disease, especially age-related macular degeneration.",The Human Foveal Connectome,9883529,R01EY028282,"['3-Dimensional', 'Accounting', 'Address', 'Adult', 'Age related macular degeneration', 'Aging', 'Anatomy', 'Apical', 'Appearance', 'Architecture', 'Area', 'Axon', 'Biological Process', 'Catalogs', 'Cells', 'Cellular Morphology', 'Characteristics', 'Clinical', 'Complex', 'Cone', 'Data', 'Development', 'Disease', 'Electron Microscopy', 'Eye', 'Female', 'Floor', 'Functional disorder', 'Future', 'Goals', 'Health Status', 'Human', 'Image', 'Image Analysis', 'Individual', 'Lead', 'Link', 'Lipofuscin', 'Location', 'Machine Learning', 'Mediating', 'Melanosomes', 'Methods', 'Miniaturization', 'Mitochondria', 'Morphology', 'Muller&apos', 's cell', 'Neurobiology', 'Neurosciences', 'Optical Coherence Tomography', 'Organ Donor', 'Organelles', 'Outcome', 'Pathway interactions', 'Photoreceptors', 'Pigments', 'Process', 'Recovery', 'Research', 'Resources', 'Retina', 'Retinal Cone', 'Retinal Diseases', 'Rod', 'Services', 'Signal Transduction', 'Source', 'Structure', 'Structure of retinal pigment epithelium', 'Supporting Cell', 'Synapses', 'Technology', 'Testing', 'Time', 'Tissues', 'Variant', 'Vertebrate Photoreceptors', 'Vision', 'Visual Acuity', 'Visual Pathways', 'Work', 'cell type', 'clinical imaging', 'connectome', 'density', 'disorder of macula of retina', 'fovea centralis', 'ganglion cell', 'in vivo imaging', 'innovation', 'insight', 'macula', 'male', 'miniaturize', 'neural circuit', 'nonhuman primate', 'novel', 'pathology imaging', 'postsynaptic', 'programs', 'reconstruction', 'relating to nervous system', 'resilience', 'three dimensional structure', 'tool', 'visual performance']",NEI,UNIVERSITY OF WASHINGTON,R01,2020,505976,-0.013748225524090671
"Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision Summary  Restoring vision to the blind has been an age-old dream, but it took an avalanche of biomedical research and  development over the last few decades to begin turning this dream into reality.  In recent years the potential of saving  and restoring sight has been demonstrated in vitro, in animal models, and in some cases even in human patients.  With  the advent of early clinical trials for these therapies, often primarily aimed at safety and enrolling patients with profound  vision loss, there is a growing need for vision assessments that not only can measure rudimentary vision, but reliably  demonstrate small changes.  Ideally these measures should also demonstrate efficacy in real-world situations, and  include the use of vision for tasks such as eye-hand coordination, orientation, and mobility.  In our laboratory we have demonstrated that the properties of rudimentary “native” vision can be assessed with a  visual functioning questionnaire specifically designed for ultra-low vision, the ULV-VFQ, and with a set of standardized  visual activities of daily living, the ULV-ADL.  Moreover, we demonstrated that the performance of users of the Argus II  retinal prosthesis system and the BrainPort vision substitution device is very similar to that of individuals with native  ULV.  This application lays out a program to validate the previously completed assessments in a larger ULV population  (Aim 1), to develop a range of additional assessments (Aim 2), to translate a subset of the visual activities used in these  assessments to real-world situations and minimize redundancies (Aim 3), and to assess the similarity in performance  between individuals with native ULV and recipients of the Argus II, BrainPort, and other sight-restoring treatments (Aim  4).  The new assessments under Aim 2 will cover instrumental activities of daily living (IADL) and orientation & mobility  (O&M), and all assessments will cover both static and dynamic scenarios.  Our long-term collaborator Dr. Duane  Geruschat will act as a consultant in the design and evaluation of these assess.ements.  Human subjects testing will be carried out at the Johns Hopkins Wilmer Eye Institute and the Chicago Lighthouse,  which not only counts a substantial ULV population among its employees and clients, but also a number of BrainPort  users.  Investigators at both sites have extensive research experience with this population.  O&M scenarios under Aim 2  will be realized in virtual reality with the assistance of our partners at Balti Virtual.  The resulting assessments promise to  not only have a major impact on future clinical trials of sight-restoring therapies, but also lay the foundation to  rehabilitation approaches for recipients of such therapies. Narrative  With the advent of new treatments that aim to restore vision to the blind there is an increasing need for reliable  measurement of very low vision levels, so changes in vision related to the treatment can be documented.  We have  previously designed some of these measures and are proposing to demonstrate their reliability in a large population of  individuals with profoundly impaired (“ultra-low”) vision, and to develop a broad range of additional vision measures  that are sensitive to ultra-low vision, for use in future clinical trials of sight-restoring therapies.  Participants in these  studies will be patients with very limited (so-called Ultra-Low) vision and users of the Brainport vision substitution device  and the Argus II retinal implant.",Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision,9942458,R01EY028452,"['Activities of Daily Living', 'Address', 'Age', 'Animal Model', 'Assessment tool', 'Award', 'Baltimore', 'Benefits and Risks', 'Biomedical Research', 'Blindness', 'Chicago', 'Client', 'Clinic', 'Clinical', 'Clinical Trials', 'Consumption', 'Devices', 'Dimensions', 'Disease', 'Dreams', 'Employee', 'Enrollment', 'Equilibrium', 'Equipment and supply inventories', 'Evaluation', 'Eye', 'Foundations', 'Future', 'Health', 'Human', 'Impairment', 'In Vitro', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Judgment', 'Laboratories', 'Life', 'Light', 'Maryland', 'Measurement', 'Measures', 'Medical', 'Modality', 'Ocular Prosthesis', 'Outcome', 'Participant', 'Patient Self-Report', 'Patients', 'Perception', 'Performance', 'Persons', 'Population', 'Preparation', 'Principal Component Analysis', 'Property', 'Prosthesis', 'Questionnaires', 'Regenerative Medicine', 'Regulation', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Safety', 'Savings', 'Services', 'Shapes', 'Side', 'Site', 'Standardization', 'System', 'Testing', 'Therapeutic Intervention', 'Therapy Clinical Trials', 'Time', 'Translating', 'Vision', 'Visual', 'Visual impairment', 'blind', 'design', 'early phase clinical trial', 'expectation', 'experience', 'eye hand coordination', 'human subject', 'instrumental activity of daily living', 'novel', 'programs', 'recruit', 'regenerative', 'regenerative therapy', 'research and development', 'response', 'restoration', 'retina implantation', 'retinal prosthesis', 'statistics', 'stem cells', 'therapeutic gene', 'tool', 'virtual', 'virtual reality', 'visual performance']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2020,371421,0.2577791992245512
"Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision Summary  Restoring vision to the blind has been an age-old dream, but it took an avalanche of biomedical research and  development over the last few decades to begin turning this dream into reality.  In recent years the potential of saving  and restoring sight has been demonstrated in vitro, in animal models, and in some cases even in human patients.  With  the advent of early clinical trials for these therapies, often primarily aimed at safety and enrolling patients with profound  vision loss, there is a growing need for vision assessments that not only can measure rudimentary vision, but reliably  demonstrate small changes.  Ideally these measures should also demonstrate efficacy in real-world situations, and  include the use of vision for tasks such as eye-hand coordination, orientation, and mobility.  In our laboratory we have demonstrated that the properties of rudimentary “native” vision can be assessed with a  visual functioning questionnaire specifically designed for ultra-low vision, the ULV-VFQ, and with a set of standardized  visual activities of daily living, the ULV-ADL.  Moreover, we demonstrated that the performance of users of the Argus II  retinal prosthesis system and the BrainPort vision substitution device is very similar to that of individuals with native  ULV.  This application lays out a program to validate the previously completed assessments in a larger ULV population  (Aim 1), to develop a range of additional assessments (Aim 2), to translate a subset of the visual activities used in these  assessments to real-world situations and minimize redundancies (Aim 3), and to assess the similarity in performance  between individuals with native ULV and recipients of the Argus II, BrainPort, and other sight-restoring treatments (Aim  4).  The new assessments under Aim 2 will cover instrumental activities of daily living (IADL) and orientation & mobility  (O&M), and all assessments will cover both static and dynamic scenarios.  Our long-term collaborator Dr. Duane  Geruschat will act as a consultant in the design and evaluation of these assess.ements.  Human subjects testing will be carried out at the Johns Hopkins Wilmer Eye Institute and the Chicago Lighthouse,  which not only counts a substantial ULV population among its employees and clients, but also a number of BrainPort  users.  Investigators at both sites have extensive research experience with this population.  O&M scenarios under Aim 2  will be realized in virtual reality with the assistance of our partners at Balti Virtual.  The resulting assessments promise to  not only have a major impact on future clinical trials of sight-restoring therapies, but also lay the foundation to  rehabilitation approaches for recipients of such therapies. Narrative  With the advent of new treatments that aim to restore vision to the blind there is an increasing need for reliable  measurement of very low vision levels, so changes in vision related to the treatment can be documented.  We have  previously designed some of these measures and are proposing to demonstrate their reliability in a large population of  individuals with profoundly impaired (“ultra-low”) vision, and to develop a broad range of additional vision measures  that are sensitive to ultra-low vision, for use in future clinical trials of sight-restoring therapies.  Participants in these  studies will be patients with very limited (so-called Ultra-Low) vision and users of the Brainport vision substitution device  and the Argus II retinal implant.",Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision,9742488,R01EY028452,"['Activities of Daily Living', 'Address', 'Age', 'Animal Model', 'Assessment tool', 'Award', 'Baltimore', 'Benefits and Risks', 'Biomedical Research', 'Blindness', 'Chicago', 'Client', 'Clinic', 'Clinical', 'Clinical Trials', 'Consumption', 'Devices', 'Dimensions', 'Disease', 'Dreams', 'Employee', 'Enrollment', 'Equilibrium', 'Equipment and supply inventories', 'Evaluation', 'Eye', 'Foundations', 'Future', 'Health', 'Human', 'Impairment', 'In Vitro', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Judgment', 'Laboratories', 'Life', 'Light', 'Maryland', 'Measurement', 'Measures', 'Medical', 'Modality', 'Natural regeneration', 'Ocular Prosthesis', 'Outcome', 'Participant', 'Patient Self-Report', 'Patients', 'Perception', 'Performance', 'Persons', 'Population', 'Preparation', 'Principal Component Analysis', 'Property', 'Prosthesis', 'Questionnaires', 'Regenerative Medicine', 'Regulation', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Safety', 'Savings', 'Services', 'Shapes', 'Side', 'Site', 'Standardization', 'Stem cells', 'System', 'Testing', 'Therapeutic Intervention', 'Therapy Clinical Trials', 'Time', 'Translating', 'Vision', 'Visual', 'Visual impairment', 'blind', 'design', 'expectation', 'experience', 'eye hand coordination', 'human subject', 'instrumental activity of daily living', 'novel', 'programs', 'recruit', 'regenerative', 'research and development', 'response', 'restoration', 'retina implantation', 'retinal prosthesis', 'statistics', 'therapeutic gene', 'tool', 'virtual', 'virtual reality', 'visual performance']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2019,372074,0.2577791992245512
"Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision Summary  Restoring vision to the blind has been an age‐old dream, but it took an avalanche of biomedical research and  development over the last few decades to begin turning this dream into reality.  In recent years the potential of saving  and restoring sight has been demonstrated in vitro, in animal models, and in some cases even in human patients.  With  the advent of early clinical trials for these therapies, often primarily aimed at safety and enrolling patients with profound  vision loss, there is a growing need for vision assessments that not only can measure rudimentary vision, but reliably  demonstrate small changes.  Ideally these measures should also demonstrate efficacy in real‐world situations, and  include the use of vision for tasks such as eye‐hand coordination, orientation, and mobility.  In our laboratory we have demonstrated that the properties of rudimentary “native” vision can be assessed with a  visual functioning questionnaire specifically designed for ultra‐low vision, the ULV‐VFQ, and with a set of standardized  visual activities of daily living, the ULV‐ADL.  Moreover, we demonstrated that the performance of users of the Argus II  retinal prosthesis system and the BrainPort vision substitution device is very similar to that of individuals with native  ULV.  This application lays out a program to validate the previously completed assessments in a larger ULV population  (Aim 1), to develop a range of additional assessments (Aim 2), to translate a subset of the visual activities used in these  assessments to real‐world situations and minimize redundancies (Aim 3), and to assess the similarity in performance  between individuals with native ULV and recipients of the Argus II, BrainPort, and other sight‐restoring treatments (Aim  4).  The new assessments under Aim 2 will cover instrumental activities of daily living (IADL) and orientation & mobility  (O&M), and all assessments will cover both static and dynamic scenarios.  Our long‐term collaborator Dr. Duane  Geruschat will act as a consultant in the design and evaluation of these assess.ements.  Human subjects testing will be carried out at the Johns Hopkins Wilmer Eye Institute and the Chicago Lighthouse,  which not only counts a substantial ULV population among its employees and clients, but also a number of BrainPort  users.  Investigators at both sites have extensive research experience with this population.  O&M scenarios under Aim 2  will be realized in virtual reality with the assistance of our partners at Balti Virtual.  The resulting assessments promise to  not only have a major impact on future clinical trials of sight‐restoring therapies, but also lay the foundation to  rehabilitation approaches for recipients of such therapies.       Narrative  With the advent of new treatments that aim to restore vision to the blind there is an increasing need for reliable  measurement of very low vision levels, so changes in vision related to the treatment can be documented.  We have  previously designed some of these measures and are proposing to demonstrate their reliability in a large population of  individuals with profoundly impaired (“ultra‐low”) vision, and to develop a broad range of additional vision measures  that are sensitive to ultra‐low vision, for use in future clinical trials of sight‐restoring therapies.  Participants in these  studies will be patients with very limited (so‐called Ultra‐Low) vision and users of the Brainport vision substitution device  and the Argus II retinal implant.      ",Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision,9559710,R01EY028452,"['Activities of Daily Living', 'Address', 'Age', 'Animal Model', 'Assessment tool', 'Award', 'Baltimore', 'Benefits and Risks', 'Biomedical Research', 'Blindness', 'Chicago', 'Client', 'Clinic', 'Clinical', 'Clinical Trials', 'Devices', 'Dimensions', 'Disease', 'Dreams', 'Employee', 'Enrollment', 'Equilibrium', 'Equipment and supply inventories', 'Evaluation', 'Eye', 'Foundations', 'Future', 'Health', 'Human', 'Impairment', 'In Vitro', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Judgment', 'Laboratories', 'Life', 'Light', 'Maryland', 'Measurement', 'Measures', 'Medical', 'Modality', 'Natural regeneration', 'Outcome', 'Participant', 'Patient Self-Report', 'Patients', 'Perception', 'Performance', 'Persons', 'Population', 'Preparation', 'Principal Component Analysis', 'Property', 'Prosthesis', 'Questionnaires', 'Regenerative Medicine', 'Regulation', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Safety', 'Savings', 'Services', 'Shapes', 'Side', 'Site', 'Standardization', 'Stem cells', 'System', 'Testing', 'Therapeutic Intervention', 'Therapy Clinical Trials', 'Time', 'Translating', 'Vision', 'Visual', 'Visual impairment', 'blind', 'design', 'expectation', 'experience', 'eye hand coordination', 'human subject', 'instrumental activity of daily living', 'novel', 'programs', 'recruit', 'regenerative', 'research and development', 'response', 'restoration', 'retina implantation', 'retinal prosthesis', 'statistics', 'therapeutic gene', 'tool', 'virtual', 'virtual reality', 'visual performance']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2018,372712,0.2577791992245512
"Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision Summary  Restoring vision to the blind has been an age‐old dream, but it took an avalanche of biomedical research and  development over the last few decades to begin turning this dream into reality.  In recent years the potential of saving  and restoring sight has been demonstrated in vitro, in animal models, and in some cases even in human patients.  With  the advent of early clinical trials for these therapies, often primarily aimed at safety and enrolling patients with profound  vision loss, there is a growing need for vision assessments that not only can measure rudimentary vision, but reliably  demonstrate small changes.  Ideally these measures should also demonstrate efficacy in real‐world situations, and  include the use of vision for tasks such as eye‐hand coordination, orientation, and mobility.  In our laboratory we have demonstrated that the properties of rudimentary “native” vision can be assessed with a  visual functioning questionnaire specifically designed for ultra‐low vision, the ULV‐VFQ, and with a set of standardized  visual activities of daily living, the ULV‐ADL.  Moreover, we demonstrated that the performance of users of the Argus II  retinal prosthesis system and the BrainPort vision substitution device is very similar to that of individuals with native  ULV.  This application lays out a program to validate the previously completed assessments in a larger ULV population  (Aim 1), to develop a range of additional assessments (Aim 2), to translate a subset of the visual activities used in these  assessments to real‐world situations and minimize redundancies (Aim 3), and to assess the similarity in performance  between individuals with native ULV and recipients of the Argus II, BrainPort, and other sight‐restoring treatments (Aim  4).  The new assessments under Aim 2 will cover instrumental activities of daily living (IADL) and orientation & mobility  (O&M), and all assessments will cover both static and dynamic scenarios.  Our long‐term collaborator Dr. Duane  Geruschat will act as a consultant in the design and evaluation of these assess.ements.  Human subjects testing will be carried out at the Johns Hopkins Wilmer Eye Institute and the Chicago Lighthouse,  which not only counts a substantial ULV population among its employees and clients, but also a number of BrainPort  users.  Investigators at both sites have extensive research experience with this population.  O&M scenarios under Aim 2  will be realized in virtual reality with the assistance of our partners at Balti Virtual.  The resulting assessments promise to  not only have a major impact on future clinical trials of sight‐restoring therapies, but also lay the foundation to  rehabilitation approaches for recipients of such therapies.       Narrative  With the advent of new treatments that aim to restore vision to the blind there is an increasing need for reliable  measurement of very low vision levels, so changes in vision related to the treatment can be documented.  We have  previously designed some of these measures and are proposing to demonstrate their reliability in a large population of  individuals with profoundly impaired (“ultra‐low”) vision, and to develop a broad range of additional vision measures  that are sensitive to ultra‐low vision, for use in future clinical trials of sight‐restoring therapies.  Participants in these  studies will be patients with very limited (so‐called Ultra‐Low) vision and users of the Brainport vision substitution device  and the Argus II retinal implant.      ",Benefit Assessment Tools for Substitute Prosthetic Regenerative and Ultra-Low Vision,9403478,R01EY028452,"['Activities of Daily Living', 'Address', 'Age', 'Animals', 'Assessment tool', 'Award', 'Baltimore', 'Benefits and Risks', 'Biomedical Research', 'Blindness', 'Chicago', 'Client', 'Clinic', 'Clinical', 'Clinical Trials', 'Devices', 'Dimensions', 'Disease', 'Dreams', 'Employee', 'Enrollment', 'Equilibrium', 'Equipment and supply inventories', 'Evaluation', 'Eye', 'Foundations', 'Future', 'Health', 'Human', 'Impairment', 'In Vitro', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Judgment', 'Laboratories', 'Life', 'Light', 'Maryland', 'Measurement', 'Measures', 'Medical', 'Modality', 'Modeling', 'Natural regeneration', 'Outcome', 'Participant', 'Patient Self-Report', 'Patients', 'Perception', 'Performance', 'Persons', 'Population', 'Preparation', 'Principal Component Analysis', 'Property', 'Prosthesis', 'Questionnaires', 'Recruitment Activity', 'Regenerative Medicine', 'Regulation', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Residual state', 'Safety', 'Savings', 'Services', 'Shapes', 'Side', 'Site', 'Standardization', 'Stem cells', 'System', 'Testing', 'Therapeutic Intervention', 'Therapy Clinical Trials', 'Time', 'Translating', 'Vision', 'Visual', 'Visual impairment', 'blind', 'design', 'expectation', 'experience', 'eye hand coordination', 'human subject', 'instrumental activity of daily living', 'novel', 'programs', 'regenerative', 'research and development', 'response', 'restoration', 'retina implantation', 'retinal prosthesis', 'statistics', 'therapeutic gene', 'tool', 'virtual', 'virtual reality']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2017,388911,0.2577791992245512
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,9857605,K99EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'archetypal analysis', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'machine learning method', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,K99,2020,145891,0.04457486452594077
"Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure Project Summary Glaucoma is the second leading cause of blindness globally, and is characterized by optic nerve damage that leads to the death of retinal ganglion cells with accompanying visual field (VF) loss. The optic nerve head (ONH) is the site of injury to the optic nerve fibers and plays a central role in glaucoma pathogenesis and diagnosis. Traditionally, glaucoma is diagnosed based on fundus inspection of the ONH, which provides information about the surface contour of the ONH. However, the optic nerve damage occurs in the deeper layers. With the development of optical coherence tomography (OCT) techniques for three-dimensional (3D) retinal imaging, parameters derived from the 3D ONH related structure (e.g., Bruch's membrane opening minimum rim width, peripapillary retinal nerve fiber layer thickness, disc tilt etc.) have been studied to better understand glaucoma pathogenesis, and are used to supplement clinical diagnosis. In addition, studies of the ONH biomechanics have also shown that the strain level at the ONH at any given intraocular pressure level depends on the 3D geometry of the ONH related structure. A high strain level is hypothesized to contribute to retinal ganglion cell injury. Previous research has suggested that the 3D ONH related structure is correlated to glaucoma pathogenesis and critically important to glaucoma diagnosis. However, to date, a systematic study using clinical data to determine the impact of the 3D ONH related structure on glaucoma has not been conducted.  We propose to study the relationship between the 3D ONH related structure and glaucoma with a diverse set of combined techniques including image processing, computational mechanics and machine learning. The specific aims of this project are to: (1) Derive features from the 3D ONH related structure and study their implications on VF loss patterns (K99 Phase). (2) Investigate the impact of the strain field patterns at the ONH on glaucoma (K99 Phase). (3) Study the effect of the 3D ONH related features on OCT diagnostic parameters (R00 Phase). (4) Model central vision loss from the 3D ONH related structural features (R00 Phase). Collectively, these studies will provide new insights and perspectives into the structure-function relationships in glaucoma and establish ocular anatomy specific norms of retinal nerve fiber layer profiles, which will advance our current understanding of glaucoma pathogenesis and improve glaucoma diagnosis. Our research is of high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.  Through the proposed research and training plans, the applicant will build a solid knowledge base in ophthalmology and further improve his expertise in mathematical modeling and data science. This project will provide critical training opportunities to further enhance the applicant's capabilities to become an independent computational vision scientist in ophthalmology. Project Narrative The proposed research will study the relationship between the three-dimensional (3D) optic nerve head (ONH) related structure and glaucoma. Our study will advance the current understanding of glaucoma pathogenesis and improve glaucoma diagnosis by gaining new insights into the structure-function relationships in glaucoma and establishing ocular anatomy specific norms of retinal nerve fiber layer profiles. Our research has high clinical relevance and can be potentially translated into clinical practice for better glaucoma diagnosis, monitoring and treatment.",Relationship between Glaucoma and the Three-Dimensional Optic Nerve Head Related Structure,9666293,K99EY028631,"['3-Dimensional', 'Age', 'Anatomy', 'Biomechanics', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Cessation of life', 'Clinical', 'Clinical Data', 'Computer Simulation', 'Cross-Sectional Studies', 'Data', 'Data Science', 'Development', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Ear', 'Elements', 'Eye', 'Fundus', 'Gaussian model', 'Geometry', 'Glaucoma', 'Hour', 'Image', 'Individual', 'Injury', 'Lead', 'Linear Models', 'Linear Regressions', 'Location', 'Machine Learning', 'Measurement', 'Mechanics', 'Medical Records', 'Methods', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Multivariate Analysis', 'Nerve Fibers', 'Observational Study', 'Ophthalmology', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Pathogenesis', 'Patients', 'Pattern', 'Phase', 'Physiologic Intraocular Pressure', 'Play', 'Population Study', 'Process', 'Quality of life', 'Research', 'Research Training', 'Resolution', 'Retinal Ganglion Cells', 'Role', 'Scanning', 'Scheme', 'Scientist', 'Severities', 'Site', 'Solid', 'Source', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Testing', 'Thick', 'Translating', 'Variant', 'Vision', 'Visual Fields', 'Width', 'base', 'cell injury', 'clinical Diagnosis', 'clinical practice', 'clinically relevant', 'deep neural network', 'demographics', 'fundus imaging', 'image processing', 'improved', 'independent component analysis', 'insight', 'knowledge base', 'learning strategy', 'mathematical model', 'nonlinear regression', 'optic cup', 'retina blood vessel structure', 'retinal imaging', 'retinal nerve fiber layer', 'study population', 'training opportunity', 'unsupervised learning']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,K99,2019,146837,0.04457486452594077
"Gesture Wand for Mobile Devices    DESCRIPTION (provided by applicant): The primary goal of this project is to develop a gesture wand that will be especially useful to older individuals to overcome problems associated with the decreasing size of the user interface in mobile devices. This will be targeted exclusively to individuals who may have their vision or manual dexterity compromised. Due to advances in technology, mobile devices will become increasingly smaller. As the size of these devices decreases, their user interfaces will also shrink in size. This presents a special problem for older adults, who experience age and disease related decrements in vision and manual dexterity. These losses can cause significant problems when attempting to interface with small mobile devices. Given the aging demographic of the population and the increasing availability of compact technologies, the number of older adults using small mobile devices will continue to increase. Our solution to the interface problem is an interface using movement of a wand in free space that has audio confirmation and feedback. A gesture wand prototype will be quickly developed using 3-D accelerometer MEMS chip and a single chip wireless connection (i.e. Bluetooth) with microcontroller. The gesture wand quick prototype will be used to determine the best gestures for use in a mobile device virtual interface for older age individuals. The specific gestures will be numbers and control commands. The gestures will be recognized using a Hidden Markov Model  to break the gestures down into sequential symbols. The microcontroller on the wand will be programmed for preprocessing and feature extraction. The mobile device will compare the incoming data using the Hidden Markov Model of possible gestures. Using the gesture wand hardware and software developed, we will test the proof of concept with at a least 36 individuals age 60 and older who have their vision or manual dexterity skills compromised or both. After a short training session, they will be asked to use the gesture wand to enter numbers and specific control commands. Success of this aim will be if 90 % of the people can reliably operate the prototype gesture wand 90 % of the time in spite of vision or manipulative skill problems. The primary goal of this project is to develop a gesture wand that will be especially useful to older individuals to overcome problems associated with the decreasing size of the user interface in mobile devices. This will be targeted exclusively to individuals who may have their vision or manual dexterity compromised.           n/a",Gesture Wand for Mobile Devices,7404765,R43AG029037,"['3-Dimensional', 'Age', 'Communities', 'Computer software', 'Data', 'Demographic Aging', 'Development', 'Devices', 'Disease', 'Elderly', 'Electronic Mail', 'Feedback', 'Gestures', 'Goals', 'Impairment', 'Individual', 'Internet', 'Learning', 'Manuals', 'Measures', 'Movement', 'Numbers', 'Operative Surgical Procedures', 'Participant', 'Performance', 'Personal Computers', 'Population', 'Relative (related person)', 'Semiconductors', 'Series', 'Solutions', 'Standards of Weights and Measures', 'Technology', 'Telephone', 'Testing', 'Time', 'Training', 'Vision', 'Visual', 'Visual impairment', 'Voice', 'Wireless Technology', 'concept', 'experience', 'markov model', 'programs', 'prototype', 'size', 'skills', 'software development', 'success', 'time use', 'touchscreen', 'usability', 'virtual']",NIA,CYTHOR,R43,2008,100000,-0.018907981555577404
"Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye Age-related macular degeneration (AMD) is the leading cause of blindness in the elderly in the developed world; no cure exists and prevalence is rising rapidly. Because only primates have a macula and since no model of AMD exists in non-human primates, the disease course can only be elucidated through in-depth study of humans. Blindness in AMD is caused by progressive and irreversible death of rod and cone photoreceptors secondary to degeneration of the retinal pigment epithelium (RPE) that is essential for their health and function. Clinical imaging and histology have informed us greatly about the later stages of disease but fundamental knowledge to understand how AMD diverges from normal aging at onset is lacking. With advanced adaptive optics ophthalmoscopy (AOO) imaging methods, combined with clinical imaging and visual function testing, we will characterize healthy human retinal aging in cross-sectional study, by defining the in vivo RPE-photoreceptor cellular organization and microscopic autofluorescence variation with age and wavelength. This will produce the largest quantitative in vivo normative dataset of AOO cell-based metrics to date and we will use this data to generate new quantitative analysis tools needed to evaluate emerging therapies designed to prevent or slow vision loss in AMD (Aim 1). In a case-control study, we will then compare normal photoreceptor topography and RPE cell morphometry to clinically defined early AMD to quantitatively define the earliest cellular changes in AMD that can be detected in vivo. This work will identify the cellular alterations and phenotypes that differentiate normal aging from early AMD to facilitate early onset detection. These results will be contextualized by comparison to tissue-level alterations seen with aging and early AMD in clinical imaging, specifically choriocapillaris decline and drusen (Aim 2). The results of this study will result in a paradigm shift from the use of clinical diagnosis and classification systems for AMD that rely solely on tissue- level biomarkers or traditional funduscopic clinical signs to those that rely on rigorous quantitative in vivo cell- based metrics. Together, this knowledge and these tools will lay the foundation needed to develop and evaluate new preventative therapies that are needed to limit or prevent vision loss in AMD. Project Narrative Age-related macular degeneration is the leading cause of blindness in the elderly in the US and is a significant public health issue that is projected to worsen due to the rapidly aging population. Here we aim to understand how retinal cells change in normal aging and how these normal age-related changes differ from the changes that lead to age-related macular degeneration. This project will allow us to detect age-related macular degeneration earlier and will produce new tools to monitor retinal cells that will facilitate the development and testing of preventative therapies to slow or prevent vision loss in age-related macular degeneration.",Distinguishing normal aging from age-related macular degeneration at the level of single cells int eh living human eye,9973645,R01EY030517,"['Age', 'Age related macular degeneration', 'Aging', 'Area', 'Atrophic', 'Biological Markers', 'Blindness', 'Bruch&apos', 's basal membrane structure', 'Case-Control Studies', 'Cells', 'Cessation of life', 'Choroid', 'Classification', 'Clinical', 'Clinical Research', 'Complex', 'Conflict (Psychology)', 'Cross-Sectional Studies', 'Cytoplasmic Granules', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic Procedure', 'Disease', 'Drusen', 'Elderly', 'Evaluation', 'Eye', 'Foundations', 'Genetic', 'Goals', 'Health', 'Histology', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Lead', 'Lipofuscin', 'Machine Learning', 'Maps', 'Melanins', 'Methods', 'Microscopic', 'Modeling', 'Monitor', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Optics', 'Perfusion', 'Phenotype', 'Photoreceptors', 'Prevalence', 'Preventive therapy', 'Preventive treatment', 'Primate Diseases', 'Primates', 'Public Health', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Photoreceptors', 'Risk', 'Secondary to', 'Spatial Distribution', 'Structure', 'Structure of retinal pigment epithelium', 'System', 'Techniques', 'Technology', 'Testing', 'Therapy Evaluation', 'Time', 'Tissues', 'Variant', 'Vertebrate Photoreceptors', 'Vision', 'Work', 'adaptive optics', 'age related', 'aging population', 'base', 'clinical Diagnosis', 'clinical decision-making', 'clinical imaging', 'cohort', 'early onset', 'fluorophore', 'healthy aging', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'macula', 'morphometry', 'multimodality', 'neurovascular unit', 'nonhuman primate', 'normal aging', 'prevent', 'restorative treatment', 'retinal imaging', 'retinal rods', 'therapy design', 'tool']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,527040,0.05843966356478487
"Personalizing Glaucoma Diagnosis by Disease Specific Patterns and Individual Eye Anatomy Project Summary/Abstract Glaucoma is a disease of the optic nerve which is accompanied by visual ﬁeld (VF) loss. While accurate VF loss diagnosis and the detection of its progression over time is of high relevance to clinical practitioners as it indicates the initiation of or change in ocular therapy, there is no consensus on objective measures for this purpose, and VF measurements are known to be often unreliable. The main objective of this project is to develop clinically applicable measures to improve the diagnosis of glaucomatous VF loss and of its progression by two approaches: First, the identiﬁcation of representative loss patterns and their progression, achieved by large-scale, customized bioinformatical procedures applied to data from glaucoma patients from nine clinical centers and second, the inclusion of eye and patient speciﬁc personalized parameters. In total, 480,486 VFs, are available for this project. One major aim is to develop novel diagnostic indices based on computationally identiﬁed evolution patterns of VF loss, particularly (1) an index that denotes the probability of glaucomatous vision loss and (2) an index that assigns probabilities to a VF that follow-up measurements will be in a certain defect class. The indices will be statistically evaluated on separate VF samples and compared to existing approaches. Routinely available patient speciﬁc parameters which are candidates to impact glaucomatous vision loss are patient ethnicity, type of glaucoma, spherical equivalent (SE) of refractive error and the location of the blind spot relative to ﬁxation. The effect of these parameters on the vision loss patterns will be systematically studied. The impact of their inclusion in the novel diagnostic indices and their potential improvement on glaucoma diagnosis will be quantiﬁed on a separate data set. A further aim is the calculation of a spatial map speciﬁc to a measured VF that represents the preferred VF locations of future defects as well as their reliability as an aid to event-based progression diagnosis. A second major objective is the investigation of the relationship of VF loss and individual parameters related to retinal structure, based on retinal nerve ﬁber layer thickness (RNFLT) measurements around the optic disc. The inter-relationship of representative patterns of RNFLT and its decrease over time with trajectories of major retinal arteries, SE, and blind spot location is systematically studied, and the impact on patterns of VF loss is quantitatively analyzed with the goal to improve the interpretation of existing VF loss and to predict future glaucomatous vision loss. Main contributions of the project with relevance to clinical practice are publicly available open-source software implementations of new diagnostic indices and maps, enhanced by individual functional and structural parameters, and a detailed and personalized model for the relationship between retinal structure and glaucomatous vision loss. Project Narrative Glaucoma is an ocular disease accompanied by vision loss which may progress over time up to total blindness, but the assessment of glaucomatous vision loss is noisy, and it is often hard for clinical practitioners to decide whether changes over time reﬂect true changes of functional vision or are the result of normal measurement variations or artifacts. This project contributes directly and immediately to public health by exploring the impact of individual anatomical parameters on the spatial patterns of glaucomatous vision loss in order to improve the diagnosis of vision loss and of its progression. Main objective of the project is the development of new quantitative diagnostic indices, implemented as publicly available software.",Personalizing Glaucoma Diagnosis by Disease Specific Patterns and Individual Eye Anatomy,9802123,R01EY030575,"['Anatomy', 'Atrophic', 'Axon', 'Bioinformatics', 'Blindness', 'Clinical', 'Cluster Analysis', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Ethnic Origin', 'Event', 'Evolution', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Hemorrhage', 'Impairment', 'Individual', 'Investigation', 'Length', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Modeling', 'Morphologic artifacts', 'Nerve Fibers', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Probability', 'Procedures', 'Public Health', 'Refractive Errors', 'Retinal', 'Retinal Defect', 'Retinal Ganglion Cells', 'Retinal blind spot', 'Sampling', 'Structure', 'Structure-Activity Relationship', 'System', 'Thick', 'Time', 'Variant', 'Vision', 'Visual Fields', 'Work', 'base', 'central retinal artery', 'clinical application', 'clinical practice', 'disease diagnosis', 'follow-up', 'fovea centralis', 'improved', 'indexing', 'multidisciplinary', 'neglect', 'novel diagnostics', 'open source', 'optic nerve disorder', 'outcome forecast', 'retinal nerve fiber layer', 'sample fixation', 'sex']",NEI,SCHEPENS EYE RESEARCH INSTITUTE,R01,2019,534037,0.1421927634935512
"Diabetic Retinopathy: genetics and neurodegeneration PROJECT SUMMARY/ABSTRACT Diabetes mellitus (DM) is the leading cause of vision loss among working aged adults. Its prevalence is increasing and despite the strides in knowledge and treatments, our understanding of the pathways leading to vision loss in DM remains limited. Hyperglycemia and duration of DM contribute to but do not fully explain the predisposition to develop diabetic retinal diseases. Given the predisposition for diabetic retinal diseases to cluster in families, genetic risk factors are thought to be important but none has so far been definitively implicated. Furthermore, data from small studies suggest that there are more phenotypes of diabetic retinal disease than are currently recognized in clinical practice. Diabetic retinal disease has traditionally been considered primarily a vascular process: diabetic retinopathy (DR) and diabetic macular edema (DME) are the main clinical manifestations. With improved imaging modalities and image analysis algorithms, there has been increasing recognition of a new clinical manifestation of diabetic retinal disease, diabetic retinal neurodegeneration (DRN). This is visible as alterations in thickness of retinal nerve fiber (RNFL) and/or ganglion cell layer (GCL) on optical coherence tomography (OCT) images. To date, DRN is poorly understood, and its role in clinical management of patients with DM has not been established. However, if retinal neurodegeneration occurs and is progressive, it can lead to profound visual difficulties for patients with DM. DRN may account for previously unexplained poor visual outcomes among patients with diabetic retinal disease despite standard of care treatment. Dr. Channa is a retina specialist, with prior research experience in retinal imaging and clinical trials of novel treatments for DME. In this K23 career development award she proposes to use a nationally representative dataset, the UK Biobank cohort to: 1) improve our understanding of DRN by determining RNFL and GCL thickness, using OCT imaging, in participants with DM (who have no DR or DME) compared to those who do not have DM 2) determine genetic factors associated with DR, DME and DRN. Dr. Channa proposes a career development plan, which includes mentorship, coursework, publications and clinical time. This will situate her as an independent clinician-scientist with expertise in translational research employing bioinformatics and computational skills in genomics and retinal image analysis to elucidate pathways of vision loss among patients with DM, ultimately leading to development of novel therapies. Her research work and career development will take place in the academic and collaborative environment of the largest medical center in the world, where she has institutional support and mentorship to develop as an independent clinician-scientist. PROJECT NARRATIVE In this career development award we aim to use genetic and retinal imaging data to enhance our understanding of the pathways that can lead to vision loss among people with diabetic retinal diseases. Improved understanding will translate into interventions aimed at preventing blindness from diabetes.",Diabetic Retinopathy: genetics and neurodegeneration,9868630,K23EY030911,"['Address', 'Adult', 'Affect', 'Algorithmic Analysis', 'American', 'Appearance', 'Artificial Intelligence', 'Bioinformatics', 'Blindness', 'Blood Vessels', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational algorithm', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Development Plans', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Disease', 'Disease Pathway', 'Environment', 'Family', 'Fundus', 'Future', 'Ganglion Cell Layer', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genomics', 'Goals', 'Hyperglycemia', 'Image', 'Image Analysis', 'Intervention', 'K-Series Research Career Programs', 'Knowledge', 'Lead', 'Measurement', 'Medical center', 'Mentors', 'Mentorship', 'Methods', 'Molecular', 'Nerve', 'Nerve Degeneration', 'Nerve Fibers', 'Optical Coherence Tomography', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Phenotype', 'Predisposition', 'Prevalence', 'Prevention', 'Process', 'Publications', 'Race', 'Regression Analysis', 'Reporting', 'Research', 'Retina', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Risk Factors', 'Role', 'Sample Size', 'Scanning', 'Scientist', 'Specialist', 'Techniques', 'Testing', 'Thick', 'Time', 'Training', 'Translating', 'Translational Research', 'Vascular Endothelial Growth Factors', 'Vision', 'Visual', 'Work', 'aged', 'base', 'biobank', 'career development', 'clinical practice', 'cohort', 'collaborative environment', 'diabetes management', 'diabetic', 'disability', 'experience', 'family genetics', 'fiber cell', 'genetic risk factor', 'genome wide association study', 'genomic data', 'illness length', 'imaging modality', 'improved', 'large datasets', 'macular edema', 'novel', 'novel therapeutics', 'population based', 'prevent', 'retinal imaging', 'screening', 'skills', 'standard of care']",NEI,BAYLOR COLLEGE OF MEDICINE,K23,2020,290835,0.06589278416264678
"Gaze-contingent computer screen magnification control for people with low vision ! Project Summary This application describes proposed research with the goal of facilitating use of a computer screen magnifier by people with low vision. Screen magnification is a well-established, popular technology for access of onscreen content. Its main shortcoming is that it requires the user to continuously control, with the mouse or trackpad, the location of the focus of magnification, in order to ensure that the magnified content of interest is within the screen viewport. This tedious process may be time-consuming and ineffective. For example, the simple task of reading the news on a web site requires continuous horizontal scrolling, which affects the experience of using this otherwise very beneficial technology, and may discourage its use, especially by those with poor manual coordination.  We propose to develop a software system that enables hands-free control of a screen magnifier. This system will rely on the user’s eye gaze (measured by a regular IR-based tracker, or from analysis of the images in a camera embedded in the screen) to update the location of the focus of magnification as desired. This research is inspired by preliminary work, which showed promising results with two simple gaze-based control algorithms, tested on three individuals with low vision.  This project will be a collaboration between the Department of Computer Science and Engineering at UC Santa Cruz (PI: Manduchi, Co-I: Prado) and the School of Optometry at UC Berkeley (PI: Chung). Dr. Legge from the Department of Psychology at U. Minnesota will participate as a consultant. Two human subjects studies are planned. In Study 1 with 80 low vision subjects from four different categories of visual impairment, we will investigate the failure rate of a commercial gaze tracker (Aim 1), and will record mouse tracks, gaze tracks, and images from the subjects while performing a number of tasks using two modalities of screen magnification (Aim 2). In Study 2, with the same number of subjects, we will repeat the Study 1 experiment, but using a gaze-based controller trained from the data collected in Study 1, and individually tunable for best performance (Aim 3). In addition, we will experiment with an appearance-based gaze tracker that uses images from the screen camera, thereby removing the need for specialized gaze tracking hardware, as well as with a computer tablet form factor (Aim 4). We expect that reading speed and error rate using our gaze-based controller will be no worse than using mouse-based control. If successful, this study will show that the convenience of hands-free control offered by the proposed system comes at no additional cost in terms of individual performance at the considered tasks. ! ! Project Narrative People with low vision often use screen magnification software to read on a computer screen. Since a magnifier expands the screen content beyond the physical size of the screen (the “viewport”), it is necessary to move the content using the mouse so that the portion of interest falls within the viewport. This project will facilitate use of a screen magnifier by means of a new software system that relies on the user’s own gaze to control scrolling when reading with magnification. !",Gaze-contingent computer screen magnification control for people with low vision,10053172,R01EY030952,"['Affect', 'Age', 'Algorithms', 'Appearance', 'Apple', 'Behavior Control', 'Benchmarking', 'Blindness', 'Categories', 'Collaborations', 'Communication', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Correlation Studies', 'Data', 'Data Set', 'Desktop Video', 'Engineering', 'Ensure', 'Eye', 'Face', 'Failure', 'Funding', 'Glass', 'Goals', 'Hand', 'Image', 'Individual', 'Learning', 'Location', 'Magic', 'Manuals', 'Measures', 'Minnesota', 'Modality', 'Mus', 'Operating System', 'Optometry', 'Performance', 'Peripheral', 'Process', 'Psychological reinforcement', 'Psychology', 'Reader', 'Reading', 'Research', 'Resort', 'Role', 'Schools', 'Science', 'Speech', 'Speed', 'Structure', 'Study Subject', 'System', 'Tablet Computer', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Translating', 'Update', 'Vision', 'Visual', 'Visual impairment', 'Work', 'algorithm development', 'algorithm training', 'base', 'computer science', 'control trial', 'cost', 'data acquisition', 'design', 'experience', 'experimental study', 'falls', 'gaze', 'human subject', 'interest', 'motor control', 'news', 'recurrent neural network', 'sample fixation', 'software systems', 'tool', 'web page', 'web site']",NEI,UNIVERSITY OF CALIFORNIA SANTA CRUZ,R01,2020,350753,0.11355413935014581
"Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings Project Summary: Darwin Babino, PhD, a trained pharmacologist/electrophysiologist, has spent the last ten years working on several disciplines in the vision sciences. His proposal entitled “Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings” presents his overarching goal to improve vision restoration approaches by developing methods to test the potential of these techniques thereby accelerating the development of effective interventions. Dr. Babino and his primary mentor, Dr. Russell Van Gelder, have assembled a strong team of co-mentors at the University of Washington SOM and collaborators to guide him through the proposed training and research. His previous training will be supplemented with goals to help his development as an independent investigator: 1) Study design and practical learning in performing panretinal (MEA) biological experiments; 2) Fundamental and advanced techniques of the proposed optogenetic and stem-cell restoration techniques; 3) Application of advanced machine learning techniques; 4) Develop leadership and professional skills to establish an independent group. The ability to assess the function of panretinal circuitry will foster our understanding of the advantages and weaknesses of different restoration techniques (Aim 1). The work proposed here will improve an existing retinal acuity assessment tool which combines machine learning techniques on novel, high-density multielectrode array recordings of ganglion cell responses in several mouse models. The utility of this system will be demonstrated in assessing visual potential of the mouse retina in three different approaches to vision restoration that are challenging for in vivo assessment (Aim 2). In collaboration with Dr. Deepak A. Lamba at UCSF, we will apply our system to animals which have undergone stem-cell replacement of retinal cells including photoreceptor cells. An optogenetics approach will also be evaluated in collaboration with Dr. John Flannery at UC Berkeley whose group has developed vectors for expressing rhodopsin and cone opsins in ganglion and bipolar cells. Finally, differences between native and restored vison with small molecule photoswitches, light-activated inhibitors of voltage-gated potassium channels, which confer light-dependent firing on treated cells, will be assessed. The resulting advanced electrophysiology application will help elucidate fundamental questions about the functional retina, mechanisms that lead to retinal degeneration and the potential of several therapeutics for the treatment of retinal diseases. Furthermore, this career development award will facilitate Dr. Babino’s development into an independent investigator by priming an R01 grant application. Project Narrative: Project Narrative: The prevalence of vision loss from retinal degeneration numbers in the millions world-wide and is expected to double by the year 2050, and despite the development of several promising approaches to restore vision in the blind, progress in developing these therapies has been hampered by challenges in analysis of these methods in animal models. We describe a novel system that analyzes, by machine learning, retinal ganglion cell output in native, degenerated and therapeutically treated blind retinas which can characterize the visual information content of the ‘reanimated’ blind retina and thereby facilitate the development of these technologies. The system developed through this grant, as well as the career development pursued by the investigator, will be readily applicable to the assessment of potential retinal acuity restoration by current and novel therapeutic approaches.",Assessment of murine retinal acuity ex vivo by machine learning of multielectrode array recordings,9943144,K99EY031333,"['Aftercare', 'Amacrine Cells', 'Animal Model', 'Animals', 'Applications Grants', 'Assessment tool', 'Behavioral Assay', 'Biological', 'Blindness', 'Cells', 'Collaborations', 'Cone', 'Contrast Sensitivity', 'Data', 'Development', 'Discipline', 'Dissection', 'Doctor of Philosophy', 'Ectopic Expression', 'Electrophysiology (science)', 'Electroretinography', 'Evolution', 'Feedback', 'Fostering', 'Ganglia', 'Genetic', 'Goals', 'Grant', 'Human', 'Image', 'In Vitro', 'Individual', 'Intervention', 'K-Series Research Career Programs', 'Knockout Mice', 'Knowledge', 'Lead', 'Leadership', 'Learning', 'Light', 'MW opsin', 'Machine Learning', 'Measurable', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Methods', 'Movement', 'Mus', 'Opsin', 'Output', 'Photoreceptors', 'Prevalence', 'Protocols documentation', 'Psychophysics', 'Research', 'Research Design', 'Research Personnel', 'Resolution', 'Retina', 'Retinal Cone', 'Retinal Degeneration', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Retinal gene therapy', 'Rhodopsin', 'Rod', 'Rodent', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Specificity', 'Stimulus', 'Synapsins', 'System', 'Systems Analysis', 'Systems Development', 'Techniques', 'Testing', 'Therapeutic', 'Training', 'Transgenic Organisms', 'Universities', 'Vertebrate Photoreceptors', 'Viral', 'Vision', 'Visual', 'Visual Acuity', 'Visual system structure', 'Voltage-Gated Potassium Channel', 'Washington', 'Wild Type Mouse', 'Work', 'base', 'behavior test', 'blind', 'career development', 'cell type', 'cost effective', 'density', 'effective intervention', 'experimental study', 'ganglion cell', 'improved', 'in vivo', 'induced pluripotent stem cell', 'inhibitor/antagonist', 'interest', 'light intensity', 'mimicry', 'mouse model', 'multi-electrode arrays', 'mutant', 'nonhuman primate', 'novel', 'novel therapeutic intervention', 'optogenetics', 'promoter', 'rapid eye movement', 'response', 'restoration', 'scale up', 'skills', 'small molecule', 'stem cells', 'technology development', 'therapy development', 'tool', 'vector', 'vision science', 'visual information']",NEI,UNIVERSITY OF WASHINGTON,K99,2020,113080,0.09650405989885173
"Disposable, medication-integrated tactile and motion sensor for glaucoma therapy compliance improvement ABSTRACT Glaucoma is the leading cause of irreversible blindness in the world. The number of people with primary open angle glaucoma is expected to exceed 100 million by 2040. The first-line therapy for glaucoma treatment is patient-administered hypotensive medication delivered topically via an eye drop. However, studies have consistently shown that patients rarely adhere to dosing recommendations. According to the Wilmer Glaucoma Center of Excellence, nearly 50% of individuals discontinue eye drops within six months of their first prescription. Of those that persist beyond six months, only 37% continue the therapy after three years, and only 10% of those prescribed glaucoma drops are persistent (without gaps) over the first year. Failure to adhere to dosing recommendations dramatically limits the effectiveness of eye drops in lowering intraocular pressure and delaying or preventing the progression of glaucoma. This well-known problem has prompted the development of several technological solutions for tracking adherence. Retinal Care's proposed solution is fundamentally different. The proposed device is a simple and inexpensive combination of sensors designed to provide feedback to patients, providers, payers, and care coordinators regarding the way a patient interacts with their medication. Tactile and motion data is acquired through a custom force-sensitive resistor (FSR) and a standard three-axis accelerometer. Combined, these two data sources provide significant insight into drop adherence, application mechanics, and patient behavior. More importantly, this data can inform decisions on how and when to intervene with a patient to maximize the likelihood of continued long-term drop adherence and vision preservation. The primary innovations are in the single-use design (enabled by low-cost custom FSR fabrication and the unique combination of low-cost electrical components), the novel mining of motion and tactile information for patient adherence and behavioral data, and the integration with an existing care coordination framework. Retinal Care approaches health care more holistically than traditional companies; recognizing the behavioral and psychosocial factors that are a root cause of blindness from eye diseases like glaucoma. While Retinal Care employs cutting-edge technology such as deep learning and advanced medical devices, we work actively toward implementing technology in a way that translates directly to improved quality of life for our patients by managing the entire care path. The technology proposed here, while novel in design, is not intended primarily as a tracking tool, though it will accomplish that sub-goal with greater effectiveness and at less cost than any existing product. Instead, it is designed explicitly to reduce blindness by providing the crucial data needed to tailor our interaction and intervention strategies to the individual patient; to maximize patient engagement and adherence to glaucoma care through a combination of education, incentivization, tailored communications, and personal interaction with our trained care coordinators. The goal of this project is to demonstrate feasibility (cost and functionality) of the simple device that will enable Retinal Care to effectively reduce blindness and visual impairment from glaucoma. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness globally and in the US, where it affects more than 3 million Americans and costs the US economy $2.86 billion every year in direct costs and productivity losses. Topical medication administered through eye drops is a common and effective first-line therapy for reducing intraocular pressure and controlling glaucoma, but patient adherence to dosing recommendations is a consistent and pervasive issue that contributes significantly to vision loss. Retinal Care Inc. intends to develop and deploy a suite of simple, disposable, bottle-integrated sensors that will continuously collect real-time adherence and behavioral data to inform the design of patient-specific intervention and incentivization strategies to improve adherence and reduce blindness from glaucoma.","Disposable, medication-integrated tactile and motion sensor for glaucoma therapy compliance improvement",10010396,R41EY031632,"['Accelerometer', 'Adherence', 'Adoption', 'Affect', 'Age related macular degeneration', 'American', 'Antihypertensive Agents', 'Behavior', 'Behavioral', 'Blindness', 'Businesses', 'Caring', 'Cells', 'Cellular Phone', 'Clinical', 'Clinical Trials', 'Coin', 'Communication', 'Consumption', 'Coupled', 'Custom', 'Data', 'Data Sources', 'Development', 'Device or Instrument Development', 'Devices', 'Diabetic Retinopathy', 'Direct Costs', 'Dose', 'Drops', 'Education', 'Educational Intervention', 'Effectiveness', 'Electrical Engineering', 'Electronics', 'Engineering', 'Eye', 'Eye diseases', 'Eyedrops', 'Failure', 'Feedback', 'Film', 'Generations', 'Glaucoma', 'Goals', 'Hand', 'Health', 'Healthcare', 'Human', 'Incentives', 'Individual', 'Intervention', 'Kinetics', 'Label', 'Liquid substance', 'Measurement', 'Mechanics', 'Medical', 'Medical Device', 'Memory', 'Methods', 'Mining', 'Mobile Health Application', 'Modeling', 'Motion', 'Nylons', 'Ophthalmology', 'Patients', 'Performance', 'Peripheral', 'Pharmaceutical Preparations', 'Physiologic Intraocular Pressure', 'Plant Roots', 'Polyurethanes', 'Primary Open Angle Glaucoma', 'Provider', 'Psychosocial Factor', 'Quality of life', 'Radio', 'Recommendation', 'Regimen', 'Resistance', 'Retina', 'Tactile', 'Technology', 'Testing', 'Textiles', 'Thinness', 'Time', 'Topical application', 'Touch sensation', 'Training', 'Translating', 'United States', 'Vision', 'Visual Fields', 'Visual impairment', 'Work', 'advanced analytics', 'analog', 'base', 'care coordination', 'compliance behavior', 'cost', 'data integration', 'deep learning', 'design', 'improved', 'improved outcome', 'incentive strategies', 'individual patient', 'innovation', 'insight', 'interoperability', 'iterative design', 'kinematics', 'motion sensor', 'novel', 'patient engagement', 'performance tests', 'predictive modeling', 'preference', 'preservation', 'prevent', 'productivity loss', 'prototype', 'recruit', 'screening', 'sensor', 'tool', 'treatment adherence', 'usability', 'wearable device']",NEI,"RETINAL CARE, INC.",R41,2020,219896,0.05793301991742316
"Abiotic-Biotic Interfaces for Ophthalmology Symposium ABSTRACT This proposal seeks funding to support a symposium, Abiotic-Biotic Interfaces for Ophthalmology (ABI), which will bring together recognized world experts in clinical, research, vision science, engineering, industrial and pharmaceutical communities as well as junior investigators (i.e., young faculty and those in training) to discuss the current state of ABI, ranging from bioelectronic implantable and wearable devices, to nanoscale scaffolds for stem cell and gene therapies. Given the multidisciplinary nature of this field, it is essential to bring together researchers and clinicians with varying levels of expertise across many domains related to ABI to advance the progress of this novel field, identify challenges of advancement, and develop a strategic action plan to overcome these challenges. The timing to have such a symposium to further the application of implantable and/or wearable bioengineered systems in ophthalmology is now as we focus on precision and personalized medicine and leverage the revolution in deep learning artificial intelligence algorithms. Through symposium talks, sessions, and discussions we will cover the fundamentals and also identify innovative and cutting-edge strategies and methodologies to accelerate the rate of major discoveries and development of novel therapeutics. The specific aims of this symposium are: Specific Aim 1. To bring together both established and junior investigators representing a broad range of disciplines to discuss cutting edge research in this novel field, catalyze the development of cross-disciplinary and translational approaches to advance abiotic-biotic interfaces for ophthalmology, and identify gaps in knowledge and barriers to advancement. We will identify research questions and develop an agenda to guide future research that is consistent with the objectives and interests of NEI. Specific Aim 2. Develop a junior investigator program to motivate a diverse group of students and junior investigators to pursue research careers in vision science and ophthalmologic therapeutic development, who will ultimately submit grant proposals to NEI solicitations and contribute to the scientific literature. Specific Aim 3. Develop a strategic action plan to set priorities for future studies that will encourage inter-agency collaborations (e.g., NEI, NSF, DARPA, etc.). This is critical because often certain engineering tasks are best suited to be supported by NSF or DARPA whereas the biological testing of the engineered systems lends itself to funding from NEI. Hence such inter-agency or cross-agency efforts can help leverage the funding to develop sophisticated abiotic-biotic systems NARRATIVE This meeting is the first on this topic dedicated to the broad use of implantable and/or wearable bioelectronics for ophthalmological applications. It is anticipated that the strategic action plan will significantly impact the field by greatly accelerating the translation of basic science and engineering research findings to stimulate the development of novel treatments and improve clinical practice. Key topics include visual restoration, drug and gene delivery, and sensing intraocular pressure. This meeting will foster training and development of future leaders in this emerging field and promote collaboration and exchange of knowledge and ideas among junior and established investigators.",Abiotic-Biotic Interfaces for Ophthalmology Symposium,10070800,R13EY031988,"['Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biological Testing', 'Biomedical Engineering', 'Cellular Phone', 'Clinical Research', 'Collaborations', 'Communities', 'Computer software', 'Contact Lenses', 'Custom', 'Data', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Drug Delivery Systems', 'Electronics', 'Engineering', 'Eye', 'Faculty', 'Fostering', 'Funding', 'Future', 'Gene Delivery', 'Glass', 'Industrialization', 'Intraocular lens implant device', 'Knowledge', 'Literature', 'Medicine', 'Methodology', 'Nature', 'Neural Retina', 'Ophthalmology', 'Optics', 'Pharmacologic Substance', 'Physiologic Intraocular Pressure', 'Physiological', 'Research', 'Research Personnel', 'Route', 'Scientific Inquiry', 'Scientist', 'Senior Scientist', 'Students', 'System', 'Time', 'Training', 'Translations', 'Virtual and Augmented reality', 'Visual', 'base', 'career', 'clinical practice', 'deep learning', 'gene therapy', 'implantable device', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'meetings', 'multidisciplinary', 'nanoscale', 'neural network', 'novel', 'novel therapeutics', 'personalized medicine', 'portability', 'precision medicine', 'programs', 'restoration', 'scaffold', 'stem cell therapy', 'symposium', 'therapeutic development', 'translational approach', 'vision science', 'wearable device']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R13,2020,42465,0.03536912015571065
"Smartphone phenotype collection for diagnostic screening of mild cognitive impairment Project Summary This project addresses a critical need for early detection of mild cognitive impairment (MCI) and other Alzheimer's-related dementias (ADRD). Advances in smartphone hardware, computer vision, and machine learning have enabled the possibility of producing smartphone-based cognitive testing applications able to collect electronic sensor data and transform it into highly informative phenotypes that can serve as early indicators of future disease progression. In this project, we aim to develop a revolutionary new smartphone- based cognitive testing platform, called CTX, that will enable the rapid development and deployment of smartphone-based tests that can capture raw sensor streams in a synchronized fashion, subsample and compress the combined streams, and transmit them to a cloud server for subsequent analysis and modeling. CTX will provide a high-level application development framework that will significantly reduce the time and technical knowledge required to produce a smartphone-based cognitive testing application by providing an application programming interface (API) that enables developers to simply declare what sensor data should be collected and when. The framework will handle all the details of collecting the sensor data, synchronizing it, and transmitting it to a back-end server. The API will also have a variety of other high-level features to facilitate development of cognitive test apps. To demonstrate the feasibility of our vision for CTX, in Aim 1 of this project we will develop the software framework, back-end server software and a prototype smartphone app to exercise and validate many of the platform's features. For Aim 2, we will develop three different tests for this app to test saccade (eye movement) latency, verbal recall, and wrist mobility, each collecting a different type of sensor data (video, audio, and inertial measurement). These tests were selected because their results have been been shown to be predictive of MCI. We will implement phenotype extraction pipelines that employ advanced signal processing, machine learning, and computer vision algorithms to extract the target phenotypes from the sensor data collected for these tests and demonstrate they operate with sufficient accuracy to replicate published experimental designs. Successful completion of this project will eliminate the need for expensive and cumbersome phenotype collection equipment (e.g., eye tracking stations) and create the possibility of generating data from which MCI onset can be predicted. Data collected in Phase II via these and other such tests will enable us to apply our machine learning expertise to produce models able to predict transition to MCI that are both sensitive and specific, transforming any smartphone into an MCI risk assessment tool available for at-home use by millions of people. Project Narrative This NIH Phase I project will address the critical need for early detection of Alzheimer's Disease (AD) and Alzheimer's-related dementias (ADRD) by developing a revolutionary new smartphone-based cognitive testing platform that will provide individuals with an ongoing status of their cognitive health. Doctors who are given access to the results of these tests will be able to monitor patients more closely and provide more timely diagnoses. By studying test results from many people, researchers may someday be able to identify patterns that can distinguish mild cognitive impairment from normative age-related cognitive decline.",Smartphone phenotype collection for diagnostic screening of mild cognitive impairment,9679400,R43AG062072,"['Achievement', 'Address', 'Adult', 'Age', 'Age-associated memory impairment', 'Algorithms', 'Alzheimer disease detection', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease model', 'Apple', 'Assessment tool', 'Back', 'Big Data', 'Cellular Phone', 'Cognitive', 'Collection', 'Computer Vision Systems', 'Computer software', 'Cyclophosphamide', 'Data', 'Data Set', 'Dementia', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic tests', 'Disease Progression', 'Early Diagnosis', 'Elderly', 'Emotional', 'Equipment', 'Exercise', 'Exhibits', 'Experimental Designs', 'Eye', 'Eye Movements', 'Face', 'Facial Expression', 'Forearm', 'Frequencies', 'Future', 'Genetic Risk', 'Genotype', 'Goals', 'Health', 'Healthcare', 'Home environment', 'Image', 'Individual', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Memory impairment', 'Methods', 'Modeling', 'Monitor', 'Patient Monitoring', 'Patients', 'Pattern', 'Phase', 'Phenotype', 'Publishing', 'Reporting', 'Research Infrastructure', 'Research Personnel', 'Risk Assessment', 'Rotation', 'Saccades', 'Scanning', 'Secure', 'Sensitivity and Specificity', 'Small Business Innovation Research Grant', 'Software Framework', 'Software Tools', 'Stream', 'Tablets', 'Telephone', 'Test Result', 'Testing', 'Time', 'United States National Institutes of Health', 'Vision', 'Visuospatial', 'Work', 'Wrist', 'Yang', 'age related', 'age related cognitive change', 'application programming interface', 'base', 'cloud platform', 'cognitive development', 'cognitive task', 'cognitive testing', 'cohort', 'cost', 'crowdsourcing', 'data modeling', 'diagnostic screening', 'interest', 'markov model', 'mild cognitive impairment', 'predictive modeling', 'prototype', 'response', 'screening', 'sensor', 'signal processing', 'smartphone Application', 'software development', 'success']",NIA,"PARABON NANOLABS, INC.",R43,2018,394297,0.019237151235531116
"CAMERA TO DETECT REGIONS OF INTEREST IN A PAP SMEAR Automated screening of Pap smear slides is challenging due the high              processing and data transfer requirements placed on the processing               engine. These requirements can be significantly reduced by processing            the images at the image plane of the camera, and reading out only the            relevant data, which results in lower cost and higher performance                systems. Image sensors with smarts or computational capability at each           pixel can be advantageously used in the application to build extremely           compact and low-cost automated screening systems. Morphological                  filtering algorithms have been shown to be effective at detecting object         size and shape, which are distinguishing features in diagnostic                  microscopy. The goal of this research is to design, simulate and                 fabricate a CMOS chip with morphological filtering circuits at each              pixel, which will allow detecting suspicious cells in a Pap Smear at             more than 1000 frames/second. In Phase I, Bosonics will (1) determine            the desired imager's technical capabilities for a compact microscope             mountable smart camera (2) design candidate morphological filtering              architectures and circuits; (3) simulate the morphological algorithms            with realistic circuits models; and (4) design and fabricate a 5x5               imager demonstration chip in CMOS.                                                                                                                                PROPOSED COMMERCIAL APPLICATION:                                                 The chips produced under this program will lower the cost of machine             vision systems by providing an integrated detector/processing function           as well as increasing performance by reducing the output bandwidth               requirements. The detector arrays developed under this program will have         wide application in automatic target recognition, machine vision for             automated manufacturing, medical diagnostic imaging, and remote sensing          and surveillance.                                                                 n/a",CAMERA TO DETECT REGIONS OF INTEREST IN A PAP SMEAR,6012563,R43CA079295,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biomedical equipment development', ' cervical /vaginal smear', ' computer simulation', ' computer system design /evaluation', ' cytology', ' image processing', ' morphology', ' photomicrography']",NCI,"BOSONICS, INC.",R43,1999,700,0.0330850807805646
"CAMERA TO DETECT REGIONS OF INTEREST IN A PAP SMEAR Automated screening of Pap smear slides is challenging due the high              processing and data transfer requirements placed on the processing               engine. These requirements can be significantly reduced by processing            the images at the image plane of the camera, and reading out only the            relevant data, which results in lower cost and higher performance                systems. Image sensors with smarts or computational capability at each           pixel can be advantageously used in the application to build extremely           compact and low-cost automated screening systems. Morphological                  filtering algorithms have been shown to be effective at detecting object         size and shape, which are distinguishing features in diagnostic                  microscopy. The goal of this research is to design, simulate and                 fabricate a CMOS chip with morphological filtering circuits at each              pixel, which will allow detecting suspicious cells in a Pap Smear at             more than 1000 frames/second. In Phase I, Bosonics will (1) determine            the desired imager's technical capabilities for a compact microscope             mountable smart camera (2) design candidate morphological filtering              architectures and circuits; (3) simulate the morphological algorithms            with realistic circuits models; and (4) design and fabricate a 5x5               imager demonstration chip in CMOS.                                                                                                                                PROPOSED COMMERCIAL APPLICATION:                                                 The chips produced under this program will lower the cost of machine             vision systems by providing an integrated detector/processing function           as well as increasing performance by reducing the output bandwidth               requirements. The detector arrays developed under this program will have         wide application in automatic target recognition, machine vision for             automated manufacturing, medical diagnostic imaging, and remote sensing          and surveillance.                                                                 n/a",CAMERA TO DETECT REGIONS OF INTEREST IN A PAP SMEAR,2715812,R43CA079295,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' cervical /vaginal smear', ' computer simulation', ' computer system design /evaluation', ' cytology', ' image processing', ' morphology', ' photomicrography']",NCI,"BOSONICS, INC.",R43,1998,100000,0.0330850807805646
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9698505,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,50000,0.24435071242993112
"A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device ABSTRACT This project will create the first objective measurement tool, the VisBox, for the vision subtype of concussion (VSC). This will enable physicians to identify VSC without an eye-care professional, for referral to a vision specialist for personalized vision therapy recommendations. The persistence of concussion symptoms beyond several weeks is often a life-altering situation for affected individuals, and children are particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties. A lack of accessible, objective vision diagnostics are critical barriers to identification of VSC and referral for treatment. The VisBox will be a software product that is used with the OcuTracker, Oculogica’s proprietary eye-tracking hardware platform. The VisBox will input eye movement measurements from the OcuTracker, calculate metrics that correspond to aspects of cranial nerve function affected during a concussion, and use those metrics to calculate a score to predict VSC using an algorithm developed with guided machine learning in the course of this study. The VisBox will be used by non- vision specialists to objectively measure three vision disorders related to concussion: convergence insufficiency (CI), accommodative insufficiency (AI), and saccadic dysfunction (SD) in under 4 minutes, during the clinical visit where the concussion is diagnosed. The long-term goal is to develop an objective assessment of vision characteristics, that will enable physicians that are non-specialists in vision to 1) screen for concussion-related vision disorders; 2) identify VSC; 3) make decisions about the necessity of a referral for a comprehensive vision examination; 4) monitor the effectiveness of vision treatment. Phase I Hypothesis. VisBox can produce an output score that correlates with the presence or absence of TBI- related vision disorder, i.e., VSC, by leveraging the OcuTracker visual stimulus and eye tracking system. Specific Aim I. Generate OcuTracker eye tracking data and the diagnosis of TBI-related vision disorder in 250 pediatric concussion patients. Specific Aim II. Develop and validate VisBox algorithm for assessing CI, AI, and SD using OcuTracker data. Plans for Phase II. The VisBox score will be used to predict responsiveness to vision therapy in a prospective randomized clinical study. Phase II will be a multi-armed study comparing vision therapy with placebo therapy in concussion patients and assessing whether the VisBox software can predict which patients are responsive to vision therapy. Commercial Opportunity. VisBox customers are non-eye care specialists including neurologists, pediatricians, emergency room physicians, sports medicine physicians, and concussion specialists. The total addressable market is $400M, assuming 4M annual scans at $100/scan needed for concussions in the US. PUBLIC HEALTH RELEVANCE STATEMENT At least 4 million concussions occur in the US each year, and up to 30% of these injuries persist beyond 4 weeks in a condition known as persistent post-concussion symptoms, which is often a life-altering situation for affected individuals, with children particularly vulnerable as they are at risk for co-morbidities such as chronic pain, fatigue, depression, anxiety, and learning difficulties – with often serious consequences. The lack of an accessible, objective vision diagnostics presents a critical barrier to identification of the vision disorder concussion sub-type (VSC) and referral for treatment. The proposed technology will be the first objective tool that can be used by non-vision-specialists to identify concussion-related vision symptoms that is accessible to a broad range of facilities and will enable non-specialist physicians the ability to refer patients to concussion specialists to improve outcomes, decrease the time it takes patients to return to work or play, and reduce healthcare costs associated with this debilitating condition.",A software tool for objective identification of concussion-related vision disorders using a novel eye-tracking device,9465330,R41NS103698,"['Address', 'Affect', 'Algorithms', 'Anxiety', 'Area Under Curve', 'Brain Concussion', 'Caring', 'Characteristics', 'Child', 'Childhood', 'Clinical', 'Clinical Research', 'Clinical assessments', 'Comorbidity', 'Computer software', 'Convergence Insufficiency', 'Cranial Nerves', 'Data', 'Data Analyses', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Economics', 'Effectiveness', 'Emergency Department Physician', 'Evaluation', 'Eye', 'Eye Movements', 'Family', 'Fatigue', 'Fees', 'Functional disorder', 'Goals', 'Health Care Costs', 'Individual', 'Injury', 'Intervention', 'Learning', 'Life', 'Machine Learning', 'Measurement', 'Measures', 'Mental Depression', 'Monitor', 'Neurologist', 'Neurosurgeon', 'Optometrist', 'Output', 'Patients', 'Performance', 'Phase', 'Physicians', 'Placebos', 'Play', 'Post-Concussion Syndrome', 'Prevalence', 'Primary Care Physician', 'Randomized', 'Recommendation', 'Research Personnel', 'Resolution', 'Rest', 'Risk', 'Sampling', 'Scanning', 'Small Business Technology Transfer Research', 'Software Tools', 'Specialist', 'Sports Medicine', 'Symptoms', 'System', 'TBI Patients', 'Technology', 'Therapeutic Intervention', 'Time', 'Traumatic Brain Injury recovery', 'Treatment Efficacy', 'Vision', 'Vision Disorders', 'Visit', 'Work', 'associated symptom', 'chronic pain', 'commercial application', 'concussive symptom', 'disabling symptom', 'disorder subtype', 'economic impact', 'handheld equipment', 'improved outcome', 'lens', 'novel', 'patient response', 'pediatrician', 'population based', 'prospective', 'public health relevance', 'recruit', 'skills', 'software development', 'success', 'therapy outcome', 'tool', 'tv watching', 'visual stimulus']",NINDS,"OCULOGICA, INC.",R41,2018,503162,0.24435071242993112
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9507909,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Grain', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'cognitive development', 'computerized', 'cost', 'deep learning', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'sensor technology', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2018,203125,0.024460019362188584
"Naturalistic Data Collection In The SmartPlayroom PROJECT SUMMARY The aims of this proposal are to fully develop and validate the SmartPlayroom as a powerful automated data collection and analysis tool in developmental research. This room looks like any playroom in a home or school but is designed to naturalistically collect data in real time and simultaneously on all aspects of children's behavior. Behaviors include movement kinematics, language, eye movements, and social interaction while a child performs naturalistic tasks, plays and explores without instruction, walks or crawls, and interacts with a caregiver. The space is equipped with mobile eye tracking, wireless physiological heart rate and galvanic skin response sensors, audio and video recording, and depth sensor technologies. Funding is requested to demonstrate the scientific advantage of naturalistic measurement using an example from visual attention research (Aim 1), and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use in 4-9 year-old children (Aim 2). By combining fine-grained sensor data with high-throughput automated computer vision and machine learning tools, we will be able to automate quantitative data collection and analysis in the SmartPlayroom for use in addressing myriad developmental questions. The SmartPlayroom approach overcomes completely the limitations of task-based experimentation in developmental research, offering quantitative precision in the collection of ecologically valid data. It has the power to magnify both construct validity and measurement reliability in developmental research. The investigators are committed to making freely available our data, computer vision algorithms, and discoveries so that we might move the field forward quickly. NARRATIVE We focus this work on developing and validating a novel and innovative data collection space called the SmartPlayroom, designed to pair naturalistic exploration and action with the precision of computerized automated data collection and analysis. This proposal aims to demonstrate the scientific advantage of naturalistic measurement, and in the process, to provide data to further develop flexible computer vision algorithms for automated behavioral analysis for use with 4-9 year-old children in the SmartPlayroom. !",Naturalistic Data Collection In The SmartPlayroom,9373088,R21MH113870,"['9 year old', 'Address', 'Adult', 'Age', 'Algorithms', 'Attention', 'Automated Annotation', 'Behavior', 'Behavior assessment', 'Behavioral', 'Benchmarking', 'Caregivers', 'Cereals', 'Child', 'Child Behavior', 'Child Development', 'Child Rearing', 'Childhood', 'Cognitive', 'Collection', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cues', 'Darkness', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Developmental Process', 'Discipline', 'Education', 'Environment', 'Event', 'Eye', 'Eye Movements', 'Face', 'Funding', 'Galvanic Skin Response', 'Goals', 'Heart Rate', 'Home environment', 'Human', 'Instruction', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Memory', 'Methods', 'Modernization', 'Monitor', 'Movement', 'Neurodevelopmental Disorder', 'Performance', 'Physiological', 'Play', 'Policies', 'Process', 'Research', 'Research Personnel', 'Schools', 'Social Interaction', 'Societies', 'Technology', 'Time', 'Time Study', 'Training', 'Video Recording', 'Vision', 'Visual attention', 'Walking', 'Wireless Technology', 'Work', 'base', 'behavioral study', 'cognitive development', 'computerized', 'cost', 'design', 'eye hand coordination', 'flexibility', 'frontier', 'grasp', 'indexing', 'innovation', 'kinematics', 'novel', 'research and development', 'sample fixation', 'sensor', 'skills', 'tool']",NIMH,BROWN UNIVERSITY,R21,2017,243750,0.024460019362188584
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10022332,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,243885,0.015406065865328474
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,10228145,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'comorbidity', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2020,59206,0.015406065865328474
"SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder  Intellectual Merit: This project will for the first time provide the fundamental tools to integrate unique multimodal data toward screening, diagnosis, and intervention in eating disorders, with an initial focus on children with ARFID and related developmental and health disorders. This work is critical for enriching the understanding of healthy development and for broadening the foundations of behavioral data science. ARFID ·motivates the development of new computer vision and data analysis tools critical for the analysis of multidimensional behavioral data. The main aims are: 1. Develop and user individualized and integrated continuous facial affect coding from videos to discern affective motivations for food avoidance, critical due to the unique sensory aspects of eating disorders, and resulting from active stimulation via friendly and carefully designed images/videos and real food presentation; 2. Use data analysis and machine learning to derive sensory profiles based on patterns of food consumption and preference from existing unique datasets of selective eaters; and 3. Translate the tools developed in Aims 1 and 2 into the clinic and home to assess the capacity of these tools to define a threshold of clinically significant food avoidance, to detect change in acceptability of food with repeated presentations, and to examine and modify the accuracy of our food suggestion algorithms. Broader Impacts: The impact of this application comprises two broad domains. First is the derivation of processes, tools, and strategies to analyze very disparate data across multiple levels of analysis and to codify those strategies to inform similar future work, in particular incorporating automatic behavioral coding. Second is the exploitation of these tools to address questions about the emergence of healthy/unhealthy food selectivity across the lifespan, including recommendation delivery via apps and at-home recordings. The health impact of even partial success in this project is very broad and significant. Undergraduate students will be involved in this project via the 6-weeks summer research program at the Information Initiative at Duke, a center dedicated to the fundamentals of data science and its applications; via the co-Pl's research lab devoted to eating disorders; and via the Pl's project dedicated to training undergraduate students to address eating disorders of their friends via an anonymous app. Outreach and dissemination will follow the broad use of the developed app, both in the clinic and the general population, including the Pl's connections with low-income and under-represented bi-lingual preK. RELEVANCE (See instructions): Eating disorders are potentially life-threatening mental illnesses affecting the general population; -90% of individuals never receive treatment, in part due to lack of awareness and access. Individuals with eating disorders experience a diminished quality of life, high mental and physical illness comorbidities, and an existence marked by profound loneliness and isolation. Combining expertise in eating disorders with computer vision and machine learning, we bring for the first time data science to this health challenge. PROJECT/PERFORMANCE S1TE(S) (If addItIonal space Is needed use Project/Performance Stte Format Page) n/a",SCH: INT: Computational Tools for Avoidaint/Restrictive Food Intake Disorder ,9927093,R01MH122370,"['Address', 'Affect', 'Affective', 'Algorithms', 'Anxiety', 'Assessment tool', 'Attention', 'Awareness', 'Behavior Therapy', 'Behavioral', 'Caregivers', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Code', 'Comorbidity', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Depressed mood', 'Derivation procedure', 'Development', 'Diagnosis', 'Diet', 'Disease', 'Distress', 'Eating', 'Eating Disorders', 'Emotional', 'Emotions', 'Evolution', 'Exposure to', 'Face', 'Family', 'Food', 'Food Patterns', 'Food Preferences', 'Foundations', 'Friends', 'Fright', 'Future', 'General Population', 'Goals', 'Health', 'Health Personnel', 'Home environment', 'Image', 'Impairment', 'Individual', 'Industry', 'Instruction', 'Intervention', 'Life', 'Link', 'Literature', 'Loneliness', 'Longevity', 'Low income', 'Machine Learning', 'Maps', 'Mathematics', 'Measures', 'Mental disorders', 'Monitor', 'Motion', 'Motivation', 'Parents', 'Performance', 'Phenotype', 'Primary Health Care', 'Process', 'Psyche structure', 'Quality of life', 'Reaction', 'Recommendation', 'Research', 'Scientist', 'Sensory', 'Severities', 'Smell Perception', 'Standardization', 'Structure', 'Suggestion', 'System', 'Taste aversion', 'Time', 'Training', 'Translating', 'Uncertainty', 'Work', 'analytical tool', 'base', 'behavior change', 'clinically significant', 'computerized tools', 'design', 'experience', 'food avoidance', 'food consumption', 'gaze', 'improved', 'indexing', 'mathematical algorithm', 'multimodal data', 'novel', 'outreach', 'precision medicine', 'preference', 'programs', 'relating to nervous system', 'response', 'screening', 'success', 'summer research', 'tool', 'undergraduate student', 'wasting', 'willingness']",NIMH,DUKE UNIVERSITY,R01,2019,253545,0.015406065865328474
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9952370,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2020,695400,0.08963452576183961
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9692717,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2019,695400,0.08963452576183961
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9474630,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,695400,0.08963452576183961
"Extracting rich information from biological images Project Summary  Most laboratories studying biological processes and human disease use microscopes to image samples. Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.  The principal investigator envisions bringing transformative image analysis and machine learning algorithms and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in 3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­ scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image analysis into complex workflows with other software for microscope control, cloud computing, and data mining.  The PI will also pioneer novel algorithms and approaches changing the way images are used in biology, including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines. Public Health Relevance/Narrative Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering computational techniques and software that will change the way microscopy images are used in biology. Biologists will use the resulting software to tackle fundamentally new problems using quantitative image analysis, including detecting changes in the appearance of cells that are overlooked by human vision and studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the context of dozens of projects addressing important fundamental biological questions and world health problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source image analysis software, CellProfiler.",Extracting rich information from biological images,9708392,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,128747,0.08963452576183961
"Extracting rich information from biological images Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Extracting rich information from biological images,9276910,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Learning', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2017,513030,0.08963452576183961
"Computer Vision Methods for the Real Time Assessment of Dietary Intake    DESCRIPTION (provided by applicant): Obesity is a leading cause of preventable death and disability in the U.S. Self- monitoring of all foods and beverages consumed is central to weight loss and maintenance efforts; however, this places a heavy burden on the user. These same burdens also impede nutritional research. The proposed research is for the testing of a semi-automated, objective, near real-time computer vision and pattern recognition approach to the measurement of dietary intake. In the proposed product, cell phone pictures of meals and snacks will be analyzed by software in an attempt to automatically recognize as many items as possible. A small number of intelligent yes/no questions will help provide additional information when necessary in order to meet the accuracy demands of the target application. Following identification of the items, the software will estimate the portion sizes of all identified items. The experiments comprising this Phase I SBIR are (a) extract the most informative sets of features using a large number of food and beverage items taken from an existing database of real world meal images, (b) compare the accuracy of candidate pattern recognition approaches to identify items based on the extracted features, (c) identify the most feasible algorithms for estimating portion size, and (d) test usability and user acceptance with a simulated version of the product. Phase II will (a) apply the approach to a greater variety of food and beverage items, (b) improve automated analysis, and (c) compare the approach to existing assessment instruments. This research will extend defense- and security-related technologies to the assessment and treatment of obesity.          n/a",Computer Vision Methods for the Real Time Assessment of Dietary Intake,7405586,R43CA124265,"['Address', 'Adherence', 'Algorithms', 'Area', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Biometry', 'Body Weight decreased', 'Calculi', 'Cellular Phone', 'Cessation of life', 'Class', 'Coin', 'Computer Vision Systems', 'Computer software', 'Data', 'Databases', 'Decision Trees', 'Diabetic Diet', 'Diet Records', 'Dietary intake', 'Disease', 'Eating', 'Eating Behavior', 'Face', 'Feedback', 'Fingerprint', 'Food', 'Food and Beverages', 'Goals', 'Habits', 'Health', 'Image', 'Individual', 'Information Theory', 'Intake', 'Iris', 'Life', 'Life Style', 'Lighting', 'Machine Learning', 'Maintenance', 'Marketing', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Numbers', 'Nutritional', 'Nutritionist', 'Obesity', 'Obesity associated disease', 'Pattern Recognition', 'Phase', 'Placement', 'Principal Investigator', 'Public Health', 'Research', 'Research Personnel', 'Security', 'Shapes', 'Simulate', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Three-Dimensional Image', 'Time', 'Training', 'Treatment Protocols', 'United States', 'Wing', 'base', 'design', 'digital imaging', 'disability', 'improved', 'innovation', 'instrument', 'interest', 'obesity treatment', 'research study', 'size', 'usability']",NCI,"MEDIABALANCE, INC.",R43,2007,191710,0.0775726788025779
"Sensory Cue Integration in Melanoma Screening Imaging biomarkers are features in images that have biological implications. For example, in a picture of a person with red hair, the red hair is a feature and the implication is that there is a mutation in the MC1R gene that provides instructions for making a protein called the melanocortin 1 receptor. This feature, an imaging biomarker, can be used as a medical cue to indicate increased risk for melanoma. When used in this context, this imaging biomarker becomes an imaging biomarker cue (IBC), in the sense that it may cue the medical professional observer to alter treatment accordingly, such as recommending sunscreen use. IBCs do not individually bear the full weight of medical decision-making and instead are integrated. IBC analysis may be a process of sensory cue integration or may be a process of observation and integration by technology such as a digital camera and computer. An advantage of the latter is that computational scalability enables machine vision to compute vast permutations of IBCs that would be overwhelming to a human observer. Thus computers can try many potential diagnostic methods rapidly before picking the best one to teach back to humans. The purpose of this project is to develop a human/machine interface for bi-directional teaching so expert dermatologists can teach computers what IBCs they use to achieve accurate diagnosis and computers can teach dermatologists the best way to use current IBCs and suggest integration of new IBCs that machine learning guides them to. As an outcome, we will measure the diagnostic performance of dermatologists who undergo IBC training in detecting melanoma. It is known that early detection saves lives, but the potential of technology to improve early detection, a great need since 10,000 Americans still die each year from melanoma, is unknown. This project will help answer that unknown and if we are successful in translating IBCs with commuter vision and machine learning, more melanomas will be detected early and lives will be saved. Our long-term goal is to reduce melanoma related deaths and unnecessary biopsies by helping clinicians increase the predictive value of dermoscopy-based melanoma screening. We believe sensitivity and specificity of dermoscopy- based melanoma screening for non-expert screeners can be improved by assistive technology, which is highly desirable given the cost of false positives (patient stress and unnecessary biopsies) and the extremely high cost of false negatives (delayed melanoma treatment). This project creates a technology to help medical personnel see and integrate features of abnormal skin spots that help them determine if the spot they are looking at is a melanoma. Since melanoma is deadly if left untreated, this technology helps them guide biopsy and surgical removal of skin to potentially cut more melanomas out (saving lives) and not cut so many benign lesions out unnecessarily (leaving less scars). Our augmentation of vision and cognition uses machine learning in a way that is visually intuitive so physicians may be able to show their patients the rationale behind the choice to surgically excise abnormal skin spots or not to.",Sensory Cue Integration in Melanoma Screening,10025420,R21CA240254,"['Address', 'Algorithms', 'American', 'Area Under Curve', 'Back', 'Bayesian Modeling', 'Benign', 'Biological', 'Biopsy', 'Cessation of life', 'Cicatrix', 'Classification', 'Clinical', 'Code', 'Cognition', 'Complement Factor D', 'Computers', 'Control Groups', 'Cues', 'Decision Making', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Early Diagnosis', 'Educational process of instructing', 'Effectiveness', 'Excision', 'Exposure to', 'Feedback', 'Genes', 'Goals', 'Hair', 'Health Personnel', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Instruction', 'Intuition', 'Language', 'Left', 'Lesion', 'Logic', 'Machine Learning', 'Malignant - descriptor', 'Maps', 'Measures', 'Medical', 'Melanocortin 1 Receptor', 'Methodology', 'Modeling', 'Mole the mammal', 'Mutation', 'Nevus', 'Operative Surgical Procedures', 'Outcome', 'Patients', 'Performance', 'Persons', 'Physicians', 'Predictive Value', 'Procedures', 'Process', 'Proteins', 'Radiology Specialty', 'Receiver Operating Characteristics', 'Reporting', 'Risk', 'Risk Factors', 'Savings', 'Screening Result', 'Self-Help Devices', 'Sensitivity and Specificity', 'Sensory', 'Sensory Process', 'Skin', 'Skin Abnormalities', 'Specific qualifier value', 'Spottings', 'Statistical Data Interpretation', 'Stress', 'Sunscreening Agents', 'Surface', 'Technology', 'Testing', 'Training', 'Translating', 'Uncertainty', 'Ursidae Family', 'User-Computer Interface', 'Vision', 'Visual', 'Weight', 'accurate diagnosis', 'base', 'clinical diagnostics', 'cost', 'deep learning', 'diagnostic accuracy', 'digital', 'graphical user interface', 'imaging biomarker', 'improved', 'machine learning algorithm', 'machine vision', 'melanoma', 'predictive modeling', 'prevent', 'rapid technique', 'screening', 'success', 'vector']",NCI,ROCKEFELLER UNIVERSITY,R21,2020,412585,0.0048844300877594156
