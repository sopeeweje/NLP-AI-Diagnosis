text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,7286911,R01EY003311,"['artificial intelligence', 'atrial natriuretic peptide', 'biological transport', 'body water dehydration', 'clinical research', 'cornea edema', 'corneal endothelium', 'corneal epithelium', 'corneal stroma', 'electrophysiology', 'human subject', 'intraocular fluid', 'laboratory rabbit', 'mathematical model', 'membrane permeability', 'model design /development', 'morphology', 'nitric oxide', 'refractive keratoplasty', 'thermodynamics', 'vision tests', 'visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2006,76298,0.09705011488320141
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6914441,R01EY003311,"['artificial intelligence', 'atrial natriuretic peptide', 'biological transport', 'body water dehydration', 'clinical research', 'cornea edema', 'corneal endothelium', 'corneal epithelium', 'corneal stroma', 'electrophysiology', 'human subject', 'intraocular fluid', 'laboratory rabbit', 'mathematical model', 'membrane permeability', 'model design /development', 'morphology', 'nitric oxide', 'refractive keratoplasty', 'thermodynamics', 'vision tests', 'visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2005,315720,0.09705011488320141
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6774685,R01EY003311,"['artificial intelligence', 'atrial natriuretic peptide', 'biological transport', 'body water dehydration', 'clinical research', 'cornea edema', 'corneal endothelium', 'corneal epithelium', 'corneal stroma', 'electrophysiology', 'human subject', 'intraocular fluid', 'laboratory rabbit', 'mathematical model', 'membrane permeability', 'model design /development', 'morphology', 'nitric oxide', 'refractive keratoplasty', 'thermodynamics', 'vision tests', 'visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2004,315720,0.09705011488320141
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6608089,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' clinical research', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' vision tests', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2003,315720,0.09705011488320141
"Integrated Assessment of Corneal Form and Function  DESCRIPTION (provided by applicant): The cornea is a principal refractive element in the eye; corneal transparency and corneal shape determine its optical qualities. Corneal epithelial edema, stromal edema and corneal shape anomalies can independently or collectively degrade visual performance in the form of increased internal light scatter and optical aberrations due to irregular astigmatism. The central theme of this research proposal is the refinement and application of a mathematical model that integrates the thermodynamic description of corneal epithelial, stromal and endothelial transport properties into a model of corneal hydration control. This is combined with methods to classify shape anomalies and means to assess the optical quality of the corneal surface through the analysis of corneal topography.   This investigation will involve both an in vitro model and mathematical models, as well as direct applications to human clinical data, in the following specific aims: 1) Use adaptations of the Klyce and Russell model for corneal hydration dynamics to understand the corneal response to epithelial trauma that evokes the early inflammatory response signaled by transient edema. 2) Refine artificial intelligence methods for the classification and interpretation of corneal topography and ocular wavefront data with emphasis on a device-independent approach. 3) Determine and evaluate numerical constructs to evaluate corneal surface optical quality and ocular wavefront data as they relate to visual acuity in patients.   The long-term goal of this project is to integrate corneal metabolic and structural features into a comprehensive model. With this model and the proposed development of new methods for improved and more accurate assessment of the optical performance of the human eye, further progress toward the objective evaluation of the safety and efficacy of current and developing refractive surgical procedures and contact lenses can be obtained.   n/a",Integrated Assessment of Corneal Form and Function,6545242,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' clinical research', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' vision tests', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2002,315720,0.09705011488320141
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,6384434,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2001,259731,0.10738374006388328
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,6178669,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,2000,254318,0.10738374006388328
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,2888106,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,1999,246910,0.10738374006388328
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,2710832,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,1998,239717,0.10738374006388328
"INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION The cornea is a principal refractive element in the eye; corneal                 transparency and corneal shape determine its optical qualities.                  Corneal epithelial edema, stromal edema and corneal shape anomalies              can independently or collectively degrade visual performance inthe               form of increased internal ligh scatter andoptical aberrations due to            irregular astigmatism.  The central theme of this research proposalis            the refinement and application of a mathematical model that                      integrates the thermodynamic description of corneal epithelial, stromal          and endothelial transport properties into a model of corneal hydration           control.  This is combined with methods to classify shape anomalies              and means to assess the optical quality of the corneal surface through           the analysis of corneal topography.                                               n/a",INTEGRATED ASSESSMENT OF CORNEAL FORM AND FUNCTION,2019435,R01EY003311,"['artificial intelligence', ' atrial natriuretic peptide', ' biological transport', ' body water dehydration', ' cornea edema', ' corneal endothelium', ' corneal epithelium', ' corneal stroma', ' electrophysiology', ' human subject', ' intraocular fluid', ' laboratory rabbit', ' mathematical model', ' membrane permeability', ' model design /development', ' morphology', ' nitric oxide', ' refractive keratoplasty', ' thermodynamics', ' visual perception']",NEI,LOUISIANA STATE UNIV HSC NEW ORLEANS,R01,1997,235734,0.10738374006388328
"EIDETIC--A CONSULTANT SYSTEM FOR IMAGE-BASED DIAGNOSIS Within the realm of medical decision making, pathological diagnosis is noteworthy in that practitioners depend to a large extent on visual experience in the interpretation of histologial and cytological preparations.  Since standard computer-based decision systems support only textual interactions, they are inadequate for image-intensive diagnosis. For this reason we are proposing a different sort of consultant system with the ability to manipulate both text and images.  The name of the system is EIDETIC.  Its design is novel in that the textual decision system, akin to a conventional expert system, has the ability to retrieve and display digitized micrographs from a large image data base.  The images called by the program are intended to provide an appropriate, annotated and complete visual experience for the pathologist at the point of decision.  The goal of the project is to develop a device which can measurably improve the quality of diagnosis in the domain of neuropathology.  In addition to compressing visual experience around the point of decision, other new diagnostic techniques will be engendered.  Facilities will be provided which incorporate image processing into the diagnostic routine, and which delineate appropriate use of immuno- and cytochemical stains.  Means are being developed to digitize microscopic images, create overlays, and store images with associated textual descriptors.  The consultant system will define the current diagnostic context and call appropriate images by searching these textual descriptors.  EIDETIC is designed to segregate domain specific from domain independent components.  This has been done to facilitate the extension of these methodologies to other image-intensive disciplines.  These might include areas of radiology, ophthalmology, endoscopy, and dermatology.  The system is intended as a first generation tool to explore the manner in which visual interpretation and diagnosis can be assisted by newly evolved digital technologies.  n/a",EIDETIC--A CONSULTANT SYSTEM FOR IMAGE-BASED DIAGNOSIS,3449509,R23LM004428,"['computer assisted diagnosis', ' computer assisted medical decision making', ' diagnosis quality /standard', ' histochemistry /cytochemistry', ' image processing', ' immunochemistry', ' nervous system disorder diagnosis', ' stainings']",NLM,UNIVERSITY OF PENNSYLVANIA,R23,1985,22929,0.13640625149716423
"Intracellular Analysis of Visual Cortical Function    DESCRIPTION (provided by applicant): The cerebral cortex is thought to be the seat of the complex processes involved in high-level cognition, perception and movement. Of the many cortical areas, the function of the primary visual cortex, or V1, is perhaps the best understood: Many of the transformations that V1 performs on the representation of the retinal image have been described in great detail; the anatomy of the connections within V1 and from its inputs have been well described; synaptic integration in single neurons has been studied with intracellular recording. As a result, it has been possible to construct detailed and realistic models of the function of V1. We have focused in this project on understanding the principles of cortical processing, by trying to provide experimental tests of the different models and by developing a more detailed description of synaptic integration in cortical neurons. In the current period, we will focus on those aspects of neuronal behavior that deviate from the simplest linear model of cortical function and try to understand the sources of these nonlinearities. The first aim is related to contrast-normalization (or more generally, stimulus-based normalization), which is thought to underlie perceptual constancy. Contrast-invariant orientation tuning is one aspect of normalization and our current understanding is that it might arise from the interaction of response variability and threshold. We seek to understand the source and properties of this variability. The second aim focuses on contrast-dependent changes in the tuning and response timing of neurons. The most successful model of these properties has relied on inhibitory inputs to neurons, but is not well supported by experimental evidence. We therefore seek mechanisms related to threshold, synaptic depression and other nonlinearities in the visual pathways. In the third aim, we propose to study nonlinearities in complex cells, using a recently developed measure of the computation that these cells use to integrate their visual inputs. We will test models of how cells of different cells perform this computation. We hope that the resulting data will contribute to a more coherent understanding of cortical function.      PUBLIC HEALTH RELEVANCE: We are studying the fundamental neural mechanisms by which the cerebral cortex processes visual information. From these experiments we hope to gain an understanding not only of how the visual system works, but also of how the brain performs other higher perceptual and cognitive functions. Understanding these processes in the normal brain may ultimately help us to understand how they malfunction in disease states, including epilepsy and mental disorders. Understanding the mechanisms of visual processing are also critical to constructing effective prosthetic and rehabilitative aids to vision.           PROJECT NARRATIVE We are studying the fundamental neural mechanisms by which the cerebral cortex processes visual information. From these experiments we hope to gain an understanding not only of how the visual system works, but also of how the brain performs other higher perceptual and cognitive functions. Understanding these processes in the normal brain may ultimately help is to understand how they malfunction in disease states, including epilepsy and mental disorders. Understanding the mechanisms of visual processing are also critical to constructing effective prosthetic and rehabilitative aids to vision.",Intracellular Analysis of Visual Cortical Function,7988541,R01EY004726,"['Accounting', 'Anatomy', 'Area', 'Behavior', 'Brain', 'Cell model', 'Cells', 'Cerebral cortex', 'Classification', 'Cognition', 'Complex', 'Data', 'Dendrites', 'Disease', 'Epilepsy', 'Frequencies', 'Iceberg', 'Image', 'Individual', 'Knee', 'Label', 'Linear Models', 'Measurement', 'Measures', 'Membrane', 'Membrane Potentials', 'Mental disorders', 'Modeling', 'Modification', 'Movement', 'Neurons', 'Perception', 'Phase', 'Photons', 'Physiological', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Principal Component Analysis', 'Process', 'Property', 'Prosthesis', 'Reaction Time', 'Records', 'Rehabilitation therapy', 'Relative (related person)', 'Rest', 'Retinal', 'Source', 'Stimulus', 'Synapses', 'Testing', 'Thalamic structure', 'Time', 'Undifferentiated', 'Vision', 'Visual', 'Visual Cortex', 'Visual Pathways', 'Visual system structure', 'Width', 'Work', 'abstracting', 'area striata', 'base', 'cognitive function', 'falls', 'feeding', 'in vivo', 'neuromechanism', 'object recognition', 'receptive field', 'research study', 'response', 'synaptic depression', 'visual information', 'visual process', 'visual processing']",NEI,NORTHWESTERN UNIVERSITY,R01,2010,372500,0.1796883758265265
"Mechanisms of Instructed Learning in the Auditory System  DESCRIPTION (provided by applicant):  Much of what the brain learns from experience, including language and sound identification and localization, is acquired through the mechanisms of supervised learning. In supervised learning, plasticity in one network of neurons is regulated or guided by information from another network. Our knowledge of the mechanisms of plasticity has increased tremendously over the past decade. In contrast, our knowledge of the mechanisms that regulate and instruct plasticity remains primitive.The calibration of the auditory system's map of space by the visual system is a well-characterized example of supervised learning. In the barn owl, the site in the auditory pathway where visual signals exert there effects, and the structural and functional changes they cause, have been determined. However, the properties of the instructive signals themselves, and the mechanisms by which they exert their effects, remain a mystery.The proposed research will study the instructive signals that calibrate the auditory space map in the owl. Extracellular electrophysiological techniques will be used to measure responses of instructive neural activity to visual, auditory and cross-modal parameters of stimulation. Pharmacological techniques will be used to determine the neurotransmitters that mediate the instructive signals, and the contribution of neuromodulators to the regulation of auditory plasticity. Anatomical techniques will be used to identify the source of input that gates the instructive activity. Behavioral techniques will be used to study the properties of the instructive signal as it occurs naturally in trained animals. Finally, we will manipulate the instructive signal in an attempt to train neural responses to specific auditory stimuli.This research aims at understanding, in detail, mechanisms that instruct neural plasticity. A thorough knowledge of these instructive mechanisms and the principles by which they operate will add substantially to our understanding of how the nervous system learns from experience. This, in turn, may lead to improved methods for teaching both normal and learning disabled children, as well as to improved therapeutic strategies for maximizing the restoration of function to patients following neurological injury or disease. n/a",Mechanisms of Instructed Learning in the Auditory System,7062451,R01DC005601,"['acetylcholine', 'auditory pathways', 'auditory stimulus', 'behavior test', 'behavioral /social science research tag', 'electrophysiology', 'gamma aminobutyrate', 'inferior colliculus', 'learning', 'neural information processing', 'neural plasticity', 'neurons', 'neurotransmitter receptor', 'neurotransmitters', 'norepinephrine', 'owls', 'stimulus /response', 'superior colliculus', 'visual stimulus']",NIDCD,STANFORD UNIVERSITY,R01,2006,352277,0.16150557519501926
"Mechanisms of Instructed Learning in the Auditory System  DESCRIPTION (provided by applicant):  Much of what the brain learns from experience, including language and sound identification and localization, is acquired through the mechanisms of supervised learning. In supervised learning, plasticity in one network of neurons is regulated or guided by information from another network. Our knowledge of the mechanisms of plasticity has increased tremendously over the past decade. In contrast, our knowledge of the mechanisms that regulate and instruct plasticity remains primitive.The calibration of the auditory system's map of space by the visual system is a well-characterized example of supervised learning. In the barn owl, the site in the auditory pathway where visual signals exert there effects, and the structural and functional changes they cause, have been determined. However, the properties of the instructive signals themselves, and the mechanisms by which they exert their effects, remain a mystery.The proposed research will study the instructive signals that calibrate the auditory space map in the owl. Extracellular electrophysiological techniques will be used to measure responses of instructive neural activity to visual, auditory and cross-modal parameters of stimulation. Pharmacological techniques will be used to determine the neurotransmitters that mediate the instructive signals, and the contribution of neuromodulators to the regulation of auditory plasticity. Anatomical techniques will be used to identify the source of input that gates the instructive activity. Behavioral techniques will be used to study the properties of the instructive signal as it occurs naturally in trained animals. Finally, we will manipulate the instructive signal in an attempt to train neural responses to specific auditory stimuli.This research aims at understanding, in detail, mechanisms that instruct neural plasticity. A thorough knowledge of these instructive mechanisms and the principles by which they operate will add substantially to our understanding of how the nervous system learns from experience. This, in turn, may lead to improved methods for teaching both normal and learning disabled children, as well as to improved therapeutic strategies for maximizing the restoration of function to patients following neurological injury or disease. n/a",Mechanisms of Instructed Learning in the Auditory System,6909137,R01DC005601,"['acetylcholine', 'auditory pathways', 'auditory stimulus', 'behavior test', 'behavioral /social science research tag', 'electrophysiology', 'gamma aminobutyrate', 'inferior colliculus', 'learning', 'neural information processing', 'neural plasticity', 'neurons', 'neurotransmitter receptor', 'neurotransmitters', 'norepinephrine', 'owls', 'stimulus /response', 'superior colliculus', 'visual stimulus']",NIDCD,STANFORD UNIVERSITY,R01,2005,360617,0.16150557519501926
"Mechanisms of Instructed Learning in the Auditory System  DESCRIPTION (provided by applicant):  Much of what the brain learns from experience, including language and sound identification and localization, is acquired through the mechanisms of supervised learning. In supervised learning, plasticity in one network of neurons is regulated or guided by information from another network. Our knowledge of the mechanisms of plasticity has increased tremendously over the past decade. In contrast, our knowledge of the mechanisms that regulate and instruct plasticity remains primitive.The calibration of the auditory system's map of space by the visual system is a well-characterized example of supervised learning. In the barn owl, the site in the auditory pathway where visual signals exert there effects, and the structural and functional changes they cause, have been determined. However, the properties of the instructive signals themselves, and the mechanisms by which they exert their effects, remain a mystery.The proposed research will study the instructive signals that calibrate the auditory space map in the owl. Extracellular electrophysiological techniques will be used to measure responses of instructive neural activity to visual, auditory and cross-modal parameters of stimulation. Pharmacological techniques will be used to determine the neurotransmitters that mediate the instructive signals, and the contribution of neuromodulators to the regulation of auditory plasticity. Anatomical techniques will be used to identify the source of input that gates the instructive activity. Behavioral techniques will be used to study the properties of the instructive signal as it occurs naturally in trained animals. Finally, we will manipulate the instructive signal in an attempt to train neural responses to specific auditory stimuli.This research aims at understanding, in detail, mechanisms that instruct neural plasticity. A thorough knowledge of these instructive mechanisms and the principles by which they operate will add substantially to our understanding of how the nervous system learns from experience. This, in turn, may lead to improved methods for teaching both normal and learning disabled children, as well as to improved therapeutic strategies for maximizing the restoration of function to patients following neurological injury or disease. n/a",Mechanisms of Instructed Learning in the Auditory System,6748961,R01DC005601,"['acetylcholine', 'auditory pathways', 'auditory stimulus', 'behavior test', 'behavioral /social science research tag', 'electrophysiology', 'gamma aminobutyrate', 'inferior colliculus', 'learning', 'neural information processing', 'neural plasticity', 'neurons', 'neurotransmitter receptor', 'neurotransmitters', 'norepinephrine', 'owls', 'stimulus /response', 'superior colliculus', 'visual stimulus']",NIDCD,STANFORD UNIVERSITY,R01,2004,360485,0.16150557519501926
"Mechanisms of Instructed Learning in the Auditory System  DESCRIPTION (provided by applicant):  Much of what the brain learns from experience, including language and sound identification and localization, is acquired through the mechanisms of supervised learning. In supervised learning, plasticity in one network of neurons is regulated or guided by information from another network. Our knowledge of the mechanisms of plasticity has increased tremendously over the past decade. In contrast, our knowledge of the mechanisms that regulate and instruct plasticity remains primitive.The calibration of the auditory system's map of space by the visual system is a well-characterized example of supervised learning. In the barn owl, the site in the auditory pathway where visual signals exert there effects, and the structural and functional changes they cause, have been determined. However, the properties of the instructive signals themselves, and the mechanisms by which they exert their effects, remain a mystery.The proposed research will study the instructive signals that calibrate the auditory space map in the owl. Extracellular electrophysiological techniques will be used to measure responses of instructive neural activity to visual, auditory and cross-modal parameters of stimulation. Pharmacological techniques will be used to determine the neurotransmitters that mediate the instructive signals, and the contribution of neuromodulators to the regulation of auditory plasticity. Anatomical techniques will be used to identify the source of input that gates the instructive activity. Behavioral techniques will be used to study the properties of the instructive signal as it occurs naturally in trained animals. Finally, we will manipulate the instructive signal in an attempt to train neural responses to specific auditory stimuli.This research aims at understanding, in detail, mechanisms that instruct neural plasticity. A thorough knowledge of these instructive mechanisms and the principles by which they operate will add substantially to our understanding of how the nervous system learns from experience. This, in turn, may lead to improved methods for teaching both normal and learning disabled children, as well as to improved therapeutic strategies for maximizing the restoration of function to patients following neurological injury or disease. n/a",Mechanisms of Instructed Learning in the Auditory System,6608876,R01DC005601,"['acetylcholine', ' auditory pathways', ' auditory stimulus', ' behavior test', ' behavioral /social science research tag', ' electrophysiology', ' gamma aminobutyrate', ' inferior colliculus', ' learning', ' neural information processing', ' neural plasticity', ' neurons', ' neurotransmitter receptor', ' neurotransmitters', ' norepinephrine', ' owls', ' stimulus /response', ' superior colliculus', ' visual stimulus']",NIDCD,STANFORD UNIVERSITY,R01,2003,360357,0.16150557519501926
"Mechanisms of Instructed Learning in the Auditory System  DESCRIPTION (provided by applicant):  Much of what the brain learns from experience, including language and sound identification and localization, is acquired through the mechanisms of supervised learning. In supervised learning, plasticity in one network of neurons is regulated or guided by information from another network. Our knowledge of the mechanisms of plasticity has increased tremendously over the past decade. In contrast, our knowledge of the mechanisms that regulate and instruct plasticity remains primitive.The calibration of the auditory system's map of space by the visual system is a well-characterized example of supervised learning. In the barn owl, the site in the auditory pathway where visual signals exert there effects, and the structural and functional changes they cause, have been determined. However, the properties of the instructive signals themselves, and the mechanisms by which they exert their effects, remain a mystery.The proposed research will study the instructive signals that calibrate the auditory space map in the owl. Extracellular electrophysiological techniques will be used to measure responses of instructive neural activity to visual, auditory and cross-modal parameters of stimulation. Pharmacological techniques will be used to determine the neurotransmitters that mediate the instructive signals, and the contribution of neuromodulators to the regulation of auditory plasticity. Anatomical techniques will be used to identify the source of input that gates the instructive activity. Behavioral techniques will be used to study the properties of the instructive signal as it occurs naturally in trained animals. Finally, we will manipulate the instructive signal in an attempt to train neural responses to specific auditory stimuli.This research aims at understanding, in detail, mechanisms that instruct neural plasticity. A thorough knowledge of these instructive mechanisms and the principles by which they operate will add substantially to our understanding of how the nervous system learns from experience. This, in turn, may lead to improved methods for teaching both normal and learning disabled children, as well as to improved therapeutic strategies for maximizing the restoration of function to patients following neurological injury or disease. n/a",Mechanisms of Instructed Learning in the Auditory System,6502785,R01DC005601,"['acetylcholine', ' auditory pathways', ' auditory stimulus', ' behavior test', ' behavioral /social science research tag', ' electrophysiology', ' gamma aminobutyrate', ' inferior colliculus', ' learning', ' neural information processing', ' neural plasticity', ' neurons', ' neurotransmitter receptor', ' neurotransmitters', ' norepinephrine', ' owls', ' stimulus /response', ' superior colliculus', ' visual stimulus']",NIDCD,STANFORD UNIVERSITY,R01,2002,360235,0.16150557519501926
"ERG & VEP: FIELD TOPOGRAPHY & SOURCE IDENTIFICATION The field topography of evoked potentials is the dependent of the responses on the location of a small stimulus in the visual field.  Field topographies are derived with a method of simultaneous stimulation of a large number of locations and extraction of the local responses from a single response signal.  The techniques for such studies have been developed and tested.  Goal 1: Determination of the field topography of the luminance and pattern ERGs and their components.  Correlation of these topographies with densities of retinal receptors and ganglion cells.  Inter-subject differences will be studied to establish a baseline for a clinical evaluation.  Goal 2: Development of an objective test of local retinal function for the purpose of screening, diagnosis and monitoring of patients.  The field plots will be derived from patients with specific etiologies (glaucoma, ocular hypertension, maculopathy).  The plots will be compared with fundus images to establish the exact location of retinal areas with abnormal ERG responses.  ERG fields will be compared with psychophysical fields to assess their sensitivity in the detection of local pathological changes.  Goal 3: Identification and characterization of ERG components from different retinal layers.  This will be achieved with different modes of pattern stimulation and techniques of nonlinear systems analysis.  Goal 4: Identification of VEP components from different visual areas of cortex.  Functional characterization of their sources on the basis of nonlinear systems analysis.  The field topography of the VEP is very complex due to the convoluted cortical anatomy.  For each stimulus location, the relative contributions to the response from various cortical sources are different.  A principal component analysis (SVD) will be applied to the responses at locations of comparable eccentricity in the visual field, to determine the subspace spanned by the components from different sources.  The kernel structure of the nonlinear responses will be used to identify and characterize the components within this subspace.  The invariance of the components between subjects will be tested to confirm the decomposition.  n/a",ERG & VEP: FIELD TOPOGRAPHY & SOURCE IDENTIFICATION,3263552,R01EY006861,"['cone cell', ' dark adaptation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' electroretinography', ' evoked potentials', ' eye disorder diagnosis', ' eye fundus photography', ' glaucoma', ' human subject', ' intraocular pressure', ' light adaptations', ' ophthalmoscopy', ' patient monitoring device', ' perimetry', ' psychophysics', ' retina disorder', ' retinal ganglion', ' rod cell', ' stimulus /response', ' visual cortex', ' visual fields', ' visual photoreceptor', ' visual stimulus']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,1992,291097,0.09120248139572523
"ERG & VEP: FIELD TOPOGRAPHY & SOURCE IDENTIFICATION The field topography of evoked potentials is the dependent of the responses on the location of a small stimulus in the visual field.  Field topographies are derived with a method of simultaneous stimulation of a large number of locations and extraction of the local responses from a single response signal.  The techniques for such studies have been developed and tested.  Goal 1: Determination of the field topography of the luminance and pattern ERGs and their components.  Correlation of these topographies with densities of retinal receptors and ganglion cells.  Inter-subject differences will be studied to establish a baseline for a clinical evaluation.  Goal 2: Development of an objective test of local retinal function for the purpose of screening, diagnosis and monitoring of patients.  The field plots will be derived from patients with specific etiologies (glaucoma, ocular hypertension, maculopathy).  The plots will be compared with fundus images to establish the exact location of retinal areas with abnormal ERG responses.  ERG fields will be compared with psychophysical fields to assess their sensitivity in the detection of local pathological changes.  Goal 3: Identification and characterization of ERG components from different retinal layers.  This will be achieved with different modes of pattern stimulation and techniques of nonlinear systems analysis.  Goal 4: Identification of VEP components from different visual areas of cortex.  Functional characterization of their sources on the basis of nonlinear systems analysis.  The field topography of the VEP is very complex due to the convoluted cortical anatomy.  For each stimulus location, the relative contributions to the response from various cortical sources are different.  A principal component analysis (SVD) will be applied to the responses at locations of comparable eccentricity in the visual field, to determine the subspace spanned by the components from different sources.  The kernel structure of the nonlinear responses will be used to identify and characterize the components within this subspace.  The invariance of the components between subjects will be tested to confirm the decomposition.  n/a",ERG & VEP: FIELD TOPOGRAPHY & SOURCE IDENTIFICATION,3263551,R01EY006861,"['cone cell', ' dark adaptation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' electroretinography', ' evoked potentials', ' eye disorder diagnosis', ' eye fundus photography', ' glaucoma', ' human subject', ' intraocular pressure', ' light adaptations', ' ophthalmoscopy', ' patient monitoring device', ' perimetry', ' psychophysics', ' retina disorder', ' retinal ganglion', ' rod cell', ' stimulus /response', ' visual cortex', ' visual fields', ' visual photoreceptor', ' visual stimulus']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,1991,273439,0.09120248139572523
"ERG & VEP: FIELD TOPOGRAPHY & SOURCE IDENTIFICATION The field topography of evoked potentials is the dependent of the responses on the location of a small stimulus in the visual field.  Field topographies are derived with a method of simultaneous stimulation of a large number of locations and extraction of the local responses from a single response signal.  The techniques for such studies have been developed and tested.  Goal 1: Determination of the field topography of the luminance and pattern ERGs and their components.  Correlation of these topographies with densities of retinal receptors and ganglion cells.  Inter-subject differences will be studied to establish a baseline for a clinical evaluation.  Goal 2: Development of an objective test of local retinal function for the purpose of screening, diagnosis and monitoring of patients.  The field plots will be derived from patients with specific etiologies (glaucoma, ocular hypertension, maculopathy).  The plots will be compared with fundus images to establish the exact location of retinal areas with abnormal ERG responses.  ERG fields will be compared with psychophysical fields to assess their sensitivity in the detection of local pathological changes.  Goal 3: Identification and characterization of ERG components from different retinal layers.  This will be achieved with different modes of pattern stimulation and techniques of nonlinear systems analysis.  Goal 4: Identification of VEP components from different visual areas of cortex.  Functional characterization of their sources on the basis of nonlinear systems analysis.  The field topography of the VEP is very complex due to the convoluted cortical anatomy.  For each stimulus location, the relative contributions to the response from various cortical sources are different.  A principal component analysis (SVD) will be applied to the responses at locations of comparable eccentricity in the visual field, to determine the subspace spanned by the components from different sources.  The kernel structure of the nonlinear responses will be used to identify and characterize the components within this subspace.  The invariance of the components between subjects will be tested to confirm the decomposition.  n/a",ERG & VEP: FIELD TOPOGRAPHY & SOURCE IDENTIFICATION,3263547,R01EY006861,"['cone cell', ' dark adaptation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' electroretinography', ' evoked potentials', ' eye disorder diagnosis', ' eye fundus photography', ' glaucoma', ' human subject', ' intraocular pressure', ' light adaptations', ' ophthalmoscopy', ' patient monitoring device', ' perimetry', ' psychophysics', ' retina disorder', ' retinal ganglion', ' rod cell', ' stimulus /response', ' visual cortex', ' visual fields', ' visual photoreceptor', ' visual stimulus']",NEI,SMITH-KETTLEWELL EYE RESEARCH INSTITUTE,R01,1990,309513,0.09120248139572523
"Supervised Learning in the Auditory System Project Summary: Understanding how learning is encoded in the brain remains one of the foremost challenges for neuroscience. We are using the barn owl auditory localization pathway as a model system to study the neural mechanisms of supervised learning. This pathway utilizes ascending information from both ears to synthesize a map of auditory space in the inferior colliculus. In this circuit, visual experience serves as a supervising influence which calibrates the map of auditory space during development and into adulthood. How visual experience guides this plasticity is not well understood. My training will approach one facet of this issue using a well-described paradigm for manipulating visual information-rearing young owls wearing prismatic spectacles. One primary goal of the research is to determine the extent to which the cyclic-AMP Response Element-Binding protein--a protein implicated in learning and plasticity in many systems-is activated within the inferior colliculus during prism adaptation. To do this I will use a combination of behavioral monitoring, electrophysiology, immunohistochemistry, confocal imaging, and quantitative image analysis. In total, these experiments should enhance our understanding of the biochemical link between behaviorally relevant experience and the learned changes imparted to the circuits of the auditory system. Relevance: The brain possesses a remarkable capacity to adapt with experience. This plasticity shapes many aspects of normal behavior, spanning from language learning during early childhood to adaptations to hearing loss in old age. Understanding how brain circuits change to generate adaptive behaviors will help us to better understand failures in plasticity (such as learning disorders) as well as normal brain function, and could potentially lead to treatments to prevent such failures. n/a",Supervised Learning in the Auditory System,7545853,F31DC008748,"['Adaptive Behaviors', 'Adolescent', 'Adult', 'Age', 'Animals', 'Antibodies', 'Auditory', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biochemical', 'Biological Models', 'Brain', 'CREB1 gene', 'Cyclic AMP-Responsive DNA-Binding Protein', 'Data', 'Development', 'Ear', 'Electrophysiology (science)', 'Epitopes', 'Exhibits', 'Failure', 'Goals', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Inferior Colliculus', 'Language Development', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Light', 'Link', 'Maps', 'Modeling', 'Monitor', 'Mus', 'Neurons', 'Neurosciences', 'Pan Genus', 'Pathway interactions', 'Pattern', 'Proteins', 'Research', 'Role', 'Shapes', 'Signal Transduction', 'Signaling Protein', 'Sound Localization', 'Strigiformes', 'Synaptic plasticity', 'System', 'Testing', 'Training', 'Visual', 'base', 'comparative', 'early childhood', 'experience', 'feeding', 'hearing impairment', 'method development', 'neuromechanism', 'prevent', 'prismatic spectacles', 'research study', 'transcription factor', 'visual information', 'visual map']",NIDCD,UNIVERSITY OF CALIFORNIA AT DAVIS,F31,2009,22769,0.1057123945059434
"Supervised Learning in the Auditory System Project Summary: Understanding how learning is encoded in the brain remains one of the foremost challenges for neuroscience. We are using the barn owl auditory localization pathway as a model system to study the neural mechanisms of supervised learning. This pathway utilizes ascending information from both ears to synthesize a map of auditory space in the inferior colliculus. In this circuit, visual experience serves as a supervising influence which calibrates the map of auditory space during development and into adulthood. How visual experience guides this plasticity is not well understood. My training will approach one facet of this issue using a well-described paradigm for manipulating visual information-rearing young owls wearing prismatic spectacles. One primary goal of the research is to determine the extent to which the cyclic-AMP Response Element-Binding protein--a protein implicated in learning and plasticity in many systems-is activated within the inferior colliculus during prism adaptation. To do this I will use a combination of behavioral monitoring, electrophysiology, immunohistochemistry, confocal imaging, and quantitative image analysis. In total, these experiments should enhance our understanding of the biochemical link between behaviorally relevant experience and the learned changes imparted to the circuits of the auditory system. Relevance: The brain possesses a remarkable capacity to adapt with experience. This plasticity shapes many aspects of normal behavior, spanning from language learning during early childhood to adaptations to hearing loss in old age. Understanding how brain circuits change to generate adaptive behaviors will help us to better understand failures in plasticity (such as learning disorders) as well as normal brain function, and could potentially lead to treatments to prevent such failures. n/a",Supervised Learning in the Auditory System,7334155,F31DC008748,"['Adaptive Behaviors', 'Adolescent', 'Adult', 'Age', 'Animals', 'Antibodies', 'Auditory', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biochemical', 'Biological Models', 'Brain', 'CREB1 gene', 'Cyclic AMP-Responsive DNA-Binding Protein', 'Data', 'Development', 'Ear', 'Electrophysiology (science)', 'Epitopes', 'Exhibits', 'Failure', 'Goals', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Inferior Colliculus', 'Language Development', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Light', 'Link', 'Maps', 'Modeling', 'Monitor', 'Mus', 'Neurons', 'Neurosciences', 'Numbers', 'Pan Genus', 'Pathway interactions', 'Pattern', 'Proteins', 'Research', 'Role', 'Shapes', 'Signal Transduction', 'Signaling Protein', 'Sound Localization', 'Strigiformes', 'Synaptic plasticity', 'System', 'Testing', 'Training', 'Visual', 'base', 'comparative', 'early childhood', 'experience', 'feeding', 'hearing impairment', 'method development', 'neuromechanism', 'prevent', 'prismatic spectacles', 'research study', 'transcription factor', 'visual information', 'visual map']",NIDCD,UNIVERSITY OF CALIFORNIA AT DAVIS,F31,2008,29557,0.1057123945059434
"Supervised Learning in the Auditory System    DESCRIPTION (provided by applicant): Project Summary: Understanding how learning is encoded in the brain remains one of the foremost challenges for neuroscience. We are using the barn owl auditory localization pathway as a model system to study the neural mechanisms of supervised learning. This pathway utilizes ascending information from both ears to synthesize a map of auditory space in the inferior colliculus. In this circuit, visual experience serves as a supervising influence which calibrates the map of auditory space during development and into adulthood. How visual experience guides this plasticity is not well understood. My training will approach one facet of this issue using a well-described paradigm for manipulating visual information-rearing young owls wearing prismatic spectacles. One primary goal of the research is to determine the extent to which the cyclic-AMP Response Element-Binding protein--a protein implicated in learning and plasticity in many systems-is activated within the inferior colliculus during prism adaptation. To do this I will use a combination of behavioral monitoring, electrophysiology, immunohistochemistry, confocal imaging, and quantitative image analysis. In total, these experiments should enhance our understanding of the biochemical link between behaviorally relevant experience and the learned changes imparted to the circuits of the auditory system. Relevance: The brain possesses a remarkable capacity to adapt with experience. This plasticity shapes many aspects of normal behavior, spanning from language learning during early childhood to adaptations to hearing loss in old age. Understanding how brain circuits change to generate adaptive behaviors will help us to better understand failures in plasticity (such as learning disorders) as well as normal brain function, and could potentially lead to treatments to prevent such failures.          n/a",Supervised Learning in the Auditory System,7277890,F31DC008748,"['Adaptive Behaviors', 'Adolescent', 'Adult', 'Age', 'Animals', 'Antibodies', 'Auditory', 'Auditory system', 'Barn Owls', 'Behavior', 'Behavioral', 'Biochemical', 'Biological Models', 'Brain', 'CREB1 gene', 'Cyclic AMP-Responsive DNA-Binding Protein', 'Data', 'Development', 'Ear', 'Electrophysiology (science)', 'Epitopes', 'Exhibits', 'Failure', 'Goals', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Inferior Colliculus', 'Language Development', 'Lead', 'Learning', 'Learning Disorders', 'Life', 'Light', 'Link', 'Maps', 'Modeling', 'Monitor', 'Mus', 'Neurons', 'Neurosciences', 'Numbers', 'Pan Genus', 'Pathway interactions', 'Pattern', 'Proteins', 'Research', 'Role', 'Shapes', 'Signal Transduction', 'Signaling Protein', 'Sound Localization', 'Strigiformes', 'Synaptic plasticity', 'System', 'Testing', 'Training', 'Visual', 'base', 'comparative', 'early childhood', 'experience', 'feeding', 'hearing impairment', 'method development', 'neuromechanism', 'prevent', 'prismatic spectacles', 'research study', 'transcription factor', 'visual information', 'visual map']",NIDCD,UNIVERSITY OF CALIFORNIA DAVIS,F31,2007,29557,0.1057123945059434
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,8077991,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2011,192348,0.10830603823417573
"Human-Centered Perceptual and Conceptual Classification of Biomedical Images    DESCRIPTION (provided by applicant): Biomedical images are ever increasing in quantity and importance yet effective computing solutions for managing images and understanding their content are lacking. Image understanding is a key limiting factor in advancing these endeavors. Major challenges remain in understanding the capabilities of the human visual system with respect to biomedical imaging and in extracting and utilizing tacit knowledge of domain experts. To meet these challenges, we propose an innovative, multidisciplinary approach which combines methods of user centered design, visual perception and computer imaging research to interact with domain experts and to elicit and use their extrinsic and intrinsic knowledge. We will use a novel contextual design approach to inspection of dermatology images to discover relationships between perceptually- relevant visual content of images and users' conceptual understanding as expressed through natural language. Analysis of users' eye movements and verbal descriptions, together with mapping to domain medical ontologies, will allow us to integrate visual data with a user-specified language model to define perceptual categories and inform image classification. This is a fundamental and challenging data to knowledge problem that has not been solved. This study will provide proof of concept of the value of eliciting tacit knowledge from domain experts through multiple perceptually relevant modes in order to integrate data and knowledge models for better image understanding and may help enact a paradigm shift in how we conceptualize and develop biomedical information systems, in general.             Project Narrative Biomedical images are ever increasing in quantity yet their usefulness for research, medicine, and teaching is limited by the design of current computing systems. Discoveries and concrete advances made in this study will contribute to solutions for effective use of digital images-a problem that is central to research and application across science, technology, and medicine. Advancements in our understanding of the design of useful and usable information systems will benefit society at large and contribute to the public health.  ",Human-Centered Perceptual and Conceptual Classification of Biomedical Images,7896281,R21LM010039,"['Algorithms', 'Categories', 'Classification', 'Clinical', 'Clinical Decision Support Systems', 'Computer Systems', 'Conceptual Domain', 'Data', 'Data Set', 'Dermatologist', 'Dermatology', 'Development', 'Diagnosis', 'Educational process of instructing', 'Evaluation', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Information Resources', 'Information Systems', 'Internet', 'Knowledge', 'Language', 'Learning', 'Link', 'Maps', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Multimedia', 'Natural Language Processing', 'Ontology', 'Perception', 'Phase', 'Process', 'Public Health', 'Research', 'Retrieval', 'Science', 'Semantics', 'Societies', 'Solutions', 'Specific qualifier value', 'Statistical Models', 'Structure', 'System', 'Technology', 'Training', 'Unified Medical Language System', 'Validation', 'Visual', 'Visual Perception', 'Visual system structure', 'base', 'bioimaging', 'biomedical information system', 'design', 'digital imaging', 'innovation', 'interdisciplinary approach', 'interest', 'meetings', 'natural language', 'novel', 'success', 'tool', 'user centered design', 'vector']",NLM,ROCHESTER INSTITUTE OF TECHNOLOGY,R21,2010,163457,0.10830603823417573
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9775855,R01EY011787,"['Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Genetic', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'area striata', 'awake', 'cell type', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'nerve supply', 'neural circuit', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2018,405000,0.10873448273462523
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9912748,R01EY011787,"['3-Dimensional', 'Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'cell type', 'cortical visual impairment', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'mouse genetics', 'nerve supply', 'neural circuit', 'neural network', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2020,395525,0.10873448273462523
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9685191,R01EY011787,"['3-Dimensional', 'Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Genetic', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'area striata', 'awake', 'cell type', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'nerve supply', 'neural circuit', 'neural network', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2019,394825,0.10873448273462523
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,9524027,R01EY011787,"['Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Biological Neural Networks', 'Brain', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Genetic', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'area striata', 'awake', 'cell type', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'nerve supply', 'neural circuit', 'novel', 'novel strategies', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2018,394146,0.10873448273462523
"IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX DESCRIPTION (Adapted from the Investigator's Abstract):  To date no unitary      theory of cortical function has emerged despite a long history of cortical       research.  Single cell approaches in primary visual cortex, as exemplified       by Hubeland Wiesel's studies and by recent work on parallel visual pathways,     have produced functional circuit diagrams arguing for hierarchical,              feedforward processing.  Alternatively, artificial neural network research       argues that the cortex might represent a distributed feedback circuit in         which intrinsic dynamics converge in stable states that represent                computational solutions.  these two types of models predict very different       activation patterns of the circuit.  The goal of the research is to              elucidate the three-dimensional spatio-temporal activity patterns intrinsic      to the cortical microcircuit and to identify their underlying circuits.          Studies will be carried out with brain slices from mouse visual cortex using     calcium imaging with a cooled CCD camera, a photodiode array and two-photon      microscope.  These techniques allow the investigators to follow the activity     of neuronal ensembles across the entire slice with single-cell and               submillisecond resolution.  Specifically, the investigators will (i)             determine the three-dimensional activity patterns present in a brain slice       (ii) establish the anatomical and functional connectivity underlying these       dynamics and (iii) identify neurons playing key roles and study their effect     in altering circuit dynamics.  These studies may help determine whether          cortical neurons can activate in preferential labeled lines, as predicted by     feedforward models or in a widely distributed pattern, as predicted by           feedback models, shedding light on the functional units of cortical              microcircuitry and their co-ordination in cortical function as a whole.          Finally, they will help understand the central pathophysiological                consequences of amblyopia and strabismus, as well as help design therapeutic     strategies aimed at compensating for these defect.  A more complete              understanding of the circuitry will also improve the analysis of visual          evoked potentials (VEP) and thus the measurement of acuity, contrast             sensitivity and chromatic sensitivity of preverbal children and in early         diagnosis of visual pathologies.                                                  n/a",IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX,6342657,R01EY011787,"['calcium indicator', ' confocal scanning microscopy', ' electrophysiology', ' evoked potentials', ' image processing', ' laboratory mouse', ' neural information processing', ' neuroanatomy', ' neurons', ' single cell analysis', ' synapses', ' vision disorders', ' visual cortex']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2001,243423,0.07667321576507327
"IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX DESCRIPTION (Adapted from the Investigator's Abstract):  To date no unitary      theory of cortical function has emerged despite a long history of cortical       research.  Single cell approaches in primary visual cortex, as exemplified       by Hubeland Wiesel's studies and by recent work on parallel visual pathways,     have produced functional circuit diagrams arguing for hierarchical,              feedforward processing.  Alternatively, artificial neural network research       argues that the cortex might represent a distributed feedback circuit in         which intrinsic dynamics converge in stable states that represent                computational solutions.  these two types of models predict very different       activation patterns of the circuit.  The goal of the research is to              elucidate the three-dimensional spatio-temporal activity patterns intrinsic      to the cortical microcircuit and to identify their underlying circuits.          Studies will be carried out with brain slices from mouse visual cortex using     calcium imaging with a cooled CCD camera, a photodiode array and two-photon      microscope.  These techniques allow the investigators to follow the activity     of neuronal ensembles across the entire slice with single-cell and               submillisecond resolution.  Specifically, the investigators will (i)             determine the three-dimensional activity patterns present in a brain slice       (ii) establish the anatomical and functional connectivity underlying these       dynamics and (iii) identify neurons playing key roles and study their effect     in altering circuit dynamics.  These studies may help determine whether          cortical neurons can activate in preferential labeled lines, as predicted by     feedforward models or in a widely distributed pattern, as predicted by           feedback models, shedding light on the functional units of cortical              microcircuitry and their co-ordination in cortical function as a whole.          Finally, they will help understand the central pathophysiological                consequences of amblyopia and strabismus, as well as help design therapeutic     strategies aimed at compensating for these defect.  A more complete              understanding of the circuitry will also improve the analysis of visual          evoked potentials (VEP) and thus the measurement of acuity, contrast             sensitivity and chromatic sensitivity of preverbal children and in early         diagnosis of visual pathologies.                                                  n/a",IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX,6138209,R01EY011787,"['calcium indicator', ' confocal scanning microscopy', ' electrophysiology', ' evoked potentials', ' image processing', ' laboratory mouse', ' neural information processing', ' neuroanatomy', ' neurons', ' single cell analysis', ' synapses', ' vision disorders', ' visual cortex']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2000,236390,0.07667321576507327
"IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX DESCRIPTION (Adapted from the Investigator's Abstract):  To date no unitary      theory of cortical function has emerged despite a long history of cortical       research.  Single cell approaches in primary visual cortex, as exemplified       by Hubeland Wiesel's studies and by recent work on parallel visual pathways,     have produced functional circuit diagrams arguing for hierarchical,              feedforward processing.  Alternatively, artificial neural network research       argues that the cortex might represent a distributed feedback circuit in         which intrinsic dynamics converge in stable states that represent                computational solutions.  these two types of models predict very different       activation patterns of the circuit.  The goal of the research is to              elucidate the three-dimensional spatio-temporal activity patterns intrinsic      to the cortical microcircuit and to identify their underlying circuits.          Studies will be carried out with brain slices from mouse visual cortex using     calcium imaging with a cooled CCD camera, a photodiode array and two-photon      microscope.  These techniques allow the investigators to follow the activity     of neuronal ensembles across the entire slice with single-cell and               submillisecond resolution.  Specifically, the investigators will (i)             determine the three-dimensional activity patterns present in a brain slice       (ii) establish the anatomical and functional connectivity underlying these       dynamics and (iii) identify neurons playing key roles and study their effect     in altering circuit dynamics.  These studies may help determine whether          cortical neurons can activate in preferential labeled lines, as predicted by     feedforward models or in a widely distributed pattern, as predicted by           feedback models, shedding light on the functional units of cortical              microcircuitry and their co-ordination in cortical function as a whole.          Finally, they will help understand the central pathophysiological                consequences of amblyopia and strabismus, as well as help design therapeutic     strategies aimed at compensating for these defect.  A more complete              understanding of the circuitry will also improve the analysis of visual          evoked potentials (VEP) and thus the measurement of acuity, contrast             sensitivity and chromatic sensitivity of preverbal children and in early         diagnosis of visual pathologies.                                                  n/a",IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX,2856964,R01EY011787,"['calcium indicator', ' confocal scanning microscopy', ' electrophysiology', ' evoked potentials', ' image processing', ' laboratory mouse', ' neural information processing', ' neuroanatomy', ' neurons', ' single cell analysis', ' synapses', ' vision disorders', ' visual cortex']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,1999,229564,0.07667321576507327
"IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX DESCRIPTION (Adapted from the Investigator's Abstract):  To date no unitary      theory of cortical function has emerged despite a long history of cortical       research.  Single cell approaches in primary visual cortex, as exemplified       by Hubeland Wiesel's studies and by recent work on parallel visual pathways,     have produced functional circuit diagrams arguing for hierarchical,              feedforward processing.  Alternatively, artificial neural network research       argues that the cortex might represent a distributed feedback circuit in         which intrinsic dynamics converge in stable states that represent                computational solutions.  these two types of models predict very different       activation patterns of the circuit.  The goal of the research is to              elucidate the three-dimensional spatio-temporal activity patterns intrinsic      to the cortical microcircuit and to identify their underlying circuits.          Studies will be carried out with brain slices from mouse visual cortex using     calcium imaging with a cooled CCD camera, a photodiode array and two-photon      microscope.  These techniques allow the investigators to follow the activity     of neuronal ensembles across the entire slice with single-cell and               submillisecond resolution.  Specifically, the investigators will (i)             determine the three-dimensional activity patterns present in a brain slice       (ii) establish the anatomical and functional connectivity underlying these       dynamics and (iii) identify neurons playing key roles and study their effect     in altering circuit dynamics.  These studies may help determine whether          cortical neurons can activate in preferential labeled lines, as predicted by     feedforward models or in a widely distributed pattern, as predicted by           feedback models, shedding light on the functional units of cortical              microcircuitry and their co-ordination in cortical function as a whole.          Finally, they will help understand the central pathophysiological                consequences of amblyopia and strabismus, as well as help design therapeutic     strategies aimed at compensating for these defect.  A more complete              understanding of the circuitry will also improve the analysis of visual          evoked potentials (VEP) and thus the measurement of acuity, contrast             sensitivity and chromatic sensitivity of preverbal children and in early         diagnosis of visual pathologies.                                                  n/a",IMAGING FUNCTIONAL CONNECTIVITY IN VISUAL CORTEX,2485367,R01EY011787,"['calcium indicator', ' confocal scanning microscopy', ' electrophysiology', ' evoked potentials', ' image processing', ' laboratory mouse', ' neural information processing', ' neuroanatomy', ' neurons', ' single cell analysis', ' synapses', ' vision disorders', ' visual cortex']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,1998,255314,0.07667321576507327
"VISION DISABILITIES IN LOW VISION   DESCRIPTION: (Adapted from the Investigator's Abstract) The proposed research                                                                   has the goal of developing and validating interval psychometric scales of            visual function limitations and vision disabilities. These interval scales will      be developed using Rasch probablistic measurement models applied to ordinal          patient rating responses to individual questions. Once developed and validated,      these scales will be independent of the particular assessment used, as long as       the instrument is calibrated to the scale. The significance of the proposed          research is that it will provide a means of estimating measurements of latent        functional ability variables for individual patients with visual impairments.        In the future, these measurements can be used for parametric studies,                epidemiological studies, and clinical outcome studies. The proposed research         will identify the number and nature of functional ability scales. It will            determine the dependence of those scales on the diagnosis of visual system           disorder, the type of visual impairment, the existence of co-morbidities, and        the patient's history of rehabilitation. Existing visual function instruments        (NEI-VFQ, VF-14, ADVS, and VAQ) and two general function instrument's                individual items will be evaluated with respect to scales. To estimate the           scales, a large set of specific cognitive and motor activities (e.g., writing a      check) will be classified according to functional domain (reading, fine and          gross visual-motor, visual information processing [e.g., recognition,                localization, orientation], or mobility). In telephone interviews, low vision        patients will be asked to rate the difficulty of performing each activity.           Rasch analysis will be used to test the hypothesis that there is a global            functional ability scale and to test the validity of the a priori visual             function domains. Principal component analysis of response residuals will be         used to evaluate the dimensionality of visual function limitations. Patients         also will be asked to rate the difficulty of achieving specific activity goals       (e.g., cook a meal, manage personal finances) and Rasch analysis will be used        to estimate a vision disability scale. Item ordering and item intervals on the       scales and scale validity will be compared across diagnostic groups (AMD,            glaucoma, diabetic retinopathy, RP, CVA, and anterior segment disorders) and         for different types of visual impairments (e.g., acuity loss and contracted          visual fields). Person measures of functional ability will be evaluated as a         function of severity of visual impairments (visual acuity, contrast                  sensitivity, visual fields, dark adaptation, color vision). Determining if the       NEI-VFQ, VF-14, ADVS, VAQ, SF-36, and SIP can be calibrated to common scales         will test the hypothesis that there is a common functional ability variable(s).                                                                                           n/a",VISION DISABILITIES IN LOW VISION,6524943,R01EY012045,"['blindness', ' clinical research', ' color visions', ' dark adaptation', ' eye disorder diagnosis', ' functional ability', ' human subject', ' interview', ' psychometrics', ' rehabilitation', ' statistics /biometry', ' vision disorders', ' visual fields', ' visual perception']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2002,439871,0.11548750504017515
"VISION DISABILITIES IN LOW VISION   DESCRIPTION: (Adapted from the Investigator's Abstract) The proposed research                                                                   has the goal of developing and validating interval psychometric scales of            visual function limitations and vision disabilities. These interval scales will      be developed using Rasch probablistic measurement models applied to ordinal          patient rating responses to individual questions. Once developed and validated,      these scales will be independent of the particular assessment used, as long as       the instrument is calibrated to the scale. The significance of the proposed          research is that it will provide a means of estimating measurements of latent        functional ability variables for individual patients with visual impairments.        In the future, these measurements can be used for parametric studies,                epidemiological studies, and clinical outcome studies. The proposed research         will identify the number and nature of functional ability scales. It will            determine the dependence of those scales on the diagnosis of visual system           disorder, the type of visual impairment, the existence of co-morbidities, and        the patient's history of rehabilitation. Existing visual function instruments        (NEI-VFQ, VF-14, ADVS, and VAQ) and two general function instrument's                individual items will be evaluated with respect to scales. To estimate the           scales, a large set of specific cognitive and motor activities (e.g., writing a      check) will be classified according to functional domain (reading, fine and          gross visual-motor, visual information processing [e.g., recognition,                localization, orientation], or mobility). In telephone interviews, low vision        patients will be asked to rate the difficulty of performing each activity.           Rasch analysis will be used to test the hypothesis that there is a global            functional ability scale and to test the validity of the a priori visual             function domains. Principal component analysis of response residuals will be         used to evaluate the dimensionality of visual function limitations. Patients         also will be asked to rate the difficulty of achieving specific activity goals       (e.g., cook a meal, manage personal finances) and Rasch analysis will be used        to estimate a vision disability scale. Item ordering and item intervals on the       scales and scale validity will be compared across diagnostic groups (AMD,            glaucoma, diabetic retinopathy, RP, CVA, and anterior segment disorders) and         for different types of visual impairments (e.g., acuity loss and contracted          visual fields). Person measures of functional ability will be evaluated as a         function of severity of visual impairments (visual acuity, contrast                  sensitivity, visual fields, dark adaptation, color vision). Determining if the       NEI-VFQ, VF-14, ADVS, VAQ, SF-36, and SIP can be calibrated to common scales         will test the hypothesis that there is a common functional ability variable(s).                                                                                           n/a",VISION DISABILITIES IN LOW VISION,6384727,R01EY012045,"['blindness', ' clinical research', ' color visions', ' dark adaptation', ' eye disorder diagnosis', ' functional ability', ' human subject', ' interview', ' psychometrics', ' rehabilitation', ' statistics /biometry', ' vision disorders', ' visual fields', ' visual perception']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2001,450853,0.11548750504017515
"VISION DISABILITIES IN LOW VISION   DESCRIPTION: (Adapted from the Investigator's Abstract) The proposed research                                                                   has the goal of developing and validating interval psychometric scales of            visual function limitations and vision disabilities. These interval scales will      be developed using Rasch probablistic measurement models applied to ordinal          patient rating responses to individual questions. Once developed and validated,      these scales will be independent of the particular assessment used, as long as       the instrument is calibrated to the scale. The significance of the proposed          research is that it will provide a means of estimating measurements of latent        functional ability variables for individual patients with visual impairments.        In the future, these measurements can be used for parametric studies,                epidemiological studies, and clinical outcome studies. The proposed research         will identify the number and nature of functional ability scales. It will            determine the dependence of those scales on the diagnosis of visual system           disorder, the type of visual impairment, the existence of co-morbidities, and        the patient's history of rehabilitation. Existing visual function instruments        (NEI-VFQ, VF-14, ADVS, and VAQ) and two general function instrument's                individual items will be evaluated with respect to scales. To estimate the           scales, a large set of specific cognitive and motor activities (e.g., writing a      check) will be classified according to functional domain (reading, fine and          gross visual-motor, visual information processing [e.g., recognition,                localization, orientation], or mobility). In telephone interviews, low vision        patients will be asked to rate the difficulty of performing each activity.           Rasch analysis will be used to test the hypothesis that there is a global            functional ability scale and to test the validity of the a priori visual             function domains. Principal component analysis of response residuals will be         used to evaluate the dimensionality of visual function limitations. Patients         also will be asked to rate the difficulty of achieving specific activity goals       (e.g., cook a meal, manage personal finances) and Rasch analysis will be used        to estimate a vision disability scale. Item ordering and item intervals on the       scales and scale validity will be compared across diagnostic groups (AMD,            glaucoma, diabetic retinopathy, RP, CVA, and anterior segment disorders) and         for different types of visual impairments (e.g., acuity loss and contracted          visual fields). Person measures of functional ability will be evaluated as a         function of severity of visual impairments (visual acuity, contrast                  sensitivity, visual fields, dark adaptation, color vision). Determining if the       NEI-VFQ, VF-14, ADVS, VAQ, SF-36, and SIP can be calibrated to common scales         will test the hypothesis that there is a common functional ability variable(s).                                                                                           n/a",VISION DISABILITIES IN LOW VISION,6179007,R01EY012045,"['blindness', ' clinical research', ' color visions', ' dark adaptation', ' eye disorder diagnosis', ' functional ability', ' human subject', ' interview', ' psychometrics', ' rehabilitation', ' statistics /biometry', ' vision disorders', ' visual fields', ' visual perception']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2000,441716,0.11548750504017515
"VISION DISABILITIES IN LOW VISION   DESCRIPTION: (Adapted from the Investigator's Abstract) The proposed research                                                                   has the goal of developing and validating interval psychometric scales of            visual function limitations and vision disabilities. These interval scales will      be developed using Rasch probablistic measurement models applied to ordinal          patient rating responses to individual questions. Once developed and validated,      these scales will be independent of the particular assessment used, as long as       the instrument is calibrated to the scale. The significance of the proposed          research is that it will provide a means of estimating measurements of latent        functional ability variables for individual patients with visual impairments.        In the future, these measurements can be used for parametric studies,                epidemiological studies, and clinical outcome studies. The proposed research         will identify the number and nature of functional ability scales. It will            determine the dependence of those scales on the diagnosis of visual system           disorder, the type of visual impairment, the existence of co-morbidities, and        the patient's history of rehabilitation. Existing visual function instruments        (NEI-VFQ, VF-14, ADVS, and VAQ) and two general function instrument's                individual items will be evaluated with respect to scales. To estimate the           scales, a large set of specific cognitive and motor activities (e.g., writing a      check) will be classified according to functional domain (reading, fine and          gross visual-motor, visual information processing [e.g., recognition,                localization, orientation], or mobility). In telephone interviews, low vision        patients will be asked to rate the difficulty of performing each activity.           Rasch analysis will be used to test the hypothesis that there is a global            functional ability scale and to test the validity of the a priori visual             function domains. Principal component analysis of response residuals will be         used to evaluate the dimensionality of visual function limitations. Patients         also will be asked to rate the difficulty of achieving specific activity goals       (e.g., cook a meal, manage personal finances) and Rasch analysis will be used        to estimate a vision disability scale. Item ordering and item intervals on the       scales and scale validity will be compared across diagnostic groups (AMD,            glaucoma, diabetic retinopathy, RP, CVA, and anterior segment disorders) and         for different types of visual impairments (e.g., acuity loss and contracted          visual fields). Person measures of functional ability will be evaluated as a         function of severity of visual impairments (visual acuity, contrast                  sensitivity, visual fields, dark adaptation, color vision). Determining if the       NEI-VFQ, VF-14, ADVS, VAQ, SF-36, and SIP can be calibrated to common scales         will test the hypothesis that there is a common functional ability variable(s).                                                                                           n/a",VISION DISABILITIES IN LOW VISION,2911020,R01EY012045,"['blindness', ' clinical research', ' color visions', ' dark adaptation', ' eye disorder diagnosis', ' functional ability', ' human subject', ' interview', ' psychometrics', ' rehabilitation', ' statistics /biometry', ' vision disorders', ' visual fields', ' visual perception']",NEI,JOHNS HOPKINS UNIVERSITY,R01,1999,263540,0.11548750504017515
"Shape representation and attention DESCRIPTION (provided by applicant): This proposal addresses the way the visual system processes complex shape. We focus on two intermediate visual areas, V2 and V4, located in the ventral processing stream immediately beyond primary visual cortex (area VI). These areas serve as the major input stages for higher-order shape processing areas in the temporal cortex. We propose neurophysiological experiments to investigate the way that shape is represented in these areas and the way that attention modulates these representations. Shape is difficult to describe and parameterize, so previous neurophysiological studies of shape processing have utilized simple, regular shapes that are experimentally convenient. However, intermediate shape processing is highly nonlinear, so results obtained with reduced stimulus sets may not generalize to other stimuli. We therefore propose to use both complex, natural stimuli and simpler stimuli such as gratings. To facilitate this, we are developing novel nonlinear regression algorithms to estimate the stimulus-response mapping functions of neurons in V2 and V4. The underlying shape dimensions represented therein can then be determined by applying visualization algorithms (developed in our laboratory) to the stimulus-response mapping functions estimated for single neurons. In another series of experiments we plan to investigate how extrastriate visual areas integrate information from earlier sensory areas. Finally, we propose to examine how visual attention affects shape representations in V2 and V4. We will accomplish this by quantifying the effects of selective attention to a specific shape (feature attention) and attention directed toward a specific location in space (spatial attention) on neuronal tuning curves. Successful completion of these projects will provide critical information to aid in development of quantitative computational models of shape processing in intermediate vision. n/a",Shape representation and attention,7386606,R01EY012241,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Animals', 'Area', 'Attention', 'Automobile Driving', 'Award', 'Biological Neural Networks', 'Cells', 'Complex', 'Computer Simulation', 'Conflict (Psychology)', 'Cues', 'Data Set', 'Development', 'Dimensions', 'Disease regression', 'Elements', 'Exhibits', 'Frequencies', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Location', 'Machine Learning', 'Maps', 'Modeling', 'Nature', 'Neurons', 'Noise', 'Operative Surgical Procedures', 'Pathway Analysis', 'Population', 'Positioning Attribute', 'Procedures', 'Process', 'Reporting', 'Research Personnel', 'Response to stimulus physiology', 'Rotation', 'Sampling', 'Sensory', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Stimulus', 'Stream', 'System', 'Techniques', 'Temporal Lobe', 'Training', 'V4 neuron', 'Validation', 'Vision', 'Visual attention', 'Visual system structure', 'Width', 'area V2', 'area striata', 'directed attention', 'extrastriate', 'extrastriate visual cortex', 'improved', 'movie', 'neurophysiology', 'novel', 'programs', 'receptive field', 'research study', 'response', 'selective attention', 'visual process', 'visual processing', 'visual search']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2008,355274,0.11623740972563
"Shape representation and attention DESCRIPTION (provided by applicant): This proposal addresses the way the visual system processes complex shape. We focus on two intermediate visual areas, V2 and V4, located in the ventral processing stream immediately beyond primary visual cortex (area VI). These areas serve as the major input stages for higher-order shape processing areas in the temporal cortex. We propose neurophysiological experiments to investigate the way that shape is represented in these areas and the way that attention modulates these representations. Shape is difficult to describe and parameterize, so previous neurophysiological studies of shape processing have utilized simple, regular shapes that are experimentally convenient. However, intermediate shape processing is highly nonlinear, so results obtained with reduced stimulus sets may not generalize to other stimuli. We therefore propose to use both complex, natural stimuli and simpler stimuli such as gratings. To facilitate this, we are developing novel nonlinear regression algorithms to estimate the stimulus-response mapping functions of neurons in V2 and V4. The underlying shape dimensions represented therein can then be determined by applying visualization algorithms (developed in our laboratory) to the stimulus-response mapping functions estimated for single neurons. In another series of experiments we plan to investigate how extrastriate visual areas integrate information from earlier sensory areas. Finally, we propose to examine how visual attention affects shape representations in V2 and V4. We will accomplish this by quantifying the effects of selective attention to a specific shape (feature attention) and attention directed toward a specific location in space (spatial attention) on neuronal tuning curves. Successful completion of these projects will provide critical information to aid in development of quantitative computational models of shape processing in intermediate vision. n/a",Shape representation and attention,7189021,R01EY012241,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Animals', 'Area', 'Attention', 'Automobile Driving', 'Award', 'Biological Neural Networks', 'Cells', 'Complex', 'Computer Simulation', 'Conflict (Psychology)', 'Cues', 'Data Set', 'Development', 'Dimensions', 'Disease regression', 'Elements', 'Exhibits', 'Frequencies', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Location', 'Machine Learning', 'Maps', 'Modeling', 'Nature', 'Neurons', 'Noise', 'Operative Surgical Procedures', 'Pathway Analysis', 'Population', 'Positioning Attribute', 'Procedures', 'Process', 'Reporting', 'Research Personnel', 'Response to stimulus physiology', 'Rotation', 'Sampling', 'Sensory', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Stimulus', 'Stream', 'System', 'Techniques', 'Temporal Lobe', 'Training', 'V4 neuron', 'Validation', 'Vision', 'Visual attention', 'Visual system structure', 'Width', 'area V2', 'area striata', 'directed attention', 'extrastriate', 'extrastriate visual cortex', 'improved', 'movie', 'neurophysiology', 'novel', 'programs', 'receptive field', 'research study', 'response', 'selective attention', 'visual process', 'visual processing', 'visual search']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2007,363113,0.11623740972563
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6937074,R33EY013928,"['clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human subject', 'neural information processing', 'neuropathology', 'visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R33,2005,606534,0.11810519353773273
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6830123,R33EY013928,"['clinical research', 'diagnosis design /evaluation', 'diagnosis quality /standard', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human subject', 'neural information processing', 'neuropathology', 'visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R33,2004,589323,0.11810519353773273
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6788651,R33EY013928,"['clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' early diagnosis', ' eye disorder diagnosis', ' glaucoma', ' glaucoma test', ' human subject', ' neural information processing', ' neuropathology', ' visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R33,2003,591603,0.11810519353773273
"Medical Advice from Glaucoma Informatics (MAGI)  DESCRIPTION (provided by applicant):  The project, Medical Advice from Glaucoma Informatics (MAGI), seeks to improve glaucoma diagnosis and management with state-of-the-art machine learning classifiers. These classifiers will automate the interpretation of standard automated perimetry (SAP), newer visual field tests, and structural tests for glaucoma in the general population and in stratified glaucoma populations. Phase 1 will complete the feasibility testing already underway. Phase 2 will apply the refined methods to a wider set of glaucoma testing problems.The management of glaucoma depends on a series of classifications. The glaucoma provider classifies tests as normal or indicative of glaucoma. The clinician then determines whether an eye has glaucoma or has had progression. Assembling these classifications, the provider makes decisions about management. Automated test interpreters, either as part of the testing machine or as a computer-based resource, can aid glaucoma providers with real-time interpretations. The research we propose takes advantage of our extensive data sets and builds on the ongoing research in our laboratories.Statistical classifiers, Bayesian nets, machine learning classifiers, and expert systems represent different types of classifiers with diverse properties. Machine learning classifiers can perform exceptionally well at identifying classes, even when the data are complex and have dependencies. We will test and select the optimal machine learning classifier for diagnosis. We will further improve classifier performance and determine feature utility by optimizing the feature set visual field tests are time consuming and stressful. We will streamline the tests by removing unimportant test points.Even with decades of experience, there is uncertainty with regard to the evaluation of the SAP. There is less accumulated knowledge about non-standard tests, such as short-wavelength automated perimetry, nerve fiber layer thickness, or optic nerve head topography. Machine classifiers may learn how to interpret nonstandard tests better. We will go beyond STATPAC's capabilities with classifiers that have learned to interpret SAP, nonstandard visual field tests, structural glaucoma tests, and STATPAC plots in the general population and in patients stratified by race, family history, and other information available at the time of the test.Conversion of suspects to glaucoma and progression of glaucoma cannot yet be predicted from tests. We will develop classifiers for these predictions. Classifiers will be designed to diagnose early glaucoma, detect early progression, and identify glaucomatous eyes at risk of progression.Unsupervised learning provides cluster analysis that can determine distinct groups with members in some way similar from the test data. In an effort to discover new and use useful information with unsupervised learning, we will mine our data in visual function and structural tests for glaucoma  and in specific combinations of population groups. n/a",Medical Advice from Glaucoma Informatics (MAGI),6551796,R21EY013928,"['clinical research', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' early diagnosis', ' eye disorder diagnosis', ' glaucoma', ' glaucoma test', ' human subject', ' neural information processing', ' neuropathology', ' visual fields']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R21,2002,144319,0.11810519353773273
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,8139754,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'meetings', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2011,219694,0.23417656999726544
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,7911700,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'meetings', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2010,226559,0.23417656999726544
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,7692268,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Cues', 'Data', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'meetings', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2009,228847,0.23417656999726544
"Cue Reliability and Depth Calibration During Space Perception    DESCRIPTION (provided by applicant): The long-term objective of the proposed work is to understand how learning by the visual system helps it to represent the immediate environment during perception. Because perception is accurate, we can know spatial layout: the shapes, orientations, sizes, and spatial locations of the objects and surfaces around us. But this accuracy requires that the visual system learn over time how best to interpret visual ""cues"". These cues are the signals from the environment that the visual system extracts from the retinal images that are informative about spatial layout. Known cues include binocular disparity, texture gradients, occlusion relations, motion parallax, and familiar size, to name a few. How do these cues come to be interpreted correctly? A fundamental problem is that visual cues are ambiguous. Even if cues could be measured exactly (which they cannot, the visual system being a physical device) there would still be different possible 3D interpretations for a given set of cues. As a result, the visual system is forced to operate probabilistically: the way things ""look"" to us reflects an implicit guess as to which interpretation of the cues is most likely to be correct. Each additional cue helps improve the guess. For example, the retinal image of a door could be interpreted as a vertical rectangle or as some other quadrilateral at a non-vertical orientation in space, and the shadow cues at the bottom of the door helps the system know that it's a vertical rectangle. What mechanisms do the visual system use to discern which cues are available for interpreting images correctly? The proposed work aims to answer this fundamental question about perceptual learning. It was recently shown that the visual system can detect and start using new cues for perception. This phenomenon can be studied in the laboratory using classical conditioning procedures that were previously developed to study learning in animals. In the proposed experiments, a model system is used to understand details about when this learning occurs and what is learned. The data will be compared to predictions based on older, analogous studies in the animal learning literature, and interpreted in the context of Bayesian statistical inference, especially machine learning theory. The proposed work benefits public health by characterizing the brain mechanisms that keep visual perception accurate. These mechanisms are at work in the many months during which a person with congenital cataracts learns to use vision after the cataracts are removed, and it is presumably these mechanisms that go awry when an individual with a family history of synesthesia or autism develops anomalous experience-dependent perceptual responses. Neurodegenerative diseases may disrupt visual learning, in which case visual learning tests could be used to detect disease; understanding the learning of new cues in human vision could lead to better computerized aids for the visually impaired; and knowing what causes a new cue to be learned could lead to new technologies for training people to perceive accurately in novel work environments.          n/a",Cue Reliability and Depth Calibration During Space Perception,7388324,R01EY013988,"['Address', 'Adult', 'Animal Behavior', 'Animals', 'Appearance', 'Autistic Disorder', 'Binocular Vision', 'Biological Models', 'Brain', 'Calibration', 'Cataract', 'Computer Vision Systems', 'Condition', 'Cues', 'Data', 'Depth', 'Devices', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Family history of', 'Food', 'Funding', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Learning Disabilities', 'Literature', 'Location', 'Longevity', 'Machine Learning', 'Measures', 'Memory', 'Motion', 'Motion Perception', 'Names', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Pathology', 'Perception', 'Perceptual learning', 'Persons', 'Positioning Attribute', 'Primates', 'Procedures', 'Process', 'Public Health', 'Rate', 'Recruitment Activity', 'Research', 'Retinal', 'Reversal Learning', 'Rotation', 'Shadowing (Histology)', 'Shapes', 'Signal Transduction', 'Source', 'Space Perception', 'Stimulus', 'Surface', 'System', 'Testing', 'Texture', 'Time', 'Training', 'Translations', 'Trust', 'Ursidae Family', 'Vision', 'Vision Disparity', 'Visual', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'Workplace', 'area MT', 'base', 'classical conditioning', 'clinical application', 'computerized', 'concept', 'congenital cataract', 'design', 'devices for the visually impaired', 'experience', 'improved', 'neuromechanism', 'new technology', 'novel', 'programs', 'relating to nervous system', 'research study', 'response', 'size', 'stereoscopic', 'theories', 'tool', 'visual information', 'visual learning', 'visual process', 'visual processing']",NEI,STATE COLLEGE OF OPTOMETRY,R01,2008,228847,0.23417656999726544
"Diagnostic aid software for the visual field test Visual field (VF) test is a widely used, noninvasive technique for evaluating pathology or dysfunction in the visual pathways. The VF test, in conjunction with other diagnostics, is used for detection of  laucoma and for following its progression. Early detection is critical as blindness from glaucoma is preventable in nearly all cases, provided treatment is administered early in the progression. There is a need for an automated decision aid tool that will facilitate and standardize the interpretation task. Following a successful Phase I feasibility demonstration, Phase II will apply novel machine learning approaches to the problem of glaucoma diagnosis via an automated analysis of visual field and ancillary data. IAC will develop an integrated, user friendly software program that will provide a reliable detailed classification of glaucomatous and non-glaucomatous defects with the main emphasis on glaucomatous defects and early detection. The aim is to achieve classification accuracy close to that of a highly skilled human expert. The diagnosis suggested by the software will be supported by a set of comprehensive rules extracted from the classification algorithm. Optionally, the program will provide measures of visual field and glaucoma progression. n/a",Diagnostic aid software for the visual field test,7120029,R44EY014077,"['computer human interaction', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease /disorder classification', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'human data', 'mathematics', 'model design /development', 'pathologic process', 'visual fields']",NEI,"BIOFORMATIX, INC.",R44,2006,325411,0.14244977311948967
"Diagnostic aid software for the visual field test Visual field (VF) test is a widely used, noninvasive technique for evaluating pathology or dysfunction in the visual pathways. The VF test, in conjunction with other diagnostics, is used for detection of  laucoma and for following its progression. Early detection is critical as blindness from glaucoma is preventable in nearly all cases, provided treatment is administered early in the progression. There is a need for an automated decision aid tool that will facilitate and standardize the interpretation task. Following a successful Phase I feasibility demonstration, Phase II will apply novel machine learning approaches to the problem of glaucoma diagnosis via an automated analysis of visual field and ancillary data. IAC will develop an integrated, user friendly software program that will provide a reliable detailed classification of glaucomatous and non-glaucomatous defects with the main emphasis on glaucomatous defects and early detection. The aim is to achieve classification accuracy close to that of a highly skilled human expert. The diagnosis suggested by the software will be supported by a set of comprehensive rules extracted from the classification algorithm. Optionally, the program will provide measures of visual field and glaucoma progression. n/a",Diagnostic aid software for the visual field test,6882489,R44EY014077,"['computer human interaction', 'computer program /software', 'computer system design /evaluation', 'diagnosis design /evaluation', 'disease /disorder classification', 'early diagnosis', 'eye disorder diagnosis', 'glaucoma', 'human data', 'mathematics', 'model design /development', 'pathologic process', 'visual fields']",NEI,"BIOFORMATIX, INC.",R44,2005,324664,0.14244977311948967
"Diagnostic Aid Software for Visual Field Test    DESCRIPTION (provided by applicant): Visual Field (VF) test is a widely used, noninvasive technique for evaluating pathology or dysfunction in the visual pathways. The VF test, in conjunction with other diagnostics, is used for detection of early stages of glaucoma and for following its progression. Early detection is critical as blindness from glaucoma is preventable in nearly all cases, provided treatment is administered early in the progression. However, the inherent subjectivity of the VF test makes it often difficult to interpret even for a skilled practitioner. There is a need for automated decision aid tool that will facilitate and standardize the interpretation task.   In Phase 1 of this project, IAC will design and implement novel software algorithms to automate the interpretation of VF test data for detection of glaucoma. The software will classify VF test data into normal, borderline glaucomatous, glaucomatous and unknown (not normal or glaucomatous). The aim is to provide classification performance close to that of a highly skilled human expert. The emphasis will be on the detection of early stages of glaucoma. In addition to the classification output, the software will produce a set of comprehensive rules that will explain the decision path leading to the suggested diagnosis.         n/a",Diagnostic Aid Software for Visual Field Test,6582662,R43EY014077,"['artificial intelligence', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' early diagnosis', ' glaucoma', ' glaucoma test', ' human data', ' noninvasive diagnosis', ' vision tests', ' visual fields']",NEI,INTELLIGENT AUTOMATION CORPORATION,R43,2003,99681,0.10080670521520359
"Perceptual Learning: Human vs. Optimal Bayesian Neural plasticity and perceptual learning are fundamental in the developmental stages of vision,  in attaining expertise in specialized perceptual tasks, and in recovery from brain injuries and low-  vision disorders. One important process in perceptual learning is the improvement in humans'  ability to use task-relevant (signal) information. Although there have been advances in the  understanding of the dynamics and algorithms mediating how humans optimize the selection of  task relevant visual information, little is known about how eye movement patterns vary with  practice and their impact in optimizing perceptual performance. Yet, in real world environments,  eye movements are a critical component of active vision as humans explore the visual scene to  make perceptual judgments. Understanding perceptual learning in human daily life requires  studying the mechanisms mediating the changes in the planning of eye movements with learning  and their contributions to optimizing perceptual performance. We hypothesize that two new  experimental paradigms with digitally designed visual stimuli, in conjunction with eye position  recording, and a newly developed foveated ideal observer and Bayesian learner will help  elucidate how humans learn to strategize their eye movements and the contributions of the  optimized sampling of the images to improvements in perceptual learning. The proposed work  will address the following questions: 1) Do humans use learned information about the statistical  properties of the visual stimuli and the requirements of the task at hand to strategize their eye  movements to optimize the foveal sampling of the visual scene and perceptual performance?; 2)  Do humans use knowledge of the varying resolution of their foveated visual system to optimally  learn to plan eye movements for a given set of visual stimuli and task?; 3) What are the  contributions of learning to strategize eye movements to the overall improvements in perceptual  performance in ecologically important tasks such as face recognition, object identification and  visual search?; 4) How do human fixation patterns and performance benefits from strategizing  eye movements compare to an optimal foveated observer and learner? The proposed work will  improve our understanding of the human neural algorithms mediating the dynamics of adult  perceptual learning during active vision for ecologically important tasks. The proposed  experimental protocols and theoretical developments will also provide a novel, powerful and  flexible framework with which other researchers can study eye movements and learning of  humans undergoing visual loss recovery as well as patients with learning disabilities. PUBLIC HEALTH RELEVANCE  The proposed work benefits public health by increasing our understanding of how  humans learn to move their eyes to potentially informative regions of the visual scene in  important daily tasks such as identifying faces or searching for objects. Thorough  understanding of these mechanisms in normal humans will allow identification of  learning anomalies in patients recovering from visual-loss or learning disabilities and  potentially develop tests to assess treatments.",Perceptual Learning: Human vs. Optimal Bayesian,8323947,R01EY015925,"['Accounting', 'Address', 'Adult', 'Algorithms', 'Amblyopia', 'Animals', 'Area', 'Behavior', 'Blindness', 'Brain Injuries', 'Brain imaging', 'Cells', 'Chin', 'Complex', 'Data', 'Detection', 'Development', 'Discrimination', 'Emotional', 'Emotions', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Frequencies', 'Funding', 'Goals', 'Gold', 'Health', 'Human', 'Image', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Literature', 'Location', 'Machine Learning', 'Macular degeneration', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Monitor', 'Nature', 'Neuronal Plasticity', 'Nose', 'Oral cavity', 'Patients', 'Pattern', 'Perceptual learning', 'Performance', 'Positioning Attribute', 'Process', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysiology', 'Public Health', 'Recording of previous events', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Retinal', 'Retinitis Pigmentosa', 'Role', 'Sampling', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Staging', 'Stimulus', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Work', 'active vision', 'area striata', 'design', 'experience', 'flexibility', 'gaze', 'ideal observer (Bayesian)', 'improved', 'interest', 'neurophysiology', 'novel', 'object recognition', 'oculomotor', 'prevent', 'relating to nervous system', 'sample fixation', 'tumor', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2012,281126,0.12878883677199698
"Perceptual Learning: Human vs. Optimal Bayesian    DESCRIPTION (provided by applicant): Neural plasticity and perceptual learning are fundamental in the developmental stages of vision, in attaining expertise in specialized perceptual tasks, and in recovery from brain injuries and low- vision disorders. One important process in perceptual learning is the improvement in humans' ability to use task-relevant (signal) information. Although there have been advances in the understanding of the dynamics and algorithms mediating how humans optimize the selection of task relevant visual information, little is known about how eye movement patterns vary with practice and their impact in optimizing perceptual performance. Yet, in real world environments, eye movements are a critical component of active vision as humans explore the visual scene to make perceptual judgments. Understanding perceptual learning in human daily life requires studying the mechanisms mediating the changes in the planning of eye movements with learning and their contributions to optimizing perceptual performance. We hypothesize that two new experimental paradigms with digitally designed visual stimuli, in conjunction with eye position recording, and a newly developed foveated ideal observer and Bayesian learner will help elucidate how humans learn to strategize their eye movements and the contributions of the optimized sampling of the images to improvements in perceptual learning. The proposed work will address the following questions: 1) Do humans use learned information about the statistical properties of the visual stimuli and the requirements of the task at hand to strategize their eye movements to optimize the foveal sampling of the visual scene and perceptual performance?; 2) Do humans use knowledge of the varying resolution of their foveated visual system to optimally learn to plan eye movements for a given set of visual stimuli and task?; 3) What are the contributions of learning to strategize eye movements to the overall improvements in perceptual performance in ecologically important tasks such as face recognition, object identification and visual search?; 4) How do human fixation patterns and performance benefits from strategizing eye movements compare to an optimal foveated observer and learner? The proposed work will improve our understanding of the human neural algorithms mediating the dynamics of adult perceptual learning during active vision for ecologically important tasks. The proposed experimental protocols and theoretical developments will also provide a novel, powerful and flexible framework with which other researchers can study eye movements and learning of humans undergoing visual loss recovery as well as patients with learning disabilities.      PUBLIC HEALTH RELEVANCE: The proposed work benefits public health by increasing our understanding of how humans learn to move their eyes to potentially informative regions of the visual scene in important daily tasks such as identifying faces or searching for objects. Thorough understanding of these mechanisms in normal humans will allow identification of learning anomalies in patients recovering from visual-loss or learning disabilities and potentially develop tests to assess treatments.          PUBLIC HEALTH RELEVANCE  The proposed work benefits public health by increasing our understanding of how  humans learn to move their eyes to potentially informative regions of the visual scene in  important daily tasks such as identifying faces or searching for objects. Thorough  understanding of these mechanisms in normal humans will allow identification of  learning anomalies in patients recovering from visual-loss or learning disabilities and  potentially develop tests to assess treatments.",Perceptual Learning: Human vs. Optimal Bayesian,7988249,R01EY015925,"['Accounting', 'Address', 'Adult', 'Algorithms', 'Amblyopia', 'Animals', 'Area', 'Behavior', 'Blindness', 'Brain Injuries', 'Brain imaging', 'Cells', 'Chin', 'Complex', 'Data', 'Detection', 'Development', 'Discrimination', 'Emotional', 'Emotions', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Frequencies', 'Funding', 'Goals', 'Gold', 'Hand', 'Human', 'Image', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Literature', 'Location', 'Machine Learning', 'Macular degeneration', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Monitor', 'Nature', 'Neuronal Plasticity', 'Nose', 'Oral cavity', 'Patients', 'Pattern', 'Perceptual learning', 'Performance', 'Positioning Attribute', 'Process', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysiology', 'Public Health', 'Recording of previous events', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Retinal', 'Retinitis Pigmentosa', 'Role', 'Sampling', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Staging', 'Stimulus', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Work', 'active vision', 'area striata', 'design', 'experience', 'flexibility', 'gaze', 'ideal observer (Bayesian)', 'improved', 'interest', 'neurophysiology', 'novel', 'object recognition', 'oculomotor', 'prevent', 'public health relevance', 'relating to nervous system', 'sample fixation', 'tumor', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2010,277974,0.13000632730384087
"Perceptual Learning: Human vs. Optimal Bayesian    DESCRIPTION (provided by applicant): Neural plasticity and perceptual learning are fundamental in the developmental stages of vision, in attaining expertise in specialized perceptual tasks, and in recovery from brain injuries and low- vision disorders. One important process in perceptual learning is the improvement in humans' ability to use task-relevant (signal) information. Although there have been advances in the understanding of the dynamics and algorithms mediating how humans optimize the selection of task relevant visual information, little is known about how eye movement patterns vary with practice and their impact in optimizing perceptual performance. Yet, in real world environments, eye movements are a critical component of active vision as humans explore the visual scene to make perceptual judgments. Understanding perceptual learning in human daily life requires studying the mechanisms mediating the changes in the planning of eye movements with learning and their contributions to optimizing perceptual performance. We hypothesize that two new experimental paradigms with digitally designed visual stimuli, in conjunction with eye position recording, and a newly developed foveated ideal observer and Bayesian learner will help elucidate how humans learn to strategize their eye movements and the contributions of the optimized sampling of the images to improvements in perceptual learning. The proposed work will address the following questions: 1) Do humans use learned information about the statistical properties of the visual stimuli and the requirements of the task at hand to strategize their eye movements to optimize the foveal sampling of the visual scene and perceptual performance?; 2) Do humans use knowledge of the varying resolution of their foveated visual system to optimally learn to plan eye movements for a given set of visual stimuli and task?; 3) What are the contributions of learning to strategize eye movements to the overall improvements in perceptual performance in ecologically important tasks such as face recognition, object identification and visual search?; 4) How do human fixation patterns and performance benefits from strategizing eye movements compare to an optimal foveated observer and learner? The proposed work will improve our understanding of the human neural algorithms mediating the dynamics of adult perceptual learning during active vision for ecologically important tasks. The proposed experimental protocols and theoretical developments will also provide a novel, powerful and flexible framework with which other researchers can study eye movements and learning of humans undergoing visual loss recovery as well as patients with learning disabilities.      PUBLIC HEALTH RELEVANCE: The proposed work benefits public health by increasing our understanding of how humans learn to move their eyes to potentially informative regions of the visual scene in important daily tasks such as identifying faces or searching for objects. Thorough understanding of these mechanisms in normal humans will allow identification of learning anomalies in patients recovering from visual-loss or learning disabilities and potentially develop tests to assess treatments.          PUBLIC HEALTH RELEVANCE  The proposed work benefits public health by increasing our understanding of how  humans learn to move their eyes to potentially informative regions of the visual scene in  important daily tasks such as identifying faces or searching for objects. Thorough  understanding of these mechanisms in normal humans will allow identification of  learning anomalies in patients recovering from visual-loss or learning disabilities and  potentially develop tests to assess treatments.",Perceptual Learning: Human vs. Optimal Bayesian,8123224,R01EY015925,"['Accounting', 'Address', 'Adult', 'Algorithms', 'Amblyopia', 'Animals', 'Area', 'Behavior', 'Blindness', 'Brain Injuries', 'Brain imaging', 'Cells', 'Chin', 'Complex', 'Data', 'Detection', 'Development', 'Discrimination', 'Emotional', 'Emotions', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Frequencies', 'Funding', 'Goals', 'Gold', 'Human', 'Image', 'Individual', 'Infant', 'Instruction', 'Investigation', 'Judgment', 'Knowledge', 'Learning', 'Learning Disabilities', 'Life', 'Literature', 'Location', 'Machine Learning', 'Macular degeneration', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Monitor', 'Nature', 'Neuronal Plasticity', 'Nose', 'Oral cavity', 'Patients', 'Pattern', 'Perceptual learning', 'Performance', 'Positioning Attribute', 'Process', 'Progress Reports', 'Property', 'Protocols documentation', 'Psychophysiology', 'Public Health', 'Recording of previous events', 'Recovery', 'Research', 'Research Personnel', 'Resolution', 'Retinal', 'Retinitis Pigmentosa', 'Role', 'Sampling', 'Signal Transduction', 'Source', 'Spatial Distribution', 'Staging', 'Stimulus', 'Testing', 'To specify', 'Uncertainty', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Visual impairment', 'Visual system structure', 'Work', 'active vision', 'area striata', 'design', 'experience', 'flexibility', 'gaze', 'ideal observer (Bayesian)', 'improved', 'interest', 'neurophysiology', 'novel', 'object recognition', 'oculomotor', 'prevent', 'public health relevance', 'relating to nervous system', 'sample fixation', 'tumor', 'visual information', 'visual performance', 'visual process', 'visual processing', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2011,281126,0.13000632730384087
"Spatial Modeling in Glaucoma DESCRIPTION (provided by applicant): This career training proposal is to train Michael D. Twa, OD, MS as an independent clinician-scientist. A five year training program is proposed, consisting of formal coursework in vision science, specific training in computer science and image processing, and mentoring in the application of these skills to clinical outcomes research in glaucoma. In September 2003, NIH announced a new ""Roadmap"" to accelerate advances in biomedical research for the 21st century. Three areas listed in this Roadmap are relevant to this research proposal: (1) Interdisciplinary research training. (2) Clinical research informatics. (3) Development of enabling technologies for improved assessment of clinical outcomes. The Roadmap emphasizes coordinated strategies to develop both technological and human resources to take full advantage of multidisciplinary and translational research opportunities. This proposal addresses the stated training objectives at an individual level.  Glaucoma is a leading cause of blindness. Visual field assessment and optic nerve head imaging (confocal scanning laser tomography) are commonly used to diagnose the disease and monitor its progression, yet there is considerable controversy about how to interpret and make best use of this information. Currently, raw data from these observations are reduced to statistical indices that are meant to summarize clinically meaningful features and provide a basis for classifying test results as normal or not. Unfortunately, these indices may sacrifice other relevant features in the data for interpretability.  We will use mathematical modeling methods (polynomial modeling, spline fitting and wavelet analysis) to quantify patterns in visual field data and topographic images of the optic nerve head. We will use features derived from these modeling methods to apply novel pattern recognition techniques from computer and information sciences-decision trees and non-linear regression analysis-and then compare these techniques to current methods to identify glaucoma. By improving current methods of analysis we can provide a more quantitative basis for clinical decisions, and offer greater consistency and objectivity on data interpretation. The long-term objective of this proposal is to translate advances in computer and information sciences to the analysis of clinical outcomes research in glaucoma and other eye diseases. n/a",Spatial Modeling in Glaucoma,7015012,K23EY016225,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer assisted diagnosis', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human data', 'image processing', 'mathematical model', 'model design /development', 'neuroimaging', 'optic nerve', 'patient oriented research', 'tomography', 'visual fields']",NEI,OHIO STATE UNIVERSITY,K23,2006,142642,0.06473823136925229
"Spatial Modeling in Glaucoma DESCRIPTION (provided by applicant): This career training proposal is to train Michael D. Twa, OD, MS as an independent clinician-scientist. A five year training program is proposed, consisting of formal coursework in vision science, specific training in computer science and image processing, and mentoring in the application of these skills to clinical outcomes research in glaucoma. In September 2003, NIH announced a new ""Roadmap"" to accelerate advances in biomedical research for the 21st century. Three areas listed in this Roadmap are relevant to this research proposal: (1) Interdisciplinary research training. (2) Clinical research informatics. (3) Development of enabling technologies for improved assessment of clinical outcomes. The Roadmap emphasizes coordinated strategies to develop both technological and human resources to take full advantage of multidisciplinary and translational research opportunities. This proposal addresses the stated training objectives at an individual level.  Glaucoma is a leading cause of blindness. Visual field assessment and optic nerve head imaging (confocal scanning laser tomography) are commonly used to diagnose the disease and monitor its progression, yet there is considerable controversy about how to interpret and make best use of this information. Currently, raw data from these observations are reduced to statistical indices that are meant to summarize clinically meaningful features and provide a basis for classifying test results as normal or not. Unfortunately, these indices may sacrifice other relevant features in the data for interpretability.  We will use mathematical modeling methods (polynomial modeling, spline fitting and wavelet analysis) to quantify patterns in visual field data and topographic images of the optic nerve head. We will use features derived from these modeling methods to apply novel pattern recognition techniques from computer and information sciences-decision trees and non-linear regression analysis-and then compare these techniques to current methods to identify glaucoma. By improving current methods of analysis we can provide a more quantitative basis for clinical decisions, and offer greater consistency and objectivity on data interpretation. The long-term objective of this proposal is to translate advances in computer and information sciences to the analysis of clinical outcomes research in glaucoma and other eye diseases. n/a",Spatial Modeling in Glaucoma,6863529,K23EY016225,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer assisted diagnosis', 'diagnosis design /evaluation', 'eye disorder diagnosis', 'glaucoma', 'glaucoma test', 'human data', 'image processing', 'mathematical model', 'model design /development', 'neuroimaging', 'optic nerve', 'patient oriented research', 'tomography', 'visual fields']",NEI,OHIO STATE UNIVERSITY,K23,2005,143096,0.06473823136925229
"Population analysis of shape representation in V4    DESCRIPTION (provided by applicant): The perception of shape is essential for object identification and visually guided action. The neural represenation of shape is mediated by a hierarchical system of brain areas known collectively as the ventral stream. Damage to ventral stream areas may lead to visual agnosias that can severely compromise quality of life. It is therefore important to achieve an understanding of how shape representation is generated. We will examine the neural representation of shape in V4, a brain region that is situated at an intermediate level on the ventral stream hierarchy. Our stategy will be to construct quantitative models of the relationship between neurophysiological activity and visual input at both the single cell and population levels. Our approach to constructing these models will be distinguished by the use of advanced non-linear statistical techniques, complex visual stimuli that simulates natural viewing conditions, and the use of multi-electrode arrays to record populations of neurons simultaneously. Interpretation and analysis of these models will allow us adress two specific questions: 1) what are the independent stimulus dimensions to which V4 neurons are tuned?; 2) how is the distributed activity of V4 cell populations combined to represent shape?           n/a",Population analysis of shape representation in V4,7483599,F32EY016941,"['Affect', 'Animals', 'Area', 'Attention', 'Behavior', 'Brain', 'Brain region', 'Cells', 'Classification', 'Code', 'Complex', 'Condition', 'Data', 'Devices', 'Dimensions', 'Discrimination', 'Electrodes', 'Environment', 'Evaluation', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Mediating', 'Modeling', 'Neurons', 'Perception', 'Performance', 'Population', 'Population Analysis', 'Positioning Attribute', 'Procedures', 'Property', 'Quality of life', 'Sampling', 'Shapes', 'Simulate', 'Stimulus', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'V4 neuron', 'Visual', 'Visual Agnosias', 'Visual system structure', 'Work', 'area V4', 'base', 'extrastriate visual cortex', 'neurophysiology', 'receptive field', 'relating to nervous system', 'response', 'success', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,F32,2008,50428,0.08632648048728998
"Population analysis of shape representation in V4    DESCRIPTION (provided by applicant): The perception of shape is essential for object identification and visually guided action. The neural represenation of shape is mediated by a hierarchical system of brain areas known collectively as the ventral stream. Damage to ventral stream areas may lead to visual agnosias that can severely compromise quality of life. It is therefore important to achieve an understanding of how shape representation is generated. We will examine the neural representation of shape in V4, a brain region that is situated at an intermediate level on the ventral stream hierarchy. Our stategy will be to construct quantitative models of the relationship between neurophysiological activity and visual input at both the single cell and population levels. Our approach to constructing these models will be distinguished by the use of advanced non-linear statistical techniques, complex visual stimuli that simulates natural viewing conditions, and the use of multi-electrode arrays to record populations of neurons simultaneously. Interpretation and analysis of these models will allow us adress two specific questions: 1) what are the independent stimulus dimensions to which V4 neurons are tuned?; 2) how is the distributed activity of V4 cell populations combined to represent shape?           n/a",Population analysis of shape representation in V4,7232722,F32EY016941,"['Affect', 'Animals', 'Area', 'Attention', 'Behavior', 'Brain', 'Brain region', 'Cells', 'Classification', 'Code', 'Complex', 'Condition', 'Data', 'Devices', 'Dimensions', 'Discrimination', 'Electrodes', 'Environment', 'Evaluation', 'Goals', 'Image', 'Imagery', 'Laboratories', 'Lead', 'Location', 'Machine Learning', 'Mediating', 'Modeling', 'Neurons', 'Perception', 'Performance', 'Population', 'Population Analysis', 'Positioning Attribute', 'Procedures', 'Property', 'Quality of life', 'Sampling', 'Shapes', 'Simulate', 'Stimulus', 'Stream', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'V4 neuron', 'Visual', 'Visual Agnosias', 'Visual system structure', 'Work', 'area V4', 'base', 'extrastriate visual cortex', 'neurophysiology', 'receptive field', 'relating to nervous system', 'response', 'success', 'visual search', 'visual stimulus']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,F32,2007,48796,0.08632648048728998
"The Functions and Mechanisms of Perceptual Learning Project Summary/Abstract: Research in perceptual learning has demonstrated a remarkable ability of training or practice to enhance perception in the adult human. The last thirty years have yielded many important findings about how people learn, what limits transfer, how generalization can be improved, how to model learning, and the nature of visual plasticity. At the same time, learning and transfer have been measured at a relatively coarse scale that leads to relatively inaccurate measures of learning in individuals, which could be very important to choosing adapted training options. Related issues of estimation have also limited the types of training protocols that have been studied. The objective of this research is to use innovative new adaptive performance assessment (based on Bayesian principles) to provide unbiased and high precision estimates of learning in individuals. We also use computational neural network models to generate predictions about more complicated training regimens that are then tested experimentally. We develop a framework for searching among these predictions computationally to identify better (optimized) training methods. The long-term goal is to develop efficient new assessments of learning and transfer and the modeling techniques that may then be applied to improve clinical applications, rehabilitation, and perceptual expertise identified as key aspects of the NEI mission. Project Narrative: Perceptual learning through training visual tasks can contribute to enhancing visual skills and may prove useful in remediation of some visual limitations. The current project seeks to understand perceptual learning and generalization using new rapid assessment methods, advanced statistical methods, and computational models of learning. The proposed program of model and test development and empirical testing will help to define a framework for more reliably measuring learning in individuals and predicting the efficacy of training regimens in normal adults, that could be the basis of parallel applications in rehabilitative or developmental training.",The Functions and Mechanisms of Perceptual Learning,10006883,R01EY017491,"['Adult', 'Bayesian Method', 'Bayesian Modeling', 'Behavior', 'Clinical Protocols', 'Computer Models', 'Data', 'Development', 'Goals', 'Grain', 'Individual', 'Individual Differences', 'Investigation', 'Learning', 'Literature', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Nature', 'Neural Network Simulation', 'Perception', 'Perceptual learning', 'Performance', 'Play', 'Protocols documentation', 'Psychological Transfer', 'Regimen', 'Rehabilitation therapy', 'Research', 'Research Design', 'Rewards', 'Specificity', 'Statistical Methods', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Translations', 'Visual', 'artificial neural network', 'base', 'clinical application', 'cognitive training', 'improved', 'innovation', 'model development', 'new technology', 'programs', 'relative effectiveness', 'remediation', 'skills', 'synergism', 'theories', 'visual plasticity']",NEI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2020,371418,0.18538427071565555
"The Functions and Mechanisms of Perceptual Learning Project Summary/Abstract: Research in perceptual learning has demonstrated a remarkable ability of training or practice to enhance perception in the adult human. The last thirty years have yielded many important findings about how people learn, what limits transfer, how generalization can be improved, how to model learning, and the nature of visual plasticity. At the same time, learning and transfer have been measured at a relatively coarse scale that leads to relatively inaccurate measures of learning in individuals, which could be very important to choosing adapted training options. Related issues of estimation have also limited the types of training protocols that have been studied. The objective of this research is to use innovative new adaptive performance assessment (based on Bayesian principles) to provide unbiased and high precision estimates of learning in individuals. We also use computational neural network models to generate predictions about more complicated training regimens that are then tested experimentally. We develop a framework for searching among these predictions computationally to identify better (optimized) training methods. The long-term goal is to develop efficient new assessments of learning and transfer and the modeling techniques that may then be applied to improve clinical applications, rehabilitation, and perceptual expertise identified as key aspects of the NEI mission. Project Narrative: Perceptual learning through training visual tasks can contribute to enhancing visual skills and may prove useful in remediation of some visual limitations. The current project seeks to understand perceptual learning and generalization using new rapid assessment methods, advanced statistical methods, and computational models of learning. The proposed program of model and test development and empirical testing will help to define a framework for more reliably measuring learning in individuals and predicting the efficacy of training regimens in normal adults, that could be the basis of parallel applications in rehabilitative or developmental training.",The Functions and Mechanisms of Perceptual Learning,9818191,R01EY017491,"['Adult', 'Bayesian Method', 'Bayesian Modeling', 'Behavior', 'Clinical Protocols', 'Computer Simulation', 'Data', 'Development', 'Goals', 'Grain', 'Individual', 'Individual Differences', 'Investigation', 'Learning', 'Literature', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Nature', 'Neural Network Simulation', 'Perception', 'Perceptual learning', 'Performance', 'Play', 'Protocols documentation', 'Psychological Transfer', 'Regimen', 'Rehabilitation therapy', 'Research', 'Research Design', 'Rewards', 'Specificity', 'Statistical Methods', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Translations', 'Visual', 'artificial neural network', 'base', 'clinical application', 'cognitive training', 'improved', 'innovation', 'model development', 'new technology', 'programs', 'relative effectiveness', 'remediation', 'skills', 'synergism', 'theories', 'visual plasticity']",NEI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2019,386970,0.18538427071565555
"The Functions and Mechanisms of Perceptual Learning    DESCRIPTION (provided by applicant): Deficits in discrimination and identification characterize a range of visual impairments. Training-based improvements in visual performance provide one possible non-invasive approach for remediation. Ideally, training for remediation will learn and transfer to a range of similar stimuli and tasks. However, improvements in perceptual task performance through perceptual learning or training, and the extent of transfer to related conditions, both depend critically upon the training protocol and the mixture of stimuli and tasks being trained. The current research uses computational models of visual perceptual learning, new and extended training and testing protocols, efficient estimation methods, and empirical tests. It aims to improve our understanding of the conditions for and the limits of transfer and specificity of perceptual learning. Past research has reported strong modulation of perceptual learning for multiple tasks/stimuli and a range of effects on transfer. Here, we propose new systematic investigations of both phenomena that cry out for an integrated theoretical account of these fundamental issues in perceptual learning. In Aim 1, we develop and test a theoretical framework to understand how practice on multiple stimuli or tasks interact in perceptual learning, in some cases eliminating learning, and in other cases supporting it. In Aim 2, we develop and test a theoretical framework to understand and predict the cases in which perceptual training transfers to other stimuli, tasks, and visual locations, and those where it does not. We extend a previous computational model of perceptual learning based on partially-supervised learning algorithms, to incorporate location-independent as well as location-specific visual representations. The goal of this research program is to develop the theories and practical implementation of perceptual learning in normal populations that could contribute to translational applications to developmental learning and to ameliorative training in populations with perceptual deficits. These aims are consistent with the goals of the NEI's National Plan for Eye and Vision Research.       PUBLIC HEALTH RELEVANCE: Perceptual learning through training visual tasks is one approach to remediation of some visual impairment and can contribute to development of visual skills. The current project seeks to understand the conditions for producing the best learning of multiple stimuli and tasks and for improving transfer of training to related stimuli and tasks. Through modeling learning for different training protocols, the proposed research program of model development and empirical testing aims to produce a framework for predicting the value of different training regimens in normal adults, and suggest applications in developmental and rehabilitative training.                  ",The Functions and Mechanisms of Perceptual Learning,8658078,R01EY017491,"['Accounting', 'Adult', 'Algorithms', 'Characteristics', 'Complex', 'Computer Simulation', 'Crying', 'Development', 'Discrimination', 'Effectiveness', 'Eye', 'Feedback', 'Goals', 'Human', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Location', 'Methods', 'Modeling', 'Noise', 'Pattern', 'Perceptual learning', 'Performance', 'Population', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Regimen', 'Rehabilitation therapy', 'Reporting', 'Research', 'Schedule', 'Specificity', 'Stimulus', 'System', 'Task Performances', 'Testing', 'Training', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'improved', 'information processing', 'interest', 'method development', 'model development', 'multitask', 'programs', 'public health relevance', 'remediation', 'research study', 'skills', 'theories', 'vision development', 'visual performance']",NEI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,379539,0.21581877197268498
"The Functions and Mechanisms of Perceptual Learning    DESCRIPTION (provided by applicant): Deficits in discrimination and identification characterize a range of visual impairments. Training-based improvements in visual performance provide one possible non-invasive approach for remediation. Ideally, training for remediation will learn and transfer to a range of similar stimuli and tasks. However, improvements in perceptual task performance through perceptual learning or training, and the extent of transfer to related conditions, both depend critically upon the training protocol and the mixture of stimuli and tasks being trained. The current research uses computational models of visual perceptual learning, new and extended training and testing protocols, efficient estimation methods, and empirical tests. It aims to improve our understanding of the conditions for and the limits of transfer and specificity of perceptual learning. Past research has reported strong modulation of perceptual learning for multiple tasks/stimuli and a range of effects on transfer. Here, we propose new systematic investigations of both phenomena that cry out for an integrated theoretical account of these fundamental issues in perceptual learning. In Aim 1, we develop and test a theoretical framework to understand how practice on multiple stimuli or tasks interact in perceptual learning, in some cases eliminating learning, and in other cases supporting it. In Aim 2, we develop and test a theoretical framework to understand and predict the cases in which perceptual training transfers to other stimuli, tasks, and visual locations, and those where it does not. We extend a previous computational model of perceptual learning based on partially-supervised learning algorithms, to incorporate location-independent as well as location-specific visual representations. The goal of this research program is to develop the theories and practical implementation of perceptual learning in normal populations that could contribute to translational applications to developmental learning and to ameliorative training in populations with perceptual deficits. These aims are consistent with the goals of the NEI's National Plan for Eye and Vision Research.       PUBLIC HEALTH RELEVANCE: Perceptual learning through training visual tasks is one approach to remediation of some visual impairment and can contribute to development of visual skills. The current project seeks to understand the conditions for producing the best learning of multiple stimuli and tasks and for improving transfer of training to related stimuli and tasks. Through modeling learning for different training protocols, the proposed research program of model development and empirical testing aims to produce a framework for predicting the value of different training regimens in normal adults, and suggest applications in developmental and rehabilitative training.                  ",The Functions and Mechanisms of Perceptual Learning,8458572,R01EY017491,"['Accounting', 'Adult', 'Algorithms', 'Characteristics', 'Complex', 'Computer Simulation', 'Crying', 'Development', 'Discrimination', 'Effectiveness', 'Eye', 'Feedback', 'Goals', 'Human', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Location', 'Methods', 'Modeling', 'Noise', 'Pattern', 'Perceptual learning', 'Performance', 'Population', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Regimen', 'Rehabilitation therapy', 'Reporting', 'Research', 'Schedule', 'Specificity', 'Stimulus', 'System', 'Task Performances', 'Testing', 'Training', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'improved', 'information processing', 'interest', 'method development', 'model development', 'multitask', 'programs', 'public health relevance', 'remediation', 'research study', 'skills', 'theories', 'vision development', 'visual performance']",NEI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,367921,0.21581877197268498
"The Functions and Mechanisms of Perceptual Learning    DESCRIPTION (provided by applicant): Deficits in discrimination and identification characterize a range of visual impairments. Training-based improvements in visual performance provide one possible non-invasive approach for remediation. Ideally, training for remediation will learn and transfer to a range of similar stimuli and tasks. However, improvements in perceptual task performance through perceptual learning or training, and the extent of transfer to related conditions, both depend critically upon the training protocol and the mixture of stimuli and tasks being trained. The current research uses computational models of visual perceptual learning, new and extended training and testing protocols, efficient estimation methods, and empirical tests. It aims to improve our understanding of the conditions for and the limits of transfer and specificity of perceptual learning. Past research has reported strong modulation of perceptual learning for multiple tasks/stimuli and a range of effects on transfer. Here, we propose new systematic investigations of both phenomena that cry out for an integrated theoretical account of these fundamental issues in perceptual learning. In Aim 1, we develop and test a theoretical framework to understand how practice on multiple stimuli or tasks interact in perceptual learning, in some cases eliminating learning, and in other cases supporting it. In Aim 2, we develop and test a theoretical framework to understand and predict the cases in which perceptual training transfers to other stimuli, tasks, and visual locations, and those where it does not. We extend a previous computational model of perceptual learning based on partially-supervised learning algorithms, to incorporate location-independent as well as location-specific visual representations. The goal of this research program is to develop the theories and practical implementation of perceptual learning in normal populations that could contribute to translational applications to developmental learning and to ameliorative training in populations with perceptual deficits. These aims are consistent with the goals of the NEI's National Plan for Eye and Vision Research.      PUBLIC HEALTH RELEVANCE: Perceptual learning through training visual tasks is one approach to remediation of some visual impairment and can contribute to development of visual skills. The current project seeks to understand the conditions for producing the best learning of multiple stimuli and tasks and for improving transfer of training to related stimuli and tasks. Through modeling learning for different training protocols, the proposed research program of model development and empirical testing aims to produce a framework for predicting the value of different training regimens in normal adults, and suggest applications in developmental and rehabilitative training.                    Perceptual learning through training visual tasks is one approach to remediation of some visual impairment and can contribute to development of visual skills. The current project seeks to understand the conditions for producing the best learning of multiple stimuli and tasks and for improving transfer of training to related stimuli and tasks. Through modeling learning for different training protocols, the proposed research program of model development and empirical testing aims to produce a framework for predicting the value of different training regimens in normal adults, and suggest applications in developmental and rehabilitative training.                  ",The Functions and Mechanisms of Perceptual Learning,8108502,R01EY017491,"['Accounting', 'Adult', 'Algorithms', 'Characteristics', 'Complex', 'Computer Simulation', 'Crying', 'Development', 'Discrimination', 'Effectiveness', 'Eye', 'Feedback', 'Goals', 'Human', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Location', 'Methods', 'Modeling', 'Noise', 'Pattern', 'Perceptual learning', 'Performance', 'Population', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Regimen', 'Rehabilitation therapy', 'Reporting', 'Research', 'Schedule', 'Specificity', 'Stimulus', 'System', 'Task Performances', 'Testing', 'Training', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'improved', 'information processing', 'interest', 'method development', 'model development', 'multitask', 'programs', 'remediation', 'research study', 'skills', 'theories', 'vision development', 'visual performance']",NEI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2011,398303,0.22445545129312336
"The Functions and Mechanisms of Perceptual Learning    DESCRIPTION (provided by applicant): Deficits in discrimination and identification characterize a range of visual impairments. Training-based improvements in visual performance provide one possible non-invasive approach for remediation. Ideally, training for remediation will learn and transfer to a range of similar stimuli and tasks. However, improvements in perceptual task performance through perceptual learning or training, and the extent of transfer to related conditions, both depend critically upon the training protocol and the mixture of stimuli and tasks being trained. The current research uses computational models of visual perceptual learning, new and extended training and testing protocols, efficient estimation methods, and empirical tests. It aims to improve our understanding of the conditions for and the limits of transfer and specificity of perceptual learning. Past research has reported strong modulation of perceptual learning for multiple tasks/stimuli and a range of effects on transfer. Here, we propose new systematic investigations of both phenomena that cry out for an integrated theoretical account of these fundamental issues in perceptual learning. In Aim 1, we develop and test a theoretical framework to understand how practice on multiple stimuli or tasks interact in perceptual learning, in some cases eliminating learning, and in other cases supporting it. In Aim 2, we develop and test a theoretical framework to understand and predict the cases in which perceptual training transfers to other stimuli, tasks, and visual locations, and those where it does not. We extend a previous computational model of perceptual learning based on partially-supervised learning algorithms, to incorporate location-independent as well as location-specific visual representations. The goal of this research program is to develop the theories and practical implementation of perceptual learning in normal populations that could contribute to translational applications to developmental learning and to ameliorative training in populations with perceptual deficits. These aims are consistent with the goals of the NEI's National Plan for Eye and Vision Research.      PUBLIC HEALTH RELEVANCE: Perceptual learning through training visual tasks is one approach to remediation of some visual impairment and can contribute to development of visual skills. The current project seeks to understand the conditions for producing the best learning of multiple stimuli and tasks and for improving transfer of training to related stimuli and tasks. Through modeling learning for different training protocols, the proposed research program of model development and empirical testing aims to produce a framework for predicting the value of different training regimens in normal adults, and suggest applications in developmental and rehabilitative training.                    Perceptual learning through training visual tasks is one approach to remediation of some visual impairment and can contribute to development of visual skills. The current project seeks to understand the conditions for producing the best learning of multiple stimuli and tasks and for improving transfer of training to related stimuli and tasks. Through modeling learning for different training protocols, the proposed research program of model development and empirical testing aims to produce a framework for predicting the value of different training regimens in normal adults, and suggest applications in developmental and rehabilitative training.",The Functions and Mechanisms of Perceptual Learning,8258711,R01EY017491,"['Accounting', 'Adult', 'Algorithms', 'Characteristics', 'Complex', 'Computer Simulation', 'Crying', 'Development', 'Discrimination', 'Effectiveness', 'Eye', 'Feedback', 'Goals', 'Human', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Location', 'Methods', 'Modeling', 'Noise', 'Pattern', 'Perceptual learning', 'Performance', 'Population', 'Process', 'Protocols documentation', 'Psychological Transfer', 'Regimen', 'Rehabilitation therapy', 'Reporting', 'Research', 'Schedule', 'Specificity', 'Stimulus', 'System', 'Task Performances', 'Testing', 'Training', 'Vision', 'Vision research', 'Visual', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'improved', 'information processing', 'interest', 'method development', 'model development', 'multitask', 'programs', 'public health relevance', 'remediation', 'research study', 'skills', 'theories', 'vision development', 'visual performance']",NEI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2012,387285,0.22445545129312336
"Predicting Human Olfactory Perception from Molecular Structure PROJECT SUMMARY Modern technology makes it possible to capture a visual scene as a photograph, alter it, send it to another country nearly instantaneously, and store it without concern for degradation. None of this is currently possible in olfaction. Although perfumers and flavorists are adept at mixing odorous molecules to produce a desired perceptual effect, the rules underlying this process are poorly understood at a quantitative level. Current methods for displaying odors to a subject are akin to requiring a Polaroid of every visual stimulus of interest. A more efficient method for probing the olfactory system would be to use a set of 'primary odors'—some limited number of odors from which all other complex odors could be reproduced by appropriate mixtures. Both auditory and visual stimuli have been digitized, and this will eventually be possible in olfaction as well. Predicting odor from chemical structure has been a problem in the field since its inception, but recent advances in machine learning algorithms have made great progress in analogous problems, such as facial recognition. The research proposed here will combine these machine learning techniques with high quality human psychophysics to understand how to predict the smell of a molecule or mixture of odorants, which will ultimately help improve our understanding of disease diagnosis using odors as well as eating-related health and illness. HEALTH RELEVANCE The sense of smell plays a critical role in preferences and aversions for specific foods. The proposed research will combine machine learning techniques with high quality human psychophysics to create a model that can predict the smell of odorous molecules. This model will allow us to describe and control odors, which will increase our understanding of food preference and eating-related health and wellness.",Predicting Human Olfactory Perception from Molecular Structure,9887973,R01DC017757,"['Algorithms', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Code', 'Collection', 'Color', 'Communities', 'Complex', 'Complex Mixtures', 'Country', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Eating', 'Enrollment', 'Face', 'Food', 'Food Preferences', 'Frequencies', 'Health', 'Human', 'Ligands', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Molecular Structure', 'Neurosciences', 'Non-linear Models', 'Numerical value', 'Odors', 'Olfactory Pathways', 'Perception', 'Play', 'Process', 'Psychophysics', 'Research', 'Research Personnel', 'Role', 'Smell Perception', 'Stimulus', 'Techniques', 'Technology', 'Training', 'Translating', 'Vision', 'Visual', 'Vocabulary', 'Work', 'auditory stimulus', 'base', 'computer monitor', 'disease diagnosis', 'experience', 'high dimensionality', 'improved', 'in silico', 'interest', 'machine learning algorithm', 'member', 'novel', 'physical property', 'predictive modeling', 'predictive test', 'preference', 'receptor', 'relating to nervous system', 'single molecule', 'visual stimulus']",NIDCD,MONELL CHEMICAL SENSES CENTER,R01,2020,496911,0.027134056868436948
"Diagnostic Innovations in Glaucoma: Clinical Electrophysiology    DESCRIPTION (provided by applicant): This application proposes to investigate the diagnostic precision for detecting glaucoma of clinical electrophysiological measurement (pattern electroretinogram, PERG; and multifocal visual evoked potentials, mfVEP), a technique identified as an important recent glaucoma- related development in eye research by the 2004 National Eye Institute (NEI) National Plan. Aim 1: Electrophysiological responses will be characterized in glaucoma, suspect and healthy eyes and the diagnostic accuracy of these commercially available techniques will be compared to current reference standards (evaluation of stereoscopic photographs of the optic disc and standard automated perimetry) and to recently developed diagnostic techniques including optical imaging of the optic disc and retinal nerve fiber layer (RNFL) (confocal scanning laser ophthalmoscopy, optical coherence tomography, and scanning laser polarimetry) and visual function-specific perimetry (short-wavelength automated perimetry and frequency doubling technology perimetry). Aim 2: Novel use of machine learning classifier techniques (e.g. relevance vector machines, support vector machines, mixture of Gaussian techniques, independent components analysis) will be applied to electrophysiological data to improve its diagnostic accuracy and data from different diagnostic techniques (named above) will be combined to improve overall diagnostic accuracy. Aim 3: Electrophysiological measurements will be validated as functional indicators of optic nerve damage by examining the relationship between electrophysiological abnormality and optic disc and RNFL damage in glaucoma and glaucoma suspect patients. 210 patients (105 glaucoma's, 105 glaucoma suspects) and 105 healthy participants will be enrolled and studied cross-sectionally. The specific aims of this proposal address the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Information about the relative usefulness of electrophysiological measurement, optical imaging techniques, and ganglion cell-specific perimetry for glaucoma detection is important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring. These studies will demonstrate the relative usefulness of electrophysiological measurement (pattern electroretinogram, PERG; multi-focal visual evoked potential, mfVEP) compared to optical imaging techniques (confocal scanning ophthalmoscopy, optical coherence tomography, scanning laser polarimetry) and ganglion cell-specific perimetry (short wavelength and frequency doubling perimetry) for glaucoma detection. The proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Findings will be important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring.                n/a",Diagnostic Innovations in Glaucoma: Clinical Electrophysiology,7452327,R21EY018190,"['Address', 'California', 'Caring', 'Clinical', 'Communities', 'Data', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electrophysiology (science)', 'Electroretinography', 'Enrollment', 'Evaluation', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Investigation', 'Lasers', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Names', 'National Eye Institute', 'Nerve Degeneration', 'Onset of illness', 'Ophthalmoscopy', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Pattern', 'Perimetry', 'Peripheral', 'Personal Satisfaction', 'Photography', 'Psychophysiology', 'Range', 'Reference Standards', 'Relative (related person)', 'Research', 'Retinal', 'Scanning', 'Scotoma', 'Sensitivity and Specificity', 'Severities', 'Standards of Weights and Measures', 'Structure', 'Suspect Glaucomas', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual Pathways', 'Visual evoked cortical potential', 'base', 'design', 'diagnostic accuracy', 'ganglion cell', 'improved', 'independent component analysis', 'innovation', 'novel', 'novel diagnostics', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'response', 'retinal nerve fiber layer', 'stereoscopic', 'vector']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2008,189263,0.1818194076420136
"Diagnostic Innovations in Glaucoma: Clinical Electrophysiology    DESCRIPTION (provided by applicant): This application proposes to investigate the diagnostic precision for detecting glaucoma of clinical electrophysiological measurement (pattern electroretinogram, PERG; and multifocal visual evoked potentials, mfVEP), a technique identified as an important recent glaucoma- related development in eye research by the 2004 National Eye Institute (NEI) National Plan. Aim 1: Electrophysiological responses will be characterized in glaucoma, suspect and healthy eyes and the diagnostic accuracy of these commercially available techniques will be compared to current reference standards (evaluation of stereoscopic photographs of the optic disc and standard automated perimetry) and to recently developed diagnostic techniques including optical imaging of the optic disc and retinal nerve fiber layer (RNFL) (confocal scanning laser ophthalmoscopy, optical coherence tomography, and scanning laser polarimetry) and visual function-specific perimetry (short-wavelength automated perimetry and frequency doubling technology perimetry). Aim 2: Novel use of machine learning classifier techniques (e.g. relevance vector machines, support vector machines, mixture of Gaussian techniques, independent components analysis) will be applied to electrophysiological data to improve its diagnostic accuracy and data from different diagnostic techniques (named above) will be combined to improve overall diagnostic accuracy. Aim 3: Electrophysiological measurements will be validated as functional indicators of optic nerve damage by examining the relationship between electrophysiological abnormality and optic disc and RNFL damage in glaucoma and glaucoma suspect patients. 210 patients (105 glaucoma's, 105 glaucoma suspects) and 105 healthy participants will be enrolled and studied cross-sectionally. The specific aims of this proposal address the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Information about the relative usefulness of electrophysiological measurement, optical imaging techniques, and ganglion cell-specific perimetry for glaucoma detection is important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring. These studies will demonstrate the relative usefulness of electrophysiological measurement (pattern electroretinogram, PERG; multi-focal visual evoked potential, mfVEP) compared to optical imaging techniques (confocal scanning ophthalmoscopy, optical coherence tomography, scanning laser polarimetry) and ganglion cell-specific perimetry (short wavelength and frequency doubling perimetry) for glaucoma detection. The proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset, determining functional correlates of optic nerve damage, and characterizing glaucomatous neurodegeneration within the visual pathways at structural and functional levels. Findings will be important to the clinical community for determining future evidence-based changes in standard of care for glaucoma diagnosis and monitoring.                n/a",Diagnostic Innovations in Glaucoma: Clinical Electrophysiology,7242398,R21EY018190,"['Address', 'California', 'Caring', 'Clinical', 'Communities', 'Data', 'Defect', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Disease', 'Electrophysiology (science)', 'Electroretinography', 'Enrollment', 'Evaluation', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Investigation', 'Lasers', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Monitor', 'Names', 'National Eye Institute', 'Nerve Degeneration', 'Onset of illness', 'Ophthalmoscopy', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Participant', 'Patients', 'Pattern', 'Perimetry', 'Peripheral', 'Personal Satisfaction', 'Photography', 'Psychophysiology', 'Range', 'Reference Standards', 'Relative (related person)', 'Research', 'Retinal', 'Scanning', 'Scotoma', 'Sensitivity and Specificity', 'Severities', 'Standards of Weights and Measures', 'Structure', 'Suspect Glaucomas', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual Pathways', 'Visual evoked cortical potential', 'base', 'design', 'diagnostic accuracy', 'ganglion cell', 'improved', 'independent component analysis', 'innovation', 'novel', 'novel diagnostics', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'response', 'retinal nerve fiber layer', 'stereoscopic', 'vector']",NEI,UNIVERSITY OF CALIFORNIA,R21,2007,218125,0.1818194076420136
"Understanding the mechanisms that control the dynamics of perceptual switches    DESCRIPTION (provided by applicant): When a static visual scene is viewed, different objects and organizations can spontaneously come to dominate visual awareness. These ""perceptual switches"" that activate alternative scene interpretations are important because they allow detection of behaviorally significant information that may not be predictable or initially salient and that may exist at any level of organization. The literature on binocular rivalry (a paradigm commonly used to study perceptual switches) suggests that perceptual switches are mediated by collective action of multi-stage neural competition involving component processes such as signal transduction, adaptation, inhibitory interactions, stochastic noise, non-linearity (e.g., a threshold), and response synchronization. Contemporary dynamic models provide a plausible computational framework for integrating these component processes. However, research to date has overlooked some key aspects of perceptual switches. Prominently, no attempts have been made to measure the component processes to determine how their actual (as opposed to hypothesized) properties predict the dynamics of perceptual switches. Without this knowledge, it is impossible to specify the sources of the substantial individual differences and plasticity observed in the dynamics of perceptual switches. Further, in spite of growing evidence that multi-level processes are involved, little data exist regarding how neural competition at multiple processing stages interactively controls perceptual switches. Our basic strategy will be to psychophysically and electrophysiologically measure the component processes operating at different processing stages, determine how each component process contributes to perceptual switches, and use this information to revise the current models. The advanced model will predict the dynamics of perceptual switches for each individual on the basis of his or her measured component processes. In this way, we will determine the unexplained sources of substantial variability in perceptual switches due to individual differences, plasticity, percept-to-percept variability, and intentional control. Finally, to begin to translate the basic research on perceptual switching to a broader understanding of mental health and visual attention, we will (1) use the model to trace the sources of unusual perceptual dynamics associated with some psychiatric disorders to specific component processes, and (2) determine how the component processes underlying perceptual switches and their intentional modulations are associated with voluntary attention abilities.  PUBLIC HEALTH RELEVANCE: Visual scenes often give rise to multiple interpretations; people function most effectively when they achieve a balance between the stability of a single interpretation and the flexibility to see alternative interpretations. Perceptual interpretations can be excessively unstable or excessively inflexible in a number of neurological and psychiatric disorders, including attention deficit disorder and bipolar disorder. The dynamics of these perceptual alternations will be rigorously examined using a binocular-rivalry paradigm together with psychophysical, computational modeling, and electrophysiological techniques to reveal the underlying neural mechanisms and how they differ as a function of the health status of the individual.          n/a",Understanding the mechanisms that control the dynamics of perceptual switches,7467158,R01EY018197,"['Accounting', 'Address', 'Affect', 'Anxiety', 'Attention', 'Attention Deficit Disorder', 'Attention deficit hyperactivity disorder', 'Awareness', 'Basic Science', 'Behavioral', 'Binocular rivalry', 'Biological Neural Networks', 'Bipolar Depression', 'Bipolar Disorder', 'Cesarean section', 'Characteristics', 'Complement', 'Complex', 'Computer Simulation', 'Data', 'Detection', 'Disease', 'Equilibrium', 'Event', 'Eye', 'Funding', 'Goals', 'Grouping', 'Health Status', 'Hour', 'Image', 'Incidence', 'Individual', 'Individual Differences', 'Intention', 'Knowledge', 'Laboratories', 'Literature', 'Location', 'Measurement', 'Measures', 'Mediating', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methods', 'Modeling', 'Neurologic', 'Noise', 'Numbers', 'Obsession', 'Operative Surgical Procedures', 'Paranoia', 'Participant', 'Pattern', 'Peripheral', 'Pliability', 'Principal Component Analysis', 'Process', 'Property', 'Psyche structure', 'Psychophysiology', 'Public Health', 'Public Health Applications Research', 'Rate', 'Relative (related person)', 'Research', 'Rest', 'Role', 'Screening procedure', 'Sensory', 'Signal Transduction', 'Simulate', 'Solutions', 'Source', 'Specific qualifier value', 'Speed', 'Staging', 'Stimulus', 'Stream', 'System', 'Techniques', 'Testing', 'Time', 'To specify', 'Translating', 'Variant', 'Visual', 'Visual attention', 'Visual evoked cortical potential', 'Weight', 'Work', 'base', 'computer framework', 'computerized', 'cost', 'day', 'experience', 'feeding', 'grasp', 'improved', 'neuromechanism', 'relating to nervous system', 'response', 'sample fixation', 'trait', 'vigilance']",NEI,NORTHWESTERN UNIVERSITY,R01,2008,333312,0.07615983336199172
"Shared and specific mechanisms of auditory and visual category learning PROJECT SUMMARY/ABSTRACT The ability to learn new perceptual categories enables some of the most complex human behaviors, from speech perception to visual object recognition. Current understanding of the mechanisms involved in perceptual category learning relies on the fundamental assumption that the processes underlying such learning are shared across the senses. However, the vast majority of this work has focused on the visual modality. As a consequence, the research regarding how humans learn to group complex auditory information into categories has relied greatly on conclusions from the research in the visual domain without testing this critical assumption. However, recent evidence from the attention literature suggests that even seemingly domain-general cognitive processes, such as working memory, are accomplished via sensory-biased regions in frontal cortex. The current investigation will directly compare the computational and neural mechanisms supporting auditory and visual category learning by training the same individuals on categories in both modalities while in an fMRI scanner. Aim #1 of this investigation will identify the shared and sensory-biased circuits supporting feedback processing during auditory and visual category learning. If the neural circuits supporting perceptual category learning are shared across the modalities, it is expected that similar regions will be recruited to a similar extent during feedback processing. If instead, the neural circuits are distinct for particular modalities, it is expected that sensory-biased regions will emerge as supporting category learning for auditory and visual modalities. Aim #2 will utilize advanced machine learning techniques (multivariate pattern classification and representational similarity analyses) to characterize the emergence of category-level neural representations over the course of learning. Aim #3 will identify the functional and structural connectivity of the circuits as they contribute to perceptual category learning. The proposed research will directly test the fundamental assumption about the nature of this complex problem that affects everyday behaviors. This research has the potential to impact understanding of cases where modality- specific learning abilities might be impaired, such as phonetic learning and language-related impairments in dyslexia, autism, and specific language impairment. The proposed research will provide the training foundation to support the PI’s long-term objective of developing theories of perceptual category learning that are constrained by neurobiology and behavior and will specify the behavioral, computational, and neural mechanisms of such learning. This project presents the opportunity to directly test a critical assumption underlying understanding of perceptual category learning. The proposed research will take place in an exceptional training environment and the PI will be mentored by a team of knowledgeable and accomplished scientists. The research will provide the PI with training in functional magnetic resonance experiment design and analysis which will prepare her well for a career as an independent scientist in computational cognitive neuroscience. PROJECT NARRATIVE The proposed research will contribute to fundamental knowledge about how seemingly general-purpose cognitive systems may demonstrate modality specificity. The goal of this investigation is to characterize the differences in cognitive processing during category learning when the information comes from the auditory or visual modalities. The findings from this work may inform mechanistic approaches to understanding modality- specific deficits in language-based disorders, such as dyslexia, autism, and specific language impairment.",Shared and specific mechanisms of auditory and visual category learning,10064815,F32DC018979,"['Affect', 'Area', 'Attention', 'Auditory', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Corpus striatum structure', 'Disease', 'Dyslexia', 'Environment', 'Esters', 'Feedback', 'Finches', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hobbies', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Mentors', 'Modality', 'Modeling', 'Nature', 'Neurobiology', 'Participant', 'Pattern', 'Process', 'Property', 'Research', 'Scientist', 'Sensory', 'Short-Term Memory', 'Specific qualifier value', 'Specificity', 'Speech', 'Speech Perception', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Training', 'Visual', 'Work', 'auditory stimulus', 'autism spectrum disorder', 'base', 'behavior measurement', 'career', 'cognitive neuroscience', 'cognitive process', 'cognitive system', 'design', 'experimental study', 'frontal lobe', 'individual variation', 'innovation', 'learning ability', 'neural circuit', 'neuromechanism', 'object recognition', 'programs', 'recruit', 'relating to nervous system', 'response', 'sound', 'specific language impairment', 'theories', 'visual learning']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F32,2020,64554,0.13393743388647797
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex. PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.",Representation of information across the human visual cortex,9542335,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Devices', 'Dimensions', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'area striata', 'artificial neural network', 'base', 'data modeling', 'design', 'exhaustion', 'experimental study', 'extrastriate visual cortex', 'high dimensionality', 'improved', 'innovation', 'insight', 'learning strategy', 'movie', 'novel', 'object recognition', 'object shape', 'public health relevance', 'receptive field', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2018,376543,0.23123829148298827
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex. PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.",Representation of information across the human visual cortex,9254553,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Device Designs', 'Dimensions', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'area V1', 'area striata', 'base', 'data modeling', 'design', 'exhaustion', 'experimental study', 'extrastriate visual cortex', 'high dimensionality', 'improved', 'innovation', 'insight', 'learning strategy', 'movie', 'novel', 'object recognition', 'object shape', 'public health relevance', 'receptive field', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2017,377994,0.23123829148298827
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex. PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.",Representation of information across the human visual cortex,9040948,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Health', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'abstracting', 'area V1', 'area striata', 'base', 'data modeling', 'design', 'extrastriate visual cortex', 'improved', 'innovation', 'insight', 'learning strategy', 'movie', 'novel', 'object recognition', 'object shape', 'receptive field', 'research study', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual process', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2016,379313,0.23123829148298827
"Representation of information across the human visual cortex ﻿    DESCRIPTION (provided by applicant): The human visual system is organized as a parallel, hierarchical network, and successive stages of visual processing appear to represent increasingly complicated aspects of shape-related and semantic information. However, the way that shape-related and semantic information is represented across much of the visual hierarchy is still poorly understood. The primary goal of this proposal is to understand how information about object shape and semantic category is represented explicitly across mid- and high-level visual areas. To address this important issue we propose to undertake a series of human functional MRI (fMRI) studies, using both synthetic and natural movies. Data will be analyzed by means of a powerful voxel-wise modeling (VM) approach that has been developed in my laboratory over the past several years. In Aim 1 we propose to measure human brain activity evoked by synthetic naturalistic movies, and to use VM to evaluate and compare several competing theories of shape representation across the entire visual cortex. In Aim 2 we propose to use VM to evaluate and compare competing theories of semantic representation. In Aim 3 we propose to use machine learning and and VM to discover new aspects of shape and semantic representation. These experiments will provide fundamental new insights about the representation of visual information across visual cortex.         PUBLIC HEALTH RELEVANCE: Disorders of central vision can severely affect quality of life and the design of treatments and devices for improving visual function will depend critically on understanding the organization of visual cortex. We propose to use functional MRI and sophisticated computational data analysis and modeling procedures to evaluate and compare multiple theories of visual function. The results will reveal how visual information is represented across the several dozen distinct functional areas that constitute human visual cortex.                ",Representation of information across the human visual cortex,8888120,R01EY019684,"['Address', 'Affect', 'Area', 'Award', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disease', 'Elements', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Human', 'Image', 'Individual', 'Laboratories', 'Link', 'Literature', 'Machine Learning', 'Maps', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Motion', 'Perception', 'Procedures', 'Quality of life', 'Semantics', 'Series', 'Shapes', 'Space Perception', 'Staging', 'Surface', 'System', 'Testing', 'Training', 'V2 neuron', 'V4 neuron', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'abstracting', 'area V1', 'area striata', 'base', 'data modeling', 'design', 'extrastriate visual cortex', 'improved', 'innovation', 'insight', 'movie', 'novel', 'object recognition', 'object shape', 'public health relevance', 'receptive field', 'research study', 'theories', 'therapy design', 'visual information', 'visual neuroscience', 'visual process', 'visual processing']",NEI,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2015,368851,0.23123829148298827
"Towards cortical visual prosthetics    Description (provided by applicant): Visual object recognition is crucial for most everyday tasks including face identification, reading and navigation. In spite of the massive increase in computational power over the last two decades, a 3-year-old still outperforms the most sophisticated algorithms even in simple recognition tasks. Understanding the computations performed by the human visual system to recognize objects will have profound implications not only to understand the functions (and malfunction) of the cerebral cortex but also for developing visual prosthetic devices for the visually impaired. We combine neurophysiology, electrical stimulation and tools from machine learning to further our understanding of the neuronal circuits, algorithms and computations performed by the human visual system to perform visual pattern recognition. In the vast majority of visually impaired or blind people, the problems originate at the level of the retina while the visual cortex remains unimpaired. Our proposal constitutes a proof- of-principle approach towards developing visual prosthetic devices that rely on electrical stimulation of visual cortex. The specific aims of this proposal are designed to test the possibility of decoding and recoding information in visual cortex: (1) Read-out of visual information from human visual cortex on line (2) Write-in of visual information in human visual cortex. We take advantage of a rare opportunity to study the human brain at high spatial and temporal resolution by studying patients who have electrodes implanted for clinical reasons. Our electrophysiological recordings provide us with a unique view of the human temporal lobe circuitry and allow us to test the feasibility of cortical visual prosthetics in behaving human subjects. PUBLIC HEALTH RELEVANCE: Towards cortical visual prosthetics one of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.           7. Project Narrative: Towards cortical visual prosthetics  One of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.",Towards cortical visual prosthetics,7903931,R21EY019710,"['3 year old', 'Action Potentials', 'Algorithms', 'Animals', 'Auditory', 'Brain', 'Categories', 'Cerebral cortex', 'Clinical', 'Code', 'Computer software', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Electric Stimulation', 'Electrodes', 'Epilepsy', 'Face', 'Goals', 'Human', 'Implanted Electrodes', 'Inferior', 'Limb structure', 'Macaca', 'Machine Learning', 'Methodology', 'Methods', 'Monkeys', 'Neurons', 'Output', 'Patients', 'Perception', 'Physiological', 'Prosthesis', 'Reading', 'Recording of previous events', 'Reporting', 'Research Personnel', 'Resolution', 'Retina', 'Sensory', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Visual Pattern Recognition', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Wireless Technology', 'Writing', 'base', 'brain machine interface', 'design', 'devices for the visually impaired', 'human data', 'human subject', 'improved', 'interest', 'neural prosthesis', 'neurophysiology', 'object recognition', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'retinal prosthesis', 'tool', 'vision development', 'visual information']",NEI,BOSTON CHILDREN'S HOSPITAL,R21,2010,212644,0.23625109851987341
"Towards cortical visual prosthetics    Description (provided by applicant): Visual object recognition is crucial for most everyday tasks including face identification, reading and navigation. In spite of the massive increase in computational power over the last two decades, a 3-year-old still outperforms the most sophisticated algorithms even in simple recognition tasks. Understanding the computations performed by the human visual system to recognize objects will have profound implications not only to understand the functions (and malfunction) of the cerebral cortex but also for developing visual prosthetic devices for the visually impaired. We combine neurophysiology, electrical stimulation and tools from machine learning to further our understanding of the neuronal circuits, algorithms and computations performed by the human visual system to perform visual pattern recognition. In the vast majority of visually impaired or blind people, the problems originate at the level of the retina while the visual cortex remains unimpaired. Our proposal constitutes a proof- of-principle approach towards developing visual prosthetic devices that rely on electrical stimulation of visual cortex. The specific aims of this proposal are designed to test the possibility of decoding and recoding information in visual cortex: (1) Read-out of visual information from human visual cortex on line (2) Write-in of visual information in human visual cortex. We take advantage of a rare opportunity to study the human brain at high spatial and temporal resolution by studying patients who have electrodes implanted for clinical reasons. Our electrophysiological recordings provide us with a unique view of the human temporal lobe circuitry and allow us to test the feasibility of cortical visual prosthetics in behaving human subjects. PUBLIC HEALTH RELEVANCE: Towards cortical visual prosthetics one of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.           7. Project Narrative: Towards cortical visual prosthetics  One of the key challenges for the visually impaired and blind people is the lack of visual object recognition capabilities. Visual recognition is crucial for most everyday tasks including navigation and face identification. Our proposal is a proof-of-principle approach towards the development of visual prosthetics devices based on electrical stimulation in visual cortex.",Towards cortical visual prosthetics,7701276,R21EY019710,"['3 year old', 'Action Potentials', 'Algorithms', 'Animals', 'Auditory', 'Brain', 'Categories', 'Cerebral cortex', 'Clinical', 'Code', 'Computer software', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Electric Stimulation', 'Electrodes', 'Epilepsy', 'Face', 'Goals', 'Human', 'Implanted Electrodes', 'Inferior', 'Limb structure', 'Macaca', 'Machine Learning', 'Methodology', 'Methods', 'Monkeys', 'Neurons', 'Output', 'Patients', 'Perception', 'Physiological', 'Prosthesis', 'Reading', 'Recording of previous events', 'Reporting', 'Research Personnel', 'Resolution', 'Retina', 'Sensory', 'Signal Transduction', 'Sorting - Cell Movement', 'Specificity', 'System', 'Temporal Lobe', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Visual Pattern Recognition', 'Visual impairment', 'Visual system structure', 'Visually Impaired Persons', 'Wireless Technology', 'Writing', 'base', 'brain machine interface', 'design', 'devices for the visually impaired', 'human data', 'human subject', 'improved', 'interest', 'neural prosthesis', 'neurophysiology', 'object recognition', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'retinal prosthesis', 'tool', 'vision development', 'visual information']",NEI,BOSTON CHILDREN'S HOSPITAL,R21,2009,247290,0.23625109851987341
"The gist of the space: A space centered approach to visual scene perception Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology. Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8788527,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2015,405502,0.10953677439296998
"The gist of the space: A space centered approach to visual scene perception  Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.  Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8599464,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2014,402592,0.10953677439296998
"The gist of the space: A space centered approach to visual scene perception  Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.  Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8416357,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2013,389686,0.10953677439296998
"The gist of the space: A space centered approach to visual scene perception  Project Summary  Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.  Narrative The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.",The gist of the space: A space centered approach to visual scene perception,8206519,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2012,409600,0.10953677439296998
"The gist of the space: A space centered approach to visual scene perception    DESCRIPTION (provided by applicant): Vision is central to our interactions with the world. Aside from recognizing faces and communicating with people, our daily activities are also organized around two fundamental tasks: recognizing our environment and navigating through it. The research program of Dr. Aude Oliva constitutes a new integration of behavioral, computational and cognitive neuroscience research on scene perception. A growing body of evidence from behavioral, imaging and computational investigations has shown that the perception of complex real-world scenes engages distinct cognitive and neural mechanisms from those engaged in object recognition. To date, however, this evidence has not resulted in a comprehensive framework for understanding scene processing.  Here, the PI proposes to test the novel hypothesis that real-world scene analysis is performed in a network of distinctive brain regions, with each region specialized in representing a different level of scene information. Since scenes are inherently three-dimensional spaces, she will show that the brain capitalizes on information uniquely derived from the space encompassed by a scene, rather than an exclusively object-based description. In other words, before knowing the ""gist of a scene,"" we analyze the ""gist of the space.""  Understanding the nature of the brain's representations of visual scenes is an enterprise that will push the development of fast and reliable rehabilitation strategies for individuals with visual and spatial impairments, and push forward the development of aid-based systems that rely on an understanding of the visual space. Real-world scene recognition is an unsolved mystery that will have implications for neuroscience, computational vision, artificial intelligence, robotics and psychology.      PUBLIC HEALTH RELEVANCE: The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.           The research program constitutes a new integration of computational and cognitive neuroscience research on scene and space perception, with the aim of unraveling how the understanding of visual environments (where we are, where to navigate) arises in the human brain.         ",The gist of the space: A space centered approach to visual scene perception,8039320,R01EY020484,"['Affect', 'Area', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Computers', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Image', 'Impairment', 'Individual', 'Investigation', 'Nature', 'Neurosciences Research', 'Pattern', 'Perception', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Research', 'Robotics', 'Scientist', 'Semantics', 'Space Perception', 'System', 'Testing', 'Vision', 'Visual', 'Visual Fields', 'Visuospatial', 'Work', 'base', 'cognitive neuroscience', 'computational neuroscience', 'interest', 'neuroimaging', 'neuromechanism', 'novel', 'object recognition', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'response', 'visual process', 'visual processing']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2011,404890,0.11986095200671151
"The role of short-term memory uncertainty in visual decision-making PROJECT SUMMARY/ABSTRACT The goal of this project is to gain a fundamental quantitative understanding of the mechanisms of visual short-term memory (VSTM) in health. VSTM is a central aspect of human cognition, allowing people to detect changes in the environment. Deficits in VSTM are found in many visual and neurological disorders, including visual neglect, parietal and frontal lobe damage, attention deficit/hyperactivity disorder, traumatic brain injury, and schizophrenia. A better characterization of VSTM may lead the way to better diagnosis and treatment of such deficits.  In its first period, this project has overturned established beliefs about the nature of the limitations of VSTM. The continuation of the project focuses on the richness of VSTM and in particular the hypothesis that VSTM contains a representation of uncertainty associated with a short-term memory. To test this hypothesis, the investigators use a set of novel behavioral tasks, some of which involve subjects directly reporting their confidence about a memory, while others are designed such that decision performance benefits from utilizing knowledge of VSTM uncertainty. In contrast to other work that uses stimuli such as line drawings or letters, all experiments in this project use simple, single-feature stimuli, allowing for both tight experimental control and precise mathematical modeling.  The project integrates mathematical modeling with the experiments in an essential way. The Ma laboratory is a leader in the large-scale testing of mathematical models of behavior, comparing them using state-of-the-art statistical techniques, and using the results to inform further experimental design. The models in this project are aimed at precisely characterizing the processes by which the brain arrives at a VSTM-based decision. One large category of models that will be tested is based on the notion that observers optimally or near-optimally combine VSTM information with prior and reward information to reach a decision. Beyond behavioral models, the project will use neural network modeling to address how neural circuits might implement the computations involved in the behavioral tasks of the project. Specifically, the investigators ask how the brain can incorporate knowledge of VSTM uncertainty without being explicitly trained on the correct value of uncertainty.  The broader impact of the project consists of connecting two traditionally disparate research areas, namely the study of VSTM and the study of decision-making. Besides potential clinical applications, the project will lead to a better basic understanding of how the brain manages to make good decisions in the face of great uncertainty. PROJECT NARRATIVE Deficits in visual short-term memory are found in many forms of brain damage and disease, including visual neglect, parietal and frontal lesions, attention deficit/hyperactivity disorder, and Alzheimer's disease. Here, we propose to better characterize, through experiment and theory, the behavioral and neural mechanisms underlying visual short-term memory, with the eventual goal of improving the diagnosis and treatment of these disorders.",The role of short-term memory uncertainty in visual decision-making,9554915,R01EY020958,"['Address', 'Alzheimer&apos', 's Disease', 'Area', 'Attention deficit hyperactivity disorder', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Behavioral Model', 'Belief', 'Biological', 'Biological Neural Networks', 'Brain', 'Brain Diseases', 'Brain Injuries', 'Categories', 'Cognition', 'Color', 'Data', 'Decision Making', 'Detection', 'Diagnosis', 'Disease', 'Environment', 'Experimental Designs', 'Generic Drugs', 'Goals', 'Grant', 'Health', 'Human', 'Incentives', 'Judgment', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Lesion', 'Letters', 'Maintenance', 'Measures', 'Memory', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Outcome', 'Parietal', 'Parietal Lobe', 'Performance', 'Probability', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Rewards', 'Role', 'Schizophrenia', 'Short-Term Memory', 'Stimulus', 'Techniques', 'Testing', 'Textbooks', 'Time', 'Training', 'Traumatic Brain Injury', 'Uncertainty', 'Vision Disorders', 'Visual', 'Work', 'base', 'clinical application', 'computer based statistical methods', 'data modeling', 'design', 'experimental study', 'frontal lobe', 'improved', 'logarithm', 'mathematical model', 'neglect', 'nervous system disorder', 'neural circuit', 'neuromechanism', 'novel', 'operation', 'recurrent neural network', 'relating to nervous system', 'theories']",NEI,NEW YORK UNIVERSITY,R01,2018,237795,0.0044830843173225875
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8895328,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'cognitive process', 'cognitive task', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2015,347803,0.2170819001980765
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8708870,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2014,348504,0.2170819001980765
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8515424,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2013,337678,0.2170819001980765
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.        This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8306867,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2012,355624,0.2170819001980765
"Neural and Behavioral Interactions Between Attention, Perception, and Learning    DESCRIPTION (provided by applicant): The overarching goal of this research is to characterize how perception and memory interact, in terms of both the learning mechanisms that help transform visual experience into memory, and the intentional mechanisms that regulate this transformation. The specific goal of this proposal is to test the hypothesis that incidental learning about statistical regularities in vision (visual statistical learning) is limited to selectively attend visual information, and that this behavioral interaction arises because of how selective attention modulates neural interactions between human visual and memory systems. We propose a two-stage framework in which selective attention to a high-level visual feature/category increases neural interactions between regions of occipital cortex that represent low-level features and the region of inferior temporal cortex (IT) that represents the attended feature/category, and in turn between this IT region and medial temporal lobe (MTL) sub regions involved in visual learning and memory. In addition to assessing how feature-based selective attention influences learning at a behavioral level, we will use functional magnetic resonance imaging to assess how attention influences evoked neural responses in task-relevant brain regions, as well as neural interactions between these regions in the background of ongoing tasks. We will develop an innovative approach for studying neural interactions in which evoked responses and global noise sources are scrubbed from the data and regional correlations are assessed in the residuals. This background connectivity approach provides a new way to study how intentional goals affect perception and learning. Aim 1 examines the first stage of our framework, testing: how selective attention modulates background connectivity between IT and occipital cortex, where in retinotopic visual cortex this modulation occurs, and how these changes are controlled by frontal and parietal cortex. Aim 2 examines the second stage of our framework, first establishing the role of the MTL in visual statistical learning, and then testing: how selective attention modulates interactions between IT and the MTL, where in cortical and hippocampal sub regions of the MTL this modulation occurs, and how these changes facilitate incidental learning about statistical regularities and later retrieval of this knowledge. In sum, we relate behavioral interactions between selective attention and learning to neural interactions between the mechanisms that represent visual features and those that learn about their relations. This proposal addresses several key issues in the field, including: how attention modulates the MTL, how feature-based attention is controlled, whether different neural mechanisms support rapid versus long-term visual learning, how tasks and goals are represented, and how attention and memory retrieval are related. This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery and rehabilitation of visual function following eye disease, injury, or brain damage.      PUBLIC HEALTH RELEVANCE: This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.           This research will improve our understanding of how humans learn from visual experience, and how visual processing is in turn influenced by learning. These advances will shed light on the plasticity that occurs during development and during the recovery from visual impairment caused by eye disease, injury, or brain damage. The behavioral tasks that we develop to enhance learning with attention will inform practices for rehabilitating visual function, and the methods that we develop to study neural interactions during tasks will lead to new approaches for diagnosing disorders of visual processing.         ","Neural and Behavioral Interactions Between Attention, Perception, and Learning",8162573,R01EY021755,"['Address', 'Affect', 'Architecture', 'Area', 'Attention', 'Behavioral', 'Brain', 'Brain Injuries', 'Brain region', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Data', 'Development', 'Diagnosis', 'Disease', 'Event', 'Exhibits', 'Eye diseases', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Injury', 'Knowledge', 'Lead', 'Learning', 'Light', 'Link', 'Machine Learning', 'Maps', 'Medial', 'Memory', 'Methods', 'Mind', 'Modeling', 'Nature', 'Neurosciences', 'Noise', 'Occipital lobe', 'Parietal', 'Parietal Lobe', 'Perception', 'Physiological', 'Positioning Attribute', 'Process', 'Property', 'Recovery', 'Rehabilitation therapy', 'Research', 'Residual state', 'Resolution', 'Rest', 'Retrieval', 'Role', 'Sensory Process', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Staging', 'Stimulus', 'Sum', 'Synapses', 'System', 'Temporal Lobe', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'cognitive neuroscience', 'experience', 'extrastriate visual cortex', 'frontal lobe', 'hippocampal subregions', 'improved', 'information processing', 'innovation', 'memory retrieval', 'neuroimaging', 'neuromechanism', 'novel strategies', 'relating to nervous system', 'response', 'retinotopic', 'selective attention', 'transmission process', 'visual information', 'visual learning', 'visual memory', 'visual process', 'visual processing', 'visual stimulus']",NEI,PRINCETON UNIVERSITY,R01,2011,362154,0.24186492466030263
"Predicting and Detecting Glaucomatous Progression Using Pattern Recognition    DESCRIPTION (provided by applicant): This project aims to improve glaucoma management by applying novel pattern recognition techniques to improve the accurate prediction and detection of glaucomatous progression. The premise is that complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and that advanced pattern recognition techniques can find and use that hidden information. The primary goals involve the use of mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1800 glaucomatous and healthy eyes, available as the result of long-term NIH funding. With the interdisciplinary team of glaucoma and pattern recognition experts we have assembled, with our extensive NIH-supported database of eyes, and with the knowledge we have acquired in the optimal use of pattern recognition methods from previous NIH support, we believe the proposed work can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs.      PUBLIC HEALTH RELEVANCE: The proposed project will develop and demonstrate the usefulness of pattern recognition techniques for predicting and detecting patterns of glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neurodegeneration within the visual pathways at structural and functional levels. The development/use of novel, empirical techniques for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.              The proposed project will develop and demonstrate the usefulness of pattern recognition techniques for predicting and detecting patterns of glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neurodegeneration within the visual pathways at structural and functional levels. The development/use of novel, empirical techniques for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.            ",Predicting and Detecting Glaucomatous Progression Using Pattern Recognition,8216617,R01EY022039,"['Address', 'Algorithms', 'California', 'Caring', 'Clinic', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Databases', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Eye', 'Frequencies', 'Funding', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Image', 'Imaging Device', 'Informatics', 'Knowledge', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Noise', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Perimetry', 'Physiologic Intraocular Pressure', 'Physiological', 'Provider', 'Scanning', 'Science', 'Series', 'Signal Transduction', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Translational Research', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Universities', 'Vision', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'clinical care', 'cost', 'design', 'heuristics', 'improved', 'independent component analysis', 'instrument', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'retinal nerve fiber layer', 'skills']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,386771,0.06634469893506166
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8731899,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2014,354773,0.201603351164548
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8535775,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2013,343780,0.201603351164548
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8535310,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2012,104373,0.201603351164548
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8312499,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'undergraduate student', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2012,357385,0.201603351164548
"CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes DESCRIPTION (provided by applicant): The complexity of natural images is potentially enormous: the number of possible images that can be described by a smallish (100 by 100 pixels) picture is practically infinite (10000256), more than all the images the human race has ever witnessed during its entire existence. How can any system process input data of this magnitude of dimensions and interpret/understand it in terms of the estimated 200,000 objects in the world, their spatial layouts, and scene structures? Yet, this is a task that human visual systems routinely perform in a fraction of a second. The secret must lie in the fact that natural images are highly redundant, living in a restricted space inside this universe of almost infinite possibilities, and that mammalian visual systems have discovered and exploited this fact. In particular, we conjecture that neurons and populations are tuned to the statistical structure of natural images, building on previous work showing, for example, that sparse coding ideas can help predict receptive field properties of 'simple cells' in the visual cortex. This proposal has three stages. Firstly, we will perform a statistical analysis of natural images to classify and model the types of visual patches that appear. This will result in a stimulus dictionary, which will be used as stimuli to investigate the tuning properties of neurons and neuronal populations, and a visual concept dictionary which will be used to make predictions for the tuning properties. Secondly, we will perform multielectrode neurophysiological investigation of the tuning properties of neurons, and neuron populations, at different levels of the visual cortex in response to the stimulus dictionary. Thirdly, we will perform data analysis to model the tuning properties of neurons and populations using a combination of model-driven, which assumes that neurons are tuned to statistical properties of images, and data-driven approaches which can be thought of as learning 'neural visual concepts' directly from the neuron's response to the stimuli. Our theoretical approach - for learning the stimuli dictionary, the visual concepts, and performing data analysis - is based on statistical and machine learning techniques. These assume a hierarchical compositional structure for the data which offers the possibility of taming the complexity of natural images and is also consistent with the known hierarchical structure of the visual cortex. Intellectual merit: This research will help understand the structure of natural images, determine models for the tuning properties of neurons in the visual cortex, and develop novel data analysis techniques. It has the potential to significantly advance our understanding of the statistical structures of natural images and the neural encoding of these structures, including the population level. This will lead to greater understanding of the visual cortex and also help the development of computer vision systems. Broader impacts: This project is interdisciplinary in nature and should have broad impact in multiple disciplines: neuroscience and biological vision, statistical neural data analysis, computer vision, and machine learning. Understanding neuronal properties in the visual cortex is a pre-requisite to the clinical enterprise of developing therapeutic methods and prosthetic devices for the visually impaired. The proposed research program will help facilitate a new graduate program in Computational and Cognitive Neuroscience at UCLA, an inter-college undergraduate minor in Neural Computation at CMU that the investigators are developing at their respective universities. The investigators also plan to organize workshops in NIPS, COSYNE, as well as to integrate their research into both undergraduate and graduate curriculum in their respective universities. This work will also affect undergraduate students at other colleges, by a summer undergraduate training program in Pittsburgh, another at CMU's Qatar campus. In addition, we will propose a workshop and summer school at IPAM (UCLA). We anticipate that this research will lead to invited lectures, peer reviewed publications and, if successful, will have national and international impact. The PIs have good track record in involving undergraduates, including women and minorities, in their NSF-sponsored research, and will continue to endeavor in the training of the next generation of computational neuroscientists. This project will lead to greater understanding of neural mechanisms and coding strategies in the primate  visual cortex. Such knowledge is fundamental to understanding human visual functions and is critical to the  clinical enterprise of developing better diagnostic tools, therapeutic methods, and prosthetic devices for the  visually impaired.",CRCNS: Neural Reprensentation of Hierarchical Visual Concepts in Natural Scenes,8255663,R01EY022247,"['Affect', 'Appearance', 'Biological', 'Cells', 'Clinical', 'Code', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Development', 'Diagnostic', 'Dictionary', 'Dimensions', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electrodes', 'Entropy', 'Graph', 'Human', 'Image', 'International', 'Intuition', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Letters', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Minor', 'Minority', 'Modeling', 'Nature', 'Neurons', 'Neurosciences', 'Noise', 'Pattern', 'Peer Review', 'Physiological', 'Population', 'Primates', 'Probability', 'Process', 'Property', 'Prosthesis', 'Publications', 'Qatar', 'Race', 'Research', 'Research Personnel', 'Sampling', 'Schools', 'Staging', 'Statistical Models', 'Stimulus', 'Structure', 'Students', 'System', 'Techniques', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Training', 'Training Programs', 'Universities', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Vocabulary', 'Woman', 'Work', 'base', 'cognitive neuroscience', 'college', 'computational neuroscience', 'design', 'devices for the visually impaired', 'isophosphamide mustard', 'lectures', 'neuromechanism', 'neurophysiology', 'next generation', 'novel', 'programs', 'receptive field', 'relating to nervous system', 'research study', 'response', 'statistics', 'tool', 'visual stimulus']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2011,372452,0.201603351164548
"Bioinformatics Approaches to Visual Disease Genetics     DESCRIPTION (provided by applicant): It is now recognized that many visual diseases are influenced by complex interactions between multiple different genetic variants. As a result, our ability to predict susceptibility to visual diseases will depend critically on the computational, mathematical and statistical modeling methods and software that are available for making sense of high-dimensional genetic data. We propose here a bioinformatics research project to develop network modeling approaches for identifying combinations of genetic biomarkers associated with visual disease endpoints. Our working hypothesis is that a systems-based bioinformatics approach using network modeling will play a very important role in confronting the complexity of the relationship between genomic variation and visual diseases. We will first develop and evaluate modeling methods to infer large-scale genetic interaction networks from genome-wide association studies (AIM 1). We will then apply the modeling methods developed in AIM 1 to the inference of genetic interaction networks from genome-wide association data in subjects with and without visual diseases (AIM 2). Next, we will utilize the inferred genetic interaction networks to guide the development of predictive genetic models of visual diseases (AIM 3). Finally, all network modeling methods will be released to the vision research community as part of a popular user-friendly, freely available and open-source software package (AIM 4). We anticipate that the network modeling methods and software developed and distributed as part of this project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for visual diseases.          The network modeling methods and software developed and distributed as part of this bioinformatics research project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for common diseases such as glaucoma and age-related macular degeneration.                ",Bioinformatics Approaches to Visual Disease Genetics,8698757,R01EY022300,"['Age related macular degeneration', 'Algorithms', 'Biochemical Pathway', 'Bioinformatics', 'Clinical', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Disease', 'Entropy', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Structures', 'Genetic screening method', 'Genomics', 'Genotype', 'Glaucoma', 'Goals', 'Hereditary Disease', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Network-based', 'Ontology', 'Pathway Analysis', 'Phenotype', 'Play', 'Predisposition', 'Research Project Grants', 'Risk', 'Role', 'Simulate', 'Single Nucleotide Polymorphism', 'Statistical Models', 'System', 'Time', 'Variant', 'Vision research', 'Visual', 'Work', 'base', 'database of Genotypes and Phenotypes', 'genetic analysis', 'genetic variant', 'genome wide association study', 'mathematical model', 'network models', 'open source', 'predictive modeling', 'protein protein interaction', 'software development', 'tool', 'user-friendly']",NEI,DARTMOUTH COLLEGE,R01,2014,155520,0.21431427561166191
"Bioinformatics Approaches to Visual Disease Genetics     DESCRIPTION (provided by applicant): It is now recognized that many visual diseases are influenced by complex interactions between multiple different genetic variants. As a result, our ability to predict susceptibility to visual diseases will depend critically on the computational, mathematical and statistical modeling methods and software that are available for making sense of high-dimensional genetic data. We propose here a bioinformatics research project to develop network modeling approaches for identifying combinations of genetic biomarkers associated with visual disease endpoints. Our working hypothesis is that a systems-based bioinformatics approach using network modeling will play a very important role in confronting the complexity of the relationship between genomic variation and visual diseases. We will first develop and evaluate modeling methods to infer large-scale genetic interaction networks from genome-wide association studies (AIM 1). We will then apply the modeling methods developed in AIM 1 to the inference of genetic interaction networks from genome-wide association data in subjects with and without visual diseases (AIM 2). Next, we will utilize the inferred genetic interaction networks to guide the development of predictive genetic models of visual diseases (AIM 3). Finally, all network modeling methods will be released to the vision research community as part of a popular user-friendly, freely available and open-source software package (AIM 4). We anticipate that the network modeling methods and software developed and distributed as part of this project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for visual diseases.          The network modeling methods and software developed and distributed as part of this bioinformatics research project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for common diseases such as glaucoma and age-related macular degeneration.                ",Bioinformatics Approaches to Visual Disease Genetics,8514000,R01EY022300,"['Age related macular degeneration', 'Algorithms', 'Biochemical Pathway', 'Bioinformatics', 'Clinical', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Disease', 'Entropy', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Structures', 'Genetic screening method', 'Genomics', 'Genotype', 'Glaucoma', 'Goals', 'Hereditary Disease', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Network-based', 'Ontology', 'Pathway Analysis', 'Phenotype', 'Play', 'Predisposition', 'Research Project Grants', 'Risk', 'Role', 'Simulate', 'Single Nucleotide Polymorphism', 'Statistical Models', 'System', 'Time', 'Variant', 'Vision research', 'Visual', 'Work', 'base', 'database of Genotypes and Phenotypes', 'genetic analysis', 'genetic variant', 'genome wide association study', 'mathematical model', 'network models', 'open source', 'predictive modeling', 'protein protein interaction', 'software development', 'tool', 'user-friendly']",NEI,DARTMOUTH COLLEGE,R01,2013,307800,0.21431427561166191
"Bioinformatics Approaches to Visual Disease Genetics     DESCRIPTION (provided by applicant): It is now recognized that many visual diseases are influenced by complex interactions between multiple different genetic variants. As a result, our ability to predict susceptibility to visual diseases will depend critically on the computational, mathematical and statistical modeling methods and software that are available for making sense of high-dimensional genetic data. We propose here a bioinformatics research project to develop network modeling approaches for identifying combinations of genetic biomarkers associated with visual disease endpoints. Our working hypothesis is that a systems-based bioinformatics approach using network modeling will play a very important role in confronting the complexity of the relationship between genomic variation and visual diseases. We will first develop and evaluate modeling methods to infer large-scale genetic interaction networks from genome-wide association studies (AIM 1). We will then apply the modeling methods developed in AIM 1 to the inference of genetic interaction networks from genome-wide association data in subjects with and without visual diseases (AIM 2). Next, we will utilize the inferred genetic interaction networks to guide the development of predictive genetic models of visual diseases (AIM 3). Finally, all network modeling methods will be released to the vision research community as part of a popular user-friendly, freely available and open-source software package (AIM 4). We anticipate that the network modeling methods and software developed and distributed as part of this project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for visual diseases.        PUBLIC HEALTH RELEVANCE: The network modeling methods and software developed and distributed as part of this bioinformatics research project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for common diseases such as glaucoma and age-related macular degeneration.                  The network modeling methods and software developed and distributed as part of this bioinformatics research project will play an important role in the development of the genetic tests that will be necessary to identify those at risk for common diseases such as glaucoma and age-related macular degeneration.                ",Bioinformatics Approaches to Visual Disease Genetics,8264613,R01EY022300,"['Age related macular degeneration', 'Algorithms', 'Biochemical Pathway', 'Bioinformatics', 'Biological Markers', 'Clinical', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Data', 'Development', 'Disease', 'Entropy', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Structures', 'Genetic screening method', 'Genomics', 'Genotype', 'Glaucoma', 'Goals', 'Hereditary Disease', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Network-based', 'Ontology', 'Pathway Analysis', 'Phenotype', 'Play', 'Predisposition', 'Research Project Grants', 'Risk', 'Role', 'Simulate', 'Single Nucleotide Polymorphism', 'Statistical Models', 'System', 'Time', 'Variant', 'Vision research', 'Visual', 'Work', 'base', 'database of Genotypes and Phenotypes', 'genetic analysis', 'genetic variant', 'genome wide association study', 'mathematical model', 'network models', 'open source', 'predictive modeling', 'protein protein interaction', 'software development', 'tool', 'user-friendly']",NEI,DARTMOUTH COLLEGE,R01,2012,322000,0.19192261664072255
"The neural representation and transformation of color in human visual cortex     DESCRIPTION (provided by applicant): The representation of any stimulus can be seen as a unique and distributed pattern of activity in a large population of neurons. These neural representations are thought to undergo a series of transformations across processing stages in visual cortex, and to depend on behavioral demands. The nature of these transformations reveals important insights into the computational mechanisms underlying the formation of behaviorally meaningful neural representations from incoming sensory signals. In this proposal, the focus is on measuring the neural representations and characterizing the transformations for a specific visual modality: color. The representation of color takes on many different forms. For example, humans discriminate between many thousands of hues but use only a handful of discrete color categories. This makes color an ideal candidate to investigate distributed neural representations.  The novel empirical and theoretical approaches in the current proposal aim to significantly advance understanding of 1) how the human visual system represents color, 2) how this distributed neural representation is transformed across the hierarchy of visual cortical areas 3) the dependence of these representations on behavioral demands, and 4) the dependence on context. Aim 1 experiments will test the hypothesis that the neural representation of color is transformed as chromatic signals ascend the visual system. Neural color spaces will be derived from functional magnetic resonance imaging (fMRI) measurements, using novel experimental protocols and multivariate data analysis techniques. These neural color spaces will be compared with perceptual color spaces derived from psychophysical measurements of color discrimination and categorization. Aim 1 experiments will also test the hypothesis that neural representations of color depend on behavioral demands. The proposed experiments will distinguish between two specific computational hypotheses: 1) that neural color spaces change for different behavioral tasks, indicating a change in the underlying selectivity and tuning of the neurons, versus 2) a (possibly selective) increase in response gain, with no evidence for a change in the color space. Aim 2 experiments will test the hypothesize that changes in color perception, due to a dramatic visual illusion, are correlated with corresponding shifts in the underlying neural representation, and that the extent of the shift in the neural representation varies between visual areas, depending on the neural color space in each visual area.  Ultimately, color provides a model for more complex neural representations (e.g., those underlying face and object recognition, control of movement, etc.) and the findings will provide general insights about distributed neural processes and representations. Consequently, the proposed research will provide information about how the brain transforms an incoming set of signals (of any modality) into a set of meaningful representations that subserve a multitude of tasks.        PUBLIC HEALTH RELEVANCE: The current proposal builds on previous work to study how the brain represents visual information, the computations the brain performs to transform representations of visual information, and the relationship between neural activity and visual perception. Consequently, the outlined approach will be of great benefit in understanding amblyopia, low vision, and aperceptive visual agnosias, as the methods developed in the proposal can be used to characterize distributed neural representations of other stimulus features besides color including, for example, contrast, orientation, depth, motion, etc. In addition, these methods for characterizing large-scale, distributed neural representations, non-invasively in the human brain, will be helpful for evaluating the efficacy of any therapy for visio restoration, whether it be a therapy for cortical visual deficits in amblyopia or a retinal prostheis for degenerative retinal diseases.                  The current proposal builds on previous work to study how the brain represents visual information, the computations the brain performs to transform representations of visual information, and the relationship between neural activity and visual perception. Consequently, the outlined approach will be of great benefit in understanding amblyopia, low vision, and aperceptive visual agnosias, as the methods developed in the proposal can be used to characterize distributed neural representations of other stimulus features besides color including, for example, contrast, orientation, depth, motion, etc. In addition, these methods for characterizing large-scale, distributed neural representations, non-invasively in the human brain, will be helpful for evaluating the efficacy of any therapy for visio restoration, whether it be a therapy for cortical visual deficits in amblyopia or a retinal prostheis for degenerative retinal diseases.                ",The neural representation and transformation of color in human visual cortex,8273521,R01EY022398,"['3-Dimensional', 'Amblyopia', 'Appearance', 'Area', 'Behavioral', 'Biological Models', 'Brain', 'Cognitive', 'Color', 'Color Perception', 'Complex', 'Computer Simulation', 'Data Analyses', 'Dependence', 'Discrimination', 'Elements', 'Face', 'Functional Magnetic Resonance Imaging', 'Human', 'Illusions', 'Linear Regressions', 'Measurement', 'Measures', 'Methods', 'Modality', 'Modeling', 'Motion', 'Motor', 'Movement', 'Nature', 'Neurons', 'Pattern', 'Population', 'Positioning Attribute', 'Principal Component Analysis', 'Process', 'Protocols documentation', 'Psychophysiology', 'Research', 'Retinal', 'Retinal Cone', 'Retinal Diseases', 'Sensory', 'Series', 'Signal Transduction', 'Staging', 'Stimulus', 'Sum', 'Techniques', 'Testing', 'Translations', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual Illusions', 'Visual Perception', 'Visual impairment', 'Visual system structure', 'Weight', 'Work', 'base', 'color category', 'experience', 'extrastriate visual cortex', 'insight', 'neural patterning', 'novel', 'object recognition', 'relating to nervous system', 'research study', 'response', 'restoration', 'sensory stimulus', 'vector', 'visual information']",NEI,NEW YORK UNIVERSITY,R01,2012,385000,0.038841737014945685
"Function and circuitry of adaptive inhibition in the retina Studies of the visual system face a number of challenges, two of which are the intricacy of the cell types and synaptic connections that comprise the nervous system, and the complexity of the computational processes that underlie vision. Although the retina is one of the most characterized and well understood neural circuits of the visual system, it nonetheless has a great diversity of cell types, connections and computations. The normal function of the retina is to convey information about natural visual scenes, which have complex spatial and temporal structure. The processing of natural scenes has the greatest relevance towards a fundamental understanding retinal function, and the greatest clinical relevance. Yet most studies of retinal visual processing and circuitry focus on responses to simple artificial stimuli rarely encountered normally, such as flashing spots, drifting stripes and flickering checkerboards. With respect to retinal cell types greatest diversity lies in a class of inhibitory interneurons known as amacrine cells. These cells make extensive lateral and feedback connections, and although they form stereotyped connections between each other, excitatory bipolar cells, and ganglion cells that transit signals in the optic nerve, the functional effects of nearly all of these cell types are poorly understood. This proposal aims towards a direct characterization of the functional effects of amacrine cells under ethologically relevant stimuli, including natural scenes. We combine approaches of perturbation and recording using electrical and optical methods as well as computational modeling to characterize the specific contributions of amacrine cells to stimuli that include the representation of moving objects. We take advantage of recently developed computational approaches that can simultaneously capture the retinal response to a broad range of stimuli including natural scenes, capture a wide range of phenomena previously characterized only with artificial stimuli, and that have internal units highly correlated with retinal interneurons. Our goals are to 1) Create a quantitative understanding of the functional contributions of a class of sustained amacrine cells in the salamander retina for specific stimuli including those that represent moving objects and natural scenes, and test hypotheses related to dynamic effects on visual sensitivity and sensory features generated by those amacrine cells 2) Use molecularly defined amacrine cells in the mouse to quantitatively characterize the functional contribution of specific amacrine cell types to specific stimuli including artificial moving objects and natural scenes. These studies create a new way to generate and test hypotheses related to the quantitative effect of any interneuron on retinal output under any visual stimulus. Understanding how retinal circuitry creates visual processing under natural scenes is critical to our understanding of retinal mechanisms and diseases involving the degeneration of the retinal circuitry. In addition, the computational descriptions of retinal responses will be directly useful in the design of electronic retinal prosthesis systems. The retina is a complex network of many cell types, including the most diverse but poorlyunderstood class of cells, amacrine cells. By understanding how inhibitory neurons change neural processing in the retina under natural visual scenes, we can begin to address how these cells and their connections degenerate during retinal diseases, an essential step in designing treatments for these diseases. Furthermore, by creating accurate computational models of the retinal response to natural scenes, this research will be immediately applicable to electronic retinal prosthesis systems that aim to restore vision in cases of photoreceptor degeneration.",Function and circuitry of adaptive inhibition in the retina,9892016,R01EY022933,"['Address', 'Amacrine Cells', 'Archives', 'Cells', 'Complex', 'Computer Models', 'Data', 'Disease', 'Electrophysiology (science)', 'Face', 'Feedback', 'Future', 'Goals', 'Injections', 'Interneurons', 'Lateral', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Mus', 'Nervous system structure', 'Neural Network Simulation', 'Neurons', 'Optic Nerve', 'Optical Methods', 'Output', 'Pathway interactions', 'Periodicity', 'Population', 'Process', 'Property', 'Research', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Salamander', 'Sensory', 'Signal Transduction', 'Spottings', 'Stereotyping', 'Stimulus', 'Structure', 'Synapses', 'System', 'Techniques', 'Testing', 'Theoretical Studies', 'Time', 'Vision', 'Visual', 'Visual system structure', 'biological systems', 'cell type', 'clinically relevant', 'computerized tools', 'computing resources', 'connectome', 'convolutional neural network', 'design', 'experimental study', 'extracellular', 'ganglion cell', 'inhibitory neuron', 'interest', 'neural circuit', 'novel strategies', 'photoreceptor degeneration', 'predicting response', 'receptive field', 'relating to nervous system', 'response', 'retinal prosthesis', 'therapy design', 'tool', 'visual processing', 'visual stimulus']",NEI,STANFORD UNIVERSITY,R01,2020,392194,0.12180359320152952
"Function and circuitry of adaptive inhibition in the retina Studies of the visual system face a number of challenges, two of which are the intricacy of the cell types and synaptic connections that comprise the nervous system, and the complexity of the computational processes that underlie vision. Although the retina is one of the most characterized and well understood neural circuits of the visual system, it nonetheless has a great diversity of cell types, connections and computations. The normal function of the retina is to convey information about natural visual scenes, which have complex spatial and temporal structure. The processing of natural scenes has the greatest relevance towards a fundamental understanding retinal function, and the greatest clinical relevance. Yet most studies of retinal visual processing and circuitry focus on responses to simple artificial stimuli rarely encountered normally, such as flashing spots, drifting stripes and flickering checkerboards. With respect to retinal cell types greatest diversity lies in a class of inhibitory interneurons known as amacrine cells. These cells make extensive lateral and feedback connections, and although they form stereotyped connections between each other, excitatory bipolar cells, and ganglion cells that transit signals in the optic nerve, the functional effects of nearly all of these cell types are poorly understood. This proposal aims towards a direct characterization of the functional effects of amacrine cells under ethologically relevant stimuli, including natural scenes. We combine approaches of perturbation and recording using electrical and optical methods as well as computational modeling to characterize the specific contributions of amacrine cells to stimuli that include the representation of moving objects. We take advantage of recently developed computational approaches that can simultaneously capture the retinal response to a broad range of stimuli including natural scenes, capture a wide range of phenomena previously characterized only with artificial stimuli, and that have internal units highly correlated with retinal interneurons. Our goals are to 1) Create a quantitative understanding of the functional contributions of a class of sustained amacrine cells in the salamander retina for specific stimuli including those that represent moving objects and natural scenes, and test hypotheses related to dynamic effects on visual sensitivity and sensory features generated by those amacrine cells 2) Use molecularly defined amacrine cells in the mouse to quantitatively characterize the functional contribution of specific amacrine cell types to specific stimuli including artificial moving objects and natural scenes. These studies create a new way to generate and test hypotheses related to the quantitative effect of any interneuron on retinal output under any visual stimulus. Understanding how retinal circuitry creates visual processing under natural scenes is critical to our understanding of retinal mechanisms and diseases involving the degeneration of the retinal circuitry. In addition, the computational descriptions of retinal responses will be directly useful in the design of electronic retinal prosthesis systems. The retina is a complex network of many cell types, including the most diverse but poorlyunderstood class of cells, amacrine cells. By understanding how inhibitory neurons change neural processing in the retina under natural visual scenes, we can begin to address how these cells and their connections degenerate during retinal diseases, an essential step in designing treatments for these diseases. Furthermore, by creating accurate computational models of the retinal response to natural scenes, this research will be immediately applicable to electronic retinal prosthesis systems that aim to restore vision in cases of photoreceptor degeneration.",Function and circuitry of adaptive inhibition in the retina,9740980,R01EY022933,"['Address', 'Amacrine Cells', 'Archives', 'Cells', 'Complex', 'Computer Simulation', 'Data', 'Disease', 'Electrophysiology (science)', 'Face', 'Feedback', 'Future', 'Goals', 'Injections', 'Interneurons', 'Lateral', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Mus', 'Nervous system structure', 'Neural Network Simulation', 'Neurons', 'Optic Nerve', 'Optical Methods', 'Output', 'Pathway interactions', 'Periodicity', 'Population', 'Process', 'Property', 'Research', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Salamander', 'Sensory', 'Signal Transduction', 'Spottings', 'Stereotyping', 'Stimulus', 'Structure', 'Synapses', 'System', 'Techniques', 'Testing', 'Theoretical Studies', 'Time', 'Vision', 'Visual', 'Visual system structure', 'biological systems', 'cell type', 'clinically relevant', 'computerized tools', 'computing resources', 'connectome', 'convolutional neural network', 'design', 'experimental study', 'extracellular', 'ganglion cell', 'inhibitory neuron', 'interest', 'neural circuit', 'novel strategies', 'photoreceptor degeneration', 'predicting response', 'receptive field', 'relating to nervous system', 'response', 'retinal prosthesis', 'therapy design', 'tool', 'visual processing', 'visual stimulus']",NEI,STANFORD UNIVERSITY,R01,2019,392194,0.12180359320152952
"Visual Summary-Statistic Processing in Infancy     DESCRIPTION (provided by applicant): Part of the NICHD's mission is to support basic research in human development. The Developmental Cognitive Psychology, Behavioral Neuroscience, and Psychobiology program supports research to identify links between the developing brain and the environment. The proposed research has been designed to help us understand how the visual environment shapes infants' use of summary statistics to describe the things they see. A growing body of research suggests that adults summarize a great deal of visual information by describing the world with texture-like measurements - instead of measuring exactly what we saw and where we saw it, we often pool information together over large areas by measuring how simple features co-occur and forgetting about exactly where they came from. For some tasks, these kinds of descriptions are useful. In other cases, like recognizing a single object in clutter, they don't work well at all. Understanding the limits of these summary statistic descriptions of our visual world has given us insights into why adults sometimes find visual search difficult (Rosenholtz et al., 2012), why it's hard to recognize single objects in clutter (Balas et al., 2009), and may help us understand conditions like amblyopia or macular degeneration, where we think these kinds of summaries may be nearly all the visual system has to work with. In these studies, we will work with infants and adults to understand how summary-statistic descriptions are shaped by the visual environment. We will use computer graphics techniques to create artificial textures that are matched to natural textures using a model of the early visual system. Our goal is to determine how different artificial textures need to be from natural textures for infants to tell them apart. By using a computer graphics model, we can carefully control what information is available to tell the images apart, which will help us understand what measurements contribute to infants' summary-statistic descriptions as they get older. Further, we plan to measure how well infants can tell real textures apart from artificial ones by measuring how their brain responds to those images. We will use EEG to measure how the brain responds to different kinds of natural and artificial textures. Different neural response reflect different kinds of processing in the brain, and we plan to use the location and the timing of the differences we see in infants' brains to help us understand how summary statistics are applied. These studies support the NICHD's mission and will help us understand the perceptual difficulties that some children and adults have due to visual impairments that force summary statistics to be used all the time.         PUBLIC HEALTH RELEVANCE: The human visual system summarizes a great deal of what we see by measuring what we saw, but forgetting exactly where we saw it. This strategy is good for recognizing textures like wood or stone, but makes it difficult to recognize individual objects that have lots of clutter around them. We plan to study how infants recognize textures so we can understand how their visual system learns to summarize information this way, which will help us, understand some visual impairment that result from the visual system being forced to use summaries like this all the time.            ",Visual Summary-Statistic Processing in Infancy,8687212,R15EY024375,"['Address', 'Adherence', 'Adult', 'Affect', 'Age', 'Algorithms', 'Amblyopia', 'Appearance', 'Area', 'Basic Science', 'Behavior', 'Behavioral', 'Behavioral Paradigm', 'Biological Models', 'Brain', 'Calculi', 'Characteristics', 'Child', 'Childhood', 'Cognitive Science', 'Complement', 'Computer Graphics', 'Computer Simulation', 'Crowding', 'Data', 'Development', 'Discrimination', 'Elderly', 'Electroencephalography', 'Environment', 'Event-Related Potentials', 'Exhibits', 'Exposure to', 'Face', 'Goals', 'Human', 'Human Development', 'Image', 'Individual', 'Infant', 'Learning', 'Life', 'Link', 'Location', 'Machine Learning', 'Macular degeneration', 'Measurement', 'Measures', 'Methods', 'Mission', 'Modeling', 'Nature', 'Neurophysiology - biologic function', 'Neurosciences', 'Paired Comparison', 'Parents', 'Participant', 'Pattern', 'Pattern Recognition', 'Performance', 'Play', 'Process', 'Race', 'Relative (related person)', 'Research', 'Research Support', 'Role', 'Shapes', 'Signal Transduction', 'Stimulus', 'Techniques', 'Testing', 'Texture', 'Time', 'To specify', 'Variant', 'Visual', 'Visual Psychophysics', 'Visual impairment', 'Visual system structure', 'Vocabulary', 'Wood material', 'Work', 'base', 'design', 'deviant', 'experience', 'forgetting', 'infancy', 'insight', 'preference', 'programs', 'psychobiology', 'public health relevance', 'relating to nervous system', 'response', 'shape analysis', 'spatial integration', 'statistics', 'vision development', 'visual information', 'visual process', 'visual processing', 'visual search']",NEI,NORTH DAKOTA STATE UNIVERSITY,R15,2014,408066,0.11038992388321808
"Learning and updating internal visual models ﻿    DESCRIPTION (provided by applicant): In line with the strategic plan of the NEI, this project is focused on filling a profound gap in our understanding of neural mechanisms of visual perception. Specifically, we aim to understand how the adaptation of visual cortical circuits contributes to perception. Adaptation is a ubiquitous process by which neural processing and perception are dramatically influenced by recent visual inputs. However, the functional purpose of adaptation is poorly understood. Based on preliminary data, this project tests the hypothesis that visual adaptation instantiates a form of predictive coding, which is used to make unexpected events salient. We posit that cortical circuits learn the statistical structure of visua input in a manner that extends beyond previous fatigue- based descriptions of adaptation effects. This learning is used to discount expected features and signal novel ones. Our project will test this hypothesis through the collaborative effort of three investigators with expertise in human EEG, animal neurophysiology, and computational modeling. Aim 1 will assess the ability of cortical circuits to adapt to temporal sequences of input and to signal deviations from expected sequences. Aim 2 will evaluate the effect of stimulus uncertainty on adaptation and responses to novel events. Aim 3 will determine how adaptation dynamics and responses to novel stimuli are influenced by the temporal constancy of stimulus statistics. Each of these aims involves an experimental manipulation that yields distinct behavior from fatigue- based and predictive coding mechanisms. Thus, together our aims will provide a robust test of our core hypothesis, and provide a much richer understanding of the adaptive properties of cortical circuits. Results from our project will contribute to answering one of the continuing puzzles in visual research, which is to understand the functional purpose of adaptive mechanisms in visual perception. PUBLIC HEALTH RELEVANCE: . This research is relevant to public health because it aims to uncover the function of visual adaptation, a fundamental aspect of visual perception. This work is thus essential to the mission of NEI because it will provide a more detailed understanding of how visual cortical circuits underlie visual perception, which is necessary for developing treatment strategies for individuals with visual processing deficits and for the development of effective prosthetic devices.",Learning and updating internal visual models,9334881,R01EY024858,"['Affect', 'Animals', 'Area', 'Autistic Disorder', 'Behavior', 'Biological', 'Brain', 'Code', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Disease', 'Electroencephalography', 'Elements', 'Environment', 'Event', 'Fatigue', 'Goals', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Machine Learning', 'Mission', 'Modeling', 'Monkeys', 'Neurons', 'Pattern', 'Perception', 'Process', 'Property', 'Prosthesis', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Scheme', 'Schizophrenia', 'Sensory', 'Signal Transduction', 'Stimulus', 'Strategic Planning', 'Structure', 'Testing', 'Time', 'Uncertainty', 'Update', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Work', 'area V4', 'area striata', 'awake', 'base', 'brain machine interface', 'cognitive neuroscience', 'computational neuroscience', 'design', 'discount', 'expectation', 'extrastriate visual cortex', 'human subject', 'improved', 'neuromechanism', 'neurophysiology', 'novel', 'phenomenological models', 'prevent', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'treatment strategy', 'visual adaptation', 'visual processing']",NEI,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2017,447745,0.2326373435728169
"Learning and updating internal visual models ﻿    DESCRIPTION (provided by applicant): In line with the strategic plan of the NEI, this project is focused on filling a profound gap in our understanding of neural mechanisms of visual perception. Specifically, we aim to understand how the adaptation of visual cortical circuits contributes to perception. Adaptation is a ubiquitous process by which neural processing and perception are dramatically influenced by recent visual inputs. However, the functional purpose of adaptation is poorly understood. Based on preliminary data, this project tests the hypothesis that visual adaptation instantiates a form of predictive coding, which is used to make unexpected events salient. We posit that cortical circuits learn the statistical structure of visua input in a manner that extends beyond previous fatigue- based descriptions of adaptation effects. This learning is used to discount expected features and signal novel ones. Our project will test this hypothesis through the collaborative effort of three investigators with expertise in human EEG, animal neurophysiology, and computational modeling. Aim 1 will assess the ability of cortical circuits to adapt to temporal sequences of input and to signal deviations from expected sequences. Aim 2 will evaluate the effect of stimulus uncertainty on adaptation and responses to novel events. Aim 3 will determine how adaptation dynamics and responses to novel stimuli are influenced by the temporal constancy of stimulus statistics. Each of these aims involves an experimental manipulation that yields distinct behavior from fatigue- based and predictive coding mechanisms. Thus, together our aims will provide a robust test of our core hypothesis, and provide a much richer understanding of the adaptive properties of cortical circuits. Results from our project will contribute to answering one of the continuing puzzles in visual research, which is to understand the functional purpose of adaptive mechanisms in visual perception. PUBLIC HEALTH RELEVANCE: . This research is relevant to public health because it aims to uncover the function of visual adaptation, a fundamental aspect of visual perception. This work is thus essential to the mission of NEI because it will provide a more detailed understanding of how visual cortical circuits underlie visual perception, which is necessary for developing treatment strategies for individuals with visual processing deficits and for the development of effective prosthetic devices.",Learning and updating internal visual models,9147600,R01EY024858,"['Affect', 'Animals', 'Area', 'Autistic Disorder', 'Behavior', 'Biological', 'Brain', 'Code', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Disease', 'Electroencephalography', 'Elements', 'Environment', 'Event', 'Fatigue', 'Goals', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Machine Learning', 'Mission', 'Modeling', 'Monkeys', 'Neurons', 'Pattern', 'Perception', 'Process', 'Property', 'Prosthesis', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Scheme', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Stimulus', 'Strategic Planning', 'Structure', 'Testing', 'Time', 'Uncertainty', 'Update', 'Visual', 'Visual Cortex', 'Visual Perception', 'Work', 'area V4', 'area striata', 'awake', 'base', 'brain machine interface', 'cognitive neuroscience', 'computational neuroscience', 'design', 'discount', 'expectation', 'extrastriate visual cortex', 'human subject', 'improved', 'meetings', 'neuromechanism', 'neurophysiology', 'novel', 'phenomenological models', 'prevent', 'relating to nervous system', 'response', 'statistics', 'treatment strategy', 'visual adaptation', 'visual process', 'visual processing']",NEI,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2016,561513,0.2326373435728169
"Learning and updating internal visual models ﻿    DESCRIPTION (provided by applicant): In line with the strategic plan of the NEI, this project is focused on filling a profound gap in our understanding of neural mechanisms of visual perception. Specifically, we aim to understand how the adaptation of visual cortical circuits contributes to perception. Adaptation is a ubiquitous process by which neural processing and perception are dramatically influenced by recent visual inputs. However, the functional purpose of adaptation is poorly understood. Based on preliminary data, this project tests the hypothesis that visual adaptation instantiates a form of predictive coding, which is used to make unexpected events salient. We posit that cortical circuits learn the statistical structure of visua input in a manner that extends beyond previous fatigue- based descriptions of adaptation effects. This learning is used to discount expected features and signal novel ones. Our project will test this hypothesis through the collaborative effort of three investigators with expertise in human EEG, animal neurophysiology, and computational modeling. Aim 1 will assess the ability of cortical circuits to adapt to temporal sequences of input and to signal deviations from expected sequences. Aim 2 will evaluate the effect of stimulus uncertainty on adaptation and responses to novel events. Aim 3 will determine how adaptation dynamics and responses to novel stimuli are influenced by the temporal constancy of stimulus statistics. Each of these aims involves an experimental manipulation that yields distinct behavior from fatigue- based and predictive coding mechanisms. Thus, together our aims will provide a robust test of our core hypothesis, and provide a much richer understanding of the adaptive properties of cortical circuits. Results from our project will contribute to answering one of the continuing puzzles in visual research, which is to understand the functional purpose of adaptive mechanisms in visual perception.         PUBLIC HEALTH RELEVANCE: . This research is relevant to public health because it aims to uncover the function of visual adaptation, a fundamental aspect of visual perception. This work is thus essential to the mission of NEI because it will provide a more detailed understanding of how visual cortical circuits underlie visual perception, which is necessary for developing treatment strategies for individuals with visual processing deficits and for the development of effective prosthetic devices.            ",Learning and updating internal visual models,8990935,R01EY024858,"['Affect', 'Animals', 'Area', 'Autistic Disorder', 'Behavior', 'Biological', 'Brain', 'Code', 'Computer Simulation', 'Data', 'Detection', 'Development', 'Disease', 'Electroencephalography', 'Elements', 'Environment', 'Event', 'Fatigue', 'Goals', 'Health', 'Human', 'Individual', 'Investigation', 'Knowledge', 'Learning', 'Machine Learning', 'Mission', 'Modeling', 'Monkeys', 'Neurons', 'Pattern', 'Perception', 'Process', 'Property', 'Prosthesis', 'Public Health', 'Recording of previous events', 'Research', 'Research Personnel', 'Scheme', 'Schizophrenia', 'Sensory', 'Sensory Process', 'Signal Transduction', 'Stimulus', 'Strategic Planning', 'Structure', 'Testing', 'Time', 'Uncertainty', 'Update', 'Visual', 'Visual Cortex', 'Visual Perception', 'Work', 'area V4', 'area striata', 'awake', 'base', 'brain machine interface', 'cognitive neuroscience', 'computational neuroscience', 'design', 'discount', 'expectation', 'extrastriate visual cortex', 'human subject', 'improved', 'meetings', 'neuromechanism', 'neurophysiology', 'novel', 'phenomenological models', 'prevent', 'public health relevance', 'relating to nervous system', 'response', 'statistics', 'treatment strategy', 'visual adaptation', 'visual process', 'visual processing']",NEI,"ALBERT EINSTEIN COLLEGE OF MEDICINE, INC",R01,2015,575253,0.2326373435728169
"Neural coding of interneuron populations in the retina Abstract The vertebrate retina translates visual images into electrical signals in the optic nerve, initiating the basis of all visual perception. This process is accomplished by dozens of diverse types of interneurons, each of which comprises a population of many thousands of cells. Each of these populations cover the visual field, acting together to process different aspects of visual images. Although many informative studies of retinal neural function have used single cell recordings, understanding the coordinated actions of many cells requires the recording and analysis of cell populations. This proposal focuses on amacrine cells, a diverse population of inhibitory interneurons. In particular we study wide-field amacrine cells, a prominent class of cells that make long distance connections across the retina, acting to combine visual signals from distant locations in the image. We have little information assigning computations to specific cells of this type. Using genetically identified populations of wide-field amacrine cells in the mouse retina, we will record neural activity from these populations optically, along with simultaneously recording electrically from populations of retinal ganglion cells. Neural responses to complex stimuli including natural scenes will be interpreted using advanced computational models. The primary goals of these studies are to 1) perform the first population scale measurements of sparse wide-field amacrine cells, in particular to measure how their selectivity for visual features varies dynamically during natural scenes, 2) Analyze the neural code of these cells under natural scenes using state-of-the-art computational models that can capture retinal responses to arbitrarily complex stimuli, 3) Test the hypothesis that sparse wide-field amacrine cells perform similar computations on different channels of information, acting to remove correlations from the ganglion cell population during natural scenes. These results will have immediate applicability to the emerging field of retinal prostheses, as is used to treat prevalent diseases such as age-related macular degeneration and retinitis pigmentosa by replacing the function of the damaged retina with a high resolution electronic circuit. Measurements of the retinal neural code and the computations that are performed will be directly useful for incorporation into retinal prosthesis systems. Program Director/Principal Investigator (Last, First, Middle): Baccus, Stephen A. The retina is a complex network of many cell types, including the most diverse but poorly understood class of cells, inhibitory neurons. By understanding how inhibitory neurons represent visual information, we can begin to address how these cells and their connections degenerate during retinal diseases, an essential step in designing treatments for these diseases. Furthermore, by capturing the responses of these neurons under natural visual stimuli with accurate computational models, this research will be immediately applicable to electronic retinal prosthesis systems that aim to restore vision in cases of photoreceptor degeneration.",Neural coding of interneuron populations in the retina,10052264,R01EY025087,"['Address', 'Age related macular degeneration', 'Amacrine Cells', 'Anatomy', 'Cells', 'Code', 'Complex', 'Computer Models', 'Disease', 'Distant', 'Eye Movements', 'Goals', 'Image', 'Inner Plexiform Layer', 'Interneurons', 'Location', 'Measurement', 'Measures', 'Modeling', 'Molecular', 'Motion', 'Mus', 'Neural Network Simulation', 'Neural Retina', 'Neurons', 'Neurophysiology - biologic function', 'Optic Nerve', 'Optics', 'Pharmacogenetics', 'Photoreceptors', 'Population', 'Population Heterogeneity', 'Principal Investigator', 'Process', 'Research', 'Resolution', 'Retina', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Retinitis Pigmentosa', 'Saccades', 'Signal Transduction', 'Stimulus', 'System', 'Testing', 'Translating', 'Vision', 'Visual', 'Visual Fields', 'Visual Perception', 'calcium indicator', 'cell type', 'comparative', 'convolutional neural network', 'ganglion cell', 'individual response', 'inhibitory neuron', 'object motion', 'optical imaging', 'photoreceptor degeneration', 'presynaptic', 'programs', 'relating to nervous system', 'response', 'retinal damage', 'retinal prosthesis', 'sample fixation', 'therapy design', 'visual information', 'visual stimulus']",NEI,STANFORD UNIVERSITY,R01,2020,385215,0.19166082636066634
"Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing ﻿    DESCRIPTION (provided by applicant): The long-term goal of this research is to understand how the brain decides where we look in the real world. Many factors influence our eye movements (saccades). For instance, we are more likely to look at salient objects (i.e. those that are conspicuous), such as a bright red balloon in a blue sky. We are also more likely to look at goal-dependent objects (i.e. those that share features with our goals), such as a yellow object when searching for a banana. For several decades, researchers in computer vision have been developing models based on these factors to predict the locations to which we move our eyes. Researchers in neurobiology have also been studying saccade selection, and have suggested the frontal eye field (FEF) plays a large role, as the FEF encodes both visual features and eye movements. But because the FEF encodes both visual features and saccades, it is very difficult to parse FEF activity during natural viewing. For this reason, past experiments have primarily investigated the FEF using simple, constrained tasks with artificial stimuli. In this project, I wil use images of natural scenes, which better approximate the complexity of the real world. I will record with extracellular electrodes from the FEF of awake, behaving rhesus monkeys, while they view natural scenes. In order to determine the FEF's role in the decision of where to saccade next in natural scenes, I will investigate how the FEF encodes visual features that predict saccades. In my two aims, I will test how the FEF encodes salience (Aim 1) and goal-dependence (Aim 2). I will build a model that explains neural activity using visual features (salience and goal-dependence) along with eye movements, which are a confounding source of neural activity. This model will take advantage of computer vision and machine learning algorithms in order to look at the effects of large numbers of correlates and visual features in these natural scenes. The neural data analysis methods developed for these aims will allow researchers that study many brain areas to more easily use natural scenes. Additionally, understanding how the brain chooses where to saccade in natural scenes have important consequences for neurologic and psychiatric health and disease. Several diseases including schizophrenia, autism, and Parkinson's impair the choice of saccades. A better understanding of the link between visual features, eye movements, and FEF activity promises to increase understanding of these diseases and allow the development of novel diagnostic tools. PUBLIC HEALTH RELEVANCE: This research aims to understand how the frontal eye field cortex helps determine where we look. In particular, it will investigate how the frontal eye field cortex encodes visual stimuli that drive eye movements, such as salient and important objects. Eye movement decisions are impaired in many diseases, including schizophrenia, autism, and Parkinson's, and this research could help lead to a greater understanding of these diseases and the development of novel diagnostic tools.",Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing,9266417,F31EY025532,"['Affect', 'Algorithms', 'Area', 'Autistic Disorder', 'Banana', 'Behavior', 'Brain', 'Brain region', 'Complex', 'Computer Vision Systems', 'Crowding', 'Data', 'Data Analyses', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Goals', 'Health', 'Image', 'Impairment', 'Lead', 'Link', 'Location', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Neurobiology', 'Neurologic', 'Neurons', 'Parkinson Disease', 'Play', 'Research', 'Research Personnel', 'Role', 'Running', 'Saccades', 'Schizophrenia', 'Site', 'Source', 'Stimulus', 'Testing', 'Visual', 'Visual Pathways', 'Visual attention', 'Work', 'awake', 'base', 'design', 'experience', 'experimental study', 'extracellular', 'frontal eye fields', 'nervous system disorder', 'neural model', 'neuromechanism', 'novel diagnostics', 'public health relevance', 'receptive field', 'relating to nervous system', 'response', 'tool', 'undergraduate student', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY AT CHICAGO,F31,2017,35657,0.07136671550572339
"Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing ﻿    DESCRIPTION (provided by applicant): The long-term goal of this research is to understand how the brain decides where we look in the real world. Many factors influence our eye movements (saccades). For instance, we are more likely to look at salient objects (i.e. those that are conspicuous), such as a bright red balloon in a blue sky. We are also more likely to look at goal-dependent objects (i.e. those that share features with our goals), such as a yellow object when searching for a banana. For several decades, researchers in computer vision have been developing models based on these factors to predict the locations to which we move our eyes. Researchers in neurobiology have also been studying saccade selection, and have suggested the frontal eye field (FEF) plays a large role, as the FEF encodes both visual features and eye movements. But because the FEF encodes both visual features and saccades, it is very difficult to parse FEF activity during natural viewing. For this reason, past experiments have primarily investigated the FEF using simple, constrained tasks with artificial stimuli. In this project, I wil use images of natural scenes, which better approximate the complexity of the real world. I will record with extracellular electrodes from the FEF of awake, behaving rhesus monkeys, while they view natural scenes. In order to determine the FEF's role in the decision of where to saccade next in natural scenes, I will investigate how the FEF encodes visual features that predict saccades. In my two aims, I will test how the FEF encodes salience (Aim 1) and goal-dependence (Aim 2). I will build a model that explains neural activity using visual features (salience and goal-dependence) along with eye movements, which are a confounding source of neural activity. This model will take advantage of computer vision and machine learning algorithms in order to look at the effects of large numbers of correlates and visual features in these natural scenes. The neural data analysis methods developed for these aims will allow researchers that study many brain areas to more easily use natural scenes. Additionally, understanding how the brain chooses where to saccade in natural scenes have important consequences for neurologic and psychiatric health and disease. Several diseases including schizophrenia, autism, and Parkinson's impair the choice of saccades. A better understanding of the link between visual features, eye movements, and FEF activity promises to increase understanding of these diseases and allow the development of novel diagnostic tools.         PUBLIC HEALTH RELEVANCE: This research aims to understand how the frontal eye field cortex helps determine where we look. In particular, it will investigate how the frontal eye field cortex encodes visual stimuli that drive eye movements, such as salient and important objects. Eye movement decisions are impaired in many diseases, including schizophrenia, autism, and Parkinson's, and this research could help lead to a greater understanding of these diseases and the development of novel diagnostic tools.                ",Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing,9087008,F31EY025532,"['Affect', 'Algorithms', 'Area', 'Autistic Disorder', 'Banana', 'Behavior', 'Brain', 'Brain region', 'Complex', 'Computer Vision Systems', 'Crowding', 'Data', 'Data Analyses', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Goals', 'Health', 'Image', 'Lead', 'Link', 'Location', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Neurobiology', 'Neurologic', 'Neurons', 'Parkinson Disease', 'Play', 'Research', 'Research Personnel', 'Role', 'Running', 'Saccades', 'Schizophrenia', 'Site', 'Source', 'Stimulus', 'Testing', 'Visual', 'Visual Pathways', 'Visual attention', 'Work', 'awake', 'base', 'design', 'experience', 'extracellular', 'frontal eye fields', 'nervous system disorder', 'neural model', 'neuromechanism', 'novel diagnostics', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'tool', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY AT CHICAGO,F31,2016,37176,0.07136671550572339
"Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing ﻿    DESCRIPTION (provided by applicant): The long-term goal of this research is to understand how the brain decides where we look in the real world. Many factors influence our eye movements (saccades). For instance, we are more likely to look at salient objects (i.e. those that are conspicuous), such as a bright red balloon in a blue sky. We are also more likely to look at goal-dependent objects (i.e. those that share features with our goals), such as a yellow object when searching for a banana. For several decades, researchers in computer vision have been developing models based on these factors to predict the locations to which we move our eyes. Researchers in neurobiology have also been studying saccade selection, and have suggested the frontal eye field (FEF) plays a large role, as the FEF encodes both visual features and eye movements. But because the FEF encodes both visual features and saccades, it is very difficult to parse FEF activity during natural viewing. For this reason, past experiments have primarily investigated the FEF using simple, constrained tasks with artificial stimuli. In this project, I wil use images of natural scenes, which better approximate the complexity of the real world. I will record with extracellular electrodes from the FEF of awake, behaving rhesus monkeys, while they view natural scenes. In order to determine the FEF's role in the decision of where to saccade next in natural scenes, I will investigate how the FEF encodes visual features that predict saccades. In my two aims, I will test how the FEF encodes salience (Aim 1) and goal-dependence (Aim 2). I will build a model that explains neural activity using visual features (salience and goal-dependence) along with eye movements, which are a confounding source of neural activity. This model will take advantage of computer vision and machine learning algorithms in order to look at the effects of large numbers of correlates and visual features in these natural scenes. The neural data analysis methods developed for these aims will allow researchers that study many brain areas to more easily use natural scenes. Additionally, understanding how the brain chooses where to saccade in natural scenes have important consequences for neurologic and psychiatric health and disease. Several diseases including schizophrenia, autism, and Parkinson's impair the choice of saccades. A better understanding of the link between visual features, eye movements, and FEF activity promises to increase understanding of these diseases and allow the development of novel diagnostic tools.         PUBLIC HEALTH RELEVANCE: This research aims to understand how the frontal eye field cortex helps determine where we look. In particular, it will investigate how the frontal eye field cortex encodes visual stimuli that drive eye movements, such as salient and important objects. Eye movement decisions are impaired in many diseases, including schizophrenia, autism, and Parkinson's, and this research could help lead to a greater understanding of these diseases and the development of novel diagnostic tools.                ",Deciding Where to Look Next: Frontal Eye Field's Role during Natural Viewing,8909502,F31EY025532,"['Affect', 'Algorithms', 'Area', 'Autistic Disorder', 'Banana', 'Behavior', 'Brain', 'Brain region', 'Complex', 'Computer Vision Systems', 'Crowding', 'Data', 'Data Analyses', 'Dependence', 'Development', 'Dimensions', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Environment', 'Eye', 'Eye Movements', 'Face', 'Goals', 'Health', 'Image', 'Lead', 'Link', 'Location', 'Macaca', 'Macaca mulatta', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Modeling', 'Monkeys', 'Neurobiology', 'Neurologic', 'Neurons', 'Parkinson Disease', 'Play', 'Research', 'Research Personnel', 'Role', 'Running', 'Saccades', 'Schizophrenia', 'Site', 'Source', 'Stimulus', 'Testing', 'Visual', 'Visual Pathways', 'Visual attention', 'Work', 'awake', 'base', 'design', 'experience', 'extracellular', 'frontal eye fields', 'nervous system disorder', 'neural model', 'neuromechanism', 'novel diagnostics', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'tool', 'visual stimulus']",NEI,NORTHWESTERN UNIVERSITY AT CHICAGO,F31,2015,36487,0.07136671550572339
"Post-natal development of high-level visual representation in primates View-invariant object recognition is a complex cognitive task that is critical to everyday functioning. A key neural correlate of high-level object recognition is inferior temporal (IT) cortex, a brain area present in both humans and non-human primates. Recent advances in visual systems neuroscience have begun to uncover how images are encoded in the adult IT object representation, however the learning rules by which high level visual areas (especially IT) develop remain mysterious, with both the magnitude and qualitative nature of developmental changes remaining almost completely unknown — in part because, over the last thirty years, there have been practically no studies of spiking neural responses in the higher ventral cortical areas of developing primates. There is thus a significant gap in our understanding of how visual development proceeds.  This exploratory proposal aims to characterize how representation in higher primate visual cortex changes during development. We first aim (Aim 1) to implant chronic electrode arrays to record hundreds of IT neuronal sites in response to thousands of image stimuli in awake behaving juvenile macaques. These data will comprise a snapshot of the developing primate visual representation, and will be particularly powerful because we have already extensively measured adult monkey IT using the same stimuli and methods. By comparing juvenile and adult neuronal responses at both single site and population levels, we will obtain a unprecedentedly large-scale and detailed picture of the neural correlates of high-level visual development (Aim 2).  Aims 1 and 2 are exploratory, but potentially transformative – they will result in publicly available neuronal IT development benchmarks against which any proposed model of high level visual development can be rigorously tested, and will spur the development of those models in our lab and others. In that context, we will also seek (Aim 3) to improve known semi- and un-supervised learning rules from the computer vision and computational neuroscience literature, and to compare them to both recent high-performing (but biologically implausible) supervised models as well to the rich developmental measurements obtained in Aims 1 and 2.  Establishing experimental and surgical procedures for juvenile array recordings will create the future opportunity to observe changes in high level neural visual representations while experience is manipulated in early development, and will enable experiments in other sensory, motor, or decision making domains. If successful, the proposed work will yield a deeper understanding of the principles underlying visual cortex development, understanding which will in turn be helpful for treating neurodevelopmental disorders that implicate cortical circuits, including amblyopia and autism. Project narrative  Visual object recognition is fundamental to our everyday functioning. While the brain is remarkably good at accomplishing these challenging tasks, we do not yet know how it learns this ability during development. The goal of these experiments is to develop new experimental and computational tools to discover the neural learning principles that underlie that visual ability.",Post-natal development of high-level visual representation in primates,9455686,R21EY025863,"['Adolescent', 'Adult', 'Amblyopia', 'Animals', 'Area', 'Autistic Disorder', 'Behavioral', 'Benchmarking', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Chronic', 'Collaborations', 'Complex', 'Computer Vision Systems', 'Conflict (Psychology)', 'Data', 'Data Set', 'Decision Making', 'Development', 'Electrodes', 'Exhibits', 'Eye', 'Face', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Head', 'Human', 'Image', 'Implant', 'Inferior', 'Learning', 'Literature', 'Macaca', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Motivation', 'Motor', 'Nature', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Performance', 'Population', 'Primates', 'Procedures', 'Process', 'Research', 'Rewards', 'Sensory', 'Site', 'Stimulus', 'Stream', 'Supervision', 'System', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'awake', 'base', 'cognitive task', 'computational neuroscience', 'computerized tools', 'experience', 'experimental study', 'extrastriate visual cortex', 'improved', 'juvenile animal', 'learning network', 'mature animal', 'multi-electrode arrays', 'network models', 'neural correlate', 'nonhuman primate', 'novel', 'object recognition', 'postnatal', 'predictive modeling', 'receptive field', 'relating to nervous system', 'response', 'statistics', 'vision development']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2018,232050,0.16615062968269534
"Post-natal development of high-level visual representation in primates View-invariant object recognition is a complex cognitive task that is critical to everyday functioning. A key neural correlate of high-level object recognition is inferior temporal (IT) cortex, a brain area present in both humans and non-human primates. Recent advances in visual systems neuroscience have begun to uncover how images are encoded in the adult IT object representation, however the learning rules by which high level visual areas (especially IT) develop remain mysterious, with both the magnitude and qualitative nature of developmental changes remaining almost completely unknown — in part because, over the last thirty years, there have been practically no studies of spiking neural responses in the higher ventral cortical areas of developing primates. There is thus a significant gap in our understanding of how visual development proceeds.  This exploratory proposal aims to characterize how representation in higher primate visual cortex changes during development. We first aim (Aim 1) to implant chronic electrode arrays to record hundreds of IT neuronal sites in response to thousands of image stimuli in awake behaving juvenile macaques. These data will comprise a snapshot of the developing primate visual representation, and will be particularly powerful because we have already extensively measured adult monkey IT using the same stimuli and methods. By comparing juvenile and adult neuronal responses at both single site and population levels, we will obtain a unprecedentedly large-scale and detailed picture of the neural correlates of high-level visual development (Aim 2).  Aims 1 and 2 are exploratory, but potentially transformative – they will result in publicly available neuronal IT development benchmarks against which any proposed model of high level visual development can be rigorously tested, and will spur the development of those models in our lab and others. In that context, we will also seek (Aim 3) to improve known semi- and un-supervised learning rules from the computer vision and computational neuroscience literature, and to compare them to both recent high-performing (but biologically implausible) supervised models as well to the rich developmental measurements obtained in Aims 1 and 2.  Establishing experimental and surgical procedures for juvenile array recordings will create the future opportunity to observe changes in high level neural visual representations while experience is manipulated in early development, and will enable experiments in other sensory, motor, or decision making domains. If successful, the proposed work will yield a deeper understanding of the principles underlying visual cortex development, understanding which will in turn be helpful for treating neurodevelopmental disorders that implicate cortical circuits, including amblyopia and autism. Project narrative  Visual object recognition is fundamental to our everyday functioning. While the brain is remarkably good at accomplishing these challenging tasks, we do not yet know how it learns this ability during development. The goal of these experiments is to develop new experimental and computational tools to discover the neural learning principles that underlie that visual ability.",Post-natal development of high-level visual representation in primates,9316254,R21EY025863,"['Adolescent', 'Adult', 'Amblyopia', 'Animals', 'Area', 'Autistic Disorder', 'Behavioral', 'Benchmarking', 'Biological', 'Biological Neural Networks', 'Brain', 'Categories', 'Chronic', 'Collaborations', 'Complex', 'Computer Vision Systems', 'Conflict (Psychology)', 'Data', 'Data Set', 'Decision Making', 'Development', 'Electrodes', 'Exhibits', 'Eye', 'Face', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Head', 'Human', 'Image', 'Implant', 'Inferior', 'Learning', 'Literature', 'Macaca', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monkeys', 'Motivation', 'Motor', 'Nature', 'Neural Network Simulation', 'Neurodevelopmental Disorder', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Performance', 'Population', 'Primates', 'Procedures', 'Process', 'Research', 'Rewards', 'Sensory', 'Site', 'Stimulus', 'Stream', 'Supervision', 'System', 'Techniques', 'Temporal Lobe', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'awake', 'base', 'cognitive task', 'computational neuroscience', 'computerized tools', 'experience', 'experimental study', 'extrastriate visual cortex', 'improved', 'juvenile animal', 'learning network', 'mature animal', 'multi-electrode arrays', 'network models', 'neural correlate', 'nonhuman primate', 'novel', 'object recognition', 'postnatal', 'receptive field', 'relating to nervous system', 'response', 'statistics', 'vision development']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2017,193375,0.16615062968269534
"Crossmodal Correspondences Between Visual and Auditory Features ﻿    DESCRIPTION (provided by applicant): We live in a multisensory world, in which stimuli of various types constantly compete for our attention. Information about objects or events typically appears on more than one sensory channel, so that integrating inputs across sensory systems (e.g. vision and hearing) can enhance the signal-to-noise ratio and lead to more efficient perception and action. There is increasing interest in studying how stimulus properties in one sensory modality (e.g. vision) correspond to those in another modality (e.g. hearing). For instance, sounds of high pitch are linked to small-sized visual objects whereas sounds of low pitch are linked with large objects; sounds of high/low pitch are associated with, respectively, visual stimuli of high/low elevation; and even aspects of linguistic stimuli such as vowel quality are associated with visual properties such as object size. Such crossmodal correspondences are important factors in multisensory binding. While information has exploded on the kinds of stimulus features that are reliably associated by human observers across modalities, currently there is little neural evidence to allow a mechanistic account of how crossmodal correspondences arise, or how they relate to synesthesia, a phenomenon in which some individuals experience unusual percepts (e.g. colors) triggered by particular stimuli (e.g. letters. Our goal is to address these important gaps in knowledge, by using functional magnetic resonance imaging (fMRI) in humans to investigate the neural mechanisms underlying crossmodal and synesthetic correspondences and thus to distinguish between alternative explanations that have been offered. A number of possible mechanisms have been entertained for crossmodal correspondences. These include: Hypothesis A - learned associations due to statistical co-occurrences, which would predict that the correspondences are based in multisensory or even classic unisensory regions; Hypothesis B - semantic mediation (e.g. the common word ""high"" may mediate the link between high pitch and high elevation); and Hypothesis C - conceptual linking via a high-level property such as magnitude. In a series of eight experiments that comprise three Specific Aims, we propose to examine these competing accounts, recognizing that some or all of them may be operative, and that the mechanisms may vary between different types of crossmodal correspondences. PUBLIC HEALTH RELEVANCE: The proposed systematic study of the brain basis of correspondences between stimulus properties across sensory systems will allow critical insights into the multisensory processing involved in perception and action, illuminate the multisensory basis of language and music, and expand understanding of the phenomenon of synesthesia in relation to normal experience. From a practical standpoint, the proposed work will make significant contributions to the design of sensory substitution approaches for people with visual, auditory and other sensory deficits, and the rehabilitation of individuals with multisensory processing abnormalities, including developmental (autism, dyslexia), neurological (neglect) and psychiatric (schizophrenia) disorders.",Crossmodal Correspondences Between Visual and Auditory Features,9137687,R01EY025978,"['Accounting', 'Address', 'Association Learning', 'Attention', 'Auditory', 'Auditory pitch', 'Autistic Disorder', 'Base of the Brain', 'Behavioral', 'Binding', 'Color', 'Data', 'Development', 'Dimensions', 'Disease', 'Dyslexia', 'Event', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Hearing', 'Human', 'Individual', 'Judgment', 'Knowledge', 'Language', 'Lead', 'Letters', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Modality', 'Multivariate Analysis', 'Music', 'Neurologic', 'Noise', 'Pattern', 'Perception', 'Process', 'Property', 'Regression Analysis', 'Rehabilitation therapy', 'Research Personnel', 'Rest', 'Schizophrenia', 'Semantics', 'Sensory', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Time', 'Vision', 'Visual', 'Work', 'base', 'design', 'experience', 'insight', 'interest', 'multisensory', 'neglect', 'neuroimaging', 'neuromechanism', 'relating to nervous system', 'research study', 'sensory system', 'sound', 'vector', 'visual stimulus']",NEI,EMORY UNIVERSITY,R01,2016,565302,0.04349641697157149
"Crossmodal Correspondences Between Visual and Auditory Features ﻿    DESCRIPTION (provided by applicant): We live in a multisensory world, in which stimuli of various types constantly compete for our attention. Information about objects or events typically appears on more than one sensory channel, so that integrating inputs across sensory systems (e.g. vision and hearing) can enhance the signal-to-noise ratio and lead to more efficient perception and action. There is increasing interest in studying how stimulus properties in one sensory modality (e.g. vision) correspond to those in another modality (e.g. hearing). For instance, sounds of high pitch are linked to small-sized visual objects whereas sounds of low pitch are linked with large objects; sounds of high/low pitch are associated with, respectively, visual stimuli of high/low elevation; and even aspects of linguistic stimuli such as vowel quality are associated with visual properties such as object size. Such crossmodal correspondences are important factors in multisensory binding. While information has exploded on the kinds of stimulus features that are reliably associated by human observers across modalities, currently there is little neural evidence to allow a mechanistic account of how crossmodal correspondences arise, or how they relate to synesthesia, a phenomenon in which some individuals experience unusual percepts (e.g. colors) triggered by particular stimuli (e.g. letters. Our goal is to address these important gaps in knowledge, by using functional magnetic resonance imaging (fMRI) in humans to investigate the neural mechanisms underlying crossmodal and synesthetic correspondences and thus to distinguish between alternative explanations that have been offered. A number of possible mechanisms have been entertained for crossmodal correspondences. These include: Hypothesis A - learned associations due to statistical co-occurrences, which would predict that the correspondences are based in multisensory or even classic unisensory regions; Hypothesis B - semantic mediation (e.g. the common word ""high"" may mediate the link between high pitch and high elevation); and Hypothesis C - conceptual linking via a high-level property such as magnitude. In a series of eight experiments that comprise three Specific Aims, we propose to examine these competing accounts, recognizing that some or all of them may be operative, and that the mechanisms may vary between different types of crossmodal correspondences.         PUBLIC HEALTH RELEVANCE: The proposed systematic study of the brain basis of correspondences between stimulus properties across sensory systems will allow critical insights into the multisensory processing involved in perception and action, illuminate the multisensory basis of language and music, and expand understanding of the phenomenon of synesthesia in relation to normal experience. From a practical standpoint, the proposed work will make significant contributions to the design of sensory substitution approaches for people with visual, auditory and other sensory deficits, and the rehabilitation of individuals with multisensory processing abnormalities, including developmental (autism, dyslexia), neurological (neglect) and psychiatric (schizophrenia) disorders.                ",Crossmodal Correspondences Between Visual and Auditory Features,8988153,R01EY025978,"['Accounting', 'Address', 'Association Learning', 'Attention', 'Auditory', 'Auditory pitch', 'Autistic Disorder', 'Base of the Brain', 'Behavioral', 'Binding', 'Color', 'Data', 'Development', 'Dimensions', 'Disease', 'Dyslexia', 'Event', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing', 'Human', 'Individual', 'Judgment', 'Knowledge', 'Language', 'Lead', 'Letters', 'Life', 'Linguistics', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Modality', 'Multivariate Analysis', 'Music', 'Neurologic', 'Noise', 'Pattern', 'Perception', 'Process', 'Property', 'Regression Analysis', 'Rehabilitation therapy', 'Research Personnel', 'Rest', 'Schizophrenia', 'Semantics', 'Sensory', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Time', 'Vision', 'Visual', 'Work', 'base', 'design', 'experience', 'insight', 'interest', 'multisensory', 'neglect', 'neuroimaging', 'neuromechanism', 'public health relevance', 'relating to nervous system', 'research study', 'sensory system', 'sound', 'vector', 'visual stimulus']",NEI,EMORY UNIVERSITY,R01,2015,586366,0.04349641697157149
"Crossmodal Correspondences Between Visual and Auditory Features ﻿    DESCRIPTION (provided by applicant): We live in a multisensory world, in which stimuli of various types constantly compete for our attention. Information about objects or events typically appears on more than one sensory channel, so that integrating inputs across sensory systems (e.g. vision and hearing) can enhance the signal-to-noise ratio and lead to more efficient perception and action. There is increasing interest in studying how stimulus properties in one sensory modality (e.g. vision) correspond to those in another modality (e.g. hearing). For instance, sounds of high pitch are linked to small-sized visual objects whereas sounds of low pitch are linked with large objects; sounds of high/low pitch are associated with, respectively, visual stimuli of high/low elevation; and even aspects of linguistic stimuli such as vowel quality are associated with visual properties such as object size. Such crossmodal correspondences are important factors in multisensory binding. While information has exploded on the kinds of stimulus features that are reliably associated by human observers across modalities, currently there is little neural evidence to allow a mechanistic account of how crossmodal correspondences arise, or how they relate to synesthesia, a phenomenon in which some individuals experience unusual percepts (e.g. colors) triggered by particular stimuli (e.g. letters. Our goal is to address these important gaps in knowledge, by using functional magnetic resonance imaging (fMRI) in humans to investigate the neural mechanisms underlying crossmodal and synesthetic correspondences and thus to distinguish between alternative explanations that have been offered. A number of possible mechanisms have been entertained for crossmodal correspondences. These include: Hypothesis A - learned associations due to statistical co-occurrences, which would predict that the correspondences are based in multisensory or even classic unisensory regions; Hypothesis B - semantic mediation (e.g. the common word ""high"" may mediate the link between high pitch and high elevation); and Hypothesis C - conceptual linking via a high-level property such as magnitude. In a series of eight experiments that comprise three Specific Aims, we propose to examine these competing accounts, recognizing that some or all of them may be operative, and that the mechanisms may vary between different types of crossmodal correspondences. PUBLIC HEALTH RELEVANCE: The proposed systematic study of the brain basis of correspondences between stimulus properties across sensory systems will allow critical insights into the multisensory processing involved in perception and action, illuminate the multisensory basis of language and music, and expand understanding of the phenomenon of synesthesia in relation to normal experience. From a practical standpoint, the proposed work will make significant contributions to the design of sensory substitution approaches for people with visual, auditory and other sensory deficits, and the rehabilitation of individuals with multisensory processing abnormalities, including developmental (autism, dyslexia), neurological (neglect) and psychiatric (schizophrenia) disorders.",Crossmodal Correspondences Between Visual and Auditory Features,9334867,R01EY025978,"['Activation Analysis', 'Address', 'Attention', 'Auditory', 'Auditory pitch', 'Autistic Disorder', 'Behavioral', 'Binding', 'Brain', 'Color', 'Data', 'Development', 'Dimensions', 'Disease', 'Dyslexia', 'Event', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hearing', 'Human', 'Individual', 'Judgment', 'Knowledge', 'Language', 'Lead', 'Letters', 'Linguistics', 'Link', 'Machine Learning', 'Measures', 'Mediating', 'Mediation', 'Modality', 'Multivariate Analysis', 'Music', 'Neurologic', 'Noise', 'Pattern', 'Perception', 'Process', 'Property', 'Regression Analysis', 'Rehabilitation therapy', 'Research Personnel', 'Rest', 'Schizophrenia', 'Semantics', 'Sensory', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Time', 'Vision', 'Visual', 'Work', 'base', 'design', 'experience', 'experimental study', 'insight', 'interest', 'multisensory', 'neglect', 'neuroimaging', 'neuromechanism', 'neurophysiology', 'public health relevance', 'relating to nervous system', 'sensory system', 'sound', 'vector', 'visual stimulus']",NEI,EMORY UNIVERSITY,R01,2017,620264,0.04349641697157149
"Neural dynamics underlying spatiotemporal cognitive integration Project Summary  Our ability to visually interpret the world around us depends on bottom-up computations that extract relevant information from the sensory inputs but it also depends on our accumulated core knowledge about the world providing top-down signals based on prior experience. The goal of this proposal is to study the mechanisms by which visual information is integrated spatially and temporally to combine bottom-up and top- down knowledge. Towards this goal, we combine behavioral measurements, invasive neurophysiological recordings, and computational models. The behavioral data will provide critical constraints about human integrative abilities, particularly through eye movements and the dynamics of recognition. The invasive neurophysiological data will provide high spatiotemporal resolution of neural activity along the inferior temporal cortex and the interactions with pre-frontal cortex, which is hypothesized to be critical for conveying the type of top-down signals required for recognition. Ultimately, a central goal of our proposal is to formalize our understanding of these integrative process via a quantitative computational model. This computational model should be able to capture the behavioral and physiological results and provide testable predictions. During the current award, we have made significant progress towards elucidating the mechanisms underlying pattern completion whereby the visual system is capable of inferring the identity of objects from partial information. Here we consider a set of images and videos that are “minimal” in the sense that they are recognizable but where any further reduction in the amount of spatial or temporal information renders them unrecognizable. We have strong preliminary evidence that suggests that state-of-the-art purely bottom-up theories of recognition instantiated by deep convolutional networks cannot explain human behavior and physiology. Therefore, these types of stimuli provide an ideal arena to investigate how top-down signals, presumably from pre-frontal cortex, modulate the responses along ventral visual cortex to orchestrate recognition. Understanding the neural mechanisms by which core knowledge is incorporated into sensory processing is arguably one of the greatest challenges in Cognitive Science and may have important implications for many neurological and psychiatric conditions that are characterized by dysfunctional top-down signaling and remain poorly understood. Project narrative  Interpreting the world around us requires putting together current sensory experiences and our prior experience. It has been known for a long time that such prior core knowledge of the world plays a critical role in our perceptions. Yet, the mechanisms by which such experiences are merged with sensory stimuli remain poorly understood and elusive. Here we combine behavioral measurements, direct recordings of neural data from inside the human brain, and computational models to investigate the neural circuits that combine the senses and prior experiences. There are multiple neurological and psychiatric conditions that are characterized by abnormal top-down signaling, conditions that remain poorly understood and where successful treatment will necessitate deep understanding of their mechanistic basis. The current proposal combines state-of-the-art technologies, methods and models to tackle these questions and begin to shed light on one of the most challenging mysteries of the mind, the interplay between the senses and high-level cognition.",Neural dynamics underlying spatiotemporal cognitive integration,10018017,R01EY026025,"['Architecture', 'Automobile Driving', 'Award', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Bicycling', 'Brain', 'Categories', 'Cognition', 'Cognitive', 'Cognitive Science', 'Complex', 'Computer Models', 'Cues', 'Data', 'Data Set', 'Epilepsy', 'Eye Movements', 'Goals', 'Human', 'Image', 'Inferior', 'Investigation', 'Knowledge', 'Label', 'Left', 'Light', 'Link', 'Location', 'Measurement', 'Methods', 'Mind', 'Modeling', 'Monitor', 'Neurologic', 'Operative Surgical Procedures', 'Output', 'Pattern', 'Perception', 'Physiological', 'Physiology', 'Play', 'Prefrontal Cortex', 'Process', 'Psychophysics', 'Resolution', 'Role', 'Route', 'Sensory', 'Signal Transduction', 'Source', 'Stimulus', 'Stream', 'Technology', 'Temporal Lobe', 'Testing', 'Time', 'Validation', 'Vision', 'Visual', 'Visual Cortex', 'Visual system structure', 'Work', 'base', 'behavior measurement', 'convolutional neural network', 'experience', 'experimental study', 'millisecond', 'network architecture', 'neural circuit', 'neuromechanism', 'neurophysiology', 'object recognition', 'relating to nervous system', 'response', 'sensory input', 'sensory stimulus', 'spatial integration', 'spatiotemporal', 'theories', 'visual cognition', 'visual information']",NEI,BOSTON CHILDREN'S HOSPITAL,R01,2020,432490,0.05208259290159757
"Posture and Orientation in Older Adults and Post-Stroke    DESCRIPTION (provided by applicant): The overall goal of this research is to determine how conflicting visual and self-motion information modulates the responses of the postural control system in elderly adults and in individuals post-stroke. When visual field information does not match self-motion feedback, healthy elderly respond to combined visual, vestibular, and proprioceptive signals differently than young adults. Young adults incorporate frequency components of all inputs into their responses; elderly adults rely primarily on vision. We hypothesize that elderly adults and individuals post-stroke have increased sensory thresholds to complex multimodal stimuli which produces a greater reliance on predictive or on visual inputs making it more difficult for them to selectively respond to visual and physical destabilization. By combining the technology of a virtual environment with support surface translations we plan to manipulate the influence of visual inputs, somatosensory (i.e., proprioceptive and vestibular) inputs, and prediction to reveal the contribution of segmental inputs and higher order processing to the postural response. We plan to compare healthy young and elderly individuals with young and elderly individuals post-stroke in order to distinguish between the effects of age and CNS impairment. We will first explore whether subjects change their responses to particular sensory modalities over time. Then the head and trunk will be aligned in different positions with respect to visual and support surface motion to reveal how altering sensory and biomechanical orientations affects the response to visual motion signals. Lastly, we will examine how predictable and random visual inputs influence the response to random support surface inputs. Visual field dependence will be measured with a Rod and Frame test. We will employ novel methods of Principal Component Analysis and autoregressive modeling to distinguish between body mechanics and specified neural processes. These analyses should reveal how the selection of control pathways is determined by the task as well as further define response properties of the afferent pathways. Segmental and muscle response strategies will be examined through kinematic measures including center of pressure, center of mass displacement, and electromyography, and tested for significance with a MANOVA. Clarifying the relation between visual inputs and postural stabilization will identify functional situations that present a high probability for instability and falling. Results from the proposed studies can potentially be used for developing individually designed programs of therapeutic intervention.       n/a",Posture and Orientation in Older Adults and Post-Stroke,7890167,R01AG026470,"['Adult', 'Affect', 'Afferent Pathways', 'Age', 'Aging', 'Animals', 'Behavior', 'Biomechanics', 'Brain', 'Characteristics', 'Complex', 'Conflict (Psychology)', 'Coupled', 'Dependence', 'Disease', 'Elderly', 'Electromyography', 'Environment', 'Feedback', 'Frequencies', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Laboratories', 'Left', 'Lesion', 'Locomotion', 'Measures', 'Methods', 'Modality', 'Modeling', 'Motion', 'Muscle', 'Musculoskeletal Equilibrium', 'Pathway interactions', 'Patients', 'Pattern', 'Positioning Attribute', 'Postural response', 'Posture', 'Principal Component Analysis', 'Probability', 'Process', 'Property', 'Reliance', 'Research', 'Research Personnel', 'Sensory', 'Sensory Thresholds', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Stimulus', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Translations', 'Vestibular loss', 'Vision', 'Visual', 'Visual Fields', 'Visual Motion', 'Weight', 'Work', 'age effect', 'body mechanics', 'design', 'falls', 'kinematics', 'novel', 'older patient', 'optic flow', 'post stroke', 'pressure', 'programs', 'relating to nervous system', 'response', 'retinal rods', 'somatosensory', 'virtual', 'visual information', 'visual-vestibular', 'young adult']",NIA,TEMPLE UNIV OF THE COMMONWEALTH,R01,2009,106428,0.21506005848504164
"Posture and Orientation in Older Adults and Post-Stroke    DESCRIPTION (provided by applicant): The overall goal of this research is to determine how conflicting visual and self-motion information modulates the responses of the postural control system in elderly adults and in individuals post-stroke. When visual field information does not match self-motion feedback, healthy elderly respond to combined visual, vestibular, and proprioceptive signals differently than young adults. Young adults incorporate frequency components of all inputs into their responses; elderly adults rely primarily on vision. We hypothesize that elderly adults and individuals post-stroke have increased sensory thresholds to complex multimodal stimuli which produces a greater reliance on predictive or on visual inputs making it more difficult for them to selectively respond to visual and physical destabilization. By combining the technology of a virtual environment with support surface translations we plan to manipulate the influence of visual inputs, somatosensory (i.e., proprioceptive and vestibular) inputs, and prediction to reveal the contribution of segmental inputs and higher order processing to the postural response. We plan to compare healthy young and elderly individuals with young and elderly individuals post-stroke in order to distinguish between the effects of age and CNS impairment. We will first explore whether subjects change their responses to particular sensory modalities over time. Then the head and trunk will be aligned in different positions with respect to visual and support surface motion to reveal how altering sensory and biomechanical orientations affects the response to visual motion signals. Lastly, we will examine how predictable and random visual inputs influence the response to random support surface inputs. Visual field dependence will be measured with a Rod and Frame test. We will employ novel methods of Principal Component Analysis and autoregressive modeling to distinguish between body mechanics and specified neural processes. These analyses should reveal how the selection of control pathways is determined by the task as well as further define response properties of the afferent pathways. Segmental and muscle response strategies will be examined through kinematic measures including center of pressure, center of mass displacement, and electromyography, and tested for significance with a MANOVA. Clarifying the relation between visual inputs and postural stabilization will identify functional situations that present a high probability for instability and falling. Results from the proposed studies can potentially be used for developing individually designed programs of therapeutic intervention.       n/a",Posture and Orientation in Older Adults and Post-Stroke,7670243,R01AG026470,"['Adult', 'Affect', 'Afferent Pathways', 'Age', 'Aging', 'Animals', 'Behavior', 'Biomechanics', 'Brain', 'Characteristics', 'Complex', 'Conflict (Psychology)', 'Coupled', 'Dependence', 'Disease', 'Elderly', 'Electromyography', 'Environment', 'Feedback', 'Frequencies', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Laboratories', 'Left', 'Lesion', 'Locomotion', 'Measures', 'Methods', 'Modality', 'Modeling', 'Motion', 'Muscle', 'Musculoskeletal Equilibrium', 'Pathway interactions', 'Patients', 'Pattern', 'Positioning Attribute', 'Postural response', 'Posture', 'Principal Component Analysis', 'Probability', 'Process', 'Property', 'Reliance', 'Research', 'Research Personnel', 'Sensory', 'Sensory Thresholds', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Stimulus', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Translations', 'Vestibular loss', 'Vision', 'Visual', 'Visual Fields', 'Visual Motion', 'Weight', 'Work', 'age effect', 'body mechanics', 'design', 'falls', 'kinematics', 'novel', 'older patient', 'optic flow', 'post stroke', 'pressure', 'programs', 'relating to nervous system', 'response', 'retinal rods', 'somatosensory', 'virtual', 'visual information', 'visual-vestibular', 'young adult']",NIA,TEMPLE UNIV OF THE COMMONWEALTH,R01,2009,286583,0.21506005848504164
"Posture and Orientation in Older Adults and Post-Stroke    DESCRIPTION (provided by applicant): The overall goal of this research is to determine how conflicting visual and self-motion information modulates the responses of the postural control system in elderly adults and in individuals post-stroke. When visual field information does not match self-motion feedback, healthy elderly respond to combined visual, vestibular, and proprioceptive signals differently than young adults. Young adults incorporate frequency components of all inputs into their responses; elderly adults rely primarily on vision. We hypothesize that elderly adults and individuals post-stroke have increased sensory thresholds to complex multimodal stimuli which produces a greater reliance on predictive or on visual inputs making it more difficult for them to selectively respond to visual and physical destabilization. By combining the technology of a virtual environment with support surface translations we plan to manipulate the influence of visual inputs, somatosensory (i.e., proprioceptive and vestibular) inputs, and prediction to reveal the contribution of segmental inputs and higher order processing to the postural response. We plan to compare healthy young and elderly individuals with young and elderly individuals post-stroke in order to distinguish between the effects of age and CNS impairment. We will first explore whether subjects change their responses to particular sensory modalities over time. Then the head and trunk will be aligned in different positions with respect to visual and support surface motion to reveal how altering sensory and biomechanical orientations affects the response to visual motion signals. Lastly, we will examine how predictable and random visual inputs influence the response to random support surface inputs. Visual field dependence will be measured with a Rod and Frame test. We will employ novel methods of Principal Component Analysis and autoregressive modeling to distinguish between body mechanics and specified neural processes. These analyses should reveal how the selection of control pathways is determined by the task as well as further define response properties of the afferent pathways. Segmental and muscle response strategies will be examined through kinematic measures including center of pressure, center of mass displacement, and electromyography, and tested for significance with a MANOVA. Clarifying the relation between visual inputs and postural stabilization will identify functional situations that present a high probability for instability and falling. Results from the proposed studies can potentially be used for developing individually designed programs of therapeutic intervention.       n/a",Posture and Orientation in Older Adults and Post-Stroke,7478552,R01AG026470,"['Adult', 'Affect', 'Afferent Pathways', 'Age', 'Aging', 'Animals', 'Behavior', 'Biomechanics', 'Brain', 'Characteristics', 'Complex', 'Conflict (Psychology)', 'Coupled', 'Dependence', 'Disease', 'Elderly', 'Electromyography', 'Environment', 'Feedback', 'Frequencies', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Laboratories', 'Left', 'Lesion', 'Locomotion', 'Measures', 'Methods', 'Modality', 'Modeling', 'Motion', 'Muscle', 'Musculoskeletal Equilibrium', 'Pathway interactions', 'Patients', 'Pattern', 'Positioning Attribute', 'Postural response', 'Posture', 'Principal Component Analysis', 'Probability', 'Process', 'Property', 'Reliance', 'Research', 'Research Personnel', 'Sensory', 'Sensory Thresholds', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Stimulus', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Translations', 'Vestibular loss', 'Vision', 'Visual', 'Visual Fields', 'Visual Motion', 'Weight', 'Work', 'age effect', 'body mechanics', 'design', 'falls', 'kinematics', 'novel', 'older patient', 'optic flow', 'post stroke', 'pressure', 'programs', 'relating to nervous system', 'response', 'retinal rods', 'somatosensory', 'virtual', 'visual information', 'visual-vestibular', 'young adult']",NIA,TEMPLE UNIV OF THE COMMONWEALTH,R01,2008,263925,0.21506005848504164
"Posture and Orientation in Older Adults and Post-Stroke    DESCRIPTION (provided by applicant): The overall goal of this research is to determine how conflicting visual and self-motion information modulates the responses of the postural control system in elderly adults and in individuals post-stroke. When visual field information does not match self-motion feedback, healthy elderly respond to combined visual, vestibular, and proprioceptive signals differently than young adults. Young adults incorporate frequency components of all inputs into their responses; elderly adults rely primarily on vision. We hypothesize that elderly adults and individuals post-stroke have increased sensory thresholds to complex multimodal stimuli which produces a greater reliance on predictive or on visual inputs making it more difficult for them to selectively respond to visual and physical destabilization. By combining the technology of a virtual environment with support surface translations we plan to manipulate the influence of visual inputs, somatosensory (i.e., proprioceptive and vestibular) inputs, and prediction to reveal the contribution of segmental inputs and higher order processing to the postural response. We plan to compare healthy young and elderly individuals with young and elderly individuals post-stroke in order to distinguish between the effects of age and CNS impairment. We will first explore whether subjects change their responses to particular sensory modalities over time. Then the head and trunk will be aligned in different positions with respect to visual and support surface motion to reveal how altering sensory and biomechanical orientations affects the response to visual motion signals. Lastly, we will examine how predictable and random visual inputs influence the response to random support surface inputs. Visual field dependence will be measured with a Rod and Frame test. We will employ novel methods of Principal Component Analysis and autoregressive modeling to distinguish between body mechanics and specified neural processes. These analyses should reveal how the selection of control pathways is determined by the task as well as further define response properties of the afferent pathways. Segmental and muscle response strategies will be examined through kinematic measures including center of pressure, center of mass displacement, and electromyography, and tested for significance with a MANOVA. Clarifying the relation between visual inputs and postural stabilization will identify functional situations that present a high probability for instability and falling. Results from the proposed studies can potentially be used for developing individually designed programs of therapeutic intervention.       n/a",Posture and Orientation in Older Adults and Post-Stroke,7285957,R01AG026470,"['Adult', 'Affect', 'Afferent Pathways', 'Age', 'Aging', 'Animals', 'Behavior', 'Biomechanics', 'Brain', 'Characteristics', 'Complex', 'Conflict (Psychology)', 'Coupled', 'Dependence', 'Disease', 'Elderly', 'Electromyography', 'Environment', 'Feedback', 'Frequencies', 'Goals', 'Head', 'Human', 'Impairment', 'Individual', 'Laboratories', 'Left', 'Lesion', 'Locomotion', 'Measures', 'Methods', 'Modality', 'Modeling', 'Motion', 'Muscle', 'Musculoskeletal Equilibrium', 'Pathway interactions', 'Patients', 'Pattern', 'Positioning Attribute', 'Postural response', 'Posture', 'Principal Component Analysis', 'Probability', 'Process', 'Property', 'Reliance', 'Research', 'Research Personnel', 'Sensory', 'Sensory Thresholds', 'Side', 'Signal Transduction', 'Specific qualifier value', 'Stimulus', 'Stroke', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Intervention', 'Time', 'Translations', 'Vestibular loss', 'Vision', 'Visual', 'Visual Fields', 'Visual Motion', 'Weight', 'Work', 'age effect', 'body mechanics', 'design', 'falls', 'kinematics', 'novel', 'older patient', 'optic flow', 'post stroke', 'pressure', 'programs', 'relating to nervous system', 'response', 'retinal rods', 'somatosensory', 'virtual', 'visual information', 'visual-vestibular', 'young adult']",NIA,TEMPLE UNIV OF THE COMMONWEALTH,R01,2007,246800,0.21506005848504164
"Posture and Orientation in Older Adults and Post-Stroke    DESCRIPTION (provided by applicant): The overall goal of this research is to determine how conflicting visual and self-motion information modulates the responses of the postural control system in elderly adults and in individuals post-stroke. When visual field information does not match self-motion feedback, healthy elderly respond to combined visual, vestibular, and proprioceptive signals differently than young adults. Young adults incorporate frequency components of all inputs into their responses; elderly adults rely primarily on vision. We hypothesize that elderly adults and individuals post-stroke have increased sensory thresholds to complex multimodal stimuli which produces a greater reliance on predictive or on visual inputs making it more difficult for them to selectively respond to visual and physical destabilization. By combining the technology of a virtual environment with support surface translations we plan to manipulate the influence of visual inputs, somatosensory (i.e., proprioceptive and vestibular) inputs, and prediction to reveal the contribution of segmental inputs and higher order processing to the postural response. We plan to compare healthy young and elderly individuals with young and elderly individuals post-stroke in order to distinguish between the effects of age and CNS impairment. We will first explore whether subjects change their responses to particular sensory modalities over time. Then the head and trunk will be aligned in different positions with respect to visual and support surface motion to reveal how altering sensory and biomechanical orientations affects the response to visual motion signals. Lastly, we will examine how predictable and random visual inputs influence the response to random support surface inputs. Visual field dependence will be measured with a Rod and Frame test. We will employ novel methods of Principal Component Analysis and autoregressive modeling to distinguish between body mechanics and specified neural processes. These analyses should reveal how the selection of control pathways is determined by the task as well as further define response properties of the afferent pathways. Segmental and muscle response strategies will be examined through kinematic measures including center of pressure, center of mass displacement, and electromyography, and tested for significance with a MANOVA. Clarifying the relation between visual inputs and postural stabilization will identify functional situations that present a high probability for instability and falling. Results from the proposed studies can potentially be used for developing individually designed programs of therapeutic intervention.       n/a",Posture and Orientation in Older Adults and Post-Stroke,7101515,R01AG026470,"['adult human (21+)', 'age difference', 'aging', 'behavioral /social science research tag', 'biomechanics', 'clinical research', 'computer human interaction', 'computer simulation', 'human old age (65+)', 'human subject', 'mathematical model', 'motion perception', 'neural information processing', 'orientation', 'posture', 'proprioception /kinesthesia', 'sensory signal detection', 'stroke', 'vestibular pathway', 'visual fields', 'visual perception', 'young adult human (21-34)']",NIA,TEMPLE UNIVERSITY,R01,2006,331563,0.21506005848504164
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9772484,R42EY027651,"['Address', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'machine learning algorithm', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2019,648557,0.21955646983384433
"The nGoggle: A portable brain-based device for assessment of visual function deficits PROJECT SUMMARY Assessment of loss of visual function outside the foveal area is an essential component of the management of numerous conditions, including glaucoma, retinal and neurological disorders. Despite the significant progress achieved with the development of standard automated perimetry (SAP) many decades ago, assessment of visual field loss with SAP still has significant drawbacks. SAP testing is limited by subjectivity of patient responses and high test-retest variability, frequently requiring many tests for effective detection of change over time. Moreover, as these tests are generally conducted in clinic-based settings, limited patient availability and health care resources often result in an insufficient number of tests acquired over time, with delayed diagnosis and detection of disease progression. The requirement for highly trained technicians, cost, complexity, and lack of portability of SAP also preclude its use for screening of visual field loss in underserved populations. To address shortcomings of current methods to assess visual function, we have developed the nGoggle, a wearable device that uses a head-mounted display (HMD) integrated with wireless electroencephalography (EEG), capable of objectively assessing visual field deficits using multifocal steady-state visual-evoked potentials (mfSSVEP). As part of the funded NEI SBIR Phase I, we developed the nGoggle prototype using a modified smartphone-based HMD display and non-disposable electrodes. In our Phase I studies, we conducted benchmarking tests on signal quality of EEG acquisition, developed methods for EEG data extraction and analysis, and conducted a pilot study demonstrating the ability of the device to detect visual field loss in glaucoma, a progressive neuropathy that results in characteristic damage to the optic nerve and resulting visual field defects. We also identified limitations of current existing displays and electrodes, as well as potential avenues for enhancing test reliability and improving user interface. Based on the encouraging results from Phase I and a clear delineation of the steps needed to bring the device into its final commercial product form, we now propose a series of Phase II studies. We hypothesize that optimization of nGoggle's accuracy and repeatability in detecting visual function loss can be achieved through the development of a customized head-mounted display with front-view eye/pupil tracking cameras and disposable no-prep electrodes, as well as enhancement of the visual stimulation protocol and data analytics. The specific aims of this proposal are: 1) To develop a customized head-mounted display and enhanced no-prep electrodes for improving nGoggle's ability to acquire users' mfSSVEP with high signal-to- noise ratios (SNR) in response to visual stimulation; 2) To optimize and validate mfSSVEP stimuli design and data analytics to enhance the accuracy and repeatability of assessing visual function loss with the nGoggle. 3) Complete pivotal clinical studies to support FDA approval. PROJECT NARRATIVE NGoggle Inc. has developed the nGoggle, a wearable device that uses a head-mounted display integrated with wireless electroencephalography, capable of objectively assessing visual field deficits using multifocal steady- state visual-evoked potentials. NGoggle Inc is now proposing to optimize nGoggle's accuracy and repeatability in detecting visual function loss with the use of a customized display, adherent no-prep electrodes, optimized visual stimuli and data analytics. It will also complete pivotal clinical studies to support FDA approval.",The nGoggle: A portable brain-based device for assessment of visual function deficits,9559052,R42EY027651,"['Address', 'Algorithms', 'Area', 'Base of the Brain', 'Benchmarking', 'Blindness', 'Brain', 'Cellular Phone', 'Characteristics', 'Client satisfaction', 'Clinic', 'Clinical Research', 'Custom', 'Data', 'Data Analytics', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Disease', 'Disease Progression', 'Elastomers', 'Electrodes', 'Electroencephalography', 'Electrooculogram', 'Exhibits', 'Eye', 'Funding', 'Glaucoma', 'Head', 'Healthcare', 'Machine Learning', 'Methods', 'Neuropathy', 'Noise', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Perimetry', 'Phase', 'Photic Stimulation', 'Pilot Projects', 'Protocols documentation', 'Pupil', 'Resources', 'Retinal Diseases', 'Scotoma', 'Series', 'Signal Transduction', 'Skin', 'Small Business Innovation Research Grant', 'Source', 'Stimulus', 'Testing', 'Time', 'Training', 'Underserved Population', 'Vision', 'Visual Fields', 'Visual evoked cortical potential', 'Wireless Technology', 'base', 'cost', 'design', 'field study', 'improved', 'loss of function', 'nervous system disorder', 'patient response', 'phase 1 study', 'phase 2 study', 'portability', 'prototype', 'real world application', 'relating to nervous system', 'response', 'sample fixation', 'screening', 'virtual reality', 'visual stimulus', 'wearable device']",NEI,"NGOGGLE, INC.",R42,2018,849367,0.21955646983384433
"Guiding Attention in Real-World Scenes Project Summary Real-world scenes contain far more information than we can perceive at any given moment. Scene perception therefore requires attentional selection of relevant scene regions for prioritized processing. How are those aspects of the world that should receive priority selected? Although much past research has focused on how attention is guided by the visual properties of a scene, new evidence from meaning maps, developed in the previous funding period, established that the distribution of meaning across a scene plays a central and often dominant role in guiding attention. This surprising finding raises many important new questions about the nature of scene meaning and its specific role in attentional guidance. The overarching goal of this project is to understand in detail how the semantic features of a scene’s objects and functional spaces influence the guidance of visual attention in complex real-world scenes. The specific aims are: (1) To determine the role of object semantics in attentional guidance in scenes; (2) To determine the role of functional spaces in attentional guidance in scenes; (3) To determine how viewing task interacts with scene semantics in guiding attention. The project is innovative in expanding the traditional study of attention to explicitly consider the role of meaning. To this end, new semantic maps capitalizing on the meaning map concept will be used capture local region meaning continuously over a scene, allowing for direct investigation of the relationships of different types of meaning with attention. The project is innovative in (1) expanding the traditional study of visual attention to explicitly consider the role of semantics; (2) focusing on the semantics of both scene content (objects) and scene structure (space); (3) considering the role of meaning in attentional guidance in the context of viewing task; (4) integrating the use of a wide variety of cognitive science methods marshalled in the service of understanding the influence of meaning on visual attention in real-world scenes, including eyetracking, large-scale crowd-sourcing, computational image processing, computational semantic modeling, and deep convolutional neural networks. The project is significant in challenging current models of visual attention to account for the role of scene meaning. Because the proposed studies test competing models, the results will lead to the development of integrative theoretical frameworks that advance the field regardless of the outcome. While focused on basic science, the studies have potentially important translational implications by providing a more complete characterization of the processes associated with visual attention. The proposed studies may ultimately lead to the development of rehabilitation strategies for visual attention as it operates in the real world, better capitalizing on the use of a viewer’s knowledge to offset disrupted functions in those with attention and vision deficits. Project Narrative The visual world presents us with far more information than we can process at any given moment. How does the brain select those aspects of the world that should receive priority for visual analysis? This project investigates how we select and attend to meaningful information the natural environment given what we are currently trying to accomplish. The studies combine high-resolution eyetracking with models of meaning based on crowd-sourced human ratings, computer vision models of image processing, deep learning models of scene recognition and attention, and hybrid artificial intelligence models of complex concepts. The role of meaning in guiding attention is contrasted with the role of pre-semantic image features. The knowledge gained will increase our theoretical understanding of how visual attention and perception operate in complex meaningful scenes, assist in the identification of individuals with deficits in visual attention, and may ultimately lead to the development of targeted rehabilitation strategies for the real world.",Guiding Attention in Real-World Scenes,10049970,R01EY027792,"['Address', 'Artificial Intelligence', 'Attention', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Cognition', 'Cognitive Science', 'Complex', 'Computer Vision Systems', 'Data', 'Development', 'Environment', 'Esthetics', 'Evaluation', 'Funding', 'Goals', 'Health', 'Human', 'Hybrids', 'Image', 'Individual', 'Investigation', 'Judgment', 'Knowledge', 'Lead', 'Maps', 'Marshal', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurologic', 'Outcome', 'Perception', 'Play', 'Population', 'Process', 'Property', 'Quality of life', 'Research', 'Resolution', 'Role', 'Semantics', 'Services', 'Spatial Distribution', 'Structure', 'Testing', 'Ursidae Family', 'Vision', 'Visual', 'Visual Perception', 'Visual attention', 'Work', 'base', 'behavior test', 'concept mapping', 'convolutional neural network', 'crowdsourcing', 'deep learning', 'digital imaging', 'experimental study', 'grasp', 'image processing', 'imaging properties', 'innovation', 'insight', 'model development', 'rehabilitation strategy', 'visual information', 'visual search']",NEI,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2020,381403,0.0901574594545618
"High-definition, wide field of view corneal imaging The cornea is the primary focusing structure of our visual system. Infections and diseases in the tissue can impair vision and lead to blindness, even in eyes with intact neurosensory function. Corneal disease is one of the leading causes of visual deficiency and blindness in the world. Tissue evaluation is an important step for assessing the health of the donor cornea and its appropriateness for different types of placement, yet this process suffers from high subjectivity. High-definition corneal imaging is needed to assist in selection of the most appropriate tissue for transplant. Progress on this front would greatly serve public need, as the cornea is the most commonly transplanted tissue worldwide, with nearly 185,000 transplants annually. Thus, a more sensitive and quantitative method for objective evaluation of tissue at eye banks is needed. We have developed a 3D high-definition imaging instrument based on Gabor-Domain Optical Coherence Microscopy (GDOCM). Our SBIR Phase I research successfully accomplished all Aims and demonstrated the feasibility of quantitative assessment of corneal tissue over a large field of view with GDOCM. Our Phase I results demonstrated that GDOCM has the following key advantages over existing corneal imaging techniques, which include specular and confocal microscopy: 1) improved accuracy of tissue qualification with 4-10x increase in field of view that reduces sampling error – this will provides a truer assessment of the overall tissue characteristics; 2) ability to simultaneously measure corneal thickness, quantify endothelial cell density, and identify morphological variations due to corneal disease – this will lead to complete corneal evaluation in a single instrument; 3) leveraging machine learning innovations to minimize variability induced by users – this will result in a more objective evaluation; 4) enhanced 3D cellular-level imaging of thin translucent endothelial cells – this will enable a detailed understanding of cell viability. The results of the proposed Phase studies II will demonstrate that GDOCM can provide high-definition, 3D visualization of corneal structures with immediate commercial application for qualification of donor tissue in eye banks, and with a path to in vivo clinical imaging of patients with corneal disease. Current corneal evaluation methods employed at eye banks have limited field of view and/or insufficient resolution, and their results suffer from high subjectivity. We propose to commercialize a Gabor-domain optical coherence microscope to enable non-invasive, high-definition, wide field of view imaging in 3D for eye banks.","High-definition, wide field of view corneal imaging",10007064,R44EY028827,"['3-Dimensional', 'Address', 'Area', 'Assessment tool', 'Blindness', 'Cell Count', 'Cell Density', 'Cell Survival', 'Cell Viability Process', 'Cellular Morphology', 'Characteristics', 'Clinic', 'Confocal Microscopy', 'Cornea', 'Corneal Diseases', 'Disease', 'Endothelial Cells', 'Evaluation', 'Eye', 'Eye Banks', 'Goals', 'Gold', 'Grant', 'Health', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Industry', 'Infection', 'Innovation Corps', 'International', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Ophthalmology', 'Optics', 'Organ Transplantation', 'Patient imaging', 'Phase', 'Positioning Attribute', 'Process', 'Research', 'Resolution', 'Rights', 'Sampling', 'Sampling Errors', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'Technology', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Transplantation', 'Tissues', 'Training', 'Transplantation', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visual', 'Visual impairment', 'Visual system structure', 'Visualization software', 'base', 'clinical development', 'clinical imaging', 'commercial application', 'density', 'image processing', 'improved', 'in vivo', 'in vivo regeneration', 'innovation', 'instrument', 'instrumentation', 'microscopic imaging', 'multidisciplinary', 'neurosensory', 'novel', 'phase 2 study', 'programs', 'prototype', 'screening', 'three-dimensional visualization', 'tool', 'trend']",NEI,LIGHTOPTECH CORPORATION,R44,2020,795732,0.05090783233060682
"High-definition, wide field of view corneal imaging The cornea is the primary focusing structure of our visual system. Infections and diseases in the tissue can impair vision and lead to blindness, even in eyes with intact neurosensory function. Corneal disease is one of the leading causes of visual deficiency and blindness in the world. Tissue evaluation is an important step for assessing the health of the donor cornea and its appropriateness for different types of placement, yet this process suffers from high subjectivity. High-definition corneal imaging is needed to assist in selection of the most appropriate tissue for transplant. Progress on this front would greatly serve public need, as the cornea is the most commonly transplanted tissue worldwide, with nearly 185,000 transplants annually. Thus, a more sensitive and quantitative method for objective evaluation of tissue at eye banks is needed. We have developed a 3D high-definition imaging instrument based on Gabor-Domain Optical Coherence Microscopy (GDOCM). Our SBIR Phase I research successfully accomplished all Aims and demonstrated the feasibility of quantitative assessment of corneal tissue over a large field of view with GDOCM. Our Phase I results demonstrated that GDOCM has the following key advantages over existing corneal imaging techniques, which include specular and confocal microscopy: 1) improved accuracy of tissue qualification with 4-10x increase in field of view that reduces sampling error – this will provides a truer assessment of the overall tissue characteristics; 2) ability to simultaneously measure corneal thickness, quantify endothelial cell density, and identify morphological variations due to corneal disease – this will lead to complete corneal evaluation in a single instrument; 3) leveraging machine learning innovations to minimize variability induced by users – this will result in a more objective evaluation; 4) enhanced 3D cellular-level imaging of thin translucent endothelial cells – this will enable a detailed understanding of cell viability. The results of the proposed Phase studies II will demonstrate that GDOCM can provide high-definition, 3D visualization of corneal structures with immediate commercial application for qualification of donor tissue in eye banks, and with a path to in vivo clinical imaging of patients with corneal disease. Current corneal evaluation methods employed at eye banks have limited field of view and/or insufficient resolution, and their results suffer from high subjectivity. We propose to commercialize a Gabor-domain optical coherence microscope to enable non-invasive, high-definition, wide field of view imaging in 3D for eye banks.","High-definition, wide field of view corneal imaging",10239347,R44EY028827,"['3-Dimensional', 'Address', 'Area', 'Assessment tool', 'Blindness', 'Cell Count', 'Cell Density', 'Cell Survival', 'Cell Viability Process', 'Cellular Morphology', 'Characteristics', 'Clinic', 'Confocal Microscopy', 'Cornea', 'Corneal Diseases', 'Disease', 'Endothelial Cells', 'Evaluation', 'Eye', 'Eye Banks', 'Goals', 'Gold', 'Grant', 'Health', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Industry', 'Infection', 'Innovation Corps', 'International', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Ophthalmology', 'Optics', 'Organ Transplantation', 'Patient imaging', 'Phase', 'Positioning Attribute', 'Process', 'Research', 'Resolution', 'Rights', 'Sampling', 'Sampling Errors', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'Technology', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Transplantation', 'Tissues', 'Training', 'Transplantation', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visual', 'Visual impairment', 'Visual system structure', 'Visualization software', 'base', 'clinical development', 'clinical imaging', 'commercial application', 'density', 'image processing', 'improved', 'in vivo', 'in vivo regeneration', 'innovation', 'instrument', 'instrumentation', 'microscopic imaging', 'multidisciplinary', 'neurosensory', 'novel', 'phase 2 study', 'programs', 'prototype', 'screening', 'three-dimensional visualization', 'tool', 'trend']",NEI,LIGHTOPTECH CORPORATION,R44,2020,178785,0.05090783233060682
"Virtual prototyping for retinal prosthesis patients Project Summary/Abstract Retinal dystrophies such as retinitis pigmentosa and macular degeneration induce progressive loss of photoreceptors, resulting in profound visual impairment in more than ten million people worldwide. Visual neuroprostheses (‘bionic eyes’) aim to restore functional vision by electrically stimulating remaining cells in the retina, analogous to cochlear implants. A wide variety of neuroprostheses are either in development (e.g. optogenetics, cortical) or are being implanted in patients (e.g. subretinal or epiretinal electrical). A limiting factor that affects all device types are perceptual distortions and subsequent loss of information, caused by interactions between the implant technology and the underlying neurophysiology. Understanding the causes of these distortions and finding ways to alleviate them is critically important to the success of current and future sight restoration technologies. In this proposal, human visual psychophysics, computational modeling, data-driven approaches, and virtual reality (VR) will be combined to develop and experimentally validate optimized stimulation protocols for epiretinal prostheses. This approach is analogous to virtual prototyping for airplanes and other complex systems: to use a high-quality model of both the implant electronics and the visual system in order to generate a ‘virtual patient’. Retinal electrophysiological and visual behavioral data will be used to develop and validate a computational model of the expected visual experience of patients when electrically stimulated. One way of using this model will be to generate simulations of the expected perceptual outcome of electrical stimulation across a wide variety of electrical stimulation patterns. These will be used as a training set for machine learning algorithms that will invert the input-output function of the model to find the electrical stimulation protocol that best replicates any desired perceptual experience. The model can also be used to simulate the expected perceptual experience of real patients by using sighted subjects in a VR environment – ‘VR virtual patients’. These virtual patients will be used to discover preprocessing methods (e.g., edge enhancement, retargeting, decluttering) that improve behavioral performance in VR. Although current retinal prostheses have been implanted in over 250 patients worldwide, experimentation with improved stimulation protocols remains challenging and expensive. Implementing ‘virtual patients’ in VR offers an affordable and practical alternative for high-throughput experiments to test new stimulation protocols. Stimulation protocols that result in good VR performance will be experimentally validated in real prosthesis patients in collaboration with Second Sight Medical Products Inc. and Pixium Vision, two leading device manufacturers in the field. This work has the potential to significantly improve the effectiveness of visual neuroprostheses as a treatment option for individuals suffering from blinding retinal diseases. Project Narrative Inadequate stimulation paradigms are currently one of the main factors limiting the effectiveness of visual prostheses as a treatment option for individuals suffering from blinding retinal diseases. My goal is to develop and validate novel stimulation protocols for visual prosthesis patients that minimize perceptual distortions and thereby improve behavioral performance. Developing methods for generating better stimulation protocols through a combination of behavioral testing, virtual reality, computational modeling, and machine learning, has the potential to provide a transformative improvement of this device technology.",Virtual prototyping for retinal prosthesis patients,10200240,R00EY029329,"['Affect', 'Behavioral', 'Bionics', 'Cells', 'Clinical Trials', 'Cochlear Implants', 'Collaborations', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Data', 'Development', 'Devices', 'Effectiveness', 'Electric Stimulation', 'Electrodes', 'Electronics', 'Electrophysiology (science)', 'Eye', 'Eye Movements', 'Family', 'Financial compensation', 'Future', 'Goals', 'Head', 'Human', 'Implant', 'In Vitro', 'Individual', 'Knowledge', 'Learning', 'Letters', 'Machine Learning', 'Macular degeneration', 'Manufacturer Name', 'Medical', 'Medicare', 'Methods', 'Modeling', 'Motion', 'Neurons', 'Ocular Prosthesis', 'Online Systems', 'Outcome', 'Output', 'Patients', 'Pattern', 'Perceptual distortions', 'Performance', 'Photoreceptors', 'Prosthesis', 'Prosthesis Design', 'Protocols documentation', 'Psychophysics', 'Rehabilitation therapy', 'Reporting', 'Retina', 'Retinal Diseases', 'Retinal Dystrophy', 'Retinitis Pigmentosa', 'Schedule', 'Severities', 'Shapes', 'Specialist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Psychophysics', 'Visual impairment', 'Visual system structure', 'Visualization', 'Work', 'base', 'behavior measurement', 'behavior test', 'deep neural network', 'design', 'experience', 'experimental study', 'gaze', 'implantation', 'improved', 'machine learning algorithm', 'neurophysiology', 'neuroprosthesis', 'novel', 'object recognition', 'optogenetics', 'predictive modeling', 'prototype', 'regression algorithm', 'restoration', 'retinal prosthesis', 'simulation', 'spatiotemporal', 'success', 'virtual', 'virtual reality', 'virtual reality environment']",NEI,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R00,2020,247272,0.0749786620525675
"Virtual prototyping for retinal prosthesis patients Project Summary/Abstract Retinal dystrophies such as retinitis pigmentosa and macular degeneration induce progressive loss of photoreceptors, resulting in profound visual impairment in more than ten million people worldwide. Visual neuroprostheses (‘bionic eyes’) aim to restore functional vision by electrically stimulating remaining cells in the retina, analogous to cochlear implants. A wide variety of neuroprostheses are either in development (e.g. optogenetics, cortical) or are being implanted in patients (e.g. subretinal or epiretinal electrical). A limiting factor that affects all device types are perceptual distortions and subsequent loss of information, caused by interactions between the implant technology and the underlying neurophysiology. Understanding the causes of these distortions and finding ways to alleviate them is critically important to the success of current and future sight restoration technologies. In this proposal, human visual psychophysics, computational modeling, data-driven approaches, and virtual reality (VR) will be combined to develop and experimentally validate optimized stimulation protocols for epiretinal prostheses. This approach is analogous to virtual prototyping for airplanes and other complex systems: to use a high-quality model of both the implant electronics and the visual system in order to generate a ‘virtual patient’. Retinal electrophysiological and visual behavioral data will be used to develop and validate a computational model of the expected visual experience of patients when electrically stimulated. One way of using this model will be to generate simulations of the expected perceptual outcome of electrical stimulation across a wide variety of electrical stimulation patterns. These will be used as a training set for machine learning algorithms that will invert the input-output function of the model to find the electrical stimulation protocol that best replicates any desired perceptual experience. The model can also be used to simulate the expected perceptual experience of real patients by using sighted subjects in a VR environment – ‘VR virtual patients’. These virtual patients will be used to discover preprocessing methods (e.g., edge enhancement, retargeting, decluttering) that improve behavioral performance in VR. Although current retinal prostheses have been implanted in over 250 patients worldwide, experimentation with improved stimulation protocols remains challenging and expensive. Implementing ‘virtual patients’ in VR offers an affordable and practical alternative for high-throughput experiments to test new stimulation protocols. Stimulation protocols that result in good VR performance will be experimentally validated in real prosthesis patients in collaboration with Second Sight Medical Products Inc. and Pixium Vision, two leading device manufacturers in the field. This work has the potential to significantly improve the effectiveness of visual neuroprostheses as a treatment option for individuals suffering from blinding retinal diseases. Project Narrative Inadequate stimulation paradigms are currently one of the main factors limiting the effectiveness of visual prostheses as a treatment option for individuals suffering from blinding retinal diseases. My goal is to develop and validate novel stimulation protocols for visual prosthesis patients that minimize perceptual distortions and thereby improve behavioral performance. Developing methods for generating better stimulation protocols through a combination of behavioral testing, virtual reality, computational modeling, and machine learning, has the potential to provide a transformative improvement of this device technology.",Virtual prototyping for retinal prosthesis patients,9756406,K99EY029329,"['Affect', 'Behavioral', 'Bionics', 'Cells', 'Clinical Trials', 'Cochlear Implants', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Devices', 'Effectiveness', 'Electric Stimulation', 'Electrodes', 'Electronics', 'Electrophysiology (science)', 'Eye', 'Eye Movements', 'Family', 'Financial compensation', 'Future', 'Goals', 'Head', 'Human', 'Imagery', 'Implant', 'In Vitro', 'Individual', 'Knowledge', 'Learning', 'Letters', 'Machine Learning', 'Macular degeneration', 'Manufacturer Name', 'Medical', 'Medicare', 'Methods', 'Modeling', 'Motion', 'Neurons', 'Ocular Prosthesis', 'Online Systems', 'Outcome', 'Output', 'Patients', 'Pattern', 'Perceptual distortions', 'Performance', 'Photoreceptors', 'Prosthesis', 'Prosthesis Design', 'Protocols documentation', 'Psychophysics', 'Rehabilitation therapy', 'Reporting', 'Retina', 'Retinal', 'Retinal Diseases', 'Retinal Dystrophy', 'Retinitis Pigmentosa', 'Schedule', 'Severities', 'Shapes', 'Specialist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Psychophysics', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'behavior measurement', 'behavior test', 'deep neural network', 'design', 'experience', 'experimental study', 'gaze', 'implantation', 'improved', 'machine learning algorithm', 'neurophysiology', 'neuroprosthesis', 'novel', 'object recognition', 'optogenetics', 'predictive modeling', 'prototype', 'regression algorithm', 'restoration', 'retinal prosthesis', 'simulation', 'spatiotemporal', 'success', 'virtual', 'virtual reality']",NEI,UNIVERSITY OF WASHINGTON,K99,2019,122039,0.0749786620525675
"Virtual prototyping for retinal prosthesis patients Project Summary/Abstract Retinal dystrophies such as retinitis pigmentosa and macular degeneration induce progressive loss of photoreceptors, resulting in profound visual impairment in more than ten million people worldwide. Visual neuroprostheses (‘bionic eyes’) aim to restore functional vision by electrically stimulating remaining cells in the retina, analogous to cochlear implants. A wide variety of neuroprostheses are either in development (e.g. optogenetics, cortical) or are being implanted in patients (e.g. subretinal or epiretinal electrical). A limiting factor that affects all device types are perceptual distortions and subsequent loss of information, caused by interactions between the implant technology and the underlying neurophysiology. Understanding the causes of these distortions and finding ways to alleviate them is critically important to the success of current and future sight restoration technologies. In this proposal, human visual psychophysics, computational modeling, data-driven approaches, and virtual reality (VR) will be combined to develop and experimentally validate optimized stimulation protocols for epiretinal prostheses. This approach is analogous to virtual prototyping for airplanes and other complex systems: to use a high-quality model of both the implant electronics and the visual system in order to generate a ‘virtual patient’. Retinal electrophysiological and visual behavioral data will be used to develop and validate a computational model of the expected visual experience of patients when electrically stimulated. One way of using this model will be to generate simulations of the expected perceptual outcome of electrical stimulation across a wide variety of electrical stimulation patterns. These will be used as a training set for machine learning algorithms that will invert the input-output function of the model to find the electrical stimulation protocol that best replicates any desired perceptual experience. The model can also be used to simulate the expected perceptual experience of real patients by using sighted subjects in a VR environment – ‘VR virtual patients’. These virtual patients will be used to discover preprocessing methods (e.g., edge enhancement, retargeting, decluttering) that improve behavioral performance in VR. Although current retinal prostheses have been implanted in over 250 patients worldwide, experimentation with improved stimulation protocols remains challenging and expensive. Implementing ‘virtual patients’ in VR offers an affordable and practical alternative for high-throughput experiments to test new stimulation protocols. Stimulation protocols that result in good VR performance will be experimentally validated in real prosthesis patients in collaboration with Second Sight Medical Products Inc. and Pixium Vision, two leading device manufacturers in the field. This work has the potential to significantly improve the effectiveness of visual neuroprostheses as a treatment option for individuals suffering from blinding retinal diseases. Project Narrative Inadequate stimulation paradigms are currently one of the main factors limiting the effectiveness of visual prostheses as a treatment option for individuals suffering from blinding retinal diseases. My goal is to develop and validate novel stimulation protocols for visual prosthesis patients that minimize perceptual distortions and thereby improve behavioral performance. Developing methods for generating better stimulation protocols through a combination of behavioral testing, virtual reality, computational modeling, and machine learning, has the potential to provide a transformative improvement of this device technology.",Virtual prototyping for retinal prosthesis patients,9581681,K99EY029329,"['Affect', 'Algorithms', 'Behavioral', 'Bionics', 'Cells', 'Clinical Trials', 'Cochlear Implants', 'Collaborations', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Devices', 'Effectiveness', 'Electric Stimulation', 'Electrodes', 'Electronics', 'Electrophysiology (science)', 'Eye', 'Eye Movements', 'Family', 'Financial compensation', 'Future', 'Goals', 'Head', 'Human', 'Imagery', 'Implant', 'In Vitro', 'Individual', 'Knowledge', 'Learning', 'Letters', 'Machine Learning', 'Macular degeneration', 'Manufacturer Name', 'Medical', 'Medicare', 'Methods', 'Modeling', 'Motion', 'Neurons', 'Ocular Prosthesis', 'Online Systems', 'Outcome', 'Output', 'Patients', 'Pattern', 'Perceptual distortions', 'Performance', 'Photoreceptors', 'Prosthesis', 'Prosthesis Design', 'Protocols documentation', 'Psychophysics', 'Rehabilitation therapy', 'Reporting', 'Retina', 'Retinal', 'Retinal Diseases', 'Retinal Dystrophy', 'Retinitis Pigmentosa', 'Schedule', 'Severities', 'Shapes', 'Specialist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Vision', 'Visual', 'Visual Psychophysics', 'Visual impairment', 'Visual system structure', 'Work', 'base', 'behavior measurement', 'behavior test', 'deep neural network', 'design', 'experience', 'experimental study', 'gaze', 'implantation', 'improved', 'neurophysiology', 'neuroprosthesis', 'novel', 'object recognition', 'optogenetics', 'predictive modeling', 'prototype', 'restoration', 'retinal prosthesis', 'simulation', 'spatiotemporal', 'success', 'virtual', 'virtual reality']",NEI,UNIVERSITY OF WASHINGTON,K99,2018,122763,0.0749786620525675
"CRCNS: Joint coding of shape and texture in the primate brian PROJECT DESCRIPTION  Collaborating Pis and Consultant  United States  Pl: Anitha Pasupathy, Dept. of Biological Structure, University of Washington, Seattle, USA  Co-Pl: Wyeth Bair, Dept. of Biological Structure, University of Washington, Seattle, USA Japan  Pl: lsamu Motoyoshi, Dept. of Life Sciences, The University of Tokyo, Japan  Consultant: Hidehiko Komatsu, Tamagawa University, Japan  Specific Aims  Our visual system endows us with a diverse set of abilities: to recognize and manipulate  objects, avoid obstacles and danger during navigation, evaluate the quality of food, read text,  interpret facial expressions, etc. This relies on the neuronal processing of information about  form and material texture along the ventral pathway of the primate visual system (Ungerleider &  Mishkin, 1982; Felleman & Van Essen, 1991). Studies over the past several decades have  produced detailed models of how visual information is processed in V1, the earliest stage along . this pathway (Hubel & Wiesel, 1959, 1968; Movshon et al., 1978a, b; Albrecht et al., 1980), but  beyond V1 our understanding of visual processing and representation is limited. This is  particularly true with regard to our understanding of how visual representations of form and  texture jointly contribute to object perception and recognition. The broad goal of this proposal is  two-fold-to develop an experimentally-driven image-computable model for how naturalistic  visual stimuli are processed in area V4, an important intermediate stage along the ventral visual  pathway (Aim 1) and to discover how such a representation contributes to perception (Aim 2).  Past studies have shown that V4 neurons are sensitive to both the form (Desimone and Schein,  1987; Kobatake and Tanaka, 1994; Gallant et al., 1993; Pasupathy and Connor, 2001; Nandy et  al., 2013) and the surface texture of visual stimuli (Arcizet et al., 2008; Goda et al., 2014;  Okazawa et al., 2015). But, because expertise is narrow and experimental time limited,  scientists tend to focus exclusively on the encoding of form or texture and not on their joint  coding. For example, in the laboratories of the USA portion of this collaboration, we have until  now focused on form processing by carrying out neurophysiological studies using 2D shapes  with uniform surface properties to investigate how object boundaries are encoded (Oleskiw et  al., 2014; Popovkina et al., 2016). We have modeled our data by comparing the representation  of V4 neurons to that of the units in AlexNet (Pospisil et al., 2015), a prominent convolutional  neural net (CNN) trained to recognize objects (Krizhevsky et al., 2012). At the same time, the  Japanese contingent of this collaboration has investigated the encoding of surface texture and  gloss in human perception without associated form encoding (Motoyoshi et al., 2007; Sharan et  al., 2008; Motoyoshi, 2010; Motoyoshi & Matoba, 2012). Here we propose to bring our  respective expertise in studying form and texture encoding to bear on the question of how  naturalistic stimuli with both form and surface cues are encoded in area V4 and how these  representations support human visual perception. Our specific aims are:  Aim1. To build a unified image-computable model for neuronal responses to shapes and  textures in area V4  V4 responses to 2D shapes with uniform luminance/chromatic characteristics can be explained  by a hierarchical-Max (HMax) model for object recognition that emphasizes boundary features  (Cadieu et al., 2007). Such responses can also be explained by units in artificial deep  convolutional networks, in which boundary features are not explicitly emphasized (all features  are learned from initially random weights). On the other hand, V4 responses to texture patches  can be well explained by a higher-order image-statistics-based model (Okazawa et al., 2015).  Using shape data from the Pasupathy lab and texture data from the Komatsu lab (Japanese  consultant), we will ask whether responses of V4 neurons to shapes and textures can be Page 21 n/a",CRCNS: Joint coding of shape and texture in the primate brian,9994299,R01EY029997,"['3-Dimensional', 'Biological', 'Biological Sciences', 'Categories', 'Characteristics', 'Code', 'Collaborations', 'Computer Models', 'Computers', 'Cues', 'Data', 'Dimensions', 'Discrimination', 'Facial Expression', 'Goals', 'Human', 'Image', 'Individual', 'Japan', 'Japanese Population', 'Joints', 'Laboratories', 'Modeling', 'Modification', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Physiology', 'Primates', 'Process', 'Psychophysics', 'Scientist', 'Shapes', 'Stimulus', 'Structure', 'Subgroup', 'Surface', 'Surface Properties', 'Text', 'Texture', 'Time', 'Tokyo', 'Training', 'United States', 'Universities', 'V4 neuron', 'Visual', 'Visual Pathways', 'Visual Perception', 'Visual system structure', 'Washington', 'Weight', 'area V4', 'base', 'convolutional neural network', 'experimental study', 'food quality', 'human model', 'human subject', 'information processing', 'luminance', 'neurophysiology', 'novel', 'object perception', 'object recognition', 'response', 'statistics', 'visual information', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2020,230475,0.0890316410967768
"CRCNS: Joint coding of shape and texture in the primate brian PROJECT DESCRIPTION  Collaborating Pis and Consultant  United States  Pl: Anitha Pasupathy, Dept. of Biological Structure, University of Washington, Seattle, USA  Co-Pl: Wyeth Bair, Dept. of Biological Structure, University of Washington, Seattle, USA Japan  Pl: lsamu Motoyoshi, Dept. of Life Sciences, The University of Tokyo, Japan  Consultant: Hidehiko Komatsu, Tamagawa University, Japan  Specific Aims  Our visual system endows us with a diverse set of abilities: to recognize and manipulate  objects, avoid obstacles and danger during navigation, evaluate the quality of food, read text,  interpret facial expressions, etc. This relies on the neuronal processing of information about  form and material texture along the ventral pathway of the primate visual system (Ungerleider &  Mishkin, 1982; Felleman & Van Essen, 1991). Studies over the past several decades have  produced detailed models of how visual information is processed in V1, the earliest stage along . this pathway (Hubel & Wiesel, 1959, 1968; Movshon et al., 1978a, b; Albrecht et al., 1980), but  beyond V1 our understanding of visual processing and representation is limited. This is  particularly true with regard to our understanding of how visual representations of form and  texture jointly contribute to object perception and recognition. The broad goal of this proposal is  two-fold-to develop an experimentally-driven image-computable model for how naturalistic  visual stimuli are processed in area V4, an important intermediate stage along the ventral visual  pathway (Aim 1) and to discover how such a representation contributes to perception (Aim 2).  Past studies have shown that V4 neurons are sensitive to both the form (Desimone and Schein,  1987; Kobatake and Tanaka, 1994; Gallant et al., 1993; Pasupathy and Connor, 2001; Nandy et  al., 2013) and the surface texture of visual stimuli (Arcizet et al., 2008; Goda et al., 2014;  Okazawa et al., 2015). But, because expertise is narrow and experimental time limited,  scientists tend to focus exclusively on the encoding of form or texture and not on their joint  coding. For example, in the laboratories of the USA portion of this collaboration, we have until  now focused on form processing by carrying out neurophysiological studies using 2D shapes  with uniform surface properties to investigate how object boundaries are encoded (Oleskiw et  al., 2014; Popovkina et al., 2016). We have modeled our data by comparing the representation  of V4 neurons to that of the units in AlexNet (Pospisil et al., 2015), a prominent convolutional  neural net (CNN) trained to recognize objects (Krizhevsky et al., 2012). At the same time, the  Japanese contingent of this collaboration has investigated the encoding of surface texture and  gloss in human perception without associated form encoding (Motoyoshi et al., 2007; Sharan et  al., 2008; Motoyoshi, 2010; Motoyoshi & Matoba, 2012). Here we propose to bring our  respective expertise in studying form and texture encoding to bear on the question of how  naturalistic stimuli with both form and surface cues are encoded in area V4 and how these  representations support human visual perception. Our specific aims are:  Aim1. To build a unified image-computable model for neuronal responses to shapes and  textures in area V4  V4 responses to 2D shapes with uniform luminance/chromatic characteristics can be explained  by a hierarchical-Max (HMax) model for object recognition that emphasizes boundary features  (Cadieu et al., 2007). Such responses can also be explained by units in artificial deep  convolutional networks, in which boundary features are not explicitly emphasized (all features  are learned from initially random weights). On the other hand, V4 responses to texture patches  can be well explained by a higher-order image-statistics-based model (Okazawa et al., 2015).  Using shape data from the Pasupathy lab and texture data from the Komatsu lab (Japanese  consultant), we will ask whether responses of V4 neurons to shapes and textures can be Page 21 n/a",CRCNS: Joint coding of shape and texture in the primate brian,9765318,R01EY029997,"['Biological', 'Biological Sciences', 'Categories', 'Characteristics', 'Code', 'Collaborations', 'Computer Simulation', 'Computers', 'Cues', 'Data', 'Dimensions', 'Discrimination', 'Facial Expression', 'Goals', 'Human', 'Image', 'Individual', 'Japan', 'Japanese Population', 'Joints', 'Laboratories', 'Modeling', 'Modification', 'Monkeys', 'Neurons', 'Pathway interactions', 'Perception', 'Performance', 'Physiology', 'Primates', 'Process', 'Psychophysics', 'Scientist', 'Shapes', 'Stimulus', 'Structure', 'Subgroup', 'Surface', 'Surface Properties', 'Text', 'Texture', 'Time', 'Tokyo', 'Training', 'United States', 'Universities', 'V4 neuron', 'Visual', 'Visual Pathways', 'Visual Perception', 'Visual system structure', 'Washington', 'Weight', 'area V4', 'base', 'convolutional neural network', 'experimental study', 'food quality', 'human model', 'human subject', 'information processing', 'luminance', 'neurophysiology', 'novel', 'object perception', 'object recognition', 'response', 'statistics', 'visual information', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2019,230475,0.0890316410967768
"Structural and functional tests of ganglion cell damage in glaucoma This project will use a combination of structural and functional measurements to test the hypothesis that early- stage damage in human glaucoma occurs first in the inner plexiform layer (IPL) of the retina – especially its OFF sub-lamina – as suggested by murine glaucoma models. In the first Aim, we will use a novel visible-light optical coherence tomograph (VIS OCT) to study structural changes in the retina of glaucoma patients. The newly developed VIS OCT has sufficient image contrast and resolution to segment the IPL boundaries and to define sub-lamination in volumetric OCT data, something not currently possible with existing near-infrared OCT instruments. We will make comparative measurements within the IPL and between the IPL, the ganglion cell layer (GCL) and the retinal nerve fiber layer (RNFL). Because data from mouse models of glaucoma suggests that early damage occurs preferentially within the OFF sub-lamina of the IPL, we will make separate VIS OCT measurements biased for the OFF- and ON-sublaminae of the IPL and use machine learning approaches to determine whether a similar damage process can be demonstrated in human. To test whether OFF-pathway function is preferentially lost in glaucoma, we will use a novel Steady-State Visual Evoked Potential (SSVEP) paradigm that employs sawtooth increments and decrements to bias the measurement to ON vs OFF pathways, respectively, a paradigm our data suggests discriminates glaucoma from control patients. The second Aim will optimize this SSVEP measurement for testing localized areas of the visual field. The third Aim will make comparative measurements of visual-field, VIS OCT and SSVEP loss patterns in a large sample of glaucoma patients and in age- and sex-matched controls. Thickness and interface reflectivity amplitude maps derived from VIS OCT imaging of the RNFL, GCL and IPL including sublaminae will be correlated topographically with visual field defects to assess the relative sensitivity of our structural biomarkers at and near visual field locations with demonstrable losses on conventional (Humphrey) perimetry. Similarly, SSVEP responses from different locations in the visual field will be correlated topographically with visual field loss patterns and to VIS OCT losses, with special emphasis on correlating structural damage in OFF vs ON sub-laminae of the IPL with the functional correlates derived from regional decremental and incremental SSVEPs. Separately and in combination, our structural and functional measurements are designed to provide strong tests of the biological hypothesis that the OFF pathway is preferentially damaged in human glaucoma, and to reveal new biomarkers for the disease. Improving visual outcomes in glaucoma will require a better understanding of the earliest sites and processes of damage and methods to measure them quickly and accurately in patients. This project will address both needs through a combination of novel Optical Coherence Tomography and electrophysiological measurements. The new imaging and electrophysiological tests that will be developed here, either separately or together, could eventually replace conventional visual field testing which is time-consuming and unreliable.",Structural and functional tests of ganglion cell damage in glaucoma,9913546,R01EY030361,"['Address', 'Affect', 'Age', 'Animal Model', 'Area', 'Atrophic', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Clinical', 'Complex', 'Consumption', 'Data', 'Disease', 'Early Diagnosis', 'Early treatment', 'Economic Burden', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Frequencies', 'Ganglion Cell Layer', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Inner Plexiform Layer', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modification', 'Mus', 'Noise', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Perimetry', 'Process', 'Property', 'Resolution', 'Retina', 'Retinal Ganglion Cells', 'Rodent Model', 'Sampling', 'Scotoma', 'Severities', 'Signal Transduction', 'Site', 'Specificity', 'Speed', 'Structural defect', 'Structure', 'Synapses', 'Techniques', 'Testing', 'Thick', 'Time', 'Visible Radiation', 'Vision', 'Visual', 'Visual Fields', 'Visual evoked cortical potential', 'base', 'cell injury', 'comparative', 'contrast imaging', 'design', 'extrastriate visual cortex', 'field study', 'ganglion cell', 'improved', 'instrument', 'mouse model', 'novel', 'optic nerve disorder', 'response', 'retinal imaging', 'retinal nerve fiber layer', 'sex']",NEI,STANFORD UNIVERSITY,R01,2020,521102,0.21563236329442112
"Structural and functional tests of ganglion cell damage in glaucoma This project will use a combination of structural and functional measurements to test the hypothesis that early- stage damage in human glaucoma occurs first in the inner plexiform layer (IPL) of the retina – especially its OFF sub-lamina – as suggested by murine glaucoma models. In the first Aim, we will use a novel visible-light optical coherence tomograph (VIS OCT) to study structural changes in the retina of glaucoma patients. The newly developed VIS OCT has sufficient image contrast and resolution to segment the IPL boundaries and to define sub-lamination in volumetric OCT data, something not currently possible with existing near-infrared OCT instruments. We will make comparative measurements within the IPL and between the IPL, the ganglion cell layer (GCL) and the retinal nerve fiber layer (RNFL). Because data from mouse models of glaucoma suggests that early damage occurs preferentially within the OFF sub-lamina of the IPL, we will make separate VIS OCT measurements biased for the OFF- and ON-sublaminae of the IPL and use machine learning approaches to determine whether a similar damage process can be demonstrated in human. To test whether OFF-pathway function is preferentially lost in glaucoma, we will use a novel Steady-State Visual Evoked Potential (SSVEP) paradigm that employs sawtooth increments and decrements to bias the measurement to ON vs OFF pathways, respectively, a paradigm our data suggests discriminates glaucoma from control patients. The second Aim will optimize this SSVEP measurement for testing localized areas of the visual field. The third Aim will make comparative measurements of visual-field, VIS OCT and SSVEP loss patterns in a large sample of glaucoma patients and in age- and sex-matched controls. Thickness and interface reflectivity amplitude maps derived from VIS OCT imaging of the RNFL, GCL and IPL including sublaminae will be correlated topographically with visual field defects to assess the relative sensitivity of our structural biomarkers at and near visual field locations with demonstrable losses on conventional (Humphrey) perimetry. Similarly, SSVEP responses from different locations in the visual field will be correlated topographically with visual field loss patterns and to VIS OCT losses, with special emphasis on correlating structural damage in OFF vs ON sub-laminae of the IPL with the functional correlates derived from regional decremental and incremental SSVEPs. Separately and in combination, our structural and functional measurements are designed to provide strong tests of the biological hypothesis that the OFF pathway is preferentially damaged in human glaucoma, and to reveal new biomarkers for the disease. Improving visual outcomes in glaucoma will require a better understanding of the earliest sites and processes of damage and methods to measure them quickly and accurately in patients. This project will address both needs through a combination of novel Optical Coherence Tomography and electrophysiological measurements. The new imaging and electrophysiological tests that will be developed here, either separately or together, could eventually replace conventional visual field testing which is time-consuming and unreliable.",Structural and functional tests of ganglion cell damage in glaucoma,9765006,R01EY030361,"['Address', 'Affect', 'Age', 'Animal Model', 'Area', 'Atrophic', 'Biological Assay', 'Biological Markers', 'Biological Testing', 'Clinical', 'Complex', 'Consumption', 'Data', 'Disease', 'Early Diagnosis', 'Early treatment', 'Economic Burden', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Frequencies', 'Ganglion Cell Layer', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Inner Plexiform Layer', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Modification', 'Mus', 'Noise', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathway interactions', 'Patients', 'Pattern', 'Perimetry', 'Process', 'Property', 'Resolution', 'Retina', 'Retinal', 'Retinal Ganglion Cells', 'Rodent Model', 'Sampling', 'Scotoma', 'Severities', 'Signal Transduction', 'Site', 'Specificity', 'Speed', 'Structural defect', 'Structure', 'Synapses', 'Techniques', 'Testing', 'Thick', 'Time', 'Visible Radiation', 'Vision', 'Visual', 'Visual Fields', 'Visual evoked cortical potential', 'base', 'cell injury', 'comparative', 'contrast imaging', 'design', 'extrastriate visual cortex', 'field study', 'ganglion cell', 'improved', 'instrument', 'mouse model', 'novel', 'optic nerve disorder', 'response', 'retinal imaging', 'retinal nerve fiber layer', 'sex']",NEI,STANFORD UNIVERSITY,R01,2019,551932,0.21563236329442112
"Natural image processing in the visual cortex Project Summary Signals from the natural environment are processed by neuronal populations in the cortex. Understanding the relationship between those signals and cortical activity is central to understanding normal cortical function and how it is impaired in psychiatric and neurodevelopmental disorders. Substantial progress has been made in elucidating cortical processing of simple, parametric stimuli, and computational technology is improving descriptions of neural responses to naturalistic stimuli. However, how cortical populations encode the complex, natural inputs received during every day perceptual experience is largely unknown. This project aims to elucidate how natural visual inputs are represented by neuronal populations in primary visual cortex (V1). Progress to date has been limited primarily by two factors. First, during natural vision, the inputs to V1 neurons are always embedded in a spatial and temporal context, but how V1 integrates this contextual information in natural visual inputs is poorly understood. Second, prior work focused almost exclusively on single-neuron firing rate, but to understand cortical representations one must consider the structure of population activity— the substantial trial-to-trial variability that is shared among neurons and evolves dynamically—as this structure influences population information and perception. The central hypothesis of this project is that cortical response structure is modulated by visual context to approximate an optimal representation of natural visual inputs. To test the hypothesis, this project combines machine learning to quantify the statistical properties of natural visual inputs, with a theory of how cortical populations should encode those images to achieve an optimal representation, to arrive at concrete, falsifiable predictions for V1 response structure. The predictions will be tested with measurements of population activity in V1 of awake monkeys viewing natural images and movies. Specific Aim 1 will determine whether modulation of V1 response structure by spatial context in static images is consistent with optimal encoding of those images, and will compare the predictive power of the proposed model to alternative models. Specific Aim 2 addresses V1 encoding of dynamic natural inputs, and will test whether modulation of V1 activity by temporal context is tuned to the temporal structure of natural sensory signals, as required for optimality. As both spatial and temporal are present simultaneously during natural vision, Specific Aim 3 will determine visual input statistics in free-viewing animals, and test space-time interactions in V1 activity evoked by those inputs. This project will provide the first test of a unified functional theory of contextual modulation in V1 encoding of natural visual inputs, and shed light on key aspects of natural vision that have been neglected to date. Project Narrative This project aims to determine how neurons in the visual cortex represent the inputs encountered during perceptual experience in the natural environment, through correct integration of visual information across space and time. In individuals with neurodevelopmental and psychiatric disorders, integration is often miscalibrated leading to perceptual impairments. Our study will advance knowledge of the relationship between natural sensory inputs and cortical activity, which is central to understanding normal cortical function and how it is impaired in patient populations.",Natural image processing in the visual cortex,10018026,R01EY030578,"['Address', 'Animal Testing', 'Area', 'Complex', 'Dependence', 'Development', 'Environment', 'Experimental Designs', 'Goals', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Light', 'Location', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Monkeys', 'Motion', 'Neurodevelopmental Disorder', 'Neurons', 'Perception', 'Population', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Sampling', 'Sensory', 'Signal Transduction', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'V1 neuron', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'base', 'computer framework', 'experience', 'experimental study', 'image processing', 'improved', 'model development', 'movie', 'neglect', 'patient population', 'relating to nervous system', 'response', 'sensory input', 'spatiotemporal', 'statistics', 'theories', 'vision science', 'visual information']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,417500,0.15271023204433362
"Natural image processing in the visual cortex Project Summary Signals from the natural environment are processed by neuronal populations in the cortex. Understanding the relationship between those signals and cortical activity is central to understanding normal cortical function and how it is impaired in psychiatric and neurodevelopmental disorders. Substantial progress has been made in elucidating cortical processing of simple, parametric stimuli, and computational technology is improving descriptions of neural responses to naturalistic stimuli. However, how cortical populations encode the complex, natural inputs received during every day perceptual experience is largely unknown. This project aims to elucidate how natural visual inputs are represented by neuronal populations in primary visual cortex (V1). Progress to date has been limited primarily by two factors. First, during natural vision, the inputs to V1 neurons are always embedded in a spatial and temporal context, but how V1 integrates this contextual information in natural visual inputs is poorly understood. Second, prior work focused almost exclusively on single-neuron firing rate, but to understand cortical representations one must consider the structure of population activity— the substantial trial-to-trial variability that is shared among neurons and evolves dynamically—as this structure influences population information and perception. The central hypothesis of this project is that cortical response structure is modulated by visual context to approximate an optimal representation of natural visual inputs. To test the hypothesis, this project combines machine learning to quantify the statistical properties of natural visual inputs, with a theory of how cortical populations should encode those images to achieve an optimal representation, to arrive at concrete, falsifiable predictions for V1 response structure. The predictions will be tested with measurements of population activity in V1 of awake monkeys viewing natural images and movies. Specific Aim 1 will determine whether modulation of V1 response structure by spatial context in static images is consistent with optimal encoding of those images, and will compare the predictive power of the proposed model to alternative models. Specific Aim 2 addresses V1 encoding of dynamic natural inputs, and will test whether modulation of V1 activity by temporal context is tuned to the temporal structure of natural sensory signals, as required for optimality. As both spatial and temporal are present simultaneously during natural vision, Specific Aim 3 will determine visual input statistics in free-viewing animals, and test space-time interactions in V1 activity evoked by those inputs. This project will provide the first test of a unified functional theory of contextual modulation in V1 encoding of natural visual inputs, and shed light on key aspects of natural vision that have been neglected to date. Project Narrative This project aims to determine how neurons in the visual cortex represent the inputs encountered during perceptual experience in the natural environment, through correct integration of visual information across space and time. In individuals with neurodevelopmental and psychiatric disorders, integration is often miscalibrated leading to perceptual impairments. Our study will advance knowledge of the relationship between natural sensory inputs and cortical activity, which is central to understanding normal cortical function and how it is impaired in patient populations.",Natural image processing in the visual cortex,9801995,R01EY030578,"['Address', 'Animal Testing', 'Area', 'Complex', 'Dependence', 'Development', 'Environment', 'Experimental Designs', 'Goals', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Light', 'Location', 'Macaca', 'Machine Learning', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Monkeys', 'Motion', 'Neurodevelopmental Disorder', 'Neurons', 'Perception', 'Population', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Sampling', 'Sensory', 'Signal Transduction', 'Stimulus', 'Structure', 'Technology', 'Testing', 'Time', 'V1 neuron', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'base', 'computer framework', 'experience', 'experimental study', 'image processing', 'improved', 'model development', 'movie', 'neglect', 'patient population', 'relating to nervous system', 'response', 'sensory input', 'spatiotemporal', 'statistics', 'theories', 'vision science', 'visual information']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2019,417500,0.15271023204433362
"Visual Stimulus Coding and Metabolic Demand in Macaque Primary Visual Cortex Project Summary/Abstract  The relationships between neural response properties, their anatomical underpinnings, and the metabolic profile of neural tissue are key issues that define the normal functional architecture of the cerebral cortex. Understanding how these different systems are organized and work together is fundamental to neuroscientific research. Recent advances in optical imaging of cerebral activity have made it possible to record activity of both neuronal and metabolic dynamics simultaneously.  In primate primary visual cortex (V1), the relationships between neuronal orientation and color selectivity have been related to distribution of the metabolic enzyme cytochrome oxidase (CO) and vascular dynamics. The pattern of CO distribution in macaque V1 is a defining characteristic of this brain area. In V1, metabolic demand varies locally and by layer, as evident by diffuse CO-dense patches of cortex surrounded by less dense CO regions in layer 2/3. The distribution of CO in neurons has also been shown to be related to the density and organization of the vasculature which supplies the cortical tissue with nutrients and metabolites.  The long-established idea of how these systems interact suggests that strongly orientation tuned neurons reside in only CO interpatch regions while unoriented color tuned neurons reside exclusively in CO patches. However, recent research has shown that such a functional segregation is unlikely. Because earlier techniques failed to measure cone-specific and orientation-specific responses in the same cells and relate them to the CO pattern, new techniques—such as 2-photon imaging—are needed to develop an accurate picture of the functional organization of V1. In addition, the vasculature surrounding tuned neurons has been shown to have its own tuning through changes in vessel dilation and contraction, and therefore are expected to be related to the CO pattern if neural sensitivity to specific stimuli is locally organized in V1.  The goal of this proposal is to characterize the interaction of neuronal visual stimulus tuning, CO compartment identity, and vascular dynamics in primate V1. In Aim 1 we will use multiphoton calcium imaging to record orientation and cone specific selectivity in V1 and align the imaged regions with histological sections of CO staining to determine how neurons with different response profiles are distributed among CO patch or interpatch regions. In Aim 2 we will examine whether vascular dynamics are related to cone-specific orientation selectivity and CO compartment identity. The findings of this study will give us comprehensive information on the basic organization of the V1 and fundamentally alter our understand of visual processing. Project Narrative The brain’s metabolic drives and vasculature dynamics are closely integrated with neural information coding, but these interactions are still poorly understood. This research aims to uncover and describe the organization and relationship between these characteristics in macaque primary visual cortex. Completion of this project will broaden our understand of the organization of information processing in the animal model of visual cortex that is most comparable to humans, and may lead to therapeutic targets to help humans with visual deficits.",Visual Stimulus Coding and Metabolic Demand in Macaque Primary Visual Cortex,9991433,F32EY030725,"['Anatomy', 'Animal Model', 'Architecture', 'Area', 'Autopsy', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Brain', 'Brain imaging', 'Calcium', 'Cells', 'Cerebral cortex', 'Cerebrum', 'Characteristics', 'Code', 'Color', 'Cone', 'Diffuse', 'Dyes', 'Electrodes', 'Enzymes', 'Fluorescent Dyes', 'Foundations', 'Goals', 'Histologic', 'Histology', 'Human', 'Image', 'Imaging Techniques', 'Injections', 'Label', 'Lead', 'Macaca', 'Maps', 'Measures', 'Metabolic', 'Monitor', 'Neurons', 'Nutrient', 'Output', 'Pattern', 'Primates', 'Property', 'Reporting', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Spatial Distribution', 'Stains', 'Stimulus', 'System', 'Techniques', 'Tissues', 'V1 neuron', 'Visual', 'Visual Cortex', 'Work', 'adeno-associated viral vector', 'area striata', 'arteriole', 'cellular imaging', 'cytochrome c oxidase', 'density', 'hemodynamics', 'improved', 'indexing', 'information organization', 'information processing', 'metabolic profile', 'neural patterning', 'neurovascular coupling', 'optical imaging', 'orientation selectivity', 'relating to nervous system', 'response', 'segregation', 'therapeutic target', 'two-photon', 'vascular bed', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,F32,2020,67446,0.08908199832921972
"Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex Project Summary The use of stimuli with increasingly naturalistic properties has become critical to advance our understanding of vision. Many studies demonstrate that simple artificial stimuli (e.g. sinusoidal gratings and white noise) fail to engage nonlinearities that profoundly alter responses in the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). A recent and striking example comes from the use of naturalistic ‘flow’ stimuli, which engage robust responses in V1 that are not predicted from responses to gratings. This gap in understanding motivates the development of a stimulus ensemble and analysis framework that produces a quantitative understanding of visual processing to increasingly naturalistic stimuli and the nonlinearities that they engage. Our objective is to understand how flow stimuli are processed from retina through visual cortex. To meet this goal, we will make neural population recordings in retina (Aims 1 & 3), LGN (Aims 1 & 3) and V1 (Aim 3) using matched experimental conditions and a unified theoretical/modeling framework to map the transformations that occur across these stages of visual processing. Our central hypothesis is that V1 transforms a discrete and heavily light-level-de- pendent retinal representation of natural stimuli into a continuous (uniform) representation that is relatively in- variant to changes in the mean luminance. This invariance places a strong constraint on the class of nonlineari- ties that transform retinal responses to those observed in LGN and V1. We test this hypothesis in three aims: (1) determine early visual processing (retina & LGN) of naturalistic flow stimuli; (2) develop an encoding manifold to capture the population activity at each processing stage and transforms from one stage to the next; (3) test the ability of the manifold description to predict the impact of light adaptation on processing flow stimuli from retina to V1. Aim 1 will yield a matched experimental dataset to an interesting and novel class of ecologically-relevant stimuli. Aim 2 will yield a quantitative framework by which to understand the transformations that occur between retina, LGN, and V1. Aim 3 will provide a platform for globally perturbing the output of the retina by switching from photopic to mesopic and scotopic conditions, and thereby compare predictions of our model to measured changes in LGN and V1 activity. The primary significance of this research is that it will provide a computationally and experimentally unified framework for understanding the transformations that occur in the processing of stim- uli across multiple stages of visual processing. The major innovations are (1) presenting visual stimuli for retinal recordings that are matched to eye movements and pupil dynamics in alert animals; (2) creating a novel analysis framework that captures the responses of neurons at all three levels and the inter-level transformations to in- creasingly complex stimuli; (3) utilizing light adaptation as a method of perturbing retinal output to test our model and the stability (invariance) of LGN and V1 responses to adapting retinal signals. The expected outcome is a data-driven model of the processing from retina to LGN and V1 that generalizes from starlight to sunlight. Project Narrative Restoring vision to the blind likely requires understanding how retinal signals are communicated to the brain and how these signals are transformed in the thalamocortical pathway. This project aims to acquire an understanding of these transformations in the context of complex and more naturalistic visual stimuli.",Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex,10050840,R01EY031059,"['Affect', 'Animals', 'Brain', 'Collaborations', 'Complex', 'Cone', 'Data', 'Data Set', 'Development', 'Environment', 'Eye Movements', 'Future', 'Goals', 'Lateral Geniculate Body', 'Light', 'Light Adaptations', 'Machine Learning', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Movement', 'Mus', 'Neurons', 'Noise', 'Optics', 'Outcome', 'Output', 'Pathway interactions', 'Physiological', 'Population', 'Process', 'Property', 'Pupil', 'Research', 'Retina', 'Retinal Ganglion Cells', 'Rod', 'Signal Transduction', 'Stimulus', 'Structure', 'Sunlight', 'Techniques', 'Testing', 'Theoretical model', 'Variant', 'Vision', 'Visual Cortex', 'Visual system structure', 'Work', 'area striata', 'base', 'blind', 'cell type', 'computational neuroscience', 'experimental study', 'in vivo', 'innovation', 'luminance', 'multi-electrode arrays', 'novel', 'predictive modeling', 'receptive field', 'relating to nervous system', 'response', 'retinal neuron', 'stimulus processing', 'visual processing', 'visual stimulus']",NEI,DUKE UNIVERSITY,R01,2020,528815,0.18385152355866116
"CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision   To understand and navigate the environment, sensory systems must solve simultaneously two competing and challenging tasks: the segmentation of a sensory scene into individual objects and the grouping of elementary sensory features to build these objects. Understanding perceptual grouping and segmentation is therefore a major goal of sensory neuroscience, and it is central to advancing artificial perceptual systems that can help restore impaired vision. To make progress in understanding image segmentation and improving algorithms, this project combines two key components. First, a new experimental paradigm that allows for well-controlled measurements of perceptual segmentation of natural images. This addresses a major limitation of existing data that are either restricted to artificial stimuli, or, for natural images, rely on manual labeling and conflate perceptual, motor, and cognitive factors. Second, this project involves developing and testing a computational framework that accommodates bottom-up information about image statistics and top-down information about objects and behavioral goals. This is in contrast with the paradigmatic view of visual processing as a feedforward cascade of feature detectors, that has long dominated computer vision algorithms and our understanding of visual processing. The proposed approach builds instead on the influential theory that perception requires probabilistic inference to extract meaning from ambiguous sensory inputs. Segmentation is a prime example of inference on ambiguous inputs: the pixels of an image often cannot be labeled with certainty as grouped or segmented. This project will test the hypothesis that human visual segmentation is a process of hierarchical probabilistic inference. Specific Aim 1 will determine whether the measured variability of human segmentations reflects the uncertainty predicted by the model, as required for well-calibrated probabilistic inference. Specific Aim 2 addresses how feedforward and feedback processing in human segmentation contribute to efficient integration of visual features across different levels of complexity, from small contours to object parts. Specific Aim 3 will determine reciprocal interactions between perceptual segmentation and top-down influences including: semantic scene content; visual texture discrimination; and expectations reflecting environmental statistics. The proposed approach models these influences as Bayesian priors, and thus, if supported by the proposed experiments, will offer a unified framework to understand the integration of bottom-up and top- down influences in human segmentation of natural inputs. RELEVANCE (See instructions): This project aims to provide a unified understanding of perceptual segmentation and grouping of visual inputs encountered in the natural environment, through correct integration of the information contained in the visual inputs with top-down information about objects and behavioral goals. This understanding is central to advancing artificial perceptual systems that can help restore impaired vision in patient populations. n/a",CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision  ,10135248,R01EY031166,"['Address', 'Algorithms', 'Behavioral', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Set', 'Discrimination', 'Environment', 'Experimental Designs', 'Feedback', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Individual', 'Influentials', 'Instruction', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Motor', 'Neurodevelopmental Disorder', 'Neurons', 'Participant', 'Perception', 'Process', 'Protocols documentation', 'Recurrence', 'Semantics', 'Sensory', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Texture', 'Uncertainty', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'base', 'behavior influence', 'computer framework', 'deep learning', 'detector', 'expectation', 'experimental study', 'flexibility', 'imaging Segmentation', 'improved', 'object recognition', 'patient population', 'predictive modeling', 'segmentation algorithm', 'sensory input', 'sensory integration', 'sensory neuroscience', 'sensory system', 'statistics', 'theories', 'vision science', 'visual processing']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,7300,0.03627830440347607
"CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision   To understand and navigate the environment, sensory systems must solve simultaneously two competing and challenging tasks: the segmentation of a sensory scene into individual objects and the grouping of elementary sensory features to build these objects. Understanding perceptual grouping and segmentation is therefore a major goal of sensory neuroscience, and it is central to advancing artificial perceptual systems that can help restore impaired vision. To make progress in understanding image segmentation and improving algorithms, this project combines two key components. First, a new experimental paradigm that allows for well-controlled measurements of perceptual segmentation of natural images. This addresses a major limitation of existing data that are either restricted to artificial stimuli, or, for natural images, rely on manual labeling and conflate perceptual, motor, and cognitive factors. Second, this project involves developing and testing a computational framework that accommodates bottom-up information about image statistics and top-down information about objects and behavioral goals. This is in contrast with the paradigmatic view of visual processing as a feedforward cascade of feature detectors, that has long dominated computer vision algorithms and our understanding of visual processing. The proposed approach builds instead on the influential theory that perception requires probabilistic inference to extract meaning from ambiguous sensory inputs. Segmentation is a prime example of inference on ambiguous inputs: the pixels of an image often cannot be labeled with certainty as grouped or segmented. This project will test the hypothesis that human visual segmentation is a process of hierarchical probabilistic inference. Specific Aim 1 will determine whether the measured variability of human segmentations reflects the uncertainty predicted by the model, as required for well-calibrated probabilistic inference. Specific Aim 2 addresses how feedforward and feedback processing in human segmentation contribute to efficient integration of visual features across different levels of complexity, from small contours to object parts. Specific Aim 3 will determine reciprocal interactions between perceptual segmentation and top-down influences including: semantic scene content; visual texture discrimination; and expectations reflecting environmental statistics. The proposed approach models these influences as Bayesian priors, and thus, if supported by the proposed experiments, will offer a unified framework to understand the integration of bottom-up and top- down influences in human segmentation of natural inputs. RELEVANCE (See instructions): This project aims to provide a unified understanding of perceptual segmentation and grouping of visual inputs encountered in the natural environment, through correct integration of the information contained in the visual inputs with top-down information about objects and behavioral goals. This understanding is central to advancing artificial perceptual systems that can help restore impaired vision in patient populations. n/a",CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision  ,10018924,R01EY031166,"['Address', 'Algorithms', 'Behavioral', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Set', 'Discrimination', 'Environment', 'Experimental Designs', 'Feedback', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Individual', 'Influentials', 'Instruction', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Motor', 'Neurodevelopmental Disorder', 'Neurons', 'Participant', 'Perception', 'Process', 'Protocols documentation', 'Recurrence', 'Semantics', 'Sensory', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Texture', 'Uncertainty', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'base', 'behavior influence', 'computer framework', 'deep learning', 'detector', 'expectation', 'experimental study', 'flexibility', 'imaging Segmentation', 'improved', 'object recognition', 'patient population', 'predictive modeling', 'segmentation algorithm', 'sensory input', 'sensory integration', 'sensory neuroscience', 'sensory system', 'statistics', 'theories', 'vision science', 'visual processing']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2020,190044,0.03627830440347607
"CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision   To understand and navigate the environment, sensory systems must solve simultaneously two competing and challenging tasks: the segmentation of a sensory scene into individual objects and the grouping of elementary sensory features to build these objects. Understanding perceptual grouping and segmentation is therefore a major goal of sensory neuroscience, and it is central to advancing artificial perceptual systems that can help restore impaired vision. To make progress in understanding image segmentation and improving algorithms, this project combines two key components. First, a new experimental paradigm that allows for well-controlled measurements of perceptual segmentation of natural images. This addresses a major limitation of existing data that are either restricted to artificial stimuli, or, for natural images, rely on manual labeling and conflate perceptual, motor, and cognitive factors. Second, this project involves developing and testing a computational framework that accommodates bottom-up information about image statistics and top-down information about objects and behavioral goals. This is in contrast with the paradigmatic view of visual processing as a feedforward cascade of feature detectors, that has long dominated computer vision algorithms and our understanding of visual processing. The proposed approach builds instead on the influential theory that perception requires probabilistic inference to extract meaning from ambiguous sensory inputs. Segmentation is a prime example of inference on ambiguous inputs: the pixels of an image often cannot be labeled with certainty as grouped or segmented. This project will test the hypothesis that human visual segmentation is a process of hierarchical probabilistic inference. Specific Aim 1 will determine whether the measured variability of human segmentations reflects the uncertainty predicted by the model, as required for well-calibrated probabilistic inference. Specific Aim 2 addresses how feedforward and feedback processing in human segmentation contribute to efficient integration of visual features across different levels of complexity, from small contours to object parts. Specific Aim 3 will determine reciprocal interactions between perceptual segmentation and top-down influences including: semantic scene content; visual texture discrimination; and expectations reflecting environmental statistics. The proposed approach models these influences as Bayesian priors, and thus, if supported by the proposed experiments, will offer a unified framework to understand the integration of bottom-up and top- down influences in human segmentation of natural inputs. RELEVANCE (See instructions): This project aims to provide a unified understanding of perceptual segmentation and grouping of visual inputs encountered in the natural environment, through correct integration of the information contained in the visual inputs with top-down information about objects and behavioral goals. This understanding is central to advancing artificial perceptual systems that can help restore impaired vision in patient populations. n/a",CRCNS: Probabilistic models of perceptual grouping/segmentation in natural vision  ,9916219,R01EY031166,"['Address', 'Algorithms', 'Behavioral', 'Cognitive', 'Computer Vision Systems', 'Cues', 'Data', 'Data Set', 'Discrimination', 'Environment', 'Experimental Designs', 'Feedback', 'Goals', 'Grouping', 'Human', 'Image', 'Impairment', 'Individual', 'Influentials', 'Instruction', 'Label', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Measures', 'Mental disorders', 'Modeling', 'Motor', 'Neurodevelopmental Disorder', 'Neurons', 'Participant', 'Perception', 'Process', 'Protocols documentation', 'Recurrence', 'Semantics', 'Sensory', 'Statistical Models', 'Stimulus', 'System', 'Testing', 'Texture', 'Uncertainty', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Work', 'base', 'behavior influence', 'computer framework', 'deep learning', 'detector', 'expectation', 'experimental study', 'flexibility', 'imaging Segmentation', 'improved', 'object recognition', 'patient population', 'predictive modeling', 'sensory input', 'sensory integration', 'sensory neuroscience', 'sensory system', 'statistics', 'theories', 'vision science', 'visual processing']",NEI,ALBERT EINSTEIN COLLEGE OF MEDICINE,R01,2019,195245,0.03627830440347607
"DISCRETE VS. CONTINUOUS MODELS OF VISUAL PERCEPTION Two very different types of models of visual perception have been used by researchers in the fields of cognitive psychology and human information processing.  Discrete models characterized visual perception as a discrete operation that must completely finish processing a stimulus before any further cognitive processes receive information about that stimulus (e.g., Sternberg, 1969a). Continuous models characterize it as a continuous operation that gradually transmits information about a stimulus to later cognitive processes, so that these processes can begin before perception is finished (e.g., McClelland, 1979).  It is important for both theoretical and methodological reasons to be able to discriminate between these two types of models, and the goal of the proposed research is to develop experimental tests that can choose between them.  The proposed experiments emphasize two lines of research.  One set of experiments will use psychophysiological measurements to look for evidence that some response preparation has occurred before stimulus perception has finished.  Previous studies have sought evidence of such preliminary response preparation using indirect measures based on total response latency, and results have been subject to alternative explanations.  Using electrophysiological measures including the electromyogram (EMG) and event-related cerebral potentials (ERPs), it should be possible to measure preliminary response preparation more directly.  These measures will be obtained in several different experimental paradigms yielding effects previously attributed to preliminary response preparation, and they will indicate whether such preparation is actually responsible for these effects.  Such preliminary response preparation would be consistent with continuous, but not discrete, models of perceptual processes.  The second set of experiments will use reaction time measurements to study visual attention.  If it can be established that attentional emphasis continuously modulates the output of perceptual processes (rather than their use by late processes), then this would constitute broad support for models with continuous rather than discrete activation of stimulus codes.  The results of these studies will be of interest to cognitive psychologists, human factors engineers and designers of interfaces for human/computer interaction, and researchers in some areas of artificial intelligence.  n/a",DISCRETE VS. CONTINUOUS MODELS OF VISUAL PERCEPTION,3379071,R01MH040733,"['attention', ' biological information processing', ' brain electrical activity', ' cognition', ' electroencephalography', ' electromyography', ' memory', ' mental process', ' model design /development', ' psychological models', ' psychomotor reaction time', ' psychophysiology', ' sensory discrimination', ' stimulus /response', ' visual perception', ' visual stimulus']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1990,67858,0.18265986730103312
"DISCRETE VS. CONTINUOS MODELS OF VISUAL PERCEPTION Two very different types of models of visual perception have been used by researchers in the fields of cognitive psychology and human information processing.  Discrete models characterized visual perception as a discrete operation that must completely finish processing a stimulus before any further cognitive processes receive information about that stimulus (e.g., Sternberg, 1969a). Continuous models characterize it as a continuous operation that gradually transmits information about a stimulus to later cognitive processes, so that these processes can begin before perception is finished (e.g., McClelland, 1979).  It is important for both theoretical and methodological reasons to be able to discriminate between these two types of models, and the goal of the proposed research is to develop experimental tests that can choose between them.  The proposed experiments emphasize two lines of research.  One set of experiments will use psychophysiological measurements to look for evidence that some response preparation has occurred before stimulus perception has finished.  Previous studies have sought evidence of such preliminary response preparation using indirect measures based on total response latency, and results have been subject to alternative explanations.  Using electrophysiological measures including the electromyogram (EMG) and event-related cerebral potentials (ERPs), it should be possible to measure preliminary response preparation more directly.  These measures will be obtained in several different experimental paradigms yielding effects previously attributed to preliminary response preparation, and they will indicate whether such preparation is actually responsible for these effects.  Such preliminary response preparation would be consistent with continuous, but not discrete, models of perceptual processes.  The second set of experiments will use reaction time measurements to study visual attention.  If it can be established that attentional emphasis continuously modulates the output of perceptual processes (rather than their use by late processes), then this would constitute broad support for models with continuous rather than discrete activation of stimulus codes.  The results of these studies will be of interest to cognitive psychologists, human factors engineers and designers of interfaces for human/computer interaction, and researchers in some areas of artificial intelligence.  n/a",DISCRETE VS. CONTINUOS MODELS OF VISUAL PERCEPTION,3379070,R01MH040733,"['attention', ' biological information processing', ' brain electrical activity', ' cognition', ' electroencephalography', ' electromyography', ' memory', ' mental process', ' model design /development', ' psychological models', ' psychomotor reaction time', ' psychophysiology', ' sensory discrimination', ' stimulus /response', ' visual perception', ' visual stimulus']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1988,67386,0.18265986730103312
"DISCRETE VS. CONTINUOS MODELS OF VISUAL PERCEPTION Two very different types of models of visual perception have been used by researchers in the fields of cognitive psychology and human information processing.  Discrete models characterized visual perception as a discrete operation that must completely finish processing a stimulus before any further cognitive processes receive information about that stimulus (e.g., Sternberg, 1969a). Continuous models characterize it as a continuous operation that gradually transmits information about a stimulus to later cognitive processes, so that these processes can begin before perception is finished (e.g., McClelland, 1979).  It is important for both theoretical and methodological reasons to be able to discriminate between these two types of models, and the goal of the proposed research is to develop experimental tests that can choose between them.  The proposed experiments emphasize two lines of research.  One set of experiments will use psychophysiological measurements to look for evidence that some response preparation has occurred before stimulus perception has finished.  Previous studies have sought evidence of such preliminary response preparation using indirect measures based on total response latency, and results have been subject to alternative explanations.  Using electrophysiological measures including the electromyogram (EMG) and event-related cerebral potentials (ERPs), it should be possible to measure preliminary response preparation more directly.  These measures will be obtained in several different experimental paradigms yielding effects previously attributed to preliminary response preparation, and they will indicate whether such preparation is actually responsible for these effects.  Such preliminary response preparation would be consistent with continuous, but not discrete, models of perceptual processes.  The second set of experiments will use reaction time measurements to study visual attention.  If it can be established that attentional emphasis continuously modulates the output of perceptual processes (rather than their use by late processes), then this would constitute broad support for models with continuous rather than discrete activation of stimulus codes.  The results of these studies will be of interest to cognitive psychologists, human factors engineers and designers of interfaces for human/computer interaction, and researchers in some areas of artificial intelligence.  n/a",DISCRETE VS. CONTINUOS MODELS OF VISUAL PERCEPTION,3379067,R01MH040733,"['attention', ' biological information processing', ' brain electrical activity', ' cognition', ' electroencephalography', ' electromyography', ' memory', ' mental process', ' model design /development', ' psychological models', ' psychomotor reaction time', ' psychophysiology', ' sensory discrimination', ' stimulus /response', ' visual perception', ' visual stimulus']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1987,56510,0.18265986730103312
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6879624,R01HD041386,"['Internet', 'artificial intelligence', 'attitude', 'behavior prediction', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'computer human interaction', 'cues', 'data collection methodology /evaluation', 'human subject', 'imagery', 'interactive multimedia', 'mathematics', 'population survey', 'questionnaires', 'space perception', 'visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2005,206550,0.2111000750468622
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6743701,R01HD041386,"['Internet', 'artificial intelligence', 'attitude', 'behavior prediction', 'behavior test', 'behavioral /social science research tag', 'clinical research', 'computer human interaction', 'cues', 'data collection methodology /evaluation', 'human subject', 'imagery', 'interactive multimedia', 'mathematics', 'population survey', 'questionnaires', 'space perception', 'visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2004,201780,0.2111000750468622
"Visual & Interactive Issues in the Design of Web Surveys    DESCRIPTION (provided by applicant): The rapid acceptance of the Worldwide Web as a vehicle for survey data collection raises important questions about how the new method works. Key features of Web surveys include the use of rich visual presentation of questions and the capability of interaction with the respondent. The rapid growth of the Web makes a close examination of these issues even more urgent. Neither set of features has been explored thoroughly even with earlier modes and the Web offers widely increased resources for both visual display (Web questionnaires can readily incorporate still pictures or video clips) and interaction (such as, floating screens and scrolling for help with definitions). Our application outlines a set of studies designed to address key questions about these issues. The studies focus on Web surveys, but we believe that the results would generalize to other modes of data collection that rely on visual presentation or incorporate interactive design features.   Experiments 1-5 examine how respondents interpret the visual cues in Web questionnaires. These studies test the general proposition that incidental features of the presentation of the questions (for example, the spacing of the response options, the color assigned to different response options) can give rise to unintended inferences about their meaning. These studies test predictions derived from a theoretical framework that assumes respondents use simple interpretive heuristics to assign meaning to visual features of the questions. The next two experiments examine the effects of including images as a supplement to the text of the question. Images are necessarily concrete, and Experiment 6 tests the hypothesis that this concreteness may lead respondents to interpret the questions more narrowly when they are accompanied by images. Experiment 7 tests the idea that the item depicted in an image may serve as a standard of comparison for respondents' judgments. Again, the results of these studies will lead to practical guidelines about the dangers involved in using images as an adjunct to verbal questions. The final series of studies examines when respondents are likely to take advantage of interactive features of a questionnaire. These experiments test three general hypotheses; respondents are more likely to utilize the information available to them interactively when 1) the information is easy to obtain, 2) it is clearly helpful, and 3) respondents are highly motivated to seek help. These six experiments would yield a better understanding of methods for getting respondents to use features that could yield better survey data.         n/a",Visual & Interactive Issues in the Design of Web Surveys,6629976,R01HD041386,"['Internet', ' artificial intelligence', ' attitude', ' behavior prediction', ' behavior test', ' behavioral /social science research tag', ' clinical research', ' computer human interaction', ' cues', ' data collection methodology /evaluation', ' human subject', ' imagery', ' interactive multimedia', ' mathematics', ' population survey', ' questionnaires', ' space perception', ' visual perception']",NICHD,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2003,205876,0.2111000750468622
"CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS The overall aim of this project is to improve automated cervical smear image analysis techniques sufficiently to:  1) routinely provide additional diagnostic information to supplement that provided by human visual examination, and 2) provide accurate, cost effective prescreening capabilities.  By furnishing additional quantitative diagnostic information, such automated systems would permit the practicing cytopathologist to make more accurate and refined diagnostic judgements, which would lead to improved patient management.  By providing a practical prescreening capability, such systems would increase the efficiency and efficacy of health care delivery.  Current automated cervical smear analysis research employs only the analysis of isolated cells, and practical automated analysis is not yet a reality.  The primary contribution of this project will be the completion of development and testing of image analysis techniques that extract information from cells and other objects as seen in the context of the ""background"" of the smear.  Specifically, cells, cell clusters, bare nuclei, and cytoplasmic fragments are analyzed and the resulting contextual features, slide-averaged ""features"" and high-resolution features describing single cells are combined to produce a more complete and accurate description of the smear.  This description will provide information not obtainable by human visual analysis, which can be used, 1) directly, to ascertain diagnostic clues, and 2) indirectly to make accurate prescreening possible.  An extensive pilot study has shown that the contextual analysis provides complementary information to that provided by single cell analysis.  That is, where single cell analysis seems to have difficulty, contextual analysis is most accurate - and vice versa. Thus we expect to demonstrate that the combination of our contextual analysis techniques with single cell analysis will give automated Pap smear analysis the additional screening accuracy that is needed.  The proposed project is a followup intended to:  a) validate the techniques of the pilot study, b) to expand the study to include parameters that provide additional diagnostic and prognostic information, and c) to generate specifications for a system to accomplish the analysis in a routine clinical laboratory environment.  n/a",CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS,3185092,R01CA043133,"['artificial intelligence', ' biomedical automation', ' computer assisted diagnosis', ' computer data analysis', ' cytodiagnosis', ' cytology', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' diagnostic tests', ' human subject', ' image processing', ' mass screening', ' neoplasm /cancer diagnosis', ' single cell analysis']",NCI,TUFTS MEDICAL CENTER,R01,1989,214038,0.036288031970149064
"CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS The overall aim of this project is to improve automated cervical smear image analysis techniques sufficiently to:  1) routinely provide additional diagnostic information to supplement that provided by human visual examination, and 2) provide accurate, cost effective prescreening capabilities.  By furnishing additional quantitative diagnostic information, such automated systems would permit the practicing cytopathologist to make more accurate and refined diagnostic judgements, which would lead to improved patient management.  By providing a practical prescreening capability, such systems would increase the efficiency and efficacy of health care delivery.  Current automated cervical smear analysis research employs only the analysis of isolated cells, and practical automated analysis is not yet a reality.  The primary contribution of this project will be the completion of development and testing of image analysis techniques that extract information from cells and other objects as seen in the context of the ""background"" of the smear.  Specifically, cells, cell clusters, bare nuclei, and cytoplasmic fragments are analyzed and the resulting contextual features, slide-averaged ""features"" and high-resolution features describing single cells are combined to produce a more complete and accurate description of the smear.  This description will provide information not obtainable by human visual analysis, which can be used, 1) directly, to ascertain diagnostic clues, and 2) indirectly to make accurate prescreening possible.  An extensive pilot study has shown that the contextual analysis provides complementary information to that provided by single cell analysis.  That is, where single cell analysis seems to have difficulty, contextual analysis is most accurate - and vice versa. Thus we expect to demonstrate that the combination of our contextual analysis techniques with single cell analysis will give automated Pap smear analysis the additional screening accuracy that is needed.  The proposed project is a followup intended to:  a) validate the techniques of the pilot study, b) to expand the study to include parameters that provide additional diagnostic and prognostic information, and c) to generate specifications for a system to accomplish the analysis in a routine clinical laboratory environment.  n/a",CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS,3185091,R01CA043133,"['artificial intelligence', ' biomedical automation', ' computer assisted diagnosis', ' computer data analysis', ' cytodiagnosis', ' cytology', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' diagnostic tests', ' human subject', ' image processing', ' mass screening', ' neoplasm /cancer diagnosis', ' single cell analysis']",NCI,TUFTS MEDICAL CENTER,R01,1988,216221,0.036288031970149064
"CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS The overall aim of this project is to improve automated cervical smear image analysis techniques sufficiently to:  1) routinely provide additional diagnostic information to supplement that provided by human visual examination, and 2) provide accurate, cost effective prescreening capabilities.  By furnishing additional quantitative diagnostic information, such automated systems would permit the practicing cytopathologist to make more accurate and refined diagnostic judgements, which would lead to improved patient management.  By providing a practical prescreening capability, such systems would increase the efficiency and efficacy of health care delivery.  Current automated cervical smear analysis research employs only the analysis of isolated cells, and practical automated analysis is not yet a reality.  The primary contribution of this project will be the completion of development and testing of image analysis techniques that extract information from cells and other objects as seen in the context of the ""background"" of the smear.  Specifically, cells, cell clusters, bare nuclei, and cytoplasmic fragments are analyzed and the resulting contextual features, slide-averaged ""features"" and high-resolution features describing single cells are combined to produce a more complete and accurate description of the smear.  This description will provide information not obtainable by human visual analysis, which can be used, 1) directly, to ascertain diagnostic clues, and 2) indirectly to make accurate prescreening possible.  An extensive pilot study has shown that the contextual analysis provides complementary information to that provided by single cell analysis.  That is, where single cell analysis seems to have difficulty, contextual analysis is most accurate - and vice versa. Thus we expect to demonstrate that the combination of our contextual analysis techniques with single cell analysis will give automated Pap smear analysis the additional screening accuracy that is needed.  The proposed project is a followup intended to:  a) validate the techniques of the pilot study, b) to expand the study to include parameters that provide additional diagnostic and prognostic information, and c) to generate specifications for a system to accomplish the analysis in a routine clinical laboratory environment.  n/a",CONTEXT INFORMATION IN AUTOMATED CERVICAL SMEAR ANALYSIS,3185088,R01CA043133,"['artificial intelligence', ' biomedical automation', ' computer assisted diagnosis', ' computer data analysis', ' cytodiagnosis', ' cytology', ' diagnosis quality /standard', ' diagnostic tests', ' human subject', ' image processing', ' mass screening', ' neoplasm /cancer diagnosis', ' single cell analysis']",NCI,TUFTS MEDICAL CENTER,R01,1987,211299,0.036288031970149064
"FUNCTIONAL NEUROIMAGING BY MRI--HUMAN VISUAL SYSTEM In this grant we propose the continued development and application of nuclear magnetic resonance (NMR) imaging (or MRI) based methods for studying brain function.  These new techniques offer cognitive neuroscientists a unique opportunity to study both the functional and anatomical mechanisms underlying perception, memory, language and image generation.  The brain possesses anatomically distinct processing regions.  A complete understanding of brain function requires determination of where these sites are located, what operations are performed, and how distributed processing is organized.  Changes in neuronal activity are accompanied by focal changes in cerebral blood flow, blood volume , oxygenation and metabolism.  These physiological changes can be used to produce functional maps of component mental operations.  Recent advances in our laboratory have yielded high speed MRI techniques that are sensitive to changes in cerebral blood flow, blood volume, and blood oxygenation.  These have been used to generate the first functional MRI maps of human task activation using a visual stimulus paradigm.  New preliminary data presents completely non-invasive, real-time (at a frame resolution of seconds) tomographic movies of dynamic human brain activity.  The spatial and temporal resolution of these tomographic maps are the highest reported to date.   Our first research goal will be to optimize MRI techniques for real-time mapping of the human visual system.  The visual system will be explored first because of its robust activation and our prior knowledge of its functional organization derived from PET and non-human primate studies. Second, optimized techniques will be applied to study the functional architecture of primary and secondary visual cortex (V1 and V2), and two areas to which they project, V4 and MT (V5).  Finally, higher order areas involved in visual object recognition, visual word recognition, visual memory, and visual imagery will be mapped.  The latter can only be studied in humans.  n/a",FUNCTIONAL NEUROIMAGING BY MRI--HUMAN VISUAL SYSTEM,2249412,R01MH050054,"['artificial intelligence', ' blood flow measurement', ' color visions', ' computer program /software', ' computer system design /evaluation', ' form /pattern perception', ' hemodynamics', ' human subject', ' image enhancement', ' imagery', ' magnetic resonance imaging', ' memory', ' method development', ' motion perception', ' neural information processing', ' neuroanatomy', ' parallel processing', ' positron emission tomography', ' psychophysics', ' visual cortex', ' visual fields', ' visual perception', ' visual stimulus']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,1994,272423,0.17030330949851788
"FUNCTIONAL NEUROIMAGING BY MRI--HUMAN VISUAL SYSTEM In this grant we propose the continued development and application of nuclear magnetic resonance (NMR) imaging (or MRI) based methods for studying brain function.  These new techniques offer cognitive neuroscientists a unique opportunity to study both the functional and anatomical mechanisms underlying perception, memory, language and image generation.  The brain possesses anatomically distinct processing regions.  A complete understanding of brain function requires determination of where these sites are located, what operations are performed, and how distributed processing is organized.  Changes in neuronal activity are accompanied by focal changes in cerebral blood flow, blood volume , oxygenation and metabolism.  These physiological changes can be used to produce functional maps of component mental operations.  Recent advances in our laboratory have yielded high speed MRI techniques that are sensitive to changes in cerebral blood flow, blood volume, and blood oxygenation.  These have been used to generate the first functional MRI maps of human task activation using a visual stimulus paradigm.  New preliminary data presents completely non-invasive, real-time (at a frame resolution of seconds) tomographic movies of dynamic human brain activity.  The spatial and temporal resolution of these tomographic maps are the highest reported to date.   Our first research goal will be to optimize MRI techniques for real-time mapping of the human visual system.  The visual system will be explored first because of its robust activation and our prior knowledge of its functional organization derived from PET and non-human primate studies. Second, optimized techniques will be applied to study the functional architecture of primary and secondary visual cortex (V1 and V2), and two areas to which they project, V4 and MT (V5).  Finally, higher order areas involved in visual object recognition, visual word recognition, visual memory, and visual imagery will be mapped.  The latter can only be studied in humans.  n/a",FUNCTIONAL NEUROIMAGING BY MRI--HUMAN VISUAL SYSTEM,3389268,R01MH050054,"['artificial intelligence', ' blood flow measurement', ' color visions', ' computer program /software', ' computer system design /evaluation', ' hemodynamics', ' human subject', ' image enhancement', ' imagery', ' magnetic resonance imaging', ' memory', ' method development', ' neural information processing', ' neuroanatomy', ' parallel processing', ' positron emission tomography', ' psychophysics', ' visual cortex', ' visual fields', ' visual perception', ' visual stimulus']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,1993,256155,0.17030330949851788
"MATHEMATICAL ANALYSIS OF BRAIN FUNCTION Our long-range objective is to understand the functional organization            and dynamical activity of the cortex.  The discovery of the columnar             organization of the cortex has led to the notion that the  columns  are          fundamental building blocks, from which larger functional units are              constructed.  The cortex is thus viewed as a crystal (a more or less             regular array of repeating, similar modules.  Our proposal will test and         refine this modular hypothesis.                                                                                                                                   We shall use optical imaging of the primary visual cortex of monkeys and         cats, and simultaneously record electrical responses from small neuronal         clusters and local field potentials.  We shall thus obtain a spatio-             temporal picture of the activity in the neural ensembles which encode            various stimulus parameters. The data will be analyzed with extensions           of Principal Component Analysis that we have developed.                                                                                                           We address three major aims: 1) To test the modularity hypothesis we             shall measure, in a large piece of cortical tissue, the full range of            functional maps ( for orientation, color, spatial frequency etc.)                together with the retinotopic map.  We shall measure the periodicity of,         and correlations among, the functional maps, to determine if they are            commensurate.  This will lead to a refined framework that could include          possibly incommensurate cortical scales and interactions among cortical          elements.  2) We shall investigate how the Principal Components                  (eigenfunctions) obtained from the optical images depend on the extent           of the visual stimulus, to determine how the dynamical dimension of the          primary visual cortex (viewed as a dynamical system) scales with size.           3) We shall study the concerted electrical responses of neuronal                 clusters, to clarify the link between optical signals and neuronal               activity, and to deepen our understanding of the neuronal dynamics.                                                                                               Our study is aimed at an intermediate architectural level, and deals             with the way in which the fundamental modalities of the visual world             (orientation, size, color and so on) are analyzed in the primary visual          cortex.  Such knowledge is crucial for the construction of cortical              models, which are essential for any quantitative understanding of                critical function and dysfunction.                                                n/a",MATHEMATICAL ANALYSIS OF BRAIN FUNCTION,6538668,R01MH050166,"['Macaca fascicularis', ' bioimaging /biomedical imaging', ' brain electrical activity', ' brain imaging /visualization /scanning', ' brain mapping', ' cats', ' charge coupled device camera', ' computational neuroscience', ' image processing', ' mathematical model', ' neural information processing', ' optics', ' space perception', ' stereotaxic techniques', ' visual cortex', ' visual stimulus']",NIMH,MOUNT SINAI SCHOOL OF MEDICINE OF NYU,R01,2002,366066,0.1344482331756597
"MATHEMATICAL ANALYSIS OF BRAIN FUNCTION Our long-range objective is to understand the functional organization            and dynamical activity of the cortex.  The discovery of the columnar             organization of the cortex has led to the notion that the  columns  are          fundamental building blocks, from which larger functional units are              constructed.  The cortex is thus viewed as a crystal (a more or less             regular array of repeating, similar modules.  Our proposal will test and         refine this modular hypothesis.                                                                                                                                   We shall use optical imaging of the primary visual cortex of monkeys and         cats, and simultaneously record electrical responses from small neuronal         clusters and local field potentials.  We shall thus obtain a spatio-             temporal picture of the activity in the neural ensembles which encode            various stimulus parameters. The data will be analyzed with extensions           of Principal Component Analysis that we have developed.                                                                                                           We address three major aims: 1) To test the modularity hypothesis we             shall measure, in a large piece of cortical tissue, the full range of            functional maps ( for orientation, color, spatial frequency etc.)                together with the retinotopic map.  We shall measure the periodicity of,         and correlations among, the functional maps, to determine if they are            commensurate.  This will lead to a refined framework that could include          possibly incommensurate cortical scales and interactions among cortical          elements.  2) We shall investigate how the Principal Components                  (eigenfunctions) obtained from the optical images depend on the extent           of the visual stimulus, to determine how the dynamical dimension of the          primary visual cortex (viewed as a dynamical system) scales with size.           3) We shall study the concerted electrical responses of neuronal                 clusters, to clarify the link between optical signals and neuronal               activity, and to deepen our understanding of the neuronal dynamics.                                                                                               Our study is aimed at an intermediate architectural level, and deals             with the way in which the fundamental modalities of the visual world             (orientation, size, color and so on) are analyzed in the primary visual          cortex.  Such knowledge is crucial for the construction of cortical              models, which are essential for any quantitative understanding of                critical function and dysfunction.                                                n/a",MATHEMATICAL ANALYSIS OF BRAIN FUNCTION,6392043,R01MH050166,"['Macaca fascicularis', ' bioimaging /biomedical imaging', ' brain electrical activity', ' brain imaging /visualization /scanning', ' brain mapping', ' cats', ' charge coupled device camera', ' computational neuroscience', ' image processing', ' mathematical model', ' neural information processing', ' optics', ' space perception', ' stereotaxic techniques', ' visual cortex', ' visual stimulus']",NIMH,MOUNT SINAI SCHOOL OF MEDICINE OF NYU,R01,2001,406726,0.1344482331756597
"MATHEMATICAL ANALYSIS OF BRAIN FUNCTION Our long-range objective is to understand the functional organization            and dynamical activity of the cortex.  The discovery of the columnar             organization of the cortex has led to the notion that the  columns  are          fundamental building blocks, from which larger functional units are              constructed.  The cortex is thus viewed as a crystal (a more or less             regular array of repeating, similar modules.  Our proposal will test and         refine this modular hypothesis.                                                                                                                                   We shall use optical imaging of the primary visual cortex of monkeys and         cats, and simultaneously record electrical responses from small neuronal         clusters and local field potentials.  We shall thus obtain a spatio-             temporal picture of the activity in the neural ensembles which encode            various stimulus parameters. The data will be analyzed with extensions           of Principal Component Analysis that we have developed.                                                                                                           We address three major aims: 1) To test the modularity hypothesis we             shall measure, in a large piece of cortical tissue, the full range of            functional maps ( for orientation, color, spatial frequency etc.)                together with the retinotopic map.  We shall measure the periodicity of,         and correlations among, the functional maps, to determine if they are            commensurate.  This will lead to a refined framework that could include          possibly incommensurate cortical scales and interactions among cortical          elements.  2) We shall investigate how the Principal Components                  (eigenfunctions) obtained from the optical images depend on the extent           of the visual stimulus, to determine how the dynamical dimension of the          primary visual cortex (viewed as a dynamical system) scales with size.           3) We shall study the concerted electrical responses of neuronal                 clusters, to clarify the link between optical signals and neuronal               activity, and to deepen our understanding of the neuronal dynamics.                                                                                               Our study is aimed at an intermediate architectural level, and deals             with the way in which the fundamental modalities of the visual world             (orientation, size, color and so on) are analyzed in the primary visual          cortex.  Such knowledge is crucial for the construction of cortical              models, which are essential for any quantitative understanding of                critical function and dysfunction.                                                n/a",MATHEMATICAL ANALYSIS OF BRAIN FUNCTION,6186061,R01MH050166,"['Macaca fascicularis', ' bioimaging /biomedical imaging', ' brain electrical activity', ' brain imaging /visualization /scanning', ' brain mapping', ' cats', ' charge coupled device camera', ' computational neuroscience', ' image processing', ' mathematical model', ' neural information processing', ' optics', ' space perception', ' stereotaxic techniques', ' visual cortex', ' visual stimulus']",NIMH,MOUNT SINAI SCHOOL OF MEDICINE OF NYU,R01,2000,346335,0.1344482331756597
"MATHEMATICAL ANALYSIS OF BRAIN FUNCTION Our long-range objective is to understand the functional organization            and dynamical activity of the cortex.  The discovery of the columnar             organization of the cortex has led to the notion that the  columns  are          fundamental building blocks, from which larger functional units are              constructed.  The cortex is thus viewed as a crystal (a more or less             regular array of repeating, similar modules.  Our proposal will test and         refine this modular hypothesis.                                                                                                                                   We shall use optical imaging of the primary visual cortex of monkeys and         cats, and simultaneously record electrical responses from small neuronal         clusters and local field potentials.  We shall thus obtain a spatio-             temporal picture of the activity in the neural ensembles which encode            various stimulus parameters. The data will be analyzed with extensions           of Principal Component Analysis that we have developed.                                                                                                           We address three major aims: 1) To test the modularity hypothesis we             shall measure, in a large piece of cortical tissue, the full range of            functional maps ( for orientation, color, spatial frequency etc.)                together with the retinotopic map.  We shall measure the periodicity of,         and correlations among, the functional maps, to determine if they are            commensurate.  This will lead to a refined framework that could include          possibly incommensurate cortical scales and interactions among cortical          elements.  2) We shall investigate how the Principal Components                  (eigenfunctions) obtained from the optical images depend on the extent           of the visual stimulus, to determine how the dynamical dimension of the          primary visual cortex (viewed as a dynamical system) scales with size.           3) We shall study the concerted electrical responses of neuronal                 clusters, to clarify the link between optical signals and neuronal               activity, and to deepen our understanding of the neuronal dynamics.                                                                                               Our study is aimed at an intermediate architectural level, and deals             with the way in which the fundamental modalities of the visual world             (orientation, size, color and so on) are analyzed in the primary visual          cortex.  Such knowledge is crucial for the construction of cortical              models, which are essential for any quantitative understanding of                critical function and dysfunction.                                                n/a",MATHEMATICAL ANALYSIS OF BRAIN FUNCTION,2890529,R01MH050166,"['Macaca fascicularis', ' bioimaging /biomedical imaging', ' brain electrical activity', ' brain imaging /visualization /scanning', ' brain mapping', ' cats', ' charge coupled device camera', ' computational neuroscience', ' image processing', ' mathematical model', ' neural information processing', ' optics', ' space perception', ' stereotaxic techniques', ' visual cortex', ' visual stimulus']",NIMH,MOUNT SINAI SCHOOL OF MEDICINE OF NYU,R01,1999,349750,0.1344482331756597
"MATHEMATICAL ANALYSIS OF BRAIN FUNCTION Our long-range objective is to understand the functional organization            and dynamical activity of the cortex.  The discovery of the columnar             organization of the cortex has led to the notion that the  columns  are          fundamental building blocks, from which larger functional units are              constructed.  The cortex is thus viewed as a crystal (a more or less             regular array of repeating, similar modules.  Our proposal will test and         refine this modular hypothesis.                                                                                                                                   We shall use optical imaging of the primary visual cortex of monkeys and         cats, and simultaneously record electrical responses from small neuronal         clusters and local field potentials.  We shall thus obtain a spatio-             temporal picture of the activity in the neural ensembles which encode            various stimulus parameters. The data will be analyzed with extensions           of Principal Component Analysis that we have developed.                                                                                                           We address three major aims: 1) To test the modularity hypothesis we             shall measure, in a large piece of cortical tissue, the full range of            functional maps ( for orientation, color, spatial frequency etc.)                together with the retinotopic map.  We shall measure the periodicity of,         and correlations among, the functional maps, to determine if they are            commensurate.  This will lead to a refined framework that could include          possibly incommensurate cortical scales and interactions among cortical          elements.  2) We shall investigate how the Principal Components                  (eigenfunctions) obtained from the optical images depend on the extent           of the visual stimulus, to determine how the dynamical dimension of the          primary visual cortex (viewed as a dynamical system) scales with size.           3) We shall study the concerted electrical responses of neuronal                 clusters, to clarify the link between optical signals and neuronal               activity, and to deepen our understanding of the neuronal dynamics.                                                                                               Our study is aimed at an intermediate architectural level, and deals             with the way in which the fundamental modalities of the visual world             (orientation, size, color and so on) are analyzed in the primary visual          cortex.  Such knowledge is crucial for the construction of cortical              models, which are essential for any quantitative understanding of                critical function and dysfunction.                                                n/a",MATHEMATICAL ANALYSIS OF BRAIN FUNCTION,2688886,R01MH050166,"['Macaca fascicularis', ' brain electrical activity', ' brain imaging /visualization /scanning', ' brain mapping', ' cats', ' charge coupled device camera', ' computational neuroscience', ' image processing', ' mathematical model', ' neural information processing', ' optics', ' space perception', ' stereotaxic techniques', ' visual cortex', ' visual stimulus']",NIMH,MOUNT SINAI SCHOOL OF MEDICINE OF NYU,R01,1998,330381,0.1344482331756597
"Device to control circadian-effective light in Alzheimer's disease environments Project Summary This proposed project will develop and field-test a device that accurately monitors and controls the circadian stimulus (CS) for Alzheimer disease (AD) and Alzheimer-disease-related dementia (ADRD) patients in nursing homes. Human biology has evolved to have two distinct optical systems: the visual system, by which we see and process images, and the circadian system, which regulates our biological clock and associated biological systems. These two systems have significantly different spectral and temporal responses to optical input. Specifically, circadian stimulation peaks at 460 nm and responds after several minutes of optical activation, while the visual system peaks at 555 nm and responds nearly instantaneously to inputs. All lighting systems are designed and installed in buildings with consideration only given to the photopic (visual) system and all light meters used to characterize lighting buildings are calibrated to measure photopic light, not CS. While a broad and growing body of research has documented the impacts of the circadian system on human health, including regulating sleep and improving cognition in AD/ADRD patients, research on the CS experienced by AD/ADRD patients is extremely limited. Researchers at the Lighting Research Center at Rensselaer Polytechnic Institute developed the Daysimeter, a calibrated light meter that measures circadian light and circadian stimulus. In Phase I of this project, researchers modified an existing workstation-based lighting control system they previously developed for the visual system to include Daysimeter technology, allowing this control system to record CS measurements. The accuracy of these CS measurements was confirmed in the laboratory and field-testing of 20 of devices is currently ongoing in AD/ADRD nursing homes. In this Phase II application, researchers propose adding control features to this device so that lighting can be controlled to optimize CS dosages in AD/ADRD patient environments. Machine learning-based lighting control algorithms will be driven by continuous light level and spectrum measurements as well as periodic (e.g., daily) patient health data. Data from these devices would be wirelessly transmitted to researchers via an Internet gateway and associated cloud-based data management systems. These data would be of immediate value for gaining a better understanding of AD/ADRD patients' CS exposure and could ultimately result in new lighting systems and/or building codes that consider both our visual and circadian systems. Following the development phase, 30 CS-enabled lighting control systems will be field tested over a 22-week test period. Researchers aim to commercialize this CS-enabled lighting control system shortly after the completion of this field test and the Phase II project specifically targeting AD/ADRD nursing home applications. Project Narrative A growing body of research has demonstrated how light impacts human circadian systems and how these impacts can affect sleep, alertness, cognition and agitation in people with Alzheimer's disease (AD) and Alzheimer's-disease-related dementia (ADRD). Still, significant knowledge gaps exist in determining how much circadian stimulation is typically provided to AD/ADRD patients and there are no commercial products designed to control lighting in AD/ADRD environments in ways that promote circadian-related health. This project aims to fill in these gaps by developing and testing a device specifically designed to measure and control the circadian stimulation experienced by AD/ADRD patients in nursing homes.",Device to control circadian-effective light in Alzheimer's disease environments,10018621,R44AG060857,"['Affect', 'Agitation', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Back', 'Behavior', 'Biological Clocks', 'Building Codes', 'Characteristics', 'Clinical Trials', 'Cognition', 'Data', 'Database Management Systems', 'Development', 'Device or Instrument Development', 'Devices', 'Dose', 'Effectiveness', 'Elderly', 'Environment', 'Feeds', 'Health', 'Hour', 'Human', 'Human Biology', 'Image', 'Institutes', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Monitor', 'Moods', 'Nursing Homes', 'Optics', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Phototherapy', 'Planet Earth', 'Population', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Rotation', 'Running', 'Sleep', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Visual', 'Visual system structure', 'Wakefulness', 'Wireless Technology', 'Work', 'active control', 'alertness', 'appropriate dose', 'awake', 'base', 'biological systems', 'circadian', 'circadian pacemaker', 'cloud based', 'commercialization', 'design', 'dosage', 'effectiveness testing', 'experience', 'falls', 'field study', 'health data', 'improved', 'interest', 'meter', 'next generation', 'novel', 'prototype', 'residence', 'response', 'success', 'therapy design']",NIA,"ERIK PAGE AND ASSOCIATES, INC.",R44,2020,432887,0.025140794899929982
"Device to control circadian-effective light in Alzheimer's disease environments Project Summary This proposed project will develop and field-test a device that accurately monitors and controls the circadian stimulus (CS) for Alzheimer disease (AD) and Alzheimer-disease-related dementia (ADRD) patients in nursing homes. Human biology has evolved to have two distinct optical systems: the visual system, by which we see and process images, and the circadian system, which regulates our biological clock and associated biological systems. These two systems have significantly different spectral and temporal responses to optical input. Specifically, circadian stimulation peaks at 460 nm and responds after several minutes of optical activation, while the visual system peaks at 555 nm and responds nearly instantaneously to inputs. All lighting systems are designed and installed in buildings with consideration only given to the photopic (visual) system and all light meters used to characterize lighting buildings are calibrated to measure photopic light, not CS. While a broad and growing body of research has documented the impacts of the circadian system on human health, including regulating sleep and improving cognition in AD/ADRD patients, research on the CS experienced by AD/ADRD patients is extremely limited. Researchers at the Lighting Research Center at Rensselaer Polytechnic Institute developed the Daysimeter, a calibrated light meter that measures circadian light and circadian stimulus. In Phase I of this project, researchers modified an existing workstation-based lighting control system they previously developed for the visual system to include Daysimeter technology, allowing this control system to record CS measurements. The accuracy of these CS measurements was confirmed in the laboratory and field-testing of 20 of devices is currently ongoing in AD/ADRD nursing homes. In this Phase II application, researchers propose adding control features to this device so that lighting can be controlled to optimize CS dosages in AD/ADRD patient environments. Machine learning-based lighting control algorithms will be driven by continuous light level and spectrum measurements as well as periodic (e.g., daily) patient health data. Data from these devices would be wirelessly transmitted to researchers via an Internet gateway and associated cloud-based data management systems. These data would be of immediate value for gaining a better understanding of AD/ADRD patients' CS exposure and could ultimately result in new lighting systems and/or building codes that consider both our visual and circadian systems. Following the development phase, 30 CS-enabled lighting control systems will be field tested over a 22-week test period. Researchers aim to commercialize this CS-enabled lighting control system shortly after the completion of this field test and the Phase II project specifically targeting AD/ADRD nursing home applications. Project Narrative A growing body of research has demonstrated how light impacts human circadian systems and how these impacts can affect sleep, alertness, cognition and agitation in people with Alzheimer's disease (AD) and Alzheimer's-disease-related dementia (ADRD). Still, significant knowledge gaps exist in determining how much circadian stimulation is typically provided to AD/ADRD patients and there are no commercial products designed to control lighting in AD/ADRD environments in ways that promote circadian-related health. This project aims to fill in these gaps by developing and testing a device specifically designed to measure and control the circadian stimulation experienced by AD/ADRD patients in nursing homes.",Device to control circadian-effective light in Alzheimer's disease environments,9907480,R44AG060857,"['Affect', 'Agitation', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Back', 'Behavior', 'Biological Clocks', 'Building Codes', 'Characteristics', 'Clinical Trials', 'Cognition', 'Data', 'Database Management Systems', 'Development', 'Device or Instrument Development', 'Devices', 'Dose', 'Effectiveness', 'Elderly', 'Environment', 'Feeds', 'Health', 'Hour', 'Human', 'Human Biology', 'Image', 'Institutes', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Monitor', 'Moods', 'Nursing Homes', 'Optics', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Phototherapy', 'Planet Earth', 'Population', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Rotation', 'Running', 'Sleep', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Visual', 'Visual system structure', 'Wakefulness', 'Wireless Technology', 'Work', 'active control', 'alertness', 'appropriate dose', 'awake', 'base', 'biological systems', 'circadian', 'circadian pacemaker', 'cloud based', 'commercialization', 'design', 'dosage', 'experience', 'falls', 'feeding', 'field study', 'health data', 'improved', 'interest', 'meter', 'next generation', 'novel', 'prototype', 'residence', 'response', 'success', 'therapy design']",NIA,"ERIK PAGE AND ASSOCIATES, INC.",R44,2019,1240470,0.025140794899929982
"AN EXPERT-TRAINED CONSULTATION SYSTEM FOR MAMMOGRAPHY The aim of this project is to develop a computer-assisted consultation system for clinical radiologists in the classification of benign and malignant (cancer) calcifications on mammograms. An automated screening of digital mammograms can be further developed when this system is fully tested in various clinical settings. The success of this project will inspire revolutionary improvements in other cancer diagnostic procedures through further research and development. We have demonstrated that the newly developed artificial visual neural networks and training methods (by presenting microcalcification patterns in the training session) can detect microcalcifications on mammograms. A similar method can be used for the detection of lung nodules on chest radiographs.  The proposed feature extraction methods and artificial visual neural networks simulate radiologists' routine practices in reading mammograms. Radiologists' viewing patterns and decision making processes will be modeled and converted to computer readable form. Preliminary studies have shown the promise of this approach. The Phase I study will address issues related to the differentiation of malignant from benign microcalcifications based on radiographs taken from breast tissue specimens. Based on Phase I study, the plan of the Phase II study is to (i) conduct the research involving classification of microcalcifications on clinical mammograms, (ii) analyze various features of benign and malignant microcalcifications and seek potential correlation with the learning patterns of the artificial visual neural network, and (iii) integrate the research outcome and implement a prototype consultation system for clinical use.  n/a",AN EXPERT-TRAINED CONSULTATION SYSTEM FOR MAMMOGRAPHY,2106194,R43CA063994,"['artificial intelligence', ' calcification', ' computer assisted diagnosis', ' computer system design /evaluation', ' digital imaging', ' human data', ' image processing', ' mammography', ' mathematical model', ' neoplasm /cancer classification /staging']",NCI,ADVANCED APPLICATIONS CORPORATION,R43,1994,79733,0.046185792990887084
"Improving the quality of visual developmental EEG data with eye tracking    DESCRIPTION (provided by applicant):  Research investigating event related potentials (ERPs) elicited by visual stimuli have increased our understanding of the neuronal processes underlying a variety of developmental disorders, such as dyslexia and ADHD, as well as perceptual and cognitive abilities in healthy adults for decades; however, these studies are currently difficult or impossible for populations who cannot sustain visual attention such as infants, young children with autism and aging dementia patients. Current methods for assuring attention in such populations include requiring a button response, which may be impossible for some or all participants, and experimenter monitoring, which is subject to error, highly variable, and spatially imprecise. We propose developing a child- centered methodology for studying the neural correlates visual categorization through the integration of ERP data acquisition systems and current eye-tracking technologies. This will allow one to (1) verify visual attention during trial presentation with 0.5 - 1 cm precision and (2) track visual gaze online such that when attention wanes it can be regained by displaying ""attention getting stimuli"" and missed trials can be repeated. Further, important questions about the neural correlates of visual categorization during typical development will be addressed. The three phases of this proposal include: establishing communication between the systems without compromising the spatial resolution of eye-tracking or the temporal resolution of the ERP, comparing this linked technology with the two current best practices for acquiring visual ERP data in children, and extending this technology to 2-3-year-olds to evaluate its effectiveness in populations with known visual attention problems. It is hypothesized that the child-centered eye-tracking and ERP linked technology will greatly reduce data variability and attrition rates in visual ERP research. By extension, visual ERP research will become applicable to questions concerning the causes, diagnoses, and treatment of a wider range of medical disorders than is currently possible. Further, this linked technology will allow for research addressing the neuronal processes associated with questions currently addressed using only eye-tracking, such as literacy, human/technology interaction, face recognition, and visual perception. As a result this application promotes the development of existing technologies to enable fundamental biomedical discoveries across a broad spectrum of disorders, most notably those that impact our understanding of the behavioral and cognitive development of children.      PUBLIC HEALTH RELEVANCE: Although Event Related Potentials (ERPs) to visual stimuli have provided vital information concerning the underlying neuronal deficits related to many medical disorders, the nature of technology currently limits the populations of study to those who can sustain visual attention for a prolonged period of time. The goal of this proposal is to link ERP technology with eye-tracking technology to allow for a wider range of populations, such as healthy infants and young children with autism, to benefit from the medical and scientific gains currently possible with visual ERP research.          Relevance Although Event Related Potentials (ERPs) to visual stimuli have provided vital information concerning the underlying neuronal deficits related to many medical disorders, the nature of technology currently limits the populations of study to those who can sustain visual attention for a prolonged period of time. The goal of this proposal is to link ERP technology with eye-tracking technology to allow for a wider range of populations, such as healthy infants and young children with autism, to benefit from the medical and scientific gains currently possible with visual ERP research.",Improving the quality of visual developmental EEG data with eye tracking,7870725,R03HD064629,"['3 year old', '8 year old', 'Address', 'Adult', 'Aging', 'Attention', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Behavioral', 'Brain', 'Child', 'Child Development', 'Cognition', 'Cognitive', 'Communication', 'Computer Simulation', 'Data', 'Dementia', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Dyslexia', 'Effectiveness', 'Electroencephalography', 'Esthesia', 'Event', 'Event-Related Potentials', 'Eye', 'Face', 'Goals', 'Human', 'Image', 'Infant', 'Length', 'Link', 'Measures', 'Medical', 'Methodology', 'Methods', 'Monitor', 'Motor', 'Nature', 'Neurons', 'Participant', 'Patients', 'Perception', 'Phase', 'Population', 'Population Study', 'Principal Component Analysis', 'Process', 'Relative (related person)', 'Research', 'Research Design', 'Resolution', 'Signal Transduction', 'Stimulus', 'System', 'Techniques', 'Technology', 'Time', 'Visual', 'Visual Perception', 'Visual attention', 'base', 'data acquisition', 'developmental disease', 'eye center', 'flexibility', 'gaze', 'improved', 'innovation', 'literacy', 'millisecond', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'time use', 'tool', 'visual stimulus', 'visual tracking']",NICHD,UNIVERSITY OF TEXAS DALLAS,R03,2010,73631,0.21963804698431721
"Constraints on Visual Statistical Learning in Infancy     DESCRIPTION (provided by applicant): Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceivethe world as predictable and stable. The proposed experiments will provide the first comprehensive examination of infants' detection of complex statistical patterns in visual sequences and layouts b describing computation of probabilistic information by infants from 2 to 14 months. This is a formaive time in perceptual and cognitive development characterized by rapid developmental change in perception and learning of environmental structure. In particular, the experiments will examine how structural variability, cognitive load, and memory limitations affect learning, how contextual cues facilitate or impede this learning, and whether the products of such learning can be generalized toa different setting. In addition, the experiments will provide critical tests of domain-specificity b examining the specific contributions of spatial information to visual statistical learning. The shot-term objectives of the proposed research are to learn how developing perceptual and cognitive skills intract in early development to identify statistically defined patterns. The long-term goals are to clarifytheories of cognitive development that posit a central role for inductive learning by computing probabilitie of observations. The results of this research may have implications for understanding development in children who may be at risk for developmental disorders such as iron-deficiency anemia and autism spectrum disorders, both of which have been characterized as deficits in implicit learning. Such an understanding may lead to assessment tools more closely tailored to early diagnosis and treatment than are presently available.          Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceive the world a predictable and stable. The proposed experiments will provide the first comprehensive examination o infants' detection of complex statistical patterns in visual sequences and layouts by describing computation of probabilistic information by infants from 2 to 14 months. This research will bring nw findings and new theoretical perspectives to longstanding debates about the origins of knowledge, ad may shed light on possible ways of examining atypical development, as when implicit learning is disrupted in infants at risk for autism or iron-deficiency anemia.            ",Constraints on Visual Statistical Learning in Infancy,9063994,R01HD073535,"['Accounting', 'Achievement', 'Address', 'Affect', 'Age', 'Appearance', 'Assessment tool', 'Attention', 'Auditory', 'Autistic Disorder', 'Child', 'Cognitive', 'Cognitive aging', 'Complex', 'Cues', 'Detection', 'Development', 'Developmental Delay Disorders', 'Dimensions', 'Discrimination', 'Early Diagnosis', 'Early treatment', 'Environment', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Infant', 'Iron deficiency anemia', 'Knowledge', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Older Population', 'Pattern', 'Perception', 'Performance', 'Population', 'Probability', 'Procedures', 'Process', 'Research', 'Risk', 'Role', 'Scanning', 'Series', 'Shapes', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Ursidae Family', 'Visual', 'Work', 'autism spectrum disorder', 'cognitive development', 'cognitive load', 'cognitive performance', 'cognitive skill', 'coping', 'developmental disease', 'disability', 'infancy', 'interest', 'novel', 'research study', 'statistics', 'theories', 'trend', 'visual information', 'visual stimulus', 'word learning']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2016,309543,0.05336099044723793
"Constraints on Visual Statistical Learning in Infancy     DESCRIPTION (provided by applicant): Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceivethe world as predictable and stable. The proposed experiments will provide the first comprehensive examination of infants' detection of complex statistical patterns in visual sequences and layouts b describing computation of probabilistic information by infants from 2 to 14 months. This is a formaive time in perceptual and cognitive development characterized by rapid developmental change in perception and learning of environmental structure. In particular, the experiments will examine how structural variability, cognitive load, and memory limitations affect learning, how contextual cues facilitate or impede this learning, and whether the products of such learning can be generalized toa different setting. In addition, the experiments will provide critical tests of domain-specificity b examining the specific contributions of spatial information to visual statistical learning. The shot-term objectives of the proposed research are to learn how developing perceptual and cognitive skills intract in early development to identify statistically defined patterns. The long-term goals are to clarifytheories of cognitive development that posit a central role for inductive learning by computing probabilitie of observations. The results of this research may have implications for understanding development in children who may be at risk for developmental disorders such as iron-deficiency anemia and autism spectrum disorders, both of which have been characterized as deficits in implicit learning. Such an understanding may lead to assessment tools more closely tailored to early diagnosis and treatment than are presently available.          Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceive the world a predictable and stable. The proposed experiments will provide the first comprehensive examination o infants' detection of complex statistical patterns in visual sequences and layouts by describing computation of probabilistic information by infants from 2 to 14 months. This research will bring nw findings and new theoretical perspectives to longstanding debates about the origins of knowledge, ad may shed light on possible ways of examining atypical development, as when implicit learning is disrupted in infants at risk for autism or iron-deficiency anemia.            ",Constraints on Visual Statistical Learning in Infancy,8853897,R01HD073535,"['Accounting', 'Achievement', 'Address', 'Affect', 'Age', 'Appearance', 'Attention', 'Auditory', 'Autistic Disorder', 'Child', 'Cognitive', 'Cognitive aging', 'Complex', 'Cues', 'Detection', 'Development', 'Developmental Delay Disorders', 'Dimensions', 'Discrimination', 'Early Diagnosis', 'Early treatment', 'Environment', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Infant', 'Iron deficiency anemia', 'Knowledge', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Older Population', 'Pattern', 'Perception', 'Performance', 'Population', 'Probability', 'Procedures', 'Process', 'Research', 'Risk', 'Role', 'Scanning', 'Series', 'Shapes', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Ursidae Family', 'Visual', 'Work', 'autism spectrum disorder', 'cognitive development', 'cognitive load', 'cognitive performance', 'cognitive skill', 'coping', 'developmental disease', 'disability', 'infancy', 'interest', 'novel', 'research study', 'statistics', 'theories', 'tool', 'trend', 'visual information', 'visual stimulus', 'word learning']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2015,304852,0.05336099044723793
"Constraints on Visual Statistical Learning in Infancy     DESCRIPTION (provided by applicant): Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceivethe world as predictable and stable. The proposed experiments will provide the first comprehensive examination of infants' detection of complex statistical patterns in visual sequences and layouts b describing computation of probabilistic information by infants from 2 to 14 months. This is a formaive time in perceptual and cognitive development characterized by rapid developmental change in perception and learning of environmental structure. In particular, the experiments will examine how structural variability, cognitive load, and memory limitations affect learning, how contextual cues facilitate or impede this learning, and whether the products of such learning can be generalized toa different setting. In addition, the experiments will provide critical tests of domain-specificity b examining the specific contributions of spatial information to visual statistical learning. The shot-term objectives of the proposed research are to learn how developing perceptual and cognitive skills intract in early development to identify statistically defined patterns. The long-term goals are to clarifytheories of cognitive development that posit a central role for inductive learning by computing probabilitie of observations. The results of this research may have implications for understanding development in children who may be at risk for developmental disorders such as iron-deficiency anemia and autism spectrum disorders, both of which have been characterized as deficits in implicit learning. Such an understanding may lead to assessment tools more closely tailored to early diagnosis and treatment than are presently available.          Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceive the world a predictable and stable. The proposed experiments will provide the first comprehensive examination o infants' detection of complex statistical patterns in visual sequences and layouts by describing computation of probabilistic information by infants from 2 to 14 months. This research will bring nw findings and new theoretical perspectives to longstanding debates about the origins of knowledge, ad may shed light on possible ways of examining atypical development, as when implicit learning is disrupted in infants at risk for autism or iron-deficiency anemia.            ",Constraints on Visual Statistical Learning in Infancy,8690126,R01HD073535,"['Accounting', 'Achievement', 'Address', 'Affect', 'Age', 'Appearance', 'Attention', 'Auditory', 'Autistic Disorder', 'Child', 'Cognitive', 'Complex', 'Cues', 'Detection', 'Development', 'Developmental Delay Disorders', 'Dimensions', 'Discrimination', 'Early Diagnosis', 'Early treatment', 'Environment', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Infant', 'Iron deficiency anemia', 'Knowledge', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Older Population', 'Pattern', 'Perception', 'Performance', 'Population', 'Probability', 'Procedures', 'Process', 'Research', 'Risk', 'Role', 'Scanning', 'Series', 'Shapes', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Ursidae Family', 'Visual', 'Work', 'autism spectrum disorder', 'coping', 'developmental disease', 'disability', 'infancy', 'interest', 'novel', 'research study', 'skills', 'statistics', 'theories', 'tool', 'trend', 'visual information', 'visual stimulus']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2014,303916,0.05336099044723793
"Constraints on Visual Statistical Learning in Infancy     DESCRIPTION (provided by applicant): Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceivethe world as predictable and stable. The proposed experiments will provide the first comprehensive examination of infants' detection of complex statistical patterns in visual sequences and layouts b describing computation of probabilistic information by infants from 2 to 14 months. This is a formaive time in perceptual and cognitive development characterized by rapid developmental change in perception and learning of environmental structure. In particular, the experiments will examine how structural variability, cognitive load, and memory limitations affect learning, how contextual cues facilitate or impede this learning, and whether the products of such learning can be generalized toa different setting. In addition, the experiments will provide critical tests of domain-specificity b examining the specific contributions of spatial information to visual statistical learning. The shot-term objectives of the proposed research are to learn how developing perceptual and cognitive skills intract in early development to identify statistically defined patterns. The long-term goals are to clarifytheories of cognitive development that posit a central role for inductive learning by computing probabilitie of observations. The results of this research may have implications for understanding development in children who may be at risk for developmental disorders such as iron-deficiency anemia and autism spectrum disorders, both of which have been characterized as deficits in implicit learning. Such an understanding may lead to assessment tools more closely tailored to early diagnosis and treatment than are presently available.          Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceive the world a predictable and stable. The proposed experiments will provide the first comprehensive examination o infants' detection of complex statistical patterns in visual sequences and layouts by describing computation of probabilistic information by infants from 2 to 14 months. This research will bring nw findings and new theoretical perspectives to longstanding debates about the origins of knowledge, ad may shed light on possible ways of examining atypical development, as when implicit learning is disrupted in infants at risk for autism or iron-deficiency anemia.            ",Constraints on Visual Statistical Learning in Infancy,8514037,R01HD073535,"['Accounting', 'Achievement', 'Address', 'Affect', 'Age', 'Appearance', 'Attention', 'Auditory', 'Autistic Disorder', 'Child', 'Cognitive', 'Complex', 'Cues', 'Detection', 'Development', 'Developmental Delay Disorders', 'Dimensions', 'Discrimination', 'Early Diagnosis', 'Early treatment', 'Environment', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Infant', 'Iron deficiency anemia', 'Knowledge', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Older Population', 'Pattern', 'Perception', 'Performance', 'Population', 'Probability', 'Procedures', 'Process', 'Research', 'Risk', 'Role', 'Scanning', 'Series', 'Shapes', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Ursidae Family', 'Visual', 'Work', 'autism spectrum disorder', 'coping', 'developmental disease', 'disability', 'infancy', 'interest', 'novel', 'research study', 'skills', 'statistics', 'theories', 'tool', 'trend', 'visual information', 'visual stimulus']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2013,296725,0.05336099044723793
"Constraints on Visual Statistical Learning in Infancy     DESCRIPTION (provided by applicant): Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceivethe world as predictable and stable. The proposed experiments will provide the first comprehensive examination of infants' detection of complex statistical patterns in visual sequences and layouts b describing computation of probabilistic information by infants from 2 to 14 months. This is a formaive time in perceptual and cognitive development characterized by rapid developmental change in perception and learning of environmental structure. In particular, the experiments will examine how structural variability, cognitive load, and memory limitations affect learning, how contextual cues facilitate or impede this learning, and whether the products of such learning can be generalized toa different setting. In addition, the experiments will provide critical tests of domain-specificity b examining the specific contributions of spatial information to visual statistical learning. The shot-term objectives of the proposed research are to learn how developing perceptual and cognitive skills intract in early development to identify statistically defined patterns. The long-term goals are to clarifytheories of cognitive development that posit a central role for inductive learning by computing probabilitie of observations. The results of this research may have implications for understanding development in children who may be at risk for developmental disorders such as iron-deficiency anemia and autism spectrum disorders, both of which have been characterized as deficits in implicit learning. Such an understanding may lead to assessment tools more closely tailored to early diagnosis and treatment than are presently available.        PUBLIC HEALTH RELEVANCE: Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceive the world a predictable and stable. The proposed experiments will provide the first comprehensive examination o infants' detection of complex statistical patterns in visual sequences and layouts by describing computation of probabilistic information by infants from 2 to 14 months. This research will bring nw findings and new theoretical perspectives to longstanding debates about the origins of knowledge, ad may shed light on possible ways of examining atypical development, as when implicit learning is disrupted in infants at risk for autism or iron-deficiency anemia.              Visual statistical learning is the process of identifying patterns of probabilistic co-occurrence among visual features, essential to our ability to perceive the world a predictable and stable. The proposed experiments will provide the first comprehensive examination o infants' detection of complex statistical patterns in visual sequences and layouts by describing computation of probabilistic information by infants from 2 to 14 months. This research will bring nw findings and new theoretical perspectives to longstanding debates about the origins of knowledge, ad may shed light on possible ways of examining atypical development, as when implicit learning is disrupted in infants at risk for autism or iron-deficiency anemia.            ",Constraints on Visual Statistical Learning in Infancy,8343731,R01HD073535,"['Accounting', 'Achievement', 'Address', 'Affect', 'Age', 'Appearance', 'Attention', 'Auditory', 'Autistic Disorder', 'Child', 'Cognitive', 'Complex', 'Cues', 'Detection', 'Development', 'Developmental Delay Disorders', 'Dimensions', 'Discrimination', 'Early Diagnosis', 'Early treatment', 'Environment', 'Eye', 'Eye Movements', 'Goals', 'Human', 'Infant', 'Iron deficiency anemia', 'Knowledge', 'Language Development', 'Lead', 'Learning', 'Light', 'Linguistics', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Older Population', 'Pattern', 'Perception', 'Performance', 'Population', 'Probability', 'Procedures', 'Process', 'Research', 'Risk', 'Role', 'Scanning', 'Series', 'Shapes', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Ursidae Family', 'Visual', 'Work', 'autism spectrum disorder', 'coping', 'developmental disease', 'disability', 'infancy', 'interest', 'novel', 'research study', 'skills', 'statistics', 'theories', 'tool', 'trend', 'visual information', 'visual stimulus']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2012,312670,0.016866064031079035
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,9327009,R00HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Anatomy', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical center', 'Memory', 'Methods', 'Modality', 'Near-Infrared Spectroscopy', 'Neonatology', 'Neural Pathways', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'Syndrome', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'experimental study', 'hemodynamics', 'high risk', 'high risk population', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'predicting response', 'programs', 'public health relevance', 'relating to nervous system', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,PRINCETON UNIVERSITY,R00,2017,242522,0.1310625913327123
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,8849468,K99HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Health', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'programs', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,UNIVERSITY OF ROCHESTER,K99,2015,82417,0.1310625913327123
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,9085979,R00HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Health', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'programs', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,PRINCETON UNIVERSITY,R00,2015,249000,0.1310625913327123
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development     DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks.         PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.                ",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,8634272,K99HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Cognitive', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Neural Pathways', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'programs', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,UNIVERSITY OF ROCHESTER,K99,2014,82417,0.1310625913327123
"Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development DESCRIPTION (provided by applicant): A hallmark of human development is the ability to make adaptive changes in perception that occurred as a result of experience. The internal representations that influence perception must be constructed from multiple levels of statistical information that are present in the natural environment. To illustrate what is meant by statistical information, after hearing a bark, there is a higher probability of seeing a dog than seeing a cat (i.e. p(Vdog | Adog) > p(Vcat | Adog). While it is widely believed that information acquired via statistical learning is an essential component of experience-based perceptual development, little is known about the neurobiological and behavioral mechanisms that translate experience into lasting perceptual change or how variations in these mechanisms can lead to atypical or delayed development. This proposal addresses three major gaps in our knowledge of the mechanisms of experience-based perceptual development: 1) the effect of statistical information on neural activity in sensory cortices in infancy; 2) whether deviations in these neural responses predict developmental delays in a high-risk population; 3) the relationship between statistically-induced changes in neural activity and behavioral changes in perception. Aim 1 Characterize the effects of statistical information on neural activity early in postnatal development. Typically developing, 6-month-olds will undergo near infrared spectroscopy (NIRS) recording to reveal changes in neural activity in auditory and visual sensory cortices during and after experience with cross-modal statistical information. We hypothesize that infant sensory cortex will exhibit significant changes in activity (i.e., increased activity during an unexpected visual omission) as  result of statistical experience. Aim 2 Examine deviations in statistically-induced neural activity in at-risk populations. If statistically-induced neural responses support typical development in numerous domains, abnormal neural responses to statistical information will predict poor behavioral outcomes later in postnatal life and establish biomarkers that could assist in ameliorating abnormal development. Using data from Aim 1 as a comparison group, we will characterize neural responses in infants at high risk for delays in perceptual and cognitive develop- ment as a result of being born extremely preterm (< 28 weeks). Aim 3 Determine the relationship between statistically-induced neural activity and perceptual change. Visual cortex activity after a visual stimulus produces a visual percept, but the behavioral consequences of visual cortex activity during the unexpected omission of a stimulus are unknown yet are essential to understanding how statistically-induced neural changes support perceptual development. Guided by specific hypotheses, we will correlate neural responses to unexpected omissions to behavior on perceptual tasks. PUBLIC HEALTH RELEVANCE: Changes in perception as a result of our experience are an essential component of infant development and in turn are key to supporting human cognition. The current proposal is significant because it is the first step in a program of research which is expected to lead to a full understanding of how experience shapes the perceptual systems in the human brain starting in infancy. Because this process of experienced-based changes in perception is believed to be foundational for normative development, such an understanding could help predict developmental delays and re-conceptualize a myriad of developmental disorders such as autism, WIlliam's Syndrome and Specific Language Impairment.",Role of Statistically Induced Changes in Sensory Cortex in Perceptual Development,9111024,R00HD076166,"['Address', 'Adult', 'Affect', 'Age', 'Attenuated', 'Auditory', 'Autistic Disorder', 'Basal Ganglia', 'Behavior', 'Behavioral', 'Behavioral Mechanisms', 'Biological Markers', 'Brain', 'Canis familiaris', 'Cognition', 'Collaborations', 'Data', 'Development', 'Developmental Delay Disorders', 'Environment', 'Event', 'Exhibits', 'Felis catus', 'Functional Magnetic Resonance Imaging', 'Gestational Age', 'Grant', 'Health', 'Hearing', 'Hippocampus (Brain)', 'Human', 'Human Development', 'Infant', 'Infant Development', 'Intervention', 'Knowledge', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Near-Infrared Spectroscopy', 'Neonatology', 'Occipital lobe', 'Outcome', 'Pediatric Neurology', 'Perception', 'Performance', 'Phase', 'Population', 'Populations at Risk', 'Premature Infant', 'Probability', 'Process', 'Recovery', 'Research', 'Resolution', 'Risk', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Translating', 'Universities', 'Variant', 'Vision', 'Visual', 'Visual Cortex', 'Visual Perception', 'Williams Syndrome', 'aged', 'awake', 'base', 'behavioral outcome', 'cognitive development', 'comparison group', 'developmental disease', 'early experience', 'experience', 'hemodynamics', 'high risk', 'infancy', 'neural correlate', 'neurobiological mechanism', 'neuroimaging', 'postnatal', 'predicting response', 'programs', 'relating to nervous system', 'research study', 'response', 'sensory cortex', 'sensory input', 'specific language impairment', 'statistics', 'visual stimulus']",NICHD,PRINCETON UNIVERSITY,R00,2016,186761,0.1310625913327123
"Auditory brain-computer interface for communication Project Summary  A fundamental end-goal of brain-computer interfaces (BCI) is to enable communication in individuals with severe motor paralysis. BCIs decode the neural signals and accomplish the intended goal via an effector, such as a computer cursor or a robotic limb. The BCI user relies on the realtime feedback of the effector's performance to modulate their neural strategy to control the external device. To date, this feedback is predominantly visual. However patients with the most severe paralysis resulting from amyotrophic lateral sclerosis (ALS), some forms of stroke and traumatic brain injuries can have severe visual impairments including oculomotor fatigue, nystagmus and ophthalmoparesis - that make the reliable use of a visual-based BCI impossible. This puts a premium on developing novel solutions that can leverage sensory modalities that are intact. In this research, I will develop and test the feasibility of an auditory-based interface to establish BCI control in motor-impaired patients with severe neurological insults  In Aim 1, I propose to implement a novel paradigm using auditory cues in lieu of visual signals, and test its feasibility in controlling an effector (ie, computer cursor) to perform a cued target-acquisition task in healthy participants. This will validate the range of parameter values of the four tested auditory input signals: 1) frequency, 2) amplitude, 3) spatial azimuth and 4) spatial elevation. This approach is distinct from most binary class auditory BCI solutions, since it relies on both the natural ability of humans to localize sounds, and the ability to associate new tones to a virtual space, thus allowing a truly multi-class auditory approach. In Aim 2, I propose to implement the auditory interface into the realtime xPC used for visual presentation in clinical trial participants with intracortical BCIs, and test their performance on the cued target-acquisition task. Although much success has been demonstrated in this task using visual feedback, this auditory approach will permit BCI use by people with visual impairments further compounding their paralysis. Finally in Aim 3, I will test the feasibility of BrainGate BCI users to utilize an auditory BCI speller to perform a copy-typing task and free- typing task.  The accomplishment of the goals of this research will be a critical step towards enabling severely paralyzed individuals with visual impairments to re-establish communication independently, continuously and reliably. Project Narrative Brain-computer interfaces enable motor-impaired individuals to communicate using an effector such as a neural cursor or a robotic arm. The successful completion of the proposed project will develop a unique technology that enables a real-time auditory-reliant BCI for communication in severely paralyzed individuals resulting from stroke, amyotrophic lateral sclerosis and severe brain injuries. Study results will advance our knowledge of developing neurotechnologies that leverage non-visual sensory modalities, as well as provide much insight into the cortical neural activities that underpin motor intention and movement.",Auditory brain-computer interface for communication,9851289,F32MH118709,"['Adult', 'Algorithms', 'Amyotrophic Lateral Sclerosis', 'Auditory', 'Auditory system', 'Base of the Brain', 'Brain Injuries', 'Brain Stem Infarctions', 'Clinical Trials', 'Communication', 'Computers', 'Cues', 'Data', 'Development', 'Devices', 'Eye Movements', 'Family Caregiver', 'Fatigue', 'Feedback', 'Frequencies', 'Functional disorder', 'Future Generations', 'Goals', 'Hearing Tests', 'Human', 'Impairment', 'Individual', 'Infrastructure', 'Institution', 'Intention', 'Joystick', 'Knowledge', 'Laboratories', 'Learning', 'Limb structure', 'Machine Learning', 'Manuals', 'Measures', 'Modality', 'Motor', 'Movement', 'Mus', 'Neurologic', 'Ophthalmopareses', 'Paralysed', 'Participant', 'Pathologic Nystagmus', 'Pathway interactions', 'Patients', 'Performance', 'Positioning Attribute', 'Psyche structure', 'Quadriplegia', 'Quality of life', 'Research', 'Resources', 'Robotics', 'Sensory', 'Signal Transduction', 'Social Interaction', 'Sound Localization', 'Speech', 'Spinal cord injury', 'Stroke', 'System', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Traumatic Brain Injury', 'Universities', 'User-Computer Interface', 'Vision', 'Visual', 'Visual Fields', 'Visual impairment', 'Workload', 'Writing', 'arm', 'auditory feedback', 'base', 'brain computer interface', 'clinical trial participant', 'engineering design', 'improved', 'insight', 'motor impairment', 'neurotechnology', 'neurotransmission', 'novel', 'oculomotor', 'relating to nervous system', 'speech synthesis', 'spelling', 'success', 'usability', 'virtual', 'visual feedback', 'way finding']",NIMH,BROWN UNIVERSITY,F32,2020,74810,0.040923591955162944
"Causal role of higher-order thalamo-cortical oscillations in sustained attention PROPOSAL SUMMARY/ABSTRACT Sustained attention – the continuous allocation of cognitive resources to respond to infrequent but behaviorally relevant stimuli – is impaired in many psychiatric disorders and represents an important aspect of cognitive control. Sustained attention requires top-down control and engagement with the external world, which is linked to both frontoparietal and thalamic controlling signals on primary sensor cortices. Despite the extensive behavioral characterization of sustained attention in animal models using the five-choice serial reaction time task (5-CSRTT), very little is known about the oscillatory interaction between the dorsal attention network and thalamo-cortical dynamics and its potential as a stimulation target for enhancing sustained attention. The objective of this project is to dissect the causal role of higher-order thalamo-cortical oscillations in sustained attention via temporally-precise rhythmic stimulation. I will focus on three regions in the visual thalamo-cortical network: higher-order visual thalamus (lateral aspect of lateral posterior nucleus, LPl), posterior parietal cortex (PPC), and primary visual cortex (V1). I will test the central hypothesis that LPl-cortical theta (4-7 Hz) functional connectivity causally coordinates PPC-V1 functional connectivity to facilitate sustained attention. The rationale of this work is that the proposed temporally-precise rhythmic optogenetic perturbations will directly test the causal role of thalamo-cortical functional connectivity in sustained attention. Accordingly, the two specific aims are: (1) Delineate the functional role of higher-order thalamo-cortical oscillations in sustained attention, (2) Determine the causal role of thalamo-cortical functional connectivity in sustained attention via temporally-precise rhythmic optogenetics. This work is significant because it will causally test a convergent model in which higher-order visual thalamus coordinates the parietal top-down control signals onto visual cortex that is crucial for developing circuit- based therapies to enhance sustained attention. The work is innovative due to its integration of closed-loop optogenetics circuit interrogation, multisite electrophysiology, freely-moving sustained attention task, and machine-learning tools for the investigation of the causal role of oscillatory synchronization. The overall positive impact of the proposed study is to provide a more comprehensive map of how the higher-order visual thalamus interacts with the frontoparietal control signal to modulate V1, and thus mediates sustained attention, a transdiagnostic cognitive function that shows impairment in many psychiatric disorders including attention deficit hyperactivity disorder, bipolar disorder, and schizophrenia. The implication of this study is that it may reveal a general mechanism underlying the interaction between two higher-order processing structures signaling to lower sensory cortices during cognitive processing. PROJECT NARRATIVE Sustained attention enables us to focus our cognitive resources on an activity for a prolonged period of time, and when impaired causes profound deficits in both cognition and behavior. Sustained attention is modulated by the thalamo-cortical rhythms. The research generated in this proposal will investigate (1) what oscillatory feature in the higher-order thalamo-cortical circuit is crucial for sustained attention, and (2) how the temporally- precise enhancing or disrupting of a thalamo-cortical oscillatory feature alters the functional connectivity in the circuit and behavioral outcomes mediated by sustained attention.",Causal role of higher-order thalamo-cortical oscillations in sustained attention,9970165,F31MH118799,"['Anatomy', 'Animal Model', 'Animals', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Behavior', 'Behavioral', 'Bipolar Disorder', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communication', 'Communities', 'Computers', 'Conflict (Psychology)', 'Couples', 'Data', 'Dorsal', 'Electrophysiology (science)', 'Exhibits', 'Ferrets', 'Foundations', 'Frequencies', 'Functional disorder', 'Impairment', 'Implant', 'Impulsivity', 'Investigation', 'Lasers', 'Lateral', 'Lateral posterior nucleus of thalamus', 'Length', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Neurons', 'Parietal', 'Parietal Lobe', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Prefrontal Cortex', 'Process', 'Psyche structure', 'Reaction Time', 'Research', 'Resources', 'Rewards', 'Role', 'Schizophrenia', 'Signal Transduction', 'Statistical Models', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thalamic structure', 'Therapeutic', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'base', 'behavioral outcome', 'calmodulin-dependent protein kinase II', 'cognitive control', 'cognitive function', 'functional disability', 'innovation', 'neurotransmission', 'novel', 'optogenetics', 'recruit', 'relating to nervous system', 'sensor', 'sensory cortex', 'signal processing', 'sustained attention', 'theories', 'tool', 'visual stimulus']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2020,37032,0.07622705566420274
"Causal role of higher-order thalamo-cortical oscillations in sustained attention PROPOSAL SUMMARY/ABSTRACT Sustained attention – the continuous allocation of cognitive resources to respond to infrequent but behaviorally relevant stimuli – is impaired in many psychiatric disorders and represents an important aspect of cognitive control. Sustained attention requires top-down control and engagement with the external world, which is linked to both frontoparietal and thalamic controlling signals on primary sensor cortices. Despite the extensive behavioral characterization of sustained attention in animal models using the five-choice serial reaction time task (5-CSRTT), very little is known about the oscillatory interaction between the dorsal attention network and thalamo-cortical dynamics and its potential as a stimulation target for enhancing sustained attention. The objective of this project is to dissect the causal role of higher-order thalamo-cortical oscillations in sustained attention via temporally-precise rhythmic stimulation. I will focus on three regions in the visual thalamo-cortical network: higher-order visual thalamus (lateral aspect of lateral posterior nucleus, LPl), posterior parietal cortex (PPC), and primary visual cortex (V1). I will test the central hypothesis that LPl-cortical theta (4-7 Hz) functional connectivity causally coordinates PPC-V1 functional connectivity to facilitate sustained attention. The rationale of this work is that the proposed temporally-precise rhythmic optogenetic perturbations will directly test the causal role of thalamo-cortical functional connectivity in sustained attention. Accordingly, the two specific aims are: (1) Delineate the functional role of higher-order thalamo-cortical oscillations in sustained attention, (2) Determine the causal role of thalamo-cortical functional connectivity in sustained attention via temporally-precise rhythmic optogenetics. This work is significant because it will causally test a convergent model in which higher-order visual thalamus coordinates the parietal top-down control signals onto visual cortex that is crucial for developing circuit- based therapies to enhance sustained attention. The work is innovative due to its integration of closed-loop optogenetics circuit interrogation, multisite electrophysiology, freely-moving sustained attention task, and machine-learning tools for the investigation of the causal role of oscillatory synchronization. The overall positive impact of the proposed study is to provide a more comprehensive map of how the higher-order visual thalamus interacts with the frontoparietal control signal to modulate V1, and thus mediates sustained attention, a transdiagnostic cognitive function that shows impairment in many psychiatric disorders including attention deficit hyperactivity disorder, bipolar disorder, and schizophrenia. The implication of this study is that it may reveal a general mechanism underlying the interaction between two higher-order processing structures signaling to lower sensory cortices during cognitive processing. PROJECT NARRATIVE Sustained attention enables us to focus our cognitive resources on an activity for a prolonged period of time, and when impaired causes profound deficits in both cognition and behavior. Sustained attention is modulated by the thalamo-cortical rhythms. The research generated in this proposal will investigate (1) what oscillatory feature in the higher-order thalamo-cortical circuit is crucial for sustained attention, and (2) how the temporally- precise enhancing or disrupting of a thalamo-cortical oscillatory feature alters the functional connectivity in the circuit and behavioral outcomes mediated by sustained attention.",Causal role of higher-order thalamo-cortical oscillations in sustained attention,9835877,F31MH118799,"['Anatomy', 'Animal Model', 'Animals', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Behavior', 'Behavioral', 'Bipolar Disorder', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communication', 'Communities', 'Computers', 'Conflict (Psychology)', 'Couples', 'Data', 'Dorsal', 'Electrophysiology (science)', 'Exhibits', 'Ferrets', 'Foundations', 'Frequencies', 'Functional disorder', 'Impairment', 'Implant', 'Impulsivity', 'Investigation', 'Lasers', 'Lateral', 'Lateral posterior nucleus of thalamus', 'Length', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Neurons', 'Parietal', 'Parietal Lobe', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Prefrontal Cortex', 'Process', 'Psyche structure', 'Reaction Time', 'Research', 'Resources', 'Rewards', 'Role', 'Schizophrenia', 'Signal Transduction', 'Statistical Models', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thalamic structure', 'Therapeutic', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'base', 'behavioral outcome', 'calmodulin-dependent protein kinase II', 'cognitive control', 'cognitive function', 'functional disability', 'innovation', 'neurotransmission', 'novel', 'optogenetics', 'recruit', 'relating to nervous system', 'sensor', 'sensory cortex', 'signal processing', 'sustained attention', 'theories', 'tool', 'visual stimulus']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2019,36528,0.07622705566420274
