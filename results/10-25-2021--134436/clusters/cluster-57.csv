text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"SPECT Imaging and Parallel Computing     DESCRIPTION (provided by applicant): The long-term objective of this grant is to use the recent rapid advances in parallel computational hardware and associated software to enable new approaches to image science and image-quality assessment in the context of single-photon emission computed tomography (SPECT). To achieve this broad objective, research under this grant strives to develop new concepts, mathematical theories and models as well as the new computational hardware and algorithms needed to implement them. One major area of emphasis is on system models in which the object is described as a function of space and time rather than as a discrete array of voxels. In this approach, the system is described by an operator rather than a matrix, and we focus on exact mathematical descriptions of this operator either through analytical singular-value decomposition or by means of the Fourier crosstalk matrix. This analysis will allow determination of the inevitable null functions (invisible objects)for any particular system and will show how the null space can be controlled by the use of a positivity constraint in the reconstruction. The object function can be regarded as one sample function of a spatiotemporal random process, and another area of emphasis will be the full infinite-dimensional characterization of this random process through a concept called a characteristic functional. Knowledge of this functional will lead to an understanding of the statistics of features derived from a reconstructed image and to new methods for computing task-based metrics of image quality.  The raw image data in SPECT and other photon-counting modalities is not a pixelized projection image but rather a list of attributes, such as position, energy and time of arrival, of each detected photon. The measured attributes can be regarded as samples from a complicated random point process, and we have derived the operator that relates the mean of this process to the spatiotemporal object function. We will study the properties of this operator in detail and relate it to image quality. This analysis will permit a rigorous study of the relation between radiation dose and image quality. Other studies will investigate new figures of merit for image quality and apply them to the optimization of SPECT systems and to the new field of adaptive SPECT. Computational power for these efforts will be obtained either through next-generation graphics processing units such as the Nvidia Maxwell or with arrays of CPUs and coprocessors. Parallel code to implement all of these advances will be made available through the web.          Image science provides the basic experimental, theoretical and computational framework needed for the objective analysis and optimization of medical imaging systems. In this grant we strive to expand the tools of image science within the context of a particular modality, Single- Photon Emission Computed Tomography or SPECT, and to develop new computational methods for assessing and improving image quality as defined in terms of specific medical tasks. By harnessing the massive computational power now becoming available at relatively low cost, we will be able to solve a number of long-standing problems in image science and advance the state-of-the-art in medical and biomedical imaging.            ",SPECT Imaging and Parallel Computing,8839670,R01EB000803,"['Accounting', 'Algorithms', 'Area', 'Biological Models', 'Characteristics', 'Code', 'Communities', 'Compton radiation', 'Computer Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Dose', 'Effectiveness', 'Equation', 'Funding', 'Gamma Rays', 'Goals', 'Grant', 'Image', 'Imaging Device', 'Internet', 'Knowledge', 'Lead', 'Measures', 'Medical', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Patients', 'Performance', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Property', 'Radiation', 'Request for Applications', 'Research', 'Sampling', 'Science', 'Sister', 'Speed', 'Statistical Models', 'Statistical Study', 'System', 'Systems Analysis', 'Time', 'base', 'bioimaging', 'citizen science', 'clinically relevant', 'computer framework', 'computing resources', 'cost', 'data acquisition', 'imaging modality', 'imaging system', 'improved', 'mathematical model', 'mathematical theory', 'next generation', 'novel', 'novel strategies', 'operation', 'parallel computer', 'reconstruction', 'single photon emission computed tomography', 'spatiotemporal', 'statistics', 'theories', 'tomography', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2015,444106,0.16852151329769274
"SPECT Imaging and Parallel Computing     DESCRIPTION (provided by applicant): The long-term objective of this grant is to use the recent rapid advances in parallel computational hardware and associated software to enable new approaches to image science and image-quality assessment in the context of single-photon emission computed tomography (SPECT). To achieve this broad objective, research under this grant strives to develop new concepts, mathematical theories and models as well as the new computational hardware and algorithms needed to implement them. One major area of emphasis is on system models in which the object is described as a function of space and time rather than as a discrete array of voxels. In this approach, the system is described by an operator rather than a matrix, and we focus on exact mathematical descriptions of this operator either through analytical singular-value decomposition or by means of the Fourier crosstalk matrix. This analysis will allow determination of the inevitable null functions (invisible objects)for any particular system and will show how the null space can be controlled by the use of a positivity constraint in the reconstruction. The object function can be regarded as one sample function of a spatiotemporal random process, and another area of emphasis will be the full infinite-dimensional characterization of this random process through a concept called a characteristic functional. Knowledge of this functional will lead to an understanding of the statistics of features derived from a reconstructed image and to new methods for computing task-based metrics of image quality.  The raw image data in SPECT and other photon-counting modalities is not a pixelized projection image but rather a list of attributes, such as position, energy and time of arrival, of each detected photon. The measured attributes can be regarded as samples from a complicated random point process, and we have derived the operator that relates the mean of this process to the spatiotemporal object function. We will study the properties of this operator in detail and relate it to image quality. This analysis will permit a rigorous study of the relation between radiation dose and image quality. Other studies will investigate new figures of merit for image quality and apply them to the optimization of SPECT systems and to the new field of adaptive SPECT. Computational power for these efforts will be obtained either through next-generation graphics processing units such as the Nvidia Maxwell or with arrays of CPUs and coprocessors. Parallel code to implement all of these advances will be made available through the web.          Image science provides the basic experimental, theoretical and computational framework needed for the objective analysis and optimization of medical imaging systems. In this grant we strive to expand the tools of image science within the context of a particular modality, Single- Photon Emission Computed Tomography or SPECT, and to develop new computational methods for assessing and improving image quality as defined in terms of specific medical tasks. By harnessing the massive computational power now becoming available at relatively low cost, we will be able to solve a number of long-standing problems in image science and advance the state-of-the-art in medical and biomedical imaging.            ",SPECT Imaging and Parallel Computing,8636473,R01EB000803,"['Accounting', 'Algorithms', 'Area', 'Biological Models', 'Characteristics', 'Code', 'Communities', 'Computer Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Dose', 'Effectiveness', 'Equation', 'Funding', 'Gamma Rays', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging Device', 'Internet', 'Knowledge', 'Lead', 'Measures', 'Medical', 'Medical Imaging', 'Methods', 'Metric', 'Modality', 'Modeling', 'Patients', 'Performance', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Property', 'Radiation', 'Request for Applications', 'Research', 'Sampling', 'Science', 'Sister', 'Speed', 'Statistical Models', 'Statistical Study', 'System', 'Systems Analysis', 'Time', 'base', 'bioimaging', 'clinically relevant', 'computer framework', 'computing resources', 'cost', 'data acquisition', 'imaging modality', 'improved', 'mathematical model', 'mathematical theory', 'next generation', 'novel', 'novel strategies', 'operation', 'parallel computer', 'reconstruction', 'single photon emission computed tomography', 'spatiotemporal', 'statistics', 'theories', 'tomography', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2014,439575,0.16852151329769274
"SPECT Imaging and Parallel Computing     DESCRIPTION (provided by applicant): The long-term objective of this grant is to use the recent rapid advances in parallel computational hardware and associated software to enable new approaches to image science and image-quality assessment in the context of single-photon emission computed tomography (SPECT). To achieve this broad objective, research under this grant strives to develop new concepts, mathematical theories and models as well as the new computational hardware and algorithms needed to implement them. One major area of emphasis is on system models in which the object is described as a function of space and time rather than as a discrete array of voxels. In this approach, the system is described by an operator rather than a matrix, and we focus on exact mathematical descriptions of this operator either through analytical singular-value decomposition or by means of the Fourier crosstalk matrix. This analysis will allow determination of the inevitable null functions (invisible objects)for any particular system and will show how the null space can be controlled by the use of a positivity constraint in the reconstruction. The object function can be regarded as one sample function of a spatiotemporal random process, and another area of emphasis will be the full infinite-dimensional characterization of this random process through a concept called a characteristic functional. Knowledge of this functional will lead to an understanding of the statistics of features derived from a reconstructed image and to new methods for computing task-based metrics of image quality.  The raw image data in SPECT and other photon-counting modalities is not a pixelized projection image but rather a list of attributes, such as position, energy and time of arrival, of each detected photon. The measured attributes can be regarded as samples from a complicated random point process, and we have derived the operator that relates the mean of this process to the spatiotemporal object function. We will study the properties of this operator in detail and relate it to image quality. This analysis will permit a rigorous study of the relation between radiation dose and image quality. Other studies will investigate new figures of merit for image quality and apply them to the optimization of SPECT systems and to the new field of adaptive SPECT. Computational power for these efforts will be obtained either through next-generation graphics processing units such as the Nvidia Maxwell or with arrays of CPUs and coprocessors. Parallel code to implement all of these advances will be made available through the web.          Image science provides the basic experimental, theoretical and computational framework needed for the objective analysis and optimization of medical imaging systems. In this grant we strive to expand the tools of image science within the context of a particular modality, Single- Photon Emission Computed Tomography or SPECT, and to develop new computational methods for assessing and improving image quality as defined in terms of specific medical tasks. By harnessing the massive computational power now becoming available at relatively low cost, we will be able to solve a number of long-standing problems in image science and advance the state-of-the-art in medical and biomedical imaging.            ",SPECT Imaging and Parallel Computing,8432005,R01EB000803,"['Accounting', 'Algorithms', 'Area', 'Biological Models', 'Characteristics', 'Code', 'Communities', 'Computer Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Dose', 'Effectiveness', 'Equation', 'Funding', 'Gamma Rays', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging Device', 'Internet', 'Knowledge', 'Lead', 'Measures', 'Medical', 'Medical Imaging', 'Methods', 'Metric', 'Modality', 'Modeling', 'Patients', 'Performance', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Property', 'Radiation', 'Request for Applications', 'Research', 'Sampling', 'Science', 'Sister', 'Speed', 'Statistical Models', 'Statistical Study', 'System', 'Systems Analysis', 'Time', 'base', 'bioimaging', 'clinically relevant', 'computer framework', 'computing resources', 'cost', 'data acquisition', 'imaging modality', 'improved', 'mathematical model', 'mathematical theory', 'next generation', 'novel', 'novel strategies', 'operation', 'parallel computing', 'reconstruction', 'single photon emission computed tomography', 'spatiotemporal', 'statistics', 'theories', 'tomography', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2013,427151,0.16852151329769274
"SPECT Imaging and Parallel Computing     DESCRIPTION (provided by applicant): The long-term objective of this grant is to use the recent rapid advances in parallel computational hardware and associated software to enable new approaches to image science and image-quality assessment in the context of single-photon emission computed tomography (SPECT). To achieve this broad objective, research under this grant strives to develop new concepts, mathematical theories and models as well as the new computational hardware and algorithms needed to implement them. One major area of emphasis is on system models in which the object is described as a function of space and time rather than as a discrete array of voxels. In this approach, the system is described by an operator rather than a matrix, and we focus on exact mathematical descriptions of this operator either through analytical singular-value decomposition or by means of the Fourier crosstalk matrix. This analysis will allow determination of the inevitable null functions (invisible objects)for any particular system and will show how the null space can be controlled by the use of a positivity constraint in the reconstruction. The object function can be regarded as one sample function of a spatiotemporal random process, and another area of emphasis will be the full infinite-dimensional characterization of this random process through a concept called a characteristic functional. Knowledge of this functional will lead to an understanding of the statistics of features derived from a reconstructed image and to new methods for computing task-based metrics of image quality.  The raw image data in SPECT and other photon-counting modalities is not a pixelized projection image but rather a list of attributes, such as position, energy and time of arrival, of each detected photon. The measured attributes can be regarded as samples from a complicated random point process, and we have derived the operator that relates the mean of this process to the spatiotemporal object function. We will study the properties of this operator in detail and relate it to image quality. This analysis will permit a rigorous study of the relation between radiation dose and image quality. Other studies will investigate new figures of merit for image quality and apply them to the optimization of SPECT systems and to the new field of adaptive SPECT. Computational power for these efforts will be obtained either through next-generation graphics processing units such as the Nvidia Maxwell or with arrays of CPUs and coprocessors. Parallel code to implement all of these advances will be made available through the web.        PUBLIC HEALTH RELEVANCE: Image science provides the basic experimental, theoretical and computational framework needed for the objective analysis and optimization of medical imaging systems. In this grant we strive to expand the tools of image science within the context of a particular modality, Single- Photon Emission Computed Tomography or SPECT, and to develop new computational methods for assessing and improving image quality as defined in terms of specific medical tasks. By harnessing the massive computational power now becoming available at relatively low cost, we will be able to solve a number of long-standing problems in image science and advance the state-of-the-art in medical and biomedical imaging.              Image science provides the basic experimental, theoretical and computational framework needed for the objective analysis and optimization of medical imaging systems. In this grant we strive to expand the tools of image science within the context of a particular modality, Single- Photon Emission Computed Tomography or SPECT, and to develop new computational methods for assessing and improving image quality as defined in terms of specific medical tasks. By harnessing the massive computational power now becoming available at relatively low cost, we will be able to solve a number of long-standing problems in image science and advance the state-of-the-art in medical and biomedical imaging.            ",SPECT Imaging and Parallel Computing,8295555,R01EB000803,"['Accounting', 'Algorithms', 'Area', 'Biological Models', 'Characteristics', 'Code', 'Communities', 'Computer Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Dose', 'Effectiveness', 'Equation', 'Funding', 'Gamma Rays', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging Device', 'Internet', 'Knowledge', 'Lead', 'Measures', 'Medical', 'Medical Imaging', 'Methods', 'Metric', 'Modality', 'Modeling', 'Patients', 'Performance', 'Photons', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Property', 'Radiation', 'Request for Applications', 'Research', 'Sampling', 'Science', 'Sister', 'Speed', 'Statistical Models', 'Statistical Study', 'System', 'Systems Analysis', 'Time', 'base', 'bioimaging', 'clinically relevant', 'computer framework', 'computing resources', 'cost', 'data acquisition', 'imaging modality', 'improved', 'mathematical model', 'mathematical theory', 'next generation', 'novel', 'novel strategies', 'operation', 'parallel computing', 'reconstruction', 'single photon emission computed tomography', 'spatiotemporal', 'statistics', 'theories', 'tomography', 'web site']",NIBIB,UNIVERSITY OF ARIZONA,R01,2012,449785,0.1352008774173071
"AN INTERACTIVE BIOMEDICAL IMAGE PROCESSOR/ANALYZER Current morphometry and image analysis systems can be broadly divided into those which display an image and require the user to trace the points or lines considered significant and those which apply complex algorithms to locate significant objects autonomously.  We have developed a prototype of an intermediate type of system in which the user can rapidly indicate the approximate location of significant objects after which the system applies an edge following algorithm to determine the exact boundary of the object. This system will be much faster to use than ""dumb"" morphometry systems and much less costly than ""intelligent"" image analyzers costing hundreds of thousands of dollars.  This system uses a new VLSI microprocessor specialized for signal processing tasks and innovative image processing circuitry we have designed.  We believe we can design a system of this type to sell for approximately $10,000.  This would bring powerful image processing technology within the reach of many more investigators.  n/a",AN INTERACTIVE BIOMEDICAL IMAGE PROCESSOR/ANALYZER,3509339,R44RR002224,"['artificial intelligence', ' biomedical automation', ' computer graphics /printing', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' computers', ' image processing', ' morphology']",NCRR,"AMERICAN INNOVISION, INC.",R44,1986,215742,0.2463970639484166
"AN INTERACTIVE BIOMEDICAL IMAGE PROCESSOR/ANALYZER Current morphometry and image analysis systems can be broadly divided into those which display an image and require the user to trace the points or lines considered significant and those which apply complex algorithms to locate significant objects autonomously.  We have developed a prototype of an intermediate type of system in which the user can rapidly indicate the approximate location of significant objects after which the system applies an edge following algorithm to determine the exact boundary of the object. This system will be much faster to use than ""dumb"" morphometry systems and much less costly than ""intelligent"" image analyzers costing hundreds of thousands of dollars.  This system uses a new VLSI microprocessor specialized for signal processing tasks and innovative image processing circuitry we have designed.  We believe we can design a system of this type to sell for approximately $10,000.  This would bring powerful image processing technology within the reach of many more investigators.  n/a",AN INTERACTIVE BIOMEDICAL IMAGE PROCESSOR/ANALYZER,3509338,R44RR002224,"['artificial intelligence', ' biomedical automation', ' computer graphics /printing', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' computers', ' image processing', ' morphology']",NCRR,"AMERICAN INNOVISION, INC.",R44,1985,243988,0.2463970639484166
"NEURO-IMAGING EXPERT SYSTEM It is proposed to develop a computerized expert system for analyzing and understanding the images of the nervous system generated by neuroimaging techniques such as computerized tomography (CT).  A prototype version, called RAD (Radiologic Automatic Diagnosis), has been implemented.  RAD will serve as an expert consultant in the field of neuroradiology, as an adjunct to computerized expert systems for medical diagnosis, and as an intelligent image processor supporting automated feature extraction from neuro-images.  Modern neuroimaging techniques have revolutionized the practice of neurology and neurosurgery.  The rapid proliferation of scanners, however, has outstripped the supply of experts with special training in scan interpretation.  If a scanner could produce the differential diagnosis associated with the radiographs, it could aid radiologists in diagnostic tasks.  Images received in digitized form from scanning devices will be segmented into objects after thresholding based on radiodensity (CT scans).  This process will be aided by intelligent histogram optimizers and artifact removal programs.  Analysis will be conducted in an object-oriented programming environment on objects represented in quadtree or octree format.  RAD will employ clinical information, and knowledge bases in neuroanatomy, neuroradiology, neurology, and medicine to establish a context for analysis.  This context will be instantiated in the form of assertions on a queue of beliefs in a truth maintenance system.  Global and local image analyzers will also make assertions about neuro-images.  The truth maintenance system will keep track of any contradictions which arise, and will provide forward chaining and backtracking explanation abilities of the reasoning leading to the differential diagnosis.  At the present time, medical diagnostic expert systems, such as INTERNIST-I/CADUCEUS are dependent for its input upon the physician-user. The ability to directly interact with patient data in neuro-images would enrich the diagnostic foundation of the system and reduce obligate user interaction.  n/a",NEURO-IMAGING EXPERT SYSTEM,3373691,R01LM004431,"['artificial intelligence', ' brain disorder diagnosis', ' computed axial tomography', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' image processing', ' information theory']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,1987,190171,0.11114932115761438
"NEURO-IMAGING EXPERT SYSTEM It is proposed to develop a computerized expert system for analyzing and understanding the images of the nervous system generated by neuroimaging techniques such as computerized tomography (CT).  A prototype version, called RAD (Radiologic Automatic Diagnosis), has been implemented.  RAD will serve as an expert consultant in the field of neuroradiology, as an adjunct to computerized expert systems for medical diagnosis, and as an intelligent image processor supporting automated feature extraction from neuro-images.  Modern neuroimaging techniques have revolutionized the practice of neurology and neurosurgery.  The rapid proliferation of scanners, however, has outstripped the supply of experts with special training in scan interpretation.  If a scanner could produce the differential diagnosis associated with the radiographs, it could aid radiologists in diagnostic tasks.  Images received in digitized form from scanning devices will be segmented into objects after thresholding based on radiodensity (CT scans).  This process will be aided by intelligent histogram optimizers and artifact removal programs.  Analysis will be conducted in an object-oriented programming environment on objects represented in quadtree or octree format.  RAD will employ clinical information, and knowledge bases in neuroanatomy, neuroradiology, neurology, and medicine to establish a context for analysis.  This context will be instantiated in the form of assertions on a queue of beliefs in a truth maintenance system.  Global and local image analyzers will also make assertions about neuro-images.  The truth maintenance system will keep track of any contradictions which arise, and will provide forward chaining and backtracking explanation abilities of the reasoning leading to the differential diagnosis.  At the present time, medical diagnostic expert systems, such as INTERNIST-I/CADUCEUS are dependent for its input upon the physician-user. The ability to directly interact with patient data in neuro-images would enrich the diagnostic foundation of the system and reduce obligate user interaction.  n/a",NEURO-IMAGING EXPERT SYSTEM,3373690,R01LM004431,"['artificial intelligence', ' brain disorder diagnosis', ' computed axial tomography', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' image processing', ' information theory']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,1986,177089,0.11114932115761438
"NEURO-IMAGING EXPERT SYSTEM It is proposed to develop a computerized expert system for analyzing and understanding the images of the nervous system generated by neuroimaging techniques such as computerized tomography (CT).  A prototype version, called RAD (Radiologic Automatic Diagnosis), has been implemented.  RAD will serve as an expert consultant in the field of neuroradiology, as an adjunct to computerized expert systems for medical diagnosis, and as an intelligent image processor supporting automated feature extraction from neuro-images.  Modern neuroimaging techniques have revolutionized the practice of neurology and neurosurgery.  The rapid proliferation of scanners, however, has outstripped the supply of experts with special training in scan interpretation.  If a scanner could produce the differential diagnosis associated with the radiographs, it could aid radiologists in diagnostic tasks.  Images received in digitized form from scanning devices will be segmented into objects after thresholding based on radiodensity (CT scans).  This process will be aided by intelligent histogram optimizers and artifact removal programs.  Analysis will be conducted in an object-oriented programming environment on objects represented in quadtree or octree format.  RAD will employ clinical information, and knowledge bases in neuroanatomy, neuroradiology, neurology, and medicine to establish a context for analysis.  This context will be instantiated in the form of assertions on a queue of beliefs in a truth maintenance system.  Global and local image analyzers will also make assertions about neuro-images.  The truth maintenance system will keep track of any contradictions which arise, and will provide forward chaining and backtracking explanation abilities of the reasoning leading to the differential diagnosis.  At the present time, medical diagnostic expert systems, such as INTERNIST-I/CADUCEUS are dependent for its input upon the physician-user. The ability to directly interact with patient data in neuro-images would enrich the diagnostic foundation of the system and reduce obligate user interaction.  n/a",NEURO-IMAGING EXPERT SYSTEM,3373688,R01LM004431,"['artificial intelligence', ' computed axial tomography', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' image processing', ' information theory', ' nervous system disorder diagnosis']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,1985,211828,0.11114932115761438
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7350139,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Condition', 'Count', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Numbers', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Rate', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'size', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2008,322249,0.2266935174121008
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7765534,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2010,324963,0.2266935174121008
"Transmission of Information in the Visual System How do we identify an object from the features that we detect? Understanding how the brain recognizes objects might give insight into how the brain solves problems in general. The object recognition problem has withstood a century of attempts, but we bring new tools ¿ fruits of the last grant period ¿ that allow us to sketch the outlines of a solution. Four approaches, all new and different, converge on one answer. AIM 1. Use crowding, along with other manipulations, to characterize three parallel processes in reading by normal and dyslexic readers. AIM 2. Count features by probability summation. Extending traditional probability summation from explaining just detection to also explain object identification, we acquire a new tool, allowing us to count the number of features the observer must detect in order to identify. AIM 3. Capture the observer's classification algorithm by computer modeling of the observer's responses to thousands of letters in white noise. We use statistical learning theory to build a classifier that accounts for human performance. The observer classifies each of several thousand images of a letter in noise as ""a"", ""b"", or ""c"", etc. These classifications are data that can tell us what the observer is doing. We use a powerful statistical learning algorithm to create a simple classifier that best models human performance. AIM 4. fMRI: Where in the brain are letters identified? Correlate the activation of the ""letter"" area in the left fusiform gyrus, and elsewhere, with two psychophysically-discovered signatures of letter identification: fast learning and channel frequency. Thus techniques from cognition, perception, statistical learning theory, and physiology together will reveal what is computed where, in the brain, when an observer identifies an object. n/a",Transmission of Information in the Visual System,7583948,R01EY004432,"['Accounting', 'Address', 'Adult', 'Age', 'Algorithms', 'Area', 'Brain', 'Cells', 'Child', 'Classification', 'Cognition', 'Computer Simulation', 'Computer-Assisted Image Analysis', 'Crowding', 'Data', 'Detection', 'Diagnostic', 'Frequencies', 'Fruit', 'Functional Magnetic Resonance Imaging', 'Fusiform gyrus', 'Grant', 'Growth', 'Human', 'Image', 'Knock-out', 'Learning', 'Left', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Measures', 'Mediating', 'Modeling', 'Names', 'Neural Network Simulation', 'Noise', 'Perception', 'Performance', 'Physiology', 'Probability', 'Problem Solving', 'Process', 'Psychophysiology', 'Reader', 'Reading', 'Schools', 'Solutions', 'Stimulus', 'Stroke', 'Sum', 'Surveys', 'Techniques', 'Testing', 'Text', 'Time', 'Ursidae Family', 'Visual system structure', 'Weight', 'Work', 'detector', 'insight', 'object recognition', 'parallel processing', 'peripheral reading', 'receptive field', 'research study', 'response', 'theories', 'tool', 'transmission process']",NEI,NEW YORK UNIVERSITY,R01,2009,328593,0.2266935174121008
"STRUCTURED ANALYSIS OF THE RETINA In the STARE (STructured Analysis of the REtina) project, we are                 developing a computerized image-interpreting system with hierarchical            inferencing to measure, compare, and diagnose images of the ocular               fundus. The system will have sufficient depth of imaging tools to be a           resource for researchers or clinicians.                                                                                                                           The STARE system is designed to find objects of interest (normal                 anatomical structures and lesions) in digitized ocular fundus images and         to use these objects to diagnose an image, to detect changes in                  sequential images, and to make clinically useful measurements that are           currently tedious or costly. To accomplish these difficult goals, we             must segment and identify the objects of interest. Identified objects            can be used to compare images, and the objects can be assembled to               describe the image. Image interpretation incorporating expert systems            and neural networks can provide the structure for cross-sectional                epidemiological studies.                                                                                                                                          There was no established paradigm to follow to construct a system for            image interpretation. We designed the overall structure of the process           and determined how each task was to be accomplished. We have broken the          project into steps, each of which has been accomplished. We are able to          find objects of importance and correctly identify and localize them on           a fundus coordinate system that we designed. We have created and tested          a neural network and an expert system (INTELLEYE) to handle the                  interpretation of an image and its contents.                                                                                                                      We will now improve the accuracy of each step, increase the number of            lesions we can identify, and integrate the image analysis steps with the         expert system to allow smooth progression from image to diagnosis and            change detection. We will validate the usefulness and accuracy of the            system by comparing its diagnosis and image comparison to trained                readers of ophthalmic images.                                                                                                                                     The goal of this project is a system with multiple imaging tools and             inferencing ability that can be adapted to a variety of imaging tasks.           The outcome will be an image-interpreting system for use in clinical and         research settings that will build annotated image databases, screen              images of the ocular fundus for health care systems, furnish decision            support for primary care providers, and extend the capability and                productivity of the ophthalmologist.                                              n/a",STRUCTURED ANALYSIS OF THE RETINA,6130715,R01LM005759,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer system design /evaluation', ' diagnosis design /evaluation', ' digital imaging', ' eye fundus photography', ' human subject', ' image processing']",NLM,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1999,96832,0.20071730323339307
"STRUCTURED ANALYSIS OF THE RETINA In the STARE (STructured Analysis of the REtina) project, we are                 developing a computerized image-interpreting system with hierarchical            inferencing to measure, compare, and diagnose images of the ocular               fundus. The system will have sufficient depth of imaging tools to be a           resource for researchers or clinicians.                                                                                                                           The STARE system is designed to find objects of interest (normal                 anatomical structures and lesions) in digitized ocular fundus images and         to use these objects to diagnose an image, to detect changes in                  sequential images, and to make clinically useful measurements that are           currently tedious or costly. To accomplish these difficult goals, we             must segment and identify the objects of interest. Identified objects            can be used to compare images, and the objects can be assembled to               describe the image. Image interpretation incorporating expert systems            and neural networks can provide the structure for cross-sectional                epidemiological studies.                                                                                                                                          There was no established paradigm to follow to construct a system for            image interpretation. We designed the overall structure of the process           and determined how each task was to be accomplished. We have broken the          project into steps, each of which has been accomplished. We are able to          find objects of importance and correctly identify and localize them on           a fundus coordinate system that we designed. We have created and tested          a neural network and an expert system (INTELLEYE) to handle the                  interpretation of an image and its contents.                                                                                                                      We will now improve the accuracy of each step, increase the number of            lesions we can identify, and integrate the image analysis steps with the         expert system to allow smooth progression from image to diagnosis and            change detection. We will validate the usefulness and accuracy of the            system by comparing its diagnosis and image comparison to trained                readers of ophthalmic images.                                                                                                                                     The goal of this project is a system with multiple imaging tools and             inferencing ability that can be adapted to a variety of imaging tasks.           The outcome will be an image-interpreting system for use in clinical and         research settings that will build annotated image databases, screen              images of the ocular fundus for health care systems, furnish decision            support for primary care providers, and extend the capability and                productivity of the ophthalmologist.                                              n/a",STRUCTURED ANALYSIS OF THE RETINA,2415716,R01LM005759,"['artificial intelligence', ' computer system design /evaluation', ' diagnosis design /evaluation', ' digital imaging', ' eye fundus photography', ' human subject', ' image processing']",NLM,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1997,265260,0.20071730323339307
"STRUCTURED ANALYSIS OF THE RETINA In the STARE (STructured Analysis of the REtina) project, we are  developing a computerized image-interpreting system with hierarchical  inferencing to measure, compare, and diagnose images of the ocular  fundus. The system will have sufficient depth of imaging tools to be a  resource for researchers or clinicians.    The STARE system is designed to find objects of interest (normal  anatomical structures and lesions) in digitized ocular fundus images and  to use these objects to diagnose an image, to detect changes in  sequential images, and to make clinically useful measurements that are  currently tedious or costly. To accomplish these difficult goals, we  must segment and identify the objects of interest. Identified objects  can be used to compare images, and the objects can be assembled to  describe the image. Image interpretation incorporating expert systems  and neural networks can provide the structure for cross-sectional  epidemiological studies.    There was no established paradigm to follow to construct a system for  image interpretation. We designed the overall structure of the process  and determined how each task was to be accomplished. We have broken the  project into steps, each of which has been accomplished. We are able to  find objects of importance and correctly identify and localize them on  a fundus coordinate system that we designed. We have created and tested  a neural network and an expert system (INTELLEYE) to handle the  interpretation of an image and its contents.    We will now improve the accuracy of each step, increase the number of  lesions we can identify, and integrate the image analysis steps with the  expert system to allow smooth progression from image to diagnosis and  change detection. We will validate the usefulness and accuracy of the  system by comparing its diagnosis and image comparison to trained  readers of ophthalmic images.    The goal of this project is a system with multiple imaging tools and  inferencing ability that can be adapted to a variety of imaging tasks.  The outcome will be an image-interpreting system for use in clinical and  research settings that will build annotated image databases, screen  images of the ocular fundus for health care systems, furnish decision  support for primary care providers, and extend the capability and  productivity of the ophthalmologist.  n/a",STRUCTURED ANALYSIS OF THE RETINA,2238143,R01LM005759,"['artificial intelligence', ' computer system design /evaluation', ' diagnosis design /evaluation', ' digital imaging', ' eye fundus photography', ' human subject', ' image processing']",NLM,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1995,274013,0.20071730323339307
"STRUCTURED ANALYSIS OF THE RETINA STARE (STructured Analysis of the REtina) is a system for computer-aided analysis of ocular fundus images and fluorescein angiograms.  The combination of image analysis in conjunction with expert systems and neural networks is a sophisticated and innovative approach in ophthalmology.  We propose to continue our development of STARE for a second three-year period.  The process of transforming an image of the retina into a set of differential diagnoses is complex but manageable.  The image is broken up into 250,000 picture elements (pixels) with 256 levels of gray or 16 million colors.  Specialized image-processing algorithms form groups of pixels that have common attributes, such as texture or a range of brightness or color.  Other algorithms assemble the lines and regions into different objects (e.g. optic nerve, blood vessels, lesions) that are not yet identified.  Features, such as color, size, shape, and edge sharpness, that describe these objects are measured.  Statistical classifiersm or expert systems may be used to identify each object.  When all the relevant objects in the picture have been found and identified, each objects, its location, and its relationship to other objects are stored in a database which forms a coded description of the image.  That description is used by a neural network or an expert system either to create a differential diagnosis list with the probability of each diagnosis or to detect change in a sequence of images.  We have developed algorithms that perform a large number of image processing tasks, and we have applied many of them for the automatic location and identification of the optic nerve, blood vessels, the fovea, exudates, cotton-wool spots, drusen, and various intraretinal hemorrhages. We have also demonstrated that the type of information in a coded description of ocular images can successfully teach a neural network to diagnose diseases from new images.  In the proposed continuation, we will expand the identification capability to more objects, thus achieving a fuller description of the image.  We will develop neural networks and expert systems to determine which is superior for transforming objects into diagnoses.  We will compare measurements of the same objects in a sequence of images to detect change.  As our ability to identify objects becomes more complete, we will apply all the steps to diagnose one disease, diabetes, and then expand the number of diseases.  Ultimately, we will have an automated ophthalmic image diagnosis system with a graphics user interface that will furnish decision support and teaching and extend the capability and productivity of the ophthalmologist and his/her assistants.  n/a",STRUCTURED ANALYSIS OF THE RETINA,3261868,R01EY005996,"['artificial intelligence', ' computer assisted diagnosis', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer simulation', ' eye disorder diagnosis', ' eye fundus photography', ' fluorescein angiography', ' human subject', ' image processing', ' mathematics', ' retina', ' retina disorder', ' statistics /biometry']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1992,166315,0.2745762249965466
"STRUCTURED ANALYSIS OF THE RETINA STARE (STructured Analysis of the REtina) is a system for computer-aided analysis of ocular fundus images and fluorescein angiograms.  The combination of image analysis in conjunction with expert systems and neural networks is a sophisticated and innovative approach in ophthalmology.  We propose to continue our development of STARE for a second three-year period.  The process of transforming an image of the retina into a set of differential diagnoses is complex but manageable.  The image is broken up into 250,000 picture elements (pixels) with 256 levels of gray or 16 million colors.  Specialized image-processing algorithms form groups of pixels that have common attributes, such as texture or a range of brightness or color.  Other algorithms assemble the lines and regions into different objects (e.g. optic nerve, blood vessels, lesions) that are not yet identified.  Features, such as color, size, shape, and edge sharpness, that describe these objects are measured.  Statistical classifiersm or expert systems may be used to identify each object.  When all the relevant objects in the picture have been found and identified, each objects, its location, and its relationship to other objects are stored in a database which forms a coded description of the image.  That description is used by a neural network or an expert system either to create a differential diagnosis list with the probability of each diagnosis or to detect change in a sequence of images.  We have developed algorithms that perform a large number of image processing tasks, and we have applied many of them for the automatic location and identification of the optic nerve, blood vessels, the fovea, exudates, cotton-wool spots, drusen, and various intraretinal hemorrhages. We have also demonstrated that the type of information in a coded description of ocular images can successfully teach a neural network to diagnose diseases from new images.  In the proposed continuation, we will expand the identification capability to more objects, thus achieving a fuller description of the image.  We will develop neural networks and expert systems to determine which is superior for transforming objects into diagnoses.  We will compare measurements of the same objects in a sequence of images to detect change.  As our ability to identify objects becomes more complete, we will apply all the steps to diagnose one disease, diabetes, and then expand the number of diseases.  Ultimately, we will have an automated ophthalmic image diagnosis system with a graphics user interface that will furnish decision support and teaching and extend the capability and productivity of the ophthalmologist and his/her assistants.  n/a",STRUCTURED ANALYSIS OF THE RETINA,3261867,R01EY005996,"['artificial intelligence', ' computer assisted diagnosis', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer simulation', ' eye disorder diagnosis', ' eye fundus photography', ' fluorescein angiography', ' human subject', ' image processing', ' mathematics', ' retina', ' retina disorder', ' statistics /biometry']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1991,164914,0.2745762249965466
"STRUCTURED ANALYSIS OF THE RETINA STARE (STructured Analysis of the REtina) is a system for computer-aided analysis of ocular fundus images and fluorescein angiograms.  The combination of image analysis in conjunction with expert systems and neural networks is a sophisticated and innovative approach in ophthalmology.  We propose to continue our development of STARE for a second three-year period.  The process of transforming an image of the retina into a set of differential diagnoses is complex but manageable.  The image is broken up into 250,000 picture elements (pixels) with 256 levels of gray or 16 million colors.  Specialized image-processing algorithms form groups of pixels that have common attributes, such as texture or a range of brightness or color.  Other algorithms assemble the lines and regions into different objects (e.g. optic nerve, blood vessels, lesions) that are not yet identified.  Features, such as color, size, shape, and edge sharpness, that describe these objects are measured.  Statistical classifiersm or expert systems may be used to identify each object.  When all the relevant objects in the picture have been found and identified, each objects, its location, and its relationship to other objects are stored in a database which forms a coded description of the image.  That description is used by a neural network or an expert system either to create a differential diagnosis list with the probability of each diagnosis or to detect change in a sequence of images.  We have developed algorithms that perform a large number of image processing tasks, and we have applied many of them for the automatic location and identification of the optic nerve, blood vessels, the fovea, exudates, cotton-wool spots, drusen, and various intraretinal hemorrhages. We have also demonstrated that the type of information in a coded description of ocular images can successfully teach a neural network to diagnose diseases from new images.  In the proposed continuation, we will expand the identification capability to more objects, thus achieving a fuller description of the image.  We will develop neural networks and expert systems to determine which is superior for transforming objects into diagnoses.  We will compare measurements of the same objects in a sequence of images to detect change.  As our ability to identify objects becomes more complete, we will apply all the steps to diagnose one disease, diabetes, and then expand the number of diseases.  Ultimately, we will have an automated ophthalmic image diagnosis system with a graphics user interface that will furnish decision support and teaching and extend the capability and productivity of the ophthalmologist and his/her assistants.  n/a",STRUCTURED ANALYSIS OF THE RETINA,3261862,R01EY005996,"['artificial intelligence', ' computer assisted diagnosis', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer simulation', ' eye disorder diagnosis', ' eye fundus photography', ' fluorescein angiography', ' human subject', ' image processing', ' mathematics', ' retina', ' retina disorder', ' statistics /biometry']",NEI,UNIVERSITY OF CALIFORNIA SAN DIEGO,R01,1990,202209,0.2745762249965466
"ENCODING REACH AND GRASP IN CEREBELLAR NEURONAL ACTIVITY This research proposal is for a one-year continuation of the study begun in the first two years of my NRSA postdoctoral fellowship.  The current study addresses the question of what parameters of grasp are encoded in the simple and complex spike activity of Purkinje cells.  My hypothesis is that the simple spike activity of cerebellar Purkinje cells modulates in relation to object volume, shape, and orientation, and to the force generated during the grasp.  Object properties appear to be encoded during the reach and early in the grasp of the object and force tends to be encoded late in the grasp.  In the current study, the reach component is held constant and the object to be grasped and the force to be generated are varied systematically. The monkey's hand and the object are outside monkey's field of view, removing possible visual contributions to the Purkinje cell discharge.  Multiple linear regression analysis will be used to analyze task-related discharge in relation to the force generated and to object properties such as shape, volume and orientation. An additional paradigm I propose is to compare the firing rates of Purkinje cells during the grasp task with and without visual guidance.  Two assumption made in both paradigms is that reach is constant and that hand posture will vary with the different objects.  The kinematics of the wrist and hand movements will be monitored to test these assumptions.  The kinematic data will also be analyzed using singular value decomposition for possible simplifying strategies the CNS may use in the control of grasp. The discharge activity of the population of Purkinje cells will be evaluated using singular value decomposition to identify patterns of activity that may reflect the simplifying strategies observed in the psychophysical  studies.  n/a",ENCODING REACH AND GRASP IN CEREBELLAR NEURONAL ACTIVITY,6062437,F32NS010491,"['Macaca mulatta', ' brain electrical activity', ' cerebellar Purkinje cell', ' cerebellum', ' computational neuroscience', ' electrophysiology', ' hand', ' histology', ' limb movement', ' model design /development', ' neural information processing', ' neurosurgery', ' oscillography', ' psychomotor function', ' sensorimotor system', ' single cell analysis', ' visual feedback']",NINDS,UNIVERSITY OF MINNESOTA TWIN CITIES,F32,1999,38368,0.20790510965539125
"IMAGERY PROCESSING IN OLD AGE Visual mental imagery helps people to perform a host of tasks, including         remembering events, spatial reasoning, and language comprehension. The           images produced in the service of these activities are the result of a           complex information processing system. This system can be conceptualized         as being composed of a set of distinct ""processing subsystems,"" each of          which performs a specific cognitive operation (e.g., shifting the                orientation of an imaged object, activating stored visual memories to            create an image, encoding the relative location of part of the imaged            object). The research described here makes use of a theory of these              processing subsystems that draws on concepts from artificial intelligence        and facts about the neurological substrate of high.level vision. The             research will characterize the relative efficacy of eleven of these              subsystems in the elderly, compared to younger adults. The primary aim           of the research is to discover whether certain subsystems are, relative          to other subsystems, selectively more effective in senescence. The               research aims to disprove the idea that cognitive aging can be understood        solely in terms of ""generalized slowing,"" showing that slowing with age          differs for different subsystems. If so, then strategies that make use           of relatively effective subsystems should be more useful for elderly             people than strategies that rely on ineffective subsystems. The                  experiments designed here are a step toward using contemporary theory            from cognitive neuroscience and techniques of task analysis from                 cognitive science to design new tests for cognitive efficiency in the            senescence.                                                                       n/a",IMAGERY PROCESSING IN OLD AGE,2001589,R01AG012675,"['adolescence (12-20)', ' age difference', ' attention', ' cognition', ' human old age (65+)', ' human subject', ' image processing', ' memory', ' neural information processing', ' neurosciences', ' occipital lobe /cortex', ' performance', ' questionnaires', ' retina', ' space perception', ' vision', ' visual perception', ' visual stimulus']",NIA,HARVARD UNIVERSITY,R01,1997,165380,0.05337101739647349
"IMAGERY PROCESSING IN OLD AGE Visual mental imagery helps people to perform a host of tasks, including  remembering events, spatial reasoning, and language comprehension. The  images produced in the service of these activities are the result of a  complex information processing system. This system can be conceptualized  as being composed of a set of distinct ""processing subsystems,"" each of  which performs a specific cognitive operation (e.g., shifting the  orientation of an imaged object, activating stored visual memories to  create an image, encoding the relative location of part of the imaged  object). The research described here makes use of a theory of these  processing subsystems that draws on concepts from artificial intelligence  and facts about the neurological substrate of high.level vision. The  research will characterize the relative efficacy of eleven of these  subsystems in the elderly, compared to younger adults. The primary aim  of the research is to discover whether certain subsystems are, relative  to other subsystems, selectively more effective in senescence. The  research aims to disprove the idea that cognitive aging can be understood  solely in terms of ""generalized slowing,"" showing that slowing with age  differs for different subsystems. If so, then strategies that make use  of relatively effective subsystems should be more useful for elderly  people than strategies that rely on ineffective subsystems. The  experiments designed here are a step toward using contemporary theory  from cognitive neuroscience and techniques of task analysis from  cognitive science to design new tests for cognitive efficiency in the  senescence.  n/a",IMAGERY PROCESSING IN OLD AGE,2054397,R01AG012675,"['adolescence (12-20)', ' age difference', ' attention', ' cognition', ' human old age (65+)', ' human subject', ' image processing', ' memory', ' neural information processing', ' neurosciences', ' occipital lobe /cortex', ' performance', ' questionnaires', ' retina', ' space perception', ' vision', ' visual perception', ' visual stimulus']",NIA,HARVARD UNIVERSITY,R01,1995,155931,0.05337101739647349
"LANGUAGE COMPREHENSION RELATED TO LOCAL BRAIN DAMAGE To understand the sentence ""Who did the girl the teacher forced to talk complain to?""  One must determine that ""the girl"" is to be taken as the missing subject of the verb ""talk"" and that ""who"" is the missing object of the preposition ""to.""  Sentences with such long-distance dependencies as that between ""the girl"" and the subject position preceding ""to talk"" pose special problems for theories of sentence comprehension.  They challenge the apparent human limits on short-term memory and processing capacity, in that arbitrary amounts of linguistic material can intervene between the items that are dependent upon each other and any one sentence can contain several long-distance dependencies.  Further, they are subject to unique linguistic constraints that a language user must honor.  We propose experiments to study the comprehension of sentences with long-distance dependencies, using reaction time and other measures of processing difficulty. Our goals are to determine what decision principles people follow in understanding such sentences, to identify the various types of information (lexical, pragmatic, suprasegmental, grammatical constraints) they use in making decisions about long-distance dependencies, and to specify the sequence in which they use functionally different types of information.   n/a",LANGUAGE COMPREHENSION RELATED TO LOCAL BRAIN DAMAGE,3315841,R01HD018708,"['artificial intelligence', ' audiotape', ' cognition', ' language', ' psycholinguistics', ' semantics', ' speech']",NICHD,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,1989,74441,0.040736541690142604
"LANGUAGE COMPREHENSION To understand the sentence ""Who did the girl the teacher forced to talk complain to?""  One must determine that ""the girl"" is to be taken as the missing subject of the verb ""talk"" and that ""who"" is the missing object of the preposition ""to.""  Sentences with such long-distance dependencies as that between ""the girl"" and the subject position preceding ""to talk"" pose special problems for theories of sentence comprehension.  They challenge the apparent human limits on short-term memory and processing capacity, in that arbitrary amounts of linguistic material can intervene between the items that are dependent upon each other and any one sentence can contain several long-distance dependencies.  Further, they are subject to unique linguistic constraints that a language user must honor.  We propose experiments to study the comprehension of sentences with long-distance dependencies, using reaction time and other measures of processing difficulty. Our goals are to determine what decision principles people follow in understanding such sentences, to identify the various types of information (lexical, pragmatic, suprasegmental, grammatical constraints) they use in making decisions about long-distance dependencies, and to specify the sequence in which they use functionally different types of information.   n/a",LANGUAGE COMPREHENSION,3315840,R01HD018708,"['artificial intelligence', ' audiotape', ' cognition', ' language', ' psycholinguistics', ' semantics', ' speech']",NICHD,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,1988,69390,0.04789888621291526
"LANGUAGE COMPREHENSION RELATED TO LOCAL BRAIN DAMAGE To understand the sentence ""Who did the girl the teacher forced to talk complain to?""  One must determine that ""the girl"" is to be taken as the missing subject of the verb ""talk"" and that ""who"" is the missing object of the preposition ""to.""  Sentences with such long-distance dependencies as that between ""the girl"" and the subject position preceding ""to talk"" pose special problems for theories of sentence comprehension.  They challenge the apparent human limits on short-term memory and processing capacity, in that arbitrary amounts of linguistic material can intervene between the items that are dependent upon each other and any one sentence can contain several long-distance dependencies.  Further, they are subject to unique linguistic constraints that a language user must honor.  We propose experiments to study the comprehension of sentences with long-distance dependencies, using reaction time and other measures of processing difficulty. Our goals are to determine what decision principles people follow in understanding such sentences, to identify the various types of information (lexical, pragmatic, suprasegmental, grammatical constraints) they use in making decisions about long-distance dependencies, and to specify the sequence in which they use functionally different types of information.   n/a",LANGUAGE COMPREHENSION RELATED TO LOCAL BRAIN DAMAGE,3315835,R01HD018708,"['artificial intelligence', ' audiotape', ' cognition', ' language', ' psycholinguistics', ' semantics', ' speech']",NICHD,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,1987,67686,0.040736541690142604
"COMPREHENDING SENTENCES WITH LONG-DISTANCE DEPENDENCIES To understand the sentence ""Who did the girl the teacher forced to talk complain to?""  One must determine that ""the girl"" is to be taken as the missing subject of the verb ""talk"" and that ""who"" is the missing object of the preposition ""to.""  Sentences with such long-distance dependencies as that between ""the girl"" and the subject position preceding ""to talk"" pose special problems for theories of sentence comprehension.  They challenge the apparent human limits on short-term memory and processing capacity, in that arbitrary amounts of linguistic material can intervene between the items that are dependent upon each other and any one sentence can contain several long-distance dependencies.  Further, they are subject to unique linguistic constraints that a language user must honor.  We propose experiments to study the comprehension of sentences with long-distance dependencies, using reaction time and other measures of processing difficulty. Our goals are to determine what decision principles people follow in understanding such sentences, to identify the various types of information (lexical, pragmatic, suprasegmental, grammatical constraints) they use in making decisions about long-distance dependencies, and to specify the sequence in which they use functionally different types of information.   n/a",COMPREHENDING SENTENCES WITH LONG-DISTANCE DEPENDENCIES,3315839,R01HD018708,"['artificial intelligence', ' audiotape', ' cognition', ' language', ' psycholinguistics', ' semantics', ' speech']",NICHD,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,1986,57427,0.04789888621291526
"COMPREHENDING SENTENCES WITH LONG-DISTANCE DEPENDENCIES To understand the sentence ""Who did the girl the teacher forced to talk complain to?""  One must determine that ""the girl"" is to be taken as the missing subject of the verb ""talk"" and that ""who"" is the missing object of the preposition ""to.""  Sentences with such long-distance dependencies as that between ""the girl"" and the subject position preceding ""to talk"" pose special problems for theories of sentence comprehension.  They challenge the apparent human limits on short-term memory and processing capacity, in that arbitrary amounts of linguistic material can intervene between the items that are dependent upon each other and any one sentence can contain several long-distance dependencies.  Further, they are subject to unique linguistic constraints that a language user must honor.  We propose experiments to study the comprehension of sentences with long-distance dependencies, using reaction time and other measures of processing difficulty. Our goals are to determine what decision principles people follow in understanding such sentences, to identify the various types of information (lexical, pragmatic, suprasegmental, grammatical constraints) they use in making decisions about long-distance dependencies, and to specify the sequence in which they use functionally different types of information.   n/a",COMPREHENDING SENTENCES WITH LONG-DISTANCE DEPENDENCIES,3315838,R01HD018708,"['artificial intelligence', ' audiotape', ' cognition', ' language', ' psycholinguistics', ' semantics', ' speech']",NICHD,UNIVERSITY OF MASSACHUSETTS AMHERST,R01,1985,66553,0.04789888621291526
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6940629,R01AG018751,"['aging', 'artificial intelligence', 'body movement', 'clinical research', 'computer system design /evaluation', 'hand', 'human old age (65+)', 'human subject', 'psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2005,231673,0.12131266542197269
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6785858,R01AG018751,"['aging', 'artificial intelligence', 'body movement', 'clinical research', 'computer system design /evaluation', 'hand', 'human old age (65+)', 'human subject', 'psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2004,231788,0.12131266542197269
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6637831,R01AG018751,"['aging', ' artificial intelligence', ' body movement', ' clinical research', ' computer system design /evaluation', ' hand', ' human old age (65+)', ' human subject', ' psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2003,231899,0.12131266542197269
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6533901,R01AG018751,"['aging', ' artificial intelligence', ' body movement', ' clinical research', ' computer system design /evaluation', ' hand', ' human old age (65+)', ' human subject', ' psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2002,232006,0.12131266542197269
"FINGER COORDINATION IN ELDERLY Impairment of hand function with age is a major disabling factor limiting many activities of daily living.  A decrease in the hand dexterity may lead to a loss of independence and require external care during most everyday activities.  Our present understanding of the functioning of the human hand and changes in its function with age is limited.  This makes it imperative to perform studies directed at improved understanding of the hand function and its deterioration with age. Series of studies on control subjects and preliminary findings in a small group of elderly subjects have allowed us to formulate two major hypotheses: (a) Aging is associated with selective impairment of intrinsic hand muscles; and (b) Aging is associated with an increase in force deficit during multi-finger tasks.  The following research program has been elaborated for an analysis of possible contribution of these age-related changes to the loss of hand dexterity with age: (1) Confirmation of the preliminary conclusions using a larger subject population and a wider spectrum of tasks; (2) Analysis of the effects of these changes on crucial features of multi-finger synergies such as minimization of secondary moments and patterns of variability of individual finger forces (error compensation among fingers); (3) Analysis of possible changes in finger and hand coordination during more common actions such as gripping and bi-manual object handling; and (4) Analysis of correlations between changes in the indices of finger coordination and activities of daily living that involve hand function. Seven experiments on elderly and control subjects are suggested that include force production by sets of fingers in gripping and pressing tasks, self-imposed perturbations, and bi-manual object handling.  The research will combine noninvasive behavioral, biomechanical, electrophysiological, and modeling methods, as well as questionnaires.  In one experiment, the results will be compared with indices of the activities of daily living. Disprovable predictions are made for each experiment.  We believe that supporting or disproving the two main Hypotheses is important not only for a better understanding of age-related changes in hand muscle coordination but also for development of new rehabilitation approaches to hand function.  n/a",FINGER COORDINATION IN ELDERLY,6369619,R01AG018751,"['aging', ' artificial intelligence', ' body movement', ' clinical research', ' computer system design /evaluation', ' hand', ' human old age (65+)', ' human subject', ' psychomotor function']",NIA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2001,308867,0.12131266542197269
"Causal Perceptual Processing    DESCRIPTION (provided by applicant): The broad, long-term objectives of this research are to make original contributions to scientific understanding of biological perception. The specific aims are to: 1) develop and test a causal model of touch sensations' integration with visual sensations for perception, and to generalize this model for application to a broader class of sensory integration phenomena, 2) apply causal models to investigate how humans perceive cause-and-effect events, 3) increase the applicant's technical proficiency with causal modeling and applied machine learning methods. The proposal includes two main projects; the first will measure how humans judge the size of objects when their distances are uncertain. Specifically the first project examines the theory that human perception uses knowledge about how size and distance sensations are caused to integrate related sensations. Human experimental participants will view objects while touching them and report their perceptions of the objects' sizes, which will be used to evaluate theoretical predictions. The second project investigates how humans perceive cause-and-effect chains of events by examining the theory that the brain uses built-in knowledge of rudimentary physical behaviors, like momentum in collisions, to interpret such simple events. Human experimental participants will view colliding objects and report what occurred, which will again be used to evaluate theoretical predictions. PUBLIC HEALTH RELEVANCE: The public health relevance of this research is to increase scientific and medical understanding of the neural communication and processing strategies the brain employs to create perceptual experiences, so that people with perceptual impairments can be provided with effective rehabilitation programs and biotechnological substitutes for diminished capabilities. Specific impairments include blindness and low-vision, traumatic brain and nervous system injuries, and strokes. In particular, modern sensory prostheses are now using computerized components that can interface with neural pathways to more comprehensively and effectively restore normal abilities in patients, and whose development faces significant obstacles establishing effective communication channels with the biological nervous system.          n/a",Causal Perceptual Processing,7545242,F32EY019228,"['Algorithms', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological', 'Biological Process', 'Blindness', 'Brain', 'Class', 'Cognition', 'Cognitive', 'Cognitive Science', 'Communication', 'Complex', 'Computational Technique', 'Computer Simulation', 'Decision Making', 'Development', 'Distance Perception', 'Economics', 'Elements', 'Esthesia', 'Etiology', 'Event', 'Face', 'Glass', 'Goals', 'Human', 'Image', 'Impairment', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Lifting', 'Machine Learning', 'Masks', 'Measures', 'Medical', 'Memory', 'Methods', 'Modeling', 'Nature', 'Nervous System Trauma', 'Nervous system structure', 'Neural Pathways', 'Neurosciences', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plague', 'Preparation', 'Process', 'Property', 'Psychologist', 'Psychology', 'Public Health', 'Rehabilitation therapy', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Science', 'Scientific Advances and Accomplishments', 'Semantics', 'Sensory', 'Sorting - Cell Movement', 'Space Perception', 'Stimulus', 'Stroke', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual impairment', 'Water', 'Work', 'abstracting', 'analytical method', 'computer monitor', 'computer science', 'computerized', 'experience', 'falls', 'haptics', 'insight', 'object perception', 'predictive modeling', 'programs', 'relating to nervous system', 'sensory integration', 'sensory prosthesis', 'size', 'skills', 'statistics', 'theories', 'tool']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2008,44846,0.11758523875205483
"Causal Perceptual Processing    DESCRIPTION (provided by applicant): The broad, long-term objectives of this research are to make original contributions to scientific understanding of biological perception. The specific aims are to: 1) develop and test a causal model of touch sensations' integration with visual sensations for perception, and to generalize this model for application to a broader class of sensory integration phenomena, 2) apply causal models to investigate how humans perceive cause-and-effect events, 3) increase the applicant's technical proficiency with causal modeling and applied machine learning methods. The proposal includes two main projects; the first will measure how humans judge the size of objects when their distances are uncertain. Specifically the first project examines the theory that human perception uses knowledge about how size and distance sensations are caused to integrate related sensations. Human experimental participants will view objects while touching them and report their perceptions of the objects' sizes, which will be used to evaluate theoretical predictions. The second project investigates how humans perceive cause-and-effect chains of events by examining the theory that the brain uses built-in knowledge of rudimentary physical behaviors, like momentum in collisions, to interpret such simple events. Human experimental participants will view colliding objects and report what occurred, which will again be used to evaluate theoretical predictions. PUBLIC HEALTH RELEVANCE: The public health relevance of this research is to increase scientific and medical understanding of the neural communication and processing strategies the brain employs to create perceptual experiences, so that people with perceptual impairments can be provided with effective rehabilitation programs and biotechnological substitutes for diminished capabilities. Specific impairments include blindness and low-vision, traumatic brain and nervous system injuries, and strokes. In particular, modern sensory prostheses are now using computerized components that can interface with neural pathways to more comprehensively and effectively restore normal abilities in patients, and whose development faces significant obstacles establishing effective communication channels with the biological nervous system.          n/a",Causal Perceptual Processing,7778287,F32EY019228,"['Algorithms', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Biological', 'Biological Process', 'Blindness', 'Brain', 'Cognition', 'Cognitive', 'Cognitive Science', 'Communication', 'Complex', 'Computational Technique', 'Computer Simulation', 'Decision Making', 'Development', 'Distance Perception', 'Economics', 'Elements', 'Esthesia', 'Etiology', 'Event', 'Face', 'Glass', 'Goals', 'Human', 'Image', 'Impairment', 'Judgment', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Lifting', 'Machine Learning', 'Masks', 'Measures', 'Medical', 'Memory', 'Methods', 'Modeling', 'Nature', 'Nervous System Trauma', 'Nervous system structure', 'Neural Pathways', 'Neurosciences', 'Participant', 'Patients', 'Pattern', 'Perception', 'Plague', 'Preparation', 'Process', 'Property', 'Psychologist', 'Psychology', 'Rehabilitation therapy', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Science', 'Scientific Advances and Accomplishments', 'Semantics', 'Sensory', 'Sorting - Cell Movement', 'Space Perception', 'Stimulus', 'Stroke', 'Testing', 'Text', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual impairment', 'Water', 'Work', 'abstracting', 'analytical method', 'computer monitor', 'computer science', 'computerized', 'experience', 'falls', 'haptics', 'insight', 'object perception', 'phrases', 'predictive modeling', 'programs', 'public health relevance', 'relating to nervous system', 'sensory integration', 'sensory prosthesis', 'skills', 'statistics', 'theories', 'tool']",NEI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,F32,2009,47210,0.11758523875205483
"fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex Description (provided by applicant): Experience is thought to play a critical role in shaping the cortical representations that support object recognition by creating neural responses are selective for some dimensions of change and invariant to others. Although many previous studies have examined the effects of supervised training on object selective regions of the brain, much less is known about the degree to which statistical regularities in the retinal input can directly shape the neural substrates involved in object recognition. Unsupervised learning is important because it allows the brain to employ simple self organizing mechanisms that turn the continuous flux of visual input into the stable objects of our experience. While behavioral and computational work strongly suggests that unsupervised learning plays a key role in object recognition, most related neuroscience work examining the role of input statistics has focused on its effects in early visual areas. Here we propose experiments that combine cutting edge techniques in fMRI, psychophysics, and computational modeling to examine two hypotheses concerning unsupervised learning in object recognition. First, we propose that neural responses may become tuned to match the range and frequency of shape and object exemplars experienced during unsupervised training. That is, neural responses will increase and become more selective for items seen more frequently during unsupervised training relative to infrequently seen or untrained items. This may provide a mechanism which improves discrimination performance for stimuli seen most frequently. Second, behavioral and computational evidence suggests the intriguing hypothesis that the brain uses spatio-temporal correlations as a means for binding different images as belonging to the same object, allowing for recognition of the same object across dramatic transformations, such as changes in its appearance due to rotation. We will determine if spatio- temporal correlations in the visual input during unsupervised training increases the invariance of both brain responses and perceptual performance relative to similar items trained in an uncorrelated manner and pre- training responses (and performance). Third, we will examine if mechanisms of unsupervised learning generalize to supervised learning. In all of our experiments we will examine neural responses and performance both before and after unsupervised training, and use computational modeling to link fMRI data to the possible underlying neural mechanisms such as sharpening of neural tuning and increased firing rates. The proposed work will fill important gaps in knowledge by providing the first account of the neural mechanisms that generate effective representations for object recognition from the statistics of visual experience.  PUBLIC HEALTH RELEVANCE The results of these studies will be important for understanding the role of visual experience in shaping normal visual representations. As these mechanisms do not require explicit instruction, they are especially important for unraveling the means by which pre-verbal children and animals learn to recognize objects. Understanding these mechanisms will form a much needed foundation for studying development disorders such as congenital prosopagnosia, autism and Williams Syndrome. Further, if we find significant behavioral improvements due to the statistics of the visual inputs, these training paradigms may be used as an intervention to offset developmental visual disabilities.",fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex,8464120,R01EY019279,"['Accounting', 'Address', 'Affect', 'Animals', 'Appearance', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Binding', 'Brain', 'Brain region', 'Child', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Development', 'Dimensions', 'Discrimination', 'Disease', 'Experimental Designs', 'Feedback', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Image', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Label', 'Learning', 'Link', 'Measurement', 'Measures', 'Modeling', 'Neurons', 'Neurosciences', 'Normal Statistical Distribution', 'Pattern', 'Performance', 'Play', 'Property', 'Prosopagnosia', 'Psychophysics', 'Recovery', 'Relative (related person)', 'Reporting', 'Resolution', 'Retinal', 'Role', 'Rotation', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Width', 'Williams Syndrome', 'Work', 'brain behavior', 'computer studies', 'design', 'disability', 'experience', 'extrastriate visual cortex', 'improved', 'neuromechanism', 'novel', 'object recognition', 'object shape', 'prototype', 'receptive field', 'relating to nervous system', 'research study', 'response', 'spatiotemporal', 'statistics', 'visual neuroscience']",NEI,STANFORD UNIVERSITY,R01,2013,361152,0.11978315052167793
"fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex Description (provided by applicant): Experience is thought to play a critical role in shaping the cortical representations that support object recognition by creating neural responses are selective for some dimensions of change and invariant to others. Although many previous studies have examined the effects of supervised training on object selective regions of the brain, much less is known about the degree to which statistical regularities in the retinal input can directly shape the neural substrates involved in object recognition. Unsupervised learning is important because it allows the brain to employ simple self organizing mechanisms that turn the continuous flux of visual input into the stable objects of our experience. While behavioral and computational work strongly suggests that unsupervised learning plays a key role in object recognition, most related neuroscience work examining the role of input statistics has focused on its effects in early visual areas. Here we propose experiments that combine cutting edge techniques in fMRI, psychophysics, and computational modeling to examine two hypotheses concerning unsupervised learning in object recognition. First, we propose that neural responses may become tuned to match the range and frequency of shape and object exemplars experienced during unsupervised training. That is, neural responses will increase and become more selective for items seen more frequently during unsupervised training relative to infrequently seen or untrained items. This may provide a mechanism which improves discrimination performance for stimuli seen most frequently. Second, behavioral and computational evidence suggests the intriguing hypothesis that the brain uses spatio-temporal correlations as a means for binding different images as belonging to the same object, allowing for recognition of the same object across dramatic transformations, such as changes in its appearance due to rotation. We will determine if spatio- temporal correlations in the visual input during unsupervised training increases the invariance of both brain responses and perceptual performance relative to similar items trained in an uncorrelated manner and pre- training responses (and performance). Third, we will examine if mechanisms of unsupervised learning generalize to supervised learning. In all of our experiments we will examine neural responses and performance both before and after unsupervised training, and use computational modeling to link fMRI data to the possible underlying neural mechanisms such as sharpening of neural tuning and increased firing rates. The proposed work will fill important gaps in knowledge by providing the first account of the neural mechanisms that generate effective representations for object recognition from the statistics of visual experience. PUBLIC HEALTH RELEVANCE The results of these studies will be important for understanding the role of visual experience in shaping normal visual representations. As these mechanisms do not require explicit instruction, they are especially important for unraveling the means by which pre-verbal children and animals learn to recognize objects. Understanding these mechanisms will form a much needed foundation for studying development disorders such as congenital prosopagnosia, autism and Williams Syndrome. Further, if we find significant behavioral improvements due to the statistics of the visual inputs, these training paradigms may be used as an intervention to offset developmental visual disabilities. Health Relevance: The results of these studies will be important for understanding the role of  visual experience in shaping normal visual representations. As these mechanisms do not  require explicit instruction, they are especially important for unraveling the means by which  pre-verbal children and animals learn to recognize objects. Understanding these mechanisms  will form a much needed foundation for studying development disorders such as congenital  prosopagnosia, autism and Williams Syndrome. Further, if we find significant behavioral  improvements due to the statistics of the visual inputs, these training paradigms may be used  as an intervention to offset developmental visual disabilities.",fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex,8266462,R01EY019279,"['Accounting', 'Address', 'Affect', 'Animals', 'Appearance', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Binding', 'Brain', 'Brain region', 'Child', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Development', 'Dimensions', 'Discrimination', 'Disease', 'Experimental Designs', 'Feedback', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Image', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Label', 'Learning', 'Link', 'Measurement', 'Measures', 'Modeling', 'Neurons', 'Neurosciences', 'Normal Statistical Distribution', 'Pattern', 'Performance', 'Play', 'Property', 'Prosopagnosia', 'Psychophysics', 'Psychophysiology', 'Recovery', 'Relative (related person)', 'Reporting', 'Resolution', 'Retinal', 'Role', 'Rotation', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Width', 'Williams Syndrome', 'Work', 'brain behavior', 'computer studies', 'design', 'disability', 'experience', 'extrastriate visual cortex', 'improved', 'neuromechanism', 'novel', 'object recognition', 'object shape', 'prototype', 'receptive field', 'relating to nervous system', 'research study', 'response', 'spatiotemporal', 'statistics', 'visual neuroscience']",NEI,STANFORD UNIVERSITY,R01,2012,380160,0.058535224014189334
"fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex    Description (provided by applicant): Experience is thought to play a critical role in shaping the cortical representations that support object recognition by creating neural responses are selective for some dimensions of change and invariant to others. Although many previous studies have examined the effects of supervised training on object selective regions of the brain, much less is known about the degree to which statistical regularities in the retinal input can directly shape the neural substrates involved in object recognition. Unsupervised learning is important because it allows the brain to employ simple self organizing mechanisms that turn the continuous flux of visual input into the stable objects of our experience. While behavioral and computational work strongly suggests that unsupervised learning plays a key role in object recognition, most related neuroscience work examining the role of input statistics has focused on its effects in early visual areas. Here we propose experiments that combine cutting edge techniques in fMRI, psychophysics, and computational modeling to examine two hypotheses concerning unsupervised learning in object recognition. First, we propose that neural responses may become tuned to match the range and frequency of shape and object exemplars experienced during unsupervised training. That is, neural responses will increase and become more selective for items seen more frequently during unsupervised training relative to infrequently seen or untrained items. This may provide a mechanism which improves discrimination performance for stimuli seen most frequently. Second, behavioral and computational evidence suggests the intriguing hypothesis that the brain uses spatio-temporal correlations as a means for binding different images as belonging to the same object, allowing for recognition of the same object across dramatic transformations, such as changes in its appearance due to rotation. We will determine if spatio- temporal correlations in the visual input during unsupervised training increases the invariance of both brain responses and perceptual performance relative to similar items trained in an uncorrelated manner and pre- training responses (and performance). Third, we will examine if mechanisms of unsupervised learning generalize to supervised learning. In all of our experiments we will examine neural responses and performance both before and after unsupervised training, and use computational modeling to link fMRI data to the possible underlying neural mechanisms such as sharpening of neural tuning and increased firing rates. The proposed work will fill important gaps in knowledge by providing the first account of the neural mechanisms that generate effective representations for object recognition from the statistics of visual experience.  Health Relevance: The results of these studies will be important for understanding the role of  visual experience in shaping normal visual representations. As these mechanisms do not  require explicit instruction, they are especially important for unraveling the means by which  pre-verbal children and animals learn to recognize objects. Understanding these mechanisms  will form a much needed foundation for studying development disorders such as congenital  prosopagnosia, autism and Williams Syndrome. Further, if we find significant behavioral  improvements due to the statistics of the visual inputs, these training paradigms may be used  as an intervention to offset developmental visual disabilities.",fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex,8068802,R01EY019279,"['Accounting', 'Address', 'Affect', 'Animals', 'Appearance', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Binding', 'Brain', 'Brain region', 'Child', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Development', 'Dimensions', 'Discrimination', 'Disease', 'Experimental Designs', 'Feedback', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Image', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Label', 'Learning', 'Link', 'Measurement', 'Measures', 'Modeling', 'Neurons', 'Neurosciences', 'Normal Statistical Distribution', 'Pattern', 'Performance', 'Play', 'Property', 'Prosopagnosia', 'Psychophysics', 'Psychophysiology', 'Recovery', 'Relative (related person)', 'Reporting', 'Resolution', 'Retinal', 'Role', 'Rotation', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Width', 'Williams Syndrome', 'Work', 'brain behavior', 'computer studies', 'design', 'disability', 'experience', 'extrastriate visual cortex', 'improved', 'neuromechanism', 'novel', 'object recognition', 'object shape', 'prototype', 'receptive field', 'relating to nervous system', 'research study', 'response', 'spatiotemporal', 'statistics', 'visual neuroscience']",NEI,STANFORD UNIVERSITY,R01,2011,380160,0.11978315052167793
"fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex    Description (provided by applicant): Experience is thought to play a critical role in shaping the cortical representations that support object recognition by creating neural responses are selective for some dimensions of change and invariant to others. Although many previous studies have examined the effects of supervised training on object selective regions of the brain, much less is known about the degree to which statistical regularities in the retinal input can directly shape the neural substrates involved in object recognition. Unsupervised learning is important because it allows the brain to employ simple self organizing mechanisms that turn the continuous flux of visual input into the stable objects of our experience. While behavioral and computational work strongly suggests that unsupervised learning plays a key role in object recognition, most related neuroscience work examining the role of input statistics has focused on its effects in early visual areas. Here we propose experiments that combine cutting edge techniques in fMRI, psychophysics, and computational modeling to examine two hypotheses concerning unsupervised learning in object recognition. First, we propose that neural responses may become tuned to match the range and frequency of shape and object exemplars experienced during unsupervised training. That is, neural responses will increase and become more selective for items seen more frequently during unsupervised training relative to infrequently seen or untrained items. This may provide a mechanism which improves discrimination performance for stimuli seen most frequently. Second, behavioral and computational evidence suggests the intriguing hypothesis that the brain uses spatio-temporal correlations as a means for binding different images as belonging to the same object, allowing for recognition of the same object across dramatic transformations, such as changes in its appearance due to rotation. We will determine if spatio- temporal correlations in the visual input during unsupervised training increases the invariance of both brain responses and perceptual performance relative to similar items trained in an uncorrelated manner and pre- training responses (and performance). Third, we will examine if mechanisms of unsupervised learning generalize to supervised learning. In all of our experiments we will examine neural responses and performance both before and after unsupervised training, and use computational modeling to link fMRI data to the possible underlying neural mechanisms such as sharpening of neural tuning and increased firing rates. The proposed work will fill important gaps in knowledge by providing the first account of the neural mechanisms that generate effective representations for object recognition from the statistics of visual experience.  PUBLIC HEALTH RELEVANCE The results of these studies will be important for understanding the role of visual experience in shaping normal visual representations. As these mechanisms do not require explicit instruction, they are especially important for unraveling the means by which pre-verbal children and animals learn to recognize objects. Understanding these mechanisms will form a much needed foundation for studying development disorders such as congenital prosopagnosia, autism and Williams Syndrome. Further, if we find significant behavioral improvements due to the statistics of the visual inputs, these training paradigms may be used as an intervention to offset developmental visual disabilities.",fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex,7802090,R01EY019279,"['Accounting', 'Address', 'Affect', 'Animals', 'Appearance', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Binding', 'Brain', 'Brain region', 'Child', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Development', 'Dimensions', 'Discrimination', 'Disease', 'Experimental Designs', 'Feedback', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Image', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Label', 'Learning', 'Link', 'Measurement', 'Measures', 'Modeling', 'Neurons', 'Neurosciences', 'Normal Statistical Distribution', 'Pattern', 'Performance', 'Play', 'Property', 'Prosopagnosia', 'Psychophysics', 'Psychophysiology', 'Recovery', 'Relative (related person)', 'Reporting', 'Resolution', 'Retinal', 'Role', 'Rotation', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Width', 'Williams Syndrome', 'Work', 'brain behavior', 'computer studies', 'design', 'disability', 'experience', 'extrastriate visual cortex', 'improved', 'neuromechanism', 'novel', 'object recognition', 'object shape', 'prototype', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'spatiotemporal', 'statistics', 'visual neuroscience']",NEI,STANFORD UNIVERSITY,R01,2010,396000,0.11978315052167793
"fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex    Description (provided by applicant): Experience is thought to play a critical role in shaping the cortical representations that support object recognition by creating neural responses are selective for some dimensions of change and invariant to others. Although many previous studies have examined the effects of supervised training on object selective regions of the brain, much less is known about the degree to which statistical regularities in the retinal input can directly shape the neural substrates involved in object recognition. Unsupervised learning is important because it allows the brain to employ simple self organizing mechanisms that turn the continuous flux of visual input into the stable objects of our experience. While behavioral and computational work strongly suggests that unsupervised learning plays a key role in object recognition, most related neuroscience work examining the role of input statistics has focused on its effects in early visual areas. Here we propose experiments that combine cutting edge techniques in fMRI, psychophysics, and computational modeling to examine two hypotheses concerning unsupervised learning in object recognition. First, we propose that neural responses may become tuned to match the range and frequency of shape and object exemplars experienced during unsupervised training. That is, neural responses will increase and become more selective for items seen more frequently during unsupervised training relative to infrequently seen or untrained items. This may provide a mechanism which improves discrimination performance for stimuli seen most frequently. Second, behavioral and computational evidence suggests the intriguing hypothesis that the brain uses spatio-temporal correlations as a means for binding different images as belonging to the same object, allowing for recognition of the same object across dramatic transformations, such as changes in its appearance due to rotation. We will determine if spatio- temporal correlations in the visual input during unsupervised training increases the invariance of both brain responses and perceptual performance relative to similar items trained in an uncorrelated manner and pre- training responses (and performance). Third, we will examine if mechanisms of unsupervised learning generalize to supervised learning. In all of our experiments we will examine neural responses and performance both before and after unsupervised training, and use computational modeling to link fMRI data to the possible underlying neural mechanisms such as sharpening of neural tuning and increased firing rates. The proposed work will fill important gaps in knowledge by providing the first account of the neural mechanisms that generate effective representations for object recognition from the statistics of visual experience. PUBLIC HEALTH RELEVANCE The results of these studies will be important for understanding the role of visual experience in shaping normal visual representations. As these mechanisms do not require explicit instruction, they are especially important for unraveling the means by which pre-verbal children and animals learn to recognize objects. Understanding these mechanisms will form a much needed foundation for studying development disorders such as congenital prosopagnosia, autism and Williams Syndrome. Further, if we find significant behavioral improvements due to the statistics of the visual inputs, these training paradigms may be used as an intervention to offset developmental visual disabilities.           Health Relevance: The results of these studies will be important for understanding the role of visual experience in shaping normal visual representations. As these mechanisms do not require explicit instruction, they are especially important for unraveling the means by which pre-verbal children and animals learn to recognize objects. Understanding these mechanisms will form a much needed foundation for studying development disorders such as congenital prosopagnosia, autism and Williams Syndrome. Further, if we find significant behavioral improvements due to the statistics of the visual inputs, these training paradigms may be used as an intervention to offset developmental visual disabilities.",fMRI and Behavioral  Studies of Unsupervised Learning in High Level Visual Cortex,7663500,R01EY019279,"['Accounting', 'Address', 'Affect', 'Animals', 'Appearance', 'Autistic Disorder', 'Behavior', 'Behavioral', 'Binding', 'Brain', 'Brain region', 'Child', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Development', 'Dimensions', 'Discrimination', 'Disease', 'Experimental Designs', 'Feedback', 'Foundations', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Image', 'Instruction', 'Intervention', 'Judgment', 'Knowledge', 'Label', 'Learning', 'Link', 'Measurement', 'Measures', 'Modeling', 'Neurons', 'Neurosciences', 'Normal Statistical Distribution', 'Pattern', 'Performance', 'Play', 'Property', 'Prosopagnosia', 'Psychophysics', 'Psychophysiology', 'Recovery', 'Relative (related person)', 'Reporting', 'Resolution', 'Retinal', 'Role', 'Rotation', 'Shapes', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Visual', 'Visual Cortex', 'Width', 'Williams Syndrome', 'Work', 'brain behavior', 'computer studies', 'design', 'disability', 'experience', 'extrastriate visual cortex', 'improved', 'neuromechanism', 'novel', 'object recognition', 'object shape', 'prototype', 'public health relevance', 'receptive field', 'relating to nervous system', 'research study', 'response', 'spatiotemporal', 'statistics', 'visual neuroscience']",NEI,STANFORD UNIVERSITY,R01,2009,400000,0.058535224014189334
"Object Concepts Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally. Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8894845,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2014,70173,0.08744865982712811
"Object Concepts  Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.  Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8723219,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2014,386042,0.08744865982712811
"Object Concepts  Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.  Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8537463,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2013,374225,0.08744865982712811
"Object Concepts  Project Summary What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.  Narrative Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.",Object Concepts,8312494,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2012,393921,0.08744865982712811
"Object Concepts    DESCRIPTION (provided by applicant): What does it mean to know something about the world? Central to any theory of knowledge is a theory of concepts, those mental representations that allow us to categorize information in the world. In this project, we attempt to understand concepts by studying their neural instantiation. The central aim of this project is to advance our understanding of the neural representation of concepts via a characterization of similarity. The broader goal of this research program is to develop a strategy for understanding the neural representation of all types of knowledge; however, to make this problem more tractable, we are focusing on a specific type of concept - concrete objects - and on a particular type of knowledge about those concepts - their visual appearance. Specifically, (1) We aim to describe the neural representation of object concepts by characterizing neural tuning to features in a multidimensional similarity space; (2) We aim to examine variation in the neural representations of object concepts, across concepts, across individuals, and across attentional states; (3) We aim to explore to role of sleep-dependent consolidation processes in the acquisition of new object concept knowledge; (4) We aim to develop innovative methods for the characterization of neural similarity more generally.      PUBLIC HEALTH RELEVANCE: Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.           Without concepts, we would be unable to make sense of the infinite variation in the world. Concepts organize our experiences, and they alter perception, memory, language, and action. The goal of this project is to understand the way in which conceptual knowledge is organized and the manner in which it is implemented in the brain. We will apply innovative neuroscientific methods to discover how we learn about the objects around us and how we access that information when remembering those objects.         ",Object Concepts,8130384,R01EY021717,"['Accounting', 'Address', 'Adopted', 'Appearance', 'Artificial Intelligence', 'Attention', 'Back', 'Behavioral', 'Books', 'Brain', 'Brain region', 'Categories', 'Cognitive', 'Cognitive Science', 'Collection', 'Color', 'Diagnostic', 'Educational process of instructing', 'Family', 'Functional Magnetic Resonance Imaging', 'Goals', 'Individual', 'Knowledge', 'Language', 'Learning', 'Literature', 'Measurement', 'Measures', 'Memory', 'Methods', 'Metric', 'Neuronal Plasticity', 'Neurons', 'Pattern', 'Perception', 'Procedures', 'Process', 'Property', 'Research', 'Research Personnel', 'Role', 'Shapes', 'Sleep', 'Solutions', 'Testing', 'Thinking', 'Training', 'Variant', 'Visual', 'Work', 'austin', 'base', 'behavior measurement', 'experience', 'innovation', 'insight', 'meetings', 'mental representation', 'novel', 'programs', 'psychologic', 'relating to nervous system', 'research study', 'response', 'theories']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2011,393921,0.10882217409535926
"Neural mechanisms of attentional priority for visual features and objects DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions. Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.",Neural mechanisms of attentional priority for visual features and objects,9099855,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'support network', 'sustained attention', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2016,368557,0.11818891385407476
"Neural mechanisms of attentional priority for visual features and objects DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions. Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.",Neural mechanisms of attentional priority for visual features and objects,8893998,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'sustained attention', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2015,318059,0.11818891385407476
"Neural mechanisms of attentional priority for visual features and objects     DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions.          Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                ",Neural mechanisms of attentional priority for visual features and objects,8675258,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2014,360448,0.11818891385407476
"Neural mechanisms of attentional priority for visual features and objects     DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions.          Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                ",Neural mechanisms of attentional priority for visual features and objects,8502510,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2013,347698,0.11818891385407476
"Neural mechanisms of attentional priority for visual features and objects     DESCRIPTION (provided by applicant): The environment contains far more information than the brain can process at once. To cope with such information overload, humans need to selectively attend to relevant information and prioritize its processing. In many situations, humans need to select arbitrary features and objects in the scene and maintain attention on the selected information. It is often assumed that an attentional priority signal encodes the current focus of attention and its deployment. However, how the brain computes and maintains attentional priority for features and objects is not known. The long-term goal is to understand how the brain selects different types of information and how selection shapes perception to serve goal-oriented behavior. The objective of this proposal is to delineate the cortical circuitry representing attentional priority for features and objects using functional magnetic resonance imaging (fMRI). Based on recent data obtained in our laboratory, we hypothesize that the dorsal frontoparietal network represents different types of selected information with distinct neural populations, forming a multiplexed representation of attentional priority. In this proposal, we wil test this hypothesis by pursuing four specific aims. First, we will determine the neural representation of attentional priority for visual objects. Second, we will seek to establish a quantitative link between priority signals and task performance. Third, we will determine the relationship between attentional priority signals for features and objects and those for spatial locations. Fourth, we will evaluate the degree of categorical representation of attentional priorit, which is essential for flexible deployment of attention. The proposed research is expected to significantly advance our understanding of how the brain selects and maintains non- spatial information, thus filling in a critical gap in the current scientific knowledge. A deeper understanding of how the brain selects features and objects will provide important constraints for models of attention and can potentially transform our understanding of visual information processing and cognitive control. The proposed research is innovative both in terms of conceptual and methodological advances. Conceptually, the research will test the novel hypothesis that the dorsal frontoparietal network represents attention priority for non-spatial dimensions, challenging the prevailing view that these cortical areas mainly represent spatial information. Methodologically, the application of cutting-edge machine learning and data mining techniques (pattern classification, similarity and clustering analysis) represents a novel approach that more fully exploits the complexity and richness of fMRI data than conventional methods. Finally, the proposed research can make connections to other fields such as category learning and decision making, and suggest interesting future directions to examine common neural processes underlying these cognitive functions.        PUBLIC HEALTH RELEVANCE: Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                  Impairment in attention is associated with many neuropsychological conditions, such as neglect due to stroke, attention deficit-hyperactivity disorder, autism, and Alzheimer's disease, as well as certain visual problems such as strabismic amblyopia. By elucidating the basic brain mechanisms of attention, the proposed research will inform our understanding of the nature of attentional deficits in these disorders and contribute to the basic research foundation that will ultimately guide the diagnosis and treatment of these disorders.                ",Neural mechanisms of attentional priority for visual features and objects,8346020,R01EY022727,"['Adaptive Behaviors', 'Alzheimer&apos', 's Disease', 'Architecture', 'Area', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Autistic Disorder', 'Basic Science', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Child', 'Classification', 'Cluster Analysis', 'Complex', 'Crowding', 'Data', 'Decision Making', 'Diagnosis', 'Dimensions', 'Disease', 'Dorsal', 'Ensure', 'Environment', 'Exhibits', 'Feedback', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Human', 'Impairment', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Location', 'Machine Learning', 'Methods', 'Modeling', 'Nature', 'Parents', 'Pattern', 'Perception', 'Performance', 'Population', 'Process', 'Property', 'Research', 'Safety', 'Shapes', 'Signal Transduction', 'Silver', 'Stimulus Deprivation-Induced Amblyopia', 'Stroke', 'Swimming Pools', 'System', 'Task Performances', 'Techniques', 'Testing', 'Time', 'Variant', 'Visual', 'Visual Perception', 'Visual attention', 'Visual system structure', 'Work', 'abstracting', 'base', 'cognitive control', 'cognitive function', 'coping', 'data mining', 'distraction', 'flexibility', 'goal oriented behavior', 'information processing', 'innovation', 'interest', 'neglect', 'neural circuit', 'neural model', 'neural patterning', 'neuromechanism', 'neuropsychological', 'novel', 'novel strategies', 'relating to nervous system', 'visual information', 'visual process', 'visual processing']",NEI,MICHIGAN STATE UNIVERSITY,R01,2012,360389,0.07463737918952669
"The Role of Animacy and Size in the Neural Organization of Object Knowledge DESCRIPTION (provided by applicant): The goal of this research is to characterize the large-scale organization and emergence of object responses along the ventral stream. Cognitive systems dissociate along the animate/inanimate distinction in behavior, and neural systems reflect this distinction with a large-scale organization of animate and inanimate object responses across the cortical surface. Recently, the real-world size of objects was also shown to be a fundamental aspect of object representation, and also gives rise to a large-scale organization of big and small object information across the cortex. The first aim will directly compare animacy and size organizations using functional neuroimaging, determining how the size and animacy organizations interact, and the relative strength of these two dimensions in neural organization. Next, the emergence of these large-scale topographies is hypothesized to arise from distinct, but non-mutually exclusive causes-network connectivity and visual experience. The second aim [will explore the role that visual experience plays in shaping large-scale object organization] by measuring occipital-temporal cortex that has never received visual experience, in congenitally blind participants; and will compare long-range networks between groups using functional connectivity measures. The broader objectives of this project are to develop an expertise in advanced neuroimaging analyses, to understand the basic principles of brain organization, and to characterize the impact of normal and atypical experience on cortical development. PUBLIC HEALTH RELEVANCE: Understanding the organization and emergence of object knowledge in the neural system is a fundamental endeavor of cognitive neuroscience. This work will advance our understanding of the ways in which experience in the lifetime can modify the structure of our high-level object representation. Characterizing how differences in experience, or the lack thereof, can change how the brain processes different kinds of information is relevant and important for all individuals with visual or other sensory impairments.",The Role of Animacy and Size in the Neural Organization of Object Knowledge,8835112,F32EY022863,"['Accounting', 'Address', 'Affective', 'Animals', 'Area', 'Auditory', 'Behavior', 'Brain', 'Cereals', 'Characteristics', 'Development', 'Dimensions', 'Figs - dietary', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Health', 'Impairment', 'Individual', 'Knowledge', 'Maps', 'Measures', 'Modality', 'Nature', 'Participant', 'Play', 'Process', 'Property', 'Relative (related person)', 'Research', 'Role', 'Sensory', 'Shapes', 'Stimulus', 'Stream', 'Structure', 'Surface', 'System', 'Temporal Lobe', 'Vision', 'Visual', 'Work', 'auditory stimulus', 'blind', 'cognitive neuroscience', 'cognitive system', 'experience', 'falls', 'information organization', 'insight', 'motor control', 'neuroimaging', 'pressure', 'relating to nervous system', 'research study', 'response', 'sight for the blind', 'statistics', 'tool', 'visual stimulus']",NEI,HARVARD UNIVERSITY,F32,2015,11288,0.14558381278497956
"The Role of Animacy and Size in the Neural Organization of Object Knowledge     DESCRIPTION (provided by applicant): The goal of this research is to characterize the large-scale organization and emergence of object responses along the ventral stream. Cognitive systems dissociate along the animate/inanimate distinction in behavior, and neural systems reflect this distinction with a large-scale organization of animate and inanimate object responses across the cortical surface. Recently, the real-world size of objects was also shown to be a fundamental aspect of object representation, and also gives rise to a large-scale organization of big and small object information across the cortex. The first aim will directly compare animacy and size organizations using functional neuroimaging, determining how the size and animacy organizations interact, and the relative strength of these two dimensions in neural organization. Next, the emergence of these large-scale topographies is hypothesized to arise from distinct, but non-mutually exclusive causes-network connectivity and visual experience. The second aim [will explore the role that visual experience plays in shaping large-scale object organization] by measuring occipital-temporal cortex that has never received visual experience, in congenitally blind participants; and will compare long-range networks between groups using functional connectivity measures. The broader objectives of this project are to develop an expertise in advanced neuroimaging analyses, to understand the basic principles of brain organization, and to characterize the impact of normal and atypical experience on cortical development.         PUBLIC HEALTH RELEVANCE: Understanding the organization and emergence of object knowledge in the neural system is a fundamental endeavor of cognitive neuroscience. This work will advance our understanding of the ways in which experience in the lifetime can modify the structure of our high-level object representation. Characterizing how differences in experience, or the lack thereof, can change how the brain processes different kinds of information is relevant and important for all individuals with visual or other sensory impairments.                ",The Role of Animacy and Size in the Neural Organization of Object Knowledge,8685010,F32EY022863,"['Accounting', 'Address', 'Affective', 'Animals', 'Area', 'Auditory', 'Behavior', 'Brain', 'Cereals', 'Characteristics', 'Development', 'Dimensions', 'Figs - dietary', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Impairment', 'Individual', 'Knowledge', 'Maps', 'Measures', 'Modality', 'Nature', 'Participant', 'Play', 'Process', 'Property', 'Relative (related person)', 'Research', 'Role', 'Sensory', 'Shapes', 'Stimulus', 'Stream', 'Structure', 'Surface', 'System', 'Temporal Lobe', 'Vision', 'Visual', 'Work', 'auditory stimulus', 'blind', 'cognitive neuroscience', 'cognitive system', 'experience', 'falls', 'information organization', 'insight', 'motor control', 'neuroimaging', 'pressure', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'sight for the blind', 'statistics', 'tool', 'visual stimulus']",NEI,HARVARD UNIVERSITY,F32,2014,53282,0.14558381278497956
"The Role of Animacy and Size in the Neural Organization of Object Knowledge     DESCRIPTION (provided by applicant): The goal of this research is to characterize the large-scale organization and emergence of object responses along the ventral stream. Cognitive systems dissociate along the animate/inanimate distinction in behavior, and neural systems reflect this distinction with a large-scale organization of animate and inanimate object responses across the cortical surface. Recently, the real-world size of objects was also shown to be a fundamental aspect of object representation, and also gives rise to a large-scale organization of big and small object information across the cortex. The first aim will directly compare animacy and size organizations using functional neuroimaging, determining how the size and animacy organizations interact, and the relative strength of these two dimensions in neural organization. Next, the emergence of these large-scale topographies is hypothesized to arise from distinct, but non-mutually exclusive causes-network connectivity and visual experience. The second aim [will explore the role that visual experience plays in shaping large-scale object organization] by measuring occipital-temporal cortex that has never received visual experience, in congenitally blind participants; and will compare long-range networks between groups using functional connectivity measures. The broader objectives of this project are to develop an expertise in advanced neuroimaging analyses, to understand the basic principles of brain organization, and to characterize the impact of normal and atypical experience on cortical development.         PUBLIC HEALTH RELEVANCE: Understanding the organization and emergence of object knowledge in the neural system is a fundamental endeavor of cognitive neuroscience. This work will advance our understanding of the ways in which experience in the lifetime can modify the structure of our high-level object representation. Characterizing how differences in experience, or the lack thereof, can change how the brain processes different kinds of information is relevant and important for all individuals with visual or other sensory impairments.                ",The Role of Animacy and Size in the Neural Organization of Object Knowledge,8525704,F32EY022863,"['Accounting', 'Address', 'Affective', 'Animals', 'Area', 'Auditory', 'Behavior', 'Brain', 'Cereals', 'Characteristics', 'Development', 'Dimensions', 'Figs - dietary', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Impairment', 'Individual', 'Knowledge', 'Maps', 'Measures', 'Modality', 'Nature', 'Participant', 'Play', 'Process', 'Property', 'Relative (related person)', 'Research', 'Role', 'Sensory', 'Shapes', 'Stimulus', 'Stream', 'Structure', 'Surface', 'System', 'Temporal Lobe', 'Vision', 'Visual', 'Work', 'auditory stimulus', 'blind', 'cognitive neuroscience', 'cognitive system', 'experience', 'falls', 'information organization', 'insight', 'motor control', 'neuroimaging', 'pressure', 'public health relevance', 'relating to nervous system', 'research study', 'response', 'sight for the blind', 'statistics', 'tool', 'visual stimulus']",NEI,HARVARD UNIVERSITY,F32,2013,49214,0.14558381278497956
"3-D COMPUTERIZED ATLAS OF HUMAN BRAIN The overall objective of this project is to develop techniques and ultimately a system which will allow the rapid, objective and quantitative analysis of brain scan data obtained from computed tomography (CT), magnetic resonance imaging (MRI), and positron emission tomography (PET). This entails relating the scans to a computer based atlas of the human brain for objective determination of anatomic information with which to relate the functional image.  We plan to develop a system with ""user friendly software"" (e.g. simple to use by clinicians and basic researchers).  We expect that the system will be highly interactive and will provide real-time analytic feedback abilities to the user.  Techniques will be developed for the interactive display, manipulation, and image processing of 3-D data.  A 3-D Voxel representation of a standard Atlas of the human brain as well as of clinical CT, MRI or PET data will be implemented.  Image processing capabilities will include automatic thresholding, reslicing in any arbitrary plane, calculation of various statistics, and highlighting outlines or areas of interest.  The display capabilities will include real-time translation, rotation, scaling, segmentation, and enhancement of 3-D medical objects.  Interactive editing of such 3-D medical objects and the merging of multiple modalities (i.e., CT and MRI) for comparison and analysis will also be supported.  n/a",3-D COMPUTERIZED ATLAS OF HUMAN BRAIN,3407379,R01NS023636,"['artificial intelligence', ' brain', ' computed axial tomography', ' computer data analysis', ' computer graphics /printing', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' image processing', ' magnetic resonance imaging', ' morphology', ' neuroanatomy', ' positron emission tomography']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,1988,165560,0.09797193754155943
"3-D COMPUTERIZED ATLAS OF HUMAN BRAIN The overall objective of this project is to develop techniques and ultimately a system which will allow the rapid, objective and quantitative analysis of brain scan data obtained from computed tomography (CT), magnetic resonance imaging (MRI), and positron emission tomography (PET). This entails relating the scans to a computer based atlas of the human brain for objective determination of anatomic information with which to relate the functional image.  We plan to develop a system with ""user friendly software"" (e.g. simple to use by clinicians and basic researchers).  We expect that the system will be highly interactive and will provide real-time analytic feedback abilities to the user.  Techniques will be developed for the interactive display, manipulation, and image processing of 3-D data.  A 3-D Voxel representation of a standard Atlas of the human brain as well as of clinical CT, MRI or PET data will be implemented.  Image processing capabilities will include automatic thresholding, reslicing in any arbitrary plane, calculation of various statistics, and highlighting outlines or areas of interest.  The display capabilities will include real-time translation, rotation, scaling, segmentation, and enhancement of 3-D medical objects.  Interactive editing of such 3-D medical objects and the merging of multiple modalities (i.e., CT and MRI) for comparison and analysis will also be supported.  n/a",3-D COMPUTERIZED ATLAS OF HUMAN BRAIN,3407378,R01NS023636,"['artificial intelligence', ' brain', ' computed axial tomography', ' computer data analysis', ' computer graphics /printing', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' image processing', ' morphology', ' neuroanatomy', ' positron emission tomography']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,1987,190772,0.09797193754155943
"3-D COMPUTERIZED ATLAS OF HUMAN BRAIN The overall objective of this project is to develop techniques and ultimately a system which will allow the rapid, objective and quantitative analysis of brain scan data obtained from computed tomography (CT), magnetic resonance imaging (MRI), and positron emission tomography (PET). This entails relating the scans to a computer based atlas of the human brain for objective determination of anatomic information with which to relate the functional image.  We plan to develop a system with ""user friendly software"" (e.g. simple to use by clinicians and basic researchers).  We expect that the system will be highly interactive and will provide real-time analytic feedback abilities to the user.  Techniques will be developed for the interactive display, manipulation, and image processing of 3-D data.  A 3-D Voxel representation of a standard Atlas of the human brain as well as of clinical CT, MRI or PET data will be implemented.  Image processing capabilities will include automatic thresholding, reslicing in any arbitrary plane, calculation of various statistics, and highlighting outlines or areas of interest.  The display capabilities will include real-time translation, rotation, scaling, segmentation, and enhancement of 3-D medical objects.  Interactive editing of such 3-D medical objects and the merging of multiple modalities (i.e., CT and MRI) for comparison and analysis will also be supported.  n/a",3-D COMPUTERIZED ATLAS OF HUMAN BRAIN,3407377,R01NS023636,"['artificial intelligence', ' brain', ' computed axial tomography', ' computer data analysis', ' computer graphics /printing', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' image processing', ' morphology', ' neuroanatomy', ' positron emission tomography']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,1986,197323,0.09797193754155943
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9559873,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,300000,0.14512334612562391
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9672008,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,347221,0.14512334612562391
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals. PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9137657,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Health', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'microscopic imaging', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2016,246750,0.12999447893793636
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals.         PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.            ",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9053610,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Microscopic', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'public health relevance', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2015,239361,0.12999447893793636
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9884770,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Models', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'convolutional neural network', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2020,388626,0.20313802510945797
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9637403,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Simulation', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'convolutional neural network', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2019,388812,0.20313802510945797
"Studying crowding as a window into object recognition and development and health of visual cortex ABSTRACT  Our long-term goal is to understand how the human brain recognizes objects. This 3-year project will characterize the computational kernel (computation that is applied independently to many parts of the image data) that is isolated by crowding experiments. We present the discovery that recognition of simple objects is performed by recognition units implementing the same computation at every eccentricity. These units are dense in the fovea and thus hard to isolate there, but they are sparse in the periphery, and easily isolated. Our fMRI & psychophysics pilot data show that each of these units, at every eccentricity, has a circular receptive field with a radius of 2.6±1.5 mm (mean±SD) in human cortical area hV4. Because of cortical magnification, that 2.6 mm corresponds to a tiny 0.05 deg in the fovea, but grows linearly with eccentricity, to a comfortable 3 deg at 10 deg eccentricity. We test this idea by pursuing its implications physiologically (Aim 1), clinically (Aim 2), and psychophysically and computationally (Aim 3).  Aim 1. Better noninvasive measures for the health and development of visual cortex are needed. Conservation of crowding distance (in mm) in a particular cortical area (hV4) would validate crowding distance as a quick, noninvasive measure of that area's condition. Aim 2. Huge public interventions seek to help dyslexic children read faster and identify amblyopic children sooner. It would be valuable to know whether crowding contributes to reading problems and provides a basis for effective screening for dyslexia and amblyopia, as it can be measured before children learn to read. Aim 3. Documenting conservation of efficiency gives evidence that the same universal computation recognizes objects at every eccentricity. We are testing the first computational model of object recognition that accounts for many human characteristics of simple-object recognition. The new work extends to effect of receptive field size and learning. Project Narrative (relevance to public health) This proposal is a collaboration between a psychophysicist, expert on human object recognition, a computer scientist, expert on machine learning for object recognition by computers, and a brain imager, expert on brain mapping, to discover to what extent computer models of object recognition and the brain can account for key properties of human performance. Our first aim tracks the development of crowding in normal and amblyopic children, in collaboration with experts in optometry, reading, and development. Advances in this area could shed light on the problems of people with impaired object recognition, including amblyopia and dyslexia, with a potential for development of early pre-literate screening tests for amblyopia and risk of dyslexia.",Studying crowding as a window into object recognition and development and health of visual cortex,9455331,R01EY027964,"['Address', 'Adult', 'Affect', 'Age', 'Amblyopia', 'Area', 'Atlases', 'Biological', 'Brain', 'Brain Mapping', 'Bypass', 'Child', 'Clinical', 'Collaborations', 'Complex', 'Computer Simulation', 'Computers', 'Crowding', 'Data', 'Development', 'Disease', 'Dyslexia', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Health', 'Human', 'Human Characteristics', 'Image', 'Immunity', 'Impairment', 'Intervention', 'Italy', 'Joints', 'Learning', 'Letters', 'Light', 'Location', 'Machine Learning', 'Magic', 'Measurement', 'Measures', 'Mediating', 'Modeling', 'Neurosciences', 'Noise', 'Nose', 'Occipital lobe', 'Optometry', 'Participant', 'Perception', 'Performance', 'Peripheral', 'Physiological', 'Population Heterogeneity', 'Postdoctoral Fellow', 'Property', 'Psychophysics', 'Public Health', 'Radial', 'Reading', 'Rest', 'Risk', 'Rome', 'Scientist', 'Speed', 'Stereotyping', 'Stimulus Deprivation-Induced Amblyopia', 'Surface', 'Testing', 'Vision', 'Visual Cortex', 'Visual Fields', 'Work', 'assault', 'cerebral atrophy', 'clinical application', 'crowdsourcing', 'experimental study', 'extrastriate visual cortex', 'fovea centralis', 'imager', 'literate', 'object recognition', 'physiologic model', 'receptive field', 'relating to nervous system', 'research clinical testing', 'sample fixation', 'screening', 'vision development']",NEI,NEW YORK UNIVERSITY,R01,2018,388993,0.20313802510945797
"Access to parietal action representations after stroke lesions in visual cortex PROJECT SUMMARY  The ability to recognize and use objects according to their function (e.g., fork, hammer, pencil) requires integration of visual, semantic and action knowledge across occipital, temporal and parietal areas. Left parietal regions support critical aspects of object-directed action, such as grasping and object manipulation. This research activity uses a combination of fMRI and behavioral measures in patients with ischemic strokes to early and extrastriate visual areas to test the following hypotheses: Aim 1: There is a visual pathway to the parietal grasp region (aIPS) that bypasses processing in primary visual cortex. Aim 2: Left ventral extrastriate cortex is necessary to access manipulation information for visually presented objects. Aim 3A: Ballistic grasping actions to objects in the hemianopic field are influenced by volumetric properties (size, orientation) of targets. Aim 3B: Left ventral extrastriate lesions impair object function (e.g., `scissors used to cut') and disrupt access to manipulation knowledge from visual input. The research leverages strengths of fMRI (whole brain correlational measure) and neuropsychology (causal inference) to test new hypotheses about vision and action.  `Tools' (i.e., small manipulable objects) are an excellent domain in which to address broader questions about the integration of sensory, motor and cognitive processing. This is because tool recognition and tool use require the integration of distinct sensory, motor and cognitive representations, and the neural substrates of tool processing are well described. The research program emphasizes fresh perspectives on longstanding ideas about the dorsal and ventral visual pathways, by a) undertaking the first systematic investigation of the types of information about objects that are extracted by visual pathways that bypass primary visual cortex, and by b) studying how some parietal areas depend on inputs from the ventral stream in order to access the correct action for a given object. The research activity innovates by testing hypotheses about how lesions at different stages in the cortical visual hierarchy affect downstream processing in parietal cortex, combining neural and behavioral measures to study brain damaged patients (generating causal evidence), and by combining univariate and multivariate measures to `read out' the information content of brain regions (parietal cortex) that are anatomically remote from a lesion. The research advances understanding of how lesions in one brain region disrupt computations in other parts of the brain that depend on the damaged region for their inputs, a phenomenon (`dynamic diaschisis') that applies to brain injury generally. Advancing understanding of these basic issues using causal data has broad implications for understanding how the brain selects the correct action for the correct object, and more generally for theories of conceptual organization and causal reasoning. Understanding how the brain accesses actions from visual input has implications for related fields, such as robotics, neuroprosthetics, and evidenced based approaches for rehabilitating function after brain injury. Project Narrative Functional MRI and behavioral testing are used to test hypotheses about how strokes affecting occipital and temporal cortex disrupt access to action representations in parietal cortex. This research will advance understanding of how the brain processes visual information in support of everyday actions.",Access to parietal action representations after stroke lesions in visual cortex,9868307,R01EY028535,"['Address', 'Affect', 'Alexia', 'Anatomy', 'Area', 'Ballistics', 'Behavioral Assay', 'Brain', 'Brain Injuries', 'Brain region', 'Bypass', 'Cognitive', 'Data', 'Dorsal', 'Eating', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Imaging Device', 'Impairment', 'Investigation', 'Ischemic Stroke', 'Knowledge', 'Left', 'Lesion', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Neural Pathways', 'Neuropsychology', 'Occipital lobe', 'Parahippocampal Gyrus', 'Parietal', 'Parietal Lobe', 'Participant', 'Pathway interactions', 'Patients', 'Population', 'Process', 'Property', 'Prosopagnosia', 'Reading', 'Research', 'Research Activity', 'Robotics', 'Role', 'Semantics', 'Sensory', 'Stimulus', 'Stream', 'Stroke', 'Structure of supramarginal gyrus', 'Temporal Lobe', 'Testing', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual system structure', 'Work', 'area striata', 'base', 'behavior measurement', 'behavior test', 'blind', 'cognitive development', 'evidence base', 'extrastriate', 'extrastriate visual cortex', 'fovea centralis', 'grasp', 'information processing', 'innovation', 'lens', 'multisensory', 'neuroprosthesis', 'post stroke', 'programs', 'relating to nervous system', 'sensory integration', 'theories', 'tool', 'visual information', 'visual motor', 'visual object processing', 'visual process', 'visual processing']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2020,423007,-0.00014973712309594324
"Access to parietal action representations after stroke lesions in visual cortex PROJECT SUMMARY  The ability to recognize and use objects according to their function (e.g., fork, hammer, pencil) requires integration of visual, semantic and action knowledge across occipital, temporal and parietal areas. Left parietal regions support critical aspects of object-directed action, such as grasping and object manipulation. This research activity uses a combination of fMRI and behavioral measures in patients with ischemic strokes to early and extrastriate visual areas to test the following hypotheses: Aim 1: There is a visual pathway to the parietal grasp region (aIPS) that bypasses processing in primary visual cortex. Aim 2: Left ventral extrastriate cortex is necessary to access manipulation information for visually presented objects. Aim 3A: Ballistic grasping actions to objects in the hemianopic field are influenced by volumetric properties (size, orientation) of targets. Aim 3B: Left ventral extrastriate lesions impair object function (e.g., `scissors used to cut') and disrupt access to manipulation knowledge from visual input. The research leverages strengths of fMRI (whole brain correlational measure) and neuropsychology (causal inference) to test new hypotheses about vision and action.  `Tools' (i.e., small manipulable objects) are an excellent domain in which to address broader questions about the integration of sensory, motor and cognitive processing. This is because tool recognition and tool use require the integration of distinct sensory, motor and cognitive representations, and the neural substrates of tool processing are well described. The research program emphasizes fresh perspectives on longstanding ideas about the dorsal and ventral visual pathways, by a) undertaking the first systematic investigation of the types of information about objects that are extracted by visual pathways that bypass primary visual cortex, and by b) studying how some parietal areas depend on inputs from the ventral stream in order to access the correct action for a given object. The research activity innovates by testing hypotheses about how lesions at different stages in the cortical visual hierarchy affect downstream processing in parietal cortex, combining neural and behavioral measures to study brain damaged patients (generating causal evidence), and by combining univariate and multivariate measures to `read out' the information content of brain regions (parietal cortex) that are anatomically remote from a lesion. The research advances understanding of how lesions in one brain region disrupt computations in other parts of the brain that depend on the damaged region for their inputs, a phenomenon (`dynamic diaschisis') that applies to brain injury generally. Advancing understanding of these basic issues using causal data has broad implications for understanding how the brain selects the correct action for the correct object, and more generally for theories of conceptual organization and causal reasoning. Understanding how the brain accesses actions from visual input has implications for related fields, such as robotics, neuroprosthetics, and evidenced based approaches for rehabilitating function after brain injury. Project Narrative Functional MRI and behavioral testing are used to test hypotheses about how strokes affecting occipital and temporal cortex disrupt access to action representations in parietal cortex. This research will advance understanding of how the brain processes visual information in support of everyday actions.",Access to parietal action representations after stroke lesions in visual cortex,9659002,R01EY028535,"['Address', 'Affect', 'Alexia', 'Anatomy', 'Area', 'Ballistics', 'Behavioral Assay', 'Brain', 'Brain Injuries', 'Brain region', 'Bypass', 'Cognitive', 'Data', 'Dorsal', 'Eating', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Imaging Device', 'Impairment', 'Investigation', 'Ischemic Stroke', 'Knowledge', 'Left', 'Lesion', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Neural Pathways', 'Neuropsychology', 'Occipital lobe', 'Parahippocampal Gyrus', 'Parietal', 'Parietal Lobe', 'Participant', 'Pathway interactions', 'Patients', 'Population', 'Process', 'Property', 'Prosopagnosia', 'Reading', 'Research', 'Research Activity', 'Robotics', 'Role', 'Semantics', 'Sensory', 'Stimulus', 'Stream', 'Stroke', 'Structure of supramarginal gyrus', 'Temporal Lobe', 'Testing', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual system structure', 'Work', 'area striata', 'base', 'behavior measurement', 'behavior test', 'blind', 'cognitive development', 'evidence base', 'extrastriate', 'extrastriate visual cortex', 'fovea centralis', 'grasp', 'information processing', 'innovation', 'lens', 'multisensory', 'neuroprosthesis', 'post stroke', 'programs', 'relating to nervous system', 'sensory integration', 'theories', 'tool', 'visual information', 'visual motor', 'visual object processing', 'visual process', 'visual processing']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2019,439559,-0.00014973712309594324
"Early representation of 3D volumetric shape in visual object processing Project Summary The goal of this project is to test a novel theoretical framework for understanding how the ventral pathway subserves object vision. In the standard framework, a series of neural operations on 2D image data through many intermediate cortical stages, including area V4, leads to high-level perceptual representations, including representation of object identity, at the final stages of the ventral pathway. However, our preliminary microelectrode data from a fixating monkey show that many neurons in V4 represent volumetric (volume- enclosing) 3D shape, not 2D image patterns. These neurons respond to many different 2D images that convey the same 3D shape with different shape-in-depth cues, including shading, reflection, and refraction. They even respond preferentially to random dot stereograms that convey 3D volumetric shape with no 2D cues whatsoever. Moreover, our preliminary results with 2-photon functional imaging in anesthetized monkey V4 show that 3D shape signals are grouped by their similarity, and also group with isomorphic (same outline) 2D shape signals (which could contribute evidence to corresponding 3D shape inferences). We propose to capitalize on these preliminary data by demonstrating the prevalence of 3D shape tuning in area V4, analyzing the 3D shape coding strategies used by these neurons, and measuring how 2D and 3D shape signals are arranged at a microscopic level across the surface of V4. We expect these results to provide strong evidence that extraction of 3D shape fragments is a primary goal of V4 processing. This early extraction of 3D shape information, just two synapses beyond primary visual cortex, would suggest a competing framework for understanding the ventral pathway, in which the initial goal is to represent 3D physical structure, independent of the various 2D image cues used to infer it. In this framework, object recognition would be based on preceding information about 3D physical structure, which would explain why human object recognition is so robust to image changes, in a way that the best computational vision systems are not. The scientific impact of this work would be to divert vision experiments toward understanding representation of real world 3D structure (rather than 2D planar stimuli) and to encourage computational vision scientists to incorporate early 3D shape processing into the deep convolutional network models that are the current state of the art. Narrative This study will help explain how the human brain achieves such remarkably robust perception of visual objects. The results will help guide future rehabilitative and prosthetic strategies for patients with visual impairments, by elucidating neural strategies that could be used to bring computer vision prosthetics up to human performance levels, and by discovering specific neural signals for object information that could be replicated by electrode array implants in higher-level visual cortex.",Early representation of 3D volumetric shape in visual object processing,9942414,R01EY029420,"['3-Dimensional', '3D world', 'Area', 'Biological', 'Brain', 'Calcium Signaling', 'Code', 'Computer Vision Systems', 'Cues', 'Data', 'Electrodes', 'Functional Imaging', 'Future', 'Genetic Programming', 'Glass', 'Goals', 'Human', 'Image', 'Implant', 'Lead', 'Learning', 'Measures', 'Medial', 'Microelectrodes', 'Microscopic', 'Microscopy', 'Modeling', 'Monkeys', 'Network-based', 'Neurons', 'Ocular Prosthesis', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Population', 'Prevalence', 'Prosthesis', 'Rehabilitation therapy', 'Scientist', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Structure', 'Surface', 'Synapses', 'System', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'V4 neuron', 'Vision', 'Visual Cortex', 'Visual Perception', 'Visual impairment', 'Work', 'area V4', 'area striata', 'base', 'convolutional neural network', 'experimental study', 'individual response', 'network models', 'neurotransmission', 'nonhuman primate', 'novel', 'object perception', 'object recognition', 'operation', 'relating to nervous system', 'response', 'three dimensional structure', 'two-photon', 'virtual reality', 'visual object processing']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2020,548567,0.013587469436112302
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,10018020,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2020,332870,0.13662370047010142
"Towards a Compositional Generative Model of Human Vision Understanding object recognition has long been a central problem in vision science, because of its applied utility and computational difficulty. Progress has been slow, because of an inability to process complex natural images, where the largest challenges arise. Recently, advances in Deep Convolutional Neural Networks (DCNNs) spurred unprecedented success in natural image recognition. The general goal of this proposal is to leverage this success to test computational theories of human object recognition in natural images. However, DCNNs still markedly underperform humans when challenged with high levels of ambiguity, occlusion, and articulation. We hypothesize that humans' superior performance arises from the use of knowledge about how images and objects are structured. Preliminary evidence for this claim comes from the success of hybrid models, that combine DCNNS for identifying features and parts in images, with explicit knowledge of object and image structure. These computations occur within a hierarchy, which includes both top-down and bottom- up processing. The specific goal of the work proposed here is to strongly test whether these computational strategies, structured, hierarchical representations and bidirectional processing, are used to recognize objects in natural images. Human bodies are composed of hierarchically organized configurable parts, making them an ideal test domain. We examine the complete recognition process, from parts, to pairs of parts, to whole bodies, each in its own aim. Each aim also tests important sub-hypotheses about when and how the computational strategies are used. Aim 1 examines recognition of individual body parts, testing whether it is dependent on parsing images into more basic features and relationships, for example edges and materials. Aim 2 examines pairs of parts, testing the importance of knowledge of body connectedness relationships. Aim 3 examines perception of entire bodies, testing whether knowledge of global body structure guides bidirectional processing. In each aim, we first develop nested computer vision models that either do or do not make use of structural knowledge, to test whether it aids recognition. We then test whether human performance can be accounted for by the availability of that structural knowledge. We next measure neural activity with functional MRI to identify where and how it is used in cortex. Finally, we integrate these results to produce even stronger tests, using the nested models to predict human performance and confusion matrices as well as fMRI activity levels and confusion matrices. Altogether, this work will strongly test key theoretical accounts of object recognition in the most important domain, perception of natural images. The work, based on extensive preliminary data, measures and models the entire body recognition system. The models developed and tested here should surpass the state-of-the-art, and be useful for many real-world recognition tasks. The proposal will also lay the groundwork for future studies of recognition impaired by disease. This research uses computational, behavioral, and brain imaging methods to investigate how the visual system represents and processes information about human bodies. The studies will reveal how and when people can accurately recognize objects in natural images, how the brain supports this function, and how loss of information, similar to that that accompanies visual disease, may affect the ability to interpret everyday scenes.",Towards a Compositional Generative Model of Human Vision,9818274,R01EY029700,"['Affect', 'Area', 'Articulation', 'Behavioral', 'Body Image', 'Body part', 'Brain', 'Brain imaging', 'Complex', 'Computer Vision Systems', 'Confusion', 'Cues', 'Data', 'Development', 'Disease', 'Elbow', 'Feedback', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Human', 'Human body', 'Hybrids', 'Image', 'Impairment', 'Individual', 'Knowledge', 'Link', 'Measures', 'Modeling', 'Perception', 'Performance', 'Predictive Value', 'Process', 'Psychophysics', 'Published Comment', 'Research', 'Structure', 'System', 'Testing', 'Training', 'Vision', 'Visual', 'Visual system structure', 'Work', 'Wrist', 'base', 'convolutional neural network', 'crowdsourcing', 'human model', 'imaging modality', 'improved', 'object recognition', 'relating to nervous system', 'spatial relationship', 'success', 'theories', 'vision science']",NEI,UNIVERSITY OF MINNESOTA,R01,2019,352996,0.13662370047010142
"Neurocognitive basis of attention and eye movement guidance in the real world scenes Summary/Abstract Real world scenes contain a wealth of information that guide where we look and help us search for things in our visual environment more efficiently. For example, if you were looking for a person in a city, you would look mostly on the sidewalk, whereas if you were looking for a car, you would concentrate your attention on the street. Despite the fact that behavioral experiments have increasingly quantified the role of object and scene knowledge in the guidance of attention and eye movements, models of these processes, particularly neural models, neglect the role of visual knowledge. The goal of this project is to determine whether regions of the brain shown to be important for object and scene recognition are involved in visual guidance in natural scenes. Prior results, including our preliminary data, show that the neural activity from object processing regions can be used to predict what object a person is going to look at next. However, critical questions that remain are: is this predictive activity influenced by scene and object knowledge and is it causally related to visual guidance? Answering these two questions are the specific goals of this proposal. Individuals undergoing neurosurgical evaluation for epilepsy provide the rare opportunity of recording directly from the human brain (intracranial electroencephalography, iEEG), which provides a superior spatial and temporal resolution measure of brain activity compared to other technique. These direct recordings also allow for electrical brain stimulation (EBS), which can provide causal evidence tying the activity in particular regions to cognitive function. Finally, these data will be supplemented by magnetoencephalography (MEG) data to examine whole brain effects in healthy individuals. iEEG and MEG data arising from regions involved in object and scene recognition will be analyzed by multivariate machine learning techniques to continually classify what subjects are viewing on a moment-to- moment basis. Furthermore, we will try to predict what object subjects will view next during free viewing and visual search in natural scenes based on their neural data. We will assess how these neural signals are modified by the presence or absence of information about typical locations of objects or people in the scene that have been shown to guide behavior. Finally, using EBS we will determine if there is a causal link between the activity in regions involved in coding for object and scene knowledge and visual guidance in natural scene vision. If successful, these studies would necessitate a substantial reshaping of models of visual attention in the human brain. The results could form the foundation of a program of research into the neural basis of attention and eye movement guidance in the real world. Attention, perception, and eye movement abnormalities are seen in a host of neurological and psychiatric disorders. Thus, these studies, and the models that arise from them, have the translational potential to advance our understanding of the neurological basis of these disorders and suggest potential neurally inspired rehabilitation strategies. Narrative Abnormalities in visual attention and eye movement guidance are seen in a host of neurological and psychiatric disorders, including visual agnosia, neglect, schizophrenia, autism, etc. The neural basis of visual attention and eye movement guidance in the real world is unknown; therefore it remains unknown how neural abnormalities in these disorders relate to real world visual deficits, which is a critical barrier to designing hypothesis-driven remediation strategies. The proposed research will take critical early steps towards understanding the neural basis of real world attention and eye movement control, which has the potential to transform our understanding of these critical visual processes. The results of this research will lead to a deeper understanding of the neurobiology of eye movement and attentional guidance, a circuit relevant to a number of disorders, and take a critical step towards developing hypotheses for remediation strategies.",Neurocognitive basis of attention and eye movement guidance in the real world scenes,10004653,R21EY030297,"['Agnosia', 'Anatomy', 'Attention', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Caring', 'Categories', 'Cities', 'Code', 'Computer Models', 'Computers', 'Data', 'Disease', 'Dorsal', 'Dyskinetic syndrome', 'Electrical Stimulation of the Brain', 'Electrodes', 'Electroencephalography', 'Environment', 'Epilepsy', 'Evaluation', 'Eye', 'Eye Movements', 'Foundations', 'Functional disorder', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Knowledge', 'Link', 'Literature', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mediating', 'Mental disorders', 'Modeling', 'Monitor', 'Motivation', 'Multivariate Analysis', 'Mus', 'Neurobiology', 'Neurocognitive', 'Neurologic', 'Object Attachment', 'Operative Surgical Procedures', 'Parietal', 'Pathology', 'Perception', 'Persons', 'Play', 'Process', 'Research', 'Role', 'Saccades', 'Schizophrenia', 'Semantics', 'Site', 'Stimulus', 'Stream', 'Study models', 'Surface', 'System', 'Techniques', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual attention', 'Walking', 'attentional control', 'autism spectrum disorder', 'base', 'behavioral study', 'cognitive function', 'computer monitor', 'design', 'experimental study', 'neglect', 'nervous system disorder', 'neural circuit', 'neural model', 'neurotransmission', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'remediation', 'response', 'sample fixation', 'spatial relationship', 'temporal measurement', 'theories', 'visual process', 'visual processing', 'visual search', 'visual tracking']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,195625,0.0034851233105579033
"Neurocognitive basis of attention and eye movement guidance in the real world scenes Summary/Abstract Real world scenes contain a wealth of information that guide where we look and help us search for things in our visual environment more efficiently. For example, if you were looking for a person in a city, you would look mostly on the sidewalk, whereas if you were looking for a car, you would concentrate your attention on the street. Despite the fact that behavioral experiments have increasingly quantified the role of object and scene knowledge in the guidance of attention and eye movements, models of these processes, particularly neural models, neglect the role of visual knowledge. The goal of this project is to determine whether regions of the brain shown to be important for object and scene recognition are involved in visual guidance in natural scenes. Prior results, including our preliminary data, show that the neural activity from object processing regions can be used to predict what object a person is going to look at next. However, critical questions that remain are: is this predictive activity influenced by scene and object knowledge and is it causally related to visual guidance? Answering these two questions are the specific goals of this proposal. Individuals undergoing neurosurgical evaluation for epilepsy provide the rare opportunity of recording directly from the human brain (intracranial electroencephalography, iEEG), which provides a superior spatial and temporal resolution measure of brain activity compared to other technique. These direct recordings also allow for electrical brain stimulation (EBS), which can provide causal evidence tying the activity in particular regions to cognitive function. Finally, these data will be supplemented by magnetoencephalography (MEG) data to examine whole brain effects in healthy individuals. iEEG and MEG data arising from regions involved in object and scene recognition will be analyzed by multivariate machine learning techniques to continually classify what subjects are viewing on a moment-to- moment basis. Furthermore, we will try to predict what object subjects will view next during free viewing and visual search in natural scenes based on their neural data. We will assess how these neural signals are modified by the presence or absence of information about typical locations of objects or people in the scene that have been shown to guide behavior. Finally, using EBS we will determine if there is a causal link between the activity in regions involved in coding for object and scene knowledge and visual guidance in natural scene vision. If successful, these studies would necessitate a substantial reshaping of models of visual attention in the human brain. The results could form the foundation of a program of research into the neural basis of attention and eye movement guidance in the real world. Attention, perception, and eye movement abnormalities are seen in a host of neurological and psychiatric disorders. Thus, these studies, and the models that arise from them, have the translational potential to advance our understanding of the neurological basis of these disorders and suggest potential neurally inspired rehabilitation strategies. Narrative Abnormalities in visual attention and eye movement guidance are seen in a host of neurological and psychiatric disorders, including visual agnosia, neglect, schizophrenia, autism, etc. The neural basis of visual attention and eye movement guidance in the real world is unknown; therefore it remains unknown how neural abnormalities in these disorders relate to real world visual deficits, which is a critical barrier to designing hypothesis-driven remediation strategies. The proposed research will take critical early steps towards understanding the neural basis of real world attention and eye movement control, which has the potential to transform our understanding of these critical visual processes. The results of this research will lead to a deeper understanding of the neurobiology of eye movement and attentional guidance, a circuit relevant to a number of disorders, and take a critical step towards developing hypotheses for remediation strategies.",Neurocognitive basis of attention and eye movement guidance in the real world scenes,9830940,R21EY030297,"['Agnosia', 'Anatomy', 'Attention', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Caring', 'Categories', 'Cities', 'Code', 'Computer Simulation', 'Computers', 'Data', 'Disease', 'Dorsal', 'Dyskinetic syndrome', 'Electrical Stimulation of the Brain', 'Electrodes', 'Electroencephalography', 'Environment', 'Epilepsy', 'Evaluation', 'Eye', 'Eye Movements', 'Foundations', 'Functional disorder', 'Goals', 'Hippocampus (Brain)', 'Human', 'Individual', 'Inferior', 'Knowledge', 'Link', 'Literature', 'Location', 'Machine Learning', 'Magnetoencephalography', 'Measures', 'Mediating', 'Mental disorders', 'Modeling', 'Monitor', 'Motivation', 'Multivariate Analysis', 'Mus', 'Neurobiology', 'Neurocognitive', 'Neurologic', 'Object Attachment', 'Operative Surgical Procedures', 'Parietal', 'Pathology', 'Perception', 'Persons', 'Play', 'Process', 'Research', 'Role', 'Saccades', 'Schizophrenia', 'Semantics', 'Site', 'Stimulus', 'Stream', 'Study models', 'Surface', 'System', 'Techniques', 'Vision', 'Visual', 'Visual Agnosias', 'Visual Cortex', 'Visual attention', 'Walking', 'attentional control', 'autism spectrum disorder', 'base', 'behavioral study', 'cognitive function', 'computer monitor', 'design', 'experimental study', 'neglect', 'nervous system disorder', 'neural circuit', 'neural model', 'neurotransmission', 'programs', 'rehabilitation strategy', 'relating to nervous system', 'remediation', 'response', 'sample fixation', 'spatial relationship', 'temporal measurement', 'theories', 'visual process', 'visual processing', 'visual search']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2019,234750,0.0034851233105579033
"Neural Mechanisms of Early Memory Development   DESCRIPTION (provided by applicant): The aim of the current proposal is to                                                                      extend previous work conducted by the P.I on the ontogeny of memory to include       memory for social stimuli, specifically, faces. Work in cognitive neuroscience       has increasingly pointed to structures in the medial temporal lobe (e.g., the        fusiform gyrus) as playing a prominent role in face recognition. Unfortunately,      considerable work remains to be done to examine when in development these            function/structure relations emerge. In the current proposal a series of             studies will be conducted that will involve the recording of high-density (64        channel) event-related potentials (ERPs). Study 1 will examine infants'              recognition of familiar faces (e.g., mother, father, sibling) and objects. To        examine how much experience is necessary to facilitate recognition, Study 2          will evaluate infants' recognition of faces and objects to which they have           received extensive exposure in the home vs. laboratory. To determine if              infants' recognition of the mother's face is due to the affective significance       of this face vs. simple familiarity, Study 3 will examine Infants' recognition       of objects to which they have an emotional attachment. Studies 4 and 5 will          extend the previous studies to evaluate whether face recognition represents an       expert system or whether there is, in fact, something ""special"" about faces.         Thus, in Study 4 subjects will be asked to recognize monkey faces, whereas In        Study 5 they will be asked to recognize an artificial class of stimuli called        ""Greebles."" Across all 5 studies, detailed spatio-temporal maps will be used to      examine the neural architecture involved in face and object recognition. The         overall premise upon which this proposal is based is that experience with faces      recruits regions within the inferior temporal cortex, leading to cortical            specialization.                                                                                                                                                           n/a",Neural Mechanisms of Early Memory Development,6764151,R01NS032976,"['clinical research', 'electrophysiology', 'evoked potentials', 'human subject', 'infant human (0-1 year)', 'memory', 'neuropsychology', 'temporal lobe /cortex']",NINDS,UNIVERSITY OF MINNESOTA TWIN CITIES,R01,2004,15220,0.04923708801735346
"Neural Mechanisms of Early Memory Development   DESCRIPTION (provided by applicant): The aim of the current proposal is to                                                                      extend previous work conducted by the P.I on the ontogeny of memory to include       memory for social stimuli, specifically, faces. Work in cognitive neuroscience       has increasingly pointed to structures in the medial temporal lobe (e.g., the        fusiform gyrus) as playing a prominent role in face recognition. Unfortunately,      considerable work remains to be done to examine when in development these            function/structure relations emerge. In the current proposal a series of             studies will be conducted that will involve the recording of high-density (64        channel) event-related potentials (ERPs). Study 1 will examine infants'              recognition of familiar faces (e.g., mother, father, sibling) and objects. To        examine how much experience is necessary to facilitate recognition, Study 2          will evaluate infants' recognition of faces and objects to which they have           received extensive exposure in the home vs. laboratory. To determine if              infants' recognition of the mother's face is due to the affective significance       of this face vs. simple familiarity, Study 3 will examine Infants' recognition       of objects to which they have an emotional attachment. Studies 4 and 5 will          extend the previous studies to evaluate whether face recognition represents an       expert system or whether there is, in fact, something ""special"" about faces.         Thus, in Study 4 subjects will be asked to recognize monkey faces, whereas In        Study 5 they will be asked to recognize an artificial class of stimuli called        ""Greebles."" Across all 5 studies, detailed spatio-temporal maps will be used to      examine the neural architecture involved in face and object recognition. The         overall premise upon which this proposal is based is that experience with faces      recruits regions within the inferior temporal cortex, leading to cortical            specialization.                                                                                                                                                           n/a",Neural Mechanisms of Early Memory Development,7065536,R01NS032976,"['clinical research', 'electrophysiology', 'evoked potentials', 'human subject', 'infant human (0-1 year)', 'memory', 'neuropsychology', 'temporal lobe /cortex']",NINDS,CHILDREN'S HOSPITAL BOSTON,R01,2004,345000,0.04923708801735346
"Neural Mechanisms of Early Memory Development   DESCRIPTION (provided by applicant): The aim of the current proposal is to                                                                      extend previous work conducted by the P.I on the ontogeny of memory to include       memory for social stimuli, specifically, faces. Work in cognitive neuroscience       has increasingly pointed to structures in the medial temporal lobe (e.g., the        fusiform gyrus) as playing a prominent role in face recognition. Unfortunately,      considerable work remains to be done to examine when in development these            function/structure relations emerge. In the current proposal a series of             studies will be conducted that will involve the recording of high-density (64        channel) event-related potentials (ERPs). Study 1 will examine infants'              recognition of familiar faces (e.g., mother, father, sibling) and objects. To        examine how much experience is necessary to facilitate recognition, Study 2          will evaluate infants' recognition of faces and objects to which they have           received extensive exposure in the home vs. laboratory. To determine if              infants' recognition of the mother's face is due to the affective significance       of this face vs. simple familiarity, Study 3 will examine Infants' recognition       of objects to which they have an emotional attachment. Studies 4 and 5 will          extend the previous studies to evaluate whether face recognition represents an       expert system or whether there is, in fact, something ""special"" about faces.         Thus, in Study 4 subjects will be asked to recognize monkey faces, whereas In        Study 5 they will be asked to recognize an artificial class of stimuli called        ""Greebles."" Across all 5 studies, detailed spatio-temporal maps will be used to      examine the neural architecture involved in face and object recognition. The         overall premise upon which this proposal is based is that experience with faces      recruits regions within the inferior temporal cortex, leading to cortical            specialization.                                                                                                                                                           n/a",Neural Mechanisms of Early Memory Development,6612617,R01NS032976,"['clinical research', ' electrophysiology', ' evoked potentials', ' human subject', ' infant human (0-1 year)', ' memory', ' neuropsychology', ' temporal lobe /cortex']",NINDS,UNIVERSITY OF MINNESOTA TWIN CITIES,R01,2003,360279,0.04923708801735346
"Neural Mechanisms of Early Memory Development   DESCRIPTION (provided by applicant): The aim of the current proposal is to                                                                      extend previous work conducted by the P.I on the ontogeny of memory to include       memory for social stimuli, specifically, faces. Work in cognitive neuroscience       has increasingly pointed to structures in the medial temporal lobe (e.g., the        fusiform gyrus) as playing a prominent role in face recognition. Unfortunately,      considerable work remains to be done to examine when in development these            function/structure relations emerge. In the current proposal a series of             studies will be conducted that will involve the recording of high-density (64        channel) event-related potentials (ERPs). Study 1 will examine infants'              recognition of familiar faces (e.g., mother, father, sibling) and objects. To        examine how much experience is necessary to facilitate recognition, Study 2          will evaluate infants' recognition of faces and objects to which they have           received extensive exposure in the home vs. laboratory. To determine if              infants' recognition of the mother's face is due to the affective significance       of this face vs. simple familiarity, Study 3 will examine Infants' recognition       of objects to which they have an emotional attachment. Studies 4 and 5 will          extend the previous studies to evaluate whether face recognition represents an       expert system or whether there is, in fact, something ""special"" about faces.         Thus, in Study 4 subjects will be asked to recognize monkey faces, whereas In        Study 5 they will be asked to recognize an artificial class of stimuli called        ""Greebles."" Across all 5 studies, detailed spatio-temporal maps will be used to      examine the neural architecture involved in face and object recognition. The         overall premise upon which this proposal is based is that experience with faces      recruits regions within the inferior temporal cortex, leading to cortical            specialization.                                                                                                                                                           n/a",Neural Mechanisms of Early Memory Development,6539789,R01NS032976,"['clinical research', ' electrophysiology', ' evoked potentials', ' human subject', ' infant human (0-1 year)', ' memory', ' neuropsychology', ' temporal lobe /cortex']",NINDS,UNIVERSITY OF MINNESOTA TWIN CITIES,R01,2002,358838,0.04923708801735346
"Neural Mechanisms of Early Memory Development   DESCRIPTION (provided by applicant): The aim of the current proposal is to                                                                      extend previous work conducted by the P.I on the ontogeny of memory to include       memory for social stimuli, specifically, faces. Work in cognitive neuroscience       has increasingly pointed to structures in the medial temporal lobe (e.g., the        fusiform gyrus) as playing a prominent role in face recognition. Unfortunately,      considerable work remains to be done to examine when in development these            function/structure relations emerge. In the current proposal a series of             studies will be conducted that will involve the recording of high-density (64        channel) event-related potentials (ERPs). Study 1 will examine infants'              recognition of familiar faces (e.g., mother, father, sibling) and objects. To        examine how much experience is necessary to facilitate recognition, Study 2          will evaluate infants' recognition of faces and objects to which they have           received extensive exposure in the home vs. laboratory. To determine if              infants' recognition of the mother's face is due to the affective significance       of this face vs. simple familiarity, Study 3 will examine Infants' recognition       of objects to which they have an emotional attachment. Studies 4 and 5 will          extend the previous studies to evaluate whether face recognition represents an       expert system or whether there is, in fact, something ""special"" about faces.         Thus, in Study 4 subjects will be asked to recognize monkey faces, whereas In        Study 5 they will be asked to recognize an artificial class of stimuli called        ""Greebles."" Across all 5 studies, detailed spatio-temporal maps will be used to      examine the neural architecture involved in face and object recognition. The         overall premise upon which this proposal is based is that experience with faces      recruits regions within the inferior temporal cortex, leading to cortical            specialization.                                                                                                                                                           n/a",Neural Mechanisms of Early Memory Development,6369968,R01NS032976,"['clinical research', ' electrophysiology', ' evoked potentials', ' human subject', ' infant human (0-1 year)', ' memory', ' neuropsychology', ' temporal lobe /cortex']",NINDS,UNIVERSITY OF MINNESOTA TWIN CITIES,R01,2001,354863,0.04923708801735346
"PERCEIVING STRUCTURE IN EVENTS The aim of this project is to identify the means by which human observers organize moving structures and perceive them as dynamic wholes.  The particular moving structures used will be computer-generated displays of dots that, in their movement, mimic human walkers, rolling wheels, and other everyday events.  Previous research has shown that these displays yield robust percepts, despite their relative impoverishment of seen elements.  And the dearth of elements involved allows simple and concise mathematical description.  This project will proceed on three fronts.  The first will study perceptual organization with a particular focus on how much time is needed to organize a dynamic stimulus.  Brief displays of systems of dots will be displayed for varying amounts of time in order to assess the durations necessary for the identification of familiar movements of near-familiar objects.  The second will study perceptual organization with a focus on the effectiveness of various kinds of camouflage in inhibiting identification of common objects in motion.  Static and dynamic camouflages of several types will be employed, with a particular emphasis on the movement parameters of a dynamic camouflage that are most effective in interfering with identification.  The third will study perception organization with a focus on the information available about movement in iconic memory.  Previous research has shown that such information is available, and the nature of the coded form of that information will be assessed.  The idea is that if information about many parameters of movement is available as early as the icon, then the perceiver is clearly attuned to that information and appears not to need to elaborate it in a computational fashion.  The disciplines involved in this study are, primarily, psychology and visual perception, and, secondarily, artificial intelligence and computer simulation.  The health relatedness of this project is to be measured in terms of understanding the normal function of the human visual/perceptual system, both in situations of natural complexity and in reduced complexity such as when viewing elements on radar screens, and when watching for pedestrians crossing the streets at night.  n/a",PERCEIVING STRUCTURE IN EVENTS,3376208,R01MH037467,"['artificial intelligence', ' bioperiodicity', ' computer graphics /printing', ' computer simulation', ' mathematical model', ' memory', ' neural information processing', ' psychophysics', ' stimulus /response', ' visual perception', ' visual stimulus']",NIMH,CORNELL UNIVERSITY ITHACA,R01,1987,42448,0.039461036480970685
"PERCEIVING STRUCTURE IN EVENTS The aim of this project is to identify the means by which human observers organize moving structures and perceive them as dynamic wholes.  The particular moving structures used will be computer-generated displays of dots that, in their movement, mimic human walkers, rolling wheels, and other everyday events.  Previous research has shown that these displays yield robust percepts, despite their relative impoverishment of seen elements.  And the dearth of elements involved allows simple and concise mathematical description.  This project will proceed on three fronts.  The first will study perceptual organization with a particular focus on how much time is needed to organize a dynamic stimulus.  Brief displays of systems of dots will be displayed for varying amounts of time in order to assess the durations necessary for the identification of familiar movements of near-familiar objects.  The second will study perceptual organization with a focus on the effectiveness of various kinds of camouflage in inhibiting identification of common objects in motion.  Static and dynamic camouflages of several types will be employed, with a particular emphasis on the movement parameters of a dynamic camouflage that are most effective in interfering with identification.  The third will study perception organization with a focus on the information available about movement in iconic memory.  Previous research has shown that such information is available, and the nature of the coded form of that information will be assessed.  The idea is that if information about many parameters of movement is available as early as the icon, then the perceiver is clearly attuned to that information and appears not to need to elaborate it in a computational fashion.  The disciplines involved in this study are, primarily, psychology and visual perception, and, secondarily, artificial intelligence and computer simulation.  The health relatedness of this project is to be measured in terms of understanding the normal function of the human visual/perceptual system, both in situations of natural complexity and in reduced complexity such as when viewing elements on radar screens, and when watching for pedestrians crossing the streets at night.  n/a",PERCEIVING STRUCTURE IN EVENTS,3376206,R01MH037467,"['artificial intelligence', ' bioperiodicity', ' computer graphics /printing', ' computer simulation', ' mathematical model', ' memory', ' neural information processing', ' psychophysics', ' stimulus /response', ' visual perception', ' visual stimulus']",NIMH,CORNELL UNIVERSITY ITHACA,R01,1986,44287,0.039461036480970685
"Origins of Object Knowledge    DESCRIPTION (provided by applicant): Twelve experiments investigate the early development, in human infants, of perception of the unity of partly occluded surfaces. The experiments focus on a time during ontogeny when there may be evidence of visual sensitivity to information specifying object properties, but limited ability to perceive occlusion, with the goal of observing real-time processes by which the infant assembles visible parts of a stimulus into a coherent whole. This approach stipulates that onset of sensitivity to motion and orientation information, development of the oculomotor system, and experience viewing objects undergoing occlusion and disocclusion, play a direct, foundational role in the ontogeny of object perception. That is, there is an hypothesized period, 2 to 4 months of age, during which infants come to use newly-emerged visual skills to perceive objects accurately. The experiments follow a similar strategy: explorations of individual and group differences in both basic visual processing skills and perception of the unity of partly occluded surfaces. Infant perception is assessed with two methods: (a) recording of eye movements, to measure improvements in pickup of important visual .information, and (b) habituation/dishabituation, to ascertain perception of object unity as well as to determine the extent of sensitivity to available visual information. It is expected that the detailed analysis of individual differences afforded by this approach provide the opportunity for exceptionally sensitive measures of the emergence of visual skills and object knowledge. The short-term objectives of the present proposal are to elucidate fundamental developmental mechanisms in the context of the classic nature-nurture debate. The long-term goals are to shed light on the larger question of how knowledge is acquired and structured in the human, and how perceptual skills impact knowledge acquisition and structure. In the future, such understanding may aid in the formulation of diagnostics and treatments for some developmental disorders.         n/a",Origins of Object Knowledge,7355592,R01HD040432,"['Academy', 'Adult', 'Age', 'Age-Months', 'Birth', 'Budgets', 'Categories', 'Child Development', 'Cognition', 'Cognitive', 'Cognitive Science', 'Computer information processing', 'Condition', 'Corpus striatum structure', 'Dependence', 'Dependency', 'Detection', 'Development', 'Diagnostic', 'Drug Formulations', 'Elderly', 'Event', 'Exhibits', 'Eye', 'Eye Movements', 'Failure', 'Fostering', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Growth', 'Heart', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Infant Development', 'Investigation', 'Journals', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Learning', 'Legal patent', 'Light', 'Link', 'Literature', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Methods', 'Motion', 'Nature', 'Neurobiology', 'None or Not Applicable', 'Pattern', 'Perception', 'Performance', 'Plant Roots', 'Play', 'Preparation', 'Process', 'Process Measure', 'Property', 'Psychology', 'Range', 'Relative (related person)', 'Reporting', 'Research', 'Resources', 'Role', 'Rotation', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Side', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Students', 'Suggestion', 'Support of Research', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Vision', 'Visual', 'Visual attention', 'Visual system structure', 'Work', 'Writing', 'abstracting', 'base', 'concept', 'developmental disease', 'experience', 'follow-up', 'gaze', 'indexing', 'infancy', 'meter', 'object perception', 'oculomotor', 'psychologic', 'research study', 'sequence learning', 'size', 'skills', 'spatiotemporal', 'symposium', 'theories', 'tool', 'trend', 'visual information', 'visual process', 'visual processing']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2008,269804,0.08383198394781352
"Origins of Object Knowledge    DESCRIPTION (provided by applicant): Twelve experiments investigate the early development, in human infants, of perception of the unity of partly occluded surfaces. The experiments focus on a time during ontogeny when there may be evidence of visual sensitivity to information specifying object properties, but limited ability to perceive occlusion, with the goal of observing real-time processes by which the infant assembles visible parts of a stimulus into a coherent whole. This approach stipulates that onset of sensitivity to motion and orientation information, development of the oculomotor system, and experience viewing objects undergoing occlusion and disocclusion, play a direct, foundational role in the ontogeny of object perception. That is, there is an hypothesized period, 2 to 4 months of age, during which infants come to use newly-emerged visual skills to perceive objects accurately.   The experiments follow a similar strategy: explorations of individual and group differences in both basic visual processing skills and perception of the unity of partly occluded surfaces. Infant perception is assessed with two methods: (a) recording of eye movements, to measure improvements in pickup of important visual .information, and (b) habituation/dishabituation, to ascertain perception of object unity as well as to determine the extent of sensitivity to available visual information. It is expected that the detailed analysis of individual differences afforded by this approach provide the opportunity for exceptionally sensitive measures of the emergence of visual skills and object knowledge.   The short-term objectives of the present proposal are to elucidate fundamental developmental mechanisms in the context of the classic nature-nurture debate. The long-term goals are to shed light on the larger question of how knowledge is acquired and structured in the human, and how perceptual skills impact knowledge acquisition and structure. In the future, such understanding may aid in the formulation of diagnostics and treatments for some developmental disorders.         n/a",Origins of Object Knowledge,7783780,R01HD040432,"['Academy', 'Adult', 'Age', 'Age-Months', 'Birth', 'Budgets', 'Categories', 'Child Development', 'Cognition', 'Cognitive', 'Cognitive Science', 'Corpus striatum structure', 'Dependence', 'Dependency', 'Detection', 'Development', 'Diagnostic', 'Drug Formulations', 'Elderly', 'Event', 'Exhibits', 'Eye', 'Eye Movements', 'Failure', 'Fostering', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Growth', 'Heart', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Infant Development', 'Investigation', 'Journals', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Learning', 'Legal patent', 'Light', 'Link', 'Literature', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Methods', 'Motion', 'Nature', 'Neurobiology', 'Pattern', 'Perception', 'Performance', 'Plant Roots', 'Play', 'Preparation', 'Process', 'Process Measure', 'Property', 'Psychology', 'Relative (related person)', 'Reporting', 'Research', 'Research Support', 'Resources', 'Role', 'Rotation', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Side', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Suggestion', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Vision', 'Visual', 'Visual attention', 'Visual system structure', 'Work', 'Writing', 'abstracting', 'base', 'developmental disease', 'experience', 'gaze', 'graduate student', 'indexing', 'infancy', 'information processing', 'meter', 'object perception', 'oculomotor', 'psychologic', 'research study', 'sequence learning', 'skills', 'spatiotemporal', 'symposium', 'theories', 'tool', 'trend', 'visual information', 'visual process', 'visual processing']",NICHD,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2010,270932,0.08383198394781352
"Origins of Object Knowledge    DESCRIPTION (provided by applicant): Twelve experiments investigate the early development, in human infants, of perception of the unity of partly occluded surfaces. The experiments focus on a time during ontogeny when there may be evidence of visual sensitivity to information specifying object properties, but limited ability to perceive occlusion, with the goal of observing real-time processes by which the infant assembles visible parts of a stimulus into a coherent whole. This approach stipulates that onset of sensitivity to motion and orientation information, development of the oculomotor system, and experience viewing objects undergoing occlusion and disocclusion, play a direct, foundational role in the ontogeny of object perception. That is, there is an hypothesized period, 2 to 4 months of age, during which infants come to use newly-emerged visual skills to perceive objects accurately. The experiments follow a similar strategy: explorations of individual and group differences in both basic visual processing skills and perception of the unity of partly occluded surfaces. Infant perception is assessed with two methods: (a) recording of eye movements, to measure improvements in pickup of important visual .information, and (b) habituation/dishabituation, to ascertain perception of object unity as well as to determine the extent of sensitivity to available visual information. It is expected that the detailed analysis of individual differences afforded by this approach provide the opportunity for exceptionally sensitive measures of the emergence of visual skills and object knowledge. The short-term objectives of the present proposal are to elucidate fundamental developmental mechanisms in the context of the classic nature-nurture debate. The long-term goals are to shed light on the larger question of how knowledge is acquired and structured in the human, and how perceptual skills impact knowledge acquisition and structure. In the future, such understanding may aid in the formulation of diagnostics and treatments for some developmental disorders.         n/a",Origins of Object Knowledge,7212153,R01HD040432,"['Academy', 'Adult', 'Age', 'Age-Months', 'Birth', 'Budgets', 'Categories', 'Child Development', 'Cognition', 'Cognitive', 'Cognitive Science', 'Computer information processing', 'Condition', 'Corpus striatum structure', 'Dependence', 'Dependency', 'Detection', 'Development', 'Diagnostic', 'Drug Formulations', 'Elderly', 'Event', 'Exhibits', 'Eye', 'Eye Movements', 'Failure', 'Fostering', 'Frequencies', 'Funding', 'Future', 'Goals', 'Grant', 'Growth', 'Heart', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Infant Development', 'Investigation', 'Journals', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Learning', 'Legal patent', 'Light', 'Link', 'Literature', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Methods', 'Motion', 'Nature', 'Neurobiology', 'None or Not Applicable', 'Pattern', 'Perception', 'Performance', 'Plant Roots', 'Play', 'Preparation', 'Process', 'Process Measure', 'Property', 'Psychology', 'Range', 'Relative (related person)', 'Reporting', 'Research', 'Resources', 'Role', 'Rotation', 'Saccades', 'Sampling', 'Scanning', 'Science', 'Side', 'Specific qualifier value', 'Speed', 'Stimulus', 'Stress', 'Structure', 'Students', 'Suggestion', 'Support of Research', 'Surface', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Universities', 'Vision', 'Visual', 'Visual attention', 'Visual system structure', 'Work', 'Writing', 'abstracting', 'base', 'concept', 'developmental disease', 'experience', 'follow-up', 'gaze', 'indexing', 'infancy', 'meter', 'object perception', 'oculomotor', 'psychologic', 'research study', 'sequence learning', 'size', 'skills', 'spatiotemporal', 'symposium', 'theories', 'tool', 'trend', 'visual information', 'visual process', 'visual processing']",NICHD,NEW YORK UNIVERSITY,R01,2007,272700,0.08383198394781352
"Digital Elevation Models for Population Estimates Research exploring the feasibility of deriving population estimates from remotely sensed data demonstrates that objects in the urban landscape can be identified and incorporated into a population estimates system based on the housing unit method. Nonetheless, this research also reveals shortcomings in the technology producing the input files used in the automatic detection of objects. The problem involves the assumption and techniques used when converting high resolution images into digital elevation models (DEM). DEM files serve as input to the programs used in the detection of housing units. Efforts to correctly identify housing units are time-consuming and error-prone without clear and distinct DEMs. The objectives of this Phase I SBIR application are to further refine strengthen and test the software employed in transforming satellite and aerial imagery into digital elevation model (DEMs). DEM files serve as input to the programs used in the detection of housing units. Efforts to correctly identify housing units are time-consuming and error-prone without clear and distinct DEMs. The objectives of this Phase I SBIR application are to further refine, strengthen and test the software employed in transforming satellite and aerial imagery into digital elevation models. Specific goals of this Phase I proposal include: 1) modifying and coding new assumptions into the DEM software, 2) testing the accuracy and reliability of the digital elevation code on new sub1, aerial imagery, and 3) designing a new GUI for use in the pre- processing phase of DEM building. PROPOSED COMMERCIAL APPLICATIONS: The commercial value of this specific research is best understood when viewed as part of a larger effort to produce an automated system for deriving population estimates of user defined areas based on current, remotely sensed data. Such a system will serve a wide range of commercial interests seeking ""up-to-the-minute"" counts and measures of population and housing change. n/a",Digital Elevation Models for Population Estimates,6443114,R43HD041774,"['altitude', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' environment', ' geographic site', ' human population distribution', ' mathematical model', ' population survey', ' urban area']",NICHD,"SENECIO SOFTWARE, INC.",R43,2002,99979,0.0592121821662246
"Perceptual Organization and Attention: Behavior & fMRI    DESCRIPTION (provided by applicant): Visual perception is selective, and visual attention is the mechanism by which salient or high-priority objects are prioritized for awareness and action. Recent work has shown that attentional selection often operates on perceptual objects and not simply on spatial locations. In a multi-object scene involving partial occlusion, image regions must be grouped into coherent object representations prior to attentional deployment. The visual system employs a set of heuristics that serve to constrain object recognition based on principles of perceptual organization. Despite their importance to human navigation and behavior, knowledge of these heuristics and the neural mechanisms that underlie this process remain poorly understood. The proposed project will examine the grouping principles that are critical to object-based attentional selection, and will enumerate the dominance relations among these principles when they are consistent with competing groupings within a scene. The project also explores the neural implementation of these processes to extend our knowledge of the constraints built into the object recognition and visual attention systems. The combination of behavioral and neuroimaging methods outlined in this application will result in a better understanding of the neural circuitry that is responsible for efficient, goal-directed object recognition.           n/a",Perceptual Organization and Attention: Behavior & fMRI,7112773,F31NS055664,"['artificial intelligence', 'attention', 'behavior', 'clinical research', 'cues', 'visual perception']",NINDS,JOHNS HOPKINS UNIVERSITY,F31,2006,37861,0.1485158903394359
"Understanding Routine Sequential Action DESCRIPTION (provided by applicant): A Mentored Research Scientist Development Award (K0l) is requested, to support the establishment of an interdisciplinary research program examining the cognitive mechanisms underlying routine sequential behavior. Routine, goal-oriented action on objects -- the kind of action involved in everyday tasks such as making a cup of coffee -- is fundamental to independent functioning in daily life. When the ability to perform such actions is impaired, as frequently seen in stroke, head injury and neurodegenerative disorders, the impact is typically devastating. Understanding the mechanisms underlying routine sequential behavior, including those involved in representing goals, sequencing actions, and selecting objects, thus represents an important public health objective. The training and research contained in the present proposal pursue this goal by drawing on three important developments in recent research: (1) the application of recurrent neural network models to routine sequential action, (2) detailed tracking of eye and hand movements during the performance of naturalistic tasks, and (3) the analysis of performance in disorders affecting routine sequential action, e.g., action disorganization syndrome (ADS). Recurrent neural networks provide a framework for understanding routine behavior that differs strongly from traditional, schema-based accounts, and which appears to overcome several of their basic problems. In the proposed work, a series of computer simulations will evaluate recurrent networks as models of sequential action on objects, with an initial focus on two theoretically important issues: how objects are selected to become targets of action, and how established procedural knowledge is extended to partially novel task circumstances. Concurrent behavioral experimentation will serve to test predictions of the modeling work, and to provide empirical constraints for the developing theory. Four specific studies are proposed, two using error analyses and chronometric techniques to test predictions about naturalistic task performance in normal subjects and patients with ADS, and two using eye- and hand-tracking techniques to test detailed predictions about object selection and behavior in partially novel settings, again involving both normal and apraxic patients. In support of these research activities, the proposal includes coursework, mentored training activities, and external laboratory rotations, designed to facilitate the acquisition of new skills relating both to computational modeling and empirical research. n/a",Understanding Routine Sequential Action,7120189,K01MH065241,"['body movement', 'body physical activity', 'clinical research', 'cognition', 'computer simulation', 'eye movements', 'human subject', 'immobilization of body part', 'neuromuscular disorder', 'sequential perception']",NIMH,UNIVERSITY OF PENNSYLVANIA,K01,2006,131820,0.13092805139098454
"Understanding Routine Sequential Action DESCRIPTION (provided by applicant): A Mentored Research Scientist Development Award (K0l) is requested, to support the establishment of an interdisciplinary research program examining the cognitive mechanisms underlying routine sequential behavior. Routine, goal-oriented action on objects -- the kind of action involved in everyday tasks such as making a cup of coffee -- is fundamental to independent functioning in daily life. When the ability to perform such actions is impaired, as frequently seen in stroke, head injury and neurodegenerative disorders, the impact is typically devastating. Understanding the mechanisms underlying routine sequential behavior, including those involved in representing goals, sequencing actions, and selecting objects, thus represents an important public health objective. The training and research contained in the present proposal pursue this goal by drawing on three important developments in recent research: (1) the application of recurrent neural network models to routine sequential action, (2) detailed tracking of eye and hand movements during the performance of naturalistic tasks, and (3) the analysis of performance in disorders affecting routine sequential action, e.g., action disorganization syndrome (ADS). Recurrent neural networks provide a framework for understanding routine behavior that differs strongly from traditional, schema-based accounts, and which appears to overcome several of their basic problems. In the proposed work, a series of computer simulations will evaluate recurrent networks as models of sequential action on objects, with an initial focus on two theoretically important issues: how objects are selected to become targets of action, and how established procedural knowledge is extended to partially novel task circumstances. Concurrent behavioral experimentation will serve to test predictions of the modeling work, and to provide empirical constraints for the developing theory. Four specific studies are proposed, two using error analyses and chronometric techniques to test predictions about naturalistic task performance in normal subjects and patients with ADS, and two using eye- and hand-tracking techniques to test detailed predictions about object selection and behavior in partially novel settings, again involving both normal and apraxic patients. In support of these research activities, the proposal includes coursework, mentored training activities, and external laboratory rotations, designed to facilitate the acquisition of new skills relating both to computational modeling and empirical research. n/a",Understanding Routine Sequential Action,6941360,K01MH065241,"['body movement', 'body physical activity', 'clinical research', 'cognition', 'computer simulation', 'eye movements', 'human subject', 'immobilization of body part', 'neuromuscular disorder', 'sequential perception']",NIMH,UNIVERSITY OF PENNSYLVANIA,K01,2005,131565,0.13092805139098454
"Understanding Routine Sequential Action DESCRIPTION (provided by applicant): A Mentored Research Scientist Development Award (K0l) is requested, to support the establishment of an interdisciplinary research program examining the cognitive mechanisms underlying routine sequential behavior. Routine, goal-oriented action on objects -- the kind of action involved in everyday tasks such as making a cup of coffee -- is fundamental to independent functioning in daily life. When the ability to perform such actions is impaired, as frequently seen in stroke, head injury and neurodegenerative disorders, the impact is typically devastating. Understanding the mechanisms underlying routine sequential behavior, including those involved in representing goals, sequencing actions, and selecting objects, thus represents an important public health objective. The training and research contained in the present proposal pursue this goal by drawing on three important developments in recent research: (1) the application of recurrent neural network models to routine sequential action, (2) detailed tracking of eye and hand movements during the performance of naturalistic tasks, and (3) the analysis of performance in disorders affecting routine sequential action, e.g., action disorganization syndrome (ADS). Recurrent neural networks provide a framework for understanding routine behavior that differs strongly from traditional, schema-based accounts, and which appears to overcome several of their basic problems. In the proposed work, a series of computer simulations will evaluate recurrent networks as models of sequential action on objects, with an initial focus on two theoretically important issues: how objects are selected to become targets of action, and how established procedural knowledge is extended to partially novel task circumstances. Concurrent behavioral experimentation will serve to test predictions of the modeling work, and to provide empirical constraints for the developing theory. Four specific studies are proposed, two using error analyses and chronometric techniques to test predictions about naturalistic task performance in normal subjects and patients with ADS, and two using eye- and hand-tracking techniques to test detailed predictions about object selection and behavior in partially novel settings, again involving both normal and apraxic patients. In support of these research activities, the proposal includes coursework, mentored training activities, and external laboratory rotations, designed to facilitate the acquisition of new skills relating both to computational modeling and empirical research. n/a",Understanding Routine Sequential Action,6797151,K01MH065241,"['body movement', 'body physical activity', 'clinical research', 'cognition', 'computer simulation', 'eye movements', 'human subject', 'immobilization of body part', 'neuromuscular disorder', 'sequential perception']",NIMH,UNIVERSITY OF PENNSYLVANIA,K01,2004,131317,0.13092805139098454
"Understanding Routine Sequential Action DESCRIPTION (provided by applicant): A Mentored Research Scientist Development Award (K0l) is requested, to support the establishment of an interdisciplinary research program examining the cognitive mechanisms underlying routine sequential behavior. Routine, goal-oriented action on objects -- the kind of action involved in everyday tasks such as making a cup of coffee -- is fundamental to independent functioning in daily life. When the ability to perform such actions is impaired, as frequently seen in stroke, head injury and neurodegenerative disorders, the impact is typically devastating. Understanding the mechanisms underlying routine sequential behavior, including those involved in representing goals, sequencing actions, and selecting objects, thus represents an important public health objective. The training and research contained in the present proposal pursue this goal by drawing on three important developments in recent research: (1) the application of recurrent neural network models to routine sequential action, (2) detailed tracking of eye and hand movements during the performance of naturalistic tasks, and (3) the analysis of performance in disorders affecting routine sequential action, e.g., action disorganization syndrome (ADS). Recurrent neural networks provide a framework for understanding routine behavior that differs strongly from traditional, schema-based accounts, and which appears to overcome several of their basic problems. In the proposed work, a series of computer simulations will evaluate recurrent networks as models of sequential action on objects, with an initial focus on two theoretically important issues: how objects are selected to become targets of action, and how established procedural knowledge is extended to partially novel task circumstances. Concurrent behavioral experimentation will serve to test predictions of the modeling work, and to provide empirical constraints for the developing theory. Four specific studies are proposed, two using error analyses and chronometric techniques to test predictions about naturalistic task performance in normal subjects and patients with ADS, and two using eye- and hand-tracking techniques to test detailed predictions about object selection and behavior in partially novel settings, again involving both normal and apraxic patients. In support of these research activities, the proposal includes coursework, mentored training activities, and external laboratory rotations, designed to facilitate the acquisition of new skills relating both to computational modeling and empirical research. n/a",Understanding Routine Sequential Action,6659105,K01MH065241,"['body movement', ' body physical activity', ' clinical research', ' cognition', ' computer simulation', ' eye movements', ' human subject', ' immobilization of body part', ' neuromuscular disorder', ' sequential perception']",NIMH,UNIVERSITY OF PENNSYLVANIA,K01,2003,138659,0.13092805139098454
"Understanding Routine Sequential Action DESCRIPTION (provided by applicant): A Mentored Research Scientist Development Award (K0l) is requested, to support the establishment of an interdisciplinary research program examining the cognitive mechanisms underlying routine sequential behavior. Routine, goal-oriented action on objects -- the kind of action involved in everyday tasks such as making a cup of coffee -- is fundamental to independent functioning in daily life. When the ability to perform such actions is impaired, as frequently seen in stroke, head injury and neurodegenerative disorders, the impact is typically devastating. Understanding the mechanisms underlying routine sequential behavior, including those involved in representing goals, sequencing actions, and selecting objects, thus represents an important public health objective. The training and research contained in the present proposal pursue this goal by drawing on three important developments in recent research: (1) the application of recurrent neural network models to routine sequential action, (2) detailed tracking of eye and hand movements during the performance of naturalistic tasks, and (3) the analysis of performance in disorders affecting routine sequential action, e.g., action disorganization syndrome (ADS). Recurrent neural networks provide a framework for understanding routine behavior that differs strongly from traditional, schema-based accounts, and which appears to overcome several of their basic problems. In the proposed work, a series of computer simulations will evaluate recurrent networks as models of sequential action on objects, with an initial focus on two theoretically important issues: how objects are selected to become targets of action, and how established procedural knowledge is extended to partially novel task circumstances. Concurrent behavioral experimentation will serve to test predictions of the modeling work, and to provide empirical constraints for the developing theory. Four specific studies are proposed, two using error analyses and chronometric techniques to test predictions about naturalistic task performance in normal subjects and patients with ADS, and two using eye- and hand-tracking techniques to test detailed predictions about object selection and behavior in partially novel settings, again involving both normal and apraxic patients. In support of these research activities, the proposal includes coursework, mentored training activities, and external laboratory rotations, designed to facilitate the acquisition of new skills relating both to computational modeling and empirical research. n/a",Understanding Routine Sequential Action,6455678,K01MH065241,"['body movement', ' body physical activity', ' clinical research', ' cognition', ' computer simulation', ' eye movements', ' human subject', ' immobilization of body part', ' neuromuscular disorder', ' sequential perception']",NIMH,UNIVERSITY OF PENNSYLVANIA,K01,2002,136827,0.13092805139098454
"Intelligent Imaging Robot for Structural Genomics DESCRIPTION (provided by applicant):    Knowledge of the 3-D structure of proteins is essential for understanding how they function and the designing of drugs to affect those functions. The Structural Genomics Initiative of the NIH aims to solve the 3-D structure of thousands of proteins a year by a major scale up of technology. X-ray crystallography, which requires high-quality protein crystals, is a significant means of deducing 3-D structure. Growing protein crystals is a process of trial and error and, in high-throughput protein crystallization, essential for the Structural Genomics Initiative to succeed, combinatorial methods are used to set up thousands of crystallization vessels in parallel and machine vision robots inspect each vessel for the presence of crystals and crystal-like objects. A bottleneck is the inability of current robots to distinguish between micro crystals and other small, uninteresting objects, necessitating human intervention to make the distinction. In this Phase I SBIR proposal the feasibility of a novel imaging method will be tested. This method appears capable of distinguishing crystalline objects from amorphous ones and protein crystals from uninteresting salt crystals. Once the feasibility is demonstrated, the new method can form the basis of a robot possessing intelligent machine vision. In Phase II a prototype of the robot will be built. There is demand for such a robot among high-throughput laboratories, pharmaceutical companies, contract X-ray crystallography companies and drug discovery firms. The robot also will play an important role in the success of the Structural Genomics Initiative and the discovery of new drugs. n/a",Intelligent Imaging Robot for Structural Genomics,6694894,R43GM069262,"['Raman spectrometry', ' X ray crystallography', ' artificial intelligence', ' crystallization', ' functional /structural genomics', ' method development', ' protein structure', ' robotics']",NIGMS,"JAN SCIENTIFIC, INC.",R43,2003,100000,0.059118664751014634
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8507287,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2013,240369,0.1530905593647276
"CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation Interacting with the physical environment and manipulating objects is an essential part of daily life. This ability is lost in upper-limb amputees as well as patients with spinal cord injury, stroke, ALS and other movement disorders. These people know what they want to do as well as how they would do it if their arms were functional. If such knowledge is decoded and sent to a prosthetic arm (or to the patient's own arm fitted with functional electric stimulators) the lost motor function could be restored. The decoding is unlikely to be perfect however the brain can adapt to an imperfect decoder using real-time feedback. Several groups including ours have recently demonstrated that at least in principle this can be achieved. However, as is often the case in science, the initial work has been done in idealized conditions and its applicability to real-world usage scenarios remains an open question. The goal of this project is to bring movement control brain-machine interfaces (BMIs) closer to helping the people who need them, and at the same time exploit the rich datasets we collect in order to advance our understanding of sensorimotor control and learning. This will be accomplished by creating hybrid BMIs which exploit information from multiple sources, combined with modern algorithms from machine learning and automatic control. RELEVANCE (See instructions): Being able to interact with the physical environment and manipulate objects is an essential part of daily life. Brain-machine interfaces are one way to restore this ability to patients who have lost it. The proposed project will bring brain-machine interfaces closer to helping patients in real-worid object manipulation tasks.  n/a",CRCNS: Hybrid non-invasive brain-machine interfaces for 3D object manipulation,8288148,R01NS073120,"['Address', 'Algorithms', 'Amputees', 'Behavior', 'Brain', 'Communication', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Devices', 'Dose', 'Electrodes', 'Electroencephalography', 'Epilepsy', 'Eye Movements', 'Feedback', 'Goals', 'Hand', 'Head Movements', 'Home environment', 'Hybrids', 'Instruction', 'Knowledge', 'Learning', 'Left', 'Life', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Methodology', 'Methods', 'Modeling', 'Motor', 'Motor Activity', 'Movement', 'Movement Disorders', 'Neck', 'Patients', 'Physical environment', 'Positioning Attribute', 'Prosthesis', 'Robot', 'Robotics', 'Scheme', 'Science', 'Shapes', 'Signal Transduction', 'Simulate', 'Source', 'Specific qualifier value', 'Spinal cord injury', 'Stroke', 'Testing', 'Text', 'Time', 'Upper Extremity', 'Work', 'arm', 'brain machine interface', 'design', 'grasp', 'instrument', 'interest', 'kinematics', 'visual feedback']",NINDS,UNIVERSITY OF WASHINGTON,R01,2012,250764,0.1530905593647276
"Understanding the circuit for topological object tracking DESCRIPTION    Abstract:    Understanding the circuit for topological object tracking (Science Area: Neuroscience) The problem I want to solve is how an object first arises in the brain. Light hitting the retina is caried by over a million axons of the optic nerve into primary visual cortex. These are the pixels that drive visual experience. But when we look around us, we don't see pixels. We see invariant objects in space--invariant in that we perceive the objects as unchanged despite severe changes in appearance as we move around them. How does the brain stitch together pixels into invariant, discrete objects in space? The time is ripe for a fresh attack on this problem due to a critical theoretical advance, and a host of experimental advances. I believe the essential reason why no one has solved the problem of invariant object perception until now is that no one has realized the answer could be very simple. A new mathematical theory explains how the representation of objects in the 3D visual world as surfaces enables a complete and fundamentally simple solution to the problem of object segmentation and tracking, i.e., labeling all the pixels belonging to a single object over space and time, regardless of object shape. The theory strongly suggests that a powerful """"topological engine"""" is churning away within very early stages of the visual cortex, to generate invariant labels for the different objects in the environment over space and time, and specifies the computations that must be performed in order to generate these invariant labels. Motivated by this new theory, and taking advantage of several key recent experimental advances in monkey and rodent vision research, I describe a set of experiments to: 1) identify the neural signature of the topological object label in early macaque visual cortical areas, 2) behaviorally test whether rodents also generate a surface representation, and if so, then 3) dissect the circuit by which this label is generated through two photon imaging an Understanding the brain is of huge medical importance as psychiatric and neurological diseases  directly affect the lives of a vast number of human beings. The brain is essentially an organ for  organizing information, thus the key to understanding the brain is to crack the neural code for  dynamic information organization. The proposal describes an approach to achieve this through  understanding how the brain organizes visual information into 3D objects.",Understanding the circuit for topological object tracking,9115714,DP1NS083063,"['Affect', 'Appearance', 'Area', 'Axon', 'Brain', 'Code', 'Environment', 'Human', 'Image', 'Label', 'Light', 'Macaca', 'Medical', 'Mental disorders', 'Monkeys', 'Neurosciences', 'Optic Nerve', 'Organ', 'Problem Solving', 'Retina', 'Rodent', 'Science', 'Specific qualifier value', 'Staging', 'Surface', 'Testing', 'Time', 'Vision research', 'Visual', 'Visual Cortex', 'abstracting', 'area striata', 'experience', 'information organization', 'mathematical theory', 'nervous system disorder', 'object perception', 'object shape', 'relating to nervous system', 'research study', 'theories', 'two-photon', 'visual information']",NINDS,CALIFORNIA INSTITUTE OF TECHNOLOGY,DP1,2016,820000,0.20649227189994582
"Understanding the circuit for topological object tracking DESCRIPTION    Abstract:    Understanding the circuit for topological object tracking (Science Area: Neuroscience) The problem I want to solve is how an object first arises in the brain. Light hitting the retina is caried by over a million axons of the optic nerve into primary visual cortex. These are the pixels that drive visual experience. But when we look around us, we don't see pixels. We see invariant objects in space--invariant in that we perceive the objects as unchanged despite severe changes in appearance as we move around them. How does the brain stitch together pixels into invariant, discrete objects in space? The time is ripe for a fresh attack on this problem due to a critical theoretical advance, and a host of experimental advances. I believe the essential reason why no one has solved the problem of invariant object perception until now is that no one has realized the answer could be very simple. A new mathematical theory explains how the representation of objects in the 3D visual world as surfaces enables a complete and fundamentally simple solution to the problem of object segmentation and tracking, i.e., labeling all the pixels belonging to a single object over space and time, regardless of object shape. The theory strongly suggests that a powerful """"topological engine"""" is churning away within very early stages of the visual cortex, to generate invariant labels for the different objects in the environment over space and time, and specifies the computations that must be performed in order to generate these invariant labels. Motivated by this new theory, and taking advantage of several key recent experimental advances in monkey and rodent vision research, I describe a set of experiments to: 1) identify the neural signature of the topological object label in early macaque visual cortical areas, 2) behaviorally test whether rodents also generate a surface representation, and if so, then 3) dissect the circuit by which this label is generated through two photon imaging an Understanding the brain is of huge medical importance as psychiatric and neurological diseases  directly affect the lives of a vast number of human beings. The brain is essentially an organ for  organizing information, thus the key to understanding the brain is to crack the neural code for  dynamic information organization. The proposal describes an approach to achieve this through  understanding how the brain organizes visual information into 3D objects.",Understanding the circuit for topological object tracking,8891497,DP1NS083063,"['Affect', 'Appearance', 'Area', 'Axon', 'Brain', 'Code', 'Environment', 'Human', 'Image', 'Label', 'Light', 'Macaca', 'Medical', 'Mental disorders', 'Monkeys', 'Neurosciences', 'Optic Nerve', 'Organ', 'Problem Solving', 'Retina', 'Rodent', 'Science', 'Solutions', 'Specific qualifier value', 'Staging', 'Surface', 'Testing', 'Time', 'Vision research', 'Visual', 'Visual Cortex', 'abstracting', 'area striata', 'experience', 'information organization', 'mathematical theory', 'nervous system disorder', 'object perception', 'object shape', 'relating to nervous system', 'research study', 'theories', 'two-photon', 'visual information']",NINDS,CALIFORNIA INSTITUTE OF TECHNOLOGY,DP1,2015,820000,0.20649227189994582
"Understanding the circuit for topological object tracking DESCRIPTION  Abstract:  Understanding the circuit for topological object tracking (Science Area: Neuroscience) The problem I want to solve is how an object first arises in the brain. Light hitting the retina is caried by over a million axons of the optic nerve into primary visual cortex. These are the pixels that drive visual experience. But when we look around us, we don't see pixels. We see invariant objects in space--invariant in that we perceive the objects as unchanged despite severe changes in appearance as we move around them. How does the brain stitch together pixels into invariant, discrete objects in space? The time is ripe for a fresh attack on this problem due to a critical theoretical advance, and a host of experimental advances. I believe the essential reason why no one has solved the problem of invariant object perception until now is that no one has realized the answer could be very simple. A new mathematical theory explains how the representation of objects in the 3D visual world as surfaces enables a complete and fundamentally simple solution to the problem of object segmentation and tracking, i.e., labeling all the pixels belonging to a single object over space and time, regardless of object shape. The theory strongly suggests that a powerful """"topological engine"""" is churning away within very early stages of the visual cortex, to generate invariant labels for the different objects in the environment over space and time, and specifies the computations that must be performed in order to generate these invariant labels. Motivated by this new theory, and taking advantage of several key recent experimental advances in monkey and rodent vision research, I describe a set of experiments to: 1) identify the neural signature of the topological object label in early macaque visual cortical areas, 2) behaviorally test whether rodents also generate a surface representation, and if so, then 3) dissect the circuit by which this label is generated through two-photon  imaging and genetic techniques in rodent visual cortex. These experiments, if successful,  will solve one of the most fundamental mysteries of vision: how the brain creates the percept of  objects. And this in turn may shed light on the general question of how the brain dynamically  organizes information, such that not only can pixels be organized into objects, but these objects  can then be organized into things as complex as memories and thoughts. Understanding the brain is of huge medical importance as psychiatric and neurological diseases  directly affect the lives of a vast number of human beings. The brain is essentially an organ for  organizing information, thus the key to understanding the brain is to crack the neural code for  dynamic information organization. The proposal describes an approach to achieve this through  understanding how the brain organizes visual information into 3D objects.",Understanding the circuit for topological object tracking,8703833,DP1NS083063,"['Affect', 'Appearance', 'Area', 'Axon', 'Brain', 'Code', 'Complex', 'Environment', 'Genetic Techniques', 'Human', 'Imaging Techniques', 'Label', 'Light', 'Macaca', 'Medical', 'Memory', 'Mental disorders', 'Monkeys', 'Neurosciences', 'Optic Nerve', 'Organ', 'Problem Solving', 'Retina', 'Rodent', 'Science', 'Solutions', 'Specific qualifier value', 'Staging', 'Surface', 'Testing', 'Thinking', 'Time', 'Vision', 'Vision research', 'Visual', 'Visual Cortex', 'abstracting', 'area striata', 'experience', 'information organization', 'mathematical theory', 'nervous system disorder', 'object perception', 'object shape', 'relating to nervous system', 'research study', 'theories', 'two-photon', 'visual information']",NINDS,CALIFORNIA INSTITUTE OF TECHNOLOGY,DP1,2014,811800,0.2141153914128522
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8479372,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,474880,0.07784397941398406
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8274831,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,503268,0.07784397941398406
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8102722,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,458901,0.07784397941398406
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,7761085,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2010,463608,0.07784397941398406
"Characterizing and Modeling Infants' Self-Generated Object Views: Implications for Object Recognition and Language Learning PROJECT SUMMARY/ABSTRACT Human visual object recognition is foundational to many achievements—from object name learning to tool use to real world problem solving. Understanding the developmental processes that underlie visual object recognition is of critical importance because the individual differences that characterize early visual object recognition have clinical, educational, and societal implications. For instance, toddlers with poor visual object recognition skills are more likely to have below-average vocabulary sizes. Toddlers with smaller vocabularies have a greater likelihood of developing language impairments and are more likely to lag in pre-literacy and literacy skills. Deficits in visual object recognition and word learning have also been exhibited by individuals with Autism Spectrum Disorders (ADSs). The overarching goal of the proposed project is to better understand the sensory-motor mechanisms that support visual object recognition. Considerable evidence suggests that active object manipulation relates to better visual object recognition, however little is known about the mechanisms through which object manipulation connects to visual object processing during development. The proposed research tests the hypothesis that one major route through which object manipulation matters is that it generates many different views of the same object, and that the variation within multiple visual instances of the same object facilitates visual object recognition by building more generalizable representations for recognizing unseen instances. This hypothesis is tested by (1) characterizing the properties of object information generated by infants during free play and by (2) evaluating the information in those generated visual streams by feeding them to convolutional neural networks (CNNs) – the first computational models of vision capable of human-like visual recognition. Two additional lines of research motivate the approach. First is evidence showing infants learn from statistical regularities in visual inputs presented briefly in a laboratory setting. Second is research using head-mounted cameras suggesting that object views generated by infant manipulation have unique properties, including views dominated by a single object. What we do not yet know are the visual statistics of the views infants generate in everyday toy play or their value for a statistical learner such as CNNs. The proposed research will address these gaps in the literature by characterizing the visual object inputs infants generate and how these inputs may facilitate visual object recognition. The proposed research will also determine how differences in visual inputs may be linked with individual differences in infant object name learning. This research will lead to a deeper understanding of the early development of visual object recognition, and may also provide a crucial missing link in our understanding of the developmental trajectory of other cognitive functions, including object name learning. Moreover, the knowledge to be gained from the proposed research has the potential to inform (1) individual differences in learning, (2) strategies for identifying learning delays, and (3) construction of interventions to remediate learning delays. PROJECT NARRATIVE The proposed research aims to characterize the nature of infants' early visual experiences of objects and their relation to object manipulation, language abilities, and computational models of object recognition. The period of development to be studied – 18 to 24 months – is a period in which delays in visual object recognition and in vocabulary learning have been connected to future development of language impairments and diagnoses of Autism Spectrum Disorders (ASDs). The proposed research is highly relevant to public health as it will elucidate sources of individual differences in early object recognition and word learning, laying the foundation for aiding diagnosis of early language delay and ASDs, as well as the development of future object recognition and vocabulary/language intervention programs.",Characterizing and Modeling Infants' Self-Generated Object Views: Implications for Object Recognition and Language Learning,9395459,F32HD093280,"['Achievement', 'Address', 'Biological Neural Networks', 'Characteristics', 'Clinical', 'Computer Simulation', 'Data', 'Development', 'Developmental Process', 'Diagnosis', 'Early Diagnosis', 'Exhibits', 'Foundations', 'Future', 'Gap Junctions', 'Goals', 'Head', 'Human', 'Individual', 'Individual Differences', 'Infant', 'Intervention', 'Knowledge', 'Laboratories', 'Language', 'Language Delays', 'Language Development', 'Learning', 'Link', 'Literature', 'Machine Learning', 'Modeling', 'Motor', 'Names', 'Nature', 'Parents', 'Persons', 'Play', 'Problem Solving', 'Property', 'Public Health', 'Recording of previous events', 'Research', 'Role', 'Route', 'Sampling', 'Sensory', 'Shapes', 'Source', 'Specific qualifier value', 'Stream', 'Testing', 'Toddler', 'Toy', 'Training', 'Variant', 'Vision', 'Visual', 'Vocabulary', 'autism spectrum disorder', 'base', 'cognitive function', 'developmental disease', 'experience', 'feeding', 'intervention program', 'language impairment', 'literacy', 'novel', 'object recognition', 'skills', 'statistics', 'tool', 'vision development', 'visual object processing', 'word learning']",NICHD,INDIANA UNIVERSITY BLOOMINGTON,F32,2017,57066,0.1735790087791555
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9932509,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual environment', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2020,615717,0.1496950347273124
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9504668,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2018,727051,0.1496950347273124
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9277595,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2017,825202,0.1496950347273124
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9177620,R01NS095251,"['Accounting', 'Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Investments', 'Learning', 'Left', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Records Controls', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'relating to nervous system', 'research study', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2016,891206,0.1496950347273124
"Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation Spinal cord injury causes both paralysis and loss of sensation from the limbs. The past 15 years have seen remarkable advances in “Brain Machine Interfaces” (BMIs) that allow paralyzed persons to move anthropomorphic limbs using signals recorded directly from their brains. However, these movements remain slow, clumsy, and effortful, looking remarkably like those of individuals who have lost sensation from their arms due to peripheral neuropathy. Brain-controlled prosthetic limbs are unlikely to achieve high levels of performance in the absence of artificial sensory feedback. Early attempts at restoring somatosensation used intracortical microstimulation (ICMS) to activate somatosensory cortex (s1), requiring animals to learn largely arbitrary patterns of stimulation to represent two or three virtual objects or to navigate in two-dimensional space. While an important beginning, this approach seems unlikely to scale to the broad range of limb movements and interactions with objects that we experience in daily life.  To move the field past this hurdle, we propose to replace both touch and proprioception by using multi- electrode ICMS to produce naturalistic patterns of neuronal activity in S1 of monkeys. In Aim 1, we will develop model-optimized mappings between limb state (pressure on the fingertip, or motion of the limb) and the patterns of ICMS required to evoke S1 activation that mimics that of natural inputs. These maps will account for both the dynamics of neural responses and the biophysics of ICMS. We anticipate that this biomimetic approach will evoke intuitive sensations that require little or no training to interpret. We will validate the maps by comparing natural and ICMS-evoked S1 activity using novel hardware that allows for concurrent ICMS and neural recording. In Aim 2, we will test the ability of monkeys to recognize objects using artificial touch. Having learned to identify real objects by touch, animals will explore virtual objects with an avatar that shadows their own hand movements, receiving artificial touch sensations when the avatar contacts objects. We will test their initial performance on the virtual stereognosis task without learning, as well as their improvements in performance over time. Aim 3 will be similar, but will focus on proprioception. We will train monkeys to report the direction of brief force bumps applied to their hand. After training, we will replace the actual bumps with virtual bumps created by patterned ICMS, again asking the monkeys to report their perceived sense of the direction and magnitude of the perturbation. Finally, in Aim 4, we will temporarily paralyze the monkey's arm, thereby removing both touch and proprioception, mimicking the essential characteristics of a paralyzed patient. The avatar will be controlled based on recordings from motor cortex and guided by artificial somatosensation. The monkey will reach to a set of virtual objects, find one with a particular shape, grasp it, and move it to a new location. If we can demonstrate that this model-optimized, biomimetic feedback is informative and easy to learn, it should form the basis for robust, scalable, somatosensory feedback for BMIs. PROJECT NARRATIVE Spinal cord injury causes both paralysis and loss of feeling from the limbs (somatosensation); brain machine interfaces (BMIs), which record signals directly from the brain, can be used to control prosthetic devices, computers, or environmental controls. However, BMIs currently do not restore somatosensation, a critical component of normal limb movement. We propose to develop a new type of brain interface that will mimic the somatosensory brain activity generated during movement and provide natural and informative artificial sensation for people with paralysis or limb amputation.",Biomimetic Somatosensory Feedback through Intracorticalmicrostimulation,9707897,R01NS095251,"['Achievement', 'Activities of Daily Living', 'Animals', 'Area', 'Behavioral Paradigm', 'Biomimetics', 'Biophysics', 'Brachial plexus structure', 'Brain', 'Characteristics', 'Clinical', 'Computers', 'Cutaneous', 'Electrodes', 'Esthesia', 'Feedback', 'Feeling', 'Hand', 'Individual', 'Intuition', 'Investments', 'Learning', 'Life', 'Limb Prosthesis', 'Limb structure', 'Location', 'Machine Learning', 'Maps', 'Measurement', 'Modeling', 'Monkeys', 'Motion', 'Motor', 'Motor Cortex', 'Movement', 'Muscle', 'Nerve Block', 'Neurons', 'Numbness', 'Paralysed', 'Patients', 'Pattern', 'Performance', 'Peripheral', 'Peripheral Nervous System Diseases', 'Persons', 'Problem Solving', 'Property', 'Proprioception', 'Prosthesis', 'Quadriplegia', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Skin', 'Somatosensory Cortex', 'Speed', 'Spinal cord injury', 'Stereognosis', 'Stimulus', 'System', 'Tactile', 'Techniques', 'Testing', 'Time', 'Touch sensation', 'Training', 'Update', 'Vision', 'Work', 'arm', 'base', 'biophysical model', 'brain machine interface', 'experience', 'experimental study', 'grasp', 'improved', 'infancy', 'limb amputation', 'limb movement', 'microstimulation', 'mind control', 'neural patterning', 'neuronal patterning', 'neuroprosthesis', 'novel', 'pressure', 'prevent', 'prosthesis control', 'relating to nervous system', 'response', 'sensory feedback', 'somatosensory', 'spatiotemporal', 'two-dimensional', 'virtual', 'virtual reality', 'visual feedback']",NINDS,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2019,641907,0.1496950347273124
"BIOSTATISTICS FOR CONNECTOMES     DESCRIPTION (provided by applicant): This proposal aims to develop object oriented data analysis (OODA) methods that are highly novel and complementary to existing methods of analysis of human brain scan connectomes, defined as graphs representing brain anatomical or functional connectivity. OODA is an emerging field of statistics where classical statistical approaches (e.g., hypothesis testing, regression, estimation, confidence intervals) are applied to data objects such as graphs or functions. By analyzing data objects directly we can avoid loss of information that necessarily occurs when data objects are transformed into numerical summary statistics. The conceptual leap in this proposal is that OODA statistical methods will be developed and applied directly to connectomes without needing to transform them into summary features which incur loss of information. By providing statistical tools that analyze sets of connectomes without loss of information, new insights into neurology and medicine may be achieved. The Specific Aims of this proposal are: (1) Develop OODA methods and software for analyzing human connectome data. More specifically, a mathematical framework for hypothesis testing, regression and Principal Components Analysis will be developed to model and analyze set of connectomes. The proposed methodology will allow to compare groups of connectomes (e.g., Is the brain structure/function different in cases versus controls?), to perform regression for modeling connectomes as a function of subject covariates such as age, gender, disease, or longitudinally (e.g., How does the brain structure/function change over time and does it change differently in males and females?), and to measure sources of structural or functional variation across populations of connectomes (e.g., What is the natural variability of brain structure/function within the population?); (2) Validate the tools developed in Specific Aim 1 using existing connectome datasets generated by our co-investigators to answer clinical questions relevant to their research objectives. The validation of the methodology to be developed in connectome data from will contribute to assess the biological significance of the methods proposed to be developed; and (3) Compare the performance of connectome OODA methods developed in Specific Aim 1 as complementary to existing methods of analysis of human brain scan connectomes by analyzing the same data used in Specific Aim 2 using graph-theoretical measurements.           Developing statistical methods for hypothesis testing, regression, and principal component analysis of sets of connectomes without loss of information, new insights into neurology and medicine may be achieved. We propose to develop statistical methods within the framework of object oriented data analysis (OODA) which do not require a reduction of the connectome to features, and therefore avoid loss of information. This proposal will help bridge the translation of connectome to clinical applications.                ",BIOSTATISTICS FOR CONNECTOMES,8517207,R21MH098223,"['Age', 'Algorithms', 'Area', 'Biological', 'Biometry', 'Brain', 'Brain region', 'Brain scan', 'Classification', 'Clinical', 'Clinical Medicine', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electroencephalography', 'Female', 'Functional Magnetic Resonance Imaging', 'Gender', 'Grant', 'Graph', 'Human', 'Image', 'Letters', 'Linear Models', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Neurology', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Process', 'Research', 'Research Personnel', 'Source', 'Staging', 'Statistical Methods', 'Structure', 'Technology', 'Testing', 'Time', 'Translating', 'Translations', 'Trees', 'Validation', 'Variant', 'Weight', 'Work', 'clinical application', 'insight', 'interest', 'male', 'novel', 'statistics', 'success', 'tool']",NIMH,WASHINGTON UNIVERSITY,R21,2013,182400,0.17192312288586586
"BIOSTATISTICS FOR CONNECTOMES     DESCRIPTION (provided by applicant): This proposal aims to develop object oriented data analysis (OODA) methods that are highly novel and complementary to existing methods of analysis of human brain scan connectomes, defined as graphs representing brain anatomical or functional connectivity. OODA is an emerging field of statistics where classical statistical approaches (e.g., hypothesis testing, regression, estimation, confidence intervals) are applied to data objects such as graphs or functions. By analyzing data objects directly we can avoid loss of information that necessarily occurs when data objects are transformed into numerical summary statistics. The conceptual leap in this proposal is that OODA statistical methods will be developed and applied directly to connectomes without needing to transform them into summary features which incur loss of information. By providing statistical tools that analyze sets of connectomes without loss of information, new insights into neurology and medicine may be achieved. The Specific Aims of this proposal are: (1) Develop OODA methods and software for analyzing human connectome data. More specifically, a mathematical framework for hypothesis testing, regression and Principal Components Analysis will be developed to model and analyze set of connectomes. The proposed methodology will allow to compare groups of connectomes (e.g., Is the brain structure/function different in cases versus controls?), to perform regression for modeling connectomes as a function of subject covariates such as age, gender, disease, or longitudinally (e.g., How does the brain structure/function change over time and does it change differently in males and females?), and to measure sources of structural or functional variation across populations of connectomes (e.g., What is the natural variability of brain structure/function within the population?); (2) Validate the tools developed in Specific Aim 1 using existing connectome datasets generated by our co-investigators to answer clinical questions relevant to their research objectives. The validation of the methodology to be developed in connectome data from will contribute to assess the biological significance of the methods proposed to be developed; and (3) Compare the performance of connectome OODA methods developed in Specific Aim 1 as complementary to existing methods of analysis of human brain scan connectomes by analyzing the same data used in Specific Aim 2 using graph-theoretical measurements.         PUBLIC HEALTH RELEVANCE: Developing statistical methods for hypothesis testing, regression, and principal component analysis of sets of connectomes without loss of information, new insights into neurology and medicine may be achieved. We propose to develop statistical methods within the framework of object oriented data analysis (OODA) which do not require a reduction of the connectome to features, and therefore avoid loss of information. This proposal will help bridge the translation of connectome to clinical applications.                  Developing statistical methods for hypothesis testing, regression, and principal component analysis of sets of connectomes without loss of information, new insights into neurology and medicine may be achieved. We propose to develop statistical methods within the framework of object oriented data analysis (OODA) which do not require a reduction of the connectome to features, and therefore avoid loss of information. This proposal will help bridge the translation of connectome to clinical applications.                ",BIOSTATISTICS FOR CONNECTOMES,8359149,R21MH098223,"['Age', 'Algorithms', 'Area', 'Biological', 'Biometry', 'Brain', 'Brain region', 'Brain scan', 'Classification', 'Clinical', 'Clinical Medicine', 'Computer software', 'Confidence Intervals', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electroencephalography', 'Female', 'Functional Magnetic Resonance Imaging', 'Gender', 'Grant', 'Graph', 'Human', 'Image', 'Letters', 'Linear Models', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Neurology', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Process', 'Research', 'Research Personnel', 'Source', 'Staging', 'Statistical Methods', 'Structure', 'Technology', 'Testing', 'Time', 'Translating', 'Translations', 'Trees', 'Validation', 'Variant', 'Weight', 'Work', 'clinical application', 'insight', 'interest', 'male', 'novel', 'statistics', 'success', 'tool']",NIMH,WASHINGTON UNIVERSITY,R21,2012,228000,0.15524226316460166
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9478117,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Breast Cancer Risk Factor', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2018,897471,0.06934196696576309
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9266344,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2017,229691,0.06934196696576309
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,9056632,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,73173,0.06934196696576309
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9270103,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,56107,0.06934196696576309
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8935748,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2015,250834,0.06934196696576309
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8774800,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Clinical Trials', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2014,1329000,0.06934196696576309
"Closing the loop on markerless object tracking Abstract/Summary Tracking the movements of objects and parts of objects - referred to as pose estimation - is critical for understanding the mechanisms underlying complex behavior. Characterizing dynamic behaviors of animals (and other systems) is central to many disciplines, including computer science, physics, ethology, kinesiology, and sports medicine. Here we focus on neuroscience, where linking brain activity to associated dynamic behaviors is critical for both understanding normal function as well as effects of injury, disease, or degeneration. Invasive methods for measuring behavior are highly accurate, but require placement of sensors that may themselves interact with behavior and which may be susceptible to deterioration or infection. Video provides a non-invasive approach to characterizing behavior over time. Extracting behavior from video streams has, historically, been a slow and laborious process. Recent work in machine learning and artificial neural networks (ANNs), though, has revolutionized this process, making the analysis of complex video far easier and more accurate. While these systems are highly flexible, they were not designed for real time use, meaning that large video files must first be stored to disk for subsequent analysis. This poses two problems that this proposal will attempt to address. First, there is significant cost and management challenges associated with storage of large video stores, forming a practical barrier for adoption of this important technology for characterizing behavior. Second, estimates related to behavioral state are not available in real time so they cannot be used to control the experiment. We will develop a research methodology for “closing the loop”, by taking the networks trained by an existing and highly successful markerless object tracking system (DeepLabCut) and optimizing them for real time inference. After the system is functional, verified, and benchmarked, it will be shared with the community through open source repositories. Project Narrative Understanding the neural basis underlying complex behavior requires careful analysis of the dynamics of moving objects. Recent advances in computer vision has greatly facilitated our ability to track objects from video, but these tools are currently limited to offline analysis. Here we propose to build a system that addresses this problem by “closing the loop” using real time inference to be freely shared with the public to enhance ongoing research across the neuroscience spectrum.",Closing the loop on markerless object tracking,10047656,R03MH123990,"['Address', 'Adoption', 'Animal Behavior', 'Architecture', 'Behavior', 'Behavioral', 'Benchmarking', 'Brain', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Data', 'Deterioration', 'Development', 'Discipline', 'Disease', 'Ensure', 'Ethology', 'Eye', 'Eye Movements', 'Freezing', 'Goals', 'Guidelines', 'Hand', 'Individual', 'Infection', 'Injury', 'Joints', 'Kinesiology', 'Label', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Modification', 'Monkeys', 'Movement', 'Neurosciences', 'Output', 'Performance', 'Physics', 'Process', 'Pupil', 'Research', 'Research Methodology', 'Research Personnel', 'Running', 'Sports Medicine', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Update', 'Work', 'artificial neural network', 'base', 'computer science', 'cost', 'deep learning', 'design', 'experimental study', 'flexibility', 'gaze', 'haptics', 'open source', 'relating to nervous system', 'repository', 'sensor', 'time use', 'tool', 'virtual']",NIMH,BROWN UNIVERSITY,R03,2020,162500,0.21331340671240717
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,10241562,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Visualization', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2020,2500,0.13548238270818455
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9761481,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2019,873369,0.13548238270818455
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9622047,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Biological Neural Networks', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2018,1057846,0.13548238270818455
