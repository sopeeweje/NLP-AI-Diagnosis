text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this SBIR project, we present EyeMark, a set of advanced image analysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we will develop tools for computation of microaneurysm (MA) ap- pearance and disappearance rates (jointly known as turnover rates) for use as a bi- omarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high positive influ- ence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a MA turnover computation prototype tool that ro- bustly registers longitudinal images (even with multiple lesion changes) and effectively detects DR lesions (lesion level AUROC>=0.95). The tool provides graceful degradation to confounding image factors by reporting MA turnover as a range, thereby capturing the inherent confidence in MA detection. By the end of Phase IIB we will develop a market ready, clinically validated end-to-end desktop software for robust, automated longitudinal lesion analysis and characterization that can work on the cloud to produce results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,9735477,R44TR000377,"['Adult', 'Age', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Biometry', 'Blindness', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Color', 'Computer Vision Systems', 'Computer software', 'Consumption', 'County', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Digital Imaging and Communications in Medicine', 'Early identification', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Joints', 'Lesion', 'Los Angeles', 'Machine Learning', 'Measures', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Patients', 'Pattern Recognition', 'Pear', 'Performance', 'Phase', 'Picture Archiving and Communication System', 'Process', 'Protocols documentation', 'ROC Curve', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Retrieval', 'Risk', 'Sampling', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'application programming interface', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'computerized', 'computerized tools', 'convolutional neural network', 'deep neural network', 'design', 'diabetic patient', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'high throughput analysis', 'image registration', 'imaging biomarker', 'improved', 'interest', 'longitudinal analysis', 'macula', 'medical schools', 'novel marker', 'novel therapeutics', 'prevent', 'programs', 'prototype', 'response', 'retinal imaging', 'screening', 'screening program', 'serial imaging', 'success', 'tool', 'usability', 'validation studies']",NCATS,"EYENUK, INC.",R44,2019,750000,0.06338358126151189
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this SBIR project, we present EyeMark, a set of advanced image analysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we will develop tools for computation of microaneurysm (MA) ap- pearance and disappearance rates (jointly known as turnover rates) for use as a bi- omarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high positive influ- ence on various aspects of DR care, including screening, monitoring progression, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a MA turnover computation prototype tool that ro- bustly registers longitudinal images (even with multiple lesion changes) and effectively detects DR lesions (lesion level AUROC>=0.95). The tool provides graceful degradation to confounding image factors by reporting MA turnover as a range, thereby capturing the inherent confidence in MA detection. By the end of Phase IIB we will develop a market ready, clinically validated end-to-end desktop software for robust, automated longitudinal lesion analysis and characterization that can work on the cloud to produce results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,9622980,R44TR000377,"['Adult', 'Age', 'Appearance', 'Area', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Biometry', 'Blindness', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Color', 'Communication', 'Computer Vision Systems', 'Computer software', 'County', 'Data', 'Data Set', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Early identification', 'Effectiveness', 'Electronic Health Record', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Joints', 'Lesion', 'Los Angeles', 'Machine Learning', 'Measures', 'Medicine', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Patients', 'Pattern Recognition', 'Pear', 'Performance', 'Phase', 'Picture Archiving and Communication System', 'Process', 'Protocols documentation', 'ROC Curve', 'Reporting', 'Research', 'Retinal', 'Retinal Diseases', 'Retrieval', 'Risk', 'Sampling', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'application programming interface', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'computerized', 'computerized tools', 'deep neural network', 'design', 'diabetic patient', 'digital imaging', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'high throughput analysis', 'image registration', 'improved', 'interest', 'longitudinal analysis', 'macula', 'medical schools', 'novel marker', 'novel therapeutics', 'prevent', 'programs', 'prototype', 'response', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability', 'validation studies']",NCATS,"EYENUK, INC.",R44,2018,750000,0.06338358126151189
"Automated image-based biomarker computation tools for diabetic retinopathy Abstract  In this project, we present EyeMark, a system with advanced longitudinal image anal- ysis tools for automated computation of biomarkers for diabetic retinopathy (DR) using retinal fundus images. Specifically, we have developed tools for computation of microan- eurysm (MA) appearance and disappearance rates (jointly known as turnover rates) for use as a biomarker in quantifying DR progression risk along with longitudinal analysis of other DR lesions. The availability of a reliable image-based biomarker will have high pos- itive influence on various aspects of DR care, including screening, monitoring progres- sion, drug discovery and clinical research.  Measuring MA turnover and longitudinal analysis of DR lesions involves two labor in- tensive steps: careful alignment of current and baseline images, and marking of individual lesions. This process is very time consuming and prone to error, if done entirely by human graders. The primary goal of this project is to overcome these limitations by automating both the steps involved in longitudinal analysis: accurate image registration, and lesion identification.  We have designed and developed a prototype tool that robustly registers longitudinal images (even with multiple lesion changes) and effectively detects and localizes DR le- sions. This fully automated tool can work on the cloud to produces results in near constant time (for large datasets), and also provide intuitive visualization tools for clinicians to more effectively monitor DR progression. This commercialization readiness pilot (CRP) project is intended to develop a regulatory strategy and a market access plan for EyeMark to enable its introduction in the US market and foster commercial success. Narrative The proposed tool, EyeMark, will greatly enhance the clinical care available to diabetic retinopathy (DR) patients by providing an automated tool for computation of an image- based, reliable, DR biomarker in a non-invasive manner. This will enable identification of patients who are at higher risk to progress to severe retinopathy, thus helping prevent vision loss in such patients by timely intervention. Early identification is especially important in face of long backlog of diabetic patients waiting for an eye examination, and the fact that 90% of vision loss can be saved by early identification. The availability of an effective biomarker will also positively influence the drug discovery process by facilitating early and reliable determination of biological efficacy of potential new therapies.",Automated image-based biomarker computation tools for diabetic retinopathy,10082344,SB1TR000377,"['Adult', 'Age', 'Appearance', 'Biological', 'Biological Markers', 'Biometry', 'Blindness', 'Caring', 'Clinical', 'Clinical Research', 'Code', 'Color', 'Communication', 'Computer Vision Systems', 'Consumption', 'Contracts', 'County', 'Detection', 'Devices', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Early identification', 'Environment', 'Evaluation', 'Exudate', 'Eye', 'Face', 'Faculty', 'Feedback', 'Fostering', 'Funding', 'Fundus', 'Goals', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Services', 'Hemorrhage', 'Human', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Institutes', 'Intervention', 'Intuition', 'Legal', 'Lesion', 'Los Angeles', 'Machine Learning', 'Market Research', 'Marketing', 'Measures', 'Microaneurysm', 'Monitor', 'Network-based', 'Ophthalmic examination and evaluation', 'Ophthalmology', 'Optometry', 'Participant', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Price', 'Process', 'Prothrombin', 'Readiness', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Sales', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Surveys', 'System', 'Techniques', 'Testing', 'Time', 'Treatment Effectiveness', 'Uncertainty', 'Validation', 'Visualization software', 'Work', 'algorithm development', 'base', 'bioimaging', 'care providers', 'clinical care', 'cloud based', 'commercialization', 'computerized', 'computerized tools', 'convolutional neural network', 'design', 'diabetic patient', 'drug discovery', 'experience', 'fundus imaging', 'health economics', 'high risk', 'high throughput analysis', 'image registration', 'imaging biomarker', 'interest', 'large datasets', 'longitudinal analysis', 'medical schools', 'novel marker', 'novel therapeutics', 'payment', 'prevent', 'programs', 'prototype', 'retinal imaging', 'screening', 'serial imaging', 'sound', 'success', 'tool', 'usability']",NCATS,"EYENUK, INC.",SB1,2020,300000,0.01904019599269834
"NEURAL CONTROL OF THE LARYNX This proposal seeks to better understand the central nervous system control (CNS) of the larynx in voice production.  Because certain important analysis techniques cannot be applied to humans, the study of model systems is required.  Study of two such model systems is proposed.  First, single-units will be recorded in CNS structures in cats instrumentally conditioned to vocalize.  Recordings are proposed for two CNS targets:  1) regions in the basal ganglia; and 2) ventrolateral thalamus.  These are structures at mid-levels of the proposed CNS control system.  They have been implicated in human voice production by clinical studies of brain lesions, and in animal voice control by lesion and electrical stimulation studies, but data concerning how they are involved, are lacking.  A second model proposed for study is a computational model of CNS laryngeal control.  The model is a hybrid consisting of two parts.  The most peripheral portion is a mathematical model of laryngeal function, based on biomechanical principles, whose study is of interest in its own right.  The representations of muscles in this mathematical larynx are, in turn, controlled by a trainable artificial neural network model of the CNS laryngeal control pathways.  A goal of the proposal is to constrain the network model as much as possible by known anatomy, physiology, and vocal behavior so that, after training, its function comes to match the real laryngeal control system.  Once it has been developed, the model can be subjected to various manipulations, such as the equivalent of CNS lesions, and the effects on voice production by the model studied.  The combined study of these two model systems is relevant to several health issues in communication disorders.  The data from the mammalian system will clarify the functional role of some mid-level CNS structures in normal voice control.  In addition, the data are needed to aid the process of model development.  Successful development of the computational model, in turn, provides a powerful means for studying normal and abnormal mechanisms underlying voice production.  It also may prove important in control of laryngeal prostheses, and in reducing animal experimentation.  n/a",NEURAL CONTROL OF THE LARYNX,2126569,R01DC001535,"['artificial intelligence', ' basal ganglia', ' biological models', ' biomechanics', ' brain regulatory center', ' cartilage', ' cats', ' computational neuroscience', ' electromyography', ' histology', ' larynx', ' larynx muscle', ' ligaments', ' model design /development', ' morphology', ' motor neurons', ' muscle contraction', ' muscle tension', ' neuromuscular system', ' operant conditionings', ' psychoacoustics', ' respiration regulatory center', ' single cell analysis', ' stereotaxic techniques', ' subthalamus', ' vocalization']",NIDCD,FATHER FLANAGAN'S BOYS' HOME,R01,1994,141740,0.0324341872597846
"NEURAL CONTROL OF THE LARYNX This proposal seeks to better understand the central nervous system control (CNS) of the larynx in voice production.  Because certain important analysis techniques cannot be applied to humans, the study of model systems is required.  Study of two such model systems is proposed.  First, single-units will be recorded in CNS structures in cats instrumentally conditioned to vocalize.  Recordings are proposed for two CNS targets:  1) regions in the basal ganglia; and 2) ventrolateral thalamus.  These are structures at mid-levels of the proposed CNS control system.  They have been implicated in human voice production by clinical studies of brain lesions, and in animal voice control by lesion and electrical stimulation studies, but data concerning how they are involved, are lacking.  A second model proposed for study is a computational model of CNS laryngeal control.  The model is a hybrid consisting of two parts.  The most peripheral portion is a mathematical model of laryngeal function, based on biomechanical principles, whose study is of interest in its own right.  The representations of muscles in this mathematical larynx are, in turn, controlled by a trainable artificial neural network model of the CNS laryngeal control pathways.  A goal of the proposal is to constrain the network model as much as possible by known anatomy, physiology, and vocal behavior so that, after training, its function comes to match the real laryngeal control system.  Once it has been developed, the model can be subjected to various manipulations, such as the equivalent of CNS lesions, and the effects on voice production by the model studied.  The combined study of these two model systems is relevant to several health issues in communication disorders.  The data from the mammalian system will clarify the functional role of some mid-level CNS structures in normal voice control.  In addition, the data are needed to aid the process of model development.  Successful development of the computational model, in turn, provides a powerful means for studying normal and abnormal mechanisms underlying voice production.  It also may prove important in control of laryngeal prostheses, and in reducing animal experimentation.  n/a",NEURAL CONTROL OF THE LARYNX,3218163,R01DC001535,"['artificial intelligence', ' basal ganglia', ' biological models', ' biomechanics', ' brain regulatory center', ' cartilage', ' cats', ' computational neuroscience', ' electromyography', ' histology', ' larynx', ' larynx muscle', ' ligaments', ' model design /development', ' morphology', ' motor neurons', ' muscle contraction', ' muscle tension', ' neuromuscular system', ' operant conditionings', ' psychoacoustics', ' respiration regulatory center', ' single cell analysis', ' stereotaxic techniques', ' subthalamus', ' vocalization']",NIDCD,FATHER FLANAGAN'S BOYS' HOME,R01,1993,145904,0.0324341872597846
"Development of a secure, cloud-based platform to improve record linkage & cross-agency collaboration for the public sector: using deep learning & scalable data integrations to combat the opioid crisis Project Summary/Abstract: This SBIR Phase I proposal aims to fund research and development for a new, multitenant secure cloud-based platform specifically tailored to provide local governmental agencies with tools to share datasets and link them accurately, at high quality and low cost. The OpenLattice platform will focus on reducing drug overdoses and making drug treatment less fractured. Individual-level datasets linked across medical providers and law enforcement can support analyses of prescribing pathways and treatment trajectories that precede opioid overdose, entry into treatment, disruption, and recovery. However, linking data at the individual level has proven to be a difficult and resource-intensive endeavor compared to use of aggregate-level data, with issues with deduplication plaguing many institutional databases. With 91 American deaths recorded daily from opioid overdoses and systems of care spread across multiple institutions, the need for greater and high-quality data sharing is undeniable. Our test partner for assessing the efficacy of proposed innovations is the Greater Portland Addiction Collaborative (GPAC) in Maine, a partnership of hospitals, a police department, jail, detox treatment centers and halfway houses already working together to reduce drug overdoses. This proposal aims to demonstrate proof of concept for (i) scaling high-quality data integrations across multiple governmental domains via a standardized entity data model, and (ii) improving record linkage using neural networks. Firstly, OpenLattice is developing an open source ontology and integration scripts to standardize integration of datasets into OpenLattice's database. As the individual customization requirements decline for onboarding customers and integrating new data into the platform, costs will be greatly slashed, removing a significant barrier to data solutions for smaller counties and cities across the country, who have historically faced custom integrations, system updates, data storage fees and add-ons at high cost. The OpenLattice platform also enables use of existing ETL tools and seamless integration with police dispatch systems, emergency medical calls, healthcare records, and online prescription systems across partners who have committed to data sharing and collaboration. Secondly, OpenLattice is developing a new, proprietary algorithm for record linkage that employs a promising but as-yet commercially untested technique: a multilayer perceptron neural network, more commonly known as deep learning. In pilot research, the linking algorithm has already demonstrated success rivaling—and sometimes exceeding—current state of the art linking technologies. In Phase I, OpenLattice will continue to improve ontologies, integration tools, and the deep learning neural network, and test on publicly available datasets with dissimilar data types and formats, with manual confirmation of results. When successful, these innovations will address critical barriers to improving clinical practice in treating opioid addiction by enabling a more comprehensive continuum of care for those in treatment. Project Narrative: Large-scale and coordinated responses to several of the US’s hot-button public health and criminal justice issues, such as the opioid epidemic and mass incarceration, are complicated by poor resource sharing and the US government’s highly fractured jurisdictional authority. This Small Business Innovation Research Phase I project aims to develop an efficient, scalable, cloud- based platform for hosting and linking highly sensitive state and local government databases at low cost, using (i) innovative data integration scripts and ontologies that standardize and scale capacity and (ii) technical advances in record de-duplication for linking databases. Data solutions would have tremendous societal impact on understandings of public health and the opioid epidemic by making drug treatment less fractured, saving lives and dramatically broadening contextual information, once data is broken out of silos.","Development of a secure, cloud-based platform to improve record linkage & cross-agency collaboration for the public sector: using deep learning & scalable data integrations to combat the opioid crisis",9622726,R43CE002937,[' '],NCIPC,"OPENLATTICE, INC.",R43,2018,225000,-0.07946238712939091
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,10016301,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retina', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'automated segmentation', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'segmentation algorithm', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2020,396286,0.14594220616431428
"Deep LOGISMOS Abstract: This is a competitive continuation of a project that already yielded the highly flexible, accurate, and broadly applicable LOGISMOS framework for context-aware n-dimensional image segmentation. To substantially improve and extend its capability, we will develop Deep LOGISMOS that combines and reinforces the complementary advantages of LOGISMOS and deep learning (DL). There is growing need for quantitative failure-free 3D and higher-D image analysis for diagnostic and/or planning purposes. Examples of current use exist in radiation oncology, cardiology, ophthalmology and other areas of routine clinical medicine, many of which however still rely on manual slice-by-slice tracing. This manual nature of such analyses hinders their use in precision medicine. Deep LOGISMOS research proposed here will solve this problem and will offer routine efficient analysis of clinical images of analyzable quality. To stimulate a new phase of this research project, we hypothesize that: Advanced graph-based image segmentation algorithms, when combined with deep-learning-derived application/modality specific parameters and allowing highly efficient expert-analyst guidance working in concert with the segmentation algorithms, will significantly increase quantitative analysis performance in routinely acquired, complex, diagnostic-quality medical images across diverse application areas. The proposed research focuses on establishing an image segmentation and analysis framework combining the strengths of LOGISMOS and DL, developing a new way to efficiently generate training data necessary for learning from examples, forming a failure-free strategy for 3D, 4D, and generally n-D quantitative medical image analysis, and discovering ways for automated segmentation quality control. We will fulfill these specific aims:  1. Develop an efficient approach for building large segmentation training datasets in 3D, 4D, n-D  using assisted and suggestive annotations.  2. Develop Deep LOGISMOS, combining two well-established algorithmic strategies – deep learning  and LOGISMOS graph search.  3. Develop and validate methods employing deep learning for quality control of Deep LOGISMOS.  4. In healthcare-relevant applications, demonstrate that Deep LOGISMOS improves segmentation  performance in comparison with state-of-the-art segmentation techniques. Deep LOGISMOS will bring broadly available routine quantification of clinical images, positively impacting the role of reliable image-based information in tomorrow’s precision medicine. Narrative: Previous phases of this successful research project were devoted to the development of new graph-based methods for multi-surface and/or multi-object multi-dimensional biomedical image segmentation. Deep learning is emerging as an important new way to learn from large sets of examples. This proposal will combine deep learning and graph-based image analysis to maximize their combined strengths and overcome their individual weaknesses with the overarching goal to facilitate routine use of quantitative medical image analysis techniques in personalized medical care.",Deep LOGISMOS,9831425,R01EB004640,"['3-Dimensional', 'Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Awareness', 'Biomedical Computing', 'Cardiac', 'Cardiology', 'Cardiovascular system', 'Caring', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Complex', 'Computational Science', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnostic', 'Diagnostic Neoplasm Staging', 'FDA approved', 'Failure', 'Fundus photography', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Healthcare', 'Human', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Location', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Modality', 'Morphology', 'Myocardial Infarction', 'Nature', 'Ophthalmology', 'Organ', 'PET/CT scan', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Problem Solving', 'Publications', 'Quality Control', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Role', 'Slice', 'Stroke', 'Suggestion', 'Surface', 'Techniques', 'Technology', 'Three-dimensional analysis', 'Time', 'Tissues', 'Training', 'Tumor Tissue', 'adjudication', 'automated analysis', 'base', 'bioimaging', 'clinical care', 'clinical imaging', 'clinical practice', 'deep learning', 'diabetic', 'experience', 'flexibility', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'insight', 'learning strategy', 'macular edema', 'n-dimensional', 'precision medicine', 'response', 'success', 'task analysis', 'treatment planning']",NIBIB,UNIVERSITY OF IOWA,R01,2019,409911,0.14594220616431428
"RUTGERS KNOWLEDGE-BASED BIOMEDICAL IMAGING PROJECT The fundamental objective of our proposed research project is to approach        biomedical image interpretation from a very new perspective:  that of            knowledge-intensive experimental design of the segmentation process              itself.  We use methods of artificial intelligence, specifically of              knowledge representation, diagnostic decision-making, planning and               learning, to carry out our objectives.                                                                                                                            Our central hypothesis is simple:  to make significant progress in               automating image recognition and measurement tasks we need to treat              recognition problems at the level of experimental design, so the best            solutions to various types of imaging problems can be derived by a               process of explicit specification, testing, and evaluation of different          segmentation strategies.  We have already built a preliminary prototype          of the proposed system, and have tested it on brain lesion recognition           problems from multimodality magnetic resonance imaging (MRI).  We are now        proposing to test both the methodological and practical assumptions              underlying the system.  We will concentrate on automatic segmentation and        interpretation techniques for individual and serial MRI examinations,            which will be applied to automatically quantitate CNS changes in patients        with tumors, AIDS-related lesions, MS lesions, and other conditions.                                                                                              The significance of this research for MR image interpretation lies in its        ability to provide both the clinical researcher and the laboratory               investigator the tools needed to carry out their work more efficiently           and effectively.  In the clinical case we are focusing on the assessment         of volume changes in AIDS-related and other lesions to quantitate their          response to treatment, and in an industrial laboratory application the           quantitation of lesion volumes is also critical in assessing the                 effectiveness of drugs undergoing testing.  In both cases there is a             clear potential contribution to biomedical knowledge and future health           care.                                                                             n/a",RUTGERS KNOWLEDGE-BASED BIOMEDICAL IMAGING PROJECT,2283216,R01RR006235,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' computer graphics /printing', ' computer human interaction', ' computer system design /evaluation', ' human data', ' image processing', ' lymphoma', ' magnetic resonance imaging', ' meningioma', ' neoplasm /cancer diagnosis', ' phantom model', ' progressive multifocal leukoencephalopathy']",NCRR,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,1995,429076,0.07750114230104574
"RUTGERS KNOWLEDGE-BASED BIOMEDICAL IMAGING PROJECT The fundamental objective of our proposed research project is to approach biomedical image interpretation from a very new perspective:  that of knowledge-intensive experimental design of the segmentation process itself.  We use methods of artificial intelligence, specifically of knowledge representation, diagnostic decision-making, planning and learning, to carry out our objectives.  Our central hypothesis is simple:  to make significant progress in automating image recognition and measurement tasks we need to treat recognition problems at the level of experimental design, so the best solutions to various types of imaging problems can be derived by a process of explicit specification, testing, and evaluation of different segmentation strategies.  We have already built a preliminary prototype of the proposed system, and have tested it on brain lesion recognition problems from multimodality magnetic resonance imaging (MRI).  We are now proposing to test both the methodological and practical assumptions underlying the system.  We will concentrate on automatic segmentation and interpretation techniques for individual and serial MRI examinations, which will be applied to automatically quantitate CNS changes in patients with tumors, AIDS-related lesions, MS lesions, and other conditions.  The significance of this research for MR image interpretation lies in its ability to provide both the clinical researcher and the laboratory investigator the tools needed to carry out their work more efficiently and effectively.  In the clinical case we are focusing on the assessment of volume changes in AIDS-related and other lesions to quantitate their response to treatment, and in an industrial laboratory application the quantitation of lesion volumes is also critical in assessing the effectiveness of drugs undergoing testing.  In both cases there is a clear potential contribution to biomedical knowledge and future health care.  n/a",RUTGERS KNOWLEDGE-BASED BIOMEDICAL IMAGING PROJECT,2283215,R01RR006235,"['artificial intelligence', ' biomedical automation', ' computer graphics /printing', ' computer human interaction', ' computer system design /evaluation', ' human data', ' image processing', ' lymphoma', ' magnetic resonance imaging', ' meningioma', ' neoplasm /cancer diagnosis', ' phantom model', ' progressive multifocal leukoencephalopathy']",NCRR,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,1994,419233,0.07750114230104574
"RUTGERS KNOWLEDGE-BASED BIOMEDICAL IMAGING PROJECT The fundamental objective of our proposed research project is to approach biomedical image interpretation from a very new perspective:  that of knowledge-intensive experimental design of the segmentation process itself.  We use methods of artificial intelligence, specifically of knowledge representation, diagnostic decision-making, planning and learning, to carry out our objectives.  Our central hypothesis is simple:  to make significant progress in automating image recognition and measurement tasks we need to treat recognition problems at the level of experimental design, so the best solutions to various types of imaging problems can be derived by a process of explicit specification, testing, and evaluation of different segmentation strategies.  We have already built a preliminary prototype of the proposed system, and have tested it on brain lesion recognition problems from multimodality magnetic resonance imaging (MRI).  We are now proposing to test both the methodological and practical assumptions underlying the system.  We will concentrate on automatic segmentation and interpretation techniques for individual and serial MRI examinations, which will be applied to automatically quantitate CNS changes in patients with tumors, AIDS-related lesions, MS lesions, and other conditions.  The significance of this research for MR image interpretation lies in its ability to provide both the clinical researcher and the laboratory investigator the tools needed to carry out their work more efficiently and effectively.  In the clinical case we are focusing on the assessment of volume changes in AIDS-related and other lesions to quantitate their response to treatment, and in an industrial laboratory application the quantitation of lesion volumes is also critical in assessing the effectiveness of drugs undergoing testing.  In both cases there is a clear potential contribution to biomedical knowledge and future health care.  n/a",RUTGERS KNOWLEDGE-BASED BIOMEDICAL IMAGING PROJECT,3421543,R01RR006235,"['artificial intelligence', ' biomedical automation', ' computer graphics /printing', ' computer human interaction', ' computer system design /evaluation', ' human data', ' image processing', ' lymphoma', ' magnetic resonance imaging', ' meningioma', ' neoplasm /cancer diagnosis', ' phantom model', ' progressive multifocal leukoencephalopathy']",NCRR,RUTGERS THE ST UNIV OF NJ NEW BRUNSWICK,R01,1993,329997,0.07750114230104574
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7496032,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2008,189850,0.07248042701727517
"Toward Quantitative Disease Assessment from Capsule Endoscopy Images    DESCRIPTION (provided by applicant): Capsule endoscopy has recently emerged as a valuable imaging technology for the gastrointestinal (GI) tract, especially the small bowel and the esophagus. With this technology, it has become possible to directly evaluate the gut mucosa of patients with a variety of conditions, such as obscure gastrointestinal bleeding, celiac disease and Crohn's disease. Although the use of capsule endoscopy is gaining rapidly, the evaluation of capsule endoscopic imagery presents numerous practical challenges. In a typical case, the capsule acquires 50,000 or more images over an eight-hour period. The quality of these images is highly variable due to the uncontrolled motion of the capsule itself as it moves through the GI tract, the complexity of the structures being imaged, and inherent limitations of the imager itself. In practice, relatively few (often less than 100) of these images contain significant diagnostic content. As a result, it is challenging to create an effective, repeatable means for evaluating capsule endoscopic sequences. The goal of this project is create a tool for semi-automated, objective, quantitative assessment of pathologic findings in capsule endoscopic data. The clinical focus will be on quantitative assessment of lesions that appear in Crohn's disease of the small bowel. The technical approach to this problem will make use of statistical learning methods to create algorithms that perform lesion classification and assessment in a manner consistent with a trained expert. The underlying hypothesis of this project is that appropriately constructed algorithms will be able to perform assessment of lesions appearing in capsule endoscopic images with a level of consistency comparable to human observers. In proving this hypothesis, the proposed project will pursue the following three specific aims:       Aim 1: Data acquisition. To develop a substantial database of images of intestinal lesions together with an expert assessment of several attributes indicative of lesion severity.       Aim 2: Tissue classification and image enhancement. To develop algorithms for low-level classification of tissue type from image content using statistical learning techniques, and to create algorithms for registering multiple partial views of a lesion to create more complete views.       Aim 3: Automated Lesion Assessment. To apply and validate statistical learning methods that can assess the images produced by Aim 2 in a manner consistent with the expert assessments compiled in Aim 1.       The focus of this R21 is on the development of tools that have proven efficacy on a representative corpus of data. This will set the stage for subsequent technological developments leading toward the automated detection of lesions, and subsequent clinical studies addressing the development of quantitative measures for Crohn's disease severity in a more substantial clinical setting.          n/a",Toward Quantitative Disease Assessment from Capsule Endoscopy Images,7362843,R21EB008227,"['Address', 'Aggressive Clinical Course', 'Algorithms', 'Anti-Inflammatory Agents', 'Anti-inflammatory', 'Appearance', 'Area', 'Body of uterus', 'Celiac Disease', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Condition', 'Crohn&apos', 's disease', 'Data', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Eating', 'End Point', 'Endoscopy', 'Esophagus', 'Evaluation', 'Gastrointestinal tract structure', 'Goals', 'Healed', 'Hemorrhage', 'Histocompatibility Testing', 'Hour', 'Human', 'Image', 'Image Enhancement', 'Imagery', 'Imaging technology', 'Intestines', 'Lesion', 'Machine Learning', 'Measures', 'Methods', 'Motion', 'Mucous Membrane', 'Numbers', 'Outcome', 'Pathologic', 'Patients', 'Severities', 'Severity of illness', 'Small Intestines', 'Staging', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Ulcer', 'base', 'capsule', 'data acquisition', 'gastrointestinal', 'healing', 'improved', 'indexing', 'size', 'small bowel Crohn&apos', 's disease', 'tool', 'tool development']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2007,235138,0.07248042701727517
"A suite of diagnostic aids based on image retrieval    DESCRIPTION (provided by applicant): The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx). We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker. In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies. Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid. The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance. PUBLIC HEALTH RELEVANCE: This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.           Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,7730016,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Cade', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer Systems Development', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Hand', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Knowledge', 'Label', 'Lead', 'Learning', 'Left', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'public health relevance', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,347642,0.05310156583839415
"A suite of diagnostic aids based on image retrieval  Project Summary The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx).  We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker.  In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies.  Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid.  The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance.  Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,8300707,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Lead', 'Learning', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Systems Development', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2012,320346,0.059826679736442276
"A suite of diagnostic aids based on image retrieval    DESCRIPTION (provided by applicant): The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx). We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker. In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies. Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid. The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance. PUBLIC HEALTH RELEVANCE: This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.           Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,8119450,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Health', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Label', 'Lead', 'Learning', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Systems Development', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2011,320034,0.05310156583839415
"A suite of diagnostic aids based on image retrieval    DESCRIPTION (provided by applicant): The predominant approach to computer-aided diagnosis (CAD) in medical imaging has been to use automated image analysis to serve as a ""second reader,"" with the aim of improving radiologists' diagnostic performance. CAD techniques traditionally aim to highlight suspicious lesions (called CADe) and/or estimate diagnostic variables, such as probability of malignancy (called CADx). We have been developing and evaluating a different approach to CAD, in which the radiologist will be assisted by a content-based search engine that will automatically identify and display examples of lesions, with known pathology, that are similar to the lesion being evaluated (referred to as the query). This will involve searching a large database for the images that are most similar to the query, based on image features that are automatically extracted by the software. The philosophy of this approach is to help inform the radiologist's diagnosis in difficult cases by presenting relevant information from past cases. The retrieved example lesions will allow the radiologist to explicitly compare known cases to the unknown case. A key advantage of the proposed retrieval approach to CAD is that it leaves decision-making entirely in the hands of the radiologist, unlike CADx, which acts as a supplemental decision maker. In our approach, we aim to tackle the key challenge of image retrieval, which is to develop a meaningful computerized measure of the similarity (relevance) of a patient's images to other images in the database. Departing from typical approaches based on numerical distance measures, we have proposed that the most useful measure of similarity is one that is designed specifically to match that perceived by the radiologist. We postulate that the radiologist's notion of similarity is some complicated unknown function of the images, and use advanced machine-learning algorithms to learn this function from similarity scores collected from radiologists in reader studies. Under R21 funding, we successfully demonstrated the feasibility and good performance of our approach in small data sets. The purpose of this proposed R01 project is to follow up the R21 project with a significantly larger scale effort in order to bring this approach to fruition, which will lead to a suite of retrieval-based CAD tools. We will develop the following unique components toward a clinical diagnostic aid: 1) instead of using indexing terms or simple distance measures to identify relevant images in the database, the system will use a similarity measure specifically trained to match radiologists' notion of relevance, as inferred from data obtained in an observer study; 2) in addition to presenting the retrieved cases to the radiologist, the system will use them to boost a CADx classifier to improve its classification accuracy on the query lesion; 3) the system will have the new capability of automatically building a large reference library by extracting known cases from a hospital PACS, thereby maximizing the benefit by retrieving more-similar cases; and 4) the system will be augmented with a highly interactive interface, which will include new tools for automatically adapting the similarity measure according to users' preferences, and for effectively presenting retrieved results. All of these components are novel and important to ultimate success of this kind of diagnostic aid. The project will include a preliminary demonstration using the Hospital Information System at the University of Chicago Hospitals, and will include preliminary evaluation studies to determine the effect of the system on radiologists' diagnostic performance. PUBLIC HEALTH RELEVANCE: This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.           Project Narrative This project will focus on development of a suite of supporting tools to facilitate the interpretation of images in radiology by mining similar cases from a database. The proposed system will make available to the radiologist through an intuitive interface a broad selection of relevant past cases to the one being diagnosed, along with an improved measure of its malignancy that is boosted by using retrieved cases, from which the radiologist can draw his or her own conclusions. We hypothesize that by providing such case-based evidence it will help radiologists in their decision-making process, particularly in diagnosis of difficult cases.",A suite of diagnostic aids based on image retrieval,7899840,R01EB009905,"['Algorithms', 'Breast Microcalcification', 'Cade', 'Caring', 'Chicago', 'Classification', 'Clinical', 'Computer Systems Development', 'Computer software', 'Computer-Assisted Diagnosis', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Ensure', 'Environment', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Florida', 'Funding', 'Hand', 'Hospital Information Systems', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Knowledge', 'Label', 'Lead', 'Learning', 'Left', 'Lesion', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Mammography', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Mining', 'Modeling', 'Pathology', 'Patients', 'Performance', 'Philosophy', 'Probability', 'Process', 'Radiology Specialty', 'Reader', 'Research', 'Retrieval', 'Software Tools', 'System', 'Techniques', 'Time', 'Training', 'Universities', 'base', 'case-based', 'computerized', 'design', 'follow-up', 'imaging modality', 'improved', 'indexing', 'novel', 'preference', 'public health relevance', 'radiologist', 'success', 'tool', 'vector']",NIBIB,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2010,328969,0.05310156583839415
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,9976348,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2020,529154,0.0979399067905048
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8689173,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2014,202714,0.04555542865791878
"Scalable Biomedical Pattern Recognition Via Deep Learning     DESCRIPTION (provided by applicant):  Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.      The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.      Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.      In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes.             Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,8566062,R21LM011664,"['Acquired Immunodeficiency Syndrome', 'Algorithms', 'Architecture', 'Area', 'Biomedical Research', 'Caring', 'Classification', 'Clinical', 'Clinical Data', 'Computational algorithm', 'Computerized Medical Record', 'Couples', 'Data', 'Data Set', 'Data Sources', 'Dependence', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Engineering', 'Evaluation', 'Exhibits', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Human', 'Image', 'Individual', 'Judgment', 'Knowledge', 'Label', 'Laboratories', 'Learning', 'Literature', 'Manuals', 'Measures', 'Medical', 'Metformin', 'Methods', 'Modeling', 'Myocardial Infarction', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'PTGS2 gene', 'Pattern', 'Pattern Recognition', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Probability', 'Process', 'ROC Curve', 'Records', 'Research', 'Risk', 'Sampling', 'Sea', 'Serum', 'Single Nucleotide Polymorphism', 'Source', 'Specific qualifier value', 'Structure', 'Testing', 'Time', 'To specify', 'Uncertainty', 'Uric Acid', 'Work', 'cell growth', 'clinical care', 'clinical phenotype', 'density', 'diabetic', 'genetic association', 'genetic variant', 'inhibitor/antagonist', 'interest', 'meetings', 'neoplastic cell', 'non-diabetic', 'outcome forecast', 'prevent', 'speech recognition', 'success', 'type I and type II diabetes']",NLM,VANDERBILT UNIVERSITY,R21,2013,175500,0.04555542865791878
"Scalable Biomedical Pattern Recognition Via Deep Learning DESCRIPTION (provided by applicant): Patterns extracted from Electronic Medical Records (EMRs) and other biomedical datasets can provide valuable feedback to a learning healthcare system, but our ability to find them is limited by certain manual steps. The dominant approach to finding the patterns uses supervised learning, where a computational algorithm searches for patterns among input variables (or features) that model an outcome variable (or label). This usually requires an expert to specify the learning task, construct input features, and prepare the outcome labels. This workflow has served us well for decades, but the dependence on human effort prevents it from scaling and it misses the most informative patterns, which are almost by definition the ones that nobody anticipates. It is poorly suited to the emerging era of population-scale data, in which we can conceive of massive new undertakings such as surveiling for all emerging diseases, detecting all unanticipated medication effects, or inferring the complete clinical phenotype of all genetic variants.  The approach of unsupervised feature learning overcomes these limitations by identifying meaningful patterns in massive, unlabeled datasets with little or no human involvement. While there is a large literature on feature creation, a new surge of interest in unsupervised methods is  being driven by the recent development of deep learning, in which a compact hierarchy of expressive features is learned from large unlabeled datasets. In the domains of image and speech recognition, deep learning has produced features that meet or exceed (by as much as 70%) the previous state of the art on difficult standardized tasks.  Unfortunately, the noisy, sparse, and irregular data typically found in an EMR is a poor substrate for deep learning. Our approach uses Gaussian process regression to convert such an irregular sequence of observations into a longitudinal probability density that is suitable for use with a deep architecture. With this approach, we can learn continuous unsupervised features that capture the longitudinal structure of sparse and irregular observations. In our preliminary results unsupervised features were as powerful (0.96 AUC) in an unanticipated classification task as gold-standard features engineered by an expert with full knowledge of the domain, the classification task, and the class labels.  In this project we will learn unsupervised features for records of all individuals in our deidentifed EMR image, for each of 100 laboratory tests and 200 medications of relevance to type 1 or type 2 diabetes. We will evaluate the features using three pattern recognition tasks that were unknown to the feature-learning algorithm: 1) an easy supervised classification task of distinguishing diabetics vs. nondiabetics, 2) a much more difficult task of distinguishing type 1 vs. type 2 diabetics, and 3) a genetic association task that considers the features as micro-phenotypes and measures their association with 29 different single nucleotide polymorphisms with known associations to type 1 or type 2 diabetes. Every piece of data generated in the course of medical care can provide crucial feedback to a learning healthcare system, but only if relevant patterns can be found among them. The current practice of using human experts to guide the pattern search has served us well for decades, but it is poorly suited to the emerging era of population- scale data, in which we may conceive of massive new undertakings such as detecting all emerging diseases or all unanticipated medication effects. This project will develop methods to mathematically identify such patterns at a large scale, with no need for human judgment to specify what patterns to look for or where to look for them.",Scalable Biomedical Pattern Recognition Via Deep Learning,9302040,R21LM011664,[' '],NLM,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2014,7696,0.04555542865791878
"Interpretable deep learning models for translational medicine Understanding the state of cellular signaling systems provides insights to how cells behave under physiological and pathological conditions. Cellular signaling systems are organized as hierarchy (cascade) and signals of a molecular is often compositionally encoded to control cellular processes, such as gene expression. This project aims to develop advanced deep learning models (DLMs) to simulate cellular signaling systems based on gene expression data. In last 3 years, the project has made significant progresses, but the challenges remain. Importantly, contemporary DLMs behave as “black boxes”, in that it is difficult to interpret how signals are encoded and how to interpret which signal a hidden node represent in a DLM. This black-box nature prevents researchers from gaining biological insights using DLMs, even though these models can be much superior in modeling data than other types of models in many tasks, e.g., predicting drug sensitivity of cancer cells. In this competitive renewal, we propose to develop novel DLMs and innovative inference algorithms to train “interpretable” DLMs and apply them in translational research. The proposed research is innovative and of high significance in several perspectives: 1) Our novel DLMs and algorithms take advantage of big data resulting from systematic chemical/genetic perturbations of cellular signaling machinery, so that we can use the perturbation condition as side information to reveal how signals are encoded in a DLM. 2) We integrate principles of causal inference and information theory with deep learning method to make DLMs interpretable. As results, that researchers can gain mechanistic insights from such models. 3) Innovative application of interpretable DLMs will advance translational research. For example, we will train interpretable DLMs to model cellular signaling at the level of single cells and use this information investigate inter-cellular interactions among cells in tumor microenvironment to shed light on immune evasion mechanisms of cancers. We will also use information derived from interpretable DLMs to predict cancer cell drug sensitivity. We anticipate that our study will bring forth significant advances not only in deep learning methodology but also in precision medicine. This project aims to develop advance machine learning methods, referred to as deep learning models, to simulate cellular signaling systems, at both multiple cell and single cell levels. Success of these models will enable researchers to investigate cellular behaviors under physiological and pathological condition, and such information can be used to guide therapy of cancer patients.",Interpretable deep learning models for translational medicine,9972153,R01LM012011,"['Affect', 'Algorithms', 'Antineoplastic Agents', 'Big Data', 'Biological', 'Cancer Patient', 'Cancer cell line', 'Cell model', 'Cell physiology', 'Cells', 'Data', 'Disease', 'Event', 'Gene Expression', 'Genetic', 'Genetic Transcription', 'Grain', 'Human', 'Immune Evasion', 'Immunotherapy', 'Individual', 'Information Theory', 'Intervention', 'Knowledge', 'Learning', 'Libraries', 'Light', 'Malignant Neoplasms', 'Messenger RNA', 'Methodology', 'MicroRNAs', 'Mining', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Network-based', 'Organoids', 'Outcome', 'Paper', 'Pathologic', 'Pathway interactions', 'Patients', 'Pharmacology', 'Phenotype', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Side', 'Signal Pathway', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Technology', 'The Cancer Genome Atlas', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Yeasts', 'base', 'biological systems', 'cancer cell', 'cancer therapy', 'cell behavior', 'chemical genetics', 'data modeling', 'deep field survey', 'deep learning', 'deep learning algorithm', 'design', 'drug sensitivity', 'experience', 'genome-wide', 'innovation', 'inquiry-based learning', 'insight', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'novel', 'patient response', 'pre-clinical', 'precision medicine', 'precision oncology', 'predicting response', 'prevent', 'response', 'single-cell RNA sequencing', 'success', 'theories', 'tool', 'transcription factor', 'transcriptome', 'transcriptomics', 'translational impact', 'translational medicine', 'translational model', 'tumor', 'tumor microenvironment']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2020,309622,0.056320554446178235
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9527181,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2018,545116,0.04696575145815075
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9403171,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Learning', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2017,548068,0.04696575145815075
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9979659,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'MeSH Thesaurus', 'Measures', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'large scale data', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'public repository', 'specific biomarkers']",NLM,UNIVERSITY OF CENTRAL FLORIDA,U01,2020,467177,0.04696575145815075
"Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine PROJECT SUMMARY/ABSTRACT  The NIH and other agencies are funding high-throughput genomics (‘omics) experiments that deposit digital samples of data into the public domain at breakneck speeds. This high-quality data measures the ‘omics of diseases, drugs, cell lines, model organisms, etc. across the complete gamut of experimental factors and conditions. The importance of these digital samples of data is further illustrated in linked peer-reviewed publications that demonstrate its scientific value. However, meta-data for digital samples is recorded as free text without biocuration necessary for in-depth downstream scientific inquiry.  Deep learning is revolutionary machine intelligence paradigm that allows for an algorithm to program itself thereby removing the need to explicitly specify rules or logic. Whereas physicians / scientists once needed to first understand a problem to program computers to solve it, deep learning algorithms optimally tune themselves to solve problems. Given enough example data to train on, deep learning machine intelligence outperform humans on a variety of tasks. Today, deep learning is state-of-the-art performance for image classification, and, most importantly for this proposal, for natural language processing.  This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples. We will then develop and train deep learning algorithms for STARGEO digital curation based on learning the associated free text meta-data each digital sample. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.  Finally, we will demonstrate the biological utility to leverage CrADLe for digital curation with two large- scale and independent molecular datasets in: 1) The Cancer Genome Atlas (TCGA), and 2) The Accelerating Medicines Partnership-Alzheimer’s Disease (AMP-AD). We posit that CrADLe digital curation of open samples will augment these two distinct disease projects with a host big data to fuel the discovery of potential biomarker and gene targets. Therefore, successful funding and completion of this work may greatly reduce the burden of disease on patients by enhancing the efficiency and effectiveness of digital curation for biomedical big data. PROJECT NARRATIVE This proposal is about engineering Crowd Assisted Deep Learning (CrADLe) machine intelligence to rapidly scale the digital curation of public digital samples and directly translating this ‘omics data into useful biological inference. We will first use our NIH BD2K-funded Search Tag Analyze Resource for Gene Expression Omnibus (STARGEO.org) to crowd-source human annotation of open digital samples on which we will develop and train deep learning algorithms for STARGEO digital curation of free-text sample-level metadata. Given the ongoing deluge of biomedical data in the public domain, CrADLe may perhaps be the only way to scale the digital curation towards a precision medicine ideal.",Crowd-Assisted Deep Learning (CrADLe) Digital Curation to Translate Big Data into Precision Medicine,9747977,U01LM012675,"['Algorithms', 'Alzheimer&apos', 's Disease', 'Animal Model', 'Artificial Intelligence', 'Big Data', 'Big Data to Knowledge', 'Biological', 'Biological Assay', 'Categories', 'Cell Line', 'Cell model', 'Classification', 'Clinical', 'Collaborations', 'Communities', 'Controlled Vocabulary', 'Crowding', 'Data', 'Data Quality', 'Data Set', 'Defect', 'Deposition', 'Diagnosis', 'Disease', 'Disease model', 'Drug Modelings', 'E-learning', 'Effectiveness', 'Engineering', 'Funding', 'Funding Agency', 'Future', 'Gene Expression', 'Gene Targeting', 'Genomics', 'Human', 'Image', 'Intelligence', 'Label', 'Link', 'Logic', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medicine', 'Meta-Analysis', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Molecular Profiling', 'National Research Council', 'Natural Language Processing', 'Ontology', 'Pathway interactions', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Pharmaceutical Preparations', 'Physicians', 'Problem Solving', 'PubMed', 'Public Domains', 'Publications', 'Resources', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Source', 'Specific qualifier value', 'Speed', 'Subject Headings', 'Text', 'The Cancer Genome Atlas', 'Training', 'Translating', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'big biomedical data', 'biomarker discovery', 'burden of illness', 'cell type', 'classical conditioning', 'computer program', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'digital', 'disease phenotype', 'experimental study', 'genomic data', 'human disease', 'improved', 'knockout gene', 'novel therapeutics', 'open data', 'potential biomarker', 'precision medicine', 'programs', 'repository', 'specific biomarkers']",NLM,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2019,115051,0.04696575145815075
"Deep learning for protein subcellular/sub-organelle localizations and localization motifs Project Summary Eukaryotic cells have diverse cellular components, including subcellular organelles and sub-organelle compartments. The accurate targeting of proteins to these cellular components is crucial in establishing and maintaining cellular organizations and functions. Mis-localization of proteins is often associated with metabolic disorders and diseases. However, the vast majority of proteins lack subcellular/sub-organelle localization annotation. Compared with experimental methods, computational prediction of protein localization provides an efficient and effective way for proteome annotation and experimental design. The current prediction tools for protein localization have significant room for improvement. In addition, no tool can predict localization at the sub- organelle resolution or internal localization signals. Deep learning, as the cutting-edge technology in machine learning, presents a new opportunity for this classical bioinformatics problem. The availability of recent high- throughput localization data can also train deep learning well. The PI’s lab has demonstrated some success on a special case, i.e., predicting mitochondrial localizations for plants using deep learning.  In this project, the PI proposes to develop new methods and a standalone toolkit for accurate and scalable protein localization prediction at the subcellular and sub-organelle levels, as well as for characterization of localization motifs (including novel internal motifs). The general approach is to design a semi-supervised deep- learning method that utilizes both annotated protein sequences with known localization and unannotated protein sequences as training data. Through the realization of an unsupervised deep-learning approach, a general representation of protein sequences will be implemented, characterizing both local and global features of protein sequences. By visualizing and characterizing the deep-learning models, novel, interpretable protein sequence patterns will be predicted as putative targeting peptides and compared with known localization signals. We will also use the methods to be developed and the unsupervised models to be trained on all protein sequences as a general framework for other sequence-based prediction problems that predict the label of a protein and the key residues contributing to the label. We will make the platform highly customizable and apply it to three applications, including ubiquitination protein prediction, enzyme EC number prediction, and protein family/subfamily classification. The innovative contributions to protein sequence-based analyses and predictions include: (1) using raw amino acid sequences as training inputs without feature engineering; (2) utilizing the huge amount of unannotated data in an unsupervised deep learning to characterize a general protein feature representation; (3) identifying potential targeting signals (especially internal motifs) by decoding the trained deep- learning models, augmented with sophisticated attention mechanisms; 4) detecting multiple-organelle targeting and sub-organelle localizations by a novel hierarchical multi-label architecture; and (5) combining features from different data sources by a multiplicative fused CNN model. Relevance to Public Health  A protein typically has a well-defined localization in a cell to perform its function, and mis-localization of proteins is often associated with metabolic disorders and diseases. Protein localization prediction can provide valuable information for understanding disease mechanisms and designing treatment. To address the limitations of current computational methods, this project will apply cutting-edge deep-learning methods to deliver new computational methods and tools with improved accuracy and detailed sub-organelle prediction for protein localization.",Deep learning for protein subcellular/sub-organelle localizations and localization motifs,9768571,R21LM012790,"['Address', 'Amino Acid Sequence', 'Architecture', 'Attention', 'Base Sequence', 'Bioinformatics', 'Cells', 'Classification', 'Computer software', 'Computing Methodologies', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Engineering', 'Enzymes', 'Eukaryotic Cell', 'Experimental Designs', 'Generations', 'Hybrids', 'Imagery', 'Label', 'Machine Learning', 'Metabolic Diseases', 'Methodology', 'Methods', 'Mitochondria', 'Modeling', 'N-terminal', 'Neural Network Simulation', 'Nobel Prize', 'Organelles', 'Pattern', 'Peptide Signal Sequences', 'Peptides', 'Plants', 'Protein Family', 'Protein translocation', 'Proteins', 'Proteome', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Signal Transduction', 'Supervision', 'Techniques', 'Technology', 'Training', 'Ubiquitination', 'Work', 'base', 'bioinformatics tool', 'computerized tools', 'convolutional neural network', 'deep learning', 'design', 'improved', 'innovation', 'interest', 'learning network', 'learning strategy', 'novel', 'online resource', 'predictive modeling', 'protein function', 'recurrent neural network', 'success', 'therapy design', 'tool']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R21,2019,205330,0.06251573915573903
"Deep learning for protein subcellular/sub-organelle localizations and localization motifs Project Summary Eukaryotic cells have diverse cellular components, including subcellular organelles and sub-organelle compartments. The accurate targeting of proteins to these cellular components is crucial in establishing and maintaining cellular organizations and functions. Mis-localization of proteins is often associated with metabolic disorders and diseases. However, the vast majority of proteins lack subcellular/sub-organelle localization annotation. Compared with experimental methods, computational prediction of protein localization provides an efficient and effective way for proteome annotation and experimental design. The current prediction tools for protein localization have significant room for improvement. In addition, no tool can predict localization at the sub- organelle resolution or internal localization signals. Deep learning, as the cutting-edge technology in machine learning, presents a new opportunity for this classical bioinformatics problem. The availability of recent high- throughput localization data can also train deep learning well. The PI’s lab has demonstrated some success on a special case, i.e., predicting mitochondrial localizations for plants using deep learning.  In this project, the PI proposes to develop new methods and a standalone toolkit for accurate and scalable protein localization prediction at the subcellular and sub-organelle levels, as well as for characterization of localization motifs (including novel internal motifs). The general approach is to design a semi-supervised deep- learning method that utilizes both annotated protein sequences with known localization and unannotated protein sequences as training data. Through the realization of an unsupervised deep-learning approach, a general representation of protein sequences will be implemented, characterizing both local and global features of protein sequences. By visualizing and characterizing the deep-learning models, novel, interpretable protein sequence patterns will be predicted as putative targeting peptides and compared with known localization signals. We will also use the methods to be developed and the unsupervised models to be trained on all protein sequences as a general framework for other sequence-based prediction problems that predict the label of a protein and the key residues contributing to the label. We will make the platform highly customizable and apply it to three applications, including ubiquitination protein prediction, enzyme EC number prediction, and protein family/subfamily classification. The innovative contributions to protein sequence-based analyses and predictions include: (1) using raw amino acid sequences as training inputs without feature engineering; (2) utilizing the huge amount of unannotated data in an unsupervised deep learning to characterize a general protein feature representation; (3) identifying potential targeting signals (especially internal motifs) by decoding the trained deep- learning models, augmented with sophisticated attention mechanisms; 4) detecting multiple-organelle targeting and sub-organelle localizations by a novel hierarchical multi-label architecture; and (5) combining features from different data sources by a multiplicative fused CNN model. Relevance to Public Health  A protein typically has a well-defined localization in a cell to perform its function, and mis-localization of proteins is often associated with metabolic disorders and diseases. Protein localization prediction can provide valuable information for understanding disease mechanisms and designing treatment. To address the limitations of current computational methods, this project will apply cutting-edge deep-learning methods to deliver new computational methods and tools with improved accuracy and detailed sub-organelle prediction for protein localization.",Deep learning for protein subcellular/sub-organelle localizations and localization motifs,9600437,R21LM012790,"['Address', 'Amino Acid Sequence', 'Architecture', 'Attention', 'Base Sequence', 'Bioinformatics', 'Biological Neural Networks', 'Cells', 'Classification', 'Computer software', 'Computing Methodologies', 'Data', 'Data Sources', 'Detection', 'Development', 'Disease', 'Engineering', 'Enzymes', 'Eukaryotic Cell', 'Experimental Designs', 'Generations', 'Hybrids', 'Imagery', 'Label', 'Machine Learning', 'Metabolic Diseases', 'Methodology', 'Methods', 'Mitochondria', 'Modeling', 'N-terminal', 'Neural Network Simulation', 'Nobel Prize', 'Organelles', 'Pattern', 'Peptide Signal Sequences', 'Peptides', 'Plants', 'Protein Family', 'Protein translocation', 'Proteins', 'Proteome', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Series', 'Signal Transduction', 'Supervision', 'Techniques', 'Technology', 'Training', 'Ubiquitination', 'Work', 'base', 'computerized tools', 'deep learning', 'design', 'improved', 'innovation', 'interest', 'learning network', 'learning strategy', 'novel', 'online resource', 'predictive modeling', 'protein function', 'recurrent neural network', 'success', 'therapy design', 'tool']",NLM,UNIVERSITY OF MISSOURI-COLUMBIA,R21,2018,174375,0.06251573915573903
"Developing deep learning models for precision oncology Project Summary/Abstract The goal of this study is to develop machine learning methods, especially deep learning models (DLMs), to learn a better representation of activation states of cellular signaling pathways in an individual tumor and use such information to predict its sensitivity to anti-cancer drugs. Cancer is mainly caused by somatic genome alterations (SGAs) that perturb cellular signaling pathways, and aberrations in pathways eventually lead to cancer development. Precision oncology aims to accurately detect and target tumor-specific aberrations, but challenges remain. Currently, there is no well-established method to detect the activation states of signaling pathways, and the common practice of using mutation status of a targeted gene as the indicator for prescribing a molecularly targeted drug has limitations. To overcome such limitation, we hypothesize that, by closely simulating the hierarchical organization of cellular signaling systems, DLMs can be used to systematically identify major cancer signaling pathways, to detect tumor-specific aberrations in signaling pathways, and to predict cancer cell sensitivity to anti-cancer drugs.  We will develop models that more precisely represent the state of signaling systems in cancer cells and use such information to enhance precision oncology. I will design and apply innovative DLMs to cancer big data, including large-scale pharmacogenomic data and cancer omics data to learn unified representation of aberrations in signaling systems caused by driver SGAs in cancer cell, despite of their different growth conditions, such as in cell culture, PDX and real tumor. This will enable us to transfer the models trained using cell lines and PDXs to clinical setting (real tumors) in future. By the nature of drugs that may share common target proteins, we develop model DLM-MLT (the combination of DLM and multi-task learning) to predict the sensitivity of tumor samples to multiple drugs at once. Furthermore, we will develop model BioSI-DLM to use various perturbations (ex. SGA/LINCS perturbation data) as side information to learn better representation that potentially map latent variables in a DLM to biological entities. We hypothesize that the representation learned from our designed models will significantly improve the prediction accuracy compared with the conventional indication for drug treatment (ex. mutation state of the drug targeting protein). In summary, our study uses deep learning based machine learning methods to learn better and concise representation embedded in the cancer omics data to reflect the personalized genomic changes, which could be used to guide the personalized treatment. Our study could significantly contribute to the development of cancer ontology and promote the development of precision medicine. Project Narrative Cancer is among the leading causes of death worldwide. The proposed project aims to develop machine learning methods, especially deep learning, to study cellular signaling systems and disease mechanism. A better representation embedded in the cancer omics data will improve the prediction of drug sensitivity and patient survival. Our study promotes the development of precision medicine to guide the personalized treatment based on patient’s unique genetic changes.",Developing deep learning models for precision oncology,9892632,K99LM013089,"['Antineoplastic Agents', 'Big Data', 'Biological', 'Biological Markers', 'Cancer cell line', 'Cause of Death', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Clinical', 'Data', 'Development', 'Disease', 'Drug Targeting', 'Foundations', 'Future', 'Gene Expression', 'Genes', 'Genome', 'Genomics', 'Goals', 'Growth', 'Human', 'Individual', 'Knowledge', 'Label', 'Lead', 'Learning', 'Malignant Neoplasms', 'Maps', 'Messenger RNA', 'Methods', 'MicroRNAs', 'Modeling', 'Mutation', 'Nature', 'Oncogenic', 'Ontology', 'PIK3CA gene', 'Paper', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Pharmacotherapy', 'Proteins', 'Proteomics', 'Rattus', 'Research Activity', 'Resistance', 'Sampling', 'Side', 'Signal Pathway', 'Signal Transduction', 'System', 'Testing', 'The Cancer Genome Atlas', 'Training', 'Work', 'Xenograft procedure', 'Yeasts', 'base', 'cancer cell', 'deep learning', 'design', 'drug sensitivity', 'experimental study', 'improved', 'innovation', 'machine learning method', 'model design', 'molecular drug target', 'molecular phenotype', 'multi-task learning', 'mutational status', 'novel', 'personalized medicine', 'precision medicine', 'precision oncology', 'response', 'transcription factor', 'transcriptomics', 'tumor', 'tumor xenograft']",NLM,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K99,2020,93908,-0.018996520951201648
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,9972588,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,318155,0.13064502267620587
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9910382,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2020,510157,0.0013989511691722683
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9740493,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Augmented Reality', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Imagery', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Visual', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'tool', 'trend', 'virtual reality', 'web services']",NIBIB,"KITWARE, INC.",R01,2019,508446,0.0013989511691722683
"Molecular Profiling of Premalignant Oral Lesions    DESCRIPTION (provided by applicant):  Head and neck squamous cell carcinoma (HNSCC) is a major health problem affecting current and former tobacco users, with approximately 40,000 cases per year in the United States and 500,000 cases worldwide. The development of HNSCC is heralded by the development of dysplastic lesions within the mucosa and early diagnosis of pre-malignant lesions is known to directly correlate with increased survival. However, current diagnostic techniques for premalignant disease, based on recognition of nuclear and cellular atypia, are relatively poor predictors of ultimate clinical outcome. Since morphological or cytological changes may occur late in the process of transformation, histologically benign appearing lesions may have malignant potential. Conversely, even severely dysplastic oral lesions can undergo spontaneous regression. Thus, histological findings cannot clearly predict malignant change. A method for detecting molecularly premalignant lesions at an early stage and for predicting the likelihood of malignant progression is required.       The goal of this proposal is to identify a panel of biomarkers that will allow for the identification of molecularly premalignant lesions. Accordingly, gene expression profiling of microdissected keratinocytes from biopsies containing normal mucosal tissue from nonsmokers and invasive HNSCC will be performed in order to identify potential oral mucosa progression markers (OPM). The interpretation and analysis of the array data will be performed within a newly established Bioinformatics Core. This web-accessible annotation, cataloging facility will use both unsupervised and supervised learning methodologies. The utility of these potential OPMs will then be validated using custom human tissue array samples having the different histologic diagnoses including: normal, reactive, hyperkeratosis, hyperplasia and various grades of dysplasia. These analyses may identify markers that correlate with the biologic severity of dysplasia and with the potential for malignant progression. This molecular analysis may also greatly improve diagnostic prediction compared to the cellular pattern recognition currently used by pathologists.         n/a",Molecular Profiling of Premalignant Oral Lesions,7470024,R01DE015830,"['Affect', 'Arts', 'Atypia', 'Benign', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biology', 'Biopsy', 'Cancerous', 'Cataloging', 'Catalogs', 'Chemoprevention', 'Chemopreventive Agent', 'Classification', 'Clinical', 'Custom', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Differentiated Gene', 'Disease', 'Disease regression', 'Dysplasia', 'Early Diagnosis', 'Educational workshop', 'Future', 'Gene Expression', 'Gene Expression Profiling', 'Genes', 'Genetic', 'Goals', 'Head and Neck Cancer', 'Head and Neck Squamous Cell Carcinoma', 'Health', 'Histologic', 'Hyperkeratosis', 'Hyperplasia', 'Invasive', 'Learning', 'Lesion', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Profiling', 'Monitor', 'Mucous Membrane', 'Nuclear', 'Online Systems', 'Oral', 'Oral cavity', 'Oral mucous membrane structure', 'Outcome', 'Pathologist', 'Patients', 'Pattern Recognition', 'Phase', 'Premalignant', 'Process', 'Prognostic Marker', 'Purpose', 'Recommendation', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Severities', 'Squamous cell carcinoma', 'Staging', 'System', 'Tissue Microarray', 'Tissues', 'Tobacco', 'United States', 'Validation', 'Work', 'base', 'human tissue', 'improved', 'insight', 'keratinocyte', 'malignant mouth neoplasm', 'non-smoker', 'oral lesion', 'prevent', 'programs', 'response', 'tumor progression', 'validation studies', 'web-accessible']",NIDCR,UNIVERSITY OF CHICAGO,R01,2008,311993,0.10592422494514246
"Molecular Profiling of Premalignant Oral Lesions    DESCRIPTION (provided by applicant):  Head and neck squamous cell carcinoma (HNSCC) is a major health problem affecting current and former tobacco users, with approximately 40,000 cases per year in the United States and 500,000 cases worldwide. The development of HNSCC is heralded by the development of dysplastic lesions within the mucosa and early diagnosis of pre-malignant lesions is known to directly correlate with increased survival. However, current diagnostic techniques for premalignant disease, based on recognition of nuclear and cellular atypia, are relatively poor predictors of ultimate clinical outcome. Since morphological or cytological changes may occur late in the process of transformation, histologically benign appearing lesions may have malignant potential. Conversely, even severely dysplastic oral lesions can undergo spontaneous regression. Thus, histological findings cannot clearly predict malignant change. A method for detecting molecularly premalignant lesions at an early stage and for predicting the likelihood of malignant progression is required.       The goal of this proposal is to identify a panel of biomarkers that will allow for the identification of molecularly premalignant lesions. Accordingly, gene expression profiling of microdissected keratinocytes from biopsies containing normal mucosal tissue from nonsmokers and invasive HNSCC will be performed in order to identify potential oral mucosa progression markers (OPM). The interpretation and analysis of the array data will be performed within a newly established Bioinformatics Core. This web-accessible annotation, cataloging facility will use both unsupervised and supervised learning methodologies. The utility of these potential OPMs will then be validated using custom human tissue array samples having the different histologic diagnoses including: normal, reactive, hyperkeratosis, hyperplasia and various grades of dysplasia. These analyses may identify markers that correlate with the biologic severity of dysplasia and with the potential for malignant progression. This molecular analysis may also greatly improve diagnostic prediction compared to the cellular pattern recognition currently used by pathologists.         n/a",Molecular Profiling of Premalignant Oral Lesions,7235630,R01DE015830,"['Affect', 'Arts', 'Atypia', 'Benign', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biology', 'Biopsy', 'Cancerous', 'Cataloging', 'Catalogs', 'Chemoprevention', 'Chemopreventive Agent', 'Classification', 'Clinical', 'Custom', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Procedure', 'Differentiated Gene', 'Disease', 'Disease regression', 'Dysplasia', 'Early Diagnosis', 'Educational workshop', 'Future', 'Gene Expression', 'Gene Expression Profiling', 'Genes', 'Genetic', 'Goals', 'Head and Neck Cancer', 'Head and Neck Squamous Cell Carcinoma', 'Health', 'Histologic', 'Hyperkeratosis', 'Hyperplasia', 'Invasive', 'Learning', 'Lesion', 'Malignant - descriptor', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Profiling', 'Monitor', 'Mucous Membrane', 'Nuclear', 'Online Systems', 'Oral', 'Oral cavity', 'Oral mucous membrane structure', 'Outcome', 'Pathologist', 'Patients', 'Pattern Recognition', 'Phase', 'Premalignant', 'Process', 'Prognostic Marker', 'Purpose', 'Recommendation', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Severities', 'Squamous cell carcinoma', 'Staging', 'System', 'Tissue Microarray', 'Tissues', 'Tobacco', 'United States', 'Validation', 'Work', 'base', 'human tissue', 'improved', 'insight', 'keratinocyte', 'malignant mouth neoplasm', 'non-smoker', 'oral lesion', 'prevent', 'programs', 'response', 'tumor progression', 'validation studies', 'web-accessible']",NIDCR,UNIVERSITY OF CHICAGO,R01,2007,316626,0.10592422494514246
"Molecular Profiling of Premalignant Oral Lesions    DESCRIPTION (provided by applicant):  Head and neck squamous cell carcinoma (HNSCC) is a major health problem affecting current and former tobacco users, with approximately 40,000 cases per year in the United States and 500,000 cases worldwide. The development of HNSCC is heralded by the development of dysplastic lesions within the mucosa and early diagnosis of pre-malignant lesions is known to directly correlate with increased survival. However, current diagnostic techniques for premalignant disease, based on recognition of nuclear and cellular atypia, are relatively poor predictors of ultimate clinical outcome. Since morphological or cytological changes may occur late in the process of transformation, histologically benign appearing lesions may have malignant potential. Conversely, even severely dysplastic oral lesions can undergo spontaneous regression. Thus, histological findings cannot clearly predict malignant change. A method for detecting molecularly premalignant lesions at an early stage and for predicting the likelihood of malignant progression is required.       The goal of this proposal is to identify a panel of biomarkers that will allow for the identification of molecularly premalignant lesions. Accordingly, gene expression profiling of microdissected keratinocytes from biopsies containing normal mucosal tissue from nonsmokers and invasive HNSCC will be performed in order to identify potential oral mucosa progression markers (OPM). The interpretation and analysis of the array data will be performed within a newly established Bioinformatics Core. This web-accessible annotation, cataloging facility will use both unsupervised and supervised learning methodologies. The utility of these potential OPMs will then be validated using custom human tissue array samples having the different histologic diagnoses including: normal, reactive, hyperkeratosis, hyperplasia and various grades of dysplasia. These analyses may identify markers that correlate with the biologic severity of dysplasia and with the potential for malignant progression. This molecular analysis may also greatly improve diagnostic prediction compared to the cellular pattern recognition currently used by pathologists.         n/a",Molecular Profiling of Premalignant Oral Lesions,7095254,R01DE015830,"['biomarker', 'cell morphology', 'clinical research', 'gene expression profiling', 'head /neck neoplasm', 'human subject', 'keratinocyte', 'neoplastic transformation', 'oral mucosa', 'preneoplastic state', 'smoking', 'squamous cell carcinoma', 'tobacco abuse']",NIDCR,UNIVERSITY OF CHICAGO,R01,2006,327954,0.10592422494514246
"Molecular Profiling of Premalignant Oral Lesions    DESCRIPTION (provided by applicant):  Head and neck squamous cell carcinoma (HNSCC) is a major health problem affecting current and former tobacco users, with approximately 40,000 cases per year in the United States and 500,000 cases worldwide. The development of HNSCC is heralded by the development of dysplastic lesions within the mucosa and early diagnosis of pre-malignant lesions is known to directly correlate with increased survival. However, current diagnostic techniques for premalignant disease, based on recognition of nuclear and cellular atypia, are relatively poor predictors of ultimate clinical outcome. Since morphological or cytological changes may occur late in the process of transformation, histologically benign appearing lesions may have malignant potential. Conversely, even severely dysplastic oral lesions can undergo spontaneous regression. Thus, histological findings cannot clearly predict malignant change. A method for detecting molecularly premalignant lesions at an early stage and for predicting the likelihood of malignant progression is required.       The goal of this proposal is to identify a panel of biomarkers that will allow for the identification of molecularly premalignant lesions. Accordingly, gene expression profiling of microdissected keratinocytes from biopsies containing normal mucosal tissue from nonsmokers and invasive HNSCC will be performed in order to identify potential oral mucosa progression markers (OPM). The interpretation and analysis of the array data will be performed within a newly established Bioinformatics Core. This web-accessible annotation, cataloging facility will use both unsupervised and supervised learning methodologies. The utility of these potential OPMs will then be validated using custom human tissue array samples having the different histologic diagnoses including: normal, reactive, hyperkeratosis, hyperplasia and various grades of dysplasia. These analyses may identify markers that correlate with the biologic severity of dysplasia and with the potential for malignant progression. This molecular analysis may also greatly improve diagnostic prediction compared to the cellular pattern recognition currently used by pathologists.         n/a",Molecular Profiling of Premalignant Oral Lesions,6965411,R01DE015830,"['biomarker', 'cell morphology', 'clinical research', 'gene expression profiling', 'head /neck neoplasm', 'human subject', 'keratinocyte', 'neoplastic transformation', 'oral mucosa', 'preneoplastic state', 'smoking', 'squamous cell carcinoma', 'tobacco abuse']",NIDCR,UNIVERSITY OF CHICAGO,R01,2005,347405,0.10592422494514246
"MRI near Total Joint replacements Project Abstract Overview: The parent project for this supplement aims to provide routine MRI of subjects with total joint replacements by reducing the severe image artifacts near metal, while offering highly efficient patient-specific scans that can detect bone loss, infection, and temperature changes near the implant in clinically feasible scan times. The supplement aims to incorporate deep learning techniques to better meet the parent grant goals. Relevance: Total joint replacements are one of the most successful orthopedic procedures, used annually to reduce pain from joint diseases in about one million patients in the United States (a number projected to double by 2030). However, about 10% of joint replacements fail in 5-10 years due to bone loss (osteolysis), infection, or other complications, often leading to revision surgery. Accurate, early, non-invasive assessment of complications remains limited, but would offer earlier and less invasive treatments, reduce unnecessary surgery, or allow better surgical planning. Approach: Prior to, and during the parent grant period, we have developed novel “multi-spectral imaging” (MSI) MRI techniques that allow visualization of pathology adjacent to metallic implants, and together with other groups have successfully applied them to imaging of patients with devices including joint replacements and spinal fixation hardware. However these methods remain slow, have limited spatial resolution, and are challenging to use routinely. The recent growth of the machine learning field including convolutional neural networks (CNNs), and its application to medical imaging offers unique opportunities to substantially improve MRI near metal, and specifically the goals of the parent grant. We propose 3 small, independent aims in the supplement: (1) to bring fast, isotropic imaging near metal to clinical practice by using CNN-based methods to reduce reconstruction times to under 30 seconds, (2) to improve image quality away from metal by using a new reconstruction and CNN to avoid needing standard imaging in addition to MSI methods and (3) to reduce background-gradient induced artifacts near to metal using a CNN-based approach to enable better diagnosis of abnormalities adjacent to metal. Summary: We aim to supplement our parent grant with CNN-based approaches to speed up scanning and image reconstruction, and to improve image quality near to and way from metal. These techniques will allow routine, non-invasive evaluation for earlier and more accurate detection and treatment of complications in these patients, as well as numerous other applications of MRI near metal implants. Project Narrative There is a growing need for accurate diagnosis of complications surrounding joint arthroplasty, where MRI would provide excellent contrast if not for the fact that the presence of metal severely degrades images. Building on recent ideas in MRI and deep learning, we propose to develop practical methods for routine clinical imaging of patients with metal implants by increasing speed as well as offering image contrast that shows infection and other complications near the metal devices. Ultimately these methods will be tested and offered for widespread use to enable earlier and better treatment of complications resulting from arthroplasty, as well as for better understanding of the implications of different devices.",MRI near Total Joint replacements,9750463,R01EB017739,"['Address', 'Biological Neural Networks', 'Clinical', 'Code', 'Data', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Direct Costs', 'Evaluation', 'Frequencies', 'Goals', 'Grant', 'Gray unit of radiation dose', 'Growth', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Infection', 'Joint repair', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Metals', 'Methods', 'Morphologic artifacts', 'Network-based', 'Operative Surgical Procedures', 'Orthopedic Procedures', 'Osteolysis', 'Pathology', 'Patients', 'Phase', 'Principal Component Analysis', 'Protocols documentation', 'Replacement Arthroplasty', 'Residual state', 'Resolution', 'Scanning', 'Signal Transduction', 'Slice', 'Speed', 'Spinal', 'Stretching', 'Techniques', 'Temperature', 'Testing', 'Time', 'United States', 'Unnecessary Surgery', 'Variant', 'Vendor', 'Work', 'accurate diagnosis', 'arthropathies', 'bone loss', 'clinical imaging', 'clinical practice', 'cluster computing', 'contrast imaging', 'cost', 'deep learning', 'field study', 'image reconstruction', 'imaging approach', 'imaging modality', 'improved', 'learning strategy', 'metallicity', 'novel', 'pain reduction', 'parent grant', 'parent project', 'reconstruction', 'response', 'sample fixation', 'spectrograph']",NIBIB,STANFORD UNIVERSITY,R01,2018,156870,-0.012101078705273058
"Deep Learning in the context of Multispectral optoacoustic tomography Administrative supplement ABSTRACT for Administrative Supplement: Current methods identified at late to identify pancreatic cancer are suboptimal stage resulting in a substantially unmet clinical with the majority of cases need. The current imaging approaches are often limited in spatiotemporal resolution and specificity with high inter- and intra-reader variability in radiological exams that often result in flawed evaluation in identifying pancreatic cancer. Our original grant R01EB020125 aimed to utilize UPRT nanoparticles containing IR780 dye to detect pancreatic cancer using Multispectral optoacoustic tomography (MSOT) imaging. The objective of our administrative supplement is to develop machine learning algorithms to accurately, objectively and consistently assess and distinguish pancreatic cancer versus normal pancreas as utilizing MSOT images. Building upon our experience in theranostic nanoparticles, MSOT imaging, and machine and deep learning, the focus of this supplement is to identify molecular features of pancreatic cancer using MSOT. As MSOT is a new imaging modality, interpreting its images will be challenging for medical professionals. Therefore, we will develop a computer-assisted image analysis (CAIA) system which will help physicians to interpret these images accurately and consistently, minimizing inter-reader variability. Similarly, we will develop and evaluate a machine-learning classifier to quantitatively identify pancreatic cancer. Together, these studies aim to optimize and validate our novel MSOT imaging combined with machine learning to identify pancreatic cancer. This project extends our existing grant which develops a pancreatic tumor targeted nanoparticle detectable using multispectral optoacoustic tomography to include evaluation of the images using deep learning. The deep learning algorithms will segment possible pancreatic cancer regions and identify features to characterize possible pancreatic cancer regions.",Deep Learning in the context of Multispectral optoacoustic tomography Administrative supplement,9750320,R01EB020125,"['Administrative Supplement', 'Algorithms', 'Clinical', 'Computer-Assisted Image Analysis', 'Dyes', 'Evaluation', 'Grant', 'Image', 'Image Analysis', 'Machine Learning', 'Malignant neoplasm of pancreas', 'Medical', 'Methods', 'Molecular', 'Pancreas', 'Physicians', 'Radiology Specialty', 'Reader', 'Resolution', 'Specificity', 'Systems Analysis', 'deep learning', 'experience', 'imaging approach', 'imaging modality', 'nanoparticle', 'novel', 'optoacoustic tomography', 'pancreatic neoplasm', 'spatiotemporal', 'theranostics']",NIBIB,WAKE FOREST UNIVERSITY HEALTH SCIENCES,R01,2018,133300,0.09927333486458818
"Expert System for Personalized Reconstruction of PET Acquisitions The objective of this proposal is to test two hypotheses of the imaging characteristics of positron emission tomography (PET): (1) that substantial improvements in reconstruction quantification can be obtained for positron emission tomography (PET) systems by utilizing an automated, expert system that determines the best algorithm and reconstruction parameters for quantification for a particular lesion in a particular patient; and (2) that determination of the local PSF will allow more accurate and flexible use of the system. Reconstruction is an essential component of PET imaging. Many algorithms have been developed, but the algorithm that gives the most reliable SUV measurement depends in a complicated way on many circumstances of the acquisition, including – but not limited to – count level, lesion size, lesion shape, lesion location, background level and structure (e.g., a lesion near the bladder versus the liver), and patient size. In addition, the quantitative response of that reconstruction depends on parameters of that approach, such as iteration number, point- spread function (PSF) model parameters, filtering, and the particular lesion. We will synthetically embed lesions of known size, shape, location, and activity concentration into an existing data set. This will allow us to know the truth and extract the response of the reconstruction. We can then compensate for this response. In addition, we can process different algorithms and reconstruction parameters to determine the best combination for each lesion in each patient. Our second approach synthetically embeds point-source data very near the lesion, as opposed to embedding a lesion of similar size. This will give us two data sets: with and without the point source. We will then reconstruct both sets and take the difference to estimate the local PSF in reconstruction space. This local PSF can be convolved in reconstruction space with the estimated lesion shape to calculate the estimated bias and noise for an ROI. This second method has the advantage that corrections and variance can be determined for arbitrarily shaped ROIs, but the disadvantage that more processing – and perhaps error propagation – is needed. The specific aims of this proposal include: (i) developing and integrating the initial expert-system tools that will allow for graphical user input and for the execution of ensembles of lesions with the use of different reconstruction algorithms and appropriate ranges for reconstruction parameters; (ii) developing a new method for using embedded point sources to estimate the PSF in each patient's reconstruction as a function of reconstruction algorithm and its associated parameters as an alternative way to estimate bias and variance in SUV measurements; (iii) testing the system with phantoms that have lesions of different size, shape, and SUV values; and (iv) testing the system by embedding clinically relevant lesions of known size, shape, and location, as recommended by our physicians, into archival patient data. This project develops a software framework for efficiently processing PET patient studies to determine the reconstruction algorithm and its parameters that best quantify each lesion in each patient. In addition, quantitative corrections for the reconstruction and the uncertainty are estimated. This tool could allow for personalized PET reconstructions and more accurate quantification of tracer studies for diagnosing and treating diseases, particularly cancers.",Expert System for Personalized Reconstruction of PET Acquisitions,9292307,R21EB021559,"['Accounting', 'Algorithms', 'Archives', 'Area', 'Bladder', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Data', 'Computer software', 'Computers', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Diagnosis', 'Disadvantaged', 'Discipline of Nuclear Medicine', 'Disease', 'Environment', 'Expert Systems', 'Image', 'Knowledge', 'Lesion', 'Letters', 'Liver', 'Location', 'Malignant Neoplasms', 'Measurement', 'Methods', 'Modeling', 'Noise', 'Patients', 'Physicians', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Running', 'Shapes', 'Software Framework', 'Source', 'Structure', 'System', 'Testing', 'Time', 'Tracer', 'Uncertainty', 'Vendor', 'clinically relevant', 'flexibility', 'interest', 'reconstruction', 'response', 'simulation', 'software systems', 'tool', 'uptake']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R21,2017,241500,0.09604126549731672
"Expert System for Personalized Reconstruction of PET Acquisitions The objective of this proposal is to test two hypotheses of the imaging characteristics of positron emission tomography (PET): (1) that substantial improvements in reconstruction quantification can be obtained for positron emission tomography (PET) systems by utilizing an automated, expert system that determines the best algorithm and reconstruction parameters for quantification for a particular lesion in a particular patient; and (2) that determination of the local PSF will allow more accurate and flexible use of the system. Reconstruction is an essential component of PET imaging. Many algorithms have been developed, but the algorithm that gives the most reliable SUV measurement depends in a complicated way on many circumstances of the acquisition, including – but not limited to – count level, lesion size, lesion shape, lesion location, background level and structure (e.g., a lesion near the bladder versus the liver), and patient size. In addition, the quantitative response of that reconstruction depends on parameters of that approach, such as iteration number, point- spread function (PSF) model parameters, filtering, and the particular lesion. We will synthetically embed lesions of known size, shape, location, and activity concentration into an existing data set. This will allow us to know the truth and extract the response of the reconstruction. We can then compensate for this response. In addition, we can process different algorithms and reconstruction parameters to determine the best combination for each lesion in each patient. Our second approach synthetically embeds point-source data very near the lesion, as opposed to embedding a lesion of similar size. This will give us two data sets: with and without the point source. We will then reconstruct both sets and take the difference to estimate the local PSF in reconstruction space. This local PSF can be convolved in reconstruction space with the estimated lesion shape to calculate the estimated bias and noise for an ROI. This second method has the advantage that corrections and variance can be determined for arbitrarily shaped ROIs, but the disadvantage that more processing – and perhaps error propagation – is needed. The specific aims of this proposal include: (i) developing and integrating the initial expert-system tools that will allow for graphical user input and for the execution of ensembles of lesions with the use of different reconstruction algorithms and appropriate ranges for reconstruction parameters; (ii) developing a new method for using embedded point sources to estimate the PSF in each patient's reconstruction as a function of reconstruction algorithm and its associated parameters as an alternative way to estimate bias and variance in SUV measurements; (iii) testing the system with phantoms that have lesions of different size, shape, and SUV values; and (iv) testing the system by embedding clinically relevant lesions of known size, shape, and location, as recommended by our physicians, into archival patient data. This project develops a software framework for efficiently processing PET patient studies to determine the reconstruction algorithm and its parameters that best quantify each lesion in each patient. In addition, quantitative corrections for the reconstruction and the uncertainty are estimated. This tool could allow for personalized PET reconstructions and more accurate quantification of tracer studies for diagnosing and treating diseases, particularly cancers.",Expert System for Personalized Reconstruction of PET Acquisitions,9182252,R21EB021559,"['Accounting', 'Algorithms', 'Archives', 'Area', 'Bladder', 'Blinded', 'Characteristics', 'Clinical Data', 'Computer software', 'Computers', 'Data', 'Data Set', 'Data Sources', 'Detection', 'Diagnosis', 'Disadvantaged', 'Discipline of Nuclear Medicine', 'Disease', 'Environment', 'Expert Systems', 'Image', 'Knowledge', 'Lesion', 'Letters', 'Liver', 'Location', 'Malignant Neoplasms', 'Measurement', 'Methods', 'Modeling', 'Noise', 'Patients', 'Physicians', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Running', 'Shapes', 'Software Framework', 'Source', 'Structure', 'System', 'Testing', 'Time', 'Tracer', 'Uncertainty', 'Vendor', 'clinically relevant', 'flexibility', 'interest', 'reconstruction', 'response', 'simulation', 'software systems', 'tool', 'uptake']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R21,2016,201250,0.09604126549731672
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Abstract Selective internal radiation therapy (SIRT) with preferential delivery of 90Y microspheres to target lesions has shown promising response rates with limited toxicity in the treatment of hepatocellular (HCC), the second leading cause of cancer death in the world. However, to achieve more durable responses, there is much room to improve/adapt the treatment to ensure that all lesions and lesion sub-regions receive adequate radiation delivery. While externally delivered stereotactic body radiation therapy (SBRT) is well suited for smaller solitary HCC, its application for larger or multifocal disease is challenged by the radiation tolerance of the normal liver parenchyma. A dosimetry guided combined approach that exploits complementary advantages of internal and external radiation delivery can be expected to improve treatment of HCC. To make this transition, however, prospective clinical trials establishing safety are needed. Furthermore, for routine clinic use, accurate and fast voxel-level dose estimation in internal radionuclide therapy, that lags behind external beam therapy dosimetry, is still needed. Our long-term goal is to improve the efficacy of radiation therapy with personalized dosimetry guided treatment. Our objective in this application is to demonstrate that it is possible to use 90Y imaging based absorbed dose estimates after SIRT to safely deliver external radiation to target regions (voxels) that are predicted to be underdosed and to develop deep learning based tools to make voxel-level internal dose estimation practical for routine clinic use. Specifically, in Aim 1, we will perform a Phase 1 clinical trial in HCC patients where we will take the novel approach of using the 90Y PET/CT derived absorbed dose map after SIRT to deliver SBRT to tumor regions predicted to be underdosed based on previously established dose-response models. The primary objective of the trial is to obtain estimates of safety of combined SIRT+SBRT for future Phase II trial design. In parallel, in Aim 2, building on promising initial results we will develop novel deep learning based tools for 90Y PET/CT and SPECT/CT reconstruction, joint reconstruction-segmentation and scatter estimation under the low count-rate setting, typical for 90Y. These methods have a physics/mathematics foundation, where convolutional neural networks (CNNs) are included within the iterative reconstruction process, instead of post-reconstruction denoising. In Aim 3, we will develop a CNN for fast voxel-level dosimetry and combine with the CNNs of Aim 2 to develop an innovative end-to-end framework with unified dosimetry-task based training. At the end of this study, we will be ready to use the new deep learning tools in a Phase II trial to demonstrate enhanced efficacy with SIRT+SBRT compared with SIRT alone and advance towards our long- term goal. This will accelerate adoption of these next-generation tools in clinical practice and will have a significant positive impact because treatment based on patient specific dosimetry will substantially improve efficacy, compared with current standard practice in SIRT. Although we focus on 90Y SIRT, our tools will be applicable in radionuclide therapy in general, a rapidly advancing treatment option. Narrative We will perform a Phase I clinical trial where standard-of-care Y-90 microsphere radioembolization in hepatocellular carcinoma will be followed by external radiation to target regions that are predicted to be underdosed by Y-90, based on patient specific dosimetry. In parallel, we will develop and test voxel-level internal dosimetry tools using convolution neural networks to make such dosimetry-based planning accurate and fast for routine clinic use. This study is relevant to public health because a dosimetry-guided combination radiation treatment approach is likely to substantially improve patient outcome compared to current standard practice of internal or external radiation only.",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,10052989,R01EB022075,"['90Y', 'Address', 'Adoption', 'Cancer Etiology', 'Cessation of life', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Complex', 'Data', 'Disease', 'Dose', 'Ensure', 'Evaluable Disease', 'External Beam Radiation Therapy', 'Failure', 'Foundations', 'Funding', 'Future', 'Goals', 'Hepatotoxicity', 'Image', 'Joint repair', 'Joints', 'Lesion', 'Liver', 'Liver parenchyma', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Methods', 'Microspheres', 'Modality', 'Modeling', 'Motivation', 'Noise', 'PET/CT scan', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Photons', 'Physics', 'Pilot Projects', 'Positron-Emission Tomography', 'Primary carcinoma of the liver cells', 'Process', 'Public Health', 'Radiation', 'Radiation Dose Unit', 'Radiation Tolerance', 'Radiation therapy', 'Radioembolization', 'Radionuclide therapy', 'Reporting', 'Safety', 'Scanning', 'Testing', 'Time', 'Toxic effect', 'Training', 'base', 'clinical practice', 'clinically relevant', 'convolutional neural network', 'deep learning', 'denoising', 'dosimetry', 'image reconstruction', 'imaging Segmentation', 'improved', 'innovation', 'internal radiation', 'learning strategy', 'multimodal data', 'multimodality', 'next generation', 'novel', 'novel strategies', 'personalized cancer therapy', 'phase II trial', 'prospective', 'radiation delivery', 'reconstruction', 'response', 'single photon emission computed tomography', 'standard of care', 'tool', 'trial design', 'tumor']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,670584,0.03415440093387247
"Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment Supplement Title: Deep learning-based methods for PET image reconstruction and segmentation to enhance radionuclide therapy dosimetry Abstract There is much recent interest in quantitative imaging of yttrium-90 (Y-90) for dosimetry because of the promise of novel Y-90 labelled radionuclide therapies. Deep learning methods are well suited for addressing the challenges of Y-90 positron emission tomography (PET) imaging, where compared with diagnostic FDG PET, true coincidence count-rates are very low while random coincidences are high. The potential of deep learning-based algorithms to outperform conventional algorithms in medical imaging is well recognized, however research in applying these methods to nuclear medicine imaging modalities such as PET is very limited. The few studies applying deep learning to PET imaging have been mostly limited to post-reconstruction image processing/analysis for denoising and feature extraction, and not in the image formation/reconstruction process. Additionally, deep learning research in PET thus far have focused on improving diagnostic imaging, not quantitative imaging, which together with accurate lesion/organ segmentation are pre-requisite for accurate dosimetry. In this supplement, we propose to develop and evaluate deep learning-based image reconstruction and lesion/organ segmentation for low count PET applications such as Y-90 PET. Our approach starts with the raw projection data and utilizes a deep recurrent network in the image formation process. Because the two tasks are mutually dependent, our formalism takes the novel approach of joint reconstruction-segmentation with multi-modality (PET/CT) data. Specifically, we will 1) develop and evaluate Y-90 PET image reconstruction with a deep recurrent network for the regularizer, 2) develop and evaluate deep-learning based joint PET segmentation-reconstruction using multi- modal 90Y PET/CT data. To train/validate/test the proposed methods, we will use clinically realistic phantom measurements and simulations as well as leverage on existing patient data from the parent grant where thus far, PET data and radiologist defined morphologic liver/lesion contours for over 50 cases and 150 lesions are available. We will compare the new Y-90 PET reconstruction with the formulation we recently developed under the parent grant (using conventional untrained regularizers) that showed promising results but suffered from resolution- noise tradeoff. The expected outcome of this work is a well validated deep learning reconstruction- segmentation framework for challenging PET imaging applications where conventional methods are suboptimal. The proposed research is expected to result in new and accurate tools for quantitative image reconstruction and lesion/organ segmentation that have the potential to contribute significantly toward improving dosimetry in internal radionuclide therapy such as Yttrium- 90 radioembolization in liver malignancies. This study is relevant to public health because a dosimetry-guided personalized approach to radionuclide therapy is highly likely to substantially improve patient outcomes compared to current standard practice. !",Imaging and Dosimetry of Yttrium-90 for Personalized Cancer Treatment,9750430,R01EB022075,"['90Y', 'Address', 'Algorithms', 'Clinical', 'Data', 'Diagnostic', 'Diagnostic Imaging', 'Discipline of Nuclear Medicine', 'Formulation', 'Image', 'Joint repair', 'Joints', 'Label', 'Lesion', 'Liver', 'Malignant Neoplasms', 'Measurement', 'Medical Imaging', 'Methods', 'Modality', 'Morphology', 'Noise', 'Organ', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Positron-Emission Tomography', 'Process', 'Public Health', 'Radioembolization', 'Radionuclide therapy', 'Recurrence', 'Research', 'Resolution', 'Testing', 'Training', 'Work', 'base', 'deep learning', 'dosimetry', 'image processing', 'image reconstruction', 'imaging Segmentation', 'imaging modality', 'improved', 'interest', 'learning strategy', 'novel', 'novel strategies', 'parent grant', 'personalized approach', 'personalized cancer therapy', 'quantitative imaging', 'radiologist', 'reconstruction', 'simulation', 'tool']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2018,102093,0.13158493669515797
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9764151,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'colorectal cancer prevention', 'computer aided detection', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'innovation', 'minimally invasive', 'mortality', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,461656,0.12084034487279884
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9566185,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'colorectal cancer prevention', 'computer aided detection', 'cost', 'deep learning', 'improved', 'innovation', 'minimally invasive', 'mortality', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,436007,0.12084034487279884
"Deep radiomic decision support system for colorectal cancer Project Summary/Abstract Computer-aided detection (CADe) has been shown to increase readers’ sensitivity and reduce inter-observer variance in detecting abnormalities in medical images. However, they prompt relatively large numbers of false positives (FPs) that readers find tedious to review and, during this process, the readers can incorrectly dismiss true lesions prompted correctly to them by CADe systems. Thus, there is a demand for an advanced decision support system that would provide not only high detection sensitivity, but also high specificity while being able to explain why a specific location was prompted as a lesion. In this project, we propose to improve the detection specificity of CADe by deep convolutional neural networks (DCNNs) that can analyze the extrinsic radiomic phenotype, such as the context of local anatomy, of target lesions, whereas current CADe systems consider only the intrinsic radiomic phenotype, such as the shape and texture of detected lesions. Further, we can use DCNNs to provide an explanation of why a specific location was prompted by using anatomically meaningful object categories with similar-image retrieval of past diagnosed cases. In this project, we will focus on computed tomographic colonography (CTC), which is a minimally invasive screening method for early detection of colorectal lesions to prevent colorectal cancer (CRC), which is the second leading cause of cancer deaths in the United States. Historically, however, only adenomas were believed to be precursors of CRC. Recent studies have revealed a molecular pathway where also serrated lesions can develop into CRC. Recent studies have indicated that CTC can detect serrated lesions accurately based upon the phenomenon called contrast coating. Thus, the goal of this project is to develop a deep radiomic decision support (DeepDES) system that leverages deep learning for providing high sensitivity and specificity in the detection of colorectal lesions, in particular, serrated lesions, and for providing diagnostic information that explains why a specific location was prompted as a lesion to assist readers in assessing detected lesions correctly. To achieve the goal, we will explore the following specific aims: (1) Develop a radiomic deep-learning (RAID) scheme for the detection of colorectal lesions, (2) develop a DeepDES system for diagnosis of detected lesions, and (3) evaluate the clinical benefit of DeepDES system. Successful development of the proposed DeepDES system will provide an advanced decision support that addresses the current concerns about CADe by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States. Project Narrative Successful development of the proposed deep radiomic decision support (DeepDES) system will provide an advanced decision support that addresses the current concerns about computer-aided detection (CADe) by yielding both high detection sensitivity and high specificity while being able to explain why a specific location was prompted as a target lesion. Such a system is expected to outperform current state-of-the-art CADe systems in the diagnosis of colorectal lesions, in particular, serrated lesions. Broad adoption and use of the DeepDES system will advance the prevention and early diagnosis of cancer, and thus will ultimately reduce mortality from colorectal cancer in the United States.",Deep radiomic decision support system for colorectal cancer,9288493,R01EB023942,"['3-Dimensional', 'Address', 'Adoption', 'Anatomy', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Carcinoma', 'Categories', 'Cessation of life', 'Clinical', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Simulation', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Early Diagnosis', 'Evaluation', 'Goals', 'Guidelines', 'Human', 'Image', 'Learning', 'Lesion', 'Location', 'Machine Learning', 'Medical Imaging', 'Methods', 'Molecular', 'Multi-Institutional Clinical Trial', 'Optics', 'Pathway interactions', 'Performance', 'Phenotype', 'Prevention', 'Problem Solving', 'Process', 'Psychological Transfer', 'Reader', 'Retrieval', 'Safety', 'Scheme', 'Sensitivity and Specificity', 'Shapes', 'Specificity', 'System', 'Testing', 'Texture', 'Time', 'Training', 'United States', 'adenoma', 'base', 'cancer diagnosis', 'computer aided detection', 'cost', 'improved', 'innovation', 'minimally invasive', 'mortality', 'prevent', 'radiologist', 'radiomics', 'screening', 'success']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R01,2017,436007,0.12084034487279884
"Deep radiomic colon cleansing for laxative-free CT colonography Project Summary/Abstract Colon cancer, the second leading cause of cancer deaths for men and women in the United States, can be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC), also known as virtual colonoscopy, could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, an FDA panel has recently identified two remaining concerns about CTC: patient adherence, and the detection of small polyps and flat lesions. Our clinical multi-center trial showed that laxative-free preparation by oral ingestion of a contrast agent (iodine) to indicate fecal materials for electronic cleansing (EC), followed by computer-aided detection (CADe), makes CTC easy to tolerate for patients while enabling the detection of ≥10 mm lesions at sensitivity comparable to that of optical colonoscopy. However, small polyps and flat lesions were a significant source of false negatives, because EC produced image artifacts that imitated such lesions. Because laxative-free CTC addresses the concern of patient adherence, the only remaining concern about CTC is the detection of small polyps and flat lesions. The goal of this project is to develop a novel multi-material deep-learning scheme, hereafter denoted as Deep- ECAD, that integrates EC and CADe for the detection of small polyps and flat lesions in laxative-free spectral CTC (spCTC), where spectral imaging and deep learning will be used to overcome the above limitations of conventional CTC. Our specific aims are to (1) establish a laxative-free ultra-low-dose spCTC image database, (2) develop a multi-material deep-learning method for EC, (3) develop deep radiomic detection of small polyps and flat lesions, and (4) evaluate the clinical benefit of Deep-ECAD with laxative-free cases. Successful development of the proposed Deep-ECAD scheme will substantially improve human readers’ performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free spCTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Successful development of the proposed deep-learning EC-CADe scheme for detecting small polyps and flat lesions in ultra-low-dose laxative-free spCTC (Deep-ECAD) will substantially improve reader performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free CTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Deep radiomic colon cleansing for laxative-free CT colonography,9297792,R21EB024025,"['Address', 'Advisory Committees', 'Air', 'Area', 'Benefits and Risks', 'Cancer Etiology', 'Carcinoma', 'Cessation of life', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Assisted', 'Consensus', 'Contrast Media', 'Databases', 'Dehydration', 'Detection', 'Development', 'Diagnosis', 'Diarrhea', 'Dose', 'E-learning', 'Early Diagnosis', 'Excision', 'Feces', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Ingestion', 'Intestines', 'Iodine', 'Learning', 'Lesion', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical Societies', 'Medicare', 'Methods', 'Morphologic artifacts', 'Multi-Institutional Clinical Trial', 'Optics', 'Oral', 'Osmolar Concentration', 'Patients', 'Performance', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Population', 'Preparation', 'Problem Solving', 'Radiation', 'Reader', 'Risk', 'Safety', 'Scheme', 'Societies', 'Source', 'Thinness', 'United States', 'Woman', 'base', 'compliance behavior', 'computer aided detection', 'cost', 'image processing', 'improved', 'laxative', 'learning strategy', 'men', 'minimally invasive', 'mortality', 'novel', 'older patient', 'prevent', 'radiation risk', 'radiologist', 'radiomics', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2017,256500,0.06349358525005153
"Deep radiomic colon cleansing for laxative-free CT colonography Project Summary/Abstract Colon cancer, the second leading cause of cancer deaths for men and women in the United States, can be prevented by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC), also known as virtual colonoscopy, could substantially increase the capacity, safety, and patient compliance of colorectal examinations. However, an FDA panel has recently identified two remaining concerns about CTC: patient adherence, and the detection of small polyps and flat lesions. Our clinical multi-center trial showed that laxative-free preparation by oral ingestion of a contrast agent (iodine) to indicate fecal materials for electronic cleansing (EC), followed by computer-aided detection (CADe), makes CTC easy to tolerate for patients while enabling the detection of ≥10 mm lesions at sensitivity comparable to that of optical colonoscopy. However, small polyps and flat lesions were a significant source of false negatives, because EC produced image artifacts that imitated such lesions. Because laxative-free CTC addresses the concern of patient adherence, the only remaining concern about CTC is the detection of small polyps and flat lesions. The goal of this project is to develop a novel multi-material deep-learning scheme, hereafter denoted as Deep- ECAD, that integrates EC and CADe for the detection of small polyps and flat lesions in laxative-free spectral CTC (spCTC), where spectral imaging and deep learning will be used to overcome the above limitations of conventional CTC. Our specific aims are to (1) establish a laxative-free ultra-low-dose spCTC image database, (2) develop a multi-material deep-learning method for EC, (3) develop deep radiomic detection of small polyps and flat lesions, and (4) evaluate the clinical benefit of Deep-ECAD with laxative-free cases. Successful development of the proposed Deep-ECAD scheme will substantially improve human readers’ performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free spCTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer. Project Narrative Successful development of the proposed deep-learning EC-CADe scheme for detecting small polyps and flat lesions in ultra-low-dose laxative-free spCTC (Deep-ECAD) will substantially improve reader performance in the detection of small polyps and flat lesions while minimizing the inconveniences of bowel preparation and radiation risk to patients. Such a scheme will make laxative-free CTC a highly accurate and acceptable screening option for large populations, in particular, Medicare population, leading to an increased screening rate, promoting early diagnosis of colon cancer, and ultimately reducing mortality due to colon cancer.",Deep radiomic colon cleansing for laxative-free CT colonography,9523172,R21EB024025,"['Address', 'Advisory Committees', 'Air', 'Area', 'Benefits and Risks', 'Cancer Etiology', 'Carcinoma', 'Cessation of life', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Colorectal Cancer', 'Computed Tomographic Colonography', 'Computer Assisted', 'Consensus', 'Contrast Media', 'Databases', 'Dehydration', 'Detection', 'Development', 'Diagnosis', 'Diarrhea', 'Dose', 'E-learning', 'Early Diagnosis', 'Excision', 'Feces', 'Goals', 'Guidelines', 'Height', 'Human', 'Image', 'Intestines', 'Iodine', 'Learning', 'Lesion', 'Low Dose Radiation', 'Malignant Neoplasms', 'Medical Societies', 'Medicare', 'Methods', 'Morphologic artifacts', 'Multi-Institutional Clinical Trial', 'Optics', 'Oral Ingestion', 'Osmolar Concentration', 'Patients', 'Performance', 'Polypectomy', 'Polypoid Lesion', 'Polyps', 'Population', 'Preparation', 'Problem Solving', 'Radiation', 'Reader', 'Risk', 'Safety', 'Scheme', 'Societies', 'Source', 'Thinness', 'United States', 'Woman', 'base', 'compliance behavior', 'computer aided detection', 'cost', 'deep learning', 'image processing', 'improved', 'laxative', 'learning strategy', 'men', 'minimally invasive', 'mortality', 'novel', 'older patient', 'prevent', 'radiation risk', 'radiologist', 'radiomics', 'screening', 'soft tissue', 'spectrograph', 'virtual']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R21,2018,213750,0.06349358525005153
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9521289,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2018,471965,0.042974811452598224
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9783816,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,438449,0.042974811452598224
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9997914,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,498014,0.042974811452598224
"QuBBD: Deep Poisson Methods for Biomedical Time-to-Event and Longitude Data  The proposed research directly addresses the mission of NIH's BD2K initiative by developing appropriate tools to derive novel insights from available Big Data and by adapting sophisticated machine learning methodology to a framework familiar to biomedical researchers. This new methodology will be one of the first to enable use of machine learning techniques with time-to-event and continuous longitudinal outcome data, and will be the first such extension of the deep Poisson model. In essence, this undertaking builds the missing bridge between the need for advanced prognostic and predictive techniques among biomedical and clinical researchers and the unrealized potential of deep learning methods in the context of biomedical data collected longitudinally. To facilitate smooth adoption in clinical research, the results will be translated into terms familiar to applied practitioners through publications and well-described software packages. The application of the methodology developed will be illustrated using data from the NIH dbGAP repository, thereby further promoting the use of open access data sources. Optimal risk models are essential to realize the promise of precision medicine. This project develops novel machine learning methods for time-to-event and continuous longitudinal data to enhance risk model performance by exploiting correlations between large numbers of predictors and genetic data. This will enable biomedical researchers to better stratify patients in terms of their likelihood of response to multiple therapies.",QuBBD: Deep Poisson Methods for Biomedical Time-to-Event and Longitude Data ,9771473,R01EB025020,"['Address', 'Adoption', 'Advanced Development', 'Architecture', 'Big Data', 'Big Data to Knowledge', 'Blood Glucose', 'Blood Pressure', 'Categories', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Research', 'Comorbidity', 'Computer software', 'Data', 'Data Sources', 'Development', 'Electronic Health Record', 'Event', 'Factor Analysis', 'Formulation', 'Funding', 'Gaussian model', 'Genetic', 'Hazard Models', 'Health system', 'Individual', 'Link', 'Lipids', 'Machine Learning', 'Medical Genetics', 'Medical History', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Noise', 'Outcome', 'Performance', 'Persons', 'Pharmacology', 'Principal Investigator', 'Publications', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Risk stratification', 'Specific qualifier value', 'Structure', 'Techniques', 'Time', 'Translating', 'Translations', 'United States National Institutes of Health', 'Work', 'analog', 'cardiovascular disorder epidemiology', 'data access', 'data modeling', 'database of Genotypes and Phenotypes', 'deep learning', 'genetic information', 'hazard', 'insight', 'learning algorithm', 'learning strategy', 'multimodality', 'novel', 'patient stratification', 'practical application', 'precision medicine', 'prognostic', 'repository', 'response', 'risk prediction model', 'semiparametric', 'temporal measurement', 'time use', 'tool', 'treatment response']",NIBIB,DUKE UNIVERSITY,R01,2019,251983,0.0012734858322508422
"QuBBD: Deep Poisson Methods for Biomedical Time-to-Event and Longitude Data  The proposed research directly addresses the mission of NIH's BD2K initiative by developing appropriate tools to derive novel insights from available Big Data and by adapting sophisticated machine learning methodology to a framework familiar to biomedical researchers. This new methodology will be one of the first to enable use of machine learning techniques with time-to-event and continuous longitudinal outcome data, and will be the first such extension of the deep Poisson model. In essence, this undertaking builds the missing bridge between the need for advanced prognostic and predictive techniques among biomedical and clinical researchers and the unrealized potential of deep learning methods in the context of biomedical data collected longitudinally. To facilitate smooth adoption in clinical research, the results will be translated into terms familiar to applied practitioners through publications and well-described software packages. The application of the methodology developed will be illustrated using data from the NIH dbGAP repository, thereby further promoting the use of open access data sources. Optimal risk models are essential to realize the promise of precision medicine. This project develops novel machine learning methods for time-to-event and continuous longitudinal data to enhance risk model performance by exploiting correlations between large numbers of predictors and genetic data. This will enable biomedical researchers to better stratify patients in terms of their likelihood of response to multiple therapies.",QuBBD: Deep Poisson Methods for Biomedical Time-to-Event and Longitude Data ,9532186,R01EB025020,"['Address', 'Adoption', 'Advanced Development', 'Algorithms', 'Architecture', 'Big Data', 'Big Data to Knowledge', 'Blood Glucose', 'Blood Pressure', 'Categories', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Research', 'Comorbidity', 'Computer software', 'Data', 'Data Sources', 'Development', 'Electronic Health Record', 'Event', 'Factor Analysis', 'Formulation', 'Funding', 'Gaussian model', 'Genetic', 'Gray unit of radiation dose', 'Hazard Models', 'Health system', 'Individual', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical Genetics', 'Medical History', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Modality', 'Modeling', 'Noise', 'Outcome', 'Performance', 'Persons', 'Pharmacology', 'Principal Investigator', 'Publications', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Risk stratification', 'Specific qualifier value', 'Structure', 'Techniques', 'Time', 'Translating', 'Translations', 'United States National Institutes of Health', 'Work', 'analog', 'cardiovascular disorder epidemiology', 'data access', 'data modeling', 'database of Genotypes and Phenotypes', 'deep learning', 'genetic information', 'hazard', 'insight', 'learning strategy', 'novel', 'patient stratification', 'practical application', 'precision medicine', 'predictive modeling', 'prognostic', 'repository', 'response', 'semiparametric', 'temporal measurement', 'time use', 'tool', 'treatment response']",NIBIB,DUKE UNIVERSITY,R01,2018,259358,0.0012734858322508422
"QuBBD: Deep Poisson Methods for Biomedical Time-to-Event and Longitude Data  The proposed research directly addresses the mission of NIH's BD2K initiative by developing appropriate tools to derive novel insights from available Big Data and by adapting sophisticated machine learning methodology to a framework familiar to biomedical researchers. This new methodology will be one of the first to enable use of machine learning techniques with time-to-event and continuous longitudinal outcome data, and will be the first such extension of the deep Poisson model. In essence, this undertaking builds the missing bridge between the need for advanced prognostic and predictive techniques among biomedical and clinical researchers and the unrealized potential of deep learning methods in the context of biomedical data collected longitudinally. To facilitate smooth adoption in clinical research, the results will be translated into terms familiar to applied practitioners through publications and well-described software packages. The application of the methodology developed will be illustrated using data from the NIH dbGAP repository, thereby further promoting the use of open access data sources. Optimal risk models are essential to realize the promise of precision medicine. This project develops novel machine learning methods for time-to-event and continuous longitudinal data to enhance risk model performance by exploiting correlations between large numbers of predictors and genetic data. This will enable biomedical researchers to better stratify patients in terms of their likelihood of response to multiple therapies.",QuBBD: Deep Poisson Methods for Biomedical Time-to-Event and Longitude Data ,9392642,R01EB025020,"['Address', 'Adoption', 'Advanced Development', 'Algorithms', 'Architecture', 'Big Data', 'Big Data to Knowledge', 'Blood Glucose', 'Blood Pressure', 'Categories', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Research', 'Comorbidity', 'Computer software', 'Data', 'Data Sources', 'Development', 'Electronic Health Record', 'Event', 'Factor Analysis', 'Formulation', 'Funding', 'Gaussian model', 'Genetic', 'Gray unit of radiation dose', 'Hazard Models', 'Health system', 'Individual', 'Learning', 'Link', 'Lipids', 'Machine Learning', 'Medical Genetics', 'Medical History', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Modality', 'Modeling', 'Noise', 'Outcome', 'Performance', 'Persons', 'Pharmacology', 'Principal Investigator', 'Publications', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Risk stratification', 'Specific qualifier value', 'Structure', 'Techniques', 'Time', 'Translating', 'Translations', 'United States National Institutes of Health', 'Work', 'analog', 'cardiovascular disorder epidemiology', 'data access', 'data modeling', 'database of Genotypes and Phenotypes', 'genetic information', 'hazard', 'insight', 'learning strategy', 'novel', 'patient stratification', 'practical application', 'precision medicine', 'predictive modeling', 'prognostic', 'repository', 'response', 'semiparametric', 'temporal measurement', 'time use', 'tool', 'treatment response']",NIBIB,DUKE UNIVERSITY,R01,2017,262150,0.0012734858322508422
"Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data NARRATIVE SUMMARY The landscape of data formats is rapidly expanding, with image, text and other complex formats becoming available for health related outcomes. By considering such data within the context of observational causal inference, they can be leveraged to improve clinical decisions, help evaluate treatment efficacy by estimating individualized treatment effects and help develop intelligent therapeutic systems where individualized treatments can be deployed. In R01EB025021, we concentrate on understanding how nearly exact matching can be achieved in the presence of a large number of categorical covariates. The proposed approach (called FLAME - Fast Large Almost Matching Exactly) is able to quickly learn which categorical covariates are important and to produce high quality matches \citep{wang2017flame,dieng2018collapsing}. The main shortfall in the proposed work for R01EB025021 is that it does not naturally extend to more complex data types, it only works for categorical data in which each feature is meaningful. {\bf This proposal will develop new statistical and computational tools for causal analysis of complex data structures.} Our new approach is called {\emph Matching After Learning to Stretch (MALTS)}. For each unit (e.g. patient), we propose learn a latent representation of their covariate information and a distance metric on the latent space such that units that are matched tend to provide accurate estimates of treatment effect. MALTS can use deep learning to encode the latent representations for the units, or it can learn basis transformations in linear space (stretching and rotation matrices) for simpler continuous data types. We will develop the MALTS algorithm, and apply it in a medical context. Our goal is to construct high quality matches for the following types of data: (i) medical images, such as x-rays and CT scans, (ii) medical record data, (iii) time series data (continuous EEG data), (iv) a combination of any of the first three types of data. We aim to leverage the newly developed tools to continue our evaluation of the efficacy of isolation for flu-like ailments as well as to apply them more broadly to publicly available modern datasets such as the MIMIC III database. Reliable and consistent causal analysis of public health interventions requires the use of massive previously unavailable datastreams. For example, evaluation of the efficacy of isolation interventions on flu-like-illness spread must include information on friendships and interactions between individuals, biometric information, imaging, longitudinal health record data as well as standard demographic data. The proposed research provides machine learning and deep learning tools for properly employing this data for the identification and quantification of causal effects of such treatments that can lead to the development of better public health interventions.",Machine Learning and Deep Learning Solutions Supplement: Matching Methods for Causal Inference with Complex Data,9750434,R01EB025021,"['Algorithms', 'Biometry', 'Categories', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Electroencephalography', 'Friendships', 'Goals', 'Health', 'Image', 'Individual', 'Intervention', 'Lead', 'Learning', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medical Records', 'Methods', 'Modernization', 'Outcome', 'Patients', 'Research', 'Roentgen Rays', 'Rotation', 'Series', 'Stretching', 'Structure', 'System', 'Text', 'Therapeutic', 'Time', 'Treatment Efficacy', 'Work', 'X-Ray Computed Tomography', 'computerized tools', 'data format', 'deep learning', 'efficacy evaluation', 'flu', 'health record', 'improved', 'individualized medicine', 'novel strategies', 'public health intervention', 'tool', 'treatment effect']",NIBIB,DUKE UNIVERSITY,R01,2018,98714,0.01955977070125877
"Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery Abstract  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques to quantitative image analysis and image reconstruction. There are 12 specific NIH projects that will benefit from the proposed computing infrastructure system. We present the 12 projects through examples from within four Specific Research Topics areas: (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The proposed system is a computing cluster, which uses ScaleMP's Versatile SMP software to aggregate the cluster nodes into a single symmetric multiprocessing computer. The major hardware components consist of 1 HP Enterpris\e ProLiant DL380 server and 8 Apollo 6500 compute nodes, with a total of 2.1 TB of main memory, 18 Intel Xeon E5-2640v4 10-core CPUs, and 32 nVidia Tesla P100 GPUs. The servers will be connected via a 100Gbps EDR Infiniband network. In addition, three important software components, which aim to reduce the complexity of the computing environment and increase researcher productivity, will be integrated into the hardware components: the aforementioned ScaleMP vSMP to create a single virtual computer from the cluster nodes, Cendio ThinLinc to provide remote desktop graphical login services, and Bitfusion Flex AI Platform which provides GPU virtualization, scheduling, and optimization, as well as curated container deployment of common deep learning frameworks. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many-dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA- compliant sharable environment. Project Narrative  Development of emerging imaging systems for biological and medical imaging often involves multi-dimensional acquisition protocols and thus correspondingly the need for complex reconstruction algorithms and advanced machine learning algorithms in order to produce the desired resulting image and quantitative tumor characteristics. This proposal requests funding for a high performance computing system, entitled Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery, to further the development and application of deep learning techniques within four Specific Research Topics areas of (a) tomographic image reconstruction, (b) quantitative image analysis, (c) functional quantification, and (d) association of radiomics (image data) with phenotypic and genomic data. The Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery will allow researchers to expedite, extend, and translate their current NIH funding in areas of many- dimensional image reconstruction and image analysis algorithms – all of which will benefit greatly from deep learning approaches – within a secure, protected, and HIPAA-compliant sharable environment.",Protected Radiomics Analysis Commons for Deep Learning in Biomedical Discovery,9494294,S10OD025081,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Characteristics', 'Complex', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Development', 'Dimensions', 'Environment', 'Funding', 'Health Insurance Portability and Accountability Act', 'High Performance Computing', 'Image', 'Image Analysis', 'Machine Learning', 'Medical Imaging', 'Memory', 'Productivity', 'Protocols documentation', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Schedule', 'Secure', 'Services', 'System', 'Techniques', 'Translating', 'United States National Institutes of Health', 'biological systems', 'cluster computing', 'computer cluster', 'deep learning', 'genomic data', 'image reconstruction', 'imaging system', 'phenotypic data', 'quantitative imaging', 'radiomics', 'reconstruction', 'tomography', 'tumor', 'virtual']",OD,UNIVERSITY OF CHICAGO,S10,2018,338913,0.1345609252398696
"Acquisition of a next-generation computing cluster We request funds to purchase our next-generation computing cluster to support computationally intensive NIH-funded research at Washington University in St. Louis. This system will become the foundation of the Center for High Performance Computing (CHPC) to support our active, diverse user community. It has been designed to meet our current and future computing needs. It adds additional capabilities to support emerging fields such as “Deep Learning”. The CHPC currently supports over 775 users from 300 different groups across 33 departments. 58 papers have cited the CHPC. The Center has a proven funding model and is economically sustainable. The Center has partnered with other University organizations to offer training workshops, not only on the use of the cluster, but also on introductory programming for users with no prior programming experience. If this proposal is funded, we will be able to continue to support this ever-growing diverse community of researchers. The proposed system would replace critical components including the management node, the login nodes, the storage, and upgrade the Infiniband networking. We would add substantial upgrades to our computing power with state-of-the-art processors, increased memory capacity for growing jobs, General Purpose Graphical Processing units (GPGPUs), and new capabilities for “Deep Learning”. Nearly all fields of NIH-funded research are faced with increasingly large data sets that require additional computing power to analyze. We propose building a next-generation computing cluster to support this research. Our Center has a proven track record in supporting a large, diverse group of users in all aspects of their computationally demanding research.",Acquisition of a next-generation computing cluster,9707936,S10OD025200,"['Communities', 'Educational workshop', 'Foundations', 'Funding', 'Future', 'High Performance Computing', 'Memory', 'Modeling', 'Occupations', 'Paper', 'Research', 'Research Personnel', 'System', 'Training', 'United States National Institutes of Health', 'Universities', 'Washington', 'cluster computing', 'deep learning', 'design', 'experience', 'next generation']",OD,WASHINGTON UNIVERSITY,S10,2019,597200,0.04125070505101017
"Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning Cerebrovascular disease remains a common cause of death and major disability in the United States, and identifying and preventing strokes should be a high priority. Direct measurement of regional cerebral blood flow (CBF) is challeng- ing in these patients, since we do not have a non-invasive, radiation-free imaging method that has been appropriately validated against gold standard techniques. This is important, because there is compelling evidence that measuring the CBF change before and after a stress test meant to increase CBF (a measurement known as cerebrovascular reserve [CVR]) can identify patients at increased stroke risk. Stress tests have been a mainstay of the diagnostic workup of cardiology patients for many years, and we believe strongly that their use will benefit cerebrovascular disease patients as well. The goal of this project is to improve the quality of arterial spin label (ASL) MRI using deep learning, a powerful form of machine learning, that is currently undergoing tremendous progress. We will then to apply this in a prospective, adaptive validation trial against oxygen-15 water PET CBF, using simultaneous PET/MRI to minimize biological variability. Finally, we will apply this improv- ed tool to study the effects of gender on CVR and its reproducibility. Successful completion of this study will result in a validated methodology to assess CVR in cerebrovascular disease patients without the use of radiation or contrast. As such, it will provide solid, evidence-based recommendations for clinicians developing new paradigms and interventions in patients with impaired CVR. There is strong evidence that imaging of cerebrovascular reserve (CVR), the ability to increase cerebral blood flow (CBF) in response to a challenge, can identify patients at increased risk of stroke. Therefore, measuring CVR would be extremely useful for designing clinical trials of interventions to mitigate this risk. However, current methods to measure CBF and CVR are suboptimal, and do not work well in patients with cerebrovascular disease. The goals of this project are • to improve non-contrast, radiation-free arterial spin label MRI methods  using deep learning, a powerful form of artificial intelligence that has  shown tremendous progress for computer vision • to validate these methods against a CBF gold-standard, oxygen-15 water  PET, using simultaneous PET/MRI, using an adaptive “play-the-winner” strategy • to apply them to assess gender differences in CVR and test their  reproducibility, with the goal of establishing age and gender normative  ranges to better identify outliers.",Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning,10181176,R01EB025220,"['Acetazolamide', 'Address', 'Age', 'Artificial Intelligence', 'Biological', 'Blood flow', 'Brain', 'Brain imaging', 'Bypass', 'Cardiac', 'Cardiology', 'Carotid Stenosis', 'Cause of Death', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'Clinical', 'Clinical Trials Design', 'Computer Vision Systems', 'Consensus', 'Cytolysis', 'Data', 'Deposition', 'Diagnostic', 'Excision', 'Gadolinium', 'Gender', 'Goals', 'Gold', 'Guidelines', 'ImProv', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Intervention', 'Intervention Trial', 'Japanese Population', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Noise', 'Nutrient', 'Outcome', 'Oxygen', 'Patient Triage', 'Patients', 'Physiologic pulse', 'Physiological', 'Play', 'Positron-Emission Tomography', 'Premenopause', 'Procedures', 'Radiation', 'Reference Standards', 'Reproducibility', 'Rest', 'Risk', 'Role', 'Scanning', 'Signal Transduction', 'Solid', 'Spin Labels', 'Stress Tests', 'Stroke prevention', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Waste Products', 'Water', 'Woman', 'Xenon', 'base', 'blood flow measurement', 'cerebral hemodynamics', 'cerebrovascular', 'cerebrovascular imaging', 'clinical application', 'cohort', 'convolutional neural network', 'deep field survey', 'deep learning', 'design', 'direct application', 'disability', 'evidence based guidelines', 'gender difference', 'imaging modality', 'improved', 'learning network', 'men', 'nervous system disorder', 'novel strategies', 'performance tests', 'prospective', 'response', 'stressor', 'stroke risk', 'systematic review', 'time use', 'tool']",NIBIB,STANFORD UNIVERSITY,R01,2020,307236,-0.06881128163778095
"Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning Cerebrovascular disease remains a common cause of death and major disability in the United States, and identifying and preventing strokes should be a high priority. Direct measurement of regional cerebral blood flow (CBF) is challeng- ing in these patients, since we do not have a non-invasive, radiation-free imaging method that has been appropriately validated against gold standard techniques. This is important, because there is compelling evidence that measuring the CBF change before and after a stress test meant to increase CBF (a measurement known as cerebrovascular reserve [CVR]) can identify patients at increased stroke risk. Stress tests have been a mainstay of the diagnostic workup of cardiology patients for many years, and we believe strongly that their use will benefit cerebrovascular disease patients as well. The goal of this project is to improve the quality of arterial spin label (ASL) MRI using deep learning, a powerful form of machine learning, that is currently undergoing tremendous progress. We will then to apply this in a prospective, adaptive validation trial against oxygen-15 water PET CBF, using simultaneous PET/MRI to minimize biological variability. Finally, we will apply this improv- ed tool to study the effects of gender on CVR and its reproducibility. Successful completion of this study will result in a validated methodology to assess CVR in cerebrovascular disease patients without the use of radiation or contrast. As such, it will provide solid, evidence-based recommendations for clinicians developing new paradigms and interventions in patients with impaired CVR. There is strong evidence that imaging of cerebrovascular reserve (CVR), the ability to increase cerebral blood flow (CBF) in response to a challenge, can identify patients at increased risk of stroke. Therefore, measuring CVR would be extremely useful for designing clinical trials of interventions to mitigate this risk. However, current methods to measure CBF and CVR are suboptimal, and do not work well in patients with cerebrovascular disease. The goals of this project are • to improve non-contrast, radiation-free arterial spin label MRI methods  using deep learning, a powerful form of artificial intelligence that has  shown tremendous progress for computer vision • to validate these methods against a CBF gold-standard, oxygen-15 water  PET, using simultaneous PET/MRI, using an adaptive “play-the-winner” strategy • to apply them to assess gender differences in CVR and test their  reproducibility, with the goal of establishing age and gender normative  ranges to better identify outliers.",Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning,9961582,R01EB025220,"['Acetazolamide', 'Address', 'Age', 'Artificial Intelligence', 'Biological', 'Blood flow', 'Brain', 'Brain imaging', 'Bypass', 'Cardiac', 'Cardiology', 'Carotid Stenosis', 'Cause of Death', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'Clinical', 'Clinical Trials Design', 'Computer Vision Systems', 'Consensus', 'Cytolysis', 'Data', 'Deposition', 'Diagnostic', 'Excision', 'Gadolinium', 'Gender', 'Goals', 'Gold', 'Guidelines', 'ImProv', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Intervention', 'Intervention Trial', 'Japanese Population', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Noise', 'Nutrient', 'Outcome', 'Oxygen', 'Patient Triage', 'Patients', 'Physiologic pulse', 'Physiological', 'Play', 'Positron-Emission Tomography', 'Premenopause', 'Procedures', 'Radiation', 'Reference Standards', 'Reproducibility', 'Rest', 'Risk', 'Role', 'Scanning', 'Signal Transduction', 'Solid', 'Spin Labels', 'Stress Tests', 'Stroke prevention', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Waste Products', 'Water', 'Woman', 'Xenon', 'base', 'blood flow measurement', 'cerebral hemodynamics', 'cerebrovascular', 'cerebrovascular imaging', 'clinical application', 'cohort', 'convolutional neural network', 'deep field survey', 'deep learning', 'design', 'direct application', 'disability', 'evidence based guidelines', 'gender difference', 'imaging modality', 'improved', 'learning network', 'men', 'nervous system disorder', 'novel strategies', 'performance tests', 'prospective', 'response', 'stressor', 'stroke risk', 'systematic review', 'time use', 'tool']",NIBIB,STANFORD UNIVERSITY,R01,2020,565941,-0.06881128163778095
"Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning Cerebrovascular disease remains a common cause of death and major disability in the United States, and identifying and preventing strokes should be a high priority. Direct measurement of regional cerebral blood flow (CBF) is challeng- ing in these patients, since we do not have a non-invasive, radiation-free imaging method that has been appropriately validated against gold standard techniques. This is important, because there is compelling evidence that measuring the CBF change before and after a stress test meant to increase CBF (a measurement known as cerebrovascular reserve [CVR]) can identify patients at increased stroke risk. Stress tests have been a mainstay of the diagnostic workup of cardiology patients for many years, and we believe strongly that their use will benefit cerebrovascular disease patients as well. The goal of this project is to improve the quality of arterial spin label (ASL) MRI using deep learning, a powerful form of machine learning, that is currently undergoing tremendous progress. We will then to apply this in a prospective, adaptive validation trial against oxygen-15 water PET CBF, using simultaneous PET/MRI to minimize biological variability. Finally, we will apply this improv- ed tool to study the effects of gender on CVR and its reproducibility. Successful completion of this study will result in a validated methodology to assess CVR in cerebrovascular disease patients without the use of radiation or contrast. As such, it will provide solid, evidence-based recommendations for clinicians developing new paradigms and interventions in patients with impaired CVR. There is strong evidence that imaging of cerebrovascular reserve (CVR), the ability to increase cerebral blood flow (CBF) in response to a challenge, can identify patients at increased risk of stroke. Therefore, measuring CVR would be extremely useful for designing clinical trials of interventions to mitigate this risk. However, current methods to measure CBF and CVR are suboptimal, and do not work well in patients with cerebrovascular disease. The goals of this project are • to improve non-contrast, radiation-free arterial spin label MRI methods  using deep learning, a powerful form of artificial intelligence that has  shown tremendous progress for computer vision • to validate these methods against a CBF gold-standard, oxygen-15 water  PET, using simultaneous PET/MRI, using an adaptive “play-the-winner” strategy • to apply them to assess gender differences in CVR and test their  reproducibility, with the goal of establishing age and gender normative  ranges to better identify outliers.",Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning,9789276,R01EB025220,"['Acetazolamide', 'Address', 'Age', 'Artificial Intelligence', 'Biological', 'Blood flow', 'Brain', 'Brain imaging', 'Bypass', 'Cardiac', 'Cardiology', 'Carotid Stenosis', 'Cause of Death', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'Clinical', 'Clinical Trials Design', 'Computer Vision Systems', 'Consensus', 'Cytolysis', 'Data', 'Deposition', 'Diagnostic', 'Excision', 'Gadolinium', 'Gender', 'Goals', 'Gold', 'Guidelines', 'ImProv', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Intervention', 'Intervention Trial', 'Japanese Population', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Noise', 'Nutrient', 'Outcome', 'Oxygen', 'Patient Triage', 'Patients', 'Physiologic pulse', 'Physiological', 'Play', 'Positron-Emission Tomography', 'Premenopause', 'Procedures', 'Radiation', 'Reference Standards', 'Reproducibility', 'Rest', 'Risk', 'Role', 'Scanning', 'Signal Transduction', 'Solid', 'Spin Labels', 'Stress Tests', 'Stroke prevention', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Waste Products', 'Water', 'Woman', 'Xenon', 'base', 'blood flow measurement', 'cerebral hemodynamics', 'cerebrovascular', 'cerebrovascular imaging', 'clinical application', 'cohort', 'convolutional neural network', 'deep field survey', 'deep learning', 'design', 'direct application', 'disability', 'evidence based guidelines', 'gender difference', 'imaging modality', 'improved', 'learning network', 'men', 'nervous system disorder', 'novel strategies', 'performance tests', 'prospective', 'response', 'stressor', 'stroke risk', 'systematic review', 'time use', 'tool']",NIBIB,STANFORD UNIVERSITY,R01,2019,586260,-0.06881128163778095
"Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning Cerebrovascular disease remains a common cause of death and major disability in the United States, and identifying and preventing strokes should be a high priority. Direct measurement of regional cerebral blood flow (CBF) is challeng- ing in these patients, since we do not have a non-invasive, radiation-free imaging method that has been appropriately validated against gold standard techniques. This is important, because there is compelling evidence that measuring the CBF change before and after a stress test meant to increase CBF (a measurement known as cerebrovascular reserve [CVR]) can identify patients at increased stroke risk. Stress tests have been a mainstay of the diagnostic workup of cardiology patients for many years, and we believe strongly that their use will benefit cerebrovascular disease patients as well. The goal of this project is to improve the quality of arterial spin label (ASL) MRI using deep learning, a powerful form of machine learning, that is currently undergoing tremendous progress. We will then to apply this in a prospective, adaptive validation trial against oxygen-15 water PET CBF, using simultaneous PET/MRI to minimize biological variability. Finally, we will apply this improv- ed tool to study the effects of gender on CVR and its reproducibility. Successful completion of this study will result in a validated methodology to assess CVR in cerebrovascular disease patients without the use of radiation or contrast. As such, it will provide solid, evidence-based recommendations for clinicians developing new paradigms and interventions in patients with impaired CVR. There is strong evidence that imaging of cerebrovascular reserve (CVR), the ability to increase cerebral blood flow (CBF) in response to a challenge, can identify patients at increased risk of stroke. Therefore, measuring CVR would be extremely useful for designing clinical trials of interventions to mitigate this risk. However, current methods to measure CBF and CVR are suboptimal, and do not work well in patients with cerebrovascular disease. The goals of this project are • to improve non-contrast, radiation-free arterial spin label MRI methods  using deep learning, a powerful form of artificial intelligence that has  shown tremendous progress for computer vision • to validate these methods against a CBF gold-standard, oxygen-15 water  PET, using simultaneous PET/MRI, using an adaptive “play-the-winner” strategy • to apply them to assess gender differences in CVR and test their  reproducibility, with the goal of establishing age and gender normative  ranges to better identify outliers.",Cerebrovascular Reserve Imaging with Simultaneous PET/MRI Using Arterial Spin Labeling and Deep Learning,9599417,R01EB025220,"['Acetazolamide', 'Address', 'Age', 'Artificial Intelligence', 'Biological', 'Biological Neural Networks', 'Blood flow', 'Brain', 'Brain imaging', 'Bypass', 'Cardiac', 'Cardiology', 'Carotid Stenosis', 'Cause of Death', 'Cerebrovascular Circulation', 'Cerebrovascular Disorders', 'Clinical', 'Clinical Trials Design', 'Computer Vision Systems', 'Consensus', 'Cytolysis', 'Data', 'Deposition', 'Diagnostic', 'Excision', 'Gadolinium', 'Gender', 'Goals', 'Gold', 'Guidelines', 'ImProv', 'Image', 'Imaging problem', 'Impairment', 'Individual', 'Intervention', 'Intervention Trial', 'Japanese Population', 'Label', 'Link', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Noise', 'Nutrient', 'Outcome', 'Oxygen', 'Patient Triage', 'Patients', 'Physiologic pulse', 'Physiological', 'Play', 'Positron-Emission Tomography', 'Premenopause', 'Procedures', 'Radiation', 'Reference Standards', 'Reproducibility', 'Rest', 'Risk', 'Role', 'Scanning', 'Signal Transduction', 'Solid', 'Spin Labels', 'Stress Tests', 'Stroke', 'Stroke prevention', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Waste Products', 'Water', 'Woman', 'Xenon', 'base', 'blood flow measurement', 'cerebral hemodynamics', 'cerebrovascular', 'cerebrovascular imaging', 'clinical application', 'cohort', 'deep field survey', 'deep learning', 'design', 'direct application', 'disability', 'evidence based guidelines', 'gender difference', 'imaging modality', 'improved', 'learning network', 'men', 'nervous system disorder', 'novel strategies', 'performance tests', 'prospective', 'response', 'stressor', 'stroke risk', 'systematic review', 'time use', 'tool']",NIBIB,STANFORD UNIVERSITY,R01,2018,653337,-0.06881128163778095
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9746373,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Computer software', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Infrastructure', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,234000,0.03081226865359529
"Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy Project Summary/Abstract Diagnosis of lumbar radiculopathy (LR) currently relies on a qualitative interpretation of magnetic resonance imaging (MRI) studies and lacks standardization. This has led to inconsistent treatment and rising costs, while quality of life metrics have remained stagnant. To standardize the diagnosis of LR, the subjective and qualitative radiologic assessment needs to be augmented with accurate measurements of neuroforamina (NF) and central canal (CC) areas, two anatomical structures that are critical to the etiology of LR. However, precise measurements will require manual delineations of these regions on MRI. This is a tedious and time-consuming process that is not feasible on a daily, large-scale basis in the clinic. Deep Learning (DL) is a relatively new machine learning technique, which holds the promise of automating NF and CC segmentation. None the less, there remain several challenges to making DL-based segmentation routine in clinical practice. First, training and validating a DL model for segmentation of a given anatomical structure requires a large amount of expert annotated training data. Expert annotated data is expensive and time consuming to obtain, thus thwarting the development of quantitative imaging diagnostics for LR. To address this, we propose an expert-led manual delineation of NF and CC using de-identified MRI data extracted from UCLA's picture archiving and communications system (PACS). We expect the resulting database to contain data from over 35,000 lumbar MRI scans, with associated clinical history, demographics, and patient outcomes data. In a subset (1000) of these data, NFs and CCs will be annotated by multiple human expert raters. The consensus of these delineations will be used as ground truth segmentations to train, validate and improve our understanding of DL models. Secondly, as a part of this proposal, we aim to address several technical challenges that limit the deployment of automated image segmentation techniques to the clinic. Chief amongst these challenges is the failure of automated methodologies in the face of variation due to factors such as pathology, scanner protocol alterations, and general demographic variation. Additionally, our current understanding of DL does not allow us to categorically state the total number of expert annotated data that will be needed to train a model with a specified level of accuracy. Finally, we do not currently understand how selection of training cases for expert delineation affects generalization accuracy. To address the aforementioned challenges, we propose experiments to define the relationship between DL algorithms and the cardinality of training data. We will also explore the use of unsupervised machine learning strategies, namely clustering and reinforcement learning, to understand how training data selection influences algorithmic accuracy. In summary, we propose to address data availability and technical knowledge gaps to the development of accurate DL-based techniques for automated NF and CC delineation, with a broader view to standardize the diagnosis and treatment of LR. Project Narrative Basing radiological diagnoses on a quantitative characterization of neuroforamina (NF) and central canal (CC) areas would greatly improve the diagnosis and treatment of lumbar radiculopathy (LR). Manual measurement of this anatomy on every clinical study is not feasible; however, deep learning- (DL) based automated methods can reliable perform this task if 1) expert annotations to train DL algorithms are available and 2) we can train DL models to work accurately despite image heterogeneity. We address these knowledge gaps by developing 1) a database containing spine MR images with expert annotation of NFs and CCs and 2) intelligent training data selection frameworks to train DL algorithms and assess their robustness to heterogeneity.",Developing Database and Software infrastructure for Quantitative Radiologic Analysis of Lumbar Radiculopathy,9928429,R21EB026665,"['Address', 'Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Categories', 'Central cord canal structure', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Computer Analysis', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Diagnostic Imaging', 'Etiology', 'Evaluation', 'Expenditure', 'Face', 'Failure', 'Foundations', 'Future', 'Goals', 'Gold', 'Health', 'Health system', 'Heterogeneity', 'Human', 'Image', 'Image Analysis', 'Intelligence', 'Intraobserver Variability', 'Investigative Techniques', 'Knowledge', 'Learning', 'Link', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Natural History', 'Needs Assessment', 'Outcome', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Prevalence', 'Process', 'Protocols documentation', 'Psychological reinforcement', 'Quality of life', 'Radiculopathy', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Resources', 'Sampling', 'Scanning', 'Selection for Treatments', 'Sensitivity and Specificity', 'Specialist', 'Specific qualifier value', 'Spinal Diseases', 'Standardization', 'Techniques', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'United States', 'Variant', 'Vertebral column', 'Work', 'algorithm training', 'base', 'clinical application', 'clinical database', 'clinical practice', 'cost', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experimental study', 'imaging Segmentation', 'imaging study', 'improved', 'insight', 'learning strategy', 'network architecture', 'neural network architecture', 'neuroimaging', 'novel', 'quantitative imaging', 'relational database', 'segmentation algorithm', 'software infrastructure', 'theories', 'treatment adherence', 'treatment optimization', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2020,195000,0.03081226865359529
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9752639,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation Dose Unit', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'neural network', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2019,196250,0.1263841504758292
"Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography Project Summary/Abstract Positron emission tomography (PET) is a high-sensitivity molecular imaging modality widely used in oncology, neurology, and cardiology, with the ability to observe molecular-level activities inside a living body through the injection of specific radioactive tracers. In addition to the commonly used F-18-FDG, new tracers are being constantly developed and investigated to pinpoint specific pathways in various diseases. New PET scanners are also being proposed by exploiting time of flight (TOF) information, enabling depth of interaction capability, and extending the solid angle coverage. To realize the full potential of the new PET tracers and scanners, there is an increasing need for the development of advanced image reconstruction methods. This grant application proposes a new framework for regularized image reconstruction that synergistically integrates deep learning and regularized image reconstruction. The new framework is enabled by the recent advances in machine learning, which provide a tool to digest vast amount information embedded in existing medical images. The proposed method embeds a pre-trained deep neural network in an iterative image reconstruction framework and uses the deep neural network to regularize PET image directly. By training the deep neural network with a large amount of high-quality low-noise PET images, the proposed method can capture complex prior information from existing inter-subject and intra-subject data and thus is expected to substantially outperform the current state-of-the-art regularized image reconstruction method. The two specific aims of this exploratory proposal are (1) to develop the theoretical framework to synergistically integrate deep learning in regularized image reconstruction for PET and (2) to implement the proposed method and validate its effectiveness using existing animal data. Once the proposed method is validated using existing animal data, we will seek funding to acquire necessary human data for the implementation of the proposed method on clinical PET scanners. Project Narrative Positron emission tomography (PET) is a medical imaging technique widely used in clinic for detecting cancer, cardiovascular diseases, and neurological disorders. This project will develop an innovative image reconstruction method that has potential to improve PET image quality and reduce radiation dose. Its success will improve the accuracy of PET for cancer detection and other diseases.",Synergistic integration of deep learning and regularized image reconstruction for positron emission tomography,9586688,R21EB026668,"['Advanced Development', 'Anatomy', 'Applications Grants', 'Biological Neural Networks', 'Cancer Detection', 'Cardiology', 'Cardiovascular Diseases', 'Clinic', 'Clinical', 'Complex', 'Core Facility', 'Data', 'Data Set', 'Detection', 'Disease', 'Dose', 'Funding', 'Genomics', 'Grant', 'Image', 'Imaging Techniques', 'Injections', 'Learning', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Molecular', 'Morphologic artifacts', 'Mus', 'Network-based', 'Neurology', 'Noise', 'Output', 'Pathway interactions', 'Patients', 'Play', 'Positron-Emission Tomography', 'Radiation', 'Radioactive Tracers', 'Rattus', 'Role', 'Solid', 'Time', 'Tracer', 'Training', 'Use Effectiveness', 'Validation', 'Work', 'X-Ray Computed Tomography', 'anatomic imaging', 'animal data', 'base', 'cost', 'deep learning', 'deep neural network', 'fluorodeoxyglucose', 'human data', 'image reconstruction', 'imaging modality', 'improved', 'innovation', 'learning strategy', 'molecular imaging', 'nervous system disorder', 'nonhuman primate', 'novel strategies', 'oncology', 'success', 'tool']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R21,2018,221250,0.1263841504758292
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9927625,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2020,458900,0.05311634952702655
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9762102,R01EB026708,"['3-Dimensional', 'Abdomen', 'Air', 'Algorithms', 'Area', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'convolutional neural network', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'real-time images', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2019,460690,0.05311634952702655
"Improved Techniques for Substitute CT Generation from MRI datasets This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET for PET/MR and target delineation for radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from only MR-data. Unfortunately, MRI has limited capability to resolve bone and the inability of most MR acquisitions to distinguish between air and bone makes segmentation of these tissues types challenging. This project will utilize deep learning, a new and growing area of machine learning, to develop new methodology to create substitute CT images from rapid MR acquisitions that can be utilized in PET/MR and radiation treatment planning workflows. In Aim 1 we will study rapid MR acquisitions to be used with deep learning approaches for sCT generation in the head and pelvis using 3T PET/MR images matched with PET/CT imaging to create deep learning training and evaluation datasets. Different deep learning networks and MR inputs will be studied and adapted to determine the best PET reconstruction performance. In Aim 2 we will investigate rapid but motion-resilient approaches to whole- body MR imaging for subsequent deep learning-based substitute CT generation. In an exploratory subaim, we also propose to study methods of sCT generation that only utilize PET-only data. The data acquired in Aim 2 will be used to create comprehensive whole-body, motion-resilient datasets for training and evaluation of deep learning networks. In Aim 3 we will evaluate substitute CT approaches for MR-only radiation treatment planning. MR-only approaches will be compared to standard CT-based treatment simulation in the brain, head & neck, chest, abdomen, and pelvis and deep learning networks will be optimized and evaluated for region- specific RT planning and simulation. Additionally, transfer learning approaches will be studied to extend sCT to a 0.35T MR-Linac to demonstrate respiratory motion resolved substitute CT generation. This proposal will enable improved substitute CT images for use in PET/MR and MR-only radiation treatment planning. Given the greatly improved soft-tissue contrast of MR relative to CT, which aids interpretation of PET in PET/MR and target delineation in radiation treatment planning, a remaining limitation is the current capability to obtain sufficiently accurate substitute CT images from MR-only data. This project will determine improved rapid and motion resilient MR approaches for deep learning-based generation of substitute CT images, enabling greater quantitative accuracy and robustness for PET/MR and MR-only radiation treatment planning.",Improved Techniques for Substitute CT Generation from MRI datasets,9580704,R01EB026708,"['Abdomen', 'Air', 'Algorithms', 'Area', 'Biological Neural Networks', 'Body Regions', 'Brain', 'Chest', 'Clinical', 'Data', 'Data Set', 'Databases', 'Deformity', 'Development', 'Evaluation', 'Financial compensation', 'Future', 'Generations', 'Head', 'Head and neck structure', 'Image', 'Ionizing radiation', 'Linear Accelerator Radiotherapy Systems', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Methodology', 'Methods', 'Motion', 'PET/CT scan', 'Pathologic', 'Patients', 'Pelvis', 'Performance', 'Positron-Emission Tomography', 'Psychological Transfer', 'Radial', 'Radiation exposure', 'Radiation therapy', 'Residual state', 'Resolution', 'Sampling', 'Techniques', 'Technology', 'Tissues', 'Training', 'Uncertainty', 'Work', 'X-Ray Computed Tomography', 'attenuation', 'base', 'bone', 'deep learning', 'electron density', 'image guided', 'imaging capabilities', 'improved', 'learning network', 'prospective', 'reconstruction', 'respiratory', 'routine imaging', 'simulation', 'soft tissue', 'treatment planning', 'tumor', 'whole body imaging']",NIBIB,UNIVERSITY OF WISCONSIN-MADISON,R01,2018,460690,0.05311634952702655
"Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures PROJECT SUMMARY/ABSTRACT: Arterial hemorrhage after pelvic fractures is a leading reversible cause of death after blunt trauma. Prediction of arterial bleeding risk is difficult, and currently determined using subjective criteria, often based on qualitative results of admission computed tomography (CT). Segmented hematoma and contrast extravasation (CE) volumes predict need for angioembolization, major transfusion, and mortality but cannot be applied in real-time. The ill-defined multi-focal nature of pelvic hematomas and CE prevents reliable estimation using diameter-based measurements. Dr. Dreizin is a trauma radiologist at the University of Maryland School of Medicine. His early work has focused on improving the speed and reliability of volumetric analysis of pelvic hematomas using semi-automated techniques, and derivation of a logistic regression-based prediction tool for major arterial injury after pelvic fractures. Dr. Dreizin’s goal for this four- year K08 mentored career development award proposal is to gain the skills needed to 1) implement deep learning architectures for automated hematoma volume segmentation and 2) develop computational models for outcome prediction after pelvic trauma. These tools could greatly improve the speed and accuracy of clinical decision making in the setting of life-threatening traumatic pelvic bleeding. Fully convolutional neural networks (FCNs) have emerged as the most robust and scalable method for automated medical image segmentation. Intuitive software platforms for training FCN implementations and generating multivariable machine learning models have been developed in the Python programming environment. The training objectives and research activities of this proposal are necessary to provide Dr. Dreizin with new skills and practical experience in Python programming, deep learning software, and computational modeling software. By understanding the principles and computational infrastructure behind modern machine learning, Dr. Dreizin will be able to train and validate state-of-the-art algorithms independently and effectively lead a team of researchers in this area. To achieve his goals, Dr. Dreizin has assembled a multidisciplinary team of mentors, advisors, and collaborators with world-leading expertise in computer vision in medical imaging, probability theory, data science, and comparative effectiveness research. Dr. Dreizin will focus on two specific aims. In Aim 1, he will train and validate deep learning architectures for segmentation of traumatic pelvic hematomas and CE by computing the Dice metric, time effort, and correlation with clinical outcomes. In Aim 2, he will generate and test quantitative models for predicting major arterial bleeding after pelvic trauma based on a rich multi-label dataset of segmented features. The training and pilot data will be necessary for Dr. Dreizin’s long- term goal of research independence and R01 support to develop automated segmentation algorithms for the spectrum of clinically important imaging features after pelvic trauma, as well as fully automated multivariable clinical prediction tools with potential for translation to industry and as an FDA-cleared product. PROJECT NARRATIVE: Hemorrhage after pelvic fractures is common after motor vehicle collisions, falls, and crush injuries, with mortality rates that range from 5-54%. The volume of hemorrhage, as measured on computed tomography (CT) scans, predicts the need for rapid intervention or transfusion, and is a strong predictor of mortality, but no automated image-processing methods exist for real-time hemorrhage volume measurement. We propose to develop automated software for hemorrhage-detection, and real-time risk prediction software for major arterial hemorrhage after pelvic fractures.",Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures,9819865,K08EB027141,"['Admission activity', 'Adoption', 'Algorithms', 'Angiography', 'Architecture', 'Area', 'Arterial Injury', 'Award', 'Blunt Trauma', 'Caliber', 'Catheters', 'Cause of Death', 'Clinical', 'Communities', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Crush Injury', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Detection', 'Development', 'Diagnosis', 'Early Intervention', 'Engineering', 'Environment', 'Extravasation', 'Fall injury', 'Funding', 'Goals', 'Hematoma', 'Hemorrhage', 'Hospitalization', 'Human', 'Image', 'Industry', 'Intervention', 'Intuition', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Life', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Maryland', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Obesity', 'Outcome', 'Patients', 'Pelvis', 'Predictive Value', 'Probability Theory', 'Process', 'Programming Languages', 'Pythons', 'Radiology Specialty', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Shorthand', 'Speed', 'Supervision', 'Techniques', 'Terminology', 'Testing', 'Therapeutic Embolization', 'Thinness', 'Time', 'Training', 'Transfusion', 'Translations', 'Trauma', 'Treatment outcome', 'Triage', 'Universities', 'Vehicle crash', 'Work', 'X-Ray Computed Tomography', 'adverse outcome', 'artificial neural network', 'base', 'clinical decision-making', 'comparative effectiveness', 'computer infrastructure', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'effectiveness research', 'experience', 'hemodynamics', 'heuristics', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'learning strategy', 'medical schools', 'mortality', 'multidisciplinary', 'muscle form', 'neural network architecture', 'outcome prediction', 'pelvis fracture', 'personalized predictions', 'predictive modeling', 'prevent', 'primary outcome', 'radiologist', 'random forest', 'real time model', 'secondary outcome', 'skills', 'standard of care', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF MARYLAND BALTIMORE,K08,2019,186183,0.024698652871269305
"Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures PROJECT SUMMARY/ABSTRACT: Arterial hemorrhage after pelvic fractures is a leading reversible cause of death after blunt trauma. Prediction of arterial bleeding risk is difficult, and currently determined using subjective criteria, often based on qualitative results of admission computed tomography (CT). Segmented hematoma and contrast extravasation (CE) volumes predict need for angioembolization, major transfusion, and mortality but cannot be applied in real-time. The ill-defined multi-focal nature of pelvic hematomas and CE prevents reliable estimation using diameter-based measurements. Dr. Dreizin is a trauma radiologist at the University of Maryland School of Medicine. His early work has focused on improving the speed and reliability of volumetric analysis of pelvic hematomas using semi-automated techniques, and derivation of a logistic regression-based prediction tool for major arterial injury after pelvic fractures. Dr. Dreizin’s goal for this four- year K08 mentored career development award proposal is to gain the skills needed to 1) implement deep learning architectures for automated hematoma volume segmentation and 2) develop computational models for outcome prediction after pelvic trauma. These tools could greatly improve the speed and accuracy of clinical decision making in the setting of life-threatening traumatic pelvic bleeding. Fully convolutional neural networks (FCNs) have emerged as the most robust and scalable method for automated medical image segmentation. Intuitive software platforms for training FCN implementations and generating multivariable machine learning models have been developed in the Python programming environment. The training objectives and research activities of this proposal are necessary to provide Dr. Dreizin with new skills and practical experience in Python programming, deep learning software, and computational modeling software. By understanding the principles and computational infrastructure behind modern machine learning, Dr. Dreizin will be able to train and validate state-of-the-art algorithms independently and effectively lead a team of researchers in this area. To achieve his goals, Dr. Dreizin has assembled a multidisciplinary team of mentors, advisors, and collaborators with world-leading expertise in computer vision in medical imaging, probability theory, data science, and comparative effectiveness research. Dr. Dreizin will focus on two specific aims. In Aim 1, he will train and validate deep learning architectures for segmentation of traumatic pelvic hematomas and CE by computing the Dice metric, time effort, and correlation with clinical outcomes. In Aim 2, he will generate and test quantitative models for predicting major arterial bleeding after pelvic trauma based on a rich multi-label dataset of segmented features. The training and pilot data will be necessary for Dr. Dreizin’s long- term goal of research independence and R01 support to develop automated segmentation algorithms for the spectrum of clinically important imaging features after pelvic trauma, as well as fully automated multivariable clinical prediction tools with potential for translation to industry and as an FDA-cleared product. PROJECT NARRATIVE: Hemorrhage after pelvic fractures is common after motor vehicle collisions, falls, and crush injuries, with mortality rates that range from 5-54%. The volume of hemorrhage, as measured on computed tomography (CT) scans, predicts the need for rapid intervention or transfusion, and is a strong predictor of mortality, but no automated image-processing methods exist for real-time hemorrhage volume measurement. We propose to develop automated software for hemorrhage-detection, and real-time risk prediction software for major arterial hemorrhage after pelvic fractures.",Machine learning-based segmentation and risk modeling for real-time prediction of major arterial bleeding after pelvic fractures,9955253,K08EB027141,"['Admission activity', 'Adoption', 'Algorithms', 'Angiography', 'Architecture', 'Area', 'Arterial Injury', 'Award', 'Blunt Trauma', 'Caliber', 'Catheters', 'Cause of Death', 'Clinical', 'Communities', 'Comparative Effectiveness Research', 'Computer Models', 'Computer Vision Systems', 'Computer software', 'Crush Injury', 'Data', 'Data Science', 'Data Set', 'Derivation procedure', 'Detection', 'Development', 'Diagnosis', 'Early Intervention', 'Engineering', 'Environment', 'Extravasation', 'Funding', 'Goals', 'Hematoma', 'Hemorrhage', 'Hospitalization', 'Human', 'Image', 'Industry', 'Intervention', 'Intuition', 'K-Series Research Career Programs', 'Knowledge', 'Label', 'Lead', 'Learning', 'Life', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Maryland', 'Measurement', 'Measures', 'Medical Imaging', 'Mentors', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Obesity', 'Outcome', 'Patients', 'Pelvis', 'Predictive Value', 'Probability Theory', 'Process', 'Programming Languages', 'Pythons', 'Radiology Specialty', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Risk', 'Scanning', 'Sensitivity and Specificity', 'Shorthand', 'Speed', 'Supervision', 'Techniques', 'Terminology', 'Testing', 'Therapeutic Embolization', 'Thinness', 'Time', 'Training', 'Transfusion', 'Translations', 'Trauma', 'Treatment outcome', 'Triage', 'Universities', 'Vehicle crash', 'Work', 'X-Ray Computed Tomography', 'adverse outcome', 'algorithm development', 'artificial neural network', 'automated segmentation', 'base', 'clinical decision-making', 'computer infrastructure', 'convolutional neural network', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'fall injury', 'hemodynamics', 'heuristics', 'image processing', 'imaging Segmentation', 'improved', 'improved outcome', 'learning strategy', 'medical schools', 'mortality', 'multidisciplinary', 'muscle form', 'neural network architecture', 'outcome prediction', 'pelvis fracture', 'personalized predictions', 'predictive modeling', 'prevent', 'primary outcome', 'radiologist', 'random forest', 'real time model', 'secondary outcome', 'segmentation algorithm', 'skills', 'standard of care', 'support vector machine', 'temporal measurement', 'tool']",NIBIB,UNIVERSITY OF MARYLAND BALTIMORE,K08,2020,186183,0.024698652871269305
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9651713,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Biological Neural Networks', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Dose', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2018,78500,0.09992333244983599
"Deep learning techniques for time-of-flight PET detectors Project Summary/Abstract One of the key advances in modern positron emission tomography (PET) systems for clinical imaging is the use of time-of-flight (TOF) information. In cancer imaging TOF provides superior lesion detection and more accurate quantification that is crucial in measuring response to therapy, as well as in neurological and cardiovascular imaging applications. An additional benefit of TOF is the ability to lower the radiation dose or scan time without sacrificing image quality, important for patient safety and comfort. The magnitude of these clinical benefits is determined by the TOF resolution of the PET detectors, therefore the prospect of achieving unprecedented image quality and clinical imaging capabilities with superior TOF resolution has fueled significant research in developing detector technology for TOF-PET systems. However, these developments have been largely unaccompanied by advances in signal processing methods needed to extract TOF information from the detector’s electrical signals, with most detectors making use of crude analog algorithms that discard most of the useful timing information contained in the signals. Now, with the availability of low-cost fast waveform digitizers, there is an exciting opportunity to implement sophisticated digital signal processing algorithms to achieve superior TOF resolution. The main advantage of developing advanced signal processing algorithms is that it presents a cost-effective route to improved TOF resolution that is complementary to instrumentation innovations. In essence, the TOF gain comes for free; the detector signals already contain the information needed for better TOF resolution, it just needs to be used effectively. Here we propose to tailor deep learning techniques to estimate TOF from the detector signals. Deep learning with convolutional neural networks (CNNs) is a powerful approach to learn complex representations of input data that can be used for tasks such as classification and regression. CNNs are therefore very suitable for directly estimating TOF from the detector waveforms, since these waveforms are influenced by several complex and intertwined processes which are hard to accurately model. Furthermore, large amounts of ground truth training data are readily generated. We recently demonstrated the feasibility of CNN-based TOF estimation, and found up to 23% improvement in TOF resolution compared to standard signal processing methods. This proposal aims to optimize these methods to push the limits of achievable TOF resolution and develop methods for their practical implementation. First, we will develop CNN architectures and methods suitable for silicon photomultipliers (SiPMs) that are now used in modern TOF-PET systems. We will also optimize the digitizing parameters to make optimal use of CNNs for TOF estimation. Second, we will implement CNN-TOF methods in a modern commercial PET detector, including using a global CNN to simultaneously estimate TOF and the crystal-of-interaction from the detector waveforms, demonstrating the practical feasibility of using this promising deep learning method in next generation PET systems. Narrative The use of time-of-flight information in positron emission tomography (PET) is a powerful way to increase clinical imaging capabilities of PET, and is now used in most modern systems. Improving time-of-flight performance promises to provide substantial benefits for lesion detection in cancer imaging, kinetic modeling with dynamic imaging, and the use of lower radiation dose for patient safety. Here we introduce deep learning signal processing methods to significantly improve the performance of time-of-flight PET detectors without requiring new materials, which thereby represents a cost effective route towards maximizing the use of the rich imaging signal provided by time-of-flight.",Deep learning techniques for time-of-flight PET detectors,9784818,R03EB027268,"['Address', 'Adoption', 'Algorithms', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Coupled', 'Crystallization', 'Data', 'Data Quality', 'Detection', 'Development', 'Devices', 'Digital Signal Processing', 'Electronics', 'Foundations', 'Future', 'Goals', 'Healthcare', 'Human Engineering', 'Image', 'Industry', 'Industry Collaboration', 'Investigation', 'Kinetics', 'Knowledge', 'Learning', 'Lesion', 'Low Dose Radiation', 'Machine Learning', 'Manufacturer Name', 'Measures', 'Methods', 'Modeling', 'Modernization', 'Network-based', 'Neurologic', 'Noise', 'Outcome', 'Patient Care', 'Performance', 'Photons', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Property', 'Radiation Dose Unit', 'Research', 'Research Personnel', 'Resolution', 'Route', 'Sampling', 'Scanning', 'Signal Transduction', 'Silicon', 'Solid', 'Speed', 'Sum', 'System', 'Techniques', 'Technology', 'Temperature', 'Time', 'Training', 'Tube', 'analog', 'base', 'cancer imaging', 'cardiovascular imaging', 'clinical imaging', 'convolutional neural network', 'cost', 'cost effective', 'deep learning', 'detector', 'digital', 'imaging capabilities', 'improved', 'innovation', 'instrumentation', 'learning strategy', 'neural network architecture', 'next generation', 'patient safety', 'photomultiplier', 'physical process', 'response', 'scale up', 'signal processing', 'time use', 'voltage']",NIBIB,UNIVERSITY OF CALIFORNIA AT DAVIS,R03,2019,78500,0.09992333244983599
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning.",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,10140491,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis ', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'software infrastructure', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2020,742405,-0.06104704562047217
"Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning Project Summary Motivation: Gadolinium-based contrast agents (GBCAs) are used in approximately a third of all MRI scans. The unique relaxation parameters of GBCAs create indispensable image contrast for a wide range of clinical applications, such as angiography and tumor detection. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis (NSF). NSF can be painful, cause severe disability, and even death. The risk of developing NSF prevents millions of patients with advanced chronic kidney disease (CKD) from receiving contrast-enhanced MRI exams. The recent identification of gadolinium deposition within the brain and body has raised additional safety concerns about the usage of GBCAs. Studies have demonstrated increased signal intensity on the unenhanced T1-weighted MR images that is correlated with previous GBCA exposure, and this gadolinium retention is independent of renal function. While initial reports focused on linear GBCAs, more recent reports show that gadolinium deposition occurs with macrocyclic GBCAs as well, albeit at lower levels. FDA has recently issued warnings about gadolinium retention following contrast-enhanced MRI, and required GBCA manufacturers to conduct human and animal studies to further assess the safety of these contrast agents. This project addresses these concerns by developing low-dose and zero-dose contrast-enhanced MRI using artificial intelligence (AI) and deep learning (DL). Approach: This fast-track project has two phases and three aims. Aim 1 (Phase I) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using pre-contrast images and contrast-enhanced images acquired with only 10% of standard GBCA dose. A software infrastructure will be constructed to seamlessly integrate the DL software between MR scanners and PACS. Aim 2 (Phase II) is to develop a DL method that can synthesize full-dose contrast-enhanced MR images using GBCA-free acquisitions with different image contrast. In Aim 3 (Phase II), we will clinically validate and evaluate both low-dose and zero-dose DL methods, including on patients with mild- to-moderate CKD. Non-inferiority tests and diagnostic performance of the synthesized full-dose images compared to the true full-dose images will be performed. Significance: This work will lead to safer contrast-enhanced MRI. The low-dose and zero-dose contrast-enhanced MRI method will benefit not only millions of patients with advanced CKD, who cannot currently undergo contrast-enhanced MRI, but many more patients with normal kidney function, who are at the risk of gadolinium retention after contrast-enhanced MRI. Project Narrative Gadolinium-based contrast agents (GBCAs) are widely used in MRI exams to create indispensable image contrast for monitoring treatment and investigating pathology and function. However, the usage of GBCAs has been linked to the development of nephrogenic systemic fibrosis, preventing patients with advanced chronic kidney disease from receiving contrast-enhanced MRI exams, as well as potential gadolinium deposition in the body and brain for patients with normal kidney function. This project aims to address these problems by developing and validating low-dose and zero-dose contrast-enhanced MRI using deep learning. !",Low- and Zero-dose Contrast-enhanced MRI Using Deep Learning,9776655,R44EB027560,"['Address', 'Affect', 'Angiography', 'Animals', 'Artificial Intelligence', 'Brain', 'Cessation of life', 'Chronic Kidney Failure', 'Clinical', 'Clinical Research', 'Computer software', 'Contrast Media', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diagnostic', 'Dose', 'Evaluation', 'Gadolinium', 'Goals', 'Health Professional', 'Hospitals', 'Human', 'Image', 'Image Enhancement', 'Infrastructure', 'Kidney Failure', 'Link', 'MRI Scans', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Motivation', 'Nephrogenic Systemic Fibrosis\xa0', 'Pain', 'Pathology', 'Patients', 'Performance', 'Phase', 'Relaxation', 'Renal function', 'Reporting', 'Research', 'Risk', 'Safety', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Software Validation', 'System', 'Testing', 'Training', 'Work', 'base', 'clinical application', 'contrast enhanced', 'contrast imaging', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'disability', 'experience', 'image reconstruction', 'learning strategy', 'prevent', 'software development', 'tumor']",NIBIB,"SUBTLE MEDICAL, INC.",R44,2019,185379,-0.06104704562047217
"Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse Project Summary/ Abstract Expiratory central airway collapse (ECAC), defined by >50% collapse of large airways during expiration, resulting from either cartilaginous weakening or redundancy of the posterior membranous wall of the trachea, is an increasingly recognized disorder associated with cigarette smoking and chronic obstructive pulmonary disease (COPD). Airflow obstruction in smokers primarily arises from increased resistance to airflow in the small distal conducting airways <2 mm in diameter. It is plausible that in a subset of smokers with and without COPD, central airway collapse results in additional resistance to airflow, resulting in substantial respiratory morbidity. Ninety-two million adults in the Unites States are active or past smokers, and ECAC is present in approximately 5% of current and former smokers. The presence of ECAC is associated with greater dyspnea, worse respiratory-quality of life and greater frequency of exacerbations after adjustment for underlying lung disease. Whether these patients will benefit from interventional therapies such as stenting or tracheopexy depends on whether the airflow resistance caused by ECAC contributes to symptoms, and this in turn depends on the relative contribution of central and small airways to overall airflow resistance. If the overall airflow resistance is primarily due to distal small airways obstruction in a given patient with ECAC, treating central airway collapse is unlikely to benefit such a patient. Our central hypothesis is that ECAC results in additional airflow obstruction beyond that incurred in the small airways, and that in a subset of patients the central airways are the major site of airflow obstruction and hence are amenable to therapy. The complex interplay of proximal and distal airway resistances and transpulmonary pressures does not lend itself to direct measurements in human subjects across a range of physiological pressure and flow changes. We propose a combination of CT-derived imaging and patient-personalized benchtop model and deep learning to answer these questions with the following specific aims. Aim 1 of this application will be to derive personalized patient- specific information on airway geometry and resistance using airway segmentation from computed tomography (CT) scans. We will calculate airway resistances in central and small airways using standard formulae. The goal of Aim 2 is to create bench-top simulations to understand the complex interplay between the resistance of small and large airways. In Aim 3, we will use deep learning to derive probability scores for clinically substantial ECAC from segmented airway images on computed tomography. The results of our study will enable patient-specific personalized therapies for ECAC. The mechanistic insights gained from this study will help identify patients with clinically significant ECAC and hence most likely to benefit from therapeutic interventions. PROJECT NARRATIVE Expiratory central airway collapse (ECAC), greater than 50% collapse of the large airways during expiration, is present in 5% of chronic smokers, and is associated with substantial respiratory morbidity disproportionate to underlying lung disease. Resistance to airflow in smokers is thought to primarily occur in the small conducting airways. By using benchtop models and deep learning to determine the effect of central airway collapse on overall airway resistance and its contribution to airflow obstruction relative to small airway resistance, the proposed project will identify patients with ECAC who will benefit from intervention, and cause a paradigm shift in the therapy of these patients.",Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse,10013198,R21EB027891,"['3-Dimensional', '3D Print', 'Adult', 'Affect', 'Age', 'Air Movements', 'Airway Resistance', 'Area', 'Body mass index', 'Breathing', 'Caliber', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Disease', 'Distal', 'Dyspnea', 'Exhalation', 'Forced expiratory volume function', 'Frequencies', 'Generations', 'Geometry', 'Goals', 'Image', 'Individual', 'Intervention', 'Length', 'Liquid substance', 'Lung diseases', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Neural Network Simulation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Probability', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quality of life', 'Race', 'Resistance', 'Scanning', 'Site', 'Smoker', 'Smoking', 'Spirometry', 'Stents', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Trachea', 'Training', 'Translations', 'Tube', 'United States', 'Visualization', 'X-Ray Computed Tomography', 'airway obstruction', 'base', 'cartilaginous', 'cigarette smoking', 'clinical application', 'clinical predictors', 'clinically significant', 'convolutional neural network', 'deep learning', 'expiration', 'human subject', 'individual patient', 'insight', 'patient subsets', 'personalized medicine', 'pressure', 'respiratory', 'respiratory morbidity', 'response', 'sex', 'simulation', 'three-dimensional modeling']",NIBIB,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R21,2020,187049,0.013521897790601891
"Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse Project Summary/ Abstract Expiratory central airway collapse (ECAC), defined by >50% collapse of large airways during expiration, resulting from either cartilaginous weakening or redundancy of the posterior membranous wall of the trachea, is an increasingly recognized disorder associated with cigarette smoking and chronic obstructive pulmonary disease (COPD). Airflow obstruction in smokers primarily arises from increased resistance to airflow in the small distal conducting airways <2 mm in diameter. It is plausible that in a subset of smokers with and without COPD, central airway collapse results in additional resistance to airflow, resulting in substantial respiratory morbidity. Ninety-two million adults in the Unites States are active or past smokers, and ECAC is present in approximately 5% of current and former smokers. The presence of ECAC is associated with greater dyspnea, worse respiratory-quality of life and greater frequency of exacerbations after adjustment for underlying lung disease. Whether these patients will benefit from interventional therapies such as stenting or tracheopexy depends on whether the airflow resistance caused by ECAC contributes to symptoms, and this in turn depends on the relative contribution of central and small airways to overall airflow resistance. If the overall airflow resistance is primarily due to distal small airways obstruction in a given patient with ECAC, treating central airway collapse is unlikely to benefit such a patient. Our central hypothesis is that ECAC results in additional airflow obstruction beyond that incurred in the small airways, and that in a subset of patients the central airways are the major site of airflow obstruction and hence are amenable to therapy. The complex interplay of proximal and distal airway resistances and transpulmonary pressures does not lend itself to direct measurements in human subjects across a range of physiological pressure and flow changes. We propose a combination of CT-derived imaging and patient-personalized benchtop model and deep learning to answer these questions with the following specific aims. Aim 1 of this application will be to derive personalized patient- specific information on airway geometry and resistance using airway segmentation from computed tomography (CT) scans. We will calculate airway resistances in central and small airways using standard formulae. The goal of Aim 2 is to create bench-top simulations to understand the complex interplay between the resistance of small and large airways. In Aim 3, we will use deep learning to derive probability scores for clinically substantial ECAC from segmented airway images on computed tomography. The results of our study will enable patient-specific personalized therapies for ECAC. The mechanistic insights gained from this study will help identify patients with clinically significant ECAC and hence most likely to benefit from therapeutic interventions. PROJECT NARRATIVE Expiratory central airway collapse (ECAC), greater than 50% collapse of the large airways during expiration, is present in 5% of chronic smokers, and is associated with substantial respiratory morbidity disproportionate to underlying lung disease. Resistance to airflow in smokers is thought to primarily occur in the small conducting airways. By using benchtop models and deep learning to determine the effect of central airway collapse on overall airway resistance and its contribution to airflow obstruction relative to small airway resistance, the proposed project will identify patients with ECAC who will benefit from intervention, and cause a paradigm shift in the therapy of these patients.",Deep Learning and Fluid Dynamics Based Phenotyping of Expiratory Central Airway Collapse,9721392,R21EB027891,"['3-Dimensional', '3D Print', 'Adult', 'Affect', 'Age', 'Air', 'Airway Resistance', 'Area', 'Body mass index', 'Breathing', 'Caliber', 'Chronic', 'Chronic Obstructive Airway Disease', 'Clinical', 'Complex', 'Data', 'Data Set', 'Databases', 'Disease', 'Distal', 'Dyspnea', 'Exhalation', 'Forced expiratory volume function', 'Frequencies', 'Generations', 'Geometry', 'Goals', 'Image', 'Imagery', 'Individual', 'Intervention', 'Length', 'Liquid substance', 'Lung diseases', 'Maps', 'Measurement', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Neural Network Simulation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Phenotype', 'Physiological', 'Probability', 'Pulmonary Emphysema', 'Pulmonary Function Test/Forced Expiratory Volume 1', 'Quality of life', 'Race', 'Resistance', 'Scanning', 'Site', 'Smoker', 'Smoking', 'Spirometry', 'Stents', 'Symptoms', 'Testing', 'Therapeutic Intervention', 'Trachea', 'Training', 'Translations', 'Tube', 'United States', 'X-Ray Computed Tomography', 'airway obstruction', 'base', 'cartilaginous', 'cigarette smoking', 'clinical application', 'clinical predictors', 'clinically significant', 'convolutional neural network', 'deep learning', 'expiration', 'human subject', 'individual patient', 'insight', 'patient subsets', 'personalized medicine', 'pressure', 'respiratory', 'response', 'sex', 'simulation', 'three-dimensional modeling']",NIBIB,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R21,2019,226659,0.013521897790601891
"Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images SUMMARY For patients who undergo operative resections for gastrointestinal cancers, treatment selection fundamentally relies on the result of intra-operative assessment of the extent of the underlying cancer (i.e. staging). Specifically, the absence or presence of distant metastases dictates the role of operative treatment, chemotherapy, and radiation. However, the accuracy of operative staging (i.e. staging laparoscopy) is limited resulting in “under-staging” in up to 30% of these patients adversely affecting their cancer treatment. While operative “under-staging” is thought to equally affect many other malignancies, the cause is believed to arise from the inability of a conventional operative exam to reliably differentiate benign from metastatic lesions. Recent results demonstrated that expert surgeons on average misidentify 36±19% of grossly visible metastases questioning the accuracy of a human examiner.  Our long-term goal is to significantly improve the accuracy of operative staging laparoscopy in patients with gastrointestinal cancers by enhancing its capability to detect metastases through means of machine learning. To achieve this goal, we will use existing videos from staging laparoscopies and abstract images of peritoneal lesions that underwent biopsy (i.e. ground truth) as part of routine care (Aim 1). These images will then be used for the development of an automated classification system. The first step of developing the classification system involves training of a deep neural network with weak supervision that will allow for automated segmentation of lesions from their surrounding background (Aim 2). The second step will extract feature vectors from the lesions segmented in Aim 2 providing information for classification. The feature vectors will be extracted by two parallel processes: unsupervised deep learning and extraction of expert-selected features. The resulting feature vectors will be used to train a model allowing the classification (benign vs. metastasis) of any peritoneal lesion (Aim 3).  The results of this study are expected to provide material for future improvements / modifications of the proposed deep learning classification system as well as the foundation for future development of an automated surgical guidance system designed to help surgeons reliably identify metastases. Relevance: This study will establish a robust, yet simple method to improve the staging accuracy of standard laparoscopy via the detection of peritoneal metastases otherwise missed by human examiners. This will significantly improve cancer care through better treatment allocation. Further, it is expected that the detection of currently missed metastases will have a major impact on staging and treatment algorithms for a variety of cancers. PROJECT NARRATIVE During operations to treat gastrointestinal cancers, disease spread to other sites (i.e. metastases) is not recognized in a significant proportion of patients adversely affecting their cancer care. The proposed study will utilize artificial intelligence computer algorithms that will allow for automated identification and classification of such metastases. The results are expected to provide the foundation for future development of an automated surgical guidance system meant to enhance operative detection of metastases.",Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images,9984379,R03EB027900,"['Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benign', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Chemotherapy and/or radiation', 'Classification', 'Clinical', 'Computational Science', 'Computational algorithm', 'Data Sources', 'Detection', 'Development', 'Disease', 'Distant', 'Distant Metastasis', 'Engineering', 'Excision', 'Foundations', 'Future', 'Gallbladder Carcinoma', 'Goals', 'Healthcare', 'Human', 'Image', 'Laparoscopy', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of gastrointestinal tract', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pancreatic carcinoma', 'Patient observation', 'Patients', 'Peritoneal', 'Peritoneum', 'Preparation', 'Process', 'Recurrence', 'Role', 'Selection for Treatments', 'Site', 'Staging', 'Stomach Carcinoma', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'United States', 'artificial neural network', 'automated segmentation', 'cancer care', 'cancer recurrence', 'cancer therapy', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'information classification', 'intraperitoneal therapy', 'neural network', 'operation', 'outcome forecast', 'routine care', 'user-friendly', 'vector']",NIBIB,LAHEY CLINIC,R03,2020,77450,0.023680257547195528
"Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images SUMMARY For patients who undergo operative resections for gastrointestinal cancers, treatment selection fundamentally relies on the result of intra-operative assessment of the extent of the underlying cancer (i.e. staging). Specifically, the absence or presence of distant metastases dictates the role of operative treatment, chemotherapy, and radiation. However, the accuracy of operative staging (i.e. staging laparoscopy) is limited resulting in “under-staging” in up to 30% of these patients adversely affecting their cancer treatment. While operative “under-staging” is thought to equally affect many other malignancies, the cause is believed to arise from the inability of a conventional operative exam to reliably differentiate benign from metastatic lesions. Recent results demonstrated that expert surgeons on average misidentify 36±19% of grossly visible metastases questioning the accuracy of a human examiner.  Our long-term goal is to significantly improve the accuracy of operative staging laparoscopy in patients with gastrointestinal cancers by enhancing its capability to detect metastases through means of machine learning. To achieve this goal, we will use existing videos from staging laparoscopies and abstract images of peritoneal lesions that underwent biopsy (i.e. ground truth) as part of routine care (Aim 1). These images will then be used for the development of an automated classification system. The first step of developing the classification system involves training of a deep neural network with weak supervision that will allow for automated segmentation of lesions from their surrounding background (Aim 2). The second step will extract feature vectors from the lesions segmented in Aim 2 providing information for classification. The feature vectors will be extracted by two parallel processes: unsupervised deep learning and extraction of expert-selected features. The resulting feature vectors will be used to train a model allowing the classification (benign vs. metastasis) of any peritoneal lesion (Aim 3).  The results of this study are expected to provide material for future improvements / modifications of the proposed deep learning classification system as well as the foundation for future development of an automated surgical guidance system designed to help surgeons reliably identify metastases. Relevance: This study will establish a robust, yet simple method to improve the staging accuracy of standard laparoscopy via the detection of peritoneal metastases otherwise missed by human examiners. This will significantly improve cancer care through better treatment allocation. Further, it is expected that the detection of currently missed metastases will have a major impact on staging and treatment algorithms for a variety of cancers. PROJECT NARRATIVE During operations to treat gastrointestinal cancers, disease spread to other sites (i.e. metastases) is not recognized in a significant proportion of patients adversely affecting their cancer care. The proposed study will utilize artificial intelligence computer algorithms that will allow for automated identification and classification of such metastases. The results are expected to provide the foundation for future development of an automated surgical guidance system meant to enhance operative detection of metastases.",Development of Deep Neural Networks for Automated Detection of Cancer Metastases in Staging Laparoscopy Images,9727582,R03EB027900,"['Affect', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benign', 'Biopsy', 'Cancer Detection', 'Cancer Patient', 'Classification', 'Clinical', 'Computational Science', 'Computational algorithm', 'Data Sources', 'Detection', 'Development', 'Disease', 'Distant', 'Distant Metastasis', 'Engineering', 'Excision', 'Foundations', 'Future', 'Gallbladder Carcinoma', 'Goals', 'Healthcare', 'Human', 'Image', 'Laparoscopy', 'Learning', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of gastrointestinal tract', 'Medical Imaging', 'Methods', 'Modeling', 'Modification', 'Neoplasm Metastasis', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Pancreatic carcinoma', 'Patient observation', 'Patients', 'Peritoneal', 'Peritoneum', 'Preparation', 'Process', 'Radiation', 'Recurrence', 'Role', 'Selection for Treatments', 'Site', 'Staging', 'Stomach Carcinoma', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'United States', 'artificial neural network', 'cancer care', 'cancer recurrence', 'cancer therapy', 'chemotherapy', 'deep learning', 'deep neural network', 'design', 'experience', 'improved', 'information classification', 'intraperitoneal therapy', 'neural network', 'operation', 'outcome forecast', 'routine care', 'user-friendly', 'vector']",NIBIB,LAHEY CLINIC,R03,2019,77450,0.023680257547195528
"Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma PROJECT SUMMARY This project aims to apply novel machine learning techniques to recently developed optical imaging measurement to improve the accurate prediction and detection of glaucomatous progression. Complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and advanced pattern recognition/machine learning-based analysis techniques can find and use that hidden information. We will use mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1,800 patient and healthy eyes, available as the result of long-term NIH funding. We also will investigate deep learning and novel statistical techniques for this purpose. The required longitudinal measurements from several newly developed optical imaging techniques were not available to our previously funded NEI- supported work. The proposed work potentially can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care by informing clinical decision-making based on mathematically based, externally validated methods. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs. PROJECT NARRATIVE The proposed project will improve machine learning techniques for predicting and detecting glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments and will make use of a very large amount of data, obtained using previously awarded NIH funds, to do so. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neuro- degeneration within the visual pathways at structural and functional levels. The development of a clinically useful novel, empirical system for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and on the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.",Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma,9517942,R21EY027945,"['Address', 'Algorithms', 'Anatomy', 'Award', 'Caring', 'Classification', 'Clinical', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Defect', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Environment', 'Eye', 'Frequencies', 'Funding', 'Future', 'Gaussian model', 'Generations', 'Glaucoma', 'Goals', 'Health Personnel', 'Image', 'Imaging Device', 'Imaging Techniques', 'Instruction', 'Laboratories', 'Lasers', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perimetry', 'Physiologic Intraocular Pressure', 'Reporting', 'Research', 'Scanning', 'Science', 'Series', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Variant', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'care providers', 'clinical care', 'clinical decision-making', 'cost', 'deep learning', 'expectation', 'glaucoma test', 'high dimensionality', 'improved', 'independent component analysis', 'instrument', 'learning strategy', 'markov model', 'mathematical model', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'recruit', 'retinal nerve fiber layer', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2018,193750,-0.0316297918887194
"Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma PROJECT SUMMARY This project aims to apply novel machine learning techniques to recently developed optical imaging measurement to improve the accurate prediction and detection of glaucomatous progression. Complex functional and structural tests in daily use by eye care providers contain hidden information that is not fully used in current analyses, and advanced pattern recognition/machine learning-based analysis techniques can find and use that hidden information. We will use mathematically rigorous techniques to discover patterns of defects and to track their changes in longitudinal series of perimetric and optical imaging data from up to 1,800 patient and healthy eyes, available as the result of long-term NIH funding. We also will investigate deep learning and novel statistical techniques for this purpose. The required longitudinal measurements from several newly developed optical imaging techniques were not available to our previously funded NEI- supported work. The proposed work potentially can enhance significantly the medical and surgical treatment of glaucoma and reduce the cost of glaucoma care by informing clinical decision-making based on mathematically based, externally validated methods. Moreover, improved techniques for predicting and detecting glaucomatous progression can be used for refined subject recruitment and to define endpoints for clinical trials of intraocular pressure-lowering and neuroprotective drugs. PROJECT NARRATIVE The proposed project will improve machine learning techniques for predicting and detecting glaucomatous change in patient eyes tested longitudinally by visual field and optical imaging instruments and will make use of a very large amount of data, obtained using previously awarded NIH funds, to do so. This proposal addresses the current NEI Glaucoma and Optic Neuropathies Program objectives of developing improved diagnostic measures to characterize and detect optic nerve disease onset and characterize glaucomatous neuro- degeneration within the visual pathways at structural and functional levels. The development of a clinically useful novel, empirical system for predicting and detecting glaucomatous progression can have a significant impact on the future of clinical care and on the future of clinical trials designed to investigate IOP lowering and neuroprotective drugs.",Machine Learning Methods for Detecting Disease-related Functional and Structural Change in Glaucoma,9298423,R21EY027945,"['Address', 'Algorithms', 'Anatomy', 'Award', 'Caring', 'Classification', 'Clinical', 'Clinical Trials', 'Clinical Trials Design', 'Complex', 'Data', 'Defect', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Disease', 'Environment', 'Eye', 'Frequencies', 'Funding', 'Future', 'Gaussian model', 'Generations', 'Glaucoma', 'Goals', 'Health Personnel', 'Image', 'Imaging Device', 'Imaging Techniques', 'Instruction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Mathematics', 'Measurement', 'Measures', 'Medical', 'Methods', 'Modeling', 'National Eye Institute', 'Nerve Degeneration', 'Neuroprotective Agents', 'Onset of illness', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perimetry', 'Physiologic Intraocular Pressure', 'Provider', 'Recruitment Activity', 'Reporting', 'Research', 'Scanning', 'Science', 'Series', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Treatment Effectiveness', 'United States National Institutes of Health', 'Variant', 'Vision research', 'Visual Fields', 'Visual Pathways', 'Work', 'base', 'clinical care', 'clinical decision-making', 'cost', 'expectation', 'glaucoma test', 'high dimensionality', 'improved', 'independent component analysis', 'instrument', 'learning strategy', 'markov model', 'mathematical model', 'novel', 'optic nerve disorder', 'optical imaging', 'polarimetry', 'programs', 'retinal nerve fiber layer', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2017,232500,-0.0316297918887194
"Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes/eyelids and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to develop a more precise DR scoring scheme. This would help identify patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-Automated Lesion Characterization in Ultrawide-Field Retinal Images,10082348,R44EY028081,"['Agreement', 'Algorithms', 'Applications Grants', 'Biological', 'Blindness', 'Cataract', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Ensure', 'Exposure to', 'Eye', 'Eye diseases', 'Eyelash', 'Eyelid structure', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Internet', 'Lasers', 'Lesion', 'Light', 'Localized Lesion', 'Manuals', 'Measures', 'Modality', 'Morphologic artifacts', 'Online Systems', 'Ophthalmoscopy', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scheme', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Validation', 'Vision', 'Work', 'automated analysis', 'base', 'cloud based', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'success', 'tool', 'usability']",NEI,"EYENUK, INC.",R44,2020,1000000,0.09346336514678664
"Fully-automated lesion characterization in ultrawide-field retinal images Abstract  In this grant application we propose to develop, EyeReadUWF, a fully automated tool for lesion characterization in ultra-widefield scanning laser ophthalmoscopy (UWF SLO) images. In recent times non mydriatic UWF SLO imaging has been shown to be a promising alternative to conventional digital color fundus imaging for grading of diabetic eye diseases, with advantages including 130°-200° field-of-view showing more than 80% of the retina in a single image, no need for multiple fields, multiple flashes, or refocusing between field acquisitions, ability to penetrate media opacities like cataract, and lower rate of ungradable images. UWF SLO images are particularly suitable for detecting predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. Accurate quantification of presence and extent of PPLs can only be done by a robust automated tool that is specifically designed for the pseudo-colored images of UWF SLO modality. EyeReadUWF will automatically characterize lesions in pseudo colored UWF images while handling possible artifacts from eyelashes and determine the lesion predominance in peripheral and central regions of UWF image. The ability to accurately quantify the presence and extent of predominantly peripheral lesions in UWF SLO images can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research. Narrative The proposed tool, EyeReadUWF, will perform automated lesion characterization in ultra- widefield scanning laser ophthalmoscopy (UWF SLO) images to quantify the presence and extent of predominantly peripheral lesions (PPLs), which have been associated with higher risk of diabetic retinopathy (DR) progression. To the best of our knowledge, no commercial automated analysis tool is currently indicated for UWF SLO images. Once clinically validated, the tool can enable clinicians to triage patients with higher risk of DR progression and onset of PDR, have a positive impact on diabetic patient management, and aid drug discovery research.",Fully-automated lesion characterization in ultrawide-field retinal images,9559582,R43EY028081,"['Agreement', 'Algorithms', 'Anti-HIV Agents', 'Applications Grants', 'Architecture', 'Area', 'Biological', 'Blindness', 'Cataract', 'Categories', 'Characteristics', 'Clinical', 'Cloud Computing', 'Color', 'Competence', 'Computer software', 'Coupled', 'Data Set', 'Detection', 'Development', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Engineering', 'Ensure', 'Exposure to', 'Exudate', 'Eye', 'Eye diseases', 'Eyelash', 'Gold', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Lasers', 'Lesion', 'Light', 'Manuals', 'Measures', 'Microaneurysm', 'Modality', 'Morphologic artifacts', 'Normalcy', 'Ophthalmoscopy', 'Output', 'Patient Triage', 'Patients', 'Penetration', 'Peripheral', 'Phase', 'Receiver Operating Characteristics', 'Research', 'Retina', 'Retinal Diseases', 'Risk', 'Scanning', 'Scientist', 'Screening procedure', 'Severities', 'Small Business Innovation Research Grant', 'Software Engineering', 'Speed', 'Spottings', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Vision', 'Work', 'base', 'deep learning', 'design', 'diabetic', 'diabetic patient', 'digital', 'drug discovery', 'experience', 'fovea centralis', 'fundus imaging', 'high risk', 'image processing', 'imaging modality', 'interest', 'operation', 'proliferative diabetic retinopathy', 'retinal imaging', 'screening', 'screening program', 'software development', 'success', 'tool', 'usability', 'user-friendly']",NEI,"EYENUK, INC.",R43,2018,216440,0.09346336514678664
"LONG-TERM PLASMA EXCHANGE IN FAMILIAL HYPERCHOLESTEROLEM The objective of this study is to determine in subjects heterozygous for familial hypercholesterolemia (FH) whether the very massive reduction in plasma total and low density lipoprotein cholesterol (approximately 120 mg/dl) which can be achieved using repetitive isovolumetric plasma exchange (RPE) coupled with hypocholesterolemic drug therapy can induce regression or prevent progression of atheromatous coronary artery disease.  The substantial decrease and improved long term control of low density lipoprotein cholesterol by RPE coupled with hypocholesterolemic drugs should amplify the preliminary evidence which has indicated that regression of early femoral atherosclerosis and nonprogression of advanced coronary lesions can be achieved by drug treatment alone in heterozygous FH.  We propose to undertake long-term (four years) RPE at two week intervals in fifteen heterozygous subjects with FH.  Pretreatment and within treatment coronary atheromatous lesions and ventricular function and perfusion will be assessed by serial quantitative, computerized coronary angiography, rest and exercise Thallium-201 perfusion studies, respectively.  The effectiveness of RPE will be judged not only by longitudinal studies of the plasma exchange group, but also in a randomized concurrent control group of subjects receiving only maximal drug therapy.  In addition, comparison will also be made against two groups of patients (historical controls) selected by Dr. John Brensike from the type II coronary intervention study recently completed at the NIH.  These patients will be selected using the same criteria for entry into this study and will have been treated with diet alone or diet plus cholestyramine.  The subjects will have undergone cardiac catheterization at the start of the study, at two years after entry, and at five years after entry.  In effect, therefore, the results of repeat coronary angiography in fifteen patients who undergo massive reductions in plasma cholesterol by REP plus maximal drug therapy will be compared to three control groups: a randomized concurrently treated group (diet plus maximal drug therapy), and two historical NIH concurrently treated groups (one with dietary treatment only, and a group on diet plus cholestyramine).  n/a",LONG-TERM PLASMA EXCHANGE IN FAMILIAL HYPERCHOLESTEROLEM,3339740,R01HL028356,"['angiography', ' antiatherogenic agent', ' artificial intelligence', ' atherosclerosis', ' biological fluid transport', ' cardiovascular disorder chemotherapy', ' cardiovascular stress test', ' cholestyramine', ' cineangiocardiography', ' coronary disorder', ' diet therapy', ' familial hyperlipoproteinemia type II', ' heart imaging /visualization /scanning', ' human subject', ' human therapy evaluation', ' longitudinal human study', ' low density lipoprotein', ' nutrition related tag', ' phantom model', ' plasmapheresis', ' remission /regression']",NHLBI,UNIVERSITY OF CINCINNATI,R01,1987,332629,0.011920190158183921
"LONG-TERM PLASMA EXCHANGE IN FAMILIAL HYPERCHOLESTEROLEM The objective of this study is to determine in subjects heterozygous for familial hypercholesterolemia (FH) whether the very massive reduction in plasma total and low density lipoprotein cholesterol (approximately 120 mg/dl) which can be achieved using repetitive isovolumetric plasma exchange (RPE) coupled with hypocholesterolemic drug therapy can induce regression or prevent progression of atheromatous coronary artery disease.  The substantial decrease and improved long term control of low density lipoprotein cholesterol by RPE coupled with hypocholesterolemic drugs should amplify the preliminary evidence which has indicated that regression of early femoral atherosclerosis and nonprogression of advanced coronary lesions can be achieved by drug treatment alone in heterozygous FH.  We propose to undertake long-term (four years) RPE at two week intervals in fifteen heterozygous subjects with FH.  Pretreatment and within treatment coronary atheromatous lesions and ventricular function and perfusion will be assessed by serial quantitative, computerized coronary angiography, rest and exercise Thallium-201 perfusion studies, respectively.  The effectiveness of RPE will be judged not only by longitudinal studies of the plasma exchange group, but also in a randomized concurrent control group of subjects receiving only maximal drug therapy.  In addition, comparison will also be made against two groups of patients (historical controls) selected by Dr. John Brensike from the type II coronary intervention study recently completed at the NIH.  These patients will be selected using the same criteria for entry into this study and will have been treated with diet alone or diet plus cholestyramine.  The subjects will have undergone cardiac catheterization at the start of the study, at two years after entry, and at five years after entry.  In effect, therefore, the results of repeat coronary angiography in fifteen patients who undergo massive reductions in plasma cholesterol by REP plus maximal drug therapy will be compared to three control groups: a randomized concurrently treated group (diet plus maximal drug therapy), and two historical NIH concurrently treated groups (one with dietary treatment only, and a group on diet plus cholestyramine).  n/a",LONG-TERM PLASMA EXCHANGE IN FAMILIAL HYPERCHOLESTEROLEM,3339739,R01HL028356,"['angiography', ' antiatherogenic agent', ' artificial intelligence', ' atherosclerosis', ' biological fluid transport', ' cardiovascular disorder chemotherapy', ' cardiovascular stress test', ' cholestyramine', ' cineangiocardiography', ' coronary disorder', ' diet therapy', ' familial hyperlipoproteinemia type II', ' heart imaging /visualization /scanning', ' human subject', ' human therapy evaluation', ' longitudinal human study', ' low density lipoprotein', ' nutrition related tag', ' phantom model', ' plasmapheresis', ' remission /regression']",NHLBI,UNIVERSITY OF CINCINNATI,R01,1986,453314,0.011920190158183921
"LONG-TERM PLASMA EXCHANGE IN FAMILIAL HYPERCHOLESTEROLEM The objective of this study is to determine in subjects heterozygous for familial hypercholesterolemia (FH) whether the very massive reduction in plasma total and low density lipoprotein cholesterol (approximately 120 mg/dl) which can be achieved using repetitive isovolumetric plasma exchange (RPE) coupled with hypocholesterolemic drug therapy can induce regression or prevent progression of atheromatous coronary artery disease.  The substantial decrease and improved long term control of low density lipoprotein cholesterol by RPE coupled with hypocholesterolemic drugs should amplify the preliminary evidence which has indicated that regression of early femoral atherosclerosis and nonprogression of advanced coronary lesions can be achieved by drug treatment alone in heterozygous FH.  We propose to undertake long-term (four years) RPE at two week intervals in fifteen heterozygous subjects with FH.  Pretreatment and within treatment coronary atheromatous lesions and ventricular function and perfusion will be assessed by serial quantitative, computerized coronary angiography, rest and exercise Thallium-201 perfusion studies, respectively.  The effectiveness of RPE will be judged not only by longitudinal studies of the plasma exchange group, but also in a randomized concurrent control group of subjects receiving only maximal drug therapy.  In addition, comparison will also be made against two groups of patients (historical controls) selected by Dr. John Brensike from the type II coronary intervention study recently completed at the NIH.  These patients will be selected using the same criteria for entry into this study and will have been treated with diet alone or diet plus cholestyramine.  The subjects will have undergone cardiac catheterization at the start of the study, at two years after entry, and at five years after entry.  In effect, therefore, the results of repeat coronary angiography in fifteen patients who undergo massive reductions in plasma cholesterol by REP plus maximal drug therapy will be compared to three control groups: a randomized concurrently treated group (diet plus maximal drug therapy), and two historical NIH concurrently treated groups (one with dietary treatment only, and a group on diet plus cholestyramine).  n/a",LONG-TERM PLASMA EXCHANGE IN FAMILIAL HYPERCHOLESTEROLEM,3339738,R01HL028356,"['angiography', ' antiatherogenic agent', ' artificial intelligence', ' atherosclerosis', ' biological fluid transport', ' cardiovascular disorder chemotherapy', ' cardiovascular stress test', ' cholestyramine', ' cineangiocardiography', ' coronary disorder', ' diet therapy', ' familial hyperlipoproteinemia type II', ' heart imaging /visualization /scanning', ' human subject', ' human therapy evaluation', ' longitudinal human study', ' low density lipoprotein', ' nutrition related tag', ' phantom model', ' plasmapheresis', ' remission /regression']",NHLBI,UNIVERSITY OF CINCINNATI,R01,1985,424226,0.011920190158183921
"Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo 1 Dermatologists rely on visual (clinical widefield) and dermoscopic examination of skin lesions to guide the need  2 for biopsy. With this approach, sensitivity is high, but specificity tends to be quite variable and lower, resulting  3 in millions of biopsies of benign lesions every year. To improve specificity, several optical technologies are  4 being developed to noninvasively detect skin cancer. Of these, reflectance confocal microscopy (RCM) is the  5 furthest advanced in clinical utility, proven for diagnosing skin cancers with high sensitivity and specificity.  6 RCM imaging, guided by dermoscopy, detects skin cancers with 2 times superior specificity, and reduces the  7 benign-to-malignant biopsy rate by 2 times, compared to that with dermoscopy alone. In 2016, the Centers for  8 Medicare and Medicaid Services granted current procedural terminology (CPT) reimbursement codes for RCM  9 imaging of skin. RCM imaging combined with dermoscopy is now advancing into clinical practice, sparing pa- 10 tients from unnecessary biopsies of benign lesions. However, toward widespread acceptance and adoption, a 11 key challenge is that clinical widefield examination, dermoscopy and RCM imaging are currently performed as 12 three separate procedures with separate devices. Clinicians do not precisely know the location of RCM imag- 13 es relative to the surrounding contextual lesion morphology that is seen with clinical widefield examination and 14 dermoscopy, resulting in lower and more variable diagnostic accuracy (particularly, sensitivity, positive and 15 negative predictive values). We propose a novel solution: (i) a new objective lens with an integrated micro- 16 camera, to deliver a concurrent widefield image of the skin surface surrounding the location of RCM imaging; 17 (ii) a new software algorithm for widefield image-based tracking of the location of RCM images within a dermoscopic 18 field of view; (iii) a new diagnostic approach that will proactively use widefield imaging to locate RCM images in 19 dermoscopic images. We intend to deliver this integrated widefield clinical, dermoscopic and RCM imaging ap- 20 proach into the clinic, toward a new standard for more accurate, consistent and faster RCM imaging to guide 21 patient care. Preliminary studies with a “mock” objective lens and micro-camera on a bench-top set-up 22 demonstrated excellent optical sectioning (~2 µm) and resolution (~1 µm) for RCM imaging, and accurate and 23 repeatable location of RCM fields-of-view within the widefield image. RCM images showed excellent cellular 24 and morphologic detail in vivo. Our specific aims are (1) to develop a handheld reflectance confocal micro- 25 scope with integrated widefield camera; (2) to develop image processing algorithms for real-time widefield im- 26 aging-guided tracking of RCM image locations within dermoscopic fields; (3) to test and validate performance 27 on 100 patients. Although our proposition is for skin lesions, the research will surely have wider impact for 28 imaging in other settings, particularly, with miniaturized confocal microscopes and endoscopes, which have 29 very small fields-of-view. We are a highly synergistic team from Montana State University, Memorial Sloan 30 Kettering Cancer Center, Northeastern University and Caliber Imaging and Diagnostics (formerly, Lucid Inc.). RELEVANCE TO PUBLIC HEALTH Clinical examination and dermoscopy combined with reflectance confocal microscopy (RCM) imaging is a newly emerging optical imaging procedure that can noninvasively guide diagnosis of skin cancers, and reduce the need for biopsy. However, clinical examination, dermoscopy and RCM imaging are currently performed as three separate procedures with separate devices, limiting effectiveness and impact. We propose a device to combine the three into a single procedure, which will help dermatologists and patients by making the skin examinations quicker, more accurate and more consistent, expanding the impact of this proven approach.",Simultaneous coaxial widefield imaging and reflectance confocal microscopy for improved diagnosis of skin cancers in vivo,9860776,R01EB028752,"['Address', 'Adoption', 'Affordable Care Act', 'Aging', 'Algorithmic Software', 'Algorithms', 'Benign', 'Biopsy', 'Caliber', 'Cancer Center', 'Categories', 'Cellular Morphology', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Current Procedural Terminology', 'Dermatologist', 'Dermatology', 'Dermis', 'Dermoscopy', 'Devices', 'Diagnosis', 'Diagnostic', 'Drops', 'Effectiveness', 'Endoscopes', 'Engineering', 'Epidermis', 'Grant', 'Head and neck structure', 'Image', 'Imaging Techniques', 'Lesion', 'Lesion by Morphology', 'Letters', 'Location', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medicaid services', 'Medicare/Medicaid', 'Memorial Sloan-Kettering Cancer Center', 'Microscope', 'Microscopic', 'Montana', 'Morphology', 'Optics', 'Oral', 'Outcome', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sensitivity and Specificity', 'Site', 'Skin', 'Skin Cancer', 'Specificity', 'Surface', 'Technology', 'Testing', 'Time', 'United States Centers for Medicare and Medicaid Services', 'Universities', 'Visual', 'base', 'blind', 'cancer diagnosis', 'clinical examination', 'clinical practice', 'cost', 'design', 'design and construction', 'diagnostic accuracy', 'gastrointestinal', 'image guided', 'image processing', 'image registration', 'improved', 'in vivo', 'innovation', 'instrument', 'instrumentation', 'interest', 'lens', 'medical specialties', 'microscopic imaging', 'miniaturize', 'novel', 'novel diagnostics', 'optical imaging', 'prospective test', 'reflectance confocal microscopy', 'response', 'routine practice', 'skin lesion', 'volunteer']",NIBIB,MONTANA STATE UNIVERSITY - BOZEMAN,R01,2020,649717,0.03998551141960509
"Optimizing Acquisition and Reconstruction of Under-sampled MRI for Signal Detection PROJECT SUMMARY Magnetic resonance imaging (MRI) is a versatile imaging modality that suffers from slow acquisition times which is a challenge for both time sensitive applications and for patient throughput. Accelerating MRI would benefit patients both by reducing the time they need to be in the scanner and in reducing the cost of healthcare. This project is part of a larger scientific effort to accelerate MRI while maintaining the diagnostic quality. Acceleration, even by a factor of two would result in a major advance for public health. Two of the current approaches to accelerate MRI rely on collecting less data (under-sampling) and constrained or deep learning reconstruction. These approaches can lead to images with diagnostic quality with significant under-sampling but may suffer from artifacts which are hard to characterize. Specifically, this project will optimize the performance of constrained reconstruction and deep learning on detecting subtle lesions in acquiring and reconstructing under-sampled MRI. To carry out this optimization, we will first develop the methods required for detection of lesions by machine and human observer models. Then the models will be validated by psychophysical studies where humans perform the detection task. In the first aim of this project, we will optimize constrained reconstruction based on the ideal linear observer. We will consider under-sampled acquisition strategies in 2D MRI including one and two dimensional subsampling methods with constrained reconstruction using both wavelet and total variation constraints. We will perform simulations using anatomical backgrounds both for lesions which match the prior information of the constraints and those which do not to better understand how choices in acquisition and reconstruction affect ideal detection. While the ideal linear observer approximates the best possible detection, typically the signal detection is carried out by a human. In the second aim, we will optimize constrained reconstruction using human observer models and validate the models using human observer studies. A recent approach to reconstruction of under- sampled images is based on deep learning. In the third aim, this work will optimize deep learning reconstruction based on ideal and human observers. Due to the complexity of the deep learning approach, having this task-based approach to optimization is particularly relevant. This project will optimize a network using signal detection to better understand how training and architecture choices in the neural network affect detection of lesions which are not included in training images. This research project will help to strengthen the research environment at Manhattan College by involving students in biomedical research incorporating applied mathematics, statistics and data science. PROJECT NARRATIVE Magnetic resonance imaging (MRI) is a versatile imaging modality that suffers from slow acquisition times which is a challenge for both time sensitive applications and for patient throughput. Accelerating MRI would benefit patients and improve public health both by reducing the time they need to be in the scanner and in reducing the cost of healthcare. This project would advance a larger scientific effort to accelerate MRI while maintaining the diagnostic quality by optimizing the performance of constrained reconstruction and deep learning on detecting subtle lesions in accelerated MRI.",Optimizing Acquisition and Reconstruction of Under-sampled MRI for Signal Detection,9880534,R15EB029172,"['Acceleration', 'Affect', 'Anatomy', 'Architecture', 'Biomedical Research', 'Collaborations', 'Data', 'Data Science', 'Dependence', 'Detection', 'Development', 'Diagnostic', 'Dimensions', 'Environment', 'Evaluation', 'Gaussian model', 'Grant', 'Health Care Costs', 'Human', 'Image', 'Lead', 'Lesion', 'Magnetic Resonance Imaging', 'Mathematics', 'Methods', 'Modeling', 'Morphologic artifacts', 'Patients', 'Performance', 'Positron-Emission Tomography', 'Psychophysics', 'Public Health', 'Research', 'Research Project Grants', 'Resolution', 'Sampling', 'Signal Transduction', 'Students', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'college', 'deep learning', 'density', 'flexibility', 'imaging modality', 'improved', 'insight', 'neural network', 'neural network architecture', 'predictive modeling', 'reconstruction', 'simulation', 'single photon emission computed tomography', 'statistics', 'two-dimensional']",NIBIB,MANHATTAN COLLEGE,R15,2020,395210,0.11764204479645597
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9824066,R21ES029722,"['Adult', 'Algorithms', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2019,221376,-0.019184607299743528
"Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study PROJECT SUMMARY The built environment is an important modifiable determinant of human health, yet our ability to understand its effects on human health have been limited by the lack of scalable data on specific components (and exposures) of the built environment. The emergence of ubiquitous geo-referenced imagery in the United States (e.g. Google Street View Imagery), combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring street-level built environment features at scales needed for population-based research. To develop and demonstrate the potential of deep learning algorithms for environmental health research we will: develop methods to assess green space features using street view imagery and deep learning algorithms; create new deep learning algorithms to predict urban green space quality, stress reduction and restorative potential; and apply new street view measures to 9,070 adult Twin Pairs in the Washington Twin Registry to determine associations between green space and mental health. Our proposed study will dramatically move the field of environmental health forward by provided a completely new, transferable and scalable exposure assessment method for assessing built environment exposures relevant to human health and provide robust information on how urban green space influences mental health. Overall, our new approach will provide rich new data sources for environmental epidemiologists, city planners, policy makers and neighborhoods and communities at large. PROJECT NARRATIVE The built environment is an important determinant of human health, yet our ability to measure specific components of the built environment relevant to health is limited. The availability of street view imagery, combined with recent advances in image processing using deep learning algorithms, offers unprecedented opportunity for measuring detailed built environment features at scales needed for population-based research. Here we develop such approaches for green space and evaluate associations with mental health using a unique Twin analysis.",Deep Learning of Street View Imagery to assess Urban Green Space Relationships with Mental Health:  A Twin Study,9998736,R21ES029722,"['Adult', 'Anxiety', 'Attention', 'Baseline Surveys', 'Biological', 'Buffers', 'Case Study', 'Cities', 'Communities', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Databases', 'Dizygotic Twins', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Epidemiologist', 'Esthetics', 'Flowers', 'Genetic', 'Green space', 'Health', 'Human', 'Image', 'Imagery', 'Link', 'Measures', 'Mechanics', 'Mental Depression', 'Mental Health', 'Mental Health Associations', 'Methods', 'Monozygotic twins', 'Nature', 'Neighborhoods', 'Neurocognitive', 'Outcome Measure', 'Pathway interactions', 'Perception', 'Plants', 'Poaceae', 'Policy Maker', 'Population Research', 'Psychological Transfer', 'Registries', 'Research', 'Rest', 'Sampling', 'Stress', 'Surveys', 'Training', 'Trees', 'Twin Multiple Birth', 'Twin Studies', 'United States', 'Washington', 'base', 'biological adaptation to stress', 'built environment', 'crowdsourcing', 'deep learning', 'deep learning algorithm', 'directed attention', 'distraction', 'early life exposure', 'experimental study', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'learning strategy', 'longitudinal analysis', 'novel', 'novel strategies', 'response', 'restoration', 'segmentation algorithm', 'stress reduction', 'theories']",NIEHS,OREGON STATE UNIVERSITY,R21,2020,185625,-0.019184607299743528
"Next-Generation Ultrasound Localization Microscopy Project Summary/Abstract Abnormal alterations of tissue microcirculation are often associated with early stage of tissue pathology. Detection and characterization of these early microvascular abnormalities can greatly benefit clinical diagnosis and treatment monitoring as well as facilitating the creation of new therapies to counter disease development. For decades, there has been a longstanding quest for the development of a clinical imaging modality that can noninvasively and directly image such tissue microvascular variations. To date, however, such an imaging method remains elusive due to the fundamental compromise between imaging spatial resolution and depth penetration. Therefore, the long-term objective of this project is to fulfill this unmet clinical need by developing the next-generation ultrasound localization microscopy (ULM), which is an ultrasound-based imaging technique that can directly assess structural and functional tissue microvasculature in vivo in humans at a clinically relevant depth. Different from other imaging modalities, ULM is not limited by the resolution-penetration compromise: ULM can noninvasively image capillary-scale microvessels at several centimeters depth and quantitatively measure their blood flow speed (as low as 1 mm/s). Such combination of deep imaging penetration and exquisite spatial resolution and the unique functionality of measuring small vessel blood flow speed make ULM a promising technique for many clinical applications including cancer and cardiovascular diseases. At present, however, ULM is not ready for clinical use due to several key technical limitations: 1) ULM data acquisition is very slow (tens of seconds with breath holding); 2) ULM post-processing is very expensive computationally (several hours to generate a single 2D ULM image); 3) ULM is difficult to be extended to 3D imaging (which is important for comprehensive evaluation of tissue microvasculature such as in cancer applications). These limitations largely forbids ULM from being effectively used in the clinic to provide useful microvascular biomarkers. In this proposal, we will concentrate on addressing these technical barriers and transform ULM to a truly useful clinical imaging tool. Our approach synergistically combines deep learning (DL), parallel computing, and ultrafast 3D ultrasound imaging to fundamentally shorten ULM data acquisition time, substantially accelerate ULM post-processing, and enhance ULM to 3D imaging. Our first aim will develop and validate DL-based ULM data processing algorithms that would enable real-time 4D morphometric ULM and fast 3D quantitative ULM. Our method uniquely collects real labeled optical imaging data on a chicken embryo microvessel model for DL training. Our second aim will focus on realizing 3D-ULM on a 2D row-column-addressing transducer with ultrafast 3D plane wave imaging. We will develop a DL-based beamforming technique to enable high-fidelity 3D microbubble imaging for robust 3D-ULM. Our final aim will focus on validating the in vivo performance of the newly developed 3D-ULM imaging techniques on a mouse tumor model. We will be collaborating with world-renowned experts in deep learning, optical imaging, and comparative medicine at the University of Illinois to accomplish these aims of the proposal. Project Narrative Imaging-based detection and characterization of abnormal tissue microvascular variations is clinically significant for diagnosis, treatment evaluation, and therapy development in many pathologies such as cancer, cardiovascular diseases, inflammation, and neurodegenerative diseases. At present, there is no viable noninvasive imaging tool that can fulfill this important clinical need. To fill this gap, we propose to develop a new ultrasound-based super-resolution microvessel imaging technique that can directly and quantitatively assess the structure and the function of tissue microcirculation in vivo in humans.",Next-Generation Ultrasound Localization Microscopy,10039725,R21EB030072,"['3-Dimensional', '3D ultrasound', '4T1', 'Address', 'Adopted', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Animals', 'Biological Markers', 'Blood', 'Blood Vessels', 'Blood capillaries', 'Blood flow', 'Breast Carcinoma', 'Cardiovascular Diseases', 'Chickens', 'Clinic', 'Clinical', 'Clinical Treatment', 'Complex', 'Data', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Embryo', 'Evaluation', 'Goals', 'Health', 'Hour', 'Human', 'Illinois', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging Techniques', 'Incentives', 'Inflammation', 'Knowledge', 'Label', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Medicine', 'Metabolic', 'Methods', 'Microbubbles', 'Microcirculation', 'Microscopy', 'Modality', 'Modeling', 'Modification', 'Monitor', 'Morphologic artifacts', 'Mus', 'Neurodegenerative Disorders', 'Noise', 'Nutrient', 'Organ', 'Oxygen', 'Pathogenesis', 'Pathology', 'Patients', 'Penetration', 'Performance', 'Property', 'Provider', 'Resolution', 'Series', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'Techniques', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Training', 'Transducers', 'Transportation', 'Ultrasonic Transducer', 'Ultrasonography', 'Universities', 'Variant', 'Vendor', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically relevant', 'clinically significant', 'comparative', 'computerized data processing', 'cost', 'data acquisition', 'deep learning', 'deep neural network', 'hemodynamics', 'imaging detection', 'imaging modality', 'in vivo', 'in vivo imaging', 'innovation', 'instrumentation', 'microCT', 'microscopic imaging', 'next generation', 'non-invasive imaging', 'novel', 'novel therapeutics', 'optical imaging', 'parallel computer', 'performance tests', 'quantitative ultrasound', 'real-time images', 'therapy development', 'tool', 'tumor', 'two photon microscopy']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,565346,0.02342338674270797
"Optimization of PET Image Reconstruction for Lesion Detection Optimization of PET Image Reconstruction for Lesion Detection Abstract PET is a molecular imaging modality widely used in oncology studies due to its high sensitivity and the potential of early diagnosis. For neuroendocrine tumors (NETs), 68Ga-DOTATATE PET has been recently used in clinical routine for imaging NETs in adult and pediatric patients since 2016. It plays an important role in the diagnosis and staging of NETs. However, compared to 18F-FDG PET, the image quality of 68Ga-DOTATATE PET is lower due to much larger positron range, shorter half-life, and lower dose administration limited by generator capacity. All of these compromises the lesion detectability of 68Ga-DOTATATE PET, especially for small lesions, and can potentially lead to inaccurate NET diagnosis. As 68Ga-DOTATATE PET is increasingly used in clinics, there is an urgent and unmet need to further optimize 68Ga-DOTATATE PET/CT imaging for NET detection. Recently, data-driven methods have been developed for PET image denoising, where the PET system model is not considered. As the tumor-to-background ratio of 68Ga-DOTATATE PET is greater than 18F-FDG PET, the lesion recovery of 68Ga-DOTATATE PET can be hugely influenced by the smoothing effects as well as potential mismatches between training and testing datasets. In this study, we propose a novel data- informed and lesion detection-driven image reconstruction framework. The PET system model, image denoising module, and lesion-detection module will all be included in this reconstruction framework. The two specific aims of this exploratory proposal are (1) to develop a lesion detection-driven PET image reconstruction framework and validate it based on comprehensive computer simulations, (2) to apply the proposed reconstruction framework to existing clinical 68Ga-DOTATATE PET/CT datasets and test it based on various figure-of-merits. We expect that the integrated outcome of the specific aims will be a novel and robust image reconstruction framework to better recover lesions in a 68Ga- DOTATATE PET scan, which is essential for NET managements. Optimization of PET Image Reconstruction for Lesion Detection  Project Narrative Positron emission tomography (PET) is an imaging modality widely used in oncology. This project aims to develop a novel lesion detection-driven PET image reconstruction framework. Success of this project can enhance the lesion detectability of current PET imaging protocols, e.g. 68Ga-DOTATATE PET/CT scanning for neuroendocrine tumors (NETs).",Optimization of PET Image Reconstruction for Lesion Detection,10041119,R03EB030280,"['Address', 'Adult', 'Algorithms', 'Awareness', 'Biological Models', 'Clinic', 'Clinical', 'Computer Simulation', 'Data', 'Data Set', 'Detection', 'Diagnosis', 'Distant Metastasis', 'Dose', 'Early Diagnosis', 'Enhancing Lesion', 'FOLH1 gene', 'Gallium', 'Goals', 'Half-Life', 'Image', 'Incidence', 'Injections', 'Label', 'Lead', 'Lesion', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Neuroendocrine Tumors', 'Noise', 'Oncology', 'Outcome', 'Output', 'Patients', 'Performance', 'Phase', 'Physics', 'Play', 'Positron', 'Positron-Emission Tomography', 'Prevalence', 'Protocols documentation', 'Radionuclide Imaging', 'Reader', 'Recovery', 'Recurrence', 'Resolution', 'Role', 'Savings', 'Sensitivity and Specificity', 'Staging', 'Testing', 'Time', 'Tracer', 'Training', 'United States', 'Validation', 'Vendor', 'X-Ray Computed Tomography', 'base', 'cancer type', 'deep learning', 'denoising', 'effectiveness validation', 'experience', 'fluorodeoxyglucose', 'image reconstruction', 'imaging modality', 'improved', 'learning strategy', 'molecular imaging', 'neural network', 'neuroendocrine differentiation', 'novel', 'outcome forecast', 'pediatric patients', 'pentetreotide', 'radiologist', 'radiotracer', 'reconstruction', 'routine imaging', 'success', 'treatment optimization', 'treatment planning', 'tumor']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R03,2020,94255,0.09280256789246791
"LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research PROJECT SUMMARY Imaging forms the backbone of living subjects research. Living subjects research is both essential to the progress of translational medicine and very expensive. The research community actively seeks to develop and validate new clinical endpoints to solve a range of etiology, natural history, diagnostic and prognostic problems. This project aims to develop and commercialize LATTICE, an Electronic Research Record, Image Management and Sharing Solution, and Deep Learning Platform. LATTICE is designed to increase the efficiency of imaging-driven biomedical research and clinical trials. This efficiency is accomplished first through a structured workflow that includes protocol management, subject scheduling, and records collection from multiple imaging modalities. Access to imaging and associated data within the same workflow simplifies the process for the research team. Structuring the data into a de-identified, privacy-managed Image Bank enables sharing for collaboration and re-use for retrospective research. Image processing algorithms connected to the Image Bank facilitate batch analysis, while the system also provides a platform for the development of new image-based outcome measures and clinical endpoints. A key objective of LATTICE is to enable investigators and collaborators to accelerate the translation of insights to the clinic with maximum efficiency. Successful translation requires structuring the workflow, record keeping, and protocols into a rigorous, transparent, reproducible and validated process. LATTICE is designed to reduce the friction in translating successful research projects to the clinic. Researchers in the Advanced Ocular Imaging Program (AOIP) at the Medical College of Wisconsin developed elements of LATTICE as separate technologies. The Specific Aims of this proposal are directed to an integrated workflow addressing a broader set of objectives. The AOIP LATTICE Electronic Research Record will be translated into a commercially managed repository and brought under regulatory Design Control. The current AOIP Image Bank containing 3,000,000 de- identified retinal images will be integrated into the LATTICE workflow. Critically, this integration will allow the sharing of the Image Bank with external researchers. Three retinal image process algorithms that operate on retinal images will integrate into this workflow. These algorithms include analysis of adaptive optics images of the fundus, analysis of the foveal avascular zone from optical coherence tomography angiography (OCTA), and model-based analysis of the fovea imaged with OCT. A computational deep learning workflow will also be prototyped using a cloud-based architecture. This final workflow will be constructed to demonstrate the feasibility of deploying a collaborative deep learning environment for the development of new clinical endpoints using shared, de-identified images. LATTICE will be a unique system for both prospective and retrospective translational research. LATTICE will make a profound impact on the cost of managing image-based research and add leverage to translational research expenditures for moving insights into the clinic. PROJECT NARRATIVE LATTICE is an innovative electronic research record and development platform for image-based ophthalmic research. LATTICE is designed to reduce the cost of translational research, promote the re- use of images, and simplify the development and application of new techniques to analyze medical images. LATTICE will integrate research workflow tools with a database of 3,000,000 retinal images and advanced image processing software to accelerate the process of translating eye research insights from the lab to the clinic.",LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research,9777970,R43EY030408,"['Address', 'Algorithmic Software', 'Algorithms', 'Angiography', 'Architecture', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnostic', 'Documentation', 'Elements', 'Etiology', 'Expenditure', 'Eye', 'Friction', 'Future', 'Health Insurance Portability and Accountability Act', 'Image', 'Libraries', 'Medical Imaging', 'Methods', 'Modeling', 'Morphology', 'Natural History', 'Optical Coherence Tomography', 'Outcome Measure', 'Output', 'Privacy', 'Process', 'Protocols documentation', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Scanning', 'Schedule', 'Secure', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Translational Research', 'Translations', 'Vertebral column', 'Wisconsin', 'Writing', 'adaptive optics', 'base', 'cloud based', 'cost', 'deep learning', 'design', 'educational atmosphere', 'fovea centralis', 'fundus imaging', 'image processing', 'imaging modality', 'imaging platform', 'imaging program', 'innovation', 'insight', 'medical schools', 'ocular imaging', 'operation', 'prognostic', 'programs', 'prospective', 'prototype', 'repository', 'retinal imaging', 'system architecture', 'tool', 'translational medicine', 'web services', 'wiki']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R43,2019,299999,0.04276811467187848
"Advancing Ulcerative Colitis Monitoring with Deep Learning Models Project Summary/Abstract The number of practicing pathologists around the world is expected to decrease by as much as 30% over the next two decades, with some of the world’s poorest countries having a ratio of only one pathologist to many hundreds of thousands of people. At the same time, the diagnostic caseload that requires their expertise in clinical trials and hospital settings will continue to grow. The digitization of pathology data, coupled with the use of machine learning techniques for analyzing and scoring the data, provides exciting opportunities to make the field of pathology more efficient and scalable, even as the workforce continues to evolve. Deep learning in particular provides the potential to enhance the interpretation of medical images by improving the detection of image-based biomarkers for a broad range of diseases. Image interpretation plays an important role in patient eligibility and endpoint determination during the course of clinical trials. For patients with ulcerative colitis, the development of trained and reliable algorithms that can help pathologists identify disease progression and response to treatment in a timely and effective manner can provide benefit in two important ways. First, it will help to ensure that the most appropriate score for histological disease severity is being assigned to each image using the Robarts Histopathology Index (RHI) or similar grading scale. Second, it will support a triage process by which images known to contain non- healthy tissues can be prioritized for earlier assessment. Through a unique partnership between Azavea, a geospatial technology and machine learning firm, and Robarts, a clinical trials organization, the proposed research will begin to address these needs by developing deep learning algorithms for histopathology digital image analysis, testing them on machine-readable annotations of medical imagery from previous clinical studies, and exposing them through a metadata- searchable interface that will enable the images to be categorized and quickly accessed by pathologists and others to support reader training and increase communication between multiple readers and sites. In so doing, it will not only help streamline the evaluation of new ulcerative colitis treatments that rely heavily on the image interpretation process, but also provide the foundation for the identification of additional components present in other gastrointestinal disease indications in the future. Project Narrative The proposed research will contribute critical new insights on the reliability, sensitivity, and practicality of machine learning to support gastrointestinal disease detection and evaluation in a clinical trials setting. In pathology, where manual interpretation of images using a microscope has remained relatively unchanged for decades, machine learning provides particular potential to improve the speed and accuracy of diagnoses by reducing the subjectivity that is often inherent in the process.",Advancing Ulcerative Colitis Monitoring with Deep Learning Models,10081185,R43EB030441,"['Address', 'Algorithms', 'Appearance', 'Architecture', 'Catalogs', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communication', 'Computer software', 'Country', 'Coupled', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Eligibility Determination', 'Endoscopy', 'Endpoint Determination', 'Ensure', 'Evaluation', 'Foundations', 'Future', 'Gastrointestinal Diseases', 'Histologic', 'Histology', 'Histopathology', 'Hospitals', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Knowledge', 'Label', 'Learning Skill', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Metadata', 'Methods', 'Microscope', 'Modeling', 'Monitor', 'Output', 'Pathologist', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Predictive Value', 'Process', 'Publications', 'Readability', 'Reader', 'Reporting', 'Research', 'Role', 'Series', 'Services', 'Severity of illness', 'Site', 'Software Design', 'Speed', 'Stains', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Triage', 'Ulcerative Colitis', 'Validation', 'base', 'deep learning', 'deep learning algorithm', 'diagnostic accuracy', 'digital imaging', 'gastrointestinal', 'imaging biomarker', 'imaging detection', 'improved', 'indexing', 'insight', 'instrument', 'learning network', 'prototype', 'software development', 'tool', 'treatment response']",NIBIB,"AZAVEA, INC",R43,2020,150000,0.060930827264691664
"Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data Age-related macular degeneration (AMD) is a leading cause of irreversible blindness worldwide. Successful genome-wide association studies (GWAS) of AMD have identified many disease-susceptibility genes. Through great efforts from international GWAS consortium and large-scale collaborative projects, massive datasets including high-quality GWAS data and well-characterized clinical phenotypes are now available in public repositories such as dbGaP and UK Biobank. Clinically, color fundus images have been extensively used by ophthalmologists to diagnose AMD and its severity level. The combination of wealthy GWAS data and fundus image data provides an unprecedented opportunity for researchers to test new hypotheses that are beyond the objectives of original projects. Among them, predictive models for AMD development and its progression based on both GWAS and fundus image data have not been explored. Most existing prediction models only focus on classic statistical approaches, often regression models with a limited number of predictors (e.g., SNPs). Moreover, most predictions only give static risks rather than dynamic risk trajectories over time, of which the latter is more informative for a progressive disease like AMD. Recent advances of machine learning techniques, particularly deep learning, have been proven to significantly improve prediction accuracy by incorporating multiple layers of hidden non-linear effects when large-scale training datasets with well-defined phenotypes are available. Despite its success in many areas, deep learning has not been fully explored in AMD and other eye diseases. Motivated by multiple large-scale studies of AMD development or progression, where GWAS and/or longitudinal fundus image data have been collected, we propose novel deep learning methods for predicting AMD status and its progression, and to identify subgroups with significant different risk profiles. Specially, in Aim 1, we will construct a novel local convolutional neural network to predict disease occurrence (AMD or not) and severity (e.g., mild AMD, intermediate AMD, late AMD) based on (1a): a large cohort of 35,000+ individuals with GWAS data and (1b): a smaller cohort of 4,000+ individuals with both GWAS and fundus image data. In Aim 2, we will develop a novel deep neural network survival model for predicting individual disease progression trajectory (e.g., time to late-AMD). In both aims, we will use the local linear approximation technique to identify important predictors that contribute to individual risk profile prediction and to identify subgroups with different risk profiles. In Aim 3, we will validate and calibrate our methods using independent cohorts and implement proposed methods into user-friendly software and easy-to-access web interface. With the very recent FDA approval for Beovu, a novel injection treatment for wet AMD (one type of late AMD) by inhibiting VEGF and thus suppressing the growth of abnormal blood vessels, it makes our study more significant, as it will provide most cutting-edge and comprehensive prediction models for AMD which have great potential to facilitate early diagnosis and tailored treatment and clinical management of the disease. PROJECT NARRATIVE The objective of this proposal is to develop new analytic methods and software tools to facilitate novel prediction of AMD development and its progression. The successful completion of the project will generate the first comprehensive set of deep-learning-based prediction models and web-based interfaces, which jointly analyzes large-scale GWAS and fundus image data and has the great potential to enhance the early diagnosis and current clinical management of AMD. The analytic approach can be applied to other eye diseases where large-scale genetics and/or image data are collected.",Deep-learning-based prediction of AMD and its progression with GWAS and fundus image data,10056062,R21EY030488,"['Achievement', 'Age related macular degeneration', 'Applications Grants', 'Area', 'Biological', 'Blindness', 'Blood Vessels', 'Categories', 'Characteristics', 'Clinical', 'Clinical Management', 'Cohort Studies', 'Collection', 'Color', 'Communities', 'Computer software', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Management', 'Disease Progression', 'Disease susceptibility', 'Early Diagnosis', 'Elderly', 'Exposure to', 'Eye diseases', 'Genes', 'Genetic', 'Genotype', 'Growth', 'Image', 'Individual', 'Injections', 'International', 'Knowledge', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'National Eye Institute', 'Network-based', 'Online Systems', 'Ophthalmologist', 'Phenotype', 'Positioning Attribute', 'Progressive Disease', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Severities', 'Software Tools', 'Statistical Methods', 'Subgroup', 'Susceptibility Gene', 'Techniques', 'Testing', 'Time', 'Training', 'Universities', 'Vascular Endothelial Growth Factors', 'Work', 'analytical method', 'base', 'biobank', 'clinical phenotype', 'cohort', 'computerized tools', 'convolutional neural network', 'data warehouse', 'database of Genotypes and Phenotypes', 'deep learning', 'deep neural network', 'fundus imaging', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'graphical user interface', 'improved', 'individualized medicine', 'innovation', 'interest', 'learning strategy', 'neural network', 'novel', 'personalized predictions', 'personalized risk prediction', 'predictive modeling', 'public repository', 'secondary analysis', 'success', 'synergism', 'user friendly software', 'user-friendly', 'web based interface', 'web interface']",NEI,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R21,2020,188198,0.06162427888037788
"Discovery and Validation of AMD Biomarkers for Progression Using Deep Learning Project Abstract Age-related macular degeneration (AMD) is the leading cause of blindness among elderly individuals. Currently there are no proven effective therapies for treatment of advanced non-neovascular AMD, termed geographic atrophy (GA). Earlier intervention may be preferable, but this would require identification of those individuals with the highest risk for progression to atrophy. Over the last two decades, various studies including ours have identified several optical coherence tomography (OCT)-based factors that appear to associate with a higher risk for AMD progression. The central hypothesis of this proposal is that a deep learning - artificial intelligence (AI) construct can objectively and automatically learn and quantify the most important risk factors, yielding a better prediction of AMD progression risk than current subjectively specified features. In this proposal, we will first develop an AI- based system to automatically identify the “subjectively-specified” high risk factors based on individual spectral domain (SD) OCT 2D scans, and to automatically segment GA (the end-stage outcome variable of AMD) in OCT 2D en face maps. Subsequently, as a proof-of-concept study of our hypothesis, we will apply an AI-based “reverse learning” approach to objectively learn and identify AMD high risk factors in longitudinal OCT data. To achieve these objectives, we will pursue the following specific aims: Aim 1: Develop and validate an AI approach to classify individual OCT 2D scans as containing or not containing the pre-specified risk factor(s). In our previous work, we manually identified the presence or absence of the pre-specific high-risk factors and assigned to a risk score based on the entire OCT volume. Such approach was time consuming and not precise. In this proposal, an AI algorithm will be applied to detect the high risk factors from individual OCT scans. Hence, the precision of the scoring system can be greatly enhanced with high computational complexity. Aim 2: Develop and validate an AI approach to segment GA lesions from 2D OCT en face maps. For the OCT volumes having atrophy, we will perform the GA segmentation from the choroidal hypertransmission-resulted en face map using the multi-scale CNNs. Aim 3: Develop and validate an AI “reverse learning” approach to objectively identify the high risk factors using longitudinal OCT data. The “reverse learning” will be based on the multiple CNNs, followed by de- convolutional networks to identify the high risk factors objectively. Our previous scoring system will possibly be refined and optimized by the potential inclusion (or substitution) of novel risk factors derived from our objective AI approaches. The work in this proposal will be performed retrospectively in SD-OCT images from the image data pool that the multi-PI Sadda has aggregated over years as the director of the Doheny image reading center. Project Narrative Age-related macular degeneration (AMD) is the leading cause of blindness among elderly individuals and it may be preferable to intervene at an earlier stage in the disease process. We propose to use artificial intelligence techniques to automatically and objectively identify and quantify end-stage atrophy as well to identify the features on spectral domain optical coherence tomography (SD-OCT), which are associated with a higher risk for progression to late atrophic AMD. This research should have implications for clinical practice in the staging and monitoring of AMD patients, as well as facilitating new therapeutic trials for AMD.",Discovery and Validation of AMD Biomarkers for Progression Using Deep Learning,9986814,R21EY030619,"['3-Dimensional', 'Age related macular degeneration', 'Architecture', 'Artificial Intelligence', 'Atrophic', 'Back', 'Blindness', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Consensus', 'Consumption', 'Data', 'Data Pooling', 'Data Set', 'Deposition', 'Development', 'Disease', 'Drusen', 'Early Intervention', 'Early intervention trials', 'Elderly', 'Future', 'Image', 'Individual', 'Learning', 'Lesion', 'Machine Learning', 'Manuals', 'Maps', 'Monitor', 'Neurons', 'Nonexudative age-related macular degeneration', 'Optical Coherence Tomography', 'Outcome', 'Outcome Measure', 'Patients', 'Phenotype', 'Process', 'Reading', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Risk Factors', 'Scanning', 'Specific qualifier value', 'Staging', 'Staging System', 'System', 'Techniques', 'Therapeutic Trials', 'Time', 'Validation', 'Visit', 'Work', 'algorithm training', 'base', 'clinical practice', 'convolutional neural network', 'deep learning', 'deep neural network', 'effective therapy', 'follow-up', 'geographic atrophy', 'high risk', 'imaging Segmentation', 'improved', 'intelligent algorithm', 'multidisciplinary', 'novel', 'novel therapeutics', 'primary outcome', 'prognostic', 'progression marker', 'research study']",NEI,DOHENY EYE INSTITUTE,R21,2020,196250,0.04525534004754922
"Discovery and Validation of AMD Biomarkers for Progression Using Deep Learning Project Abstract Age-related macular degeneration (AMD) is the leading cause of blindness among elderly individuals. Currently there are no proven effective therapies for treatment of advanced non-neovascular AMD, termed geographic atrophy (GA). Earlier intervention may be preferable, but this would require identification of those individuals with the highest risk for progression to atrophy. Over the last two decades, various studies including ours have identified several optical coherence tomography (OCT)-based factors that appear to associate with a higher risk for AMD progression. The central hypothesis of this proposal is that a deep learning - artificial intelligence (AI) construct can objectively and automatically learn and quantify the most important risk factors, yielding a better prediction of AMD progression risk than current subjectively specified features. In this proposal, we will first develop an AI- based system to automatically identify the “subjectively-specified” high risk factors based on individual spectral domain (SD) OCT 2D scans, and to automatically segment GA (the end-stage outcome variable of AMD) in OCT 2D en face maps. Subsequently, as a proof-of-concept study of our hypothesis, we will apply an AI-based “reverse learning” approach to objectively learn and identify AMD high risk factors in longitudinal OCT data. To achieve these objectives, we will pursue the following specific aims: Aim 1: Develop and validate an AI approach to classify individual OCT 2D scans as containing or not containing the pre-specified risk factor(s). In our previous work, we manually identified the presence or absence of the pre-specific high-risk factors and assigned to a risk score based on the entire OCT volume. Such approach was time consuming and not precise. In this proposal, an AI algorithm will be applied to detect the high risk factors from individual OCT scans. Hence, the precision of the scoring system can be greatly enhanced with high computational complexity. Aim 2: Develop and validate an AI approach to segment GA lesions from 2D OCT en face maps. For the OCT volumes having atrophy, we will perform the GA segmentation from the choroidal hypertransmission-resulted en face map using the multi-scale CNNs. Aim 3: Develop and validate an AI “reverse learning” approach to objectively identify the high risk factors using longitudinal OCT data. The “reverse learning” will be based on the multiple CNNs, followed by de- convolutional networks to identify the high risk factors objectively. Our previous scoring system will possibly be refined and optimized by the potential inclusion (or substitution) of novel risk factors derived from our objective AI approaches. The work in this proposal will be performed retrospectively in SD-OCT images from the image data pool that the multi-PI Sadda has aggregated over years as the director of the Doheny image reading center. Project Narrative Age-related macular degeneration (AMD) is the leading cause of blindness among elderly individuals and it may be preferable to intervene at an earlier stage in the disease process. We propose to use artificial intelligence techniques to automatically and objectively identify and quantify end-stage atrophy as well to identify the features on spectral domain optical coherence tomography (SD-OCT), which are associated with a higher risk for progression to late atrophic AMD. This research should have implications for clinical practice in the staging and monitoring of AMD patients, as well as facilitating new therapeutic trials for AMD.",Discovery and Validation of AMD Biomarkers for Progression Using Deep Learning,9807978,R21EY030619,"['3-Dimensional', 'Age related macular degeneration', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Atrophic', 'Back', 'Biological Markers', 'Blindness', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Consensus', 'Consumption', 'Data', 'Data Set', 'Deposition', 'Development', 'Disease', 'Drusen', 'Early Intervention', 'Early intervention trials', 'Elderly', 'Future', 'Image', 'Individual', 'Learning', 'Lesion', 'Machine Learning', 'Manuals', 'Maps', 'Meta-Analysis', 'Monitor', 'Neurons', 'Nonexudative age-related macular degeneration', 'Optical Coherence Tomography', 'Outcome', 'Outcome Measure', 'Patients', 'Phenotype', 'Process', 'Reading', 'Research', 'Research Personnel', 'Residual state', 'Risk', 'Risk Factors', 'Scanning', 'Specific qualifier value', 'Staging', 'Staging System', 'System', 'Techniques', 'Therapeutic Trials', 'Time', 'Training', 'Validation', 'Visit', 'Work', 'base', 'clinical practice', 'deep learning', 'deep neural network', 'effective therapy', 'follow-up', 'geographic atrophy', 'high risk', 'imaging Segmentation', 'improved', 'multidisciplinary', 'novel', 'novel therapeutics', 'primary outcome', 'prognostic', 'research study']",NEI,DOHENY EYE INSTITUTE,R21,2019,235500,0.04525534004754922
"Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology PROJECT SUMMARY/ABSTRACT Candidate: Atalie Carina Thompson, MD, MPH is a current glaucoma fellow and Heed fellow with a long-term career goal of becoming an independent clinician-scientist and leader in the field of glaucoma and public health. She has a long-standing interest in addressing healthcare disparities in medicine, and in improving the diagnosis of glaucoma and other ophthalmic diseases through imaging technology. While obtaining a medical degree at Stanford, she received a fellowship to complete a master’s degree in public health with additional higher-level coursework in biostatistics and epidemiology. Her immediate goal in this proposal is to refine and validate a deep learning (DL) algorithm capable of quantifying neuroretinal damage on optic disc photographs and then to apply it in a pilot teleophthalmology program. With a K23 Mentored Patient-Oriented Research Career Development Award, she will acquire additional didactic training and mentored research experience in glaucoma imaging, machine learning, biostatistics, clinical research, and the responsible conduct of research. Environment: The mentorship and expertise of the advisory committee, the extensive resources at the Duke Eye Center and Departments of Biostatistics and Biomedical Engineering, and the significant institutional commitment will provide her with the support needed to transition successfully into an independent clinician-scientist. Research: This proposal will test the hypothesis that a DL algorithm trained with SDOCT detects glaucoma on optic disc photographs with greater accuracy than human graders. In Specific Aim 1, a DL algorithm that quantifies neuroretinal damage on optic disc photographs will be refined. The main hypothesis is that the quantitative output provided by the DL algorithm will allow accurate discrimination of eyes at different stages of the disease according to standard automated perimetry, and will generate cut-offs suitable for use in a screening setting. In Specific Aim 2, the short-term repeatability and reproducibility of the DL algorithm in optic disc photographs acquired over a time period of several weeks will be determined. The hypothesis is that the test-retest variability of the predictions from the DL algorithm will be similar to the original measurements acquired by SDOCT. In Specific Aim 3, the DL algorithm will be applied to optic disc photographs obtained during a pilot screening teleophthalmology program in primary care clinics and assisted living facilities. The hypothesis is that the DL algorithm will be more accurate than human graders when a full ophthalmic examination is used as the gold standard. This work will constitute the basis of an R01 grant and will advance our understanding of the application of deep learning algorithms in glaucoma and teleophthalmology. PROJECT NARRATIVE Glaucoma is the leading cause of irreversible blindness in the world. However, since the disease can be asymptomatic until later stages, many patients with glaucoma will not know they have glaucoma until they suffer substantial and irreversible visual field loss. This study seeks to refine and validate a deep learning algorithm for early diagnosis of glaucoma on optic disc photographs and subsequently test it in a pilot teleophthalmology program.",Deep learning to quantify glaucomatous damage on fundus photographs for teleophthalmology,9868507,K23EY030897,"['Address', 'Adult', 'Advisory Committees', 'Agreement', 'Algorithms', 'Artificial Intelligence', 'Assisted Living Facilities', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Consumption', 'Data', 'Dependence', 'Detection', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Diagnostic', 'Discrimination', 'Disease', 'Early Diagnosis', 'Effectiveness', 'Environment', 'Epidemiology', 'Evaluation', 'Eye', 'Eye diseases', 'Fellowship', 'Frequencies', 'Fundus', 'Fundus photography', 'Glaucoma', 'Goals', 'Gold', 'Grant', 'Human', 'Image', 'Imaging technology', 'Improve Access', 'Individual', 'Label', 'Machine Learning', 'Manuals', 'Masks', 'Master&apos', 's Degree', 'Measurement', 'Medical', 'Medicine', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Nature', 'Optic Disk', 'Optical Coherence Tomography', 'Output', 'Patients', 'Perimetry', 'Primary Health Care', 'Public Health', 'Reference Standards', 'Reproducibility', 'Research', 'Research Priority', 'Research Proposals', 'Resources', 'Scientist', 'Screening procedure', 'Sensitivity and Specificity', 'Severity of illness', 'Specialist', 'Suspect Glaucomas', 'Technology', 'Testing', 'Thick', 'Time', 'Training', 'Validation', 'Visual Fields', 'Visual impairment', 'Width', 'Work', 'algorithm training', 'career', 'carina', 'cohort', 'cost', 'cost effective', 'deep learning', 'deep learning algorithm', 'deep neural network', 'demographics', 'experience', 'eye center', 'health care disparity', 'high risk', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'learning network', 'neural network', 'novel', 'novel diagnostics', 'population based', 'programs', 'prospective', 'public health intervention', 'responsible research conduct', 'retinal nerve fiber layer', 'screening', 'tool']",NEI,DUKE UNIVERSITY,K23,2020,195131,0.05545966521038501
"Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes Project Summary Glaucoma is a leading cause of vision morbidity and blindness worldwide. Early disease detection and sensitive monitoring of progression are crucial to allow timely treatment for preservation of vision. The introduction of ocular imaging technologies significantly improves these capabilities, but in clinical practice there are still substantial challenges at managing the optimal care for individual cases due to difficulties of accurately assessing the potential progression and its speed and magnitude. These difficulties are due to a variety of causes that change over the course of the disease, including large inter-subject variability, inherent measurement variability, image quality, varying dynamic ranges of measurements, minimal measurable level of tissues, etc. In this proposal, we propose novel agnostic data-driven deep learning approaches to detect glaucoma and accurately forecast its progression that are optimized to each individual case. We will use state- of-the-art automated computerized machine learning methods, namely the deep learning approach, to identify structural features embedded within OCT images that are associated with glaucoma and its progression without any a priori assumptions. This will provide novel insight into structural information, and has shown very encouraging preliminary results. Instead of relying on the conventional knowledge-based approaches (e.g. quantifying tissues known to be significantly associated with glaucoma such as retinal nerve fiber layer), the proposed cutting-edge agnostic deep learning approaches determine the features responsible for future structural and functional changes out of thousands of features autonomously by learning from the provided large longitudinal dataset. This program will advance the use of structural and functional information obtained in the clinics with a substantial impact on the clinical management of subjects with glaucoma. Furthermore, the developed methods have potentials to be applied to various clinical applications beyond glaucoma and ophthalmology. Project Narrative This research proposal is focusing on the development and refinement of innovative analytical methods and cutting-edge technologies using agnostic deep learning approaches that will substantially improve detection of glaucoma and its progression forecasting and monitoring in order to prevent blindness.",Deep Learning Approaches for Personalized Modeling and Forecasting of Glaucomatous Changes,9864905,R01EY030929,"['3-Dimensional', 'Area', 'Atlases', 'Blindness', 'Brain', 'Caring', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Management', 'Collaborations', 'Color', 'Complex', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Disease model', 'Early Diagnosis', 'Eye', 'Future', 'Glaucoma', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measurable', 'Measurement', 'Medical Imaging', 'Methods', 'Modeling', 'Monitor', 'Morbidity - disease rate', 'Ophthalmology', 'Optical Coherence Tomography', 'Outcome', 'Patients', 'Performance', 'Research', 'Research Proposals', 'Retina', 'Sampling', 'Series', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thinness', 'Time', 'Tissues', 'Training', 'Vision', 'Visit', 'Visual Fields', 'analytical method', 'base', 'case-by-case basis', 'clinical application', 'clinical practice', 'cohort', 'computerized', 'cost', 'deep learning', 'falls', 'feature selection', 'follow-up', 'image processing', 'imaging modality', 'improved', 'in vivo', 'individual patient', 'innovation', 'insight', 'knowledge base', 'longitudinal analysis', 'longitudinal dataset', 'machine learning method', 'novel', 'ocular imaging', 'personalized approach', 'personalized medicine', 'personalized predictions', 'predictive modeling', 'preservation', 'prevent', 'programs', 'retinal nerve fiber layer', 'theories', 'tool', 'treatment planning', 'trend']",NEI,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,400056,0.07440929023821899
"Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography Project Abstract / Summary Primary open angle glaucoma (POAG) is a leading cause of blindness in the United States and worldwide. It is estimated that over 2.2 million Americans suffer from POAG and that over 130,000 are legally blind from the disease. As the population ages, the number of people with POAG in the United States will increase to over 3.3 million in 2020 and worldwide to an estimated 111.8 million by 2040. POAG is a progressive disease associated with characteristic functional and structural changes that clinicians use to diagnose and monitor the disease. Over the past several years, spectral domain optical coherent tomography (SDOCT) has become the standard tool for measuring structure in POAG. This 3D imaging modality provides a wealth of information about retinal structure and POAG-related retinal layers. This large amount of data is hard for clinicians to interpret and use effectively to help guide treatment decisions. Instead, summary metrics such as average layer thicknesses are used to reduce SDOCT images to a handful of values. While these metrics are useful, they can be difficult to interpret and they throwaway important information regarding voxel intensity and texture, relationships across retinal layers, and the overall 3D structure of the retina. Relying too heavily on these metrics limits our ability to gain a deeper understanding structural contributions to POAG, the relationship between structure and visual function, and how structural (and functional) changes progress in POAG. Recent advances in artificial intelligence and deep learning, however, offer new data-driven tools and techniques to interpret 3D SDOCT images and learn from the large SDOCT datasets being collected in clinics around the world. This proposal will apply state-of-the-art deep learning techniques to 3D SDOCT data in order to (1) develop more accurate POAG detection tools, (2) reveal structure-function relationships, and (3) predict structural and functional progression in POAG. This proposal also details a training plan to help the PI transition from a postdoctoral scholar to an independent researcher. The mentored phase of this award will be supervised by the primary mentor, Dr. Linda Zangwill, and a multidisciplinary mentoring team including Dr. Robert Weinreb (Ophthalmology), Dr. David Kriegman (Computer Science and Engineering), and Dr. Armin Schwartzman (Biostatistics). Performing the proposed research, formal coursework, and mentored career development will the provide the PI with highly sought- after skills and experience to help ensure a successful transition into independence. Project Narrative Three-dimensional imaging techniques such as optical coherence tomography have become an essential tool in the clinical care of glaucoma and other eye diseases. These imaging techniques provide clinicians with huge amounts of structural information, but interpreting the data and using it effectively to improve outcomes remains challenging in clinical glaucoma management. This project will improve patient care by applying powerful deep learning techniques to provide clinicians with critical decision support information to more accurately detect glaucoma, reveal associations between structure and visual function, and predict glaucoma progression.",Deep Learning Approaches to Detect Glaucoma and Predict Progression from Spectral Domain Optical Coherence Tomography,10055661,K99EY030942,"['3-Dimensional', 'Affect', 'Age', 'American', 'Artificial Intelligence', 'Award', 'Biometry', 'Blindness', 'Caring', 'Characteristics', 'Clinic', 'Clinical', 'Computational Technique', 'Cornea', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Engineering', 'Ensure', 'Evaluation', 'Eye', 'Eye diseases', 'Frequencies', 'Glaucoma', 'Image', 'Imaging Techniques', 'Individual', 'Learning', 'Length', 'Measurement', 'Measures', 'Medicine', 'Mentors', 'Modeling', 'Monitor', 'Ophthalmology', 'Optic Disk', 'Optical Coherence Tomography', 'Optics', 'Participant', 'Patient Care', 'Patients', 'Performance', 'Phase', 'Population', 'Primary Open Angle Glaucoma', 'Probability', 'Progressive Disease', 'Race', 'Research', 'Research Personnel', 'Retina', 'Scanning', 'Severities', 'Severity of illness', 'South Korea', 'Standardization', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'Techniques', 'Texture', 'Thick', 'Thinness', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Training', 'Translating', 'United States', 'Universities', 'Vision', 'Visual Fields', 'Visualization', 'Width', 'Work', 'base', 'career development', 'clinical care', 'college', 'computer science', 'deep learning', 'experience', 'field study', 'imaging modality', 'improved', 'improved outcome', 'individual patient', 'large datasets', 'legally blind', 'macula', 'multidisciplinary', 'predictive modeling', 'preservation', 'research clinical testing', 'retinal nerve fiber layer', 'sex', 'skills', 'standard measure', 'three dimensional structure', 'tomography', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2020,117347,0.057425951576038185
"EVALUATION OF CORONARY DISEASE BY DIGITAL ANGIOGRAPHY The aim of this porposal is to assess the feasibility of using digital angiography to evaluate the severity of coronary artery disease. Quantitative methods to be studied will include those designed to measure anatomic coronary artery narrowing, myocardial perfusion abnormalities and segmental myocardial wall dysfunction induced by myocardial ischemia. Results will be compared to the computer-assisted method of measuring lesion dimensions from standard contrast angiograms previously developed by Brown, et al.  One quantitative method to be evaluated will involve the use of videodensitometric as well as image border methods for measuring anatomic coronary artery narrowing from digital subtraction angiograms obtained following intracoronary injection of contrast material.  Both methods will be used to measure the minimum lumen diameter (and area) of coronary artery lesions.  We also will attempt to develop less invasive methods for obtaining coronary angiograms and quantitating the severity of coronary stenosis following injection of contrast material into the aortic root.  Image processing algorithms to be evaluated in these low contrast images will include band pass filtering of electrocardiogram-gated images and a two-dimensional background interpolation method.  The accuracy of these methods will be tested in phantom, dog and clinical models.  A second general quantitative method for assessing the severity of coronary artery disease will entail evaluating myocardial perfusion using videodensitometry to generate contrast density versus time curves in myocardial regions supplied by individual coronary arteries.  Data obtained from segments of myocardium supplied by stenotic coronary arteries will be compared to data from segments supplied by non-stenotic arteries.  Studies will be performed in dogs and humans.  The third general method for evaluating coronary artery disease involves the use of digital subtraction angiography to obtain left ventricular angiograms as a means of assessing global and segmental systolic and diastolic ventricular function at rest and immediately following atrial pacing in humans.  The myocardial perfusion and segmental wall motion methods both will be related to the minimum lumen diameter of lesions in coronary arteries supplying each myocardial segment.  If successful, these studies will provide improved methods for assessing the presence and severity of coronary lesions during routine clinical evaluation of patients with suspected coronary artery disease.  n/a",EVALUATION OF CORONARY DISEASE BY DIGITAL ANGIOGRAPHY,3342560,R01HL031440,"['angiocardiography', ' artificial intelligence', ' computer assisted diagnosis', ' contrast media', ' coronary disorder', ' coronary occlusion /thrombosis', ' diagnosis quality /standard', ' disease /disorder model', ' electrocardiography', ' heart circulation', ' heart disorder diagnosis', ' heart function', ' histopathology', ' human subject', ' image processing', ' mathematical model', ' myocardial ischemia /hypoxia', ' myocardium disorder', ' phantom model']",NHLBI,UNIVERSITY OF CALIFORNIA IRVINE,R01,1986,142939,0.07156407533018712
"EVALUATION OF CORONARY DISEASE BY DIGITAL ANGIOGRAPHY The aim of this porposal is to assess the feasibility of using digital angiography to evaluate the severity of coronary artery disease. Quantitative methods to be studied will include those designed to measure anatomic coronary artery narrowing, myocardial perfusion abnormalities and segmental myocardial wall dysfunction induced by myocardial ischemia. Results will be compared to the computer-assisted method of measuring lesion dimensions from standard contrast angiograms previously developed by Brown, et al.  One quantitative method to be evaluated will involve the use of videodensitometric as well as image border methods for measuring anatomic coronary artery narrowing from digital subtraction angiograms obtained following intracoronary injection of contrast material.  Both methods will be used to measure the minimum lumen diameter (and area) of coronary artery lesions.  We also will attempt to develop less invasive methods for obtaining coronary angiograms and quantitating the severity of coronary stenosis following injection of contrast material into the aortic root.  Image processing algorithms to be evaluated in these low contrast images will include band pass filtering of electrocardiogram-gated images and a two-dimensional background interpolation method.  The accuracy of these methods will be tested in phantom, dog and clinical models.  A second general quantitative method for assessing the severity of coronary artery disease will entail evaluating myocardial perfusion using videodensitometry to generate contrast density versus time curves in myocardial regions supplied by individual coronary arteries.  Data obtained from segments of myocardium supplied by stenotic coronary arteries will be compared to data from segments supplied by non-stenotic arteries.  Studies will be performed in dogs and humans.  The third general method for evaluating coronary artery disease involves the use of digital subtraction angiography to obtain left ventricular angiograms as a means of assessing global and segmental systolic and diastolic ventricular function at rest and immediately following atrial pacing in humans.  The myocardial perfusion and segmental wall motion methods both will be related to the minimum lumen diameter of lesions in coronary arteries supplying each myocardial segment.  If successful, these studies will provide improved methods for assessing the presence and severity of coronary lesions during routine clinical evaluation of patients with suspected coronary artery disease.  n/a",EVALUATION OF CORONARY DISEASE BY DIGITAL ANGIOGRAPHY,3342559,R01HL031440,"['angiocardiography', ' artificial intelligence', ' computer assisted diagnosis', ' contrast media', ' coronary disorder', ' coronary occlusion /thrombosis', ' diagnosis quality /standard', ' disease /disorder model', ' electrocardiography', ' heart circulation', ' heart disorder diagnosis', ' heart function', ' histopathology', ' human subject', ' image processing', ' mathematical model', ' myocardial ischemia /hypoxia', ' myocardium disorder', ' phantom model']",NHLBI,UNIVERSITY OF CALIFORNIA IRVINE,R01,1985,193516,0.07156407533018712
"Robust AI to develop risk models in retinopathy of prematurity using deep learning ROP is a retinal neovascular disease affecting preterm infants, and is a leading cause of childhood blindness worldwide. Known clinical risk factors include preterm birth, low birthweight and use of supplemental oxygen but improved risk models are needed to identify infants that progress to treatment requiring disease and blindness. Deep learning techniques have been used to successfully identify “plus” disease in multi- institutional cohorts and to provide a continuous measure of disease severity. A major limitation of deep learning, however, is the need for large amounts of well curated datasets. Other limitations include overfitting and “brittleness” that can cause model performance to drop on external data. There are, however, numerous barriers to building and hosting these large central repositories with multi-institutional data required for robust deep learning including concerns about data sharing, regulations costs, patient privacy and intellectual property. In this project, we aim to demonstrate the utility of distributed/federated deep learning approaches where the data are located within institutions, but model parameters are shared with a central server. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Specifically, we seek to build robust risk models for predicting treatment requiring disease. Two large cohorts will be used to validate the hypothesis that the performance of the risk models using distributed learning approaches that of centrally hosted and is more robust than models built on single institutional datasets.  Grants Admin Updated 04.01.2019 JBou Retinopathy of prematurity is a retinal neovascular disease affecting preterm infants and a leading cause of preventable blindness worldwide. We are developing machine-learning based techniques to collaboratively build risk models for treatment requiring disease using multi-institutional data repositories. Distributed deep learning will be used to build robust models to improve clinical decision making in ROP.",Robust AI to develop risk models in retinopathy of prematurity using deep learning,10048436,R21EY031883,"['Affect', 'Architecture', 'Blindness', 'Blood Vessels', 'Childhood', 'Clinical', 'Collection', 'Communities', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Disease', 'Drops', 'Ecosystem', 'Eye diseases', 'Future', 'Gestational Age', 'Grant', 'Heterogeneity', 'Image', 'Infant', 'Institution', 'Intellectual Property', 'Label', 'Lead', 'Learning', 'Left', 'Logistic Regressions', 'Low Birth Weight Infant', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Oxygen', 'Patient imaging', 'Patients', 'Performance', 'Premature Birth', 'Premature Infant', 'Protocols documentation', 'Publishing', 'Rare Diseases', 'Regulation', 'Research', 'Research Personnel', 'Retina', 'Retinal Detachment', 'Retinopathy of Prematurity', 'Risk', 'Risk Factors', 'Sensitivity and Specificity', 'Severities', 'Severity of illness', 'Site', 'Techniques', 'Testing', 'Time', 'Training', 'Update', 'Vascular Diseases', 'Vascular Proliferation', 'Weight', 'Work', 'base', 'clinical decision-making', 'clinical risk', 'cohort', 'convolutional neural network', 'cost', 'data de-identification', 'data sharing', 'data warehouse', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'individual patient', 'large datasets', 'learning strategy', 'multiple data sources', 'neovascular', 'open source', 'patient population', 'patient privacy', 'patient subsets', 'predictive modeling', 'repository', 'risk prediction model', 'screening guidelines', 'secondary analysis', 'tool']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2020,274883,0.09034893171677627
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10058463,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data reuse', 'data sharing', 'data visualization', 'data warehouse', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2020,627034,0.0422985056682468
"LEARNING SIMPLE ARITHMETIC PROCEDURE The long term objective of this research is to understand the possible neural mechanisms underlying the learning of simple cognitive procedures such as arithmetic through neural network modeling of the process.  The specific goals are:  (1) To implement and test a neural network model of addition.  (2) To analyze how the network has solved the task and evaluate it with respect to the human data.  (3) To lesion the network and analyze its behavior with reference to human data.  (4) To determine the optimal method of retraining the network after damage.  Neural network of addition have been done before, but only for single digit addition.  The difference here is the attempt to model the sequential process of addition in a parallel network.  The network will be trained in this task via the back propagation algorithm.  We will use recurrent networks that record their processing history in their state so that the network can use this information to keep track of where it is in the procedure.  Once the network has learned the task, standard techniques will be applied to analyze how the network has solved the task. Also at this stage, random lesions may be introduced into the network, which allow comparison of its behavior with that observed in humans.  Finally, the network will then be retrained on the task to determine the optimal method of retraining.  This will have obvious implications for the treatment of brain damaged patients with acalculia. Thus exploring the behavior of networks trained to do these tasks, we hope to learn better ways of training children and retraining lesion patients.  n/a",LEARNING SIMPLE ARITHMETIC PROCEDURE,3429276,R03MH046054,"['artificial intelligence', ' computer simulation', ' disease /disorder model', ' learning', ' nervous system disorder', ' neural information processing', ' training']",NIMH,UNIVERSITY OF CALIFORNIA SAN DIEGO,R03,1990,35470,0.03573971908563576
"ELASTICITY IMAGING FOR EARLY RENAL PATHOLOGY DETECTION Changes in soft tissue elasticity are usually related to pathological            processes.  Because of this, palpation is still widely used for                  diagnosis.  Its efficacy, however, is limited to abnormalities located           relatively close to the skin surface.  The goal of quantitative                  elasticity imaging is to develop surrogate, remote palpation, thus               expanding its range to include deep lying lesions.  The elastic                  properties of any continuous medium such as tissue can be assessed               through precise measurement of mechanical deformations throughout that           medium induced by forces applied at the surface.  Using modern medical           imaging devices to precisely measure internal motion, it should be               possible to estimate and even image elastic properties of internal               organs.  In competition with other imaging modalities, ultrasound has two        major advantages for elasticity imaging; it is inherently real-time and          speckle artifacts limiting the quality of conventional images provide            excellent markers for accurate tracking of tissue motion.  Elasticity can        be imaged, therefore, by measuring motion with an ultrasound speckle             tracking algorithm, followed by reconstruction of the elasticity                 distribution.  Although some other imaging systems, particularly real-           time ultrasound, must be used to monitor tissue motion, elasticity               imaging represents a fundamentally new diagnostic modality.  To                  investigate quantitative elasticity imaging for medical diagnosis, a             research plan addressing the important clinical problem of renal                 inflammation and scarring has been formulated.  Preliminary data support         the hypothesis that kidney elasticity changes with renal damage and              concomitant scarring before renal problems are detectable by traditional         diagnostic techniques such as laboratory measurements of renal function.         Therefore, quantitative elasticity imaging may be valuable in detecting          and quantifying scar for conditions such as kidney transplant rejection          where rejection is difficult to quantify from functional measurements            alone.  Based on the results of these studies, it is the long range goal         of this research program to develop a sensitive diagnostic technique             based on quantitative elasticity imaging permitting surrogate palpation          of deep lying lesions.                                                            n/a",ELASTICITY IMAGING FOR EARLY RENAL PATHOLOGY DETECTION,2016733,R01DK047324,"['animal tissue', ' artificial intelligence', ' computer program /software', ' elasticity', ' glomerular filtration rate', ' guinea pigs', ' histopathology', ' hydroxyproline', ' kidney disorder diagnosis', ' laboratory rabbit', ' mechanical stress', ' nephritis', ' phantom model']",NIDDK,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,1997,209601,-0.04405995865830605
"ELASTICITY IMAGING FOR EARLY RENAL PATHOLOGY DETECTION Changes in soft tissue elasticity are usually related to pathological  processes.  Because of this, palpation is still widely used for  diagnosis.  Its efficacy, however, is limited to abnormalities located  relatively close to the skin surface.  The goal of quantitative  elasticity imaging is to develop surrogate, remote palpation, thus  expanding its range to include deep lying lesions.  The elastic  properties of any continuous medium such as tissue can be assessed  through precise measurement of mechanical deformations throughout that  medium induced by forces applied at the surface.  Using modern medical  imaging devices to precisely measure internal motion, it should be  possible to estimate and even image elastic properties of internal  organs.  In competition with other imaging modalities, ultrasound has two  major advantages for elasticity imaging; it is inherently real-time and  speckle artifacts limiting the quality of conventional images provide  excellent markers for accurate tracking of tissue motion.  Elasticity can  be imaged, therefore, by measuring motion with an ultrasound speckle  tracking algorithm, followed by reconstruction of the elasticity  distribution.  Although some other imaging systems, particularly real-  time ultrasound, must be used to monitor tissue motion, elasticity  imaging represents a fundamentally new diagnostic modality.  To  investigate quantitative elasticity imaging for medical diagnosis, a  research plan addressing the important clinical problem of renal  inflammation and scarring has been formulated.  Preliminary data support  the hypothesis that kidney elasticity changes with renal damage and  concomitant scarring before renal problems are detectable by traditional  diagnostic techniques such as laboratory measurements of renal function.  Therefore, quantitative elasticity imaging may be valuable in detecting  and quantifying scar for conditions such as kidney transplant rejection  where rejection is difficult to quantify from functional measurements  alone.  Based on the results of these studies, it is the long range goal  of this research program to develop a sensitive diagnostic technique  based on quantitative elasticity imaging permitting surrogate palpation  of deep lying lesions.  n/a",ELASTICITY IMAGING FOR EARLY RENAL PATHOLOGY DETECTION,2146817,R01DK047324,"['animal tissue', ' artificial intelligence', ' computer program /software', ' elasticity', ' glomerular filtration rate', ' guinea pigs', ' histopathology', ' hydroxyproline', ' kidney disorder diagnosis', ' laboratory rabbit', ' mechanical stress', ' nephritis', ' phantom model']",NIDDK,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,1995,191426,-0.04405995865830605
"EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA Melanoma is the most lethal skin-cancer.  The occurrence rate of malignant melanoma among the white population is rising faster than almost any other cancer in North America.  Nearly all patients can be saved and cured by early detection and prompt surgical treatment.  The important diagnostic and prognostic variables of melanoma are the vertical thickness, three- dimensional (3D) size and shape, and color of the lesion.  The other characteristic features of early melanoma are irregularities in the boundary of the lesion, and the appearance of non-uniform pigmentation with a variety of color.  The initial changes are subtle and cannot be observed with the naked eye.  A novel optical instrument called the ""Nevoscope"" has been developed to view the multiple images of the lesion in situ from several angles by transilluminating the skin-lesion.  The multiple views have been digitized and 3D images of the lesion have been reconstructed to measure the thickness and 3D size.  The objective of this research is to improve the design and performance of the Nevoscope, to perform analysis on thickness, 3D size, color, and margin, boundary and surface characteristics to detect early malignant lesions.  The approach proposed here is based on the knowledge-based analysis and interpretation of the images of the transilluminated skin-lesion.  The complete system will be tested in a clinical environment.  The analysis and interpretation will be compared with the histology and the diagnosis made by a dermatologist for the lesions whose excisions have been planned.  n/a",EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA,3459480,R29CA049976,"['artificial intelligence', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' early diagnosis', ' fiber optics', ' histology', ' human subject', ' image processing', ' imaging /visualization /scanning', ' medical records', ' melanoma', ' morphology', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' pigmentation', ' pigmented nevus', ' prognosis', ' visible light']",NCI,UNIVERSITY OF CINCINNATI,R29,1992,93798,0.10285711554399683
"EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA Melanoma is the most lethal skin-cancer.  The occurrence rate of malignant melanoma among the white population is rising faster than almost any other cancer in North America.  Nearly all patients can be saved and cured by early detection and prompt surgical treatment.  The important diagnostic and prognostic variables of melanoma are the vertical thickness, three- dimensional (3D) size and shape, and color of the lesion.  The other characteristic features of early melanoma are irregularities in the boundary of the lesion, and the appearance of non-uniform pigmentation with a variety of color.  The initial changes are subtle and cannot be observed with the naked eye.  A novel optical instrument called the ""Nevoscope"" has been developed to view the multiple images of the lesion in situ from several angles by transilluminating the skin-lesion.  The multiple views have been digitized and 3D images of the lesion have been reconstructed to measure the thickness and 3D size.  The objective of this research is to improve the design and performance of the Nevoscope, to perform analysis on thickness, 3D size, color, and margin, boundary and surface characteristics to detect early malignant lesions.  The approach proposed here is based on the knowledge-based analysis and interpretation of the images of the transilluminated skin-lesion.  The complete system will be tested in a clinical environment.  The analysis and interpretation will be compared with the histology and the diagnosis made by a dermatologist for the lesions whose excisions have been planned.  n/a",EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA,3459479,R29CA049976,"['artificial intelligence', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' early diagnosis', ' fiber optics', ' histology', ' human subject', ' image processing', ' imaging /visualization /scanning', ' medical records', ' melanoma', ' morphology', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' pigmentation', ' pigmented nevus', ' prognosis', ' visible light']",NCI,UNIVERSITY OF CINCINNATI,R29,1991,88008,0.10285711554399683
"EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA Melanoma is the most lethal skin-cancer.  The occurrence rate of malignant melanoma among the white population is rising faster than almost any other cancer in North America.  Nearly all patients can be saved and cured by early detection and prompt surgical treatment.  The important diagnostic and prognostic variables of melanoma are the vertical thickness, three- dimensional (3D) size and shape, and color of the lesion.  The other characteristic features of early melanoma are irregularities in the boundary of the lesion, and the appearance of non-uniform pigmentation with a variety of color.  The initial changes are subtle and cannot be observed with the naked eye.  A novel optical instrument called the ""Nevoscope"" has been developed to view the multiple images of the lesion in situ from several angles by transilluminating the skin-lesion.  The multiple views have been digitized and 3D images of the lesion have been reconstructed to measure the thickness and 3D size.  The objective of this research is to improve the design and performance of the Nevoscope, to perform analysis on thickness, 3D size, color, and margin, boundary and surface characteristics to detect early malignant lesions.  The approach proposed here is based on the knowledge-based analysis and interpretation of the images of the transilluminated skin-lesion.  The complete system will be tested in a clinical environment.  The analysis and interpretation will be compared with the histology and the diagnosis made by a dermatologist for the lesions whose excisions have been planned.  n/a",EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA,3459478,R29CA049976,"['artificial intelligence', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' early diagnosis', ' fiber optics', ' histology', ' human subject', ' image processing', ' imaging /visualization /scanning', ' medical records', ' melanoma', ' morphology', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' pigmentation', ' pigmented nevus', ' prognosis', ' visible light']",NCI,UNIVERSITY OF CINCINNATI,R29,1990,82308,0.10285711554399683
"EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA Melanoma is the most lethal skin-cancer.  The occurrence rate of malignant melanoma among the white population is rising faster than almost any other cancer in North America.  Nearly all patients can be saved and cured by early detection and prompt surgical treatment.  The important diagnostic and prognostic variables of melanoma are the vertical thickness, three- dimensional (3D) size and shape, and color of the lesion.  The other characteristic features of early melanoma are irregularities in the boundary of the lesion, and the appearance of non-uniform pigmentation with a variety of color.  The initial changes are subtle and cannot be observed with the naked eye.  A novel optical instrument called the ""Nevoscope"" has been developed to view the multiple images of the lesion in situ from several angles by transilluminating the skin-lesion.  The multiple views have been digitized and 3D images of the lesion have been reconstructed to measure the thickness and 3D size.  The objective of this research is to improve the design and performance of the Nevoscope, to perform analysis on thickness, 3D size, color, and margin, boundary and surface characteristics to detect early malignant lesions.  The approach proposed here is based on the knowledge-based analysis and interpretation of the images of the transilluminated skin-lesion.  The complete system will be tested in a clinical environment.  The analysis and interpretation will be compared with the histology and the diagnosis made by a dermatologist for the lesions whose excisions have been planned.  n/a",EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA,3459477,R29CA049976,"['artificial intelligence', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' early diagnosis', ' fiber optics', ' histology', ' human subject', ' image processing', ' imaging /visualization /scanning', ' medical records', ' melanoma', ' morphology', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' pigmentation', ' pigmented nevus', ' prognosis', ' visible light']",NCI,UNIVERSITY OF CINCINNATI,R29,1989,79256,0.10285711554399683
"EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA Melanoma is the most lethal skin-cancer.  The occurrence rate of malignant melanoma among the white population is rising faster than almost any other cancer in North America.  Nearly all patients can be saved and cured by early detection and prompt surgical treatment.  The important diagnostic and prognostic variables of melanoma are the vertical thickness, three- dimensional (3D) size and shape, and color of the lesion.  The other characteristic features of early melanoma are irregularities in the boundary of the lesion, and the appearance of non-uniform pigmentation with a variety of color.  The initial changes are subtle and cannot be observed with the naked eye.  A novel optical instrument called the ""Nevoscope"" has been developed to view the multiple images of the lesion in situ from several angles by transilluminating the skin-lesion.  The multiple views have been digitized and 3D images of the lesion have been reconstructed to measure the thickness and 3D size.  The objective of this research is to improve the design and performance of the Nevoscope, to perform analysis on thickness, 3D size, color, and margin, boundary and surface characteristics to detect early malignant lesions.  The approach proposed here is based on the knowledge-based analysis and interpretation of the images of the transilluminated skin-lesion.  The complete system will be tested in a clinical environment.  The analysis and interpretation will be compared with the histology and the diagnosis made by a dermatologist for the lesions whose excisions have been planned.  n/a",EARLY DETECTION OF CUTANEOUS MALIGNANT MELANOMA,3459476,R29CA049976,"['artificial intelligence', ' clinical biomedical equipment', ' computer assisted diagnosis', ' computer assisted medical decision making', ' computer system design /evaluation', ' early diagnosis', ' fiber optics', ' histology', ' human subject', ' image processing', ' imaging /visualization /scanning', ' medical records', ' melanoma', ' morphology', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' pigmentation', ' pigmented nevus', ' prognosis', ' visible light']",NCI,UNIVERSITY OF CINCINNATI,R29,1988,105769,0.10285711554399683
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,10136941,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'learning classifier', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2020,746725,0.06338000406122225
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,9885663,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Traction', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'success', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2019,206139,0.06338000406122225
"KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY DESCRIPTION (Adapted from Applicant's Abstract):  Knowledge-guided, fully        automated image analytic procedures will be applied, and further developed       for the extraction of diagnostic and prognostic information from                 histopathologic sections.  It is proposed to develop knowledge files for the     grading of solar lesions, for the analysis of prostatic intraepithelial          neoplastic lesions (PIN), for benign proliferative epithelial lesions of the     breast, and for kidney tumors.  Quantitative progression indices will be         derived from histometric measurements.  These may serve to identify patients     at high risk to develop infiltrating disease, to measure rate of lesion          progression, and to allow a numeric assessment of the efficacy of                chemopreventive intervention.                                                                                                                                     Knowledge files are under development for a quantitative measurement of the      vascularization around PIN lesions.                                                                                                                               For nuclei, lesions and patients, novel methodology is proposed to               characterize these entities by identification, rather than by mere               classification.  This will allow a significantly more precise                    characterization of the nuceli in a lesion and of the state of lesion            progression.  The identification methods will be integrated into the current     diagnostic decision support system, and be given capabilities to handle          missing data, contradictory evidence, atypical diagnostic clue expression.       This capability relies on automated reasoning will be developed, and the         methodology will be adapted for used in histopathologic diagnosis.                n/a",KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,6137486,R01CA053877,"['artificial intelligence', ' bioimaging /biomedical imaging', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' image processing', ' information system analysis', ' kidney neoplasms', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,2000,442719,0.09252633589394231
"KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY DESCRIPTION (Adapted from Applicant's Abstract):  Knowledge-guided, fully        automated image analytic procedures will be applied, and further developed       for the extraction of diagnostic and prognostic information from                 histopathologic sections.  It is proposed to develop knowledge files for the     grading of solar lesions, for the analysis of prostatic intraepithelial          neoplastic lesions (PIN), for benign proliferative epithelial lesions of the     breast, and for kidney tumors.  Quantitative progression indices will be         derived from histometric measurements.  These may serve to identify patients     at high risk to develop infiltrating disease, to measure rate of lesion          progression, and to allow a numeric assessment of the efficacy of                chemopreventive intervention.                                                                                                                                     Knowledge files are under development for a quantitative measurement of the      vascularization around PIN lesions.                                                                                                                               For nuclei, lesions and patients, novel methodology is proposed to               characterize these entities by identification, rather than by mere               classification.  This will allow a significantly more precise                    characterization of the nuceli in a lesion and of the state of lesion            progression.  The identification methods will be integrated into the current     diagnostic decision support system, and be given capabilities to handle          missing data, contradictory evidence, atypical diagnostic clue expression.       This capability relies on automated reasoning will be developed, and the         methodology will be adapted for used in histopathologic diagnosis.                n/a",KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,2856305,R01CA053877,"['artificial intelligence', ' bioimaging /biomedical imaging', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' image processing', ' information system analysis', ' kidney neoplasms', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,1999,434584,0.09252633589394231
"KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY DESCRIPTION (Adapted from Applicant's Abstract):  Knowledge-guided, fully        automated image analytic procedures will be applied, and further developed       for the extraction of diagnostic and prognostic information from                 histopathologic sections.  It is proposed to develop knowledge files for the     grading of solar lesions, for the analysis of prostatic intraepithelial          neoplastic lesions (PIN), for benign proliferative epithelial lesions of the     breast, and for kidney tumors.  Quantitative progression indices will be         derived from histometric measurements.  These may serve to identify patients     at high risk to develop infiltrating disease, to measure rate of lesion          progression, and to allow a numeric assessment of the efficacy of                chemopreventive intervention.                                                                                                                                     Knowledge files are under development for a quantitative measurement of the      vascularization around PIN lesions.                                                                                                                               For nuclei, lesions and patients, novel methodology is proposed to               characterize these entities by identification, rather than by mere               classification.  This will allow a significantly more precise                    characterization of the nuceli in a lesion and of the state of lesion            progression.  The identification methods will be integrated into the current     diagnostic decision support system, and be given capabilities to handle          missing data, contradictory evidence, atypical diagnostic clue expression.       This capability relies on automated reasoning will be developed, and the         methodology will be adapted for used in histopathologic diagnosis.                n/a",KNOWLEDGE BASED SYSTEMS FOR DIAGNOSTIC HISTOPATHOLOGY,2389351,R01CA053877,"['artificial intelligence', ' breast neoplasms', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' histopathology', ' image processing', ' information system analysis', ' kidney neoplasms', ' neoplasm /cancer diagnosis', ' prognosis', ' prostate neoplasms']",NCI,UNIVERSITY OF ARIZONA,R01,1998,426688,0.09252633589394231
"ALGORITHMS FOR PIGMENTED LESION SCREENING AND DETECTION The proposed study ""Algorithms for Pigmented Lesion Screening and Detection"", addresses the need for better physician training by providing specific accurate clinical descriptions of pigmented lesions including malignant melanoma.  In Phase I we propose to develop clinical algorithms to precisely describe malignant melanoma.  In this phase, aims include:  1. Precise color description and quantization:  location of early melanomas within the melanoma color band, definition of variegation.  2. Automatic border detection using global image features and automatic induction.  3. Analysis of asymmetry and irregularity:  We will seek optimal measures for these and apply to pigmented lesion images.  4. Importance of features:  What are the relative weights of critical features to be combined to generate a simple clinical rule for melanoma diagnosis?  Phase II will add one more analytic feature:  computer-determined visual texture.  What texture measures best help to distinguish melanoma from irregular seborrheic keratoses?  Analysis as in Phase I will be performed for benign pigmented lesions and will include development of software for computer-assisted instruction for improved clinical diagnosis of pigmented lesions.  Future application of computer vision diagnostic assistance systems might enable low-cost screening of large groups for pigmented lesions.  These could include routine hospital admissions, nursing home patients at annual intervals and public skin cancer screenings.  n/a",ALGORITHMS FOR PIGMENTED LESION SCREENING AND DETECTION,3493395,R43CA060294,"['artificial intelligence', ' biomarker', ' computer assisted diagnosis', ' computer assisted instruction', ' computer program /software', ' computer system design /evaluation', ' diagnosis quality /standard', ' digital imaging', ' erythema', ' melanoma', ' morphology', ' neoplasm /cancer diagnosis', ' pigmentation disorders', ' statistics /biometry']",NCI,STOECKER & ASSOCIATES,R43,1993,49981,-0.001485545923074537
"Statistical Methods for Multilevel Multivariate Functional Studies Abstract  While imaging studies are widely used in clinical practice and research, the number of neuroimaging- based biomarkers is small. For example, in clinical trials of immunomodulatory therapies for MS, the only commonly used imaging biomarkers are the total lesion volume and the number of new and en- hancing lesions. These biomarkers are essential, but do not capture the recovery process of lesions, which is thought to decline in more severe, progressive disease. The partial or complete recovery of lesions may depend both on the ability of the brain to heal and on external factors, such as treat- ment or environmental and behavioral exposures. In this proposal we take the natural next step of proposing imaging biomarkers for MS based on the formation and change of lesions as observed on multi-sequence structural MRIs. To solve this problem we propose to address several general method- ological problems: 1) develop models and methods for the longitudinal analysis of several images of the same brain; 2) identify and estimate the length of history that is necessary to estimate recovery; 3) study the association with known biomarkers of the disease (in this case total volume and number of new and enhancing lesions); 4) develop methods that are robust to changes in imaging protocols that inevitably arise in longitudinal neuroimaging studies; and 5) develop the computational tools that allow for sophisticated methods to be implemented seamlessly in practice. While our scientiﬁc problem is focused, the proposed statistical methods are general and can be applied to a wide variety of longitu- dinal neuroimaging studies. For example, there are many ongoing longitudinal neuroimaging studies, including the ADNI, AIBL, HBC, and MISTIE, where our methods could be used to study subtle or large changes in lesions or in white and gray matter intensities. Project narrative. The project provides statistical analysis methods for quantiﬁcation of the evolution in the intensity of brain lesions on multi-sequence Magnetic Resonance Imaging (MRI). Methods are motivated by the need to develop new neuroimaging-based biomarkers for multiple sclerosis (MS), but can be applied to other types of brain diseases including stroke, Alzheimer disease, and cancer.",Statistical Methods for Multilevel Multivariate Functional Studies,9635802,R01NS060910,"['Accounting', 'Address', 'Alzheimer&apos', 's Disease', 'Behavioral', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical Research', 'Clinical Trials', 'Computer software', 'Data', 'Databases', 'Disease', 'Enhancing Lesion', 'Event', 'Evolution', 'Funding', 'Grant', 'Graph', 'Image', 'Incidence', 'Length', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mediation', 'Mediator of activation protein', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'Multiple Sclerosis Lesions', 'Names', 'Natural History', 'Nature', 'Online Systems', 'Pattern', 'Population Heterogeneity', 'Problem Solving', 'Process', 'Progressive Disease', 'Protocols documentation', 'Randomized', 'Recording of previous events', 'Recovery', 'Research', 'Sampling', 'Statistical Data Interpretation', 'Statistical Methods', 'Stroke', 'Structure', 'Supervision', 'Techniques', 'Time', 'United States National Institutes of Health', 'base', 'biomarker validation', 'clinical practice', 'computerized tools', 'design', 'gray matter', 'healing', 'high dimensionality', 'imaging biomarker', 'imaging study', 'immunomodulatory therapies', 'improved', 'insight', 'longitudinal analysis', 'longitudinal database', 'multidimensional data', 'neuroimaging', 'non-Gaussian model', 'personalized approach', 'repaired', 'serial imaging', 'software development', 'treatment response', 'white matter']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2019,633289,0.050480086043863934
"Statistical Methods for Multilevel Multivariate Functional Studies Abstract  While imaging studies are widely used in clinical practice and research, the number of neuroimaging- based biomarkers is small. For example, in clinical trials of immunomodulatory therapies for MS, the only commonly used imaging biomarkers are the total lesion volume and the number of new and en- hancing lesions. These biomarkers are essential, but do not capture the recovery process of lesions, which is thought to decline in more severe, progressive disease. The partial or complete recovery of lesions may depend both on the ability of the brain to heal and on external factors, such as treat- ment or environmental and behavioral exposures. In this proposal we take the natural next step of proposing imaging biomarkers for MS based on the formation and change of lesions as observed on multi-sequence structural MRIs. To solve this problem we propose to address several general method- ological problems: 1) develop models and methods for the longitudinal analysis of several images of the same brain; 2) identify and estimate the length of history that is necessary to estimate recovery; 3) study the association with known biomarkers of the disease (in this case total volume and number of new and enhancing lesions); 4) develop methods that are robust to changes in imaging protocols that inevitably arise in longitudinal neuroimaging studies; and 5) develop the computational tools that allow for sophisticated methods to be implemented seamlessly in practice. While our scientiﬁc problem is focused, the proposed statistical methods are general and can be applied to a wide variety of longitu- dinal neuroimaging studies. For example, there are many ongoing longitudinal neuroimaging studies, including the ADNI, AIBL, HBC, and MISTIE, where our methods could be used to study subtle or large changes in lesions or in white and gray matter intensities. Project narrative. The project provides statistical analysis methods for quantiﬁcation of the evolution in the intensity of brain lesions on multi-sequence Magnetic Resonance Imaging (MRI). Methods are motivated by the need to develop new neuroimaging-based biomarkers for multiple sclerosis (MS), but can be applied to other types of brain diseases including stroke, Alzheimer disease, and cancer.",Statistical Methods for Multilevel Multivariate Functional Studies,9492705,R01NS060910,"['Accounting', 'Address', 'Alzheimer&apos', 's Disease', 'Behavioral', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical Research', 'Clinical Trials', 'Computer software', 'Data', 'Databases', 'Disease', 'Enhancing Lesion', 'Event', 'Evolution', 'Funding', 'Grant', 'Graph', 'Image', 'Incidence', 'Length', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mediation', 'Mediator of activation protein', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'Multiple Sclerosis Lesions', 'Names', 'Natural History', 'Nature', 'Online Systems', 'Pattern', 'Population Heterogeneity', 'Problem Solving', 'Process', 'Progressive Disease', 'Protocols documentation', 'Randomized', 'Recording of previous events', 'Recovery', 'Research', 'Sampling', 'Statistical Data Interpretation', 'Statistical Methods', 'Stroke', 'Supervision', 'Techniques', 'Time', 'United States National Institutes of Health', 'base', 'biomarker validation', 'clinical practice', 'computerized tools', 'design', 'gray matter', 'healing', 'high dimensionality', 'imaging biomarker', 'imaging study', 'immunomodulatory therapies', 'improved', 'insight', 'longitudinal analysis', 'longitudinal database', 'neuroimaging', 'non-Gaussian model', 'personalized approach', 'repaired', 'software development', 'treatment response', 'white matter']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2018,637414,0.050480086043863934
"Statistical Methods for Multilevel Multivariate Functional Studies Abstract  While imaging studies are widely used in clinical practice and research, the number of neuroimaging- based biomarkers is small. For example, in clinical trials of immunomodulatory therapies for MS, the only commonly used imaging biomarkers are the total lesion volume and the number of new and en- hancing lesions. These biomarkers are essential, but do not capture the recovery process of lesions, which is thought to decline in more severe, progressive disease. The partial or complete recovery of lesions may depend both on the ability of the brain to heal and on external factors, such as treat- ment or environmental and behavioral exposures. In this proposal we take the natural next step of proposing imaging biomarkers for MS based on the formation and change of lesions as observed on multi-sequence structural MRIs. To solve this problem we propose to address several general method- ological problems: 1) develop models and methods for the longitudinal analysis of several images of the same brain; 2) identify and estimate the length of history that is necessary to estimate recovery; 3) study the association with known biomarkers of the disease (in this case total volume and number of new and enhancing lesions); 4) develop methods that are robust to changes in imaging protocols that inevitably arise in longitudinal neuroimaging studies; and 5) develop the computational tools that allow for sophisticated methods to be implemented seamlessly in practice. While our scientiﬁc problem is focused, the proposed statistical methods are general and can be applied to a wide variety of longitu- dinal neuroimaging studies. For example, there are many ongoing longitudinal neuroimaging studies, including the ADNI, AIBL, HBC, and MISTIE, where our methods could be used to study subtle or large changes in lesions or in white and gray matter intensities. Project narrative. The project provides statistical analysis methods for quantiﬁcation of the evolution in the intensity of brain lesions on multi-sequence Magnetic Resonance Imaging (MRI). Methods are motivated by the need to develop new neuroimaging-based biomarkers for multiple sclerosis (MS), but can be applied to other types of brain diseases including stroke, Alzheimer disease, and cancer.",Statistical Methods for Multilevel Multivariate Functional Studies,9378514,R01NS060910,"['Accounting', 'Address', 'Alzheimer&apos', 's Disease', 'Behavioral', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain imaging', 'Clinical Research', 'Clinical Trials', 'Computer software', 'Data', 'Databases', 'Disease', 'Enhancing Lesion', 'Event', 'Evolution', 'Funding', 'Grant', 'Graph', 'Image', 'Incidence', 'Length', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mediation', 'Mediator of activation protein', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'Multiple Sclerosis Lesions', 'Names', 'Natural History', 'Nature', 'Online Systems', 'Pattern', 'Population Heterogeneity', 'Problem Solving', 'Process', 'Progressive Disease', 'Protocols documentation', 'Randomized', 'Recording of previous events', 'Recovery', 'Research', 'Sampling', 'Statistical Data Interpretation', 'Statistical Methods', 'Stroke', 'Supervision', 'Techniques', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'clinical practice', 'computerized tools', 'design', 'gray matter', 'healing', 'high dimensionality', 'imaging biomarker', 'imaging study', 'immunoregulation', 'improved', 'insight', 'longitudinal analysis', 'longitudinal database', 'neuroimaging', 'non-Gaussian model', 'personalized approach', 'repaired', 'software development', 'treatment response', 'white matter']",NINDS,JOHNS HOPKINS UNIVERSITY,R01,2017,659178,0.050480086043863934
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,9970009,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,649026,-0.06675159385005257
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures. In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s and Parkinson’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 35,000 researchers that use FreeSurfer through our existing open source mechanism. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner. These new capabilities well enable other studies to significantly increase their ability to detect disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately.",Deep Learning Algorithms for FreeSurfer,9971629,R56AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Architecture', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Databases', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Parkinson Disease', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'autoencoder', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'morphometry', 'nervous system disorder', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R56,2019,609504,0.04826078477989818
"Quantifying the individual contributions of comorbid tau neuropathologies using deep learning PROJECT SUMMARY/ABSTRACT Co-occurrence of different neurodegenerative diseases is increasingly common with age and acts as a confounding factor in the development of disease-specific biomarkers. Yet, even by the gold standard of evaluating immunostaining for aggregated proteins in autopsy brains, pathologic complexity makes it impossible to reliably quantify the mixture of diseases by visual inspection, especially when coexistent disorders both feature the same aggregated protein, albeit in different disease-specific patterns. Here, we hypothesize that recent advances in deep learning can identify the distinctive patterns of Alzheimer disease (AD) and progressive supranuclear palsy (PSP) neuropathology, thereby allowing us to de-convolve their individual contributions from phospho-tau immunostaining of mixed pathologies. We will tackle this problem in three steps. First, in order to incorporate biological knowledge and enable interpretability of our disease predictions, we will develop a set of deep learning classifiers to identify disease relevant “features” in virtual whole slide images. These features will include different types of cells (e.g. neurons, astrocytes), aggregates (e.g. tufted astrocytes and senile plaques that are enriched in PSP and AD, respectively) and tissue regions (gray vs. white matter, which differ in pattern of involvement in these diseases). Second, based on the assumption that comorbid pathologies exhibit a mixture of pure disease features, we will build disease classifiers from pure AD and pure PSP cases. Given a local patch of tau-stained tissue, these classifiers will return their confidence that tissue exhibited either of these diseases. We will evaluate two approaches, one building on the “features” identified above and the other a more traditional black- box deep learning approach working purely off of image patches. Finally, we will evaluate our pure disease classifiers on cases with mixed pathologies based on pathologist review and concordance with antibodies to tau isoforms whose individual histomorphologies help to distinguish between AD and PSP. As they will identify established neuropathology features demonstrated by the widely-used AT8 phospho-tau and 3R and 4R tau isoform immunostaining, our classifiers will be a valuable resource for future digital imaging based studies in neuropathology. Our framework for de-convolving comorbidities from autopsy samples can be extended to other diseases, thus enabling better integration with clinical and biomarker data, and ultimately, improved antemortem diagnosis and therapy. PROJECT NARRATIVE Co-occurrence of different neurodegenerative pathologies is increasingly common with age. Here, we aim to use deep learning to distinguish the relative contributions of individual comorbid diseases from tau-stained images of autopsy brains affected by two comorbid conditions, Alzheimer disease and progressive supranuclear palsy. Technologies developed during this proposal will provide powerful machine learning tools for neuropathology, while its successful completion will facilitate better integration with clinical and biomarker data, and ultimately, improved antemortem diagnosis and therapy.",Quantifying the individual contributions of comorbid tau neuropathologies using deep learning,10058010,R21AG066012,"['Adoption', 'Affect', 'Age', 'Aging', 'Alzheimer&apos', 's Disease', 'Antibodies', 'Astrocytes', 'Atlases', 'Autopsy', 'Biological', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Classification', 'Clinical', 'Complex', 'Data', 'Dementia', 'Deposition', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Exhibits', 'Future', 'Genetic', 'Gold', 'Heterogeneity', 'Histopathology', 'Human', 'Image', 'Individual', 'Investigation', 'Knowledge', 'Lesion', 'Libraries', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Monoclonal Antibodies', 'Morphology', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurons', 'Pathologic', 'Pathologist', 'Pathology', 'Pattern', 'Phenotype', 'Progressive Supranuclear Palsy', 'Protein Isoforms', 'Research', 'Resources', 'Sampling', 'Senile Plaques', 'Spatial Distribution', 'Stains', 'Tauopathies', 'Technology', 'Testing', 'Tissue Stains', 'Tissues', 'Visual', 'Visualization', 'base', 'case-based', 'cell type', 'clinical biomarkers', 'comorbidity', 'deep learning', 'digital imaging', 'gray matter', 'hands-on learning', 'improved', 'learning classifier', 'learning strategy', 'method development', 'neocortical', 'neuropathology', 'protein aggregation', 'specific biomarkers', 'tau Proteins', 'tau-1', 'tool', 'tumor', 'virtual', 'virtual imaging', 'white matter', 'whole slide imaging']",NIA,UT SOUTHWESTERN MEDICAL CENTER,R21,2020,450250,-0.09607186793329296
"Neurodegenerative diseases and the role of green space: A deep learning assessment PROJECT SUMMARY Alzheimer’s disease and related dementias (ADRD) have well-established risk factors such as physical activity (PA), depression, and hypertension (HTN). These risk factors disproportionately affect racial minority populations, but the mechanisms underlying racial health disparities are not well understood. In this, geographic factors could be key, as PA, depression and HTN are strongly affected by geographic exposures, including green space. However, green space is typically measured with questionnaires, which have substantial error, or satellite-based indexes that are nonspecific and provide no information on the type of vegetation (e.g., tree vs. grass), nor whether the vegetation is within view at the street level. As a result, no study has quantified the contribution of green space to racial disparities in ADRD. And while novel technologies such as Google Street Views (GSV) imaging are promising data sources for capturing unique measures of green space, managing, processing, and analyzing high-dimensional data present significant logistical and analytical challenges, especially when linking these data to existing data from large prospective cohorts. Finally, we need to understand green space in the context of other potentially correlated geographic exposures, or the urban exposome—the totality of life- course geographic exposures (the set of green space, air pollutants, noise, built environment, and social environment)—to estimate which factors drive health. This proposal will address these challenges by using GSV imaging to assess the effect of green space on PA, depression, and HTN, as well as subsequent ADRD risk within the Multi-Ethnic Study of Atherosclerosis (MESA)—a 10-year longitudinal study of 6,814 men and women without clinical cardiovascular disease at baseline from 4 racial/ethnic groups (Non-Hispanic White, African-American, Chinese, and Hispanic). Aim 1 will quantify the effect of specific aspects of green space (e.g. trees, grass, shrubs, plants) on ADRD and cognitive decline and evaluate whether these associations differ according to race/ethnicity. Aim 2 will determine the indirect effect of green space on ADRD that is mediated through PA, depression, and HTN. Aim 3 will quantify exposome associations with ADRD and cognitive decline using untargeted data-driven approaches in conjunction with dimension reduction techniques and evaluate whether they differ according to race/ethnicity. This research plan is complemented by a training plan that builds on the applicant’s background in epidemiology and biostatistics and includes new training in (1) implementing deep learning algorithms to analyze high-resolution geographic data, (2) cognitive function epidemiology, and (3) developing and refining data-driven approaches to perform exposome-informed epidemiological studies. These combined plans will successfully prepare the applicant for an independent research career focused on identifying modifiable geographic determinants of ADRD in diverse populations using innovative measures of geographic context. Project Narrative Green space or trees and natural vegetation can provide mental health benefits and possibly lower risk of neurodegenerative diseases such as Alzheimer’s disease and related dementias (ADRD); however, green space is often measured poorly in epidemiologic research. I propose to integrate high-resolution images from Google Street Views to derive ground-level objective measurements of green space into a diverse prospective cohort study using deep learning algorithms, mediation analysis and geographic mixtures. This research will enable unprecedented perspectives on exposures that drive ADRD and related cognitive decline risk, and will provide translational insights into potential interventions to optimize opportunities for ADRD prevention and reduce racial disparities in ADRD.",Neurodegenerative diseases and the role of green space: A deep learning assessment,9952648,K99AG066949,"['Accounting', 'Address', 'Adult', 'Affect', 'African American', 'Age', 'Air Pollutants', 'Alzheimer&apos', 's disease related dementia', 'Alzheimer&apos', 's disease risk', 'Baltimore', 'Biological', 'Biometry', 'Cardiovascular Diseases', 'Chicago', 'Chinese People', 'Cities', 'Clinical', 'Complement', 'Complex', 'County', 'Cross-Sectional Studies', 'Data', 'Data Sources', 'Diagnosis', 'Dimensions', 'Elderly', 'Environment', 'Environmental Hazards', 'Epidemiology', 'Ethnic Origin', 'Ethnic group', 'Exposure to', 'Family', 'Funding', 'Geographic Factor', 'Geography', 'Goals', 'Green space', 'Health', 'Health Benefit', 'Healthcare', 'Hispanics', 'Hypertension', 'Image', 'Imagery', 'Impaired cognition', 'Incidence', 'Individual', 'Intervention', 'Lead', 'Life Cycle Stages', 'Link', 'Literature', 'Logistics', 'Longitudinal Studies', 'Los Angeles', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Mental Depression', 'Mental Health', 'Methodology', 'Methods', 'Minority', 'Multi-Ethnic Study of Atherosclerosis', 'Neurodegenerative Disorders', 'New York', 'Noise', 'Not Hispanic or Latino', 'Pathway interactions', 'Patients', 'Physical activity', 'Plants', 'Poaceae', 'Population', 'Population Heterogeneity', 'Prevalence', 'Prevention', 'Prevention strategy', 'Prospective cohort', 'Prospective cohort study', 'Questionnaires', 'Race', 'Research', 'Resolution', 'Risk', 'Risk Factors', 'Role', 'Social Environment', 'Social Impacts', 'Techniques', 'Time', 'Training', 'Trees', 'United States National Institutes of Health', 'Woman', 'aged', 'base', 'built environment', 'career', 'cognitive function', 'cohort', 'comorbidity', 'deep learning', 'deep learning algorithm', 'dementia risk', 'design', 'economic impact', 'epidemiology study', 'ethnic minority population', 'healthy aging', 'high resolution imaging', 'indexing', 'innovation', 'insight', 'longitudinal analysis', 'men', 'multidimensional data', 'neurocognitive disorder', 'new technology', 'novel', 'physical inactivity', 'public health intervention', 'racial and ethnic', 'racial disparity', 'racial health disparity', 'racial minority', 'segmentation algorithm', 'skills', 'urban public health']",NIA,HARVARD SCHOOL OF PUBLIC HEALTH,K99,2020,129600,-0.04106836088315591
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9724174,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,24598,0.10796572445836732
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9526090,R61AR073552,"['Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2018,399482,0.10796572445836732
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.!",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,9669002,R61AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Simulation', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R61,2019,447173,0.10796572445836732
"Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement ABSTRACT This proposal aims to develop deep learning methods to automate the extraction of morphological imaging features relevant to knee osteoarthritis (OA), and total knee replacement. While, quantitative evaluation Magnetic Resonance Imaging (MRI) plays a central role in OA research in the clinical setting MR reports often tend to be subjective, qualitative, and the grading schemes utilized in epidemiological research are not used because they are extraordinarily time consuming and do not lend themselves to the demands of todays changing healthcare scenario. The “Big Data” challenge and opportunity facing us makes it necessary to build enabling tools (i) to automate the extraction of morphological OA imaging features, with the aim of evaluating disease progression prediction capabilities on larger sample sizes that have never been explored before; (ii) to discover latent patterns by uncovering unexplored data-driven imaging features by the application of state of the art deep learning approaches (1); (iii) combine multi-modality imaging with clinical, functional, activity, and other data to define the trajectory of joint degeneration in OA. Leveraging the power of these state of the art techniques, and with the extraordinary availability of a large datasets of annotated images; in this project, we propose to develop an automatic post-processing pipeline able to segment musculoskeletal tissues and identify morphological OA features in Magnetic Resonance Images (MRI), as defined by commonly used MRI grading systems. Automation of morphological grading of the tissues in the joint would be a significant breakthrough in both OA research and clinical practice. It would enable the analysis of large sample sizes, assist the radiologist/clinician in the grading of images, take a relatively short amount of time, reduce cost, and could potentially, improve classification models. The availability of automatic pipelines for the identification of morphological abnormities in MRI would drastically change clinical practice, and include semi-quantitative grades, rather than subjective impressions in radiology clinical reports. In this study, we also aim to develop a complete supervised deep learning approach to obtain data-driven representations as non-linear and semantic aggregation among elementary features able to exploit the latent information hidden in the complexity of a 3D MR images, eliminating the need for nominal grades of selected features. This second aim, while being at high risk has also a potential exceptional high impact; as it departs from the classical hypothesis driven studies, and builds a novel translational platform to revolutionize morphological grading of MR images in research studies, but also is paradigm-shifting in that it may provide a more quantitative feature driven basis for routine radiological clinical reports. The clinical impact of this proposal lies in the third aim (R33 phase), in which we propose to translate the solutions developed in the R61 phase on images in the UCSF clinical archives (PACS), and plan to include also demographic and clinical data in the electronic health records, to build the models defining total knee replacements. PROJECT NARRATIVE Deep learning is revolutionizing medical imaging by solving challenging problems in disease classification, progression and therapeutic response. In this project, we focus on using deep learning methodology on magnetic resonance images of the knee to study osteoarthritis prevalence, and progression. The usage of features derived from the imaging data, rather than established, and often subjective grading schemes, will have significant impact on clinical radiology, establishing quantitative physician assist tools with an ultimate goal of reducing the economic and healthcare burden of total knee replacement.",Deep Learning for Characterizing Knee Joint Degeneration Predicting Progression of Osteoarthritis and Total Knee Replacement,10193990,R33AR073552,"['3-Dimensional', 'Algorithms', 'Archives', 'Artificial Intelligence', 'Automation', 'Big Data', 'Bone Marrow', 'Cartilage', 'Classification', 'Clinical', 'Clinical Data', 'Clinical/Radiologic', 'Computer Models', 'Consumption', 'Data', 'Data Reporting', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Development', 'Disease', 'Disease Progression', 'Economics', 'Edema', 'Electronic Health Record', 'Epidemiology', 'Genomics', 'Goals', 'Healthcare', 'Image', 'Incidence', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Lesion', 'Ligaments', 'Magnetic Resonance Imaging', 'Medical Imaging', 'Meniscus structure of joint', 'Methodology', 'Modeling', 'Morphology', 'Multimodal Imaging', 'Musculoskeletal', 'Neural Network Simulation', 'Organ', 'Outcome', 'Pattern', 'Phase', 'Physical activity', 'Physicians', 'Picture Archiving and Communication System', 'Play', 'Prevalence', 'Quantitative Evaluations', 'Reporting', 'Research', 'Role', 'Sample Size', 'Scheme', 'Semantics', 'Structure', 'Subchondral Cyst', 'Supervision', 'Synovitis', 'System', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Translating', 'Visual', 'automated segmentation', 'bone', 'clinical practice', 'clinical translation', 'convolutional neural network', 'cost', 'deep learning', 'deep neural network', 'disease classification', 'drug discovery', 'epidemiology study', 'feature extraction', 'high risk', 'impression', 'improved', 'joint destruction', 'knee replacement arthroplasty', 'large datasets', 'learning strategy', 'musculoskeletal imaging', 'novel', 'parallel processing', 'patient population', 'radiologist', 'research study', 'speech recognition', 'tool', 'treatment response']",NIAMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R33,2020,403748,0.10796572445836732
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9970413,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated algorithm', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'feature extraction', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,497020,0.10126238030408041
"Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis ABSTRACT In the U.S., more than 600,000 knee osteoarthritis (OA)-related total knee joint replacement (TKR) cases are reported every year, exceeding $17 billion estimated direct costs annually. There is a growing need for disease- modifying therapies that prevent or delay the need for TKR. However, development of such therapies remains challenging due to the lack of objective and measurable OA biomarkers for disease progression. The course of the OA is highly variable between individuals and the OA progresses too slowly, making it difficult to identify sensitive OA biomarkers capable of capturing minor changes on the knee joint. This has slowed development of effective therapies and prevents physicians from providing the most effective advice about minimizing the need for TKR. In this project, our goal is to develop imaging biomarkers to monitor minor OA-related changes in knee joint health that lead to TKR. To achieve this goal, we will combine novel deep learning algorithms with clinical and imaging data from the Osteoarthritis Initiative (OAI). The OAI dataset includes clinical data, biospecimens, radiographs, and magnetic resonance (MR) images collected over 8 years. The proposed project has three Specific Aims: (i) to develop an automated OA-relevant biomarker identification tool from the bilateral posteroanterior fixed-flexion knee radiographs using deep convolutional neural networks (CNNs) and recurrent neural networks (RNNs) combined with the OA progression outcome of subjects (n = 882); (ii) to develop an automated OA-relevant biomarker identification tool from structural and compositional MR images using 3D CNNs with RNNs combined with the OA progression outcome of subjects (n = 882); and (iii) to determine whether deep learning–based imaging biomarkers can act as surrogates to predict the OA progression using a subject cohort (n = 296) independent of the cohort used to identify imaging biomarkers. The proposed project will couple deep learning with diagnostic radiology to unveil key combinations of OA-relevant features directly from images with minimal user interaction. This will facilitate fast individualized assessment of OA progression using whole knee joint images directly. If successful, this study will bring new insights into the development of imaging biomarkers for OA progression and more broadly into our understanding and treatment of OA. The knowledge gained in this project will help to advance close monitoring of OA progression by opening new perspectives on the regions and parameters for potential inclusion in both intervention studies and clinical practice. NARRATIVE Osteoarthritis (OA) is a chronic degenerative disorder of joints and is the most common reason leading to total knee joint replacement. Our proposed study aims to develop a novel automated OA-relevant imaging biomarker identification system based on radiographs, magnetic resonance images, and deep learning methods to study knee OA progression. We will address whether combining deep learning algorithms with medical images will determine the key combinations of features relevant to knee OA that are required to accurately predict the OA progression outcome.",Deep Learning-based Imaging Biomarkers for Knee Osteoarthritis,9818000,R01AR074453,"['3-Dimensional', 'Address', 'Algorithms', 'Bilateral', 'Biological Markers', 'Case Study', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Collaborations', 'Complex', 'Data', 'Data Set', 'Degenerative Disorder', 'Degenerative polyarthritis', 'Development', 'Diagnostic radiologic examination', 'Direct Costs', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Image', 'Image Analysis', 'Individual', 'Intervention', 'Intervention Studies', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Knowledge', 'Lead', 'Length', 'Location', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurable', 'Medical Imaging', 'Methods', 'Minor', 'Modeling', 'Monitor', 'Musculoskeletal System', 'Outcome', 'Participant', 'Patient-Focused Outcomes', 'Patients', 'Physicians', 'Play', 'Probability', 'Replacement Arthroplasty', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Role', 'Severities', 'Statistical Data Interpretation', 'Structure', 'System', 'Techniques', 'Therapeutic Intervention', 'Training', 'Visit', 'arthropathies', 'automated analysis', 'base', 'biomarker identification', 'bone', 'clinical practice', 'clinical risk', 'cohort', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'effective therapy', 'high risk', 'imaging biomarker', 'improved', 'in vivo', 'information model', 'innovation', 'insight', 'learning strategy', 'novel', 'outcome forecast', 'outcome prediction', 'patient stratification', 'predictive marker', 'predictive modeling', 'prevent', 'recurrent neural network', 'tool']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,489349,0.10126238030408041
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,9817807,R01AR074492,"['Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Dimensions', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Kinetics', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'extracellular', 'flexibility', 'gait examination', 'gait retraining', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2019,561592,0.04593648378327278
"Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis Project Summary Osteoarthritis (OA) is the leading cause of disability worldwide. The inability of non-invasive techniques to quantify disease progression has limited understanding of the pathogenesis of OA. While numerous magnetic resonance imaging (MRI) methods have been proposed for imaging OA, sensitivity to bone metabolism has been limited. We propose to develop advanced three-dimensional PET-MRI methods for bone and soft tissue metabolism to study the response of the tissues in the joint to changes in knee load. This work will lead to a new understanding of OA pathogenesis by revealing relationships between changes in cartilage and bone metabolism over time. This project aims to develop PET-MRI methods to sensitively track changes of OA in response to biomechanical loading. Our specific aims are to (1) Develop accurate, reproducible and dose-optimized kinetic models of dynamic 18F-NaF PET-MRI for quantitative bilateral whole joint imaging using deep learning and advanced MR coil technology, (2) Study the relationship between resting state bone metabolism and biomechanics using PET- MRI and (3) Perform a longitudinal study to assess the response of our new imaging methods to changes in joint biomechanics from gait retraining. The innovation of this work lies in the development of novel imaging techniques that simultaneously offer quantitative measures of tissue physiology in cartilage and bone using PET-MRI. The significance of this work is that we will be able to sensitively and quantitatively track changes in bone metabolism and soft tissue microstructure due to changes in biomechanical loading in the knee joint over time. This will provide new and more sensitive imaging tools to assess the responses of the joint to biomechanical interventions to treat OA such as gait retraining, bracing, or high tibial osteotomy. Narrative Osteoarthritis affects more than half of the population during their lives and is the leading cause of disability worldwide. Diagnostic imaging of osteoarthritis is often limited to x-ray, but more sensitive and specific imaging is a critical need for assessment of disease-modifying treatments such as bracing or gait modification. This work aims to develop novel 3D imaging approaches using positron-emission tomography (PET) and magnetic resonance imaging (MRI), to quantitatively assess joint health during mechanical treatment of osteoarthritis. !",Development of Sodium Fluoride PET-MRI for Quantitative Assessment of Knee Osteoarthritis,9997783,R01AR074492,"['3-Dimensional', 'Affect', 'Anatomy', 'Architecture', 'Arthralgia', 'Bilateral', 'Biochemical', 'Biomechanics', 'Bone Matrix', 'Bone Spur', 'Bone Tissue', 'Bone remodeling', 'Canes', 'Cartilage', 'Clinical', 'Data', 'Degenerative polyarthritis', 'Deposition', 'Development', 'Diagnostic Imaging', 'Disease', 'Disease Progression', 'Dose', 'Environment', 'Extracellular Matrix', 'Fluoride Ion', 'Future', 'Gait', 'Health', 'Human', 'Hybrids', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Intervention', 'Joints', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Lateral', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Mechanics', 'Medial', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Multimodal Imaging', 'Needs Assessment', 'Orthopedics', 'Osteotomy', 'Pain', 'Pathogenesis', 'Patients', 'Performance', 'Perfusion', 'Photons', 'Physiology', 'Population', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Protocols documentation', 'Quality of life', 'Reporting', 'Reproducibility', 'Research', 'Rest', 'Risk Factors', 'Roentgen Rays', 'Sclerosis', 'Severities', 'Shapes', 'Societies', 'Sodium Fluoride', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Treatment Efficacy', 'Work', 'analysis pipeline', 'attenuation', 'base', 'bone', 'bone metabolism', 'cartilage metabolism', 'clinical translation', 'cost', 'deep learning', 'disability', 'flexibility', 'gait examination', 'gait rehabilitation', 'imaging approach', 'imaging capabilities', 'imaging modality', 'imaging system', 'improved', 'innovation', 'joint loading', 'kinetic model', 'mechanical force', 'mechanical properties', 'mineralization', 'molecular marker', 'non-invasive imaging', 'novel', 'novel imaging technique', 'pharmacokinetic model', 'quantitative imaging', 'radiotracer', 'response', 'soft tissue', 'subchondral bone', 'tool', 'treatment strategy', 'uptake']",NIAMS,STANFORD UNIVERSITY,R01,2020,435694,0.04593648378327278
"WAVELET REPRESENTATIONS FOR DIAGNOSIS OF MELANOMA A practical, digital dermoscopic imaging system will be developed for the        reliable, non-invasive, early diagnosis of melanoma. This system will            provide an objective and user-friendly tool to assist health care                providers in diagnosing melanoma. Phase 1 produced two very important            results:                                                                         1. The feasibility of a new paradigm for reliable, automatic diagnosis           of early melanoma was demonstrated. It combines wavelet-based multi-scale        statistical parameters, that quantify textures of dermoscopic images,            with other, non-wavelet parameters reported by us in the literature.             Significantly improved differentiation between early melanoma and its            benign simulants is achieved thereby.                                            2. The feasibility of using well calibrated, multispectral, dermoscopic          lesion images for automated lesion segmentation, feature extraction and          classification was established.                                                                                                                                   The specific aims of Phase 2 are:                                                (l) Further develop the image database for training and more                     comprehensive testing of our diagnostic methods.                                 (2) Analyze parametrically the dependence of performance of the proposed         lesion classification methods on the spectral illumination bands, spatial        resolution, and dynamic range of the imaging system.                             (3) Design and build six commercial prototypes.                                  (4) Clinically test these prototypes at four major clinical centers.                                                                                              PROPOSED COMMERCIAL APPLICATIONS:                                                This imaging system could become standard instrumentation in the offices         of dermatologists and health care delivery facilities for melanoma               screening, monitoring of suspicious pigmented lesions, and as an aid in          their diagnosis. Also, the database developed during Phase 2, and beyond,        will be an important medical resource for the health-care community.              n/a",WAVELET REPRESENTATIONS FOR DIAGNOSIS OF MELANOMA,2896005,R44CA074628,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' early diagnosis', ' histopathology', ' human data', ' human subject', ' image processing', ' melanoma', ' method development', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' training']",NCI,"ELECTRO-OPTICAL SCIENCES, INC.",R44,1999,307817,0.03331652070040524
"WAVELET REPRESENTATIONS FOR DIAGNOSIS OF MELANOMA A practical, digital dermoscopic imaging system will be developed for the        reliable, non-invasive, early diagnosis of melanoma. This system will            provide an objective and user-friendly tool to assist health care                providers in diagnosing melanoma. Phase 1 produced two very important            results:                                                                         1. The feasibility of a new paradigm for reliable, automatic diagnosis           of early melanoma was demonstrated. It combines wavelet-based multi-scale        statistical parameters, that quantify textures of dermoscopic images,            with other, non-wavelet parameters reported by us in the literature.             Significantly improved differentiation between early melanoma and its            benign simulants is achieved thereby.                                            2. The feasibility of using well calibrated, multispectral, dermoscopic          lesion images for automated lesion segmentation, feature extraction and          classification was established.                                                                                                                                   The specific aims of Phase 2 are:                                                (l) Further develop the image database for training and more                     comprehensive testing of our diagnostic methods.                                 (2) Analyze parametrically the dependence of performance of the proposed         lesion classification methods on the spectral illumination bands, spatial        resolution, and dynamic range of the imaging system.                             (3) Design and build six commercial prototypes.                                  (4) Clinically test these prototypes at four major clinical centers.                                                                                              PROPOSED COMMERCIAL APPLICATIONS:                                                This imaging system could become standard instrumentation in the offices         of dermatologists and health care delivery facilities for melanoma               screening, monitoring of suspicious pigmented lesions, and as an aid in          their diagnosis. Also, the database developed during Phase 2, and beyond,        will be an important medical resource for the health-care community.              n/a",WAVELET REPRESENTATIONS FOR DIAGNOSIS OF MELANOMA,2717511,R44CA074628,"['artificial intelligence', ' clinical research', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' data collection', ' digital imaging', ' early diagnosis', ' histopathology', ' human data', ' human subject', ' image processing', ' melanoma', ' method development', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' training']",NCI,"ELECTRO-OPTICAL SCIENCES, INC.",R44,1998,441901,0.03331652070040524
"A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER   Skin cancer is the fastest growing cancer. Approximately 34,100         Americans developed cutaneous melanoma in 1995; of the survivors, many must          contend with the ongoing trauma of disfigurement and fear. Skin biopsies are         now the most frequently performed medical procedure. It is axiomatic among           dermatologists that early detection and diagnosis are critical. Great strides        have been made in early detection of suspect skin lesions; however failure to        biopsy the right lesion has severe consequences. The dilemma is exacerbated          since 50- 80 percent of biopsies prove unnecessary, contributing to an enormous      waste of health care dollars, patient trauma and negative patient behavior           feedback. The Phase I work in dermatological spectroscopy and artificial neural      net technology suggest that an automated clinical diagnostic aid which produces      a quantitative rather than qualitative diagnostic assessment of skin lesions is      possible. This project proposes development and testing of such a product.           During Phase II a large number of spectroscopic samples of melanoma and nevi         will be used to complete development of an artificial neural net classifier.         Such a classifier system will lead to a commercial product to discriminate           ""normal,"" pre-cancerous and cancerous skin lesions.                                   PROPOSED COMMERCIAL APPLICATION:  The proposed project will lead to a non-invasive, in-office, real-time test to provide an  automated, repeatable diagnostic probability of the nature of skin lesions prior to biopsy.  Skin biopsies are now the most frequently performed reimbursed Medicare procedure,   and as many as 50-80% are found not to be necessary after the fact.  The low cost of   this test, and rapid amortization of the system, coupled with the enormous health care   cost savings possible in conjunction with a significant and widely recognized health   problem, suggest that this product could have great commercial potential.  n/a",A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER,6376769,R44CA078006,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence spectrometry', ' histology', ' human subject', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' reflection spectrometry', ' skin neoplasms', ' spectrometry']",NCI,"WESTERN RESEARCH COMPANY, INC.",R44,2001,359255,0.06741407884946779
"A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER   Skin cancer is the fastest growing cancer. Approximately 34,100         Americans developed cutaneous melanoma in 1995; of the survivors, many must          contend with the ongoing trauma of disfigurement and fear. Skin biopsies are         now the most frequently performed medical procedure. It is axiomatic among           dermatologists that early detection and diagnosis are critical. Great strides        have been made in early detection of suspect skin lesions; however failure to        biopsy the right lesion has severe consequences. The dilemma is exacerbated          since 50- 80 percent of biopsies prove unnecessary, contributing to an enormous      waste of health care dollars, patient trauma and negative patient behavior           feedback. The Phase I work in dermatological spectroscopy and artificial neural      net technology suggest that an automated clinical diagnostic aid which produces      a quantitative rather than qualitative diagnostic assessment of skin lesions is      possible. This project proposes development and testing of such a product.           During Phase II a large number of spectroscopic samples of melanoma and nevi         will be used to complete development of an artificial neural net classifier.         Such a classifier system will lead to a commercial product to discriminate           ""normal,"" pre-cancerous and cancerous skin lesions.                                   PROPOSED COMMERCIAL APPLICATION:  The proposed project will lead to a non-invasive, in-office, real-time test to provide an  automated, repeatable diagnostic probability of the nature of skin lesions prior to biopsy.  Skin biopsies are now the most frequently performed reimbursed Medicare procedure,   and as many as 50-80% are found not to be necessary after the fact.  The low cost of   this test, and rapid amortization of the system, coupled with the enormous health care   cost savings possible in conjunction with a significant and widely recognized health   problem, suggest that this product could have great commercial potential.  n/a",A NON INVASIVE DERMATOLOGICAL LESION CLASSIFIER,6143548,R44CA078006,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' computer assisted diagnosis', ' diagnosis design /evaluation', ' fluorescence spectrometry', ' histology', ' human subject', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' reflection spectrometry', ' skin neoplasms', ' spectrometry']",NCI,"WESTERN RESEARCH COMPANY, INC.",R44,2000,363073,0.06741407884946779
"NONINVASIVE DERMATOLOGICAL LESION CLASSIFIER Skin cancer is the fastest growing cancer in the United States today.            Approximately 34,100 Americans developed cutaneous melanoma in 1995, and         7,200 died of the disease; of the survivors, many must contend with the          ongoing trauma of disfigurement and fear.  Skin biopsies are now the most        frequently performed medical procedure reimbursed by Medicare.  It is            axiomatic among dermatologists that early detection and diagnosis are            critical in the care and treatment of skin cancer patients.  Great               strides have been made in recent years in early detection of suspect skin        lesions; however, the diagnosis remains based in the subjective                  evaluation of which skin lesions to biopsy.  This decision is the basis          of a great dilemma for physicians of at-risk patients who develop                literally hundreds of lesions which could be pre-cancerous or cancerous.         On one hand biopsies are expensive and traumatic; on the other, failure          to biopsy the right lesion can lead to severe consequences.  The dilemma         is further exacerbated by the fact that 50-80% of biopsies prove                 unnecessary after the fact, contributing to an enormous of valuable              health care dollars, patient trauma and negative patient behavior                feedback.  Recent developments in dermatological spectroscopy used to            train an artificial neural net technology suggest that an automated              clinical diagnostic aid which produces a quantitative rather than                qualitative diagnostic assessment of skin lesions is possible.  This             project proposes development and testing of such a product.                      Spectroscopic samples of approximately 500 patients with abnormal skin           lesions will be coupled with an equal number of normal skin spectra and          used to train an artificial neural net classifier.  This automated               diagnostic aid will be tested against a large number of test samples for         which a histological diagnosis is available for evaluation of the system.                                                                                         PROPOSED COMMERCIAL APPLICATIONS:                                                The proposed project will lead to a non-invasive, in-office, real-time           test to provide an automated, repeatable diagnostic probability of the           nature of skin lesions prior to biopsy. Skin biopsies are now the most           frequently performed reimbursed Medicare procedure, and as many as 50-80%        are found not to be necessary after the fact. The low cost of this test,         and rapid amortization of the system, coupled with the enormous health           care cost savings possible in conjunction with a significant and widely          recognized health problem, suggest that this product could have great            commercial potential.                                                             n/a",NONINVASIVE DERMATOLOGICAL LESION CLASSIFIER,2645334,R43CA078006,"['artificial intelligence', ' biomedical automation', ' biomedical equipment development', ' clinical research', ' diagnosis design /evaluation', ' fluorescence spectrometry', ' histology', ' human subject', ' neoplasm /cancer classification /staging', ' neoplasm /cancer diagnosis', ' noninvasive diagnosis', ' reflection spectrometry', ' skin neoplasms', ' spectrometry']",NCI,"WESTERN RESEARCH COMPANY, INC.",R43,1998,100000,0.0708556295727206
"FRACTAL FEATURES FOR DIAGNOSING MAMMOGRAPHIC MASSES We propose developing statistical fractal features which quantify lesion         border roughness on mammograms and using these features to distinguish           malignant and benign breast lesions.  Objective measures of lesion               roughness are important in the diagnosis and staging of breast cancer.           In this novel approach, we generate a space of fractal models, and               evaluate the fractal dimension (fd) of the lesion from the statistics            of the model space.                                                                                                                                               Using intensity as the third dimension, we generate a 3-dimensional              image of the mammogram and select a set of intensity levels found in the         lesion.  For each selected intensity level, we construct a binary                thresholded image and trace the lesion border.  Analysis is restricted           to segments of thresholded borders which are in high-gradient portions           of the 3-dimensional image and can be determined with high precision.                                                                                             Each selected boundary segments is analyzed to identify self-affine              subsegments which are modeled using multiple fractal interpolation               functions having known fd values.  Thus we construct a large sample              space of fd values which are computed from high-precision boundary               traces occurring on a range of threshold levels.  The statistics of the          fd sample space are the features used to distinguish between malignant           and benign lesions.                                                                                                                                               PROPOSED COMMERCIAL APPLICATION                                                  Our product will have significant value to the diagnostician who must            distinguish malignant from benign breast lesions.  The algorithm is              readily integrated into both computer-aided diagnosis systems and                digital mammogram systems which display and process mammographic images          for the expert diagnostician.                                                     n/a",FRACTAL FEATURES FOR DIAGNOSING MAMMOGRAPHIC MASSES,2651907,R43CA078108,"['artificial intelligence', ' breast neoplasm /cancer diagnosis', ' computer assisted diagnosis', ' computer program /software', ' computer system design /evaluation', ' diagnosis design /evaluation', ' mathematical model', ' neoplasm /cancer classification /staging', ' statistics /biometry']",NCI,"ALAN PENN AND ASSOCIATES, INC.",R43,1998,99996,-0.011913142761725453
"Structure-based prediction of the interactome Supplement Summary “Structure-based prediction of the interactome” NIH R01GM081871-10 PI: Bonnie Berger We have designed and implemented a system for privacy-preserving and scalable sharing of drug-target interaction data (Aim 1, under review at Science), where we required GPUs to run our protocol, discover and experimentally validate novel drug-target interactions and will make our software publicly-available for academic and non-profit use (Aim 3). At the same time, we have presented a novel loss function for training classifiers from positive and unlabeled data and developed a software pipeline, Topaz, which uses convolutional neural networks trained with few positive examples for protein detection (Aim 2, RECOMB 2018). We are now developing new deep learning models for protein structure embedding and extending the Topaz framework to learn a general deep learning model of protein images from multiple cryo-EM micrograph datasets. Our continued progress on these projects is significantly jeopardized by our lack of GPU compute power. While in the last year we have purchased a compute node with four GPUs, we are continually frustrated by wait-times and inability to try different models and hyperparameters. Thus, we are requesting an additional node with eight GPUs to enable us to reach the broader goals of our grant. Narrative The interactions of small molecules with proteins are omnipresent throughout cellular processes and of fundamental importance to drug design and disease treatment, yet the task of predicting these interactions brings major challenges because of the heterogeneity and proprietary nature of the data. Here, we develop new mathematical methods and software that can address not only interpreting the data itself, but also the collaborative and generative process through which researchers work: new cryptographic tools can enable unprecedented forms of secure sharing and collaboration between industry and the public, and deep learning can accelerate the drug discovery process.",Structure-based prediction of the interactome,9703262,R01GM081871,"['Address', 'Biological Neural Networks', 'Cell physiology', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Detection', 'Disease', 'Drug Design', 'Drug Targeting', 'Goals', 'Grant', 'Heterogeneity', 'Image', 'Industry', 'Learning', 'Modeling', 'Nature', 'Privacy', 'Process', 'Proteins', 'Protocols documentation', 'Research Personnel', 'Running', 'Science', 'Secure', 'Structure', 'System', 'Time', 'Topaz', 'Training', 'United States National Institutes of Health', 'Wait Time', 'Work', 'base', 'cryptography', 'deep learning', 'design', 'drug discovery', 'loss of function', 'mathematical methods', 'new therapeutic target', 'novel', 'protein structure', 'small molecule', 'tool']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2018,83700,0.05448180568219428
"Content based mammogram retrieval as a diagnostic aid The objective of this project is to perform the initial development and evaluation of a computer aid to assist radiologists in their interpretation of mammograms. We will develop and evaluate an approach to computer-aided diagnosis (CAD(, in which the radiologist will be assisted by a content-based search engine that will display examples of lesions, with known pathology, that are similar to the lesion being evaluated. We will model the perceptual similarity between two lesion images as a non-linear function of those images, and use algorithms (support vector machines and artificial neural networks) to learn this function from similarity techniques that will allow the radiologist to refine the search by indicating preferences among the retrieved images, providing a capability similar to that present in text-search engines. We will focus only on the retrieval of images of microcalcification clusters (MCCs) to determine the feasibility of later developing a more-complete system capable of handling multiple lesion classes. The project will involve a thorough performance evaluation to determine the merits of continued development of the proposed approach to CAD. We will perform statistical analyses of inter-observer and intra-observer notions of image similarity, and use modern statistical resampling procedures to evaluate the generation error of our nonlinear similarity model. The specific aims of the proposed project are as follows: 1) Develop support-vector-machine and artificial-neural network methods for predicting radiologists' similarity assessments from image features extracted by computer; 2) Develop relevance-feedback techniques for refining searches based on user-assessed relevance of retrieved images; 3) Based on an MCC data set, obtain radiologists' similarity assessments, for training and testing the proposed image-retrieval system; and 4) Evaluate retrieval performance by using quantitative measures, such as precision-recall curves and generalization error, and studies of inter-observer and intra-observer variability; study diagnostic utility by measuring the fraction of retrieved images that share th same pathology as the query.  n/a",Content based mammogram retrieval as a diagnostic aid,6621877,R21CA089668,"['artificial intelligence', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human data', ' information retrieval', ' mammography']",NCI,ILLINOIS INSTITUTE OF TECHNOLOGY,R21,2003,147213,0.030615551488861113
"Content based mammogram retrieval as a diagnostic aid The objective of this project is to perform the initial development and evaluation of a computer aid to assist radiologists in their interpretation of mammograms. We will develop and evaluate an approach to computer-aided diagnosis (CAD(, in which the radiologist will be assisted by a content-based search engine that will display examples of lesions, with known pathology, that are similar to the lesion being evaluated. We will model the perceptual similarity between two lesion images as a non-linear function of those images, and use algorithms (support vector machines and artificial neural networks) to learn this function from similarity techniques that will allow the radiologist to refine the search by indicating preferences among the retrieved images, providing a capability similar to that present in text-search engines. We will focus only on the retrieval of images of microcalcification clusters (MCCs) to determine the feasibility of later developing a more-complete system capable of handling multiple lesion classes. The project will involve a thorough performance evaluation to determine the merits of continued development of the proposed approach to CAD. We will perform statistical analyses of inter-observer and intra-observer notions of image similarity, and use modern statistical resampling procedures to evaluate the generation error of our nonlinear similarity model. The specific aims of the proposed project are as follows: 1) Develop support-vector-machine and artificial-neural network methods for predicting radiologists' similarity assessments from image features extracted by computer; 2) Develop relevance-feedback techniques for refining searches based on user-assessed relevance of retrieved images; 3) Based on an MCC data set, obtain radiologists' similarity assessments, for training and testing the proposed image-retrieval system; and 4) Evaluate retrieval performance by using quantitative measures, such as precision-recall curves and generalization error, and studies of inter-observer and intra-observer variability; study diagnostic utility by measuring the fraction of retrieved images that share th same pathology as the query.  n/a",Content based mammogram retrieval as a diagnostic aid,6437170,R21CA089668,"['artificial intelligence', ' breast neoplasms', ' calcification', ' calcium disorder', ' computer assisted diagnosis', ' computer system design /evaluation', ' diagnosis design /evaluation', ' human data', ' information retrieval', ' mammography']",NCI,ILLINOIS INSTITUTE OF TECHNOLOGY,R21,2002,143782,0.030615551488861113
"New Computational Methods for Data-driven Protein Structure Prediction Proteins play fundamental roles in all biological processes. Accurate description of protein structure is an important step towards understanding of biological life and highly relevant in the development of therapeutics and drugs. Although experimental structure determination has been greatly improved, there is still a very large gap between the number of available protein sequences and that of solved protein structures, which can only be filled by computational prediction. The long-term goal of this project is to apply machine learning and optimization algorithms to understand protein sequence-structure-function relationship by analyzing sequence, structure and functional data and to develop data-driven computational methods and tools for structure and functional prediction. We believe that by developing sophisticated algorithms to extract knowledge from the increasing sequence and structure data, we can model protein sequence-structure relationship very accurately and improve structure and functional prediction greatly. This project has already produced a few CASP-winning, widely-used data- driven algorithms and web servers (http://raptorx.uchicago.edu) for protein structure modeling. This renewal will further develop machine learning (especially deep learning) algorithms for protein structure modeling without good templates. The specific aims are: (1) developing deep learning (DL) algorithms for the prediction of protein contact and distance matrix; (2) developing distance-based algorithms for fast and accurate ab initio folding of proteins without templates; (3) developing DL algorithms for template-based modeling with only weakly similar templates. This renewal will lead to further understanding and new models of protein sequence-structure relationship and yield publicly available resources for automated, accurate, quantitative analysis for a wide range of proteins. The impact will be multiplied by tens of thousands of worldwide users employing our web servers to study a wide variety of proteins relevant to basic biological research and human diseases, in both low- and high-throughput experiments. Proteins and their interactions play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. This proposal develops algorithms to understand protein sequence-structure relationship and to predict protein structures. The results will lead to a broad range of biomedical applications, such as better understanding of disease processes, development of novel diagnostics and drugs, and improved preventive therapies leading to reduced health care costs.",New Computational Methods for Data-driven Protein Structure Prediction,9817856,R01GM089753,"['Abbreviations', 'Address', 'Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Process', 'Cell Communication', 'Cells', 'Classification', 'Complex', 'Computing Methodologies', 'Coupling', 'Crystallography', 'Data', 'Development', 'Disease', 'Foundations', 'Genetic Transcription', 'Geometry', 'Goals', 'Health Care Costs', 'Homology Modeling', 'Hydrogen Bonding', 'Knowledge', 'Learning', 'Life', 'Machine Learning', 'Maintenance', 'Membrane Proteins', 'Metabolism', 'Methods', 'Modeling', 'Molecular Biology', 'Molecular Conformation', 'Occupations', 'Pharmaceutical Preparations', 'Play', 'Preventive therapy', 'Process', 'Protein Family', 'Proteins', 'Residual state', 'Resources', 'Role', 'Sequence Analysis', 'Sequence Homologs', 'Structural Models', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'System', 'Time', 'Torsion', 'Training', 'Translations', 'Variant', 'Vertebral column', 'Work', 'base', 'biological research', 'computerized tools', 'convolutional neural network', 'deep learning', 'deep learning algorithm', 'experimental study', 'human disease', 'improved', 'learning strategy', 'model building', 'neural network', 'novel diagnostics', 'novel therapeutics', 'prediction algorithm', 'predictive modeling', 'protein complex', 'protein folding', 'protein structure', 'protein structure function', 'protein structure prediction', 'simulation', 'structured data', 'therapeutic development', 'three-dimensional modeling', 'web server']",NIGMS,TOYOTA TECHNOLOGICAL INSTITUTE / CHICAGO,R01,2020,319222,0.04942732467550497
"New Computational Methods for Data-driven Protein Structure Prediction Proteins and their interactions play fundamental roles in all biological processes. Accurate description of protein structure and interactions is a fundamental step towards understanding biological life and highly relevant in the development of therapeutics and drugs. However, there is a large gap between the number of available protein sequences and the number of proteins (complexes) with solved structures and accurate interaction description, which has to be filled by computational prediction. The long-term goal of this project is to apply statistical machine learning and optimization algorithms to understand protein sequence-structure-function relationship by analyzing low- and high-throughput sequence, structure and functional data and to develop algorithms for structure and functional prediction. Our hypothesis is that by developing sophisticated algorithms to take advantage of the growing sequence and structure data, we can model sequence-structure relationship much more accurately and significantly improve structure and functional prediction, in particular for this proposal, residue (atomic) interaction strength prediction and remote homology detection. This project has produced a few CASP-winning, widely-used data-driven algorithms and web server (http://raptorx.uchicago.edu) for monomer protein modeling. This renewal will not only further develop machine learning algorithms (especially Deep Learning and probabilistic graphical models) for monomer proteins, but also branch out to protein interactions (complexes). The specific aims are: (1) develop novel structure learning algorithms to predict inter-reside contacts and coevolved residues; (2) develop context-specific, coevolution-based, and distance-dependent statistical potentials using a new machine learning model called Deep Conditional (Markov) Neural Fields (DeepCNF); (3) develop Markov Random Fields (MRF) and DeepCNF methods for remote protein (interface/complex) homology detection and fold recognition to make use of long-range residue interaction predicted by the first two aims. This renewal will lead to further understanding and new models of protein sequence-structure-function relationship and yield publicly available software and servers for automated, accurate, quantitative analysis for a wide range of proteins and their interactions. The impact will be multiplied by tens of thousands of worldwide users employing the resulting software/servers to study a wide variety of proteins and interactions relevant to basic biological research and human diseases, in both low- and high-throughput experiments. Proteins and their interactions play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. This proposal develops algorithms to understand protein sequence-structure-function relationship and to predict protein structures and interactions. The results will lead to a broad range of biomedical applications, such as better understanding of disease processes, development of novel diagnostics and drugs, and improved preventive therapies leading to reduced health care costs.",New Computational Methods for Data-driven Protein Structure Prediction,9545787,R01GM089753,"['Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Process', 'Cell Communication', 'Cells', 'Classification', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupling', 'Data', 'Detection', 'Development', 'Disease', 'Distant', 'Family', 'Genetic Transcription', 'Goals', 'Health Care Costs', 'Homologous Gene', 'Individual', 'Internet', 'Joints', 'Lasso', 'Learning', 'Life', 'Machine Learning', 'Maintenance', 'Metabolism', 'Methods', 'Modeling', 'Molecular Biology', 'Occupations', 'Pharmaceutical Preparations', 'Play', 'Preventive therapy', 'Probability', 'Process', 'Protein Family', 'Proteins', 'Role', 'Sequence Alignment', 'Sequence Homologs', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'Techniques', 'Translations', 'Work', 'atomic interactions', 'base', 'biological research', 'deep learning', 'experimental study', 'human disease', 'improved', 'learning strategy', 'monomer', 'novel', 'novel diagnostics', 'novel therapeutics', 'programs', 'protein complex', 'protein folding', 'protein structure', 'protein structure function', 'protein structure prediction', 'relating to nervous system', 'therapeutic development', 'tool']",NIGMS,TOYOTA TECHNOLOGICAL INSTITUTE / CHICAGO,R01,2018,306425,0.036828283112761005
"New Computational Methods for Data-driven Protein Structure Prediction Proteins and their interactions play fundamental roles in all biological processes. Accurate description of protein structure and interactions is a fundamental step towards understanding biological life and highly relevant in the development of therapeutics and drugs. However, there is a large gap between the number of available protein sequences and the number of proteins (complexes) with solved structures and accurate interaction description, which has to be filled by computational prediction. The long-term goal of this project is to apply statistical machine learning and optimization algorithms to understand protein sequence-structure-function relationship by analyzing low- and high-throughput sequence, structure and functional data and to develop algorithms for structure and functional prediction. Our hypothesis is that by developing sophisticated algorithms to take advantage of the growing sequence and structure data, we can model sequence-structure relationship much more accurately and significantly improve structure and functional prediction, in particular for this proposal, residue (atomic) interaction strength prediction and remote homology detection. This project has produced a few CASP-winning, widely-used data-driven algorithms and web server (http://raptorx.uchicago.edu) for monomer protein modeling. This renewal will not only further develop machine learning algorithms (especially Deep Learning and probabilistic graphical models) for monomer proteins, but also branch out to protein interactions (complexes). The specific aims are: (1) develop novel structure learning algorithms to predict inter-reside contacts and coevolved residues; (2) develop context-specific, coevolution-based, and distance-dependent statistical potentials using a new machine learning model called Deep Conditional (Markov) Neural Fields (DeepCNF); (3) develop Markov Random Fields (MRF) and DeepCNF methods for remote protein (interface/complex) homology detection and fold recognition to make use of long-range residue interaction predicted by the first two aims. This renewal will lead to further understanding and new models of protein sequence-structure-function relationship and yield publicly available software and servers for automated, accurate, quantitative analysis for a wide range of proteins and their interactions. The impact will be multiplied by tens of thousands of worldwide users employing the resulting software/servers to study a wide variety of proteins and interactions relevant to basic biological research and human diseases, in both low- and high-throughput experiments. Proteins and their interactions play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. This proposal develops algorithms to understand protein sequence-structure-function relationship and to predict protein structures and interactions. The results will lead to a broad range of biomedical applications, such as better understanding of disease processes, development of novel diagnostics and drugs, and improved preventive therapies leading to reduced health care costs.",New Computational Methods for Data-driven Protein Structure Prediction,9336937,R01GM089753,"['Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Process', 'Cell Communication', 'Cells', 'Classification', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupling', 'Data', 'Detection', 'Development', 'Disease', 'Distant', 'Family', 'Genetic Transcription', 'Goals', 'Health Care Costs', 'Homologous Gene', 'Individual', 'Internet', 'Joints', 'Lasso', 'Learning', 'Life', 'Machine Learning', 'Maintenance', 'Metabolism', 'Methods', 'Modeling', 'Molecular Biology', 'Occupations', 'Play', 'Preventive therapy', 'Probability', 'Process', 'Protein Family', 'Proteins', 'Role', 'Sequence Alignment', 'Sequence Homologs', 'Structure', 'Structure-Activity Relationship', 'Supervision', 'Techniques', 'Translations', 'Work', 'atomic interactions', 'base', 'biological research', 'drug development', 'experimental study', 'human disease', 'improved', 'learning strategy', 'monomer', 'novel', 'novel diagnostics', 'novel therapeutics', 'programs', 'protein complex', 'protein folding', 'protein function', 'protein structure', 'protein structure prediction', 'relating to nervous system', 'therapeutic development', 'tool']",NIGMS,TOYOTA TECHNOLOGICAL INSTITUTE / CHICAGO,R01,2017,306425,0.036828283112761005
"New Computational Methods for Data-driven Protein Structure Prediction Proteins and their interactions play fundamental roles in all biological processes. Accurate description of protein structure and interactions is a fundamental step towards understanding biological life and highly relevant in the development of therapeutics and drugs. However, there is a large gap between the number of available protein sequences and the number of proteins (complexes) with solved structures and accurate interaction description, which has to be filled by computational prediction. The long-term goal of this project is to apply statistical machine learning and optimization algorithms to understand protein sequence-structure-function relationship by analyzing low- and high-throughput sequence, structure and functional data and to develop algorithms for structure and functional prediction. Our hypothesis is that by developing sophisticated algorithms to take advantage of the growing sequence and structure data, we can model sequence-structure relationship much more accurately and significantly improve structure and functional prediction, in particular for this proposal, residue (atomic) interaction strength prediction and remote homology detection. This project has produced a few CASP-winning, widely-used data-driven algorithms and web server (http://raptorx.uchicago.edu) for monomer protein modeling. This renewal will not only further develop machine learning algorithms (especially Deep Learning and probabilistic graphical models) for monomer proteins, but also branch out to protein interactions (complexes). The specific aims are: (1) develop novel structure learning algorithms to predict inter-reside contacts and coevolved residues; (2) develop context-specific, coevolution-based, and distance-dependent statistical potentials using a new machine learning model called Deep Conditional (Markov) Neural Fields (DeepCNF); (3) develop Markov Random Fields (MRF) and DeepCNF methods for remote protein (interface/complex) homology detection and fold recognition to make use of long-range residue interaction predicted by the first two aims. This renewal will lead to further understanding and new models of protein sequence-structure-function relationship and yield publicly available software and servers for automated, accurate, quantitative analysis for a wide range of proteins and their interactions. The impact will be multiplied by tens of thousands of worldwide users employing the resulting software/servers to study a wide variety of proteins and interactions relevant to basic biological research and human diseases, in both low- and high-throughput experiments. Proteins and their interactions play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. This proposal develops algorithms to understand protein sequence-structure-function relationship and to predict protein structures and interactions. The results will lead to a broad range of biomedical applications, such as better understanding of disease processes, development of novel diagnostics and drugs, and improved preventive therapies leading to reduced health care costs.",New Computational Methods for Data-driven Protein Structure Prediction,9149287,R01GM089753,"['Accounting', 'Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Process', 'Cell Communication', 'Cells', 'Classification', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupling', 'Data', 'Detection', 'Development', 'Disease', 'Family', 'Genetic Transcription', 'Goals', 'Health Care Costs', 'High-Throughput Nucleotide Sequencing', 'Homologous Gene', 'Individual', 'Internet', 'Joints', 'Lasso', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Maintenance', 'Metabolism', 'Methods', 'Modeling', 'Molecular Biology', 'Occupations', 'Peptide Sequence Determination', 'Pharmaceutical Preparations', 'Play', 'Preventive therapy', 'Probability', 'Process', 'Protein Family', 'Proteins', 'Role', 'Sequence Alignment', 'Sequence Homologs', 'Structure', 'Structure-Activity Relationship', 'Techniques', 'Translations', 'Work', 'atomic interactions', 'base', 'biological research', 'deep field survey', 'human disease', 'improved', 'learning strategy', 'monomer', 'novel', 'novel diagnostics', 'novel therapeutics', 'programs', 'protein complex', 'protein folding', 'protein structure', 'protein structure function', 'protein structure prediction', 'relating to nervous system', 'research study', 'therapeutic development', 'tool']",NIGMS,TOYOTA TECHNOLOGICAL INSTITUTE / CHICAGO,R01,2016,306425,0.036828283112761005
"New Computational Methods for Data-driven Protein Structure Prediction Proteins and their interactions play fundamental roles in all biological processes. Accurate description of protein structure and interactions is a fundamental step towards understanding biological life and highly relevant in the development of therapeutics and drugs. However, there is a large gap between the number of available protein sequences and the number of proteins (complexes) with solved structures and accurate interaction description, which has to be filled by computational prediction. The long-term goal of this project is to apply statistical machine learning and optimization algorithms to understand protein sequence-structure-function relationship by analyzing low- and high-throughput sequence, structure and functional data and to develop algorithms for structure and functional prediction. Our hypothesis is that by developing sophisticated algorithms to take advantage of the growing sequence and structure data, we can model sequence-structure relationship much more accurately and significantly improve structure and functional prediction, in particular for this proposal, residue (atomic) interaction strength prediction and remote homology detection. This project has produced a few CASP-winning, widely-used data-driven algorithms and web server (http://raptorx.uchicago.edu) for monomer protein modeling. This renewal will not only further develop machine learning algorithms (especially Deep Learning and probabilistic graphical models) for monomer proteins, but also branch out to protein interactions (complexes). The specific aims are: (1) develop novel structure learning algorithms to predict inter-reside contacts and coevolved residues; (2) develop context-specific, coevolution-based, and distance-dependent statistical potentials using a new machine learning model called Deep Conditional (Markov) Neural Fields (DeepCNF); (3) develop Markov Random Fields (MRF) and DeepCNF methods for remote protein (interface/complex) homology detection and fold recognition to make use of long-range residue interaction predicted by the first two aims. This renewal will lead to further understanding and new models of protein sequence-structure-function relationship and yield publicly available software and servers for automated, accurate, quantitative analysis for a wide range of proteins and their interactions. The impact will be multiplied by tens of thousands of worldwide users employing the resulting software/servers to study a wide variety of proteins and interactions relevant to basic biological research and human diseases, in both low- and high-throughput experiments. Proteins and their interactions play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. This proposal develops algorithms to understand protein sequence-structure-function relationship and to predict protein structures and interactions. The results will lead to a broad range of biomedical applications, such as better understanding of disease processes, development of novel diagnostics and drugs, and improved preventive therapies leading to reduced health care costs.",New Computational Methods for Data-driven Protein Structure Prediction,9191141,R01GM089753,"['Accounting', 'Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Process', 'Cell Communication', 'Cells', 'Classification', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupling', 'Data', 'Detection', 'Development', 'Disease', 'Family', 'Genetic Transcription', 'Goals', 'Health Care Costs', 'High-Throughput Nucleotide Sequencing', 'Homologous Gene', 'Individual', 'Internet', 'Joints', 'Lasso', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Maintenance', 'Metabolism', 'Methods', 'Modeling', 'Molecular Biology', 'Occupations', 'Peptide Sequence Determination', 'Pharmaceutical Preparations', 'Play', 'Preventive therapy', 'Probability', 'Process', 'Protein Family', 'Proteins', 'Role', 'Sequence Alignment', 'Sequence Homologs', 'Structure', 'Structure-Activity Relationship', 'Techniques', 'Translations', 'Work', 'atomic interactions', 'base', 'biological research', 'deep field survey', 'human disease', 'improved', 'learning strategy', 'monomer', 'novel', 'novel diagnostics', 'novel therapeutics', 'programs', 'protein complex', 'protein folding', 'protein structure', 'protein structure function', 'protein structure prediction', 'relating to nervous system', 'research study', 'therapeutic development', 'tool']",NIGMS,TOYOTA TECHNOLOGICAL INSTITUTE / CHICAGO,R01,2016,29125,0.036828283112761005
"New Computational Methods for Data-driven Protein Structure Prediction Proteins and their interactions play fundamental roles in all biological processes. Accurate description of protein structure and interactions is a fundamental step towards understanding biological life and highly relevant in the development of therapeutics and drugs. However, there is a large gap between the number of available protein sequences and the number of proteins (complexes) with solved structures and accurate interaction description, which has to be filled by computational prediction. The long-term goal of this project is to apply statistical machine learning and optimization algorithms to understand protein sequence-structure-function relationship by analyzing low- and high-throughput sequence, structure and functional data and to develop algorithms for structure and functional prediction. Our hypothesis is that by developing sophisticated algorithms to take advantage of the growing sequence and structure data, we can model sequence-structure relationship much more accurately and significantly improve structure and functional prediction, in particular for this proposal, residue (atomic) interaction strength prediction and remote homology detection. This project has produced a few CASP-winning, widely-used data-driven algorithms and web server (http://raptorx.uchicago.edu) for monomer protein modeling. This renewal will not only further develop machine learning algorithms (especially Deep Learning and probabilistic graphical models) for monomer proteins, but also branch out to protein interactions (complexes). The specific aims are: (1) develop novel structure learning algorithms to predict inter-reside contacts and coevolved residues; (2) develop context-specific, coevolution-based, and distance-dependent statistical potentials using a new machine learning model called Deep Conditional (Markov) Neural Fields (DeepCNF); (3) develop Markov Random Fields (MRF) and DeepCNF methods for remote protein (interface/complex) homology detection and fold recognition to make use of long-range residue interaction predicted by the first two aims. This renewal will lead to further understanding and new models of protein sequence-structure-function relationship and yield publicly available software and servers for automated, accurate, quantitative analysis for a wide range of proteins and their interactions. The impact will be multiplied by tens of thousands of worldwide users employing the resulting software/servers to study a wide variety of proteins and interactions relevant to basic biological research and human diseases, in both low- and high-throughput experiments. Proteins and their interactions play fundamental roles in all biological processes including the maintenance of cellular integrity, metabolism, transcription/translation, and cell-cell communication. This proposal develops algorithms to understand protein sequence-structure-function relationship and to predict protein structures and interactions. The results will lead to a broad range of biomedical applications, such as better understanding of disease processes, development of novel diagnostics and drugs, and improved preventive therapies leading to reduced health care costs.",New Computational Methods for Data-driven Protein Structure Prediction,9030836,R01GM089753,"['Accounting', 'Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Process', 'Cell Communication', 'Cells', 'Classification', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupling', 'Data', 'Detection', 'Development', 'Disease', 'Family', 'Genetic Transcription', 'Goals', 'Health Care Costs', 'High-Throughput Nucleotide Sequencing', 'Homologous Gene', 'Individual', 'Internet', 'Joints', 'Lasso', 'Lead', 'Learning', 'Life', 'Machine Learning', 'Maintenance', 'Metabolism', 'Methods', 'Modeling', 'Molecular Biology', 'Occupations', 'Peptide Sequence Determination', 'Pharmaceutical Preparations', 'Play', 'Preventive', 'Probability', 'Process', 'Protein Family', 'Proteins', 'Role', 'Sequence Alignment', 'Sequence Homologs', 'Structure', 'Structure-Activity Relationship', 'Techniques', 'Translations', 'Work', 'atomic interactions', 'base', 'biological research', 'deep field survey', 'human disease', 'improved', 'monomer', 'novel', 'novel diagnostics', 'programs', 'protein complex', 'protein folding', 'protein structure', 'protein structure function', 'protein structure prediction', 'relating to nervous system', 'research study', 'therapeutic development', 'tool']",NIGMS,TOYOTA TECHNOLOGICAL INSTITUTE / CHICAGO,R01,2015,268175,0.036828283112761005
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8234040,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2012,424407,0.01599378116403917
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,8037095,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2011,417204,0.01599378116403917
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7769507,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'clinical decision-making', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2010,420313,0.01599378116403917
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7837005,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,229517,0.01599378116403917
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7585774,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'experience', 'flexibility', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'standard measure', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2009,411032,0.01599378116403917
"New Class of Numerical Observers for Nuclear Cardiology    DESCRIPTION (provided by applicant):  Single-photon emission computed tomography (SPECT) imaging has become a standard component of modern cardiology. In SPECT research (as in medical imaging generally), it has become widely accepted that advances in imaging hardware and algorithms should be guided by so-called task-based evaluation criteria, i.e., measures that reflect how the imaging technique will impact clinical decision making. In general, a human observer study is the gold standard for measuring task-based criteria; however, the expense and complexity of such studies precludes their routine use. Therefore, numerical observers-algorithms that emulate human observer performance-are now widely used as surrogates for human observers. In SPECT, one particular numerical observer, known as the channelized Hotelling observer (CHO), has come to dominate the field. The CHO is a detection algorithm that is used to approximate the human observer's performance in detecting lesions; in the case of cardiac SPECT, the lesions of interest are perfusion defects. An imaging system or algorithm can be judged by the ability of the CHO to accurately detect defects based on the images produced. SPECT researchers now rely heavily (and sometimes exclusively) on numerical observers such as the CHO, not only to validate their final results, but also as a figure of merit that guides optimization of hardware or algorithms. Because of the central role it has come to play, the CHO and its extensions have become a major research topic in their own right. In the proposed project, our goal will be to create a suite of numerical observers that will shed light on a much wider set of clinical tasks than the CHO, and we will pursue an approach that we hypothesize will be more accurate than the CHO. Therefore, the proposed research is significant because it will yield an evaluation methodology that could potentially be used very widely by the research community, underpinning the development of imaging hardware and software. We will develop a software package for image quality assessment using the proposed NO approach and distribute it freely to the research community. As a by-product of the research, the proposed project will also yield a thorough task-based evaluation of major image reconstruction algorithms, and will answer the question of which sorts of data (on the spectrum from simple phantoms to clinical data) are a sufficient foundation for numerical observers to perform as desired. The research will also yield the basis for a potential computer aided diagnostic system for cardiology. The specific aims of the research will be as follows: 1) Create a comprehensive set of imaging data and human observer scores; 2) Develop a suite of numerical observers based on our novel learning-based approach, as well as more-conventional statistical decision theory principles; 3) Compare and evaluate the numerical observers; and 4) Develop and disseminate by-products of the research program.          n/a",New Class of Numerical Observers for Nuclear Cardiology,7355521,R01HL091017,"['Agreement', 'Algorithms', 'Cardiac', 'Cardiology', 'Class', 'Clinical', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Data', 'Data Set', 'Decision Making', 'Decision Theory', 'Defect', 'Detection', 'Development', 'Diagnostic', 'Evaluation', 'Evaluation Methodology', 'Eye', 'Foundations', 'Future', 'Goals', 'Gold', 'Hand', 'Human', 'Hybrids', 'Illinois', 'Image', 'Image Analysis', 'Imaging Techniques', 'Institutes', 'Joints', 'Knowledge', 'Learning', 'Lesion', 'Light', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Motion', 'Myocardial perfusion', 'Myocardium', 'Nuclear', 'Outcome', 'Output', 'Performance', 'Perfusion', 'Play', 'Pliability', 'Process', 'Property', 'Publications', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Score', 'Severities', 'Simulate', 'Solutions', 'Sorting - Cell Movement', 'Standards of Weights and Measures', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Viability', 'Training', 'Universities', 'Ursidae Family', 'base', 'computer program', 'desire', 'experience', 'human data', 'image reconstruction', 'interest', 'medical schools', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'success', 'tool']",NHLBI,ILLINOIS INSTITUTE OF TECHNOLOGY,R01,2008,431744,0.01599378116403917
"Distance-based ab initio protein structure prediction Project Summary Predicting the three-dimensional structures of proteins without using known structures from the Protein Data Bank (PDB) as templates (ab initio) remains a grand challenge of computational biology. Whereas template-based modeling is now a mature field, ab initio modeling is a comparatively nascent one, especially for large proteins with complex topologies and multiple domains. The need for advances in ab initio modeling is evident. A lot of protein sequences do not have (recognizable) templates in the PDB, and the pace of experimental structure determination is incommensurate with the scale of the problem. Herein, we propose a new approach to ab initio modeling that consists of novel deep learning architectures to predict inter- residue distances and domain boundaries as well as robust, iterative optimization methods to construct tertiary structures from the predicted distances. This project builds on the success of our current R01, particularly the outstanding performance of the Cheng group in the 2018 worldwide protein structure prediction experiment – CASP13 – where our MULTICOM suite ranked among the top three tertiary structure predictors, alongside Google DeepMind’s AlphaFold. The methods will be implemented as open-source tools for the emerging field of distance-based ab initio protein structure modeling. We will apply the methods to study protein homo-oligomers and self-assemblies, based on our novel discovery that the quaternary structure contacts within homo-oligomers can be predicted by deep learning methods from the co-evolutionary signals embedded in multiple sequence alignments of protein monomers. Furthermore, we will apply the methods to predict the folds, functional sites, superfamilies, and protein-protein interactions of proteins that contain “essential Domains of Unknown Function” (eDUFs), a group of evolutionarily conserved, essential proteins that represents an important uncharted region of protein function/fold space. The predictions for a diverse and representative subset of eDUFs will be experimentally validated through a unique collaboration with the structural biology group of Dr. Tanner. Project Narrative Three-dimensional protein structure information is indispensable in modern biomedical research, but experimental techniques will only resolve a small fraction of known proteins due to the considerable cost. This project will develop cutting-edge computational methods based on modern artificial intelligence (AI) technology to reliably predict protein structures from sequence information alone. The prediction tools will be applied through collaborations with experimental scientists and disseminated to the community.",Distance-based ab initio protein structure prediction,10051137,R01GM093123,"['3-Dimensional', 'Amino Acid Sequence', 'Architecture', 'Area', 'Artificial Intelligence', 'Attention', 'Biomedical Research', 'C-terminal', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computing Methodologies', 'Conflict (Psychology)', 'Dependence', 'Development', 'Genome', 'Hereditary Disease', 'Homo', 'Maps', 'Methods', 'Modeling', 'Modernization', 'Mutate', 'Performance', 'Play', 'Problem Solving', 'Protein Engineering', 'Protein Region', 'Proteins', 'Recurrence', 'Renaissance', 'Residual state', 'Role', 'Scientist', 'Sequence Alignment', 'Signal Transduction', 'Site', 'Structural Models', 'Structural Protein', 'Structure', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Weight', 'X-Ray Crystallography', 'base', 'biophysical techniques', 'comparative', 'convolutional neural network', 'cost', 'data warehouse', 'deep learning', 'design', 'drug development', 'empowered', 'experience', 'experimental study', 'improved', 'learning network', 'learning strategy', 'long short term memory', 'monomer', 'novel', 'novel strategies', 'open source', 'protein function', 'protein protein interaction', 'protein structure', 'protein structure prediction', 'reconstruction', 'recurrent neural network', 'self assembly', 'structural biology', 'success', 'three dimensional structure', 'three-dimensional modeling', 'tool']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R01,2020,342270,0.051249920652627096
"Deep Learning for Connectomics Project Summary/Abstract The brain contains a vast number of neurons that are connected with each other through synapses, thereby forming a complex anatomical network that mediates information ﬂow within the brain. The brain “wiring diagram” will be a foundational tool for elucidating the function and dysfunction of brains. Electron microscopy (EM) is widely considered to be the gold standard for neuronal level circuit recon- struction. Currently, a major and serious bottleneck in this ﬁeld is image segmentation and reconstruc- tion. It is estimated that the data analysis accuracy and throughput are lagging behind data acquisition by orders of magnitude. This project aims at dramatically improving the accuracy and throughput of brain EM image analysis, thereby enabling accurate and efﬁcient reconstruction of neuronal level brain maps. Speciﬁcally, this project is built up on the recent success in deep learning methods, which are dominant tools for EM image analysis. A central and unresolved challenge of using deep learning for segmentation is how to achieve the conﬂicting goals of integrating sufﬁcient contextual features while preserving full-resolution information. This project will develop a novel residual encoder-decoder model to achieve these two goals simultaneously (Aim 1). In current deep learning segmentation methods, the labels of each pixel are predicted independently. To fully consider the brain topological structure and couple the predictions of spatially adjacent pixels, this project will develop a hybrid recurrent and convo- lutional network model (Aim 2). In this model, the recurrent network is integrated with the convolutional network to incorporate the multi-dimensional structural information. When combined with Aim 1, these methods are expected to dramatically improve the accuracy of EM image segmentation. In most cur- rent deep learning segmentation methods, the training and/or prediction stages require the extraction of patches centered on each pixel. This step forms a bottleneck that limits the overall throughput. This project will develop novel techniques to achieve whole-image training and prediction (Aim 3). These approaches will enable very efﬁcient training and segmentation, thereby dramatically increasing the throughput of EM image analysis. Project narrative Wiring diagrams of the brain circuits serve as a foundational tool for studying brain function and dys- function. This project aims at developing advanced computational methods for boosting the accuracy and throughput of brain circuit reconstruction from electron microscopy images. Comparative circuit analysis of normal and disease brains would shed light on how brain circuits go awry in psychiatric and neurological disorders.",Deep Learning for Connectomics,9475340,R21NS102828,"['Algorithms', 'Anatomy', 'Area', 'Axon', 'BRAIN initiative', 'Biological Neural Networks', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Complex', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Equilibrium', 'Foundations', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Interneurons', 'Label', 'Light', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Mus', 'Network-based', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Organism', 'Output', 'Phase', 'Recurrence', 'Reporting', 'Research Priority', 'Residual state', 'Resolution', 'Structure', 'Synapses', 'System', 'Techniques', 'Training', 'United States National Institutes of Health', 'Vision', 'base', 'brain dysfunction', 'comparative', 'data acquisition', 'deep learning', 'image reconstruction', 'imaging Segmentation', 'improved', 'learning strategy', 'microscopic imaging', 'nanometer', 'nervous system disorder', 'network models', 'novel', 'reconstruction', 'success', 'tool']",NINDS,WASHINGTON STATE UNIVERSITY,R21,2018,27175,0.023481249992176056
"Deep Learning for Connectomics Project Summary/Abstract The brain contains a vast number of neurons that are connected with each other through synapses, thereby forming a complex anatomical network that mediates information ﬂow within the brain. The brain “wiring diagram” will be a foundational tool for elucidating the function and dysfunction of brains. Electron microscopy (EM) is widely considered to be the gold standard for neuronal level circuit recon- struction. Currently, a major and serious bottleneck in this ﬁeld is image segmentation and reconstruc- tion. It is estimated that the data analysis accuracy and throughput are lagging behind data acquisition by orders of magnitude. This project aims at dramatically improving the accuracy and throughput of brain EM image analysis, thereby enabling accurate and efﬁcient reconstruction of neuronal level brain maps. Speciﬁcally, this project is built up on the recent success in deep learning methods, which are dominant tools for EM image analysis. A central and unresolved challenge of using deep learning for segmentation is how to achieve the conﬂicting goals of integrating sufﬁcient contextual features while preserving full-resolution information. This project will develop a novel residual encoder-decoder model to achieve these two goals simultaneously (Aim 1). In current deep learning segmentation methods, the labels of each pixel are predicted independently. To fully consider the brain topological structure and couple the predictions of spatially adjacent pixels, this project will develop a hybrid recurrent and convo- lutional network model (Aim 2). In this model, the recurrent network is integrated with the convolutional network to incorporate the multi-dimensional structural information. When combined with Aim 1, these methods are expected to dramatically improve the accuracy of EM image segmentation. In most cur- rent deep learning segmentation methods, the training and/or prediction stages require the extraction of patches centered on each pixel. This step forms a bottleneck that limits the overall throughput. This project will develop novel techniques to achieve whole-image training and prediction (Aim 3). These approaches will enable very efﬁcient training and segmentation, thereby dramatically increasing the throughput of EM image analysis. Project narrative Wiring diagrams of the brain circuits serve as a foundational tool for studying brain function and dys- function. This project aims at developing advanced computational methods for boosting the accuracy and throughput of brain circuit reconstruction from electron microscopy images. Comparative circuit analysis of normal and disease brains would shed light on how brain circuits go awry in psychiatric and neurological disorders.",Deep Learning for Connectomics,9371358,R21NS102828,"['Algorithms', 'Anatomy', 'Area', 'Axon', 'BRAIN initiative', 'Biological Neural Networks', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Complex', 'Computing Methodologies', 'Conflict (Psychology)', 'Data', 'Data Analyses', 'Data Set', 'Dendrites', 'Detection', 'Disease', 'Electron Microscopy', 'Equilibrium', 'Foundations', 'Functional disorder', 'Goals', 'Gold', 'Health', 'Human', 'Hybrids', 'Image', 'Image Analysis', 'Imaging technology', 'Interneurons', 'Label', 'Learning', 'Light', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Modeling', 'Mus', 'Network-based', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Organism', 'Output', 'Phase', 'Recurrence', 'Reporting', 'Research Priority', 'Residual state', 'Resolution', 'Structure', 'Synapses', 'System', 'Techniques', 'Training', 'United States National Institutes of Health', 'Vision', 'base', 'brain dysfunction', 'comparative', 'data acquisition', 'image reconstruction', 'imaging Segmentation', 'improved', 'learning strategy', 'microscopic imaging', 'nanometer', 'nervous system disorder', 'network models', 'novel', 'reconstruction', 'success', 'tool']",NINDS,WASHINGTON STATE UNIVERSITY,R21,2017,222279,0.023481249992176056
"Predicting contrast enhancement in multiple sclerosis with real time texture analysis Description: Identification of active lesions is critical for the management of multiple sclerosis (MS) patients. Currently this identification is based on post-contrast T1-weighted magnetic resonance imaging (MRI). However, there are safety concerns with repeated administration of gadolinium –based contrast agents (GBCAs). Thus, there is critical need for identifying active lesions without the use of GBCA. In this application we propose to identify the active lesions without administering GBCA using texture analysis (TA) using multi- modal non-contrast MRI and support vector machine (SVM) learning. A unique feature of this proposal is that the results will be analyzed using MRI data acquired on a large cohort of MS patients (~1000) as a part of phase III, randomized, double-blinded clinical trial (CombiRx). In addition texture features will be identified that can predict lesions that convert into tissue destructive lesions, so called black holes. This has important clinical implications since there is correlative evidence that balk holes are associated with clinical disability. A novelty of this project lies in performing texture analysis in real time that allows the physician to make the decision about administering GBCA on the spot while the patient is still in the scanner. This greatly helps in eliminating and/or minimizing the number of times GBCA needs to be administered. For real time analysis, the necessary infrastructure that includes automatic processing pipeline and integration of the MRI scanner with high performance computational resources located at Texas Advanced Computing Center (TACC) in Austin. Finally to establish real time TA as a viable alternative to GBCA administration for identifying active lesions, the developed methods will be prospectively applied to MS patients undergoing MRI scans as a part of routine clinical management. Public health relevance: Gadolinium based contrast agents (GBCAs) are routinely used for identifying active lesions in multiple sclerosis patients. However, there are safety concerns with repeated administration of GBCA. This proposal uses novel real time analysis for identifying lesions that are likely to enhance on pre- contrast MRI. Considering the large number of MS patients who are frequently scanned with GBCA, this proposal has a high degree of clinical relevance.",Predicting contrast enhancement in multiple sclerosis with real time texture analysis,9650821,R56NS105857,"['Advanced Development', 'Clinical', 'Clinical Management', 'Clinical Trials', 'Computer software', 'Contrast Media', 'Cross-Sectional Studies', 'Data', 'Decision Making', 'Double-Blind Method', 'Effectiveness', 'Enhancing Lesion', 'Evaluation', 'Gadolinium', 'Generations', 'Gold', 'Gray unit of radiation dose', 'Image', 'Image Analysis', 'Left', 'Lesion', 'Liquid substance', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modality', 'Multiple Sclerosis', 'Neuraxis', 'Pathology', 'Patients', 'Performance', 'Phase', 'Physicians', 'Prospective Studies', 'Protons', 'Randomized', 'Recovery', 'Research Infrastructure', 'Role', 'Safety', 'Sample Size', 'Sampling', 'Scanning', 'Spottings', 'Techniques', 'Technology', 'Texas', 'Texture', 'Time', 'Tissues', 'Treatment Efficacy', 'Validation', 'attenuation', 'austin', 'base', 'black hole', 'clinically relevant', 'cohort', 'computing resources', 'contrast enhanced', 'density', 'disability', 'high end computer', 'imaging facilities', 'multiple sclerosis patient', 'novel', 'parallel processing', 'prospective', 'public health relevance']",NINDS,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R56,2018,535749,0.07942617541254424
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9574149,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'disability', 'improved', 'improved outcome', 'intervention effect', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2018,579883,-0.04578360106813858
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9769180,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'improved', 'improved outcome', 'intervention effect', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2019,559137,-0.04578360106813858
"Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Project Summary/Abstract: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum Brain monitoring in critical care has grown dramatically over the past 20 years with the discovery that a large proportion of ICU patients suffer from subclinical seizures and seizure-like electrical events, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), detectable only by electroencephalography (EEG). This growth has created a crisis in critical care: It is clear that IIICAs damage the brain and cause permanent neurologic disability. Yet detection of IIICAs by expert visual review is often delayed suggesting we need better tools for real-time monitoring, to cope with the deluge of ICU EEG data. In other cases, IIICAs appear to be harmless epiphenomena, and many worry that increased awareness of IIICAs has created an epidemic of overly-aggressive prescribing of anticonvulsant drugs leading to preventable adverse events and costs. This crisis highlights critical unmet needs for automated EEG monitoring for IIICAs, and a better understanding of which types of IIICAs cause neural injury and warrant intervention. Causes of IIICAs range widely, from primary brain injuries like hemorrhagic stroke and intracranial hemorrhage, to systemic medical illnesses like sepsis and uremia. Until recently, this massive clinical heterogeneity has been an insurmountable barrier to understanding the impact of IIICAs on neurologic outcome. However, recent advances in deep learning, coupled with the unprecedented availability of a massive dataset developed by our team over the last three years, makes it feasible for the first time to systematically study the relationship between IIICAs and neurologic outcomes. To meet the need for better monitoring tools and better models for understanding IIICAs, we will take a deep learning approach to leverage the as-yet untapped information in a massive ICU EEG dataset. We will pursue three Specific Aims: SA1: Comprehensively label all occurrences of IIICAs in a massive set of cEEG recordings, thus preparing the EEG data for training computers to detect IIICA patterns; SA2: Develop supervised DL algorithms to detect IIICAs as accurately as human experts, thus providing powerful tools for both research on IIICAs and for clinical brain monitoring; SA3: Estimate the effect of IIICAs on neurologic outcome: we will develop models to quantify effects of IIICAs on risk for disability after controlling for inciting illness and other clinical factors, and to predict effects of interventions to suppress IIICAs. This work will provide four crucial benefits to advance the field of precision critical care neurology, and by extension, our ability to provide optimal neurologic care for patients during critical illness. 1) Improved understanding of the clinical significance of seizure like IIICA states; 2) development of robust tools and algorithms for critical care brain telemetry; 3) a unique, massive, publicly available, thoroughly annotated dataset that will enable other researchers to further advance the field; and 4) a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials. Project Narrative: Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum RELEVANCE: Seizures and seizure-like brain activity, collectively called “ictal-interictal-injury continuum abnormalities” (IIICAs), occur commonly in electroencephalogram recordings of brain activity in ICU patients, and simultaneously represent a preventable cause of brain injury and a common cause of over-treatment and iatrogenic harm to patients. Big Data and deep learning approaches have recently enabled advances in several fields of medicine, but have so far had little impact in ICU neuromedicine. This project will use Big Data and Deep Learning to advance the goal of protecting brain health in ICU patients, by 1) providing improved understanding of the clinical significance of IIICA states; 2) developing robust tools and algorithms for ICU brain telemetry; 3) creating a unique, massive, publicly available, annotated dataset to enable other researchers to further advance the field; and 4) developing a testable model that predicts which types of cEEG abnormalities warrant aggressive treatment, setting the stage for interventional trials.",Big Data and Deep Learning for the Interictal-Ictal-Injury Continuum,9942528,R01NS107291,"['Adverse event', 'Algorithms', 'Anesthetics', 'Anticonvulsants', 'Awareness', 'Big Data', 'Brain', 'Brain Injuries', 'Brain hemorrhage', 'Characteristics', 'Clinical', 'Collaborations', 'Communities', 'Computers', 'Coupled', 'Critical Care', 'Critical Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Early Intervention', 'Electroencephalogram', 'Electroencephalography', 'Epidemic', 'Event', 'Frequencies', 'Goals', 'Growth', 'Hour', 'Human', 'Iatrogenesis', 'Injury', 'Intervention', 'Intervention Trial', 'Intracranial Hemorrhages', 'Label', 'Medical', 'Medicine', 'Modeling', 'Monitor', 'Neurologic', 'Neurological outcome', 'Neurology', 'Nomenclature', 'Patient Care', 'Patients', 'Pattern', 'Periodicity', 'Phenotype', 'Physicians', 'Positioning Attribute', 'Research', 'Research Personnel', 'Risk', 'Seizures', 'Sepsis', 'Standardization', 'Subclinical Seizures', 'Supervision', 'Telemetry', 'Testing', 'Time', 'Training', 'Uremia', 'Visual', 'Work', 'aggressive therapy', 'brain health', 'causal model', 'clinical care', 'clinical heterogeneity', 'clinically actionable', 'clinically significant', 'computer science', 'cost', 'deep learning', 'deep learning algorithm', 'disability', 'improved', 'improved outcome', 'intervention effect', 'large datasets', 'learning strategy', 'nerve injury', 'neurophysiology', 'overtreatment', 'predictive modeling', 'preventable death', 'real time monitoring', 'tool']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,R01,2020,559900,-0.04578360106813858
"Prediction of seizure lateralization and postoperative outcome through the use of deep learning applied to multi-site MRI/DTI data:  An ENIGMA-Epilepsy study ABSTRACT  Epilepsy is a devastating neurological illness that affects 65 million people worldwide. Approximately one-third of patients affected do not respond to antiepileptic drug therapy and require a thorough diagnostic work-up. Structural neuroimaging plays a pivotal role in the diagnostic evaluation of patients with focal epilepsy, identifying visible lesions in many patients that often coincide with the seizure focus. However, 20- 40% of patients have normal-appearing MRIs and this number appears to be growing. As a result, there is increased interest in identifying subtle gray and white matter network changes on non-invasive, quantitative MRI, including structural MRI (sMRI) and diffusion tensor imaging (DTI), that can help to delineate the epileptogenic network. Unfortunately, methods for selecting optimal features from sMRI/DTI data in patients with epilepsy that can address these clinical challenges have not been developed. There are at least two major barriers that have limited progress in this field. First, sample sizes have been insufficient to develop reliable classification algorithms in patients with focal epilepsy that lead to reproducible findings. The high cost of data collection - few studies scan more than 50-60 patients - has led to underpowered studies whose findings often fail to replicate and cannot adequately model confounds. Second, high computational demands have previously limited the feasibility of using sophisticated, feature-selection (i.e., Machine Learning; ML) algorithms in clinical settings.  A new, large-scale data initiative (i.e., ENIGMA-epilepsy) acquired from 24 sites world-wide is now lifting these barriers and allowing for the development and validation of innovative data-driven approaches aimed at optimizing the use of MRI data in the evaluation of epilepsy. In this grant, we will leverage data collected through ENIGMA-Epilepsy—a new, cost-effective, innovative global approach that unblocks the power logjam by merging resources, data, capital infrastructure and talents of leading epilepsy centers from 14 countries across the world (2,149 patient and 1,727 healthy control MRI/DTI datasets). We will also leverage new developments in ML (i.e., deep learning) and network-based modeling (i.e., connectome- based approaches) and test whether these novel approaches improve upon classification accuracy relative to simpler, user-driven models. Our primary aim will be to test the ability of our deep learning approach (i.e., dense neural networks) to lateralize the seizure focus. In an exploratory aim, we will test the ability of our model to predict post-operative seizure outcomes. ENIGMA's harmonized approach will allow us to test our approach in over 24 datasets, diverse in age, ethnicity, age of onset, epilepsy duration, and surgical outcomes.  This R-21 application addresses NIH's call for more reproducible studies by introducing a highly- powered design, and is directly aligned with NINDS's 2014 Epilepsy Benchmarks, which encourage the identification of biomarkers for assessing or predicting treatment response in patients with epilepsy. NARRATIVE Epilepsy is a devastating neurological illness, affecting 65 million people worldwide. In this project, we will leverage the ENIGMA-Epilepsy infrastructure to address how advanced, non-invasive neuroimaging can be used to develop algorithms for (1) lateralizing the seizure focus and (2) predicting favorable versus unfavorable surgical outcomes. The research will be accomplished by applying novel machine learning algorithms to clinical and imaging data on an exceptionally large cohort of patients with epilepsy and healthy controls, providing unprecedented power to tackle critical diagnostic and treatment-related questions in epilepsy.",Prediction of seizure lateralization and postoperative outcome through the use of deep learning applied to multi-site MRI/DTI data:  An ENIGMA-Epilepsy study,9751025,R21NS107739,"['Address', 'Affect', 'Age', 'Age of Onset', 'Algorithms', 'Antiepileptic Agents', 'Benchmarking', 'Capital', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Complex', 'Country', 'Coupled', 'Data', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Diagnostic Procedure', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Epilepsy', 'Ethnic Origin', 'Evaluation', 'Geography', 'Gold', 'Grant', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Lead', 'Left', 'Lesion', 'Lifting', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Multimodal Imaging', 'National Institute of Neurological Disorders and Stroke', 'Network-based', 'Neurologic', 'Operative Surgical Procedures', 'Outcome', 'Partial Epilepsies', 'Patients', 'Pattern', 'Pharmacotherapy', 'Play', 'Population', 'Postoperative Period', 'Prediction of Response to Therapy', 'Probability', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Resources', 'Role', 'Sample Size', 'Sampling', 'Scanning', 'Seizures', 'Site', 'Structure', 'Syndrome', 'Talents', 'Techniques', 'Temporal Lobe Epilepsy', 'Testing', 'Thinness', 'United States National Institutes of Health', 'Validation', 'base', 'biomarker identification', 'brain abnormalities', 'classification algorithm', 'cohort', 'computing resources', 'connectome', 'cost', 'cost effective', 'deep learning', 'design', 'gray matter', 'hands-on learning', 'imaging study', 'improved', 'innovation', 'interest', 'machine learning algorithm', 'nervous system disorder', 'neural network', 'neuroimaging', 'novel', 'novel strategies', 'personalized approach', 'sex', 'standard of care', 'surgery outcome', 'white matter']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2019,444315,0.0531340330257253
"Deep learning enhanced seizure monitoring from wearable sensors Deep learning enhanced seizure monitoring from wearable sensors Over 1 million patients in the United States have uncontrolled epilepsy despite ongoing medical therapy. When seizures are prolonged or violent, there is significant risk of injury or even Sudden Unexpected Death of Epilepsy (SUDEP) which occurs in approximately 1 in 500 patients per year. Novel seizure monitoring could help alleviate this burden. Our research team has created a software application, EpiWatch, to capture different sensor measurements related to seizure activity such as convulsions (accelerometers), heart rate increases (photo- plethysmography-PPG), and unresponsiveness to behavioral prompting (interactive user interface). Our hope is to offer accurate seizure detection with improved false positive performance to encourage usage. Our team proposes to develop multi-modal sensor analysis driven by deep learning technology to enhance seizure monitoring. We are uniquely positioned to accelerate development by leveraging our team’s prior EpiWatch IRB approved study which generated over 6,000 hours of sensor data. In Phase I, we will teach EpiWatch how to read time series sensor data and how to discriminate seizure activity. EpiWatch will employ a convolutional neural network, a technique rooted in deep learning, to self-characterize seizure features from labeled sensor data. In order to infer additional information from vast amounts of unlabeled sensor data from US epilepsy patients, EpiWatch will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of EpiWatch will test its ability to identify the presence of seizures in a prospective new cohort of epilepsy patients. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact. Our goal is to combine recent advances in deep learning and scalable parallel computing to create EpiWatch. In the long term, we hope this monitoring technology will aid epilepsy patient management and improve outcomes. PROJECT NARRATIVE Recurring seizures are disabling, dangerous, and often limit independence. We are developing novel seizure detection using a consumer friendly device with wearable sensors (EpiWatch) to enable monitoring and emergency alerting for seizures that occur without warning (~50% of all seizures) and without witnesses, especially when they are prolonged (> 5 min) or accompanied by cardiac arrhythmias responsible for SUDEP (Sudden Unexpected Death with Epilepsy), a 1 in 500 annual risk for patients with uncontrolled seizures. If emergency care can be summoned under these circumstances, patients can live more safely and independently, in turn encouraging app usage. When integrated with current disease monitoring activities, EpiWatch will have the long range impact of providing a unique platform for individualized epilepsy care.",Deep learning enhanced seizure monitoring from wearable sensors,9622338,R43NS108905,"['Accelerometer', 'Apple', 'Arrhythmia', 'Behavioral', 'Biological Neural Networks', 'Biosensor', 'Caregivers', 'Caring', 'Cessation of life', 'Computer software', 'Consent', 'Convulsions', 'Dangerousness', 'Data', 'Detection', 'Development', 'Devices', 'Disease', 'Electroencephalography', 'Emergency Care', 'Emergency Situation', 'Epilepsy', 'Event', 'Goals', 'Gold', 'Heart Rate', 'Hospitals', 'Hour', 'Injury', 'Institutional Review Boards', 'Label', 'Learning', 'Measurement', 'Medical', 'Methods', 'Modality', 'Modeling', 'Monitor', 'Network-based', 'Neural Network Simulation', 'Neurologist', 'Outcome', 'Outpatients', 'Patient Monitoring', 'Patient Self-Report', 'Patient risk', 'Patients', 'Performance', 'Phase', 'Photoplethysmography', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Refractory', 'Research', 'Risk', 'Seizures', 'Series', 'Signal Transduction', 'Supervision', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Translating', 'United States', 'Violence', 'Work', 'clinical translation', 'cohort', 'computing resources', 'deep learning', 'improved', 'improved outcome', 'insight', 'novel', 'parallel computer', 'prospective', 'response', 'sensor', 'wearable device']",NINDS,"VIGILANT MEDICAL, INC.",R43,2018,238872,0.025541748742067254
"Diagnosis of indeterminate brain lesions using MRI-based machine learning and polygenic risk models PROJECT SUMMARY In 2017 an MRI was performed at a rate of over one for every 10 US residents. The majority of these were brain MRIs. Indeterminate mass lesions are present on over 1% of brain MRIs in individuals over 45 years old. Misinterpretation of brain MRI can lead to significant iatrogenic morbidity and mortality. For example, tumefactive Central Nervous System Inflammatory Demyelinating Disease (CNSIDD) is commonly misdiagnosed as a malignancy, even following pathological review. This results in inappropriate brain biopsies, debulking and radiation. While early tumor resection is associated with favorable outcome in patients with high- grade glioma, observation, biopsy at an alternate site or nonsurgical options are often more appropriate for other indeterminate mass lesions that can encompass low-grade primary brain tumor, CNSIDD, CNS lymphoma and brain metastasis. Thus, to prevent iatrogenic morbidity, there is a critical need for scalable and reproducible methods to distinguish CNSIDD from other brain lesions, and to accurately diagnose brain tumors prior to biopsy. We recently published a polygenic risk model demonstrating that the 25 known glioma germline risk variants can estimate absolute and lifetime glioma risk. The clinical significance of these models is driven by germline variants that are associated with >4-fold increased risk of glioma. We have also shown that the same 25 germline variants can predict glioma molecular subtype. As a complementary approach, we have shown that imaging characteristics differ across glioma, CNSIDD, CNS lymphoma and brain metastases. We have successfully utilized MRI-based machine learning to predict the molecular subtype in high-grade glioma. We hypothesize that both germline genotyping and MRI-based machine learning provide an opportunity to diagnose indeterminate mass lesions as well as predict glioma molecular subtype prior to surgery and thus personalized treatment. The project has the following three aims: Aim 1: Develop and validate a MRI-based machine learning model to differentiate adult diffuse glioma from tumefactive CNSIDD, CNS lymphoma and solitary brain metastases of unknown primary. Aim 2: Evaluate sensitivity and specificity of the polygenic glioma risk model to differentiate adult diffuse glioma from tumefactive CNSIDD, CNS lymphoma and solitary brain metastases. Aim 3: Integrate the polygenic glioma subtype model and MRI-based machine learning model to predict adult diffuse glioma molecular subtype and validate the integrated model using a prospective cohort. The proposed project will further enhance the care of patients by determining if an early MRI lesion is actually a glioma. Early definitive surgery in these patients could be curative. PROJECT NARRATIVE Indeterminate mass lesions are present on over 1% of brain MRIs in individuals over 45 years old, and misinterpretation of brain MRI can lead to significant iatrogenic morbidity and mortality. To prevent iatrogenic morbidity, there is a critical need for scalable and reproducible methods to distinguish indeterminate brain lesions from each other, and to accurately diagnose brain tumors prior to biopsy. We hypothesize that both germline genotyping and MRI-based machine learning provide an opportunity to diagnose indeterminate mass lesions as well as predict glioma molecular subtype prior to surgery and thus personalized treatment.",Diagnosis of indeterminate brain lesions using MRI-based machine learning and polygenic risk models,10050079,R01NS113803,"['Academic Medical Centers', 'Adult', 'Biological Assay', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Brain Pathology', 'Central Nervous System Lymphoma', 'Characteristics', 'Clinical', 'Data', 'Demyelinating Diseases', 'Development', 'Diagnosis', 'Diagnostic', 'Differential Diagnosis', 'Diffuse', 'Effectiveness', 'Excision', 'Genotype', 'Glioma', 'Iatrogenesis', 'Image', 'Individual', 'Inflammatory', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Measures', 'Metastatic malignant neoplasm to brain', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Multiple Sclerosis', 'Mutate', 'Neoplasm Metastasis', 'Neuraxis', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Patients', 'Predictive Value', 'Predisposition', 'Primary Brain Neoplasms', 'Prospective cohort', 'Prospective cohort study', 'Publishing', 'Radiation', 'Reproducibility', 'Research', 'Risk', 'Running', 'Sensitivity and Specificity', 'Site', 'Specificity', 'Training', 'Tumor Debulking', 'Variant', 'Work', 'accurate diagnosis', 'base', 'clinically significant', 'cohort', 'cost', 'diagnostic accuracy', 'improved', 'molecular subtypes', 'mortality', 'personalized medicine', 'prevent', 'prospective', 'risk variant', 'tool', 'tumor']",NINDS,MAYO CLINIC ROCHESTER,R01,2020,623080,-0.012567815503557008
"Comprehensive Multivariable Deep Learning Models to Identify Predictors of Cognitive Change in PD PROJECT SUMMARY Cognitive impairment and Parkinson’s disease dementia (PDD) are well-established disorders in Parkinson’s disease (PD) which are debilitating and contribute to increased mortality. The course, severity, and rate of progression of cognitive symptoms in PD is variable and unpredictable. Some patients develop PDD within the first several years of diagnosis, while others remain cognitively intact or have a milder form of impairment for many years after diagnosis. This heterogeneity in impairment profile and risk to PDD likely reflects the diverse underlying pathophysiological mechanisms associated with PD progression and cognitive dysfunction. The combination of diverse pathological features and clinical phenotypes makes it challenging to inform patients what to expect during the course of disease, and is a substantial barrier to developing new drugs for cognitive impairment in PD. Therefore, developing prognostic markers of risk of cognitive progression in PD is important. Our overall hypothesis is that different combinations of biomarkers will be more informative in predicting cognitive progression compared to a single biomarker alone. Thus, our objective is to investigate multivariable data to identify unique clinical-molecular-imaging biomarker signatures that identify individuals with PD who are most likely to experience substantial cognitive changes that ultimately lead to PDD. To achieve our objective, we will first develop deep learning models that identify multivariable features that are prognostic of incident mild cognitive impairment in people with early-stage PD (aim 1). Next, we will develop deep learning models that identify multivariable features that are prognostic of either (a) conversion from mild cognitive impairment to PDD (aim 2); or, (b) reversion from mild cognitive impairment to cognitively intact PD (aim 3). Finally, we will develop deep learning models that identify prognostic markers of rapid cognitive deterioration in PD leading to PDD (aim 4). For the development of the proposed models, this project will take advantage of a large repository of clinical data available at the Center for Health + Technology (CHeT) at the University of Rochester. The modeling will be carried out at the University of Rochester Data Science Consortium (RDSC) by an experienced team of data scientists that will use multimodal temporal convolution network models. A multidisciplinary team that includes neurologists, pharmacologists, and data scientists will support model execution and the interpretation of the modeling results. The expected outcomes of the efforts from this research are comprehensive multivariable prognostic markers of cognitive progression in PD across different stages of disease, from mild impairment to PDD that will add novel insight into disease process. NARRATIVE Deep learning will be used to construct models of cognitive progression in Parkinson’s disease (PD) from multiple data modalities. The models will assess and evaluate the potential impact of clinical, biosamples, genetics, and imaging variables on the progression to mild cognitive impairment and dementia, as well as on rates of cognitive progression. These models will identify markers and their combinations that are prognostic to distinct cognitive progression trajectories in PD.",Comprehensive Multivariable Deep Learning Models to Identify Predictors of Cognitive Change in PD,10052031,RF1NS115141,"['Address', 'Age', 'Biological', 'Biological Markers', 'Clinical', 'Clinical Trials', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Collaborations', 'Collection', 'Data', 'Data Analytics', 'Data Science', 'Data Scientist', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Etiology', 'Event', 'Evolution', 'Faculty', 'Genetic', 'Genetic Markers', 'Goals', 'Health Technology', 'Heterogeneity', 'Image', 'Impaired cognition', 'Impairment', 'Individual', 'Infrastructure', 'Investigation', 'Lead', 'Longitudinal Studies', 'Machine Learning', 'Medical Genetics', 'Methodology', 'Modality', 'Modeling', 'Motor', 'Natural History', 'Nature', 'Neurobehavioral Manifestations', 'Neurodegenerative Disorders', 'Neurologist', 'Observational Study', 'Outcome', 'Parkinson Disease', 'Parkinson&apos', 's Dementia', 'Parkinsonian Disorders', 'Participant', 'Pathologic', 'Patients', 'Process', 'Prognostic Marker', 'Publishing', 'Quality of life', 'Research', 'Research Priority', 'Research Project Grants', 'Risk', 'Risk Factors', 'Risk Marker', 'Series', 'Severities', 'Source', 'Talents', 'Time', 'Treatment Efficacy', 'Universities', 'advanced analytics', 'care costs', 'clinical data warehouse', 'clinical phenotype', 'cognitive change', 'cognitive disability', 'cognitive impairment in Parkinson&apos', 's', 'convolutional neural network', 'data warehouse', 'deep field survey', 'deep learning', 'experience', 'follow-up', 'imaging biomarker', 'insight', 'learning strategy', 'male', 'mild cognitive impairment', 'molecular imaging', 'mortality', 'motor disorder', 'multidisciplinary', 'multimodality', 'network models', 'neurogenetics', 'neuroimaging', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'prognostic signature', 'progression marker', 'sex']",NINDS,UNIVERSITY OF ROCHESTER,RF1,2020,1155000,0.0264005640927325
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,9928452,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diet', 'Duodenum', 'Environmental Risk Factor', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Mucous Membrane', 'Multiomic Data', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Small Intestines', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'epithelium regeneration', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'tissue injury', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2020,192552,0.05434001652755184
"Computational Characterization of Environmental Enteropathy PROJECT SUMMARY/ABSTRACT Undernutrition afflicts 20% of children < 5 years of age in low- and middle-income countries (LMICs) and is a major risk factor for mortality. Linear growth failure (or stunting) in children is tightly linked to irreversible physical and cognitive deficits, with profound implications for development. A common cause of stunting in LMICs is Environmental Enteropathy (EE) which has also been linked to decreased oral vaccine immunogenicity. To date, there are no universally accepted, clear diagnostic algorithms or non-invasive biomarkers for EE making this a critical priority. In this K23 Mentored Career Development Award application, Dr. Sana Syed, a Pediatric Gastroenterologist with advanced training in Nutrition at the University of Virginia, proposes to 1) Develop and validate a Deep Learning Net to identify morphological features of EE versus celiac and healthy small intestinal tissue, 2) correlate the Deep Learning Net identified distinguishing EE intestinal tissue findings with clinical phenotype, measures of gut barrier and absorption, and bile acid deconjugation, and 3) Use a Deep Learning Net computational approach to identify distinguishing multiomic patterns of EE versus celiac disease. This work will be carried out in the context of an ongoing birth cohort study of environmental enteropathy in Pakistan (SEEM). Dr. Syed proposes a career development plan which includes mentorship, fieldwork, coursework, publications, and clinical time that will situate her as an independent physician-scientist with expertise in translational research employing computational `omics and image approaches to elucidate biologic mechanisms of stunting pathways and in identification of novel and effective therapies for EE. PROJECT NARRATIVE This career development award will: a) Lead to the development and validation of a pediatric-specific Environmental Enteropathy (EE) Deep Learning Net for small intestinal structure which is urgently needed to standardize the diagnosis, care, and research of EE worldwide; b) Employ computational methods to correlate Deep Learning Net identified distinguishing morphological EE features with multiomic data to provide comprehensive diagnostic and predictive criteria for EE, and c) Validation of promising circulating biomarkers against intestinal biopsies, the diagnostic gold standard for enteropathies. Successful completion of this work will channel our improved understanding of the gut's critical role in childhood stunting pathways towards effective interventions to improve nutrition and health in at risk populations.",Computational Characterization of Environmental Enteropathy,9666310,K23DK117061,"['5 year old', 'Address', 'Age', 'Algorithms', 'Antigens', 'Asia', 'Bangladeshi', 'Bile Acids', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Birth', 'Caring', 'Celiac Disease', 'Cessation of life', 'Child', 'Childhood', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Clinical Research', 'Cognitive deficits', 'Cohort Studies', 'Collaborations', 'Computing Methodologies', 'Data Science', 'Detection', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic', 'Diet', 'Duodenum', 'Environmental Risk Factor', 'Epithelial', 'Etiology', 'Exhibits', 'Exposure to', 'Failure', 'Foundations', 'Funding', 'Gastroenterologist', 'Genetic Risk', 'Genetic Transcription', 'Gluten', 'Goals', 'Gold', 'Growth', 'Health', 'Histologic', 'Histology', 'Histopathology', 'Human Pathology', 'Image', 'Immune response', 'Impairment', 'Inflammation', 'Injury', 'Intestinal permeability', 'Intestines', 'K-Series Research Career Programs', 'Knowledge', 'Lactulose', 'Lamina Propria', 'Lead', 'Length', 'Link', 'Lymphocytosis', 'MS4A1 gene', 'Malnutrition', 'Measurement', 'Measures', 'Mediating', 'Mentors', 'Mentorship', 'Metabolic', 'Milieu Therapy', 'Morphology', 'Mucositis', 'Mucous Membrane', 'Multiomic Data', 'Natural regeneration', 'Neurocognitive', 'Pakistan', 'Pathogenesis', 'Pathologic', 'Pathway interactions', 'Pattern', 'Physicians', 'Population', 'Populations at Risk', 'Prevalence', 'Publications', 'Research', 'Resources', 'Rhamnose', 'Risk Factors', 'Role', 'Scientist', 'Severities', 'Standardization', 'Structure', 'System', 'Time', 'Tissues', 'Training', 'Translational Research', 'Universities', 'Vaccines', 'Validation', 'Villous', 'Virginia', 'Visual', 'Work', 'absorption', 'base', 'career', 'career development', 'circulating biomarkers', 'clinical phenotype', 'cohort', 'deep learning', 'disorder control', 'effective intervention', 'effective therapy', 'enteric pathogen', 'imaging approach', 'immunogenicity', 'improved', 'intraepithelial', 'low and middle-income countries', 'microbiome', 'mortality', 'multiple omics', 'novel', 'novel marker', 'novel therapeutics', 'nutrient absorption', 'nutrition', 'oral vaccine', 'patient oriented', 'socioeconomics', 'transcriptome', 'urinary']",NIDDK,UNIVERSITY OF VIRGINIA,K23,2019,194052,0.05434001652755184
"Assessing the Effects of Deep Brain Stimulation on Agency Project Summary Recent advances in neurotechnologies have provided us with the ability to modulate brain function by direct and indirect interventions. Deep Brain Stimulation (DBS) is one such intervention that has already been FDA-approved for certain disorders, and its use has already raised ethical questions about ways in which direct brain stimulation may affect personal identity, autonomy, authenticity and, more generally, agency. Thus far the neuroethical worries have been largely based on anecdotal clinical reports. Further neurotechnological interventions developed as part of the BRAIN initiative are bound to raise similar questions, but we lack a clear framework in which to think of the ethical consequences of these interventions. The overall goal of this project is to articulate such a framework, to enable us to better evaluate and respond to the neuroethical challenges raised by our abilities to alter brain function. The more concrete objectives of our proposal are to 1) develop comprehensive assessment tools to measure changes in agency due to direct brain interventions, 2) to use this tool to assess changes in agency due to brain interventions using DBS patient populations as a test case; and 3) to develop a database to house the data we acquire with these tools to allow us to catalogue the effects and side effects of DBS. This will also make it possible to correlate the effects of DBS with electrode placement and white matter tractography, enabling better prediction of outcomes and aid in understanding of the mechanisms by which DBS works. We will analyze this data machine with machine learning methods to inform a more comprehensive neuroethical analysis of how brain interventions affect agency. Our approach is innovative in that it applies neurophilosophical insights about agency and employs deep learning algorithms in constructing and evaluating these assessment instruments. This contribution is significant in that it will provide a broad based assessment tool and database that will be a resource for researchers and clinicians using DBS, which could be used to improve therapeutic approaches and informed consent. The data will also inform a framework for further neuroethical thought about brain interventions, allowing us to better identify, articulate and measure changes on “dimensions of agency.” Finally, the approach is generalizable, and thus could be adapted for use with other brain intervention techniques, such as brain-computer interfaces (BCIs) or pharmacological treatments.   Project Narrative: We aim to develop a computerized assessment tool (the Agency Assessment Tool, AAT) to be used by clinicians prior to and after brain interventions to measure changes in agency along multiple dimensions. We will also develop an anonymous database coupled to the AAT that will constitute a central repository for data documenting the effects of DBS. Machine learning methods will be used to build predictive models from the AAT data in order to provide neuroethically relevant predictive and diagnostic information about the effects of brain interventions on agency. ",Assessing the Effects of Deep Brain Stimulation on Agency,9609947,RF1MH117813,"['Address', 'Adverse effects', 'Affect', 'Algorithms', 'Assessment tool', 'BRAIN initiative', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Bioethics', 'Brain', 'Case Study', 'Catalogs', 'Characteristics', 'Clinical', 'Competence', 'Coupled', 'Data', 'Databases', 'Deep Brain Stimulation', 'Diagnostic', 'Dimensions', 'Disease', 'Electrodes', 'Elements', 'Ethicists', 'Ethics', 'FDA approved', 'Feeling', 'Goals', 'Human', 'Individual', 'Individuality', 'Informed Consent', 'Intervention', 'Life', 'Machine Learning', 'Measures', 'Methods', 'Neuropsychology', 'Neurosciences', 'Obsessive-Compulsive Disorder', 'Operative Surgical Procedures', 'Outcome', 'Parkinson Disease', 'Patients', 'Personhood', 'Pharmacological Treatment', 'Pharmacology', 'Population', 'Questionnaires', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Site', 'Structure', 'Techniques', 'Testing', 'Therapeutic', 'Thinking', 'Treatment outcome', 'Variant', 'Work', 'base', 'brain computer interface', 'clinical decision-making', 'clinically relevant', 'computerized', 'data warehouse', 'deep learning', 'experience', 'improved', 'innovation', 'insight', 'learning strategy', 'lens', 'neurobehavioral', 'neuroethics', 'neuroregulation', 'neurosurgery', 'neurotechnology', 'novel therapeutic intervention', 'outcome prediction', 'patient population', 'predictive modeling', 'preimplantation', 'tool', 'tractography', 'treatment-resistant depression', 'white matter']",NIMH,DARTMOUTH COLLEGE,RF1,2018,239475,-0.010381537640999854
"Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders The purpose of this training and research application is to study the functional impact of mobile element insertions (MEIs) in neurological disorders (NDs) using new developments in deep learning techniques. MEIs are transposable DNA fragments that are able to insert throughout the human genome. There are at least 124 independent MEIs associated with human diseases. Approximately 20% of these diseases represent a spectrum of NDs, yet the overall contribute of MEIs to the etiology of NDs has not been systematically estimated. To address this, we will (1) characterize functional MEIs in GTEx cohorts in healthy individuals; (2) build a comprehensive functional map of MEIs to determine tissue-specific and brain-specific impact; and (3) impute transcriptional changes on various NDs where whole-genome sequencing (WGS) data will be generated. The proposed application will also develop an extensive research program for Dr. Dadi Gao, a computational biologist and statistical geneticist who has trained in functional genomic studies of alternative splicing in neurodegenerative disorders and therapeutic targeting of a splicing defect that causes a severe neurodevelopmental disorder. He has developed novel methods to investigate regulation of the transcriptome and to facilitate analyses in drug development. He now seeks to expand his expertise by applying statistical and deep learning models on large cohorts of sequencing data from controls and cases with NDs from post-mortem tissues, then impute functional consequences of MEIs from WGS in large-scale disease cohorts. The training plan consists of two years of mentored research to learn new skills in genome analysis, MEI characterization, and advanced deep learning techniques, followed by three years of shaping an independent laboratory. The research plan is developed to comprehensively explore functional variation in the genome by decomposing transcriptomic changes against MEIs. Dr. Michael Talkowski at Massachusetts General Hospital, Harvard, and the Broad Institute will serve as the primary mentor, while Dr. Manolis Kellis at MIT and the MIT Computational Biology Group, and the Broad Institute will serve as a co-mentor and close collaborator. These mentors are recognized experts in genomic structural variants, functional genomics, the genetics of neurological disorders, and computational modeling to establish functional elements in the human genome. In addition, a team of independent investigators from basic and translational research will provide Dr. Gao with comprehensive feedback to keep both his science and career development on track. The highly collaborative environment in CGM, MGH, Harvard Medical School, the Broad Institute and the University of Michigan Medical School will prepare Dr. Gao for his transition to an independent investigator. This outstanding mentorship team and training program will facilitate the career development of Dr. Gao as he seeks to redefine the functional maps of MEIs in the human genome and to impute their impact in large-scale neurological disorders. Mobile element insertions (MEIs) represent a largely undefined component of the genetic architecture of neurological disorders, as a number of MEIs have been associated with alternative splicing in these disorders but large-scale genome-wide functional characterization has not been systematically performed across tissues. This program study will functionally characterize the impact of MEIs on alternative splicing from whole-genome sequencing and transcriptome sequencing in large cohorts using new developments in deep learning models. These results will enhance our understanding of the etiological role and pathogenic mechanisms associated with MEIs in neuronal development and human neurological disorders.",Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders,10041366,K99NS118109,"['Address', 'Algorithms', 'Alternative Splicing', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Basic Science', 'Biology', 'Blood', 'Brain', 'Brain Diseases', 'CRISPR/Cas technology', 'Cells', 'Chromosome Pairing', 'Cohort Studies', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Insertion Elements', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Disease', 'Disease model', 'Dorsal', 'Dystonia', 'Elements', 'Etiology', 'Event', 'Evolution', 'Excision Repair', 'Familial Dysautonomia', 'Feedback', 'Fellowship', 'Filipino', 'General Hospitals', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Haplotypes', 'Human', 'Human Genome', 'Individual', 'Institutes', 'International', 'Introns', 'Laboratories', 'Lateral', 'Lead', 'Learning', 'Linear Regressions', 'Link', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Mind', 'Minisatellite Repeats', 'Modeling', 'Molecular', 'Mosaicism', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuromuscular Diseases', 'Neurons', 'Outcome', 'Parkinsonian Disorders', 'Pathogenicity', 'Pattern', 'Peripheral', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Prefrontal Cortex', 'Process', 'Property', 'RNA Splicing', 'Regulation', 'Research', 'Research Personnel', 'Retroelements', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Shapes', 'Short Interspersed Nucleotide Elements', 'Source', 'Specificity', 'Structure', 'TAF1 gene', 'Techniques', 'Therapeutic Trials', 'Tissue-Specific Splicing', 'Tissues', 'Training', 'Training Programs', 'Transcription Alteration', 'Translational Research', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'brain tissue', 'career development', 'cohort', 'collaborative environment', 'convolutional neural network', 'deep learning', 'drug development', 'functional genomics', 'functional outcomes', 'gene function', 'genetic architecture', 'genome analysis', 'genome editing', 'genome sequencing', 'genome-wide', 'human disease', 'in silico', 'insight', 'medical schools', 'mind control', 'nervous system disorder', 'neuron development', 'novel', 'programs', 'response', 'skills', 'statistical learning', 'structural genomics', 'therapeutic target', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,K99,2020,126866,0.030275056798904302
"AI2AMP-PD: Accelerating Parkinsons Diagnosis using Multi-omics and Artificial Intelligence AI2AMP-PD: Accelerating Parkinson’s Diagnosis using Multi-omics and Artificial Intelligence PROJECT SUMMARY AND ABSTRACT Parkinson’s disease (PD) affects more than 7 million people worldwide, and biomarkers to bolster the therapeutic pipeline are urgently needed. Developing biomarkers for clinical use is a difficult process that requires evaluation of multiple, large cohorts, each adding confidence to the marker. The Accelerating Medicine Partnership in Parkinson’s disease (AMP PD) consortium provides an unparalleled opportunity to rapidly achieve this previously elusive goal.  We hypothesize that a powerful, multi-omics classifier powered by standard and advanced machine learning algorithms will accurately identify PD-associated biomarkers at genome scale. Transcripts and genomic classifiers associated with PD will be identified in early-stage, untreated, patients with Dopamine Transporter- neuroimaging-supported diagnosis represented in the PPMI cohort. Transcripts and genomic classifiers will be rigorously replicated in the independent PDBP and BioFIND cohorts. Multi-omics classifiers using both PD- associated transcriptome changes and PD-associated genomic variants will be built with state-of-the-art deep learning techniques (e.g. variational autoencoder).  This analysis will powerfully delineate --- for the first time --- the full spectrum of known and novel, coding and noncoding RNAs linked to PD and detectable in circulating blood cells in a harmonized, large-scale data set. It will develop and test highly innovative multi-omics classifiers and provide a generally useful computational framework for large-scale, unbiased PD biomarker discovery. Project Narrative These large-scale studies are relevant to public health for two reasons. First, they will reveal the biomarker genes whose dysregulation of expression level is associated with (and possibly causal of) early development of Parkinson’s disease. Secondly, the multi-omics, DNA-RNA predictive model built here based on large dataset and advanced deep learning methods will provide a computational framework for further biomarker development and early disease prediction.",AI2AMP-PD: Accelerating Parkinsons Diagnosis using Multi-omics and Artificial Intelligence,10157680,U01NS120637,"['Affect', 'Artificial Intelligence', 'Biological Markers', 'Blood Cells', 'Blood specimen', 'Brain', 'Brain Diseases', 'Clinical', 'Clinical Trials', 'Code', 'Cognitive', 'Cross-Sectional Studies', 'DNA', 'Data Analytics', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Enhancers', 'Evaluation', 'Future', 'Gene Expression', 'Genes', 'Genetic Risk', 'Genetic Transcription', 'Goals', 'Link', 'Logistic Regressions', 'Machine Learning', 'Medicine', 'Modeling', 'Motor', 'Nature', 'Neurosciences', 'Parkinson Disease', 'Patients', 'Population', 'Process', 'Public Health', 'RNA', 'Sampling', 'Severities', 'Techniques', 'Testing', 'Therapeutic', 'Time', 'Transcript', 'Untranslated RNA', 'Variant', 'analytical method', 'autoencoder', 'base', 'biomarker development', 'biomarker discovery', 'cohort', 'computer framework', 'deep learning', 'differential expression', 'disease diagnosis', 'dopamine transporter', 'feature selection', 'genetic variant', 'genome-wide', 'genomic signature', 'innovation', 'large datasets', 'large scale data', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'multiple omics', 'neuroimaging', 'novel', 'predictive modeling', 'risk variant', 'screening', 'transcriptome']",NINDS,BRIGHAM AND WOMEN'S HOSPITAL,U01,2020,537000,0.028751957471772182
"Lupus Nephritis Neural Network, LuNN Up to 60% of adults and 80% of children with systemic lupus erythematosus (SLE) develop nephritis (LN), with 10–30% progressing to end-stage renal disease (ESRD). The gold standard for diagnosis of LN is a renal biopsy. Histological parameters remain the best predictors of ESRD. Despite being the gold standard, histological diagnosis of LN has several shortcomings. In multiple inter-observer renal pathology assessment studies reported thus far, the inter- pathologist correlation coefficients, or concordance, in assessing most histological parameters have been sub-optimal. This has provided the impetus for the current proposal. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of LN using current diagnostic criteria. We propose to train a deep convolutional neural network to distinguish the different LN classes, and to identify a full spectrum of histological attributes useful for diagnosis. We will compare the performance of the newly generated neural network in scoring glomerular/tubulo-interstitial features and LN classes, against a panel of human renal pathologists. Finally, we propose to build a neural network that can predict clinical outcome based on baseline renal pathology. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival. Despite being the gold standard, histological diagnosis of lupus nephritis is imprecise, and marked by significant inter-pathologist discordance in readings. We propose to leverage the power of computer vision and deep learning to build a classifier that rivals the best-trained renal pathologists in making a histological diagnosis of lupus nephritis. Reliable and reproducible classification of LN could dramatically improve patient management and long-term renal and patient survival.","Lupus Nephritis Neural Network, LuNN",10246669,R56DK122036,"['Adult', 'Algorithms', 'Automobile Driving', 'Cellular Structures', 'Child', 'Chronic', 'Classification', 'Computer Vision Systems', 'Diagnosis', 'Diagnostic', 'End stage renal failure', 'Feedback', 'Gold', 'Histologic', 'Human', 'Image', 'Kidney', 'Lupus', 'Lupus Nephritis', 'Machine Learning', 'Mus', 'Nephritis', 'Outcome', 'Outcome Study', 'Pathologist', 'Pathology', 'Patients', 'Performance', 'Phenotype', 'Prediction of Response to Therapy', 'Reading', 'Reporting', 'Reproducibility', 'Retrieval', 'Supervision', 'Systemic Lupus Erythematosus', 'Testing', 'Tissues', 'Training', 'Uncertainty', 'accurate diagnosis', 'base', 'convolutional neural network', 'deep learning', 'diagnosis standard', 'falls', 'improved', 'indexing', 'innovation', 'kidney biopsy', 'neural network', 'novel', 'predict clinical outcome', 'time interval', 'tool', 'treatment response', 'user-friendly', 'web portal']",NIDDK,UNIVERSITY OF HOUSTON,R56,2020,100750,0.019776123439574498
"Paneth cell phenotype as a predictive biomarker for ulcerative colitis ABSTRACT One of the challenges for the management of ulcerative colitis (UC; a subtype of inflammatory bowel disease) is the lacking of a predictive biomarker that can help stratify patients for personalized treatment strategies. We have previously shown that in Crohn’s disease (CD; another subtype of inflammatory bowel disease), the morphologic phenotype of small intestinal Paneth cells readily predicts outcome in post-surgical CD patients. Given the shared genetic etiology and clinical features between CD and UC, we hypothesize that Paneth cell phenotype will also predict outcome in UC. Our long-term goal is to define the clinical indications of inflammatory bowel disease of which Paneth cell phenotype can predict outcome. The objective of this grant is to determine to the extent of which Paneth cell phenotype predicts development of ileal complications in UC. The central hypothesis is that in UC patients undergoing total colectomy and ileal pouch anal anastomosis (IPAA), the Paneth cell phenotype obtained at time of colectomy will predict development of pouchitis and de novo CD in the ileal pouch. Our rationale is that Paneth cell phenotype will offer better outcome prediction over current practice. Our specific aims will test the following hypotheses: (Aim1) Paneth cell phenotype correlates with ileal complications in UC patients with IPAA; (Aim 2) Deep learning will reduce observer variation and enhance rigor and reproducibility of Paneth cell phenotype analysis in surgical pathology specimens, and also identify novel clinical factors that correlate with Paneth cell function; (Aim 3) Serum markers that correlate with Paneth cell phenotype could be used to predict outcome in UC. Upon conclusion, we will understand the role for Paneth cell function in modulating disease course in IBD. This contribution is significant since it will establish Paneth cell phenotype as a critical predictive biomarker for IBD. The proposed research is innovative because we use state-of-the-art deep learning approach to build an imaging analysis pipeline, and to identify novel clinical factors that affect Paneth cell functions. Identifying how epithelial cells with innate immune function affect disease course will provide insight into other inflammatory disorders. PROJECT NARRATIVE The proposed research is relevant to the public health because ulcerative colitis, which is increasing in prevalence worldwide, represents a major national cost measured by both patient suffering and economic burden. Despite significant advances in care, clinical trial data demonstrate remission rates is at best of 40%. Strategies that stratify patients based on Paneth cell function represent a novel approach for outcome prediction. Upon conclusion, we will establish that Paneth cell phenotype is a predictive cellular biomarker for ileal complications in ulcerative colitis patients undergoing total colectomy and ileal pouch anal anastomosis. We will also define the underlying genetic associations and molecular pathways of abnormal Paneth cell phenotype in these patients. In addition, we will develop deep learning algorithms that will streamline the interpretation of Paneth cell phenotype for pathology specimens, and define serum markers that correlate with Paneth cell phenotype to allow for less invasive and more frequent monitoring.",Paneth cell phenotype as a predictive biomarker for ulcerative colitis,10119843,R01DK124274,"['Affect', 'Anastomosis - action', 'Anus', 'Biological', 'Biological Markers', 'Caring', 'Cell physiology', 'Cellular Morphology', 'Chronic', 'Classification', 'Clinical', 'Clinical Trials', 'Colectomy', 'Complex', 'Cost Measures', 'Crohn&apos', 's disease', 'Data', 'Development', 'Disease', 'Disease Management', 'Disease remission', 'Economic Burden', 'Epithelial Cells', 'Excision', 'Genetic Markers', 'Genetic Predisposition to Disease', 'Goals', 'Grant', 'Homeostasis', 'Ileal Reservoirs', 'Image', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Interobserver Variability', 'Longterm Follow-up', 'Manuals', 'Medical Genetics', 'Medical center', 'Methods', 'Molecular', 'Molecular Target', 'Monitor', 'Morphology', 'Mucous Membrane', 'Natural History', 'Natural Immunity', 'Observer Variation', 'Operative Surgical Procedures', 'Paneth Cells', 'Pathologist', 'Pathology', 'Pathway interactions', 'Patients', 'Phenotype', 'Positioning Attribute', 'Postoperative Period', 'Pouchitis', 'Prevalence', 'Process', 'Prognostic Marker', 'Public Health', 'Reproducibility', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Serum', 'Serum Markers', 'Small Intestines', 'Specimen', 'Standardization', 'Subgroup', 'Surgical Pathology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Ulcerative Colitis', 'Universities', 'Washington', 'Work', 'aggressive therapy', 'analysis pipeline', 'base', 'cell type', 'clinical practice', 'clinically relevant', 'cohort', 'combinatorial', 'deep learning', 'deep learning algorithm', 'dysbiosis', 'experience', 'experimental study', 'gastrointestinal', 'gene environment interaction', 'genetic association', 'improved', 'innate immune function', 'innovation', 'insight', 'intestinal epithelium', 'novel', 'novel strategies', 'outcome forecast', 'outcome prediction', 'patient stratification', 'personalized medicine', 'phenotypic biomarker', 'predictive marker', 'prognostic', 'treatment strategy']",NIDDK,WASHINGTON UNIVERSITY,R01,2020,386463,0.03984039227530521
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9925232,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'in silico', 'indexing', 'learning strategy', 'machine learning method', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2020,378183,0.06740097331557586
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9691995,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'deep learning algorithm', 'design', 'drug development', 'improved', 'indexing', 'learning strategy', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'supervised learning', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2019,378183,0.06740097331557586
"Interpretable and extendable deep learning model for biological sequence analysis and prediction Project Abstract Bioinformatics and computational biology have become the core of biomedical research. The PI Dr. Dong Xu's work in this area focuses on development of novel computational algorithms, software and information systems, as well as on broad applications of these tools and other informatics resources for diverse biological and medical problems. He works on many research problems in protein structure prediction, post-translational modification prediction, high-throughput biological data analyses, in silico studies of plants, microbes and cancers, biological information systems, and mobile App development for healthcare. He has published more than 300 papers, with about 12,000 citations and H-index of 55. In this project, the PI proposes to develop deep-learning algorithms, tools, web resources for analyses and predictions of biological sequences, including DNA, RNA, and protein sequences. The availability of these data provides emerging opportunities for precision medicine and other areas, while deep learning as a cutting-edge technology in machine learning, presents a new powerful method for analyses and predictions of biological sequences. With rapidly accumulating sequence data and fast development of deep-learning methods, there is an urgent need to systematically investigate how to best apply deep learning in sequence analyses and predictions. For this purpose, the PI will develop cutting-edge deep-learning methods with the following goals for the next five years:  (1) Develop a series of novel deep-learning methods and models to specifically target biological sequence analyses and predictions in: (a) general unsupervised representations of DNA/RNA, protein and SNP/mutation sequences that capture both local and global features for various applications; (b) methods to make deep-learning models interpretable for understanding biological mechanisms and generating hypotheses; (c) “rule learning”, which abstracts the underlying “rules” by combining unsupervised learning of large unlabeled data and supervised learning of small labeled data so that it can classify new unlabeled data.  (2) Apply the proposed deep-learning model to DNA/RNA sequence annotation, genotype-phenotype analyses, cancer mutation analyses, protein function/structure prediction, protein localization prediction, and protein post-translational modification prediction. The PI will exploit particular properties associated with each of these problems to improve the deep-learning models. He will develop a set of related prediction and analysis tools, which will improve the state-of-art performance and shed some light on related biological mechanisms.  (3) Make the data, models, and tools freely accessible to the research community. The system will be designed modular and open-source, available through GitHub. They will be available like integrated circuit modules, which are universal and ready to plug in for different applications. The PI will develop a web resource for biological sequence representations, analyses, and predictions, as well as tutorials to help biologists with no computational knowledge to apply deep learning to their specific research problems. Relevance to Public Health Biological sequences, including DNA, RNA and protein sequences, represent the largest sources of growing big data in current biology and medicine, which provide tremendous opportunities for precision medicine, synthetic biology, and other areas. Deep learning as an emerging machine-learning method has a great potential in utilizing these data in biomedical research. This project will develop and apply cutting-edge deep- learning methods to deliver various sequence-based computational tools for gaining new knowledge, accelerating drug development, and improving personalized diagnosis and treatment.",Interpretable and extendable deep learning model for biological sequence analysis and prediction,9485584,R35GM126985,"['Algorithmic Software', 'Amino Acid Sequence', 'Area', 'Base Sequence', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Communities', 'Computational Biology', 'Computational algorithm', 'Computer Simulation', 'DNA', 'DNA Sequence', 'Data', 'Data Analyses', 'Development', 'Genotype', 'Goals', 'Healthcare', 'Information Systems', 'Knowledge', 'Label', 'Learning', 'Light', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Methods', 'Microbe', 'Modeling', 'Mutation', 'Mutation Analysis', 'Paper', 'Performance', 'Phenotype', 'Plants', 'Plug-in', 'Post-Translational Protein Processing', 'Property', 'Proteins', 'Public Health', 'Publishing', 'RNA', 'RNA Sequences', 'Research', 'Resource Informatics', 'Sequence Analysis', 'Series', 'Source', 'Supervision', 'System', 'Technology', 'Work', 'computerized tools', 'deep learning', 'design', 'drug development', 'improved', 'indexing', 'learning strategy', 'mobile application', 'novel', 'online resource', 'open source', 'personalized diagnostics', 'personalized medicine', 'precision medicine', 'protein structure function', 'protein structure prediction', 'software systems', 'synthetic biology', 'tool', 'unsupervised learning']",NIGMS,UNIVERSITY OF MISSOURI-COLUMBIA,R35,2018,378183,0.06740097331557586
"BOND: Benchmarking based on heterogeneous biOmedical Network and Deep learning novel drug-target associations Project Summary/Abstract The applicant’s goals are to develop the necessary skills to become an independent translational biomedical informatics researcher in the area of computational drug repurposing. Exploring novel drug-target interactions (DTI) plays a crucial role in drug development. In order to lower the overall costs and uncover more potential screening targets, computational (in silico) methods have become popular and are commonly applied to poly-pharmacology and drug repurposing. Although machine learning-based strategies have been studied for years, there is no standardized benchmark that provides large-scale training datasets as well as diverse evaluation tasks to test different methods. Furthermore, the existing methods suffer from remarkable limitations, where 1) results are often biased due to a lack of negative samples, 2) novel drug-target associations with new (or isolated) drugs/targets cannot be explored, and 3) the comprehensive topological structure cannot be captured by feature learning methods . Therefore, in the era of big data, the applicant proposes a study to tackle the challenges by achieving two aims. • Aim 1 (K99 Phase): Develop a large scale benchmark for evaluating drug-target prediction based on the  generation of a multipartite network from heterogeneous biomedical datasets. • Aim 2 (R00 Phase): Adapt a deep learning model to build an accurate predictive model based on a novel  feature learning algorithm that mines the multi-dimensional biomedical network (multipartite network). In the mentored phase, the applicant will integrate heterogeneous biomedical datasets and build a benchmark for evaluation of the drug-target prediction based on well-designed strategies. The applicant will receive training in standardization tools for data integration, tools, and skills for data management, evaluation methods for drug-target predictions, and state-of-the-art machine learning/deep learning methods in computer-aided pharmacology. Complementary didactic, intellectual, and professional training will help prepare the applicant for the R00 phase where he will develop a deep learning-based predictive model and multi-dimensional graph embedding methods for feature learning. Together, these novel studies will advance the current computational drug repurposing by providing 1) comprehensive benchmarking for testing and evaluation, and 2) a scalable and accurate predictive model based on a biomedical multi-partite network. The applicant will be mentored by senior, established investigators with substantial expertise in Semantic Web, computational biology, cancer genomics, drug development, and machine learning/deep learning. Importantly, this project will provide a foundation for the applicant to establish independent research programs in 1) computational drug repurposing in real cases, 2) investigation of the diverse hidden associations in system biology (e.g., associations between drugs, genetics, and diseases), and 3) precision medicine aimed applications leveraging biomedical knowledgebases and electronic health records. Project Narrative The field of computational drug repurposing lacks a large scale benchmark that provides comprehensive and standard evaluation tasks as well as a scalable and accurate prediction model that can handle large biomedical datasets. This study aims to utilize Semantic Web technology to construct a multi-partite network based on heterogeneous biomedical databases and develop a deep learning-based predictive model based on the network. The proposed investigation will advance this field by providing a large scale benchmark for evaluation as well as a predictive model based on state-of-the-art technology.",BOND: Benchmarking based on heterogeneous biOmedical Network and Deep learning novel drug-target associations,10054989,K99GM135488,"['Address', 'Algorithms', 'Area', 'Base Ratios', 'Benchmarking', 'Big Data', 'Clinic', 'Computational Biology', 'Computer Assisted', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Dimensions', 'Disease', 'Drug Evaluation', 'Drug Targeting', 'Electronic Health Record', 'Employment', 'Evaluation', 'Foundations', 'Generations', 'Genetic', 'Goals', 'Graph', 'Investigation', 'Learning', 'Learning Module', 'Link', 'Machine Learning', 'Mentors', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Network-based', 'Pharmaceutical Preparations', 'Pharmacology', 'Phase', 'Play', 'Positioning Attribute', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Silver', 'Source', 'Standardization', 'Structure', 'Systems Biology', 'Technology', 'Testing', 'Training', 'Ursidae Family', 'Validation', 'base', 'biomedical informatics', 'cancer genomics', 'computer based Semantic Analysis', 'cost', 'data integration', 'data management', 'data tools', 'deep learning', 'deep neural network', 'design', 'drug development', 'flexibility', 'heterogenous data', 'improved', 'in silico', 'knowledge base', 'large scale data', 'learning algorithm', 'learning strategy', 'machine learning algorithm', 'new therapeutic target', 'novel', 'precision medicine', 'predictive modeling', 'predictive test', 'programs', 'repository', 'screening', 'skills', 'tool']",NIGMS,MAYO CLINIC ROCHESTER,K99,2020,100000,0.0043825342796768784
"AI platform for microscopy image restoration and virtual staining AI Platform for Microscopy Image Restoration and Virtual Staining Project Summary:  Fluorescence microscopy has enabled many major discoveries in biomedical sciences. Despite the rapid advancements in optics, lasers, probes, cameras and novel techniques, major factors such as spatial and temporal resolution, light exposure, signal-to-noise, depth of penetration and probe spectra continue to limit the types of experiments that are possible. Deep learning (DL) algorithms are well suited for image-based problems like SNR/super-resolution restoration and virtual staining, which have great enabling potentials for microscopy experiments. Previously impossible experiments could be realized such as achieving high signal-to-noise and/or spatial-temporal resolution without photobleaching/phototoxicity; simultaneously observing many image channels without interfering with native processes, etc. This could pave the way for a quantum leap forward in microscopy-based discoveries that elucidate biological functions and the mechanisms of disorders, and enable new diagnostics and therapies for human diseases.  However, these new methods have not been widely translated to new microscopy experiments. The delay is due to several practical hurdles and challenges such as required expertise, computing and trust. In order to accelerate the adoption of DL in microscopy, novel AI platform tailored for biologists are needed for training, applying and validating DL models and outputs.  The present project aims to develop an AI platform for microscopy image restoration and virtual staining called AI for Restoring and Staining (AIRS) platform. With our collaborator, Dr. Hari Shroff (National Institute of Biomedical Imaging and Bioengineering) we have successfully created DL models for SNR restoration, super-resolution restoration and virtual staining for a variety of imaging conditions and organelles in our preliminary studies. The AIRS platform intends to (1)provide a comprehensive suite of validated DL models for microscopy restoration and virtual staining applications including SNR restoration, super-resolution restoration, spatial deconvolution, spectral unmixing, prediction of 3d from 2d images, organelle virtual staining and analysis; (2)provide plug and play for common microscopy experiments; (3)provide semi-automatic update training to tailor DL models to match advanced microscopy experiments; (4)provide user friendly support for new DL model training for pioneering microscopy experiments; (5)provide confidence scores to assess the output results by a DL model, (6) provide DL models that avoid image artifact (hallucination) and allow continuous learning and evolution; (7) and be able to access the required computing infrastructure and database connection. Project Narrative Deep learning (DL) algorithms have great enabling potentials for microscopy experiments. Previously impossible experiments could now be realized. This could pave the way for a quantum leap forward in microscopy-based discoveries.  Powered by deep learning and DRVision innovations and collaborating with Dr. Hari Shroff and 7 additional labs, this project aims to create an AI platform for microscopy image restorations and virtual staining called AI for restoring and staining (AIRS). The tool will be integrated with DRVision’s flagship product Aivia for commercialization to accelerate the adoption of DL in microscopy.",AI platform for microscopy image restoration and virtual staining,9909318,U44GM136091,"['3-Dimensional', 'Active Learning', 'Adoption', 'Artificial Intelligence', 'Biological Process', 'Data', 'Databases', 'Disease', 'Evaluation', 'Evolution', 'Feedback', 'Fluorescence Microscopy', 'Government', 'Hallucinations', 'Image', 'Infrastructure', 'Lasers', 'Libraries', 'Light', 'Manuals', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'National Institute of Biomedical Imaging and Bioengineering', 'Noise', 'Optics', 'Organelles', 'Output', 'Penetration', 'Performance', 'Persons', 'Phase', 'Photobleaching', 'Phototoxicity', 'Play', 'Process', 'Resolution', 'Science', 'Signal Transduction', 'Stains', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Translating', 'Trust', 'Update', 'Validation', 'base', 'commercialization', 'deep learning', 'deep learning algorithm', 'experience', 'experimental study', 'human disease', 'improved', 'innovation', 'learning progression', 'microscopic imaging', 'novel', 'novel diagnostics', 'novel therapeutics', 'prototype', 'quantum', 'restoration', 'temporal measurement', 'tool', 'usability', 'user-friendly', 'virtual']",NIGMS,"DRVISION TECHNOLOGIES, LLC",U44,2020,172359,0.07298429100170797
"Computational Methods for Next-Generation GWAS Project Summary/Abstract  Predicting phenotypes from DNA sequence variation is a major goal for genetics with potential applications in evolutionary biology, crop breeding, and public health. A central challenge in this task is separating genetic and environmental effects on phenotypes. In natural populations breeding structure is often correlated with the environment across space such that different subpopulations experience different environments. For genome-wide association studies (GWAS) this creates a problem: genetic and environmental effects can be confounded by population structure, leading to inflated test statistics and low predictive power across populations (Bulik-Sullivan et al. 2015, Mathieson and Mcvean, 2012). Understanding when association studies are biased by population stratification and creating better methods to correct for it are thus important challenges for population genetics over the next decade.  To identify conditions under which existing methods of population stratification correction are subject to bias and develop robust new alternatives suitable for use with the continental-scale genomic datasets that are now routinely available for humans, we propose to use simulations and machine learning to separate the signals of fine-scale ancestry from polygenic phenotype association. In our first aim we will develop simulations of polygenic phenotype evolution in continuous space and use the output to evaluate existing methods of stratification control including linear mixed models, PC correction, and LD score regression. In this aim we will seek to identify the regions of parameter space – i.e. the strength of isolation by distance and the spatial distribution of environmental variation – in which existing methods can be expected to produce reliable effect size estimates, and establish guidelines for applications of GWAS to structured populations.  We will then train machine learning algorithms on real genotype data from humans and mosquitoes to describe continuous structure in large spatial samples using a variational autoencoder, a dimensionality reduction technique based on deep neural networks that can take advantage of both allele frequency and haplotype-based measures of differentiation in a single analysis and thus offer improved control of stratification inflation in GWAS relative to the now standard PCA regression approach. Last we will apply deep learning techniques to the problem of linking phenotypes and genotypes in structured samples by training neural networks on simulated phenotypes and empirical genetic data. By training our networks on empirical genetic data and incorporating contextual information about surrounding haplotype structure into the model, our networks should learn to discriminate causal associations from false positives created by population structure in the sample cohort, which will improve performance when attempting to identify associations with the real phenotype. These methods will be applied to existing genomic datasets of height in humans, tested against the current state-of-the-art approaches, and packaged as scalable software for the broader scientific community. Project Narrative Separating the signals of polygenic trait association and population structure has emerged as a major challenge for the interpretation of genome-wide association studies (GWAS). We propose to develop new simulations of populations evolving in continuous space that will allow us to rigorously benchmark existing methods of stratification control in GWAS while fully controlling the underlying demographic and selective process. We will then apply deep learning techniques to develop (1) a new method of dimensionality reduction to test as a covariate for ancestry in GWAS, and (2) a neural network that identifies genotype-phenotype connections while controlling for population structure in the sample cohort.",Computational Methods for Next-Generation GWAS,9910009,F32GM136123,"['Agriculture', 'Benchmarking', 'Biology', 'Breeding', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Culicidae', 'DNA Sequence', 'Data', 'Dimensions', 'Environment', 'Evolution', 'Gene Frequency', 'Genetic', 'Genotype', 'Geographic Locations', 'Goals', 'Guidelines', 'Haplotypes', 'Health', 'Heart Diseases', 'Height', 'Human', 'Image', 'Learning', 'Linear Models', 'Linear Regressions', 'Link', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Oligogenic Traits', 'Output', 'Performance', 'Phenotype', 'Polygenic Traits', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Positioning Attribute', 'Process', 'Public Health', 'Running', 'Sampling', 'Signal Transduction', 'Spatial Distribution', 'Stratification', 'Structure', 'Sum', 'Techniques', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'Variant', 'autoencoder', 'base', 'biobank', 'cohort', 'deep learning', 'deep neural network', 'diverse data', 'experience', 'genome wide association study', 'genome-wide', 'genomic data', 'human data', 'image reconstruction', 'improved', 'large scale simulation', 'learning strategy', 'machine learning algorithm', 'neural network', 'next generation', 'polygenic risk score', 'population stratification', 'simulation', 'statistics', 'supervised learning', 'tool', 'trait']",NIGMS,UNIVERSITY OF OREGON,F32,2020,19290,0.030070045724776902
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10027477,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2020,360287,0.1534568536384913
"Interpretable Deep Learning Algorithms for Pathology Image Analysis Interpretable Deep Learning Algorithms for Pathology Image Analysis Abstract The microscopic examination of stained tissue is a fundamental component of biomedical research and for the understanding of biological processes of disease which leads to improved diagnosis, prognosis and therapeutic response prediction. Ranging from cancer diagnosis to heart rejection and forensics the subjective interpretation of histopathology sections forms the basis of clinical decision making and research outcomes. However, it has been shown that such subjective interpretation of pathology slides suffers from large interobserver and intraobserver variability. Recent advances in computer vision and deep learning has enabled the objective and automated analysis of images. These methods have been applied with success to histology images which have demonstrated potential for development of objective image interpretation paradigms. However, significant algorithmic challenges remain to be addressed before such objective analysis of histology images can be used by clinicians and researchers. Leveraging extensive experience in developing and decimating research software based on deep learning the PI will pioneer novel algorithmic approaches to address these challenges including but not limited to: (1) training data-efficient and interpretable deep learning models with gigapixel size microscopy images for classification and segmentation using weakly supervised labels (2) fundamental redesign of data fusion paradigms for integrating information from microscopy images and molecular profiles (from multi-omics data) for improved diagnostic and prognostic determinations (3) developing visualization and interpretation software for researchers and clinical workflows to improve clinical and research validation and reproducability. The system will be designed in a modular, user-friendly manner and will be open-source, available through GitHub as universal plug-and-play modules ready to be adapted to various clinical and research applications. We will also develop a web resource with pretrained models for various organs, disease states and subtypes these will be accompanied with detailed manuals so researchers can apply deep learning to their specific research problems. Overall, the laboratory’s research will yield high impact discoveries from pathology image analysis, and its software will enable many other NIH funded laboratories to do the same, across various biomedical disciplines. Project Narrative The microscopic examination of stained tissue is a fundamental component of biomedical research, disease diagnosis, prognosis and therapeutic response prediction. However, the subjective interpretation of histology sections is subject to large interobserver and interobserver variability. This project focuses on developing artificial intelligence algorithms for the objective and automated analysis of whole histology slides leading to the development of an easy-to-use open source software package for biomedical researchers.",Interpretable Deep Learning Algorithms for Pathology Image Analysis,10029418,R35GM138216,"['Address', 'Algorithms', 'Artificial Intelligence', 'Biological Process', 'Biomedical Research', 'Classification', 'Clinical', 'Clinical Research', 'Computer Vision Systems', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline', 'Disease', 'Forensic Medicine', 'Funding', 'Heart', 'Histology', 'Histopathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intraobserver Variability', 'Label', 'Laboratories', 'Laboratory Research', 'Manuals', 'Methods', 'Microscopic', 'Modeling', 'Molecular Profiling', 'Multiomic Data', 'Organ', 'Outcomes Research', 'Pathology', 'Play', 'Research', 'Research Personnel', 'Slide', 'Supervision', 'System', 'Tissue Stains', 'Training', 'United States National Institutes of Health', 'Validation', 'Visualization', 'automated analysis', 'automated image analysis', 'base', 'cancer diagnosis', 'clinical decision-making', 'data fusion', 'decision research', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'experience', 'improved', 'intelligent algorithm', 'microscopic imaging', 'novel', 'online resource', 'open source', 'outcome forecast', 'pathology imaging', 'predicting response', 'prognostic', 'success', 'treatment response', 'user-friendly']",NIGMS,BRIGHAM AND WOMEN'S HOSPITAL,R35,2020,447500,0.10952206350040038
"Unsupervised optimization of protein therapeutics using closed-loop in vitro synthesis, nanosensing, and deep-learning Project Summary Overview of research: The Reuel Group at Iowa State University (founded Fall 2016) seeks to develop new materials, methods, and measurement devices for biomanufacturing, biotherapeutics, and biosensors. We have active work-streams in 1) optical nanosensors for protein binding, enzymatic activity, and cell membrane disruption, 2) scalable and reliable cell free protein synthesis (CFPS) methods for protein prototyping (extract and genetic template improvements), 3) microfluidics for droplet generation and measurement of CFPS products, interrogated by nanosensors, 4) algorithms for `big data' generated from nanosensors (machine learning and deep learning methods), 5) engineered endospores for time-delayed synthetic biology circuits, and 6) resonant radio frequency sensors for biomanufacturing, wound healing, and water quality. The overall vision of the research program is to simplify and improve the design and manufacturing of biological products (cells and proteins) for applications in therapies, advanced materials, and bio-electronics. Protein based therapies have demonstrated in clinic to be a potent tool in the treatment of many diseases. In recent years, the design, build, and test cycle to find therapies for new disease targets has improved dramatically using techniques such as surface display coupled to evolutionary selection. However, these mutagenic approaches have a few limitations, namely: 1) they require a suitable, naturally occurring sequence as a starting point, 2) they frequently optimize solely on a single desired feature, and 3) they operate as a `black box', meaning that generalizable design rules for in silico prediction of future products is not possible. It is the purpose of this MIRA for ESI research plan to design a closed-loop system that allows for unsupervised design and discovery of protein therapeutics that overcomes these limitations. Over the next five years we will build and integrate the system components which include enzymatic DNA synthesis coupled to cell free protein synthesis to rapidly prototype libraries of custom proteins in micro-droplet reactors. These proteins will then be characterized in the micro-droplets using optical nanosensors, to test for desired features such as stability, binding affinity, selectivity, hydrolytic activity, and/or membrane penetration. This will produce a large labeled data set (tying sequence to phenotypic properties) that can be used to train a deep learning neural network to self-determine sequence patterns for specific properties. Once the tuning coefficients of the network are found, the algorithm will then predict next best sequences which will be synthesized, tested, etc. such that the design loop progresses unsupervised until optimization criteria are met. This new approach will result in faster development of protein therapies that are optimized based on multiple criteria and not tied to existing, natural sequences. For patients this translates to more efficacious therapies with less side effects and a potential for reduced cost (due to shortened design timeline). At the end of the five-year project we will seek to translate this technology, via NIH SBIR funding, such that the new technology can make an impact on actual therapies. Project Narrative This project seeks to develop advanced tools to enable faster discovery and design of protein-based drugs for new disease targets. These tools would enable optimization of multiple parameters simultaneously, creating more potent therapies with less side effects. Thanks to speeding up the development cycle and reducing the time to market, these tools also have the potential to reduce end cost to patients.","Unsupervised optimization of protein therapeutics using closed-loop in vitro synthesis, nanosensing, and deep-learning",10028304,R35GM138265,"['Affinity', 'Algorithms', 'Big Data', 'Binding', 'Binding Proteins', 'Biological Products', 'Biological Response Modifier Therapy', 'Biomanufacturing', 'Biosensor', 'Cell membrane', 'Cells', 'Clinic', 'Coupled', 'Custom', 'DNA biosynthesis', 'Data Set', 'Development', 'Devices', 'Disease', 'Electronics', 'Engineering', 'Funding', 'Future', 'Generations', 'Genetic Template', 'In Vitro', 'Iowa', 'Label', 'Libraries', 'Machine Learning', 'Measurement', 'Membrane', 'Methods', 'Microfluidics', 'Optics', 'Patients', 'Pattern', 'Penetration', 'Pharmaceutical Preparations', 'Phenotype', 'Property', 'Protein Biosynthesis', 'Protein Engineering', 'Proteins', 'Research', 'Small Business Innovation Research Grant', 'Speed', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Uses', 'Time', 'TimeLine', 'Training', 'Translating', 'United States National Institutes of Health', 'Universities', 'Vision', 'Work', 'base', 'cost', 'deep learning', 'deep neural network', 'design', 'falls', 'improved', 'in silico', 'learning strategy', 'nanosensors', 'new technology', 'novel strategies', 'programs', 'prototype', 'radio frequency', 'sensor', 'side effect', 'synthetic biology', 'therapeutic protein', 'tool', 'treatment optimization', 'water quality', 'wound healing']",NIGMS,IOWA STATE UNIVERSITY,R35,2020,327666,-0.028614224965307477
"Interpretable Deep Learning Model for Longitudinal Electronic Health Records and Applications to Heart Failure Prediction   PROJECT  SUMMARY  Heart failure (HF) is a highly disabling and costly disease with a high mortality rate. In the pre­diagnostic phase  (i.e.,  12­36  months  before  diagnosis),  HF  is  difficult  to  detect  given  the  insidious  signs  and  symptoms.  After  diagnosis,  where  it  is not possible to reverse disease progression, efforts are made to avoid hospital admission  and  re­admission,  but  with  limited  capabilities  to  stratify  patients  by  risk.  We  propose  to  develop  interpretable  deep learning models applied to large­scale electronic health record (EHR) data to detect HF related events on  two  different  time  scales.  One  set  of  models will be developed to detect HF diagnosis one to two years before  actual  documented  diagnosis.  Separately,  we  propose  to  identify  HF  patients  who  are  at  risk  of  hospital  admission  and  readmission . The project focuses on developing deep learning models that offer the potential for  greater  accuracy,  clinical  interpretability,  and  utility  than  alternatives.  The  expected  deliverables  include  comprehensive  software  for  creating  deep  learning  algorithms  that  predict  HF  outcomes  and  related  software  tools  for  model  visualization.           PROJECT NARRATIVE Deep learning has shown tremendous success in many domains but is yet to have similar impact in health care. The key challenges in healthcare applications are the lack of interpretation for deep learning models and limited transferability of the models across institutions. We develop interpretable deep learning algorithms for heart failure prediction that can handle large longitudinal patient records and are able to adapt across institutions.",Interpretable Deep Learning Model for Longitudinal Electronic Health Records and Applications to Heart Failure Prediction,9544376,R56HL138415,"['Accounting', 'Address', 'Admission activity', 'Algorithms', 'Attention', 'Biological Neural Networks', 'Caring', 'Classification', 'Clinical', 'Code', 'Complex', 'Computer software', 'Cost of Illness', 'Data', 'Decision Trees', 'Detection', 'Diagnosis', 'Diagnostic', 'Dimensions', 'Disease Progression', 'E-learning', 'Early Diagnosis', 'Electronic Health Record', 'Event', 'Future', 'Health', 'Health system', 'Healthcare', 'Heart failure', 'Hospitals', 'Image', 'Imagery', 'Individual', 'Influentials', 'Inpatients', 'Institution', 'Intuition', 'Learning', 'Logistic Regressions', 'Measures', 'Medical', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Outcome', 'Output', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Procedures', 'Records', 'Recurrence', 'Research', 'Risk', 'Risk Factors', 'Signs and Symptoms', 'Software Tools', 'Structure', 'System', 'Time', 'Translating', 'Work', 'base', 'clinical care', 'clinical risk', 'health application', 'high dimensionality', 'improved', 'individual patient', 'interest', 'interoperability', 'learning strategy', 'mortality', 'parallel computer', 'patient stratification', 'prediction algorithm', 'predictive modeling', 'relating to nervous system', 'success']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R56,2017,756093,0.07908945988351972
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,10000961,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2020,702450,0.08609222164060805
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. The potential impact is significant given that increasing interpretation accuracy by 1% could positively benefit over 10,000 patients each year in the US alone. Thus, our team is developing an X-ray angiographic analysis system (DeepAngio) driven by deep learning technology to enhance physician interpretation. In Phase I, the PROMISE dataset of over 1,000 angiograms was used to build our Convolutional Neural Network (CNN) based deep learning model. We achieved a 0.89 Area Under the Receiving Operating Characteristic (AUROC) for identifying obstructive CAD in images with expert scored ground truth (exceeding our proposed Phase I milestone of >0.85 AUROC). Now in Phase II, we present an innovative image learning pipeline to incorporate anatomical and spatiotemporal information from video sequences (similar to a cardiologist reader). A full end to end X-ray angiography video processing pipeline will be developed and tested in a new cohort of 10,000 patient angiograms with normal and graded abnormal CAD. Our patch-based frame analysis model will advance to CNN full frame-based classification of angiographic views (left heart vs. right heart) and segmentation of coronary vessels (LAD, LCx, and RCA). A multiple frame analysis approach enabled by a Recursive Neural Network (RNN) will equip our model with dynamic temporal information to estimate lesion presence accurately. Our goal for Phase II is to improve reading specificity and translate our Phase I proof of concept research findings into a clinically meaningful tool. A multi-reader, multi-case evaluation by a group of interventional cardiologists interpreting with and without DeepAngio predictions will assess clinical usability to improve coronary stenosis estimation. In the long term, we hope the combination of a cardiologist with DeepAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE In this project, we will develop DeepAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9777388,R44HL140794,"['3-Dimensional', 'Address', 'Anatomy', 'Angiography', 'Anterior', 'Architecture', 'Area', 'Cephalic', 'Characteristics', 'Chest Pain', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Coronary', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary Vessels', 'Cost of Illness', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Engineering', 'Evaluation', 'Evaluation Studies', 'Goals', 'Gold', 'Healthcare Systems', 'Heart', 'Image', 'Institutional Review Boards', 'Intervention', 'Intraobserver Variability', 'Lateral', 'Lead', 'Learning', 'Left', 'Lesion', 'Methodology', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Neural Network Simulation', 'Observational Study', 'Outcome', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Procedures', 'Process', 'Reader', 'Reading', 'Reporting', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Specificity', 'Stenosis', 'Structure', 'Systems Analysis', 'Technology', 'Testing', 'Translating', 'Trees', 'Visual', 'Visual Aid', 'Work', 'base', 'clinically relevant', 'cohort', 'computer aided detection', 'convolutional neural network', 'coronary lesion', 'cost', 'deep learning', 'deep neural network', 'diagnostic accuracy', 'group intervention', 'image processing', 'imaging study', 'improved', 'innovation', 'novel', 'prospective', 'recursive neural network', 'spatiotemporal', 'standard of care', 'tool', 'treatment planning', 'usability']",NHLBI,"VIGILANT MEDICAL, INC.",R44,2019,24447,0.08609222164060805
"Enhanced x-ray angiography analysis and interpretation using deep learning Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9754513,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disease', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,30000,0.05878543727659028
"Enhanced x-ray angiography analysis and interpretation using deep learning Over 1 Million diagnostic X-ray angiograms are performed annually in the US to guide treatment of coronary artery disease (CAD) and cost over $12 billion. Despite being the clinical standard of care, visual interpretation is prone to inter- and intra-observer variability. Recently as part of the NHLBI supported Prospective Multicenter Imaging Study for Evaluation of Chest Pain (PROMISE) trial, our research team showed that cardiologists misinterpreted over 19% of angiograms obstructive CAD (greater than 50% vessel stenosis). Given the centrality of angiographic interpretation to the development of a treatment plan, reduced accuracy can lead to unnecessary poor outcomes and increased costs to our healthcare system. Quantitative coronary angiography (QCA) offers a computed measure of disease severity. However, the time and training required to perform QCA has largely relegated its use to research applications. Recent advances in deep learning for medical image analysis offer an opportunity to address this problem. The potential impact is significant given increasing interpretation accuracy by 1% can positively benefit over 10,000 patients each year. Thus, our team proposes to develop an X-ray angiographic analysis system (XAngio) driven by deep learning technology to enhance physician interpretation. We are uniquely positioned to accelerate development of XAngio by leveraging our team’s PROMISE dataset of over 1,000 angiograms with expert QCA scoring. In Phase I, we will teach XAngio how to read angiographic images and how to discriminate obstructive CAD. XAngio will employ a convolutional neural network, a computer vision technique rooted in deep learning, to self-characterize angiographic features from labeled images. In order to infer additional information from vast amounts of unlabeled images, XAngio will incorporate a deconvolutional neural network technique to increase predictive performance. A pilot study of XAngio will test its ability to identify the presence of obstructive CAD in PROMISE angiogram images. If we are successful, we envision a Phase II proposal which is focused on clinical translation of the technology and assessment of its impact on improving visual interpretation in a cohort of cardiologists. Our goal is to combine recent advances in deep learning, big data from PROMISE, and scalable parallel computing to create XAngio. In the long term, we hope the combination of a cardiologist with XAngio as an assistive tool will improve the clinical accuracy of angiographic interpretation. PROJECT NARRATIVE While invasive x-ray angiography is the gold standard diagnostic tool for guiding immediate treatment in the cardiac cath lab, visual interpretation of angiograms is challenging and subject to large inter- and intra-observer biases. In this project, we will develop and validate XAngio, a novel computer-assistive technology to enhance cardiologist’s angiographic reading and interpretation process. It is our hope that this technology will increase the accuracy of diagnosing obstructive coronary artery disease and, ultimately, improve patient outcomes.",Enhanced x-ray angiography analysis and interpretation using deep learning,9466642,R43HL140794,"['Address', 'Angiography', 'Area', 'Big Data', 'Biological Neural Networks', 'Cardiac', 'Chest Pain', 'Clinical', 'Computer Assisted', 'Computer Simulation', 'Computer Vision Systems', 'Computers', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Cost of Illness', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Evaluation', 'Evaluation Studies', 'Feedback', 'Goals', 'Gold', 'Healthcare Systems', 'Image', 'Image Analysis', 'Institutional Review Boards', 'Intraobserver Variability', 'Label', 'Lead', 'Learning', 'Measures', 'Medical Imaging', 'Modeling', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Observer Variation', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Pilot Projects', 'Plant Roots', 'Positioning Attribute', 'Prevalence', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reading', 'Research', 'Roentgen Rays', 'Self-Help Devices', 'Severities', 'Severity of illness', 'Statistical Data Interpretation', 'Stenosis', 'Supervision', 'Systems Analysis', 'Techniques', 'Technology', 'Technology Assessment', 'Testing', 'Time', 'Training', 'Visual', 'Work', 'base', 'clinical translation', 'cohort', 'cost', 'deep learning', 'diagnostic accuracy', 'imaging study', 'improved', 'insight', 'novel', 'parallel computer', 'prospective', 'standard of care', 'tool', 'treatment planning']",NHLBI,"VIGILANT MEDICAL, INC.",R43,2018,217746,0.04362709501280748
"Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope Project​ ​Summary/Abstract This​ ​SBIR​ ​Phase​ ​I​ ​project​ ​will​ ​develop​ ​a​ ​deep​ ​learning-based​ ​clinical​ ​decision​ ​support​ ​algorithm for​ ​identifying​ ​aortic​ ​stenosis​ ​from​ ​heart​ ​sounds​ ​recorded​ ​using​ ​the​ ​Eko​ ​Core​ ​Digital Stethoscope.​ ​This​ ​screening​ ​tool​ ​will​ ​help​ ​to​ ​decrease​ ​the​ ​number​ ​of​ ​patients​ ​with​ ​severe asymptomatic​ ​aortic​ ​stenosis​ ​that​ ​remain​ ​undertreated​ ​simply​ ​because​ ​the​ ​condition​ ​is​ ​not diagnosed.​ ​Auscultation​ ​is​ ​commonly​ ​the​ ​method​ ​by​ ​which​ ​valvular​ ​heart​ ​disease​ ​is​ ​first detected,​ ​but​ ​cases​ ​often​ ​fail​ ​to​ ​be​ ​referred​ ​to​ ​echocardiography​ ​for​ ​diagnosis​ ​because clinicians​ ​fail​ ​to​ ​detect​ ​heart​ ​murmurs,​ ​particularly​ ​in​ ​noisy​ ​or​ ​rushed​ ​environments.​ ​To​ ​address this​ ​challenge,​ ​Eko​ ​had​ ​developed​ ​the​ ​Core,​ ​a​ ​digital​ ​stethoscope​ ​attachment​ ​that​ ​can​ ​be​ ​added in-line​ ​to​ ​a​ ​clinician’s​ ​existing​ ​stethoscope​ ​that​ ​amplifies​ ​heart​ ​sounds​ ​and​ ​streams​ ​digitized phonocardiograms​ ​to​ ​a​ ​smartphone,​ ​tablet​ ​or​ ​personal​ ​computer.​ ​There,​ ​the​ ​signal​ ​can​ ​be analyzed​ ​with​ ​the​ ​decision​ ​support​ ​algorithm​ ​we​ ​will​ ​develop​ ​as​ ​part​ ​of​ ​this​ ​project.​ ​The​ ​specific aims​ ​of​ ​this​ ​study​ ​are​ ​(1)​ ​to​ ​​collect​ ​a​ ​database​ ​with​ ​condition-specific​ ​recording​ ​labels​ ​to enable​ ​deep​ ​learning​ ​for​ ​heart​ ​sounds​ ​though​ ​clinical​ ​data​ ​collection​ ​at​ ​UCSF​ ​and​ ​(2)​ ​to develop​ ​and​ ​evaluate​ ​a​ ​deep​ ​convolutional​ ​neural​ ​network-based​ ​algorithm​ ​trained​ ​on​ ​the database.​ ​By​ ​integrating​ ​this​ ​deep​ ​learning​ ​algorithm​ ​into​ ​Eko’s​ ​mobile​ ​and​ ​cloud​ ​software platform,​ ​currently​ ​used​ ​by​ ​clinicians​ ​at​ ​over​ ​700​ ​institutions​ ​worldwide,​ ​we​ ​anticipate​ ​this algorithm​ ​will​ ​enable​ ​more​ ​accurate​ ​screening​ ​for​ ​aortic​ ​stenosis,​ ​leading​ ​to​ ​earlier​ ​diagnosis and​ ​better​ ​patient​ ​outcomes. SBIR​ ​Project​ ​Narrative Valvular​ ​heart​ ​disease,​ ​and​ ​aortic​ ​stenosis​ ​in​ ​particular,​ ​are​ ​becoming​ ​increasingly​ ​prevalent manifestations​ ​of​ ​poor​ ​cardiovascular​ ​health​ ​in​ ​both​ ​the​ ​developed​ ​and​ ​developing​ ​world.​ ​A highly-accurate​ ​clinical​ ​decision​ ​support​ ​algorithm​ ​that​ ​is​ ​able​ ​to​ ​detect​ ​aortic​ ​stenosis​ ​will impact​ ​public​ ​health​ ​by​ ​reducing​ ​unnecessary​ ​referrals​ ​for​ ​echocardiography​ ​and​ ​promoting early​ ​and​ ​accurate​ ​diagnosis​ ​in​ ​underserved​ ​areas​ ​with​ ​limited​ ​access​ ​to​ ​subspecialty​ ​care.",Deep Learning for Automated Aortic Stenosis and Valvular Heart Disease Detection Using a Digital Stethoscope,9621223,R43HL144297,"['Address', 'Algorithms', 'Aortic Valve Stenosis', 'Area', 'Auscultation', 'Benign', 'Biological Neural Networks', 'Cardiac', 'Caring', 'Cellular Phone', 'Clinical', 'Clinical Data', 'Computer Vision Systems', 'Computer software', 'Data Collection', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Early Diagnosis', 'Echocardiography', 'Eko', 'Environment', 'Evaluation', 'FDA approved', 'Future', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Heart Abnormalities', 'Heart Sounds', 'Heart Valve Diseases', 'Heart murmur', 'Hospitals', 'Human', 'Image', 'Imaging Techniques', 'Institution', 'Label', 'Learning', 'Medical Device', 'Medicare', 'Methods', 'Mitral Valve Insufficiency', 'Modeling', 'Monitor', 'Network-based', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Personal Computers', 'Phase', 'Physicians', 'Positioning Attribute', 'Public Health', 'Resources', 'Screening procedure', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Specificity', 'Stethoscopes', 'Stream', 'Tablet Computer', 'Testing', 'Training', 'Weight', 'accurate diagnosis', 'base', 'cardiovascular health', 'clinical decision support', 'clinical development', 'clinically significant', 'cloud software', 'commercialization', 'cost', 'deep learning', 'deep neural network', 'diagnosis standard', 'digital', 'innovation', 'screening', 'speech recognition']",NHLBI,"EKO DEVICES, INC.",R43,2018,295881,0.039627804611578214
"Cardiac CT Deblooming PROJECT SUMMARY/ABSTRACT Coronary artery disease (CAD) is the most common type of heart disease, killing over 370,000 Americans annu- ally2. Cardiac CT is a safe, accurate, non-invasive method widely employed for diagnosis of CAD and planning therapeutic interventions. With the current CT technology, calcium blooming artifacts severely limit the accuracy of coronary stenosis assessment. Similarly, stent blooming artifacts lead to overestimation of in-stent restenosis. As a result, many coronary CT angiography (CCTA) scans are non-diagnostic and result in patients receiving costly and invasive coronary angiography (ICA) procedures.  Based on extensive feasibility results, the goal of this project is to use deep learning innovations to fundamen- tally eliminate blooming artifacts without costly redesign of the CT hardware. A consortium between GE Re- search, Rensselaer Polytechnic Institute and Weill Cornell Medicine will develop dedicated imaging protocols and machine learning methods to avoid or minimize blooming artifacts and evaluate the clinical impact of the proposed solutions. In Aim 1, the CT scan protocol will be optimized and paired with deep learning reconstruc- tion and post-processing algorithms to generate high-resolution CT images and prevent blooming artifacts. In Aim 2, image-domain and raw-data-domain deep learning processing algorithms will be developed to correct for residual blooming. After successful demonstration of the proposed methods on phantom scans and emulated clinical datasets, in Aim 3 the proposed CT methods will be clinically demonstrated and optimized based on 100 patients with coronary artery disease, using intravascular ultrasound as the ground-truth reference.  At the end of the project, we will have demonstrated and publicly disseminated a systematic methodology to essentially remove blooming artifacts in cardiac CT without a costly hardware upgrade. This will be another suc- cess of deep learning, enabling accurate coronary stenosis assessment and eliminating many unnecessary diag- nostic catheterizations. PROJECT NARRATIVE Blooming artifacts severely limit the accuracy of coronary stenosis assessment with cardiac CT, leading to un- necessary invasive coronary angiography procedures. The goal of this project is to eliminate blooming artifacts without costly redesign of the CT hardware, but based on optimized scan protocols and deep-learning-based image reconstruction and post-processing techniques. The proposed CT methods will be clinically demonstrated and optimized based on CT scans of 100 patients with coronary artery disease and using intravascular ultrasound as the ground-truth reference.",Cardiac CT Deblooming,9943684,R01HL151561,"['Address', 'Algorithms', 'American', 'Angiography', 'Area', 'Attenuated', 'Calcium', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Clinical', 'Collaborations', 'Coronary', 'Coronary Angiography', 'Coronary Arteriosclerosis', 'Coronary Stenosis', 'Coronary artery', 'Data', 'Data Set', 'Diagnosis', 'Goals', 'Heart', 'Heart Diseases', 'High Resolution Computed Tomography', 'Hospitals', 'Image', 'In Vitro', 'Institutes', 'Lead', 'Measurement', 'Medicine', 'Metals', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Morphologic artifacts', 'Motion', 'New York', 'Noise', 'Outcome', 'Patients', 'Physics', 'Plant Roots', 'Presbyterian Church', 'Prevention', 'Procedures', 'Protocols documentation', 'Recording of previous events', 'Research', 'Residual state', 'Resolution', 'Scanning', 'Speed', 'Stenosis', 'Stents', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Training', 'Ultrasonography', 'Validation', 'X-Ray Computed Tomography', 'base', 'calcification', 'cohort', 'cost', 'deep learning', 'deep learning algorithm', 'diagnostic catheterization', 'image reconstruction', 'improved', 'in silico', 'in vivo', 'innovation', 'learning network', 'machine learning method', 'man', 'microCT', 'mortality', 'prevent', 'reconstruction', 'recruit', 'restenosis', 'simulation', 'success', 'temporal measurement', 'virtual', 'virtual reality simulation']",NHLBI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,R01,2020,900092,-0.028293550680037433
"Multifidelity and multiscale modeling of the spleen function in sickle cell disease with in vitro, ex vivo and in vivo validations Project Summary The spleen plays a key role in the human immune system but also clears senescent red blood cells (RBC) from the circulation and those altered by acquired or inherited diseases. In patients with sickle cell disease (SCD), the spleen is one of the first targets of pathogenic processes and a potential protector against major complications. Under hypoxic conditions, mutated sickle hemoglobin (HbS) polymerizes to fibers which increase both the stiffness and adhesion of RBC. Splenic filtration of altered RBC prone to sickling (a process that cannot be directly observed in human subjects) contributes to anemia and likely triggers acute splenic sequestration crises (ASSC). On the other hand, it potentially prevents complications associated with intravascular sickling. Self- amplified blockade of vessels with sickled RBCs is indeed a hallmark of vaso-occlusive crises, acute chest syndrome, and acute hepatic crises, that severely impact the life quality and expectancy of patients with SCD. We propose to formulate and validate a new predictive modeling framework for how the spleen filters altered RBC in SCD by synergistically integrating in silico, in vitro, ex vivo and in vivo data using multifidelity-based neural networks (NN). This will deliver predictive models that can continuously learn when new data become available, a paradigm shift in biomedical modeling. We will develop multiscale/multifidelity computational models (and corresponding NN implementations) that link sub-cellular, cellular, and vessel level phenomena spanning across four orders of magnitude in spatio-temporal scales. This scale coupling will be accomplished using a molecular dynamics/dissipative particle dynamics (MD/DPD) framework. We will validate these predictive computational models by data from in vitro and ex vivo experiments, and RBC quantitative features collected in SCD patients. Specifically, we will use three new spleen-on-a-chip microfluidic devices with oxygen control and the unique human spleen perfusion setup of our foreign partner, with the following aims: Aim 1: Develop and validate a splenic inter-endothelial slit filtration model; Aim 2: Develop new models of RBC macrophage adhesion and of phagocytosis in the spleen; Aim 3: Perform Spleen-on-a-Chip experiments and validation; Aim 4: Validate the predictive framework based on RBC samples from patients. Realization of our four Specific Aims will significantly increase our understanding of the complex pathogenic and protective roles of the spleen in SCD. Feeding our new multifidelity neural networks with morphological and functional measures of RBC circulating in SCD patients will lead to models for residual spleen function in SCD, which should help predict the risk of acute splenic sequestration crises, and guide optimal timing for Stem Cell Transplantation or Gene Therapy. The new paradigm in using deep learning tools to integrate data from different sources will be applicable to modeling many other blood diseases. Project Narrative In patients with sickle cell disease (SCD), the spleen is the target of early pathogenic processes and a potential protector against major complications. We will formulate and validate predictive multiscale models for red blood cell (RBC) filtration by the spleen based on new deep learning neural networks fed with data from simulations, experiments using new spleen-mimetic microfluidics, and RBC quantitative features from ex vivo perfusion of human spleens and from SCD patients. These models will be used to predict acute splenic sequestrations crises and guide treatment decisions in patients with SCD.","Multifidelity and multiscale modeling of the spleen function in sickle cell disease with in vitro, ex vivo and in vivo validations",10052044,R01HL154150,"['Accounting', 'Acute', 'Adhesions', 'Adhesiveness', 'Adhesives', 'Anemia', 'Biomechanics', 'Blood Circulation', 'Blood specimen', 'Cell Communication', 'Cell Shape', 'Cell model', 'Clinical', 'Collaborations', 'Complement', 'Complex', 'Complication', 'Computer Models', 'Coupling', 'Data', 'Decision Making', 'Devices', 'Endothelium', 'Erythrocytes', 'Expectancy', 'Fiber', 'Filtration', 'Goals', 'Hematological Disease', 'Hepatic', 'Hereditary Disease', 'Hereditary Spherocytosis', 'Human', 'Hypoxia', 'Immune system', 'In Vitro', 'Lead', 'Learning', 'Life', 'Link', 'Malaria', 'Measures', 'Mechanics', 'Medical', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Molecular', 'Morphology', 'Mutate', 'Organ', 'Output', 'Oxygen', 'Paper', 'Paris, France', 'Pathogenicity', 'Patients', 'Perfusion', 'Phagocytosis', 'Physicians', 'Play', 'Polymers', 'Process', 'Proteins', 'Quality of life', 'Residual state', 'Risk', 'Role', 'Sampling', 'Shapes', 'Sickle Cell', 'Sickle Cell Anemia', 'Sickle Hemoglobin', 'Source', 'Spleen', 'Stem cell transplant', 'Surface', 'System', 'Training', 'Validation', 'acute chest syndrome', 'base', 'biophysical properties', 'cohort', 'deep learning', 'deep neural network', 'design', 'ex vivo perfusion', 'experimental study', 'feeding', 'gene therapy', 'high dimensionality', 'human subject', 'improved', 'in silico', 'in vivo', 'learning progression', 'macrophage', 'mimetics', 'molecular dynamics', 'mouse model', 'multi-scale modeling', 'neural network', 'outcome forecast', 'particle', 'predictive modeling', 'prevent', 'retention rate', 'senescence', 'sickling', 'simulation', 'spatiotemporal', 'tool', 'vaso-occlusive crisis']",NHLBI,BROWN UNIVERSITY,R01,2020,705243,0.01522069646513048
"Improving Melanoma Diagnosis with Pump-Probe Optical Imaging DESCRIPTION (provided by applicant): The goal of the research is to use a pump-probe microscopy system to find statistically significant variations between melanomas that did and did not develop metastases. This information will be used to develop automated classification algorithms to find robust molecular and structural features with strong predictive power. These insights will enable a retrospective study of melanoma and sentinel node biopsies, that can be used to validate the findings. By the end of the project, it is expected that there will be statistically significant evidence that pump-probe microscopy can substantially improve the diagnostic accuracy of histopathology. PUBLIC HEALTH RELEVANCE: We propose a novel imaging technology which can image specific cancer biomarkers in developing skin lesions. This approach could reduce the number of false negative diagnoses in thin (less than 1mm) melanomas that uncharacteristically metastasize. Additionally, this approach could eliminate thousands of false positive melanoma diagnoses per year, and save many millions of dollars in healthcare costs.",Improving Melanoma Diagnosis with Pump-Probe Optical Imaging,9189685,R01CA166555,"['Age', 'Algorithmic Analysis', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological Assay', 'Biopsy', 'Categories', 'Chemicals', 'Classification', 'Clinical', 'Color', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Employee Strikes', 'Entropy', 'Excision', 'Eye', 'Gender', 'Goals', 'Gold', 'Grant', 'Health Care Costs', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Immunohistochemistry', 'Italy', 'Lasers', 'Lead', 'Lesion', 'Malignant Neoplasms', 'Medical', 'Melanins', 'Melanosomes', 'Methods', 'Microscope', 'Microscopy', 'Mole the mammal', 'Molecular', 'Morbidity - disease rate', 'Morphology', 'Neoplasm Metastasis', 'Nevus', 'Outcome', 'Pathologist', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pigments', 'Principal Component Analysis', 'Protocols documentation', 'Publishing', 'Pump', 'Research', 'Resolution', 'Retrospective Studies', 'Sampling', 'Savings', 'Sentinel Lymph Node Biopsy', 'Skin', 'Slide', 'Spatial Distribution', 'Staging', 'Staining method', 'Stains', 'System', 'Testing', 'Text', 'Thick', 'Thinness', 'Time', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer biomarkers', 'cancer diagnosis', 'cost', 'diagnostic accuracy', 'eumelanin', 'imaging modality', 'improved', 'in vivo', 'insight', 'male', 'melanoma', 'men', 'mortality', 'novel', 'optical imaging', 'pheomelanin', 'predict clinical outcome', 'public health relevance', 'skin lesion', 'translational medicine', 'two-photon']",NCI,DUKE UNIVERSITY,R01,2017,321376,0.010381356214798909
"Improving Melanoma Diagnosis with Pump-Probe Optical Imaging DESCRIPTION (provided by applicant): The goal of the research is to use a pump-probe microscopy system to find statistically significant variations between melanomas that did and did not develop metastases. This information will be used to develop automated classification algorithms to find robust molecular and structural features with strong predictive power. These insights will enable a retrospective study of melanoma and sentinel node biopsies, that can be used to validate the findings. By the end of the project, it is expected that there will be statistically significant evidence that pump-probe microscopy can substantially improve the diagnostic accuracy of histopathology. PUBLIC HEALTH RELEVANCE: We propose a novel imaging technology which can image specific cancer biomarkers in developing skin lesions. This approach could reduce the number of false negative diagnoses in thin (less than 1mm) melanomas that uncharacteristically metastasize. Additionally, this approach could eliminate thousands of false positive melanoma diagnoses per year, and save many millions of dollars in healthcare costs.",Improving Melanoma Diagnosis with Pump-Probe Optical Imaging,8978295,R01CA166555,"['Address', 'Age', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological Assay', 'Biopsy', 'Categories', 'Chemicals', 'Classification', 'Clinical', 'Color', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Employee Strikes', 'Entropy', 'Excision', 'Eye', 'Gender', 'Goals', 'Gold', 'Grant', 'Health', 'Health Care Costs', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Immunohistochemistry', 'Lasers', 'Lead', 'Lesion', 'Malignant Neoplasms', 'Medical', 'Melanins', 'Melanosomes', 'Methods', 'Microscope', 'Microscopy', 'Mole the mammal', 'Molecular', 'Morbidity - disease rate', 'Morphology', 'Neoplasm Metastasis', 'Nevus', 'Outcome', 'Pathologist', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pigments', 'Principal Component Analysis', 'Protocols documentation', 'Publishing', 'Pump', 'Research', 'Resolution', 'Retrospective Studies', 'Sampling', 'Science', 'Sentinel Lymph Node Biopsy', 'Skin', 'Slide', 'Spatial Distribution', 'Staging', 'Staining method', 'Stains', 'System', 'Testing', 'Text', 'Thick', 'Time', 'Tissues', 'United States National Institutes of Health', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer biomarkers', 'cancer diagnosis', 'cost', 'diagnostic accuracy', 'eumelanin', 'falls', 'imaging modality', 'improved', 'in vivo', 'insight', 'male', 'melanoma', 'men', 'mortality', 'novel', 'optical imaging', 'pheomelanin', 'predict clinical outcome', 'skin lesion', 'translational medicine', 'two-photon']",NCI,DUKE UNIVERSITY,R01,2016,321376,0.010381356214798909
"Improving Melanoma Diagnosis with Pump-Probe Optical Imaging DESCRIPTION (provided by applicant): The goal of the research is to use a pump-probe microscopy system to find statistically significant variations between melanomas that did and did not develop metastases. This information will be used to develop automated classification algorithms to find robust molecular and structural features with strong predictive power. These insights will enable a retrospective study of melanoma and sentinel node biopsies, that can be used to validate the findings. By the end of the project, it is expected that there will be statistically significant evidence that pump-probe microscopy can substantially improve the diagnostic accuracy of histopathology. PUBLIC HEALTH RELEVANCE: We propose a novel imaging technology which can image specific cancer biomarkers in developing skin lesions. This approach could reduce the number of false negative diagnoses in thin (less than 1mm) melanomas that uncharacteristically metastasize. Additionally, this approach could eliminate thousands of false positive melanoma diagnoses per year, and save many millions of dollars in healthcare costs.",Improving Melanoma Diagnosis with Pump-Probe Optical Imaging,8776278,R01CA166555,"['Address', 'Age', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological Assay', 'Biological Markers', 'Biopsy', 'Categories', 'Chemicals', 'Classification', 'Clinical', 'Color', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Employee Strikes', 'Entropy', 'Excision', 'Eye', 'Gender', 'Goals', 'Gold', 'Grant', 'Health', 'Health Care Costs', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Immunohistochemistry', 'Lasers', 'Lead', 'Lesion', 'Malignant Neoplasms', 'Medical', 'Melanins', 'Melanosomes', 'Methods', 'Microscope', 'Microscopy', 'Mole the mammal', 'Molecular', 'Morbidity - disease rate', 'Morphology', 'Neoplasm Metastasis', 'Nevus', 'Outcome', 'Pathologist', 'Patient Care', 'Patients', 'Pigments', 'Principal Component Analysis', 'Protocols documentation', 'Publishing', 'Pump', 'Research', 'Resolution', 'Retrospective Studies', 'Sampling', 'Science', 'Sentinel Lymph Node Biopsy', 'Skin', 'Slide', 'Spatial Distribution', 'Staging', 'Staining method', 'Stains', 'System', 'Testing', 'Text', 'Thick', 'Time', 'Tissues', 'United States National Institutes of Health', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer diagnosis', 'cost', 'diagnostic accuracy', 'eumelanin', 'falls', 'imaging modality', 'improved', 'in vivo', 'insight', 'male', 'melanoma', 'men', 'mortality', 'novel', 'optical imaging', 'pheomelanin', 'skin lesion', 'translational medicine', 'two-photon']",NCI,DUKE UNIVERSITY,R01,2015,321376,0.010381356214798909
"Improving Melanoma Diagnosis with Pump-Probe Optical Imaging     DESCRIPTION (provided by applicant): The goal of the research is to use a pump-probe microscopy system to find statistically significant variations between melanomas that did and did not develop metastases. This information will be used to develop automated classification algorithms to find robust molecular and structural features with strong predictive power. These insights will enable a retrospective study of melanoma and sentinel node biopsies, that can be used to validate the findings. By the end of the project, it is expected that there will be statistically significant evidence that pump-probe microscopy can substantially improve the diagnostic accuracy of histopathology.         PUBLIC HEALTH RELEVANCE: We propose a novel imaging technology which can image specific cancer biomarkers in developing skin lesions. This approach could reduce the number of false negative diagnoses in thin (less than 1mm) melanomas that uncharacteristically metastasize. Additionally, this approach could eliminate thousands of false positive melanoma diagnoses per year, and save many millions of dollars in healthcare costs.              ",Improving Melanoma Diagnosis with Pump-Probe Optical Imaging,8601919,R01CA166555,"['Address', 'Age', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological Assay', 'Biological Markers', 'Biopsy', 'Categories', 'Chemicals', 'Classification', 'Clinical', 'Color', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Employee Strikes', 'Entropy', 'Excision', 'Eye', 'Gender', 'Goals', 'Gold', 'Grant', 'Health Care Costs', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Immunohistochemistry', 'Lasers', 'Lead', 'Lesion', 'Malignant Neoplasms', 'Medical', 'Melanins', 'Melanosomes', 'Methods', 'Microscope', 'Microscopy', 'Mole the mammal', 'Molecular', 'Morbidity - disease rate', 'Morphology', 'Neoplasm Metastasis', 'Nevus', 'Outcome', 'Pathologist', 'Patient Care', 'Patients', 'Pigments', 'Principal Component Analysis', 'Protocols documentation', 'Publishing', 'Pump', 'Research', 'Resolution', 'Retrospective Studies', 'Sampling', 'Science', 'Sentinel Lymph Node Biopsy', 'Skin', 'Slide', 'Spatial Distribution', 'Staging', 'Staining method', 'Stains', 'System', 'Testing', 'Text', 'Thick', 'Time', 'Tissues', 'United States National Institutes of Health', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer diagnosis', 'cost', 'diagnostic accuracy', 'eumelanin', 'falls', 'imaging modality', 'improved', 'in vivo', 'insight', 'male', 'melanoma', 'men', 'mortality', 'novel', 'optical imaging', 'pheomelanin', 'public health relevance', 'skin lesion', 'translational medicine', 'two-photon']",NCI,DUKE UNIVERSITY,R01,2014,311736,0.010381356214798909
"Improving Melanoma Diagnosis with Pump-Probe Optical Imaging     DESCRIPTION (provided by applicant): The goal of the research is to use a pump-probe microscopy system to find statistically significant variations between melanomas that did and did not develop metastases. This information will be used to develop automated classification algorithms to find robust molecular and structural features with strong predictive power. These insights will enable a retrospective study of melanoma and sentinel node biopsies, that can be used to validate the findings. By the end of the project, it is expected that there will be statistically significant evidence that pump-probe microscopy can substantially improve the diagnostic accuracy of histopathology.         PUBLIC HEALTH RELEVANCE: We propose a novel imaging technology which can image specific cancer biomarkers in developing skin lesions. This approach could reduce the number of false negative diagnoses in thin (less than 1mm) melanomas that uncharacteristically metastasize. Additionally, this approach could eliminate thousands of false positive melanoma diagnoses per year, and save many millions of dollars in healthcare costs.              ",Improving Melanoma Diagnosis with Pump-Probe Optical Imaging,8437772,R01CA166555,"['Address', 'Age', 'Algorithms', 'Archives', 'Biochemical Pathway', 'Biological Assay', 'Biological Markers', 'Biopsy', 'Categories', 'Chemicals', 'Classification', 'Clinical', 'Color', 'Databases', 'Detection', 'Diagnosis', 'Diagnostic', 'Disease', 'Employee Strikes', 'Entropy', 'Excision', 'Eye', 'Gender', 'Goals', 'Gold', 'Grant', 'Health Care Costs', 'Hematoxylin and Eosin Staining Method', 'Heterogeneity', 'Histopathology', 'Image', 'Image Analysis', 'Imaging technology', 'Immunohistochemistry', 'Lasers', 'Lead', 'Lesion', 'Malignant Neoplasms', 'Medical', 'Melanins', 'Melanosomes', 'Methods', 'Microscope', 'Microscopy', 'Mole the mammal', 'Molecular', 'Morbidity - disease rate', 'Morphology', 'Neoplasm Metastasis', 'Nevus', 'Outcome', 'Pathologist', 'Patient Care', 'Patients', 'Pigments', 'Principal Component Analysis', 'Protocols documentation', 'Publishing', 'Pump', 'Research', 'Resolution', 'Retrospective Studies', 'Sampling', 'Science', 'Sentinel Lymph Node Biopsy', 'Skin', 'Slide', 'Spatial Distribution', 'Staging', 'Staining method', 'Stains', 'System', 'Testing', 'Text', 'Thick', 'Time', 'Tissues', 'United States National Institutes of Health', 'Validation', 'Variant', 'Woman', 'Work', 'base', 'cancer diagnosis', 'cost', 'diagnostic accuracy', 'eumelanin', 'falls', 'imaging modality', 'improved', 'in vivo', 'insight', 'male', 'melanoma', 'men', 'mortality', 'novel', 'optical imaging', 'pheomelanin', 'public health relevance', 'skin lesion', 'translational medicine', 'two-photon']",NCI,DUKE UNIVERSITY,R01,2013,321376,0.010381356214798909
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9536759,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,619539,0.05318261152261561
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9315773,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Darkness', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Mosaicism', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Standardization', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'reflectance confocal microscopy', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2017,619539,0.05318261152261561
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact).         PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.            ",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,8946754,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'noninvasive diagnosis', 'optical imaging', 'public health relevance', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2015,658985,0.05318261152261561
"Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy ﻿    DESCRIPTION (provided by applicant): Melanoma is diagnosed in approximately 124,000 people and is responsible for about 10,000 deaths every year, in the USA. Dermatologists rely on visual and dermatoscopic examination to discriminate benign melanocytic lesions from malignant, resulting in high and highly variable benign-to-malignant biopsy ratios from 8:1 to 47:1, and millions of unnecessary biopsies of benign lesions. Reflectance confocal microscopy (RCM) imaging has been proven for noninvasively guiding diagnosis of melanoma in several large clinical studies. RCM imaging at the dermal-epidermal junction (DEJ) provides sensitivity of 92-88% and specificity of 71-84%. The specificity is 2 times superior to that of dermatoscopy. RCM imaging at the DEJ is now being implemented to rule out malignancy, reduce biopsy and guide treatment. However, this is currently at only a few sites, where there are highly trained experts who can ensure that imaging is appropriately performed and images are read correctly. These experts are a small international cohort of ""early adopter"" clinicians, who have worked with RCM technology during the past decade and have become highly skilled readers. For novice (non-expert) clinicians in the wider cohort who are keen to adopt RCM, learning to read images is challenging and requires substantial effort and time. Two major technical barriers underlie the dramatic variability in diagnostic accuracy among novice clinicians. Together they limit utility, reproducibility and wider adoption of RCM. The first is user dependent subjective variability in depths near the DEJ at which images are acquired, and the second is variability in interpretation of images. We propose to address these barriers with computational ""multi-faceted"" classification modeling (innovation), image analysis and machine learning algorithms. Our specific aims are: (1) to develop and evaluate algorithms for both dermatoscopic images and RCM depth-stacks, to enable automated standardized and consistent acquisition of RCM mosaics at the DEJ in melanocytic lesions; (2) to develop and evaluate algorithms to discriminate patterns of cellular morphology at the DEJ into two classes, benign lesions versus malignant (dysplastic lesions and melanoma); and (3) to test our algorithms on patients for acquisition of RCM mosaics and classification into those two groups, with statistical validation against pathology, with statistical validation against pathology. Preliminary studies show that our algorithms can delineate the DEJ with accuracy in the range ~3-13 μm in strongly pigmented dark skin and ~5-20 μm in lightly pigmented fair skin, and can detect cellular morphologic patterns with sensitivity in the range 67-80% and specificity 78-99%. Melanocytic lesions can be distinguished from the surrounding normal skin at the DEJ with 80% classification accuracy. We are a team of researchers from Memorial Sloan-Kettering Cancer Center, Northeastern University and University of Modena. Our success will produce standardized imaging and analysis approaches, to advance RCM for noninvasive detection of melanoma. Furthermore, these approaches can be useful for non-melanoma skin cancers, cutaneous lymphoma and other skin disorders (wider impact). PUBLIC HEALTH RELEVANCE: Reflectance confocal microscopy (RCM) is an optical imaging technology that can guide biopsy and enable noninvasive screening and diagnosis of skin cancers. However, visual reading and interpretation of RCM images requires substantial training for clinicians. We propose to develop computer-based algorithms to assist clinicians in reading images, serve as tools for training, and accelerate wider adoption of RCM technology by dermatologists.",Automated Image Guidance for Diagnosing Skin Cancer With Confocal Microscopy,9108343,R01CA199673,"['Address', 'Adolescent', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Area', 'Benign', 'Biometry', 'Biopsy', 'Cellular Morphology', 'Cessation of life', 'Child', 'Classification', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Computers', 'Confocal Microscopy', 'Cutaneous Lymphoma', 'Data', 'Dermal', 'Dermatologist', 'Dermoscopy', 'Detection', 'Diagnosis', 'Diagnostic', 'Drops', 'Early Diagnosis', 'Ensure', 'Epidemiology', 'Glass', 'Health', 'Hypersensitivity skin testing', 'Image', 'Image Analysis', 'Imaging technology', 'International', 'Italy', 'Lateral', 'Learning', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modality', 'Modeling', 'Neoplasm Metastasis', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Pigments', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Reproducibility', 'Research Personnel', 'Resolution', 'Site', 'Skin', 'Skin Cancer', 'Skin Carcinoma', 'Specificity', 'Survival Rate', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Universities', 'Validation', 'Visual', 'Work', 'base', 'burden of illness', 'cancer diagnosis', 'cohort', 'diagnostic accuracy', 'image guided', 'innovation', 'melanoma', 'microscopic imaging', 'noninvasive diagnosis', 'optical imaging', 'quantitative imaging', 'screening', 'skin disorder', 'success', 'tool']",NCI,SLOAN-KETTERING INST CAN RESEARCH,R01,2016,618809,0.05318261152261561
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9976466,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'neural network classifier', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2020,385010,0.07195623045177242
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9751222,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cellular Structures', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'automated analysis', 'base', 'cancer diagnosis', 'clinical database', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'feature detection', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2019,373460,0.07195623045177242
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9523267,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'deep neural network', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'whole slide imaging']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2018,385011,0.07195623045177242
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9322408,R01CA200690,"['Adult', 'Algorithmic Analysis', 'Architecture', 'Area', 'Association Learning', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Reference Standards', 'Research', 'Skin', 'Slide', 'Specimen', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'accurate diagnosis', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool']",NCI,UNIVERSITY OF WASHINGTON,R01,2017,30900,0.07195623045177242
"Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study ABSTRACT  This proposal will help to improve the accuracy of diagnosing melanoma and melanocytic lesions. The incidence of melanoma is rising faster than any other cancer, and ~1 in 50 U.S. adults will be diagnosed with melanoma this year alone. Our research team has noted substantial diagnostic errors in interpreting skin biopsies of melanocytic lesions; pathologists disagree in up to 60% of cases of invasive melanoma, which can lead to substantial patient harm. Our proposal uses computer technology to analyze whole-slide digital images of glass slides in order to improve the diagnosis of melanocytic lesions. Using data from an ongoing NIH study, we will digitize and study a set of 240 skin biopsy cases that includes a full spectrum of benign to invasive melanoma diagnoses. Each biopsy case has a reference consensus diagnosis developed by a panel of three international experts in dermatopathology and new data will be available from 160 practicing U.S. community pathologists, providing a uniquely rich clinical database that is the largest of its kind. This project will include novel computational techniques, including the detection of both cellular-level and architectural entities, and the use of a combination of feature-based and deep neural network classifiers. Our specific aims are: 1. To detect cellular-level entities in digitized whole slide images of melanocytic skin lesions. 2. To detect structural (architectural) entities in digitized whole slide images of melanocytic skin lesions. 3. To develop an automated diagnosis system that can classify digitized slide images into one of five possible diagnostic classes: benign; atypical lesions; melanoma in situ; invasive melanoma stage T1a; and invasive melanoma stage ≥T1b. In our proposed study, we are innovatively using computer image analysis algorithms and machine learning. This technology has the potential to improve the diagnostic accuracy of pathologists by providing an analytical, undeviating review to assist humans in this difficult task. Project Narrative Diagnosis of melanoma and melanocytic skin biopsy lesions is among the most challenging areas of pathology and our preliminary data shows concerning levels of errors among pathologists. Our ultimate goal is to use innovative computer image analysis and machine learning techniques to reduce diagnostic errors and save patients' lives. The first step towards this goal is a correct diagnosis of melanoma.",Improving Melanoma Pathology Accuracy through Computer Vision Techniques - the IMPACT Study,9174605,R01CA200690,"['Adult', 'Algorithms', 'Architecture', 'Area', 'Association Learning', 'Behavior', 'Benign', 'Biological Neural Networks', 'Biopsy', 'Caring', 'Cell Nucleus', 'Cessation of life', 'Characteristics', 'Clinical', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer-Assisted Image Analysis', 'Computers', 'Consensus', 'Data', 'Databases', 'Decision Making', 'Dermatopathology', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Errors', 'Diagnostic Imaging', 'Elderly', 'Evaluation', 'Event', 'Funding', 'Glass', 'Goals', 'Graph', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Individual', 'International', 'Lead', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Microscopic', 'Mitotic', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Precancerous melanosis', 'Process', 'Property', 'Reference Standards', 'Research', 'Scanning', 'Skin', 'Slide', 'Specimen', 'Staging', 'System', 'Techniques', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'cancer diagnosis', 'diagnostic accuracy', 'digital imaging', 'improved', 'innovation', 'interest', 'maltreatment', 'melanocyte', 'melanoma', 'novel', 'skin lesion', 'stem', 'tool', 'visual tracking']",NCI,UNIVERSITY OF WASHINGTON,R01,2016,408063,0.07195623045177242
"Crowdsourcing-aided machine learning for colon cancer prevention ﻿    DESCRIPTION (provided by applicant): Computer-aided detection (CADe) has become a standard tool in diagnostic radiology. Because CADe systems are highly sensitive, they can help radiologists detect abnormalities in medical images. However, CADe systems also detect large numbers of false positives that distract radiologists and reduce their confidence in the CADe technology. Colon cancer is the second leading cause of cancer deaths for men and women in the United States, but it would be preventable by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) has been endorsed as a viable option for colorectal screening under the guidelines of the American Cancer Society, U.S. Multi-Society Task Force, and the American College of Radiology. However, the interpretation of CTC images requires skill and it is time-consuming. The first-reader CADe paradigm, where a radiologist interprets a CTC study by reviewing an image gallery of potential abnormalities detected by CADe at high sensitivity, has recently been shown to provide an accurate workflow for the detection of colorectal lesions. Although most of the false-positive (FP) CADe detections are easy to dismiss even for inexperienced human readers, for a radiologist a review of a large number of CADe detections is tedious, time-consuming, and expensive. If, however, we could use crowdsourcing to distribute the images of high-sensitivity CADe detections to knowledge workers (KWs) who have been trained to dismiss FP CADe detections, we could implement an advanced high-performance CTC interpretation system that yields both high detection sensitivity and specificity. Crowdsourcing with big data can also be used to improve the performance of machine learning that is largely the reason for the low specificity of current CADe systems. The incorporation of big data in the form of large and representative online training databases to improve the classification performance of machine learning can be implemented by identifying relevant new training cases by detecting disagreements between crowdsourcing-based interpretations and computer- estimated lesion likelihoods. The goal of this project is to develop a Crowdsourcing-Aided MachinE Learning (CAMEL) scheme that will integrate machine learning with crowdsourcing for the detection of colorectal lesions in CTC. Although we will use colon CADe as an example system, the proposed concept applies to other CADe applications as well. We hypothesize that the CAMEL scheme will achieve a classification accuracy that is higher than that of machine learning alone and equivalent to that of unaided expert radiologists, and that it can improve radiologists' performance in the detection of clinically significant lesion in CTC. To achieve the goal and to test the study hypothesis, we will explore the following specific aims: (1) Develop a decision support (DES) system which allows human participation; (2) Develop a CAMEL scheme for polyp detection with crowdsourcing; (3) Evaluate the clinical benefit of CAMEL. Successful development of CAMEL will demonstrate the clinical benefit of an engaging crowdsourcing platform for accurate colon cancer screening. PUBLIC HEALTH RELEVANCE: Successful development of Crowdsourcing-Aided MachinE Learning (CAMEL) will demonstrate the clinical benefit of a crowdsourcing platform for accurate colon cancer screening. Because computer-aided detection (CADe) systems excel at detecting lesions (high sensitivity), whereas humans excel at removing false-positive CADe detections (high specificity), a crowdsourcing-assisted machine learning scheme should outperform individual human readers and CADe systems. In long term, broad adoption and use of the CAMEL scheme will facilitate early and accurate diagnoses, and thus will reduce mortality from colon cancer that is the third leading cause of cancer deaths in the United States.",Crowdsourcing-aided machine learning for colon cancer prevention,9269542,UH2CA203730,"['Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Cessation of life', 'Classification', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computers', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnostic', 'Diagnostic radiologic examination', 'Early Diagnosis', 'Evaluation', 'Excision', 'Goals', 'Guidelines', 'High Performance Computing', 'Human', 'Image', 'Individual', 'Knowledge', 'Lesion', 'Machine Learning', 'Medical Imaging', 'Performance', 'Polyps', 'Reader', 'Retrieval', 'Scheme', 'Screening for cancer', 'Sensitivity and Specificity', 'Societies', 'Specificity', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'accurate diagnosis', 'base', 'cancer prevention', 'clinically significant', 'computer aided detection', 'crowdsourcing', 'digital imaging', 'improved', 'men', 'mortality', 'public health relevance', 'radiologist', 'screening', 'skills', 'tool', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,UH2,2017,341979,-5.094611920878204e-05
"Crowdsourcing-aided machine learning for colon cancer prevention DESCRIPTION (provided by applicant): Computer-aided detection (CADe) has become a standard tool in diagnostic radiology. Because CADe systems are highly sensitive, they can help radiologists detect abnormalities in medical images. However, CADe systems also detect large numbers of false positives that distract radiologists and reduce their confidence in the CADe technology. Colon cancer is the second leading cause of cancer deaths for men and women in the United States, but it would be preventable by early detection and removal of its precursor lesions. Computed tomographic colonography (CTC) has been endorsed as a viable option for colorectal screening under the guidelines of the American Cancer Society, U.S. Multi-Society Task Force, and the American College of Radiology. However, the interpretation of CTC images requires skill and it is time-consuming. The first-reader CADe paradigm, where a radiologist interprets a CTC study by reviewing an image gallery of potential abnormalities detected by CADe at high sensitivity, has recently been shown to provide an accurate workflow for the detection of colorectal lesions. Although most of the false-positive (FP) CADe detections are easy to dismiss even for inexperienced human readers, for a radiologist a review of a large number of CADe detections is tedious, time-consuming, and expensive. If, however, we could use crowdsourcing to distribute the images of high-sensitivity CADe detections to knowledge workers (KWs) who have been trained to dismiss FP CADe detections, we could implement an advanced high-performance CTC interpretation system that yields both high detection sensitivity and specificity. Crowdsourcing with big data can also be used to improve the performance of machine learning that is largely the reason for the low specificity of current CADe systems. The incorporation of big data in the form of large and representative online training databases to improve the classification performance of machine learning can be implemented by identifying relevant new training cases by detecting disagreements between crowdsourcing-based interpretations and computer- estimated lesion likelihoods. The goal of this project is to develop a Crowdsourcing-Aided MachinE Learning (CAMEL) scheme that will integrate machine learning with crowdsourcing for the detection of colorectal lesions in CTC. Although we will use colon CADe as an example system, the proposed concept applies to other CADe applications as well. We hypothesize that the CAMEL scheme will achieve a classification accuracy that is higher than that of machine learning alone and equivalent to that of unaided expert radiologists, and that it can improve radiologists' performance in the detection of clinically significant lesion in CTC. To achieve the goal and to test the study hypothesis, we will explore the following specific aims: (1) Develop a decision support (DES) system which allows human participation; (2) Develop a CAMEL scheme for polyp detection with crowdsourcing; (3) Evaluate the clinical benefit of CAMEL. Successful development of CAMEL will demonstrate the clinical benefit of an engaging crowdsourcing platform for accurate colon cancer screening. PUBLIC HEALTH RELEVANCE: Successful development of Crowdsourcing-Aided MachinE Learning (CAMEL) will demonstrate the clinical benefit of a crowdsourcing platform for accurate colon cancer screening. Because computer-aided detection (CADe) systems excel at detecting lesions (high sensitivity), whereas humans excel at removing false-positive CADe detections (high specificity), a crowdsourcing-assisted machine learning scheme should outperform individual human readers and CADe systems. In long term, broad adoption and use of the CAMEL scheme will facilitate early and accurate diagnoses, and thus will reduce mortality from colon cancer that is the third leading cause of cancer deaths in the United States.",Crowdsourcing-aided machine learning for colon cancer prevention,9077924,UH2CA203730,"['Adoption', 'Advisory Committees', 'American Cancer Society', 'American College of Radiology', 'Big Data', 'Biological Neural Networks', 'Biopsy', 'Cancer Etiology', 'Cessation of life', 'Classification', 'Clinical', 'Colon', 'Colon Carcinoma', 'Colonoscopy', 'Colorectal', 'Computed Tomographic Colonography', 'Computer Vision Systems', 'Computers', 'Databases', 'Decision Support Systems', 'Detection', 'Development', 'Diagnostic', 'Diagnostic radiologic examination', 'Early Diagnosis', 'Evaluation', 'Excision', 'Goals', 'Guidelines', 'Health', 'High Performance Computing', 'Human', 'Image', 'Individual', 'Knowledge', 'Lesion', 'Machine Learning', 'Medical Imaging', 'Performance', 'Polyps', 'Reader', 'Retrieval', 'Scheme', 'Sensitivity and Specificity', 'Societies', 'Specificity', 'System', 'Technology', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'accurate diagnosis', 'base', 'cancer prevention', 'clinically significant', 'computer aided detection', 'crowdsourcing', 'improved', 'men', 'mortality', 'radiologist', 'screening', 'skills', 'tool', 'virtual']",NCI,MASSACHUSETTS GENERAL HOSPITAL,UH2,2016,341897,-5.094611920878204e-05
"Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization. PROJECT SUMMARY / ABSTRACT Modern digital pathology departments produce a tremendous amount of whole slide image data, which is quickly growing to petabyte scale. This plethora of data presents an unprecedented treasure chest for all kinds of medical machine learning tasks, including improvements in precision medicine.  Unfortunately, the vast majority of digital slides are not annotated on the image level, so histological points of interest are not integrated with the clinical notes or genetics associated with a patient. In contrast to other disciplines, manual labeling is not only cumbersome and time-consuming, but given the decades-long training of a pathologist, it is exorbitantly expensive and, due to clinical time constraints, impractical. Moreover, the time- dependent relationship between a patient's histology and genotype is not quantitatively leveraged to recommend combination therapies. Genetics informs us of important driver mutations, but how multiple cell types interact with these mutants over time in the tumor microenvironment to become histologically evident is less clear.  Deep learning synthesizes generations of pathologist knowledge as accurate quantitative models. Given a picture of a patient's morphology, I provide a tool that in four seconds finds the top ten most similar patients with their diagnoses, to support a pathologist's diagnosis decisions under the time pressures of active surgery. Recording the pathologist inspecting a slide at the microscope automatically annotates observed slide regions with time. Not only amenable for learning models that predict whether or not a region is salient to a pathologist making a diagnosis, this also allows all slides in a hospital to be annotated to identical criteria with only a representative sample of slides. I have submitted a manuscript reporting 85.15% accuracy in this saliency prediction task. This annotation greatly simplifies machine learning tasks, which can now focus on a non-redundant set of diagnostic regions in the slide, whether the application is to (a) find similar patients by morphology for diagnosis or (b) relate diagnostic morphology to the genetics.  Statistically modeling the relationship of the genotype to the histological phenotype in cancer opens promising new avenues in precision medicine. Taking a Big Data approach, I will leverage over 18,244 paired genome-histology samples to learn this model, using transfer learning techniques to maximize the value of all 18,244 samples for each tissue type. Genotype-phenotype model in hand, I will simulate the molecular clock in cancer, incrementally mutating the genome and predicting corresponding histology at each molecular time step. Through similar Q-learning that powers Google's champion artificial intelligence ``AlphaGo'', I will learn an agent that inhibits expression of a small set of mutant genes to maximize cancer progression-free survival time, by molecular time in the simulator. This not only measures the therapy's evolutionary durability, but also leads directly to experimentally testable hypotheses in 3D cell culture. PROJECT NARRATIVE / PUBLIC HEALTH RELEVANCE STATEMENT Digitized whole slide images of cancer tissue are a ``dark matter'' in the clinic, data that are often collected but rarely used quantitatively to model cancer or personalize medicine. I will, through close collaborations with practicing pathologists at globally leading cancer research hospitals, form statistical models of the histology evident in whole slides to (i) create clinical decision support tools that find similar patients by morphology alone to disambiguate cases that are difficult for a pathologist to diagnose under the time pressures of ongoing surgery, (ii) create a tool that learns which parts of a whole slide image are salient for a pathologist at the microscope to make a diagnosis, which greatly facilitates the deep learning techniques underlying [i] and [iii] by discarding redundant histological image data, and (iii) create a system that relates genotype to histological phenotype in cancer and learns an agent which leverages this system to determine the optimal multistage combination therapy to drive the histology towards health such that cancer progression-free survival time is maximized in the patient of interest. In this way, my statistical models will transform the vast dark matter of diagnosed histology data, representing generations of pathologist knowledge at these leading hospitals, into an indispensable resource for surgery, pathology, genetics, and precision medicine.","Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization.",9637337,F31CA214029,"['Archives', 'Artificial Intelligence', 'Big Data', 'CDH1 gene', 'Cancer Model', 'Cells', 'Chest', 'Clinic', 'Clinical', 'Clinical Markers', 'Collaborations', 'Color', 'Combined Modality Therapy', 'Computers', 'Computing Methodologies', 'Consumption', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Discipline', 'Drug Combinations', 'Evaluation', 'Excision', 'FGFR3 gene', 'Farming environment', 'Freezing', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Medicine', 'Genome', 'Genomics', 'Genotype', 'Hand', 'Health', 'Histologic', 'Histology', 'Hospitals', 'Image', 'Immunohistochemistry', 'Knowledge', 'Label', 'Learning', 'Life', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of urinary bladder', 'Manuals', 'Manuscripts', 'Maps', 'Measures', 'Medical', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Molecular', 'Morphology', 'Mutate', 'Mutation', 'Operative Surgical Procedures', 'Pathologist', 'Pathology', 'Patients', 'Pattern Recognition', 'Peripheral', 'Pharmaceutical Preparations', 'Phenotype', 'Progression-Free Survivals', 'Prostate', 'Psychological Transfer', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Retrieval', 'Sampling', 'Savings', 'Scanning', 'Second Opinions', 'Slide', 'Statistical Models', 'System', 'TMPRSS2 gene', 'Techniques', 'Texture', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'Tumor Suppressor Genes', 'Vision', 'Visual', 'actionable mutation', 'anticancer research', 'autoencoder', 'base', 'cancer genome', 'cancer imaging', 'cell type', 'clinical decision support', 'clinical practice', 'dark matter', 'deep learning', 'digital', 'digital pathology', 'histological image', 'histological specimens', 'improved', 'interest', 'microscopic imaging', 'molecular clock', 'molecular marker', 'mutant', 'overexpression', 'personalized medicine', 'petabyte', 'precision medicine', 'predictive modeling', 'pressure', 'public health relevance', 'screening', 'support tools', 'three dimensional cell culture', 'tool', 'transcriptome sequencing', 'treatment optimization', 'tumor', 'tumor heterogeneity', 'tumor microenvironment', 'tumor progression', 'whole slide imaging']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,F31,2019,45016,0.007602629124237633
"Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization. PROJECT SUMMARY / ABSTRACT Modern digital pathology departments produce a tremendous amount of whole slide image data, which is quickly growing to petabyte scale. This plethora of data presents an unprecedented treasure chest for all kinds of medical machine learning tasks, including improvements in precision medicine.  Unfortunately, the vast majority of digital slides are not annotated on the image level, so histological points of interest are not integrated with the clinical notes or genetics associated with a patient. In contrast to other disciplines, manual labeling is not only cumbersome and time-consuming, but given the decades-long training of a pathologist, it is exorbitantly expensive and, due to clinical time constraints, impractical. Moreover, the time- dependent relationship between a patient's histology and genotype is not quantitatively leveraged to recommend combination therapies. Genetics informs us of important driver mutations, but how multiple cell types interact with these mutants over time in the tumor microenvironment to become histologically evident is less clear.  Deep learning synthesizes generations of pathologist knowledge as accurate quantitative models. Given a picture of a patient's morphology, I provide a tool that in four seconds finds the top ten most similar patients with their diagnoses, to support a pathologist's diagnosis decisions under the time pressures of active surgery. Recording the pathologist inspecting a slide at the microscope automatically annotates observed slide regions with time. Not only amenable for learning models that predict whether or not a region is salient to a pathologist making a diagnosis, this also allows all slides in a hospital to be annotated to identical criteria with only a representative sample of slides. I have submitted a manuscript reporting 85.15% accuracy in this saliency pre- diction task. This annotation greatly simplifies machine learning tasks, which can now focus on a non-redundant set of diagnostic regions in the slide, whether the application is to (a) find similar patients by morphology for diagnosis or (b) relate diagnostic morphology to the genetics.  Statistically modeling the relationship of the genotype to the histological phenotype in cancer opens promising new avenues in precision medicine. Taking a Big Data approach, I will leverage over 18,244 paired genome-histology samples to learn this model, using transfer learning techniques to maximize the value of all 18,244 samples for each tissue type. Genotype-phenotype model in hand, I will simulate the molecular clock in cancer, incrementally mutating the genome and predicting corresponding histology at each molecular time step. Through similar Q-learning that powers Google's champion artificial intelligence ``AlphaGo'', I will learn an agent that inhibits expression of a small set of mutant genes to maximize cancer progression-free survival time, by molecular time in the simulator. This not only measures the therapy's evolutionary durability, but also leads directly to experimentally testable hypotheses in 3D cell culture. PROJECT NARRATIVE / PUBLIC HEALTH RELEVANCE STATEMENT Digitized whole slide images of cancer tissue are a ``dark matter'' in the clinic, data that are often collected but rarely used quantitatively to model cancer or personalize medicine. I will, through close collaborations with practicing pathologists at globally leading cancer research hospitals, form statistical models of the histology evident in whole slides to (i) create clinical decision support tools that find similar patients by morphology alone to disambiguate cases that are difficult for a pathologist to diagnose under the time pressures of ongoing surgery, (ii) create a tool that learns which parts of a whole slide image are salient for a pathologist at the microscope to make a diagnosis, which greatly facilitates the deep learning techniques underlying [i] and [iii] by discarding redundant histological image data, and (iii) create a system that relates genotype to histological phenotype in cancer and learns an agent which leverages this system to determine the optimal multistage combination therapy to drive the histology towards health such that cancer progression-free survival time is maximized in the patient of interest. In this way, my statistical models will transform the vast dark matter of diagnosed histology data, representing generations of pathologist knowledge at these leading hospitals, into an indispensable resource for surgery, pathology, genetics, and precision medicine.","Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization.",9416817,F31CA214029,"['Archives', 'Artificial Intelligence', 'Big Data', 'CDH1 gene', 'Cancer Model', 'Cells', 'Chest', 'Clinic', 'Clinical', 'Clinical Markers', 'Collaborations', 'Color', 'Combined Modality Therapy', 'Computers', 'Computing Methodologies', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Discipline', 'Drug Combinations', 'Evaluation', 'Excision', 'FGFR3 gene', 'Farming environment', 'Freezing', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Medicine', 'Genome', 'Genomics', 'Genotype', 'Hand', 'Health', 'Histologic', 'Histology', 'Hospitals', 'Image', 'Immunohistochemistry', 'Knowledge', 'Label', 'Learning', 'Life', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of urinary bladder', 'Manuals', 'Manuscripts', 'Maps', 'Measures', 'Medical', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Molecular', 'Morphology', 'Mutate', 'Mutation', 'Operative Surgical Procedures', 'Pathologist', 'Pathology', 'Patients', 'Pattern Recognition', 'Peripheral', 'Pharmaceutical Preparations', 'Phenotype', 'Progression-Free Survivals', 'Prostate', 'Psychological Transfer', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Retreatment', 'Retrieval', 'Sampling', 'Savings', 'Scanning', 'Second Opinions', 'Slide', 'Statistical Models', 'System', 'TMPRSS2 gene', 'Techniques', 'Texture', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'Tumor Suppressor Genes', 'Vision', 'Visual', 'actionable mutation', 'anticancer research', 'base', 'cancer genome', 'cancer imaging', 'cell type', 'clinical decision support', 'clinical practice', 'dark matter', 'deep learning', 'digital', 'digital pathology', 'histological image', 'histological specimens', 'improved', 'interest', 'microscopic imaging', 'molecular marker', 'mutant', 'overexpression', 'personalized medicine', 'petabyte', 'precision medicine', 'predictive modeling', 'pressure', 'public health relevance', 'screening', 'support tools', 'three dimensional cell culture', 'tool', 'transcriptome sequencing', 'treatment optimization', 'tumor', 'tumor heterogeneity', 'tumor microenvironment', 'tumor progression', 'whole slide imaging']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,F31,2018,44524,0.007602629124237633
"Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization. PROJECT SUMMARY / ABSTRACT Modern digital pathology departments produce a tremendous amount of whole slide image data, which is quickly growing to petabyte scale. This plethora of data presents an unprecedented treasure chest for all kinds of medical machine learning tasks, including improvements in precision medicine.  Unfortunately, the vast majority of digital slides are not annotated on the image level, so histological points of interest are not integrated with the clinical notes or genetics associated with a patient. In contrast to other disciplines, manual labeling is not only cumbersome and time-consuming, but given the decades-long training of a pathologist, it is exorbitantly expensive and, due to clinical time constraints, impractical. Moreover, the time- dependent relationship between a patient's histology and genotype is not quantitatively leveraged to recommend combination therapies. Genetics informs us of important driver mutations, but how multiple cell types interact with these mutants over time in the tumor microenvironment to become histologically evident is less clear.  Deep learning synthesizes generations of pathologist knowledge as accurate quantitative models. Given a picture of a patient's morphology, I provide a tool that in four seconds finds the top ten most similar patients with their diagnoses, to support a pathologist's diagnosis decisions under the time pressures of active surgery. Recording the pathologist inspecting a slide at the microscope automatically annotates observed slide regions with time. Not only amenable for learning models that predict whether or not a region is salient to a pathologist making a diagnosis, this also allows all slides in a hospital to be annotated to identical criteria with only a representative sample of slides. I have submitted a manuscript reporting 85.15% accuracy in this saliency pre- diction task. This annotation greatly simplifies machine learning tasks, which can now focus on a non-redundant set of diagnostic regions in the slide, whether the application is to (a) find similar patients by morphology for diagnosis or (b) relate diagnostic morphology to the genetics.  Statistically modeling the relationship of the genotype to the histological phenotype in cancer opens promising new avenues in precision medicine. Taking a Big Data approach, I will leverage over 18,244 paired genome-histology samples to learn this model, using transfer learning techniques to maximize the value of all 18,244 samples for each tissue type. Genotype-phenotype model in hand, I will simulate the molecular clock in cancer, incrementally mutating the genome and predicting corresponding histology at each molecular time step. Through similar Q-learning that powers Google's champion artificial intelligence ``AlphaGo'', I will learn an agent that inhibits expression of a small set of mutant genes to maximize cancer progression-free survival time, by molecular time in the simulator. This not only measures the therapy's evolutionary durability, but also leads directly to experimentally testable hypotheses in 3D cell culture. PROJECT NARRATIVE / PUBLIC HEALTH RELEVANCE STATEMENT Digitized whole slide images of cancer tissue are a ``dark matter'' in the clinic, data that are often collected but rarely used quantitatively to model cancer or personalize medicine. I will, through close collaborations with practicing pathologists at globally leading cancer research hospitals, form statistical models of the histology evident in whole slides to (i) create clinical decision support tools that find similar patients by morphology alone to disambiguate cases that are difficult for a pathologist to diagnose under the time pressures of ongoing surgery, (ii) create a tool that learns which parts of a whole slide image are salient for a pathologist at the microscope to make a diagnosis, which greatly facilitates the deep learning techniques underlying [i] and [iii] by discarding redundant histological image data, and (iii) create a system that relates genotype to histological phenotype in cancer and learns an agent which leverages this system to determine the optimal multistage combination therapy to drive the histology towards health such that cancer progression-free survival time is maximized in the patient of interest. In this way, my statistical models will transform the vast dark matter of diagnosed histology data, representing generations of pathologist knowledge at these leading hospitals, into an indispensable resource for surgery, pathology, genetics, and precision medicine.","Genotype and Histological Phenotype Relationships in Cancer, with Automated Therapy Optimization.",9258847,F31CA214029,"['Archives', 'Artificial Intelligence', 'Big Data', 'CDH1 gene', 'Cancer Model', 'Cells', 'Chest', 'Clinic', 'Clinical', 'Clinical Markers', 'Collaborations', 'Color', 'Combined Modality Therapy', 'Computers', 'Computing Methodologies', 'DNA', 'Data', 'Diagnosis', 'Diagnostic', 'Discipline', 'Drug Combinations', 'Evaluation', 'Excision', 'FGFR3 gene', 'Farming environment', 'Freezing', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Medicine', 'Genome', 'Genomics', 'Genotype', 'Hand', 'Health', 'Histologic', 'Histology', 'Hospitals', 'Image', 'Immunohistochemistry', 'Knowledge', 'Label', 'Learning', 'Life', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of urinary bladder', 'Manuals', 'Manuscripts', 'Maps', 'Measures', 'Medical', 'Memorial Sloan-Kettering Cancer Center', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Molecular', 'Morphology', 'Mutate', 'Mutation', 'Operative Surgical Procedures', 'Pathologist', 'Pathology', 'Patients', 'Pattern Recognition', 'Peripheral', 'Pharmaceutical Preparations', 'Phenotype', 'Progression-Free Survivals', 'Prostate', 'Psychological Transfer', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Retreatment', 'Retrieval', 'Sampling', 'Savings', 'Scanning', 'Second Opinions', 'Slide', 'Statistical Models', 'System', 'TMPRSS2 gene', 'Techniques', 'Texture', 'Time', 'Tissue imaging', 'Tissues', 'Training', 'Tumor Suppressor Genes', 'Vision', 'Visual', 'actionable mutation', 'anticancer research', 'base', 'cancer genome', 'cancer imaging', 'cell type', 'clinical practice', 'dark matter', 'digital', 'histological image', 'histological specimens', 'improved', 'interest', 'microscopic imaging', 'molecular marker', 'mutant', 'overexpression', 'personalized medicine', 'petabyte', 'precision medicine', 'predictive modeling', 'pressure', 'public health relevance', 'screening', 'support tools', 'three dimensional cell culture', 'tool', 'transcriptome sequencing', 'tumor', 'tumor heterogeneity', 'tumor microenvironment', 'tumor progression']",NCI,WEILL MEDICAL COLL OF CORNELL UNIV,F31,2017,44044,0.007602629124237633
"Assessing the Robustness of Radiogenomic Associations using Deep Neural Networks in Glioblastoma Multiforme Project Summary/Abstract Background: The generation of high-throughput methods in molecular biology and medical imaging has motivated the need to better understand multimodal cancer patient data. This motivation has led to the development of radiogenomics, the study of the connection between a tumor’s underlying molecular traits and its clinical and imaging phenotypes. Radiogenomic analyses provide an opportunity to identify “imaging surrogates” for inferring gene expression. This is clinically applicable for patients with glioblastoma multiforme (GBM) who routinely undergo magnetic resonance (MR) imaging. However, current radiogenomic approaches make strong algorithmic assumptions, and results are potentially biased due to the many different ways that data is preprocessed and selected. The goals of this proposal are to (1) develop new radiogenomic models for identify imaging surrogates, and (2) systematically assess the robustness of radiogenomic findings. Aim 1: To evaluate the application of deep neural networks to discover radiogenomic associations. Aim 2: To compare resultant radiogenomic associations given different model inputs. Aim 3: To determine if the use of radiomic features increases specificity of radiogenomic associations. Methods: In Aim 1, deep neural networks will be trained on public GBM data from The Cancer Genome Atlas and Ivy Glioblastoma Atlas Project (gene expression), and The Cancer Imaging Archive (paired MR images). The model will take high-dimensional gene expression data and predict semantic imaging phenotypes derived from semi-automatically segmented regions-of-interest (ROIs) on MR images. To enable learning of deep networks, the gene expression profile of each patient will be parsed into numerous sparse vectors that encode molecular pathway information. After training, “activation maxi- mization” will extract imaging surrogates from the deep neural network. In Aim 2, a set of common feature selection methods will be applied to the gene expression data. Subsequently, the altered gene data will be the input to deep network to test their ability to derive consistent imaging surrogates. In Aim 3, radiomic features such as histogram and textural features will be extracted from the same ROIs segmented in Aim 1. Instead of semantic imaging phenotypes as the target output, the deep networks will take gene expression data and predict radiomic features. The inferred genes in each imaging surrogate from Aims 1–3 will be annotated with gene set enrichment analysis (GSEA) using several major biological knowledge bases as reference gene sets. Enrichment scores will be normalized, assessed for significance using permutation testing, and corrected for multiple hypothesis testing using the Benjamini-Hochberg method. Long-term Objective: The development and systematic evaluation of radiogenomic methods will help characterize the extent of overlapping information across biological scales in multimodal cancer patient data. Relevance to Public Health The generation of high-throughput methods in molecular biology and medical imaging has motivated the need to better understand multimodal cancer patient data. This research aims to develop new models to correlate tumor gene expression and its appearance in magnetic resonance images, and to perform a systematic evaluation of radiogenomic methods to study their robustness in identifying meaningful biological mechanisms.",Assessing the Robustness of Radiogenomic Associations using Deep Neural Networks in Glioblastoma Multiforme,9656869,F31CA221061,"['Address', 'Affect', 'Algorithms', 'Appearance', 'Atlases', 'Biological', 'Cancer Patient', 'Clinical', 'Complex', 'Computational algorithm', 'Data', 'Data Quality', 'Development', 'Dimensions', 'Edema', 'Evaluation', 'Gene Chips', 'Gene Expression', 'Gene Expression Profile', 'Generations', 'Genes', 'Glioblastoma', 'Goals', 'Image', 'Lead', 'Learning', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Motivation', 'Nature', 'Neural Network Simulation', 'Non-Small-Cell Lung Carcinoma', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Population', 'Primary carcinoma of the liver cells', 'Procedures', 'Public Health', 'Radiogenomics', 'Research', 'Semantics', 'Specificity', 'Statistical Methods', 'Techniques', 'Testing', 'Texture', 'The Cancer Genome Atlas', 'Tissue Sample', 'Training', 'Tumor Biology', 'Tweens', 'Uncertainty', 'Work', 'base', 'cancer imaging', 'clinical application', 'clinical practice', 'cluster computing', 'cohort', 'comparative', 'deep learning', 'deep neural network', 'genomic data', 'high dimensionality', 'image archival system', 'interest', 'knowledge base', 'learning strategy', 'malignant breast neoplasm', 'molecular imaging', 'multimodality', 'novel', 'quantitative imaging', 'radiological imaging', 'radiologist', 'radiomics', 'trait', 'transcriptome sequencing', 'tumor', 'vector']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,F31,2019,39107,0.0225408787151934
"Assessing the Robustness of Radiogenomic Associations using Deep Neural Networks in Glioblastoma Multiforme Project Summary/Abstract Background: The generation of high-throughput methods in molecular biology and medical imaging has motivated the need to better understand multimodal cancer patient data. This motivation has led to the development of radiogenomics, the study of the connection between a tumor’s underlying molecular traits and its clinical and imaging phenotypes. Radiogenomic analyses provide an opportunity to identify “imaging surrogates” for inferring gene expression. This is clinically applicable for patients with glioblastoma multiforme (GBM) who routinely undergo magnetic resonance (MR) imaging. However, current radiogenomic approaches make strong algorithmic assumptions, and results are potentially biased due to the many different ways that data is preprocessed and selected. The goals of this proposal are to (1) develop new radiogenomic models for identify imaging surrogates, and (2) systematically assess the robustness of radiogenomic findings. Aim 1: To evaluate the application of deep neural networks to discover radiogenomic associations. Aim 2: To compare resultant radiogenomic associations given different model inputs. Aim 3: To determine if the use of radiomic features increases specificity of radiogenomic associations. Methods: In Aim 1, deep neural networks will be trained on public GBM data from The Cancer Genome Atlas and Ivy Glioblastoma Atlas Project (gene expression), and The Cancer Imaging Archive (paired MR images). The model will take high-dimensional gene expression data and predict semantic imaging phenotypes derived from semi-automatically segmented regions-of-interest (ROIs) on MR images. To enable learning of deep networks, the gene expression profile of each patient will be parsed into numerous sparse vectors that encode molecular pathway information. After training, “activation maxi- mization” will extract imaging surrogates from the deep neural network. In Aim 2, a set of common feature selection methods will be applied to the gene expression data. Subsequently, the altered gene data will be the input to deep network to test their ability to derive consistent imaging surrogates. In Aim 3, radiomic features such as histogram and textural features will be extracted from the same ROIs segmented in Aim 1. Instead of semantic imaging phenotypes as the target output, the deep networks will take gene expression data and predict radiomic features. The inferred genes in each imaging surrogate from Aims 1–3 will be annotated with gene set enrichment analysis (GSEA) using several major biological knowledge bases as reference gene sets. Enrichment scores will be normalized, assessed for significance using permutation testing, and corrected for multiple hypothesis testing using the Benjamini-Hochberg method. Long-term Objective: The development and systematic evaluation of radiogenomic methods will help characterize the extent of overlapping information across biological scales in multimodal cancer patient data. Relevance to Public Health The generation of high-throughput methods in molecular biology and medical imaging has motivated the need to better understand multimodal cancer patient data. This research aims to develop new models to correlate tumor gene expression and its appearance in magnetic resonance images, and to perform a systematic evaluation of radiogenomic methods to study their robustness in identifying meaningful biological mechanisms.",Assessing the Robustness of Radiogenomic Associations using Deep Neural Networks in Glioblastoma Multiforme,9470767,F31CA221061,"['Address', 'Affect', 'Algorithms', 'Appearance', 'Atlases', 'Biological', 'Cancer Patient', 'Clinical', 'Complex', 'Computational algorithm', 'Data', 'Data Quality', 'Development', 'Dimensions', 'Edema', 'Evaluation', 'Gene Chips', 'Gene Expression', 'Gene Expression Profile', 'Generations', 'Genes', 'Glioblastoma', 'Goals', 'Image', 'Lead', 'Learning', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Motivation', 'Nature', 'Neural Network Simulation', 'Non-Small-Cell Lung Carcinoma', 'Output', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Phenotype', 'Population', 'Primary carcinoma of the liver cells', 'Procedures', 'Public Health', 'Radiogenomics', 'Research', 'Semantics', 'Specificity', 'Statistical Methods', 'Techniques', 'Testing', 'Texture', 'The Cancer Genome Atlas', 'Tissue Sample', 'Training', 'Tumor Biology', 'Tweens', 'Uncertainty', 'Work', 'base', 'cancer imaging', 'clinical application', 'clinical practice', 'cluster computing', 'cohort', 'comparative', 'deep learning', 'deep neural network', 'genomic data', 'high dimensionality', 'image archival system', 'interest', 'knowledge base', 'learning strategy', 'malignant breast neoplasm', 'molecular imaging', 'multimodality', 'novel', 'quantitative imaging', 'radiological imaging', 'radiologist', 'radiomics', 'trait', 'transcriptome sequencing', 'tumor', 'vector']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,F31,2018,38615,0.0225408787151934
"Learning radiomic signatures to early predict response of rectal cancer patients to neoadjuvant chemoradiation therapy Abstract Colorectal cancer is the 3rd most common newly diagnosed cancer and the 3rd most common cause of cancer death among US men and women. Neoadjuvant chemoradiation therapy (CRT) followed by total mesorectal excision is the standard of care for locally advanced rectal cancer. Preoperative CRT has clearly improved rates of local disease control and colostomy free survival; however the response to therapy is heterogeneous. It would be very useful to be able to predict the individual risk of each patient, so that their therapy can be personalized. The goal of our study is to derive clinically useful radiomic signatures from multimodal imaging data for the early prediction of treatment outcomes in rectal cancer patients. Central to our methodology are 1) an improved deep learning model for automatically segmenting tumors from multimodal imaging data with high accuracy; and 2) a multi-task deep learning model for robustly learning informative radiomic features to predict survival and recurrence. These methods will be used to derive individualized predictive indices of treatment outcomes based on a multimodal imaging dataset of rectal cancer patients who have received preoperative CRT. Our methods are generally applicable to radiomic studies of cancer patients. All methods will be made publicly available and form an important new resource for the broader radiomics community. Project Narrative This project will develop multimodal imaging data analytic tools for the early prediction of treatment outcomes in rectal cancer patients who have received preoperative neoadjuvant chemoradiation therapy.",Learning radiomic signatures to early predict response of rectal cancer patients to neoadjuvant chemoradiation therapy,9438989,R21CA223358,"['Address', 'Age-Years', 'Appearance', 'Biological Neural Networks', 'Cancer Etiology', 'Cancer Patient', 'Carcinoembryonic Antigen', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Colorectal Cancer', 'Colostomy Procedure', 'Communities', 'Data', 'Data Analytics', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Distant Metastasis', 'Excision', 'Fascia', 'Goals', 'Hand', 'Hand functions', 'Hemoglobin', 'Image', 'Incidence', 'Individual', 'Learning', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Mesorectal', 'Methodology', 'Methods', 'Modeling', 'Multimodal Imaging', 'Neoadjuvant Therapy', 'Newly Diagnosed', 'Nodal', 'Noise', 'PET/CT scan', 'Pathologic', 'Patients', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Performance', 'Play', 'Prediction of Response to Therapy', 'Proportional Hazards Models', 'Radiation Oncology', 'Rectal Cancer', 'Rectal Neoplasms', 'Recurrence', 'Relapse', 'Reproducibility', 'Resources', 'Risk', 'Role', 'Serum', 'Sphincter', 'Survival Analysis', 'System', 'Techniques', 'Total Mesorectal Excision', 'Treatment outcome', 'Tumor stage', 'Universities', 'Woman', 'analytical tool', 'base', 'cancer diagnosis', 'chemoradiation', 'deep learning', 'deep neural network', 'disorder control', 'fluorodeoxyglucose positron emission tomography', 'imaging Segmentation', 'improved', 'indexing', 'learning strategy', 'men', 'multimodality', 'multitask', 'novel strategies', 'partial response', 'personalized predictions', 'predicting response', 'predictive modeling', 'radiomics', 'rectal', 'response', 'standard of care', 'survival prediction', 'tool', 'treatment response', 'tumor']",NCI,UNIVERSITY OF PENNSYLVANIA,R21,2018,210105,0.028799184154612384
"Learning radiomic signatures to early predict response of rectal cancer patients to neoadjuvant chemoradiation therapy Abstract Colorectal cancer is the 3rd most common newly diagnosed cancer and the 3rd most common cause of cancer death among US men and women. Neoadjuvant chemoradiation therapy (CRT) followed by total mesorectal excision is the standard of care for locally advanced rectal cancer. Preoperative CRT has clearly improved rates of local disease control and colostomy free survival; however the response to therapy is heterogeneous. It would be very useful to be able to predict the individual risk of each patient, so that their therapy can be personalized. The goal of our study is to derive clinically useful radiomic signatures from multimodal imaging data for the early prediction of treatment outcomes in rectal cancer patients. Central to our methodology are 1) an improved deep learning model for automatically segmenting tumors from multimodal imaging data with high accuracy; and 2) a multi-task deep learning model for robustly learning informative radiomic features to predict survival and recurrence. These methods will be used to derive individualized predictive indices of treatment outcomes based on a multimodal imaging dataset of rectal cancer patients who have received preoperative CRT. Our methods are generally applicable to radiomic studies of cancer patients. All methods will be made publicly available and form an important new resource for the broader radiomics community. Project Narrative This project will develop multimodal imaging data analytic tools for the early prediction of treatment outcomes in rectal cancer patients who have received preoperative neoadjuvant chemoradiation therapy.",Learning radiomic signatures to early predict response of rectal cancer patients to neoadjuvant chemoradiation therapy,9619051,R21CA223358,"['Address', 'Age-Years', 'Algorithms', 'Appearance', 'Cancer Etiology', 'Cancer Patient', 'Carcinoembryonic Antigen', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Colorectal Cancer', 'Colostomy Procedure', 'Communities', 'Data', 'Data Analytics', 'Data Set', 'Diagnosis', 'Diagnostic', 'Disease', 'Distant Metastasis', 'Excision', 'Fascia', 'Goals', 'Hand', 'Hand functions', 'Hemoglobin', 'Image', 'Incidence', 'Individual', 'Learning', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Mesorectal', 'Methodology', 'Methods', 'Modeling', 'Multimodal Imaging', 'Neoadjuvant Therapy', 'Newly Diagnosed', 'Nodal', 'Noise', 'PET/CT scan', 'Pathologic', 'Patients', 'Pattern', 'Pattern Recognition', 'Pennsylvania', 'Performance', 'Play', 'Prediction of Response to Therapy', 'Proportional Hazards Models', 'Radiation Oncology', 'Rectal Cancer', 'Rectal Neoplasms', 'Recurrence', 'Relapse', 'Reproducibility', 'Resources', 'Risk', 'Role', 'Serum', 'Sphincter', 'Survival Analysis', 'System', 'Techniques', 'Total Mesorectal Excision', 'Treatment outcome', 'Tumor stage', 'Universities', 'Woman', 'analytical tool', 'base', 'cancer diagnosis', 'chemoradiation', 'convolutional neural network', 'deep learning', 'deep neural network', 'disorder control', 'fluorodeoxyglucose positron emission tomography', 'imaging Segmentation', 'improved', 'indexing', 'learning strategy', 'men', 'multimodal data', 'multitask', 'novel strategies', 'partial response', 'personalized predictions', 'predicting response', 'predictive modeling', 'preservation', 'radiomics', 'rectal', 'response', 'standard of care', 'survival prediction', 'tool', 'treatment response', 'tumor']",NCI,UNIVERSITY OF PENNSYLVANIA,R21,2019,169834,0.028799184154612384
"A Computer Aided Diagnosis(CAD) Algorithm for Identification of Dysplasia in Patients with Barrett Esophagus ABSTRACT The goal of this project is to develop a based computer aided diagnosis (CAD) algorithm for identification of regions at risk for developing esophageal adenocarcinoma (EAC) in optical coherence tomography (OCT) scans of the esophagus. EAC is one of the deadliest cancers with a 5-year survival rate of less than 20%; yet the standard of care for detecting precursors to EAC is widely recognized to be inadequate. Just recently, a study found that 25% of patients who underwent a standard endoscopic surveillance exam which was found to be ‘clear’ then went on and progressed to EAC within one year. Clearly today’s approach is not working and a significant percentage of disease is being missed. While comprehensive esophageal OCT imaging has shown great potential in addressing this unmet clinical need, one of the main limiters to wider adoption and impact of this technology is the challenge of interpreting the large volume of high-resolution images in real-time. A CAD algorithm would allow OCT to realize its promise in this field and significantly improve the standard of care. Here we propose the development of a deep learning CAD algorithm which will operate on a full patient level volumetric dataset with awareness of the anatomy, robust against image quality and motion artifacts, and trained and validated against a large dataset (>1000 patients). We will aim to reach a sensitivity and specificity of 90/80% based on a threshold set by the American Society for Gastroenterology (ASGE) for the performance of advanced imaging in the detection of high grade dysplasia in BE. PROJECT NARRATIVE The goal of this project is to develop a computer aided diagnosis (CAD) algorithm for use with the NinePoint Medical OCT imaging system and provide early detection of pre-cancerous lesions. Earlier detection leads to earlier treatment, more positive health outcomes for patients and lower healthcare system costs.",A Computer Aided Diagnosis(CAD) Algorithm for Identification of Dysplasia in Patients with Barrett Esophagus,9622504,R43CA232860,"['Address', 'Adoption', 'Algorithms', 'American', 'Anatomy', 'Architecture', 'Awareness', 'Barrett Esophagus', 'Biopsy', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic', 'Disease', 'Dysplasia', 'Early Diagnosis', 'Early treatment', 'Epithelium', 'Esophageal', 'Esophageal Adenocarcinoma', 'Esophageal Diseases', 'Esophageal Intraepithelial Neoplasia', 'Esophagus', 'Gastroenterology', 'Gland', 'Goals', 'Health', 'Health Care Costs', 'Healthcare Systems', 'Image', 'Lesion', 'Machine Learning', 'Malignant Neoplasms', 'Medical', 'Morphologic artifacts', 'Motion', 'Optical Coherence Tomography', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phase', 'Physicians', 'Premalignant', 'Risk', 'Sample Size', 'Scanning', 'Sensitivity and Specificity', 'Societies', 'Software Tools', 'Squamous Epithelium', 'Surface', 'Survival Rate', 'System', 'Techniques', 'Technology', 'Time', 'Training', 'base', 'case-based', 'cost', 'deep learning', 'diagnosis quality', 'effective therapy', 'gastric foveola', 'gastric rugae', 'high resolution imaging', 'imaging system', 'improved', 'in vivo', 'interest', 'software development', 'standard of care', 'stomach cardia']",NCI,"NINEPOINT MEDICAL, INC.",R43,2018,217888,0.05906729388463927
"HistoTools:  A suite of digital pathology tools for quality control, annotation and dataset identification ABSTRACT: Roughly 40% of the US population will be diagnosed with some form of cancer in their lifetime. In a majority of these cases, a definitive cancer diagnosis is only possible via histopathologic confirmation using a tissue slide. Increasingly, these slides are being digitally scanned as high-resolution images for usage in both clinical and research digital pathology (DP) workflows. Our group has been pioneering the use of deep learning (DL), a form of machine learning, for segmentation, detection, and classification of various cancers using digital pathology images. DL learns features and their associated weighting from large datasets to maximally discriminate between user labeled data (e.g., cancer vs non-cancer, nuclei vs non-nuclei); a paradigm known as “learn from data”. Unfortunately, this paradigm makes DL especially sensitive to low quality slides, noise induced by small errors in the manual user labeling process, and general dataset heterogeneity. As many groups do not intentionally account for these problems, they learn that successful employment of DL technologies relies heavily on explicitly addressing challenges associated with (a) carefully curating high quality slides without preparation or scanning artifacts, (b) obtaining a large precise collection of annotations delineating objects of interest, and (c) selecting diverse datasets to ensure robust classifier performance when clinically deploying the model. To address these challenges we propose HistoTools, a suite of three modules or “Apps”: (1) HistoQC examines slides for artifacts and computes metrics associated with slide presentation characteristics (e.g., stain intensity, compression levels) helping to quantify ranges of acceptable characteristics for downstream algorithmic evaluation. (2) HistoAnno drastically improves the efficiency of annotation efforts using a combined active learning and deep learning approach to ensure experts focus only on regions which are important for classifier improvement. (3) HistoFinder aids in selecting suitable training and test cohorts to guarantee that various tissue level characteristics are well balanced, leading to increased reproducibility. Our team already has working prototypes of HistoQC (100% concordance with a pathologist, evaluated on n>1200 slides) and HistoAnno (30% efficiency improvement during annotation tasks). In this U01, we seek to further develop and evaluate HistoTools in the context of enhancing two companion diagnostic (CDx) assays being developed in our group. First, we will use HistoTools to quality control and annotate nuclei, tubules, and mitosis for improving our CDx classifier for predicting recurrence in breast cancers using a cohort of n>900 patients from completed trial ECOG 2197. Secondly, HistoTools will be employed for quality control and identification of tumor infiltrating lymphocytes and cancer nuclei towards improving our CDx classifier for predicting response to immunotherapy in lung cancer using the n>700 patients from completed clinical trials Checkmate 017 and 057. These tools will build on our existing open source tool repository to aid in real-time feedback and dissemination throughout the ITCR and cancer research community. RELEVANCE: This project will result in development of HistoTools, a new digital pathology toolkit for common pre-experiment machine learning tasks in the oncology domain such as (a) timely identification of poor quality slides and slide regions, (b) quantitative metrics driving optimized cohort selection, and (c) generation of highly precise and relevant annotations. Each component is designed to directly combat an existing bottleneck in the evolving usage of digital pathology. HistoTools will significantly enhance the functionality of existing toolboxes and pipelines, facilitating increasingly sophisticated machine learning applications in oncology.","HistoTools:  A suite of digital pathology tools for quality control, annotation and dataset identification",9897498,U01CA239055,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'American', 'American Society of Clinical Oncology', 'Automobile Driving', 'Cancer Patient', 'Cell Nucleus', 'Characteristics', 'Classification', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collection', 'Communities', 'Computer Assisted', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Eastern Cooperative Oncology Group', 'Employment', 'Ensure', 'Environment', 'Estrogen receptor positive', 'Evaluation', 'Feedback', 'Generations', 'Histologic', 'Histology', 'Image', 'Immunotherapy', 'International', 'Label', 'Learning', 'Lymphocyte', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Masks', 'Mitosis', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Nature', 'Nivolumab', 'Noise', 'Non-Small-Cell Lung Carcinoma', 'Nuclear', 'Oncology', 'Optics', 'Outcome', 'Paper', 'Pathologist', 'Patients', 'Performance', 'Population', 'Preparation', 'Process', 'Quality Control', 'Recurrence', 'Reproducibility', 'Research', 'Role', 'Scanning', 'Slide', 'Societies', 'Stains', 'Technology', 'Testing', 'The Cancer Imaging Archive', 'Time', 'Tissues', 'Training', 'Tumor-Infiltrating Lymphocytes', 'Validation', 'Visualization', 'Weight', 'Work', 'anticancer research', 'base', 'cancer diagnosis', 'cancer recurrence', 'cohort', 'combat', 'companion diagnostics', 'deep learning', 'design', 'diagnostic assay', 'digital', 'digital pathology', 'experimental study', 'heterogenous data', 'high resolution imaging', 'imaging informatics', 'improved', 'indexing', 'industry partner', 'innovation', 'interactive tool', 'interest', 'large datasets', 'learning network', 'malignant breast neoplasm', 'open source', 'outcome forecast', 'outcome prediction', 'pathology imaging', 'photonics', 'predicting response', 'prognostic', 'prototype', 'quantitative imaging', 'repository', 'response', 'tool', 'tumor heterogeneity']",NCI,CASE WESTERN RESERVE UNIVERSITY,U01,2020,381138,0.012121025107435696
"HistoTools:  A suite of digital pathology tools for quality control, annotation and dataset identification ABSTRACT: Roughly 40% of the US population will be diagnosed with some form of cancer in their lifetime. In a majority of these cases, a definitive cancer diagnosis is only possible via histopathologic confirmation using a tissue slide. Increasingly, these slides are being digitally scanned as high-resolution images for usage in both clinical and research digital pathology (DP) workflows. Our group has been pioneering the use of deep learning (DL), a form of machine learning, for segmentation, detection, and classification of various cancers using digital pathology images. DL learns features and their associated weighting from large datasets to maximally discriminate between user labeled data (e.g., cancer vs non-cancer, nuclei vs non-nuclei); a paradigm known as “learn from data”. Unfortunately, this paradigm makes DL especially sensitive to low quality slides, noise induced by small errors in the manual user labeling process, and general dataset heterogeneity. As many groups do not intentionally account for these problems, they learn that successful employment of DL technologies relies heavily on explicitly addressing challenges associated with (a) carefully curating high quality slides without preparation or scanning artifacts, (b) obtaining a large precise collection of annotations delineating objects of interest, and (c) selecting diverse datasets to ensure robust classifier performance when clinically deploying the model. To address these challenges we propose HistoTools, a suite of three modules or “Apps”: (1) HistoQC examines slides for artifacts and computes metrics associated with slide presentation characteristics (e.g., stain intensity, compression levels) helping to quantify ranges of acceptable characteristics for downstream algorithmic evaluation. (2) HistoAnno drastically improves the efficiency of annotation efforts using a combined active learning and deep learning approach to ensure experts focus only on regions which are important for classifier improvement. (3) HistoFinder aids in selecting suitable training and test cohorts to guarantee that various tissue level characteristics are well balanced, leading to increased reproducibility. Our team already has working prototypes of HistoQC (100% concordance with a pathologist, evaluated on n>1200 slides) and HistoAnno (30% efficiency improvement during annotation tasks). In this U01, we seek to further develop and evaluate HistoTools in the context of enhancing two companion diagnostic (CDx) assays being developed in our group. First, we will use HistoTools to quality control and annotate nuclei, tubules, and mitosis for improving our CDx classifier for predicting recurrence in breast cancers using a cohort of n>900 patients from completed trial ECOG 2197. Secondly, HistoTools will be employed for quality control and identification of tumor infiltrating lymphocytes and cancer nuclei towards improving our CDx classifier for predicting response to immunotherapy in lung cancer using the n>700 patients from completed clinical trials Checkmate 017 and 057. These tools will build on our existing open source tool repository to aid in real-time feedback and dissemination throughout the ITCR and cancer research community. RELEVANCE: This project will result in development of HistoTools, a new digital pathology toolkit for common pre-experiment machine learning tasks in the oncology domain such as (a) timely identification of poor quality slides and slide regions, (b) quantitative metrics driving optimized cohort selection, and (c) generation of highly precise and relevant annotations. Each component is designed to directly combat an existing bottleneck in the evolving usage of digital pathology. HistoTools will significantly enhance the functionality of existing toolboxes and pipelines, facilitating increasingly sophisticated machine learning applications in oncology.","HistoTools:  A suite of digital pathology tools for quality control, annotation and dataset identification",9734599,U01CA239055,"['Active Learning', 'Address', 'Adoption', 'Algorithms', 'American', 'American Society of Clinical Oncology', 'Automobile Driving', 'Cancer Patient', 'Cell Nucleus', 'Characteristics', 'Classification', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collection', 'Communities', 'Computer Assisted', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Eastern Cooperative Oncology Group', 'Employment', 'Ensure', 'Environment', 'Evaluation', 'Feedback', 'Generations', 'Heterogeneity', 'Histologic', 'Histology', 'Image', 'Imagery', 'Immunotherapy', 'International', 'Label', 'Learning', 'Lymphocyte', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Manuals', 'Masks', 'Mitosis', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Nature', 'Nivolumab', 'Noise', 'Non-Small-Cell Lung Carcinoma', 'Nuclear', 'Optics', 'Outcome', 'Paper', 'Pathologist', 'Patients', 'Performance', 'Population', 'Preparation', 'Process', 'Quality Control', 'Recurrence', 'Reproducibility', 'Research', 'Role', 'Scanning', 'Slide', 'Societies', 'Stains', 'Technology', 'Testing', 'Time', 'Tissues', 'Training', 'Tumor-Infiltrating Lymphocytes', 'Validation', 'Weight', 'Work', 'anticancer research', 'base', 'cancer diagnosis', 'cancer recurrence', 'cohort', 'combat', 'companion diagnostics', 'deep learning', 'design', 'diagnostic assay', 'digital', 'digital pathology', 'experimental study', 'high resolution imaging', 'imaging informatics', 'improved', 'indexing', 'industry partner', 'innovation', 'interactive tool', 'interest', 'learning network', 'malignant breast neoplasm', 'oncology', 'open source', 'outcome forecast', 'outcome prediction', 'pathology imaging', 'photonics', 'predicting response', 'prognostic', 'prototype', 'quantitative imaging', 'repository', 'response', 'tool', 'tumor heterogeneity']",NCI,CASE WESTERN RESERVE UNIVERSITY,U01,2019,383459,0.012121025107435696
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,10018827,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data privacy', 'data quality', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2020,394824,0.16607652053817173
"Distributed Learning of Deep Learning Models for Cancer Research Project Summary Deep learning methods are showing great promise for advancing cancer research and could potentially improve clinical decision making in cancers such as primary brain glioma, where deep learning models have recently shown promising results in predicting isocitrate dehydrogenase (IDH) mutation and survival in these patients. A major challenge thwarting this research, however, is the requirement for large quantities of labeled image data to train deep learning models. Efforts to create large public centralized collections of image data are hindered by barriers to data sharing, costs of image de-identification, patient privacy concerns, and control over how data are used. Current deep learning models that are being built using data from one or a few institutions are limited by potential overfitting and poor generalizability. Instead of centralizing or sharing patient images, we aim to distribute the training of deep learning models across institutions with computations performed on their local image data. Although our preliminary results demonstrate the feasibility of this approach, there are three key challenges to translating these methods into research practice: (1) data is heterogeneous among institutions in the amount and quality of data that could impair the distributed computations, (2) there are data security and privacy concerns, and (3) there are no software packages that implement distributed deep learning with medical images. We tackle these challenges by (1) optimizing and expanding our current methods of distributed deep learning to tackle challenges of data variability and data privacy/security, (2) creating a freely available software system for building deep learning models on multi- institutional data using distributed computation, and (3) evaluating our system to tackle deep learning problems in example use cases of classification and clinical prediction in primary brain cancer. Our approach is innovative in developing distributed deep learning methods that will address variations in data among different institutions, that protect patient privacy during distributed computations, and that enable sites to discover pertinent datasets and participate in creating deep learning models. Our work will be significant and impactful by overcoming critical hurdles that researchers face in tapping into multi-institutional patient data to create deep learning models on large collections of image data that are more representative of disease than data acquired from a single institution, while avoiding the hurdles to inter-institutional sharing of patient data. Ultimately, our methods will enable researchers to collaboratively develop more generalizable deep learning applications to advance cancer care by unlocking access to and leveraging huge amounts of multi-institutional image data. Although our clinical use case in developing this technology is primary brain cancer, our methods will generalize to all cancers, as well as to other types of data besides images for use in creating deep learning models, and will ultimately lead to robust deep learning applications that are expected to improve clinical care and outcomes in many types of cancer. Project Narrative We develop technology that will enable researchers to tap into the enormous amount of imaging data in multiple institutions to create deep learning models for cancer applications without requiring sharing of patient data. Our work will thus enable development of more robust deep learning models to improve clinical decision making in cancer than models currently built on data from single institutions. Although our focus is improving decision making in the primary brain cancer, our methods and tools are generalizable and will be broadly applicable to all cancers, with the potential for improvement in clinical care and patient health.",Distributed Learning of Deep Learning Models for Cancer Research,9827476,U01CA242879,"['Address', 'Adopted', 'Advanced Malignant Neoplasm', 'Brain', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Custom', 'Data', 'Data Quality', 'Data Scientist', 'Data Security', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Engineering', 'Ensure', 'Equipment', 'Face', 'Feedback', 'Fostering', 'Glioma', 'Health', 'Heterogeneity', 'Hospitals', 'Image', 'Impairment', 'Information Networks', 'Institution', 'Intuition', 'Isocitrate Dehydrogenase', 'Label', 'Lead', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Medical Imaging', 'Methods', 'Modeling', 'Mutation', 'Patient imaging', 'Patients', 'Performance', 'Periodicity', 'Phenotype', 'Privacy', 'Rare Diseases', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Running', 'Secure', 'Security', 'Selection for Treatments', 'Site', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translating', 'Update', 'Variant', 'Weight', 'Work', 'anticancer research', 'base', 'cancer care', 'cancer type', 'care outcomes', 'clinical care', 'clinical decision support', 'clinical decision-making', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'innovation', 'inter-institutional', 'learning strategy', 'molecular marker', 'multidisciplinary', 'novel', 'patient population', 'patient privacy', 'radiologist', 'research to practice', 'software systems', 'survival prediction', 'tool']",NCI,STANFORD UNIVERSITY,U01,2019,401628,0.16607652053817173
"Cyst-X: Interpretable Deep Learning Based Risk Stratification of Pancreatic Cystic Tumors Project Summary The overall goal of this project is to develop a new diagnostic tool, called Cyst-X, for accurate detection and characterization of pre-cancerous pancreatic cysts and improve patient outcome through precise decisions (surgical resection or surveillance). Pancreatic cancer is the most fatal cancer among all cancers due to its poor prognosis and lack of early detection methods. Unlike other common cancers where precursor lesions are well known (colon polyps-colon cancer, ductal carcinoma in situ (DCIS)-breast cancer), pancreas cancer precursors (cysts) are poorly understood. Diagnosing pancreatic cancer at earlier stages may decrease mortality and morbidity rates of this lethal disease. One major approach for diagnosing pancreatic cancer at earlier stages is to target pancreatic precancerous pancreatic neoplasms (cysts) before they turn into invasive cancer. Once cysts are detected with radiology imaging such as magnetic resonance imaging (MRI), they should be characterized with respect to their malignant potential. Low-risk cysts remain harmless; hence, patients should remain under surveillance program. On the other hand, high-risk cysts can progress into an aggressive cancer, therefore, patients should undergo surgical resection if possible. Despite this, international guidelines for risk stratification of pancreatic cysts are woefully deficient (55-76% accuracy for determining characteristics of low-risk vs high risk cystic tumors, while only 40-50% accuracy detecting cysts with MRI). Combined, these critical barriers indicate that there is an urgent need for improving characterization of pancreatic cystic tumors. Based on our preliminary results, which support the development of an image-based diagnostic decision tool, we hypothesize that our proposed Cyst-X will produce higher diagnostic accuracy for characterizing pancreatic cysts and provide better patient management compared to the current guidelines. Towards this overarching hypothesis, we will first use powerful deep learning methods (specifically deep capsule networks) for automatically detecting and segmenting the pancreas and pancreatic cysts from multi-sequence MRI scans (Aim 1). Next, we will create an interpretable image-based diagnosis model for characterizing pancreatic cysts (Aim 2). Accurate characterization is necessary for such a diagnostic model; however, emphasis will also be placed on interpretability of the machine generated diagnostic model. Visual explanation of the discriminative features will help radiologists obtain higher decision rates in patient management. In Aim 3, we will validate the proposed Cyst-X framework in a multi-center study. A total of 1200 multi-sequence MRI scans will be collected from three participating clinical centers (Mayo Clinic, Columbia University Medical Center, Erasmus Medical Center). Comprehensive evaluations will be made to test the validity and generalizability of Cyst-X. All evaluations will be made with respect to the international guidelines and biopsy proven ground truths. Our proposed study has wide implications: specifically, in the long term, it will influence early diagnosis of pancreatic cancer and clinical decision making to improve survival rates of pancreatic cancer. Project Narrative Unlike other common cancers for which early detection and surgical resection have reduced cancer deaths (e.g. colon polyps for colon cancer, ductal carcinoma in situ lesions and breast cancer), pancreas cancer precursors, such as commonly observed pancreatic cysts, are poorly understood. Towards the long-term goal of early detection of pancreatic cancer, our objective in this proposal is to accurately detect and characterize pancreatic cysts before they turn into aggressive cancer. The outcome of this research will be a new diagnostic tool, named Cyst-X, which will establish a better clinical strategy than the current guidelines by recommending a more selective use of invasive testing, surgery, and surveillance.",Cyst-X: Interpretable Deep Learning Based Risk Stratification of Pancreatic Cystic Tumors,9866770,R01CA246704,"['Academic Medical Centers', 'Algorithms', 'Artificial Intelligence', 'Biopsy', 'Cancer Etiology', 'Cessation of life', 'Characteristics', 'Clinic', 'Clinical', 'Colon Carcinoma', 'Colonic Polyps', 'Cyst', 'Cystic Neoplasm', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Early Diagnosis', 'Epithelial cyst', 'Evaluation', 'Excision', 'Goals', 'Guidelines', 'High Prevalence', 'Histopathology', 'Image', 'In Situ Lesion', 'Individual', 'International', 'Lead', 'Lesion', 'MRI Scans', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Medical center', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Mucinous Cystadenoma', 'Mucinous Neoplasm', 'Multicenter Studies', 'Names', 'Noninfiltrating Intraductal Carcinoma', 'Operative Surgical Procedures', 'Organ', 'Outcome', 'Outcomes Research', 'Pancreas', 'Pancreatectomy', 'Pancreatic Cyst', 'Pancreatic cystic neoplasia', 'Papillary', 'Patient Triage', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Property', 'Radiology Specialty', 'Recommendation', 'Reference Standards', 'Research', 'Risk', 'Risk stratification', 'Scanning', 'Sensitivity and Specificity', 'Series', 'Serous Cystadenoma', 'Side', 'Structure', 'Surveillance Program', 'Survival Rate', 'System', 'Technology', 'Testing', 'Time', 'Trust', 'Universities', 'Unnecessary Surgery', 'Visual', 'automated algorithm', 'base', 'cancer invasiveness', 'cancer type', 'capsule', 'clinical center', 'clinical decision-making', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'diagnostic accuracy', 'experimental study', 'follow-up', 'high risk', 'improved', 'learning strategy', 'malignant breast neoplasm', 'mortality', 'novel diagnostics', 'outcome forecast', 'pancreatic neoplasm', 'premalignant', 'prognostic significance', 'radiological imaging', 'radiologist', 'radiomics', 'screening', 'stem', 'tool']",NCI,UNIVERSITY OF CENTRAL FLORIDA,R01,2020,510210,0.0007948132754227464
"Deep learning for renal tumor characterization Our long-term objective is to develop deep learning techniques capable of predicting characteristics and treatment response or response to surveillance to assist clinical decision- making in renal tumors that are potential candidates for ablation therapy, biopsy, active surveillance or surgical resection. An increasing number of renal tumors are being diagnosed, due in part to incidental detection from the increased use of cross-sectional imaging. Although partial nephrectomy is still considered the primary treatment for small renal masses, percutaneous ablation is increasingly performed as a therapeutic, nephron-sparing approach. One challenge for interventional radiologists and urologists who manage these patients is selection for therapy, since the average rate of progression is slow for small renal tumors and metastasis rarely occurs. A technique that could distinguish indolent tumors from those will progress based on data from the imaging methods used to detect and delineate renal masses would enable early triage to observation versus invasive treatment. Deep learning, a type of machine learning technique which takes raw images as input, and applies many layers of transformations to calculate an output signal, has already led to breakthroughs in other areas of image recognition, and is increasingly used for medical image analysis. However, its application in the field of interventional radiology is currently limited. Furthermore, no study in the literature has applied deep learning to kidney lesion segmentation and characteristics/outcome prediction. In this project, we propose to develop novel deep learning architectures based on routine MR imaging that allow for accurate renal mass segmentation and prediction of characteristics and outcome in renal tumors. Using data from four independent cohorts, we will use our deep learning architectures to predict (1) benign versus malignant histology (2) growth rate in stage 1a renal cell carcinoma (3) SSIGN score in clear cell renal cell carcinoma and (4) clinical endpoints. We will integrate segmentation and classification into one net that suitable for clinical application. In addition, we will compare results with those of experts and traditional machine learning approaches. The inability to determine aggressiveness of renal tumors based on pretreatment imaging makes it challenging for urologists or interventional radiologists to select appropriate patients for active surveillance versus therapy with nephrectomy or ablation. Our research project uses deep learning to distinguish renal mass from normal tissue and predict characteristics, treatment response or response to surveillance in renal tumors. By using a multi-institutional patient cohort and conventional MR imaging sequences, we will demonstrate the generalizability and broad applicability of our algorithm. Our models have the potential to help guide clinical management of patients with renal tumors.",Deep learning for renal tumor characterization,9968604,R03CA249554,"['3-Dimensional', 'Ablation', 'Algorithms', 'Architecture', 'Area', 'Benign', 'Biopsy', 'Characteristics', 'Classification', 'Clear cell renal cell carcinoma', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Dropout', 'Ensure', 'Excision', 'Future', 'Growth', 'Histology', 'Image', 'Image Analysis', 'Indolent', 'Institution', 'Intervention', 'Interventional radiology', 'Kidney', 'Kidney Neoplasms', 'Learning', 'Lesion', 'Literature', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Medical Imaging', 'Metastatic Neoplasm to the Kidney', 'Modeling', 'Nephrectomy', 'Nephrons', 'Neural Network Simulation', 'Normal tissue morphology', 'Oncology', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patient imaging', 'Patients', 'Performance', 'Process', 'Renal Cell Carcinoma', 'Renal Mass', 'Research Project Grants', 'Selection for Treatments', 'Signal Transduction', 'Techniques', 'Therapeutic', 'Training', 'Triage', 'Update', 'Urologist', 'Weight', 'base', 'cancer imaging', 'clinical application', 'clinical decision-making', 'cohort', 'deep learning', 'deep neural network', 'design', 'imaging modality', 'improved', 'interest', 'learning network', 'novel', 'outcome prediction', 'predictive modeling', 'radiologist', 'radiomics', 'random forest', 'treatment response', 'tumor']",NCI,RHODE ISLAND HOSPITAL,R03,2020,80500,-0.06289062895909857
"Microfluidic intact cell platform: A novel tool for oral cancer detection Oral squamous cell carcinoma (OSCC) claims the lives of thousands in the U.S. and hundreds of thousands worldwide annually. A biopsy followed by histopathology, the gold standard for the diagnosis of OSCC, is painful, invasive, costly, not practical if longitudinal assessments of the same lesion are required and oftentimes is not available or imprecise in third world countries. A tool that quickly distinguishes cancerous from non- cancerous lesions and identifies progressive or transforming lesions could allow for early intervention, which would improve outcomes and negate the need for unnecessary biopsies in patients whose lesions remain benign or haven’t begun to degenerate. Therefore, there is an unmet need for a rapid, non-invasive, objective and cost-effective test for OSCC. We and others have reported that an altered expression profile of human beta defensin 3 (hBD-3), an epithelial cell derived antimicrobial peptide (AMP), and hBD-2, another epithelial cell AMP, is an early event in OSCC. Therefore, the ratio of hBD-3 and hBD-2 in the lesion, when compared to the contralateral site, could be exploited in distinguishing OSCC from other lesions of the oral cavity. We refer to this ratio as the beta defensin index (BDI). Our ongoing clinical study of 78 subjects with suspicious oral lesions demonstrated high sensitivity (100%) and specificity (74%) of the ELISA based BDI in distinguishing cancerous from noncancerous oral lesions (P<0.0001). With the high accuracy (98%) of our BDI based molecular assay, we now wish to advance our novel platform from the laborious, time consuming ELISA format into an imaging-based point-of-care (POC) device that utilizes microfluidic technology to quantify the BDI with an expected turnover time of half an hour. Our microfluidic intact cell assay (MICA) approach to developing a POC device for oral cancer detection is unique; it utilizes intact epithelial cells trapped in a microfluidic chip encompassing microfabricated pillar arrays with varying spaces to allow the capture of epithelial cells. Upon capture, the cells are permeabilized and labeled with fluorescent antibodies for hBD ratio analysis. We employ automated fluorescence imaging and computational algorithm to enable automated calculation of the BDI scores. We now hypothesize that the ELISA format that can effectively detect oral cancer, can be configured for point of care MICA, retaining its high accuracy and making it easier to use worldwide. To advance the discovery of this new approach for oral cancer detection, we propose the following aims: 1. Develop a working prototype of a MICA POC device for oral cancer testing equipped with cell imaging and BDI calculation capabilities. 2. Conduct a discovery phase study where MICA POC and ELISA, as independent assays, will be compared with pathology review in their ability to detect oral cancer. The MICA POC, while not intending to replace biopsy, could be deployed, in the future, to objectively and non- invasively determine who actually needs a biopsy, monitor oral premalignant lesions in real world practice and fulfill a major unmet need in low-socio economic countries where pathology review is lacking and/or unreliable. Narrative Oral cancer (OC) kills thousands in the U.S. and hundreds of thousands worldwide, and early detection is key to improved survival. Since biopsy followed by pathology review, the gold standard for OC, is costly, painful, can result in patient complications, is impractical should monitoring be required, and is often not available or imprecise in third world countries, we intend to develop (Aim 1), and test in humans (Aim 2), an innovative device that will accurately detect OC, non-invasively, within ½ hour and thereby will address a major unmet need in early OC detection worldwide. The device will incorporate microfluidic, imaging and computational technologies that will determine the ratios of two key proteins from swabbed cells obtained from suspicious oral lesions; a procedure we have already shown to be accurate using a laboratory based technique.",Microfluidic intact cell platform: A novel tool for oral cancer detection,10043470,R21CA253108,"['Address', 'Aliquot', 'Bedside Testings', 'Benign', 'Biological', 'Biological Assay', 'Biological Markers', 'Biopsy', 'Caliber', 'Cancer Detection', 'Cancerous', 'Carcinoma in Situ', 'Cations', 'Cell membrane', 'Cells', 'Cellular Assay', 'Cellular Phone', 'Clinical Research', 'Coin', 'Collaborations', 'Collecting Cell', 'Computational algorithm', 'Computer Analysis', 'Consumption', 'Contralateral', 'Country', 'Custom', 'Dental Clinics', 'Detection', 'Developing Countries', 'Development', 'Devices', 'Diagnosis', 'Early Diagnosis', 'Early Intervention', 'Engineering', 'Enzyme-Linked Immunosorbent Assay', 'Epithelial Cells', 'Event', 'Expression Profiling', 'Fluorescence', 'Fluorescent Antibody Technique', 'Future', 'Goals', 'Gold', 'Head and Neck Cancer', 'Health care facility', 'Histopathology', 'Hour', 'Human', 'Image', 'Immobilization', 'India', 'Indigenous', 'Individual', 'Label', 'Laboratories', 'Lesion', 'Measures', 'Medicine', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Molecular', 'Monitor', 'Mouth Carcinoma', 'Myelogenous', 'Non-Invasive Lesion', 'Observational Study', 'Oral', 'Oral Stage', 'Oral cavity', 'Oral mucous membrane structure', 'Pain', 'Pathology', 'Patient-Focused Outcomes', 'Patients', 'Peptides', 'Phase', 'Phenotype', 'Primary Health Care', 'Procedures', 'Proteins', 'Reporting', 'Research Personnel', 'Resources', 'Sampling', 'Screening for Oral Cancer', 'Screening procedure', 'Site', 'Specificity', 'Swab', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'University Hospitals', 'Work', 'antimicrobial', 'antimicrobial peptide', 'base', 'beta pleated sheet', 'beta-Defensins', 'beta-defensin 3', 'biomarker development', 'cellular imaging', 'chemokine', 'clinical care', 'cost', 'cost effective', 'deep learning algorithm', 'diagnosis standard', 'diagnostic accuracy', 'experience', 'fluorescence imaging', 'imaging Segmentation', 'imaging capabilities', 'imaging platform', 'immunoregulation', 'improved', 'improved outcome', 'indexing', 'innovation', 'malignant mouth neoplasm', 'metaplastic cell transformation', 'microfluidic technology', 'monitoring device', 'mouth squamous cell carcinoma', 'mucosal site', 'novel', 'novel strategies', 'oral lesion', 'overexpression', 'patient population', 'point of care', 'portability', 'portable monitoring', 'premalignant', 'primary care setting', 'prospective', 'prototype', 'recruit', 'scalpel', 'screening', 'socioeconomics', 'success', 'tertiary care', 'tool']",NCI,CASE WESTERN RESERVE UNIVERSITY,R21,2020,413972,0.06283713512764705
"Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks PROJECT SUMMARY The long-term goal of this project is to improve the care of patients with laryngeal disorders through development of automated diagnostic support for in-office flexible laryngoscopy. To accomplish this goal, we propose developing neural network-based algorithms to detect and classify structural laryngeal lesions in laryngoscopy images. An automated diagnostic tool for in-office laryngoscopy such as we propose will have several benefits: (1) It will improve access to care for patients with symptoms of laryngeal dysfunction living in communities with limited otolaryngology resources, (2) It will improve early detection of laryngeal cancers potentially reducing the morbidity of treatment, and (3) It will prove a valuable teaching tool for students and residents first learning to interpret laryngoscopic exams. Flexible laryngoscopy is a common in-office procedure performed by otolaryngologists to evaluate the upper aerodigestive tract in patients with symptoms of laryngeal dysfunction. Subtle differences in the appearance of laryngeal lesions enable otolaryngologists to differentiate benign lesions from suspected malignant ones. The expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training and therefore laryngoscopy is largely only performed in subspecialty otolaryngology clinics. The primary objective of this project is to develop neural network-based algorithms to detect and classify structural laryngeal lesions. Our hypothesis is that these algorithms can be trained using a large dataset of laryngeal images to accurately detect and classify structural laryngeal lesions on flexible laryngoscopic exam. To test this hypothesis, we propose the following aims: (1) Generate a dataset of high-quality, labeled endoscopic laryngeal images corresponding to normal and structural lesions of the larynx, (2) Develop a location-aware anchor-based reasoning neural network for accurate detection of laryngeal lesions, and (3) Develop an adaptive network model for classification of structural laryngeal pathologies including papilloma, polyp, leukoplakia and suspected malignancy. With expertise in the diagnosis and treatment of laryngeal disorders and computer vision, including object detection and classification, our multidisciplinary team is uniquely qualified to complete this project. PROJECT NARRATIVE We propose to revolutionize in-office laryngoscopy through development of a deep neural network-based automated detection and classification system for diagnosis of structural diseases of the larynx. Currently, flexible laryngoscopy is only performed by expert subspecialists with years of experience because developing the expertise and clinical acumen to correctly interpret laryngoscopic findings requires years of training. Through development of deep neural network-based algorithms to detect and classify laryngeal lesions on in- office laryngoscopy, we will improve access to care for patients living in communities without subspecialty otolaryngology care and will develop an important teaching tool for clinicians learning to interpret laryngoscopic exams.",Automated Detection and Classification of Laryngeal Diseases Using Deep Neural Networks,10043172,R03CA253212,"['Aerodigestive Tract', 'Algorithms', 'Anesthesia procedures', 'Appearance', 'Architecture', 'Awareness', 'Benign', 'Caring', 'Categories', 'Cessation of life', 'Classification', 'Clinic', 'Clinical', 'Collaborations', 'Colonic Polyps', 'Colonoscopy', 'Communities', 'Computer Vision Systems', 'Custom', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Distal', 'Drops', 'Early Diagnosis', 'Educational process of instructing', 'Ensure', 'Fellowship', 'Functional disorder', 'Gastroesophageal reflux disease', 'Goals', 'Health Services Accessibility', 'Hoarseness', 'Image', 'Improve Access', 'Infection', 'Label', 'Laryngeal Diseases', 'Laryngoscopes', 'Laryngoscopy', 'Larynx', 'Learning', 'Lesion', 'Leukoplakia', 'Location', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of larynx', 'Manuals', 'Modeling', 'Modernization', 'Morbidity - disease rate', 'Network-based', 'Normal Range', 'Otolaryngologist', 'Otolaryngology', 'Papilloma', 'Pathology', 'Patient Care', 'Patients', 'Performance', 'Pilot Projects', 'Plug-in', 'Polyps', 'Positioning Attribute', 'Procedures', 'Recurrence', 'Resources', 'Sampling', 'Semantics', 'Structure', 'Students', 'Symptoms', 'System', 'Technical Expertise', 'Testing', 'Training', 'Vision research', 'Work', 'base', 'classification algorithm', 'cost', 'deep neural network', 'detector', 'digital', 'experience', 'feature extraction', 'flexibility', 'improved', 'large datasets', 'learning algorithm', 'multidisciplinary', 'network models', 'neural network', 'tool']",NCI,UNIVERSITY OF KANSAS MEDICAL CENTER,R03,2020,154375,0.07386304766820058
"Software Solution for Clinical Management of Musculoskeletal Tumors PROJECT SUMMARY/ABSTRACT  Bone lesions are frequently encountered during every day clinical practice. Benign bone lesions, such as a small enchondroma, can be left alone and are unlikely to impact the patient during their lifetime. However, a malignant bone lesion, such as an osteosarcoma, will require a biopsy and surgical resection. Determining which lesions require treatment and which can be left alone can be a daunting process. Whether a bone lesion requires a biopsy depends on both clinical- and imaging-based factors(1–3). Advanced patient age, presence of pain, and history of prior malignancy can influence the need for biopsy. For imaging, various lesion-based parameters such as location, matrix, tumor margin, presence of soft tissue component, and periosteal reaction can help determine whether the lesion is aggressive or non-aggressive, with aggressive lesions needing a biopsy. Aggressive lesions are more likely to represent a malignancy, althought there are some benign processes that can have an aggressive imaging appearance (i.e osteomyelitis, fractures).  Misdiagnoses of malignant tumors as benign prevents needed treatment from occurring; however, benign lesions should not be unnecessarily biopsied, as this can lead to unneeded tests, biopsy complications, increased health care costs, and patient anxiety. Currently, the decision to biopsy or not is made by the clinician, considering the clinical- and imaging-based factors, which can be very subjective. Studies have shown that misdiagnosis is higher if these cases are not discussed under multidisciplinary review with input from an orthopedic oncologist, radiologist, and pathologist. Also, if the imaging studies are not interpreted by subspecialty trained musculoskeletal (MSK) radiologists, reading discrepancy of up to 28% can occur. Moreover, a recent study by Zamora et al. showed that there is poor inter-observer agreement amongst experienced orthopedic oncologists for distinguishing enchondromas and chondrosarcomas, a common clinical dilemma.  Therefore, we propose to develop a method to analyze the radiologic studies directly, extract important lesion-based features of the bone tumors and auto-classify the lesions as non-aggressive or aggressive. By using CT scans from 200 biopsied bone lesions, utilizing a deep learning approach to extract image features and access to patients' clinical-based factors, we will develop a machine learning tool to differentiate between non- aggressive and aggressive tumors and compare the results to definitive histologic confirmation of disease. We hypothesize that the proposed machine learning based software will classify aggressive vs. non- aggressive lesions as accurately as definitive histologic confirmation of disease state. The aims of the study are to: 1) Develope bone and lesion segmentation and bone-lesion feature extraction software tools for physician classification; and 2) Develope a software tool to auto-classify femur lesions as either aggressive or non-aggressive. PROJECT NARRATIVE  Bone tumors are frequently encountered during every day clinical practice. Non-aggressive bone tumors can often be left alone. However, an aggressive bone tumor typically requires a biopsy and subsequent surgery. Determining which lesions require treatment and which can be left alone can be a daunting process. Therefore, our goal is to develop, test, and commercialize a software tool to aid in differentiating between aggressive and non-aggressive bone tumors.",Software Solution for Clinical Management of Musculoskeletal Tumors,10156765,R43CA254835,"['3-Dimensional', 'Age', 'Agreement', 'Anatomy', 'Anxiety', 'Appearance', 'Benign', 'Biopsy', 'Bone neoplasms', 'Chondroma', 'Chondrosarcoma', 'Classification', 'Clinical', 'Clinical Management', 'Computer software', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Excision', 'Femur', 'Fracture', 'Funding', 'Goals', 'Gold', 'Health Care Costs', 'Histologic', 'Image', 'Image Analysis', 'International', 'Israel', 'Label', 'Lead', 'Left', 'Lesion', 'Life Cycle Stages', 'Location', 'Machine Learning', 'Maintenance', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medical Device', 'Medical center', 'Metastatic Neoplasm to the Bone', 'Methods', 'Musculoskeletal', 'Oncologist', 'Oncology', 'Operative Surgical Procedures', 'Orthopedics', 'Osteomyelitis', 'Outcome', 'Pain', 'Pathologist', 'Patients', 'Phase', 'Physicians', 'Process', 'Radiology Specialty', 'Reaction', 'Reading', 'Recording of previous events', 'Scanning', 'Small Business Innovation Research Grant', 'Software Tools', 'System', 'Testing', 'Training', 'X-Ray Computed Tomography', 'base', 'bone', 'clinical practice', 'deep learning', 'design', 'experience', 'feature extraction', 'fracture risk', 'imaging study', 'improved', 'indexing', 'innovation', 'multidisciplinary', 'osteosarcoma', 'prevent', 'radiologist', 'soft tissue', 'software development', 'standard of care', 'success', 'tool', 'tumor']",NCI,"BIOSENSICS, LLC",R43,2020,256000,0.0023858674480125154
"TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT This Fast Track SBIR aims to implement comprehensive image anonymization within an enterprise imaging informatics platform built on XNAT.  Our vision is for this platform to provide large healthcare enterprises with tools to generate secure research databases at scale that mirror their clinical image archives.  These databases would then provide local academic and industry collaborators with a rich resource for clinical research and development of AI-powered applications. Thus, our proposed anonymization services are designed to be scalable, risk-based, and verifiable. The platform's AI-powered image anonymization will include automated detection of PHI using a deep learning based natural language processing engine and automated detection of PHI in image content using a convolutational neural network.  The anonymization services will be integrated into Radiologics enterprise and clinical trial XNAT products. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT,10274066,5N91020C00025,"['Clinical Research', 'Clinical Trials', 'Computer software', 'Contracts', 'Data', 'Database Management Systems', 'Databases', 'Detection', 'Healthcare', 'Image', 'Industry Collaboration', 'Intelligence', 'Natural Language Processing', 'Phase', 'Radiology Specialty', 'Research', 'Resources', 'Risk', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Vision', 'base', 'clinical imaging', 'deep learning', 'design', 'image archival system', 'imaging informatics', 'neural network', 'prototype', 'research and development', 'tool']",NCI,"RADIOLOGICS, INC.",N43,2020,399691,-0.008302554823320598
