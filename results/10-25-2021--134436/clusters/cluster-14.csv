text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among         these are the development of highly sensitive and accurate automated             sequencing techniques, the development of optimal strategies for gene            recognition in sequence data, and an improved understanding of gene              function and regulation.  My intent in this Special Emphasis Research            Career Award project is to address these and other related problems              within the context of state-of-the-art genome research.  I believe that          my background in theoretical and experimental particle physics provides          me with a unique set of skills relevant to the solution of these and             other problems.  The goals of this training program are to: 1) obtain a          firm grounding in modern molecular biology and genetics with                     specialization in genome research, 2) develop a set of skills in                 laboratory-based genome research through a first year project in                 physical mapping and DNA sequencing, and 3) develop a long term project          focusing on DNA sequence acquisition and analysis which will utilize the         analytical, computational and model building skills which I have                 developed as a physicist.  In particular, I would hope to develop                optimum protocols for gene mapping and sequence assembly applicable to           large scale genome analysis and to develop new and more efficient                algorithms for gene sequence identification and interpretation.  In              addition, I intend to pursue the development of advanced automated               sequencing technology based on highly sensitive detectors and techniques         developed for particle physics.  Achievement of either or both of these          goals will greatly facilitate the formidable task faced by the                   researchers involved in the Human Genome Project in accumulating and             analyzing vast amounts of genomic DNA sequence.  This project will begin         by immersion in the work currently being done on the physical mapping of         human chromosome 11, and the sequencing of selected reference markers            and cDNA clones, as part of the Salk Institute large scale physical              mapping project.  The formal training I will receive during the tenure           of the NCHGR/SERCA provides an ideal environment in which I can gain the         necessary grounding in current techniques so that I can effectively work         on the development of new techniques and strategies and contribute to            the genome research of the future.                                                n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,2440343,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,INSTITUTE FOR GENOMIC RESEARCH,K01,1996,78818,0.014447199673068786
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among  these are the development of highly sensitive and accurate automated  sequencing techniques, the development of optimal strategies for gene  recognition in sequence data, and an improved understanding of gene  function and regulation.  My intent in this Special Emphasis Research  Career Award project is to address these and other related problems  within the context of state-of-the-art genome research.  I believe that  my background in theoretical and experimental particle physics provides  me with a unique set of skills relevant to the solution of these and  other problems.  The goals of this training program are to: 1) obtain a  firm grounding in modern molecular biology and genetics with  specialization in genome research, 2) develop a set of skills in  laboratory-based genome research through a first year project in  physical mapping and DNA sequencing, and 3) develop a long term project  focusing on DNA sequence acquisition and analysis which will utilize the  analytical, computational and model building skills which I have  developed as a physicist.  In particular, I would hope to develop  optimum protocols for gene mapping and sequence assembly applicable to  large scale genome analysis and to develop new and more efficient  algorithms for gene sequence identification and interpretation.  In  addition, I intend to pursue the development of advanced automated  sequencing technology based on highly sensitive detectors and techniques  developed for particle physics.  Achievement of either or both of these  goals will greatly facilitate the formidable task faced by the  researchers involved in the Human Genome Project in accumulating and  analyzing vast amounts of genomic DNA sequence.  This project will begin  by immersion in the work currently being done on the physical mapping of  human chromosome 11, and the sequencing of selected reference markers  and cDNA clones, as part of the Salk Institute large scale physical  mapping project.  The formal training I will receive during the tenure  of the NCHGR/SERCA provides an ideal environment in which I can gain the  necessary grounding in current techniques so that I can effectively work  on the development of new techniques and strategies and contribute to  the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,2208285,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,STANFORD UNIVERSITY,K01,1995,79392,0.014447199673068786
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among these are the development of highly sensitive and accurate automated sequencing techniques, the development of optimal strategies for gene recognition in sequence data, and an improved understanding of gene function and regulation.  My intent in this Special Emphasis Research Career Award project is to address these and other related problems within the context of state-of-the-art genome research.  I believe that my background in theoretical and experimental particle physics provides me with a unique set of skills relevant to the solution of these and other problems.  The goals of this training program are to: 1) obtain a firm grounding in modern molecular biology and genetics with specialization in genome research, 2) develop a set of skills in laboratory-based genome research through a first year project in physical mapping and DNA sequencing, and 3) develop a long term project focusing on DNA sequence acquisition and analysis which will utilize the analytical, computational and model building skills which I have developed as a physicist.  In particular, I would hope to develop optimum protocols for gene mapping and sequence assembly applicable to large scale genome analysis and to develop new and more efficient algorithms for gene sequence identification and interpretation.  In addition, I intend to pursue the development of advanced automated sequencing technology based on highly sensitive detectors and techniques developed for particle physics.  Achievement of either or both of these goals will greatly facilitate the formidable task faced by the researchers involved in the Human Genome Project in accumulating and analyzing vast amounts of genomic DNA sequence.  This project will begin by immersion in the work currently being done on the physical mapping of human chromosome 11, and the sequencing of selected reference markers and cDNA clones, as part of the Salk Institute large scale physical mapping project.  The formal training I will receive during the tenure of the NCHGR/SERCA provides an ideal environment in which I can gain the necessary grounding in current techniques so that I can effectively work on the development of new techniques and strategies and contribute to the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,2208284,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,STANFORD UNIVERSITY,K01,1994,81199,0.014447199673068786
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among these are the development of highly sensitive and accurate automated sequencing techniques, the development of optimal strategies for gene recognition in sequence data, and an improved understanding of gene function and regulation.  My intent in this Special Emphasis Research Career Award project is to address these and other related problems within the context of state-of-the-art genome research.  I believe that my background in theoretical and experimental particle physics provides me with a unique set of skills relevant to the solution of these and other problems.  The goals of this training program are to: 1) obtain a firm grounding in modern molecular biology and genetics with specialization in genome research, 2) develop a set of skills in laboratory-based genome research through a first year project in physical mapping and DNA sequencing, and 3) develop a long term project focusing on DNA sequence acquisition and analysis which will utilize the analytical, computational and model building skills which I have developed as a physicist.  In particular, I would hope to develop optimum protocols for gene mapping and sequence assembly applicable to large scale genome analysis and to develop new and more efficient algorithms for gene sequence identification and interpretation.  In addition, I intend to pursue the development of advanced automated sequencing technology based on highly sensitive detectors and techniques developed for particle physics.  Achievement of either or both of these goals will greatly facilitate the formidable task faced by the researchers involved in the Human Genome Project in accumulating and analyzing vast amounts of genomic DNA sequence.  This project will begin by immersion in the work currently being done on the physical mapping of human chromosome 11, and the sequencing of selected reference markers and cDNA clones, as part of the Salk Institute large scale physical mapping project.  The formal training I will receive during the tenure of the NCHGR/SERCA provides an ideal environment in which I can gain the necessary grounding in current techniques so that I can effectively work on the development of new techniques and strategies and contribute to the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,3068602,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' nucleic acid sequence', ' technology /technique development', ' training']",NHGRI,SALK INSTITUTE FOR BIOLOGICAL STUDIES,K01,1993,89532,0.014447199673068786
"MOLECULAR ANALYSIS OF THE HUMAN GENOME The Human Genome Project faces a number of formidable challenges.  Among these are the development of highly sensitive and accurate automated sequencing techniques, the development of optimal strategies for gene recognition in sequence data, and an improved understanding of gene function and regulation.  My intent in this Special Emphasis Research Career Award project is to address these and other related problems within the context of state-of-the-art genome research.  I believe that my background in theoretical and experimental particle physics provides me with a unique set of skills relevant to the solution of these and other problems.  The goals of this training program are to: 1) obtain a firm grounding in modern molecular biology and genetics with specialization in genome research, 2) develop a set of skills in laboratory-based genome research through a first year project in physical mapping and DNA sequencing, and 3) develop a long term project focusing on DNA sequence acquisition and analysis which will utilize the analytical, computational and model building skills which I have developed as a physicist.  In particular, I would hope to develop optimum protocols for gene mapping and sequence assembly applicable to large scale genome analysis and to develop new and more efficient algorithms for gene sequence identification and interpretation.  In addition, I intend to pursue the development of advanced automated sequencing technology based on highly sensitive detectors and techniques developed for particle physics.  Achievement of either or both of these goals will greatly facilitate the formidable task faced by the researchers involved in the Human Genome Project in accumulating and analyzing vast amounts of genomic DNA sequence.  This project will begin by immersion in the work currently being done on the physical mapping of human chromosome 11, and the sequencing of selected reference markers and cDNA clones, as part of the Salk Institute large scale physical mapping project.  The formal training I will receive during the tenure of the NCHGR/SERCA provides an ideal environment in which I can gain the necessary grounding in current techniques so that I can effectively work on the development of new techniques and strategies and contribute to the genome research of the future.  n/a",MOLECULAR ANALYSIS OF THE HUMAN GENOME,3068600,K01HG000007,"['artificial chromosomes', ' artificial intelligence', ' chromosomes', ' complementary DNA', ' computer assisted sequence analysis', ' flow cytometry', ' genetic mapping', ' genetic markers', ' genetic techniques', ' genome', ' human genetic material tag', ' in situ hybridization', ' molecular biology', ' molecular genetics', ' technology /technique development', ' training']",NHGRI,SALK INSTITUTE FOR BIOLOGICAL STUDIES,K01,1992,80784,0.014447199673068786
"ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING This is an application for an NCHGR/SERCA grant (K01) to support                 interdisciplinary research in genomic science.  The immediate objective of       this research project is to develop a fully automated/robust algorithm for       computer assembly of high density cosmid contigs to serve as templates for       large-scale sequence-based mapping.  This includes integrating the cosmid        contigs with chromosome-wide YAC based maps and incorporating diverse            sources of data (e.g., DNA sequence from cosmid ends, STSs and other             markers, or results of specific gap-filling efforts) to resolve                  ambiguities and verify self-consistency.  Initial efforts will be focused        on the high resolution mapping and sampled sequencing of human chromosome        11.  The mapping strategy employs high density cosmid contig assembly over       individual 200 kb to 1 Mb regions of the chromosome coupled with DNA             sequencing of the cosmid ends.  The relative order and spacing of the            sequence fragments is determined from the template contig resulting in a         physical map of 1 to 5 kb resolution which contains up to 40% of the             entire sequence at one-pass accuracy.  A simple restriction-site based           approach to cosmid fingerprinting will be effective, provided that the           contig-building algorithm correlates fragment data from multiple                 restriction digests and includes labeled vector/insert end fragments to          determine the orientation of individual cosmids, i.e., the orientation of        the genomic insert relative to the cloning vector.                                                                                                                The candidate is a physicist with nearly a ten year record of achievement        and publication in the field of plasma fusion energy--theory/computation.        The research advisor, Prof. Glen Evans, is the Principal Investigator of         the Genome Science and Technology Center (GESTEC) at the University of           Texas Southwestern Medical Center at Dallas, one of the top academic             medical centers in the nation and the performance site of this grant.            Prof. Evans is an accomplished biologist with an established record of           coordinating multi-disciplinary research to develop informatics and              automation for the Human Genome Project (HGP).  The candidate's skills           also compliment those of Prof. Harold Garner, physicist and co-Principal         Investigator of GESTEC.  The candidate will receive explicit training            through an intensive 18 months program that includes formal course-work in       the Division of Cell and Molecular Biology (at UT Southwestern), and             laboratory rotations in the mapping, sequencing, and informatics units of        GESTEC.                                                                           n/a",ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING,2430543,K01HG000018,"['DNA', ' artificial chromosomes', ' artificial intelligence', ' chemical fingerprinting', ' chromosomes', ' computer assisted sequence analysis', ' computer program /software', ' genetic mapping', ' human genetic material tag', ' molecular cloning', ' nucleic acid sequence', ' plasmids', ' restriction fragment length polymorphism']",NHGRI,UNIVERSITY OF TEXAS SW MED CTR/DALLAS,K01,1997,97527,0.03684123082608305
"ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING This is an application for an NCHGR/SERCA grant (K01) to support  interdisciplinary research in genomic science.  The immediate objective of  this research project is to develop a fully automated/robust algorithm for  computer assembly of high density cosmid contigs to serve as templates for  large-scale sequence-based mapping.  This includes integrating the cosmid  contigs with chromosome-wide YAC based maps and incorporating diverse  sources of data (e.g., DNA sequence from cosmid ends, STSs and other  markers, or results of specific gap-filling efforts) to resolve  ambiguities and verify self-consistency.  Initial efforts will be focused  on the high resolution mapping and sampled sequencing of human chromosome  11.  The mapping strategy employs high density cosmid contig assembly over  individual 200 kb to 1 Mb regions of the chromosome coupled with DNA  sequencing of the cosmid ends.  The relative order and spacing of the  sequence fragments is determined from the template contig resulting in a  physical map of 1 to 5 kb resolution which contains up to 40% of the  entire sequence at one-pass accuracy.  A simple restriction-site based  approach to cosmid fingerprinting will be effective, provided that the  contig-building algorithm correlates fragment data from multiple  restriction digests and includes labeled vector/insert end fragments to  determine the orientation of individual cosmids, i.e., the orientation of  the genomic insert relative to the cloning vector.    The candidate is a physicist with nearly a ten year record of achievement  and publication in the field of plasma fusion energy--theory/computation.  The research advisor, Prof. Glen Evans, is the Principal Investigator of  the Genome Science and Technology Center (GESTEC) at the University of  Texas Southwestern Medical Center at Dallas, one of the top academic  medical centers in the nation and the performance site of this grant.  Prof. Evans is an accomplished biologist with an established record of  coordinating multi-disciplinary research to develop informatics and  automation for the Human Genome Project (HGP).  The candidate's skills  also compliment those of Prof. Harold Garner, physicist and co-Principal  Investigator of GESTEC.  The candidate will receive explicit training  through an intensive 18 months program that includes formal course-work in  the Division of Cell and Molecular Biology (at UT Southwestern), and  laboratory rotations in the mapping, sequencing, and informatics units of  GESTEC.  n/a",ADVANCED ALGORITHMS AND TOOLS FOR CONTIG BUILDING,2208336,K01HG000018,"['DNA', ' artificial chromosomes', ' artificial intelligence', ' chemical fingerprinting', ' chromosomes', ' computer assisted sequence analysis', ' computer program /software', ' genetic mapping', ' human genetic material tag', ' molecular cloning', ' nucleic acid sequence', ' plasmids', ' restriction fragment length polymorphism']",NHGRI,UNIVERSITY OF TEXAS SW MED CTR/DALLAS,K01,1995,81100,0.03684123082608305
"GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS In this proposal we present a systematic approach to gene mapping and genotyping based on the simultaneous analysis of multiple Amplified Sequence Polymorphisms (ASPs).  The proposal has three broad features: the development of a technology suitable for the automation of gene mapping and genotyping, the application of this technology to the development of markers for the X chromosome and then for the entire genome, and the development of a computer tool for the management of gene mapping experiments. The main concept associated with ASP technology is that a DNA segment containing the sequence variation of a polymorphic locus can be amplified in such a way that it has a unique physical property.  This unique property will allow individual loci to be distinguished from one another such that multiple loci can be analyzed simultaneously.  In this application, we are proposing to use the length of the DNA segment as this distinguishing physical property and the polymerase chain reaction (PCR) as the method of amplification.  Two alternative approaches for the generation of ASP markers are to be explored.  The first is allele specific PCR (AS-PCR) in which the length of the PCR amplified fragment is different for different loci producing the marker directly.  The second is allele specific primer extension (AS-PE) in which the PCR products are analyzed with oligonucleotide primers which produce allele specific fragments of different lengths for different loci.  Specifically we plan to 1) refine ASP technology, 2) develop ASPs for the X chromosome and the genome and 3) create appropriate software for aiding the scientist in concerning ASP based mapping experiments, including an expert system.  n/a",GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS,3333120,R01HG000099,"['alleles', ' biological polymorphism', ' chromosomes', ' computer assisted sequence analysis', ' gel electrophoresis', ' genetic mapping', ' genetic markers', ' genetic regulatory element', ' genome', ' genotype', ' molecular cloning', ' natural gene amplification', ' oligonucleotides', ' polymerase chain reaction', ' restriction fragment length polymorphism']",NHGRI,CITY OF HOPE/BECKMAN RESEARCH INSTITUTE,R01,1992,294334,0.09187547979069469
"GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS In this proposal we present a systematic approach to gene mapping and genotyping based on the simultaneous analysis of multiple Amplified Sequence Polymorphisms (ASPs).  The proposal has three broad features: the development of a technology suitable for the automation of gene mapping and genotyping, the application of this technology to the development of markers for the X chromosome and then for the entire genome, and the development of a computer tool for the management of gene mapping experiments. The main concept associated with ASP technology is that a DNA segment containing the sequence variation of a polymorphic locus can be amplified in such a way that it has a unique physical property.  This unique property will allow individual loci to be distinguished from one another such that multiple loci can be analyzed simultaneously.  In this application, we are proposing to use the length of the DNA segment as this distinguishing physical property and the polymerase chain reaction (PCR) as the method of amplification.  Two alternative approaches for the generation of ASP markers are to be explored.  The first is allele specific PCR (AS-PCR) in which the length of the PCR amplified fragment is different for different loci producing the marker directly.  The second is allele specific primer extension (AS-PE) in which the PCR products are analyzed with oligonucleotide primers which produce allele specific fragments of different lengths for different loci.  Specifically we plan to 1) refine ASP technology, 2) develop ASPs for the X chromosome and the genome and 3) create appropriate software for aiding the scientist in concerning ASP based mapping experiments, including an expert system.  n/a",GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS,3333119,R01HG000099,"['alleles', ' biological polymorphism', ' chromosomes', ' computer assisted sequence analysis', ' gel electrophoresis', ' genetic mapping', ' genetic markers', ' genetic regulatory element', ' genome', ' genotype', ' molecular cloning', ' natural gene amplification', ' oligonucleotides', ' polymerase chain reaction', ' restriction fragment length polymorphism']",NHGRI,CITY OF HOPE/BECKMAN RESEARCH INSTITUTE,R01,1991,282985,0.09187547979069469
"GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS In this proposal we present a systematic approach to gene mapping and genotyping based on the simultaneous analysis of multiple Amplified Sequence Polymorphisms (ASPs).  The proposal has three broad features: the development of a technology suitable for the automation of gene mapping and genotyping, the application of this technology to the development of markers for the X chromosome and then for the entire genome, and the development of a computer tool for the management of gene mapping experiments. The main concept associated with ASP technology is that a DNA segment containing the sequence variation of a polymorphic locus can be amplified in such a way that it has a unique physical property.  This unique property will allow individual loci to be distinguished from one another such that multiple loci can be analyzed simultaneously.  In this application, we are proposing to use the length of the DNA segment as this distinguishing physical property and the polymerase chain reaction (PCR) as the method of amplification.  Two alternative approaches for the generation of ASP markers are to be explored.  The first is allele specific PCR (AS-PCR) in which the length of the PCR amplified fragment is different for different loci producing the marker directly.  The second is allele specific primer extension (AS-PE) in which the PCR products are analyzed with oligonucleotide primers which produce allele specific fragments of different lengths for different loci.  Specifically we plan to 1) refine ASP technology, 2) develop ASPs for the X chromosome and the genome and 3) create appropriate software for aiding the scientist in concerning ASP based mapping experiments, including an expert system.  n/a",GENE MAPPING WITH AMPLIFIED SEQUENCE POLYMORPHISMS-ASPS,3333118,R01HG000099,"['alleles', ' biological polymorphism', ' chromosomes', ' computer assisted sequence analysis', ' gel electrophoresis', ' genetic mapping', ' genetic markers', ' genetic regulatory element', ' genome', ' genotype', ' molecular cloning', ' natural gene amplification', ' oligonucleotides', ' polymerase chain reaction', ' restriction fragment length polymorphism']",NHGRI,BECKMAN RES INST OF THE CITY OF HOPE,R01,1990,283176,0.09187547979069469
"REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA We proposed to develop a database for storage, retrieval, and graphical display of physical mapping data being produced by several laboratories at the Yale Departments of Human Genetics and Biology.  In the near future, large amounts of physical mapping data describing the human genome will be produced at Yale and elsewhere, and will need to be stored in an organized fashion so it can be retrieved and displayed easily.  Many different types of data are being produced which characterize the genome at different levels of detail.  This information is typically uncertain and incomplete, and data at one level may interact with (reinforce, complement or contradict) data at another level.  The routines that retrieve this data should adapt intelligently to the uncertainty, incompleteness and interdependencies of the data.  Representation of Physical Mapping Data.  The laboratories of Drs. Kenneth Kidd, David Ward, Sherman Weissman, Frank Ruddle, Stephen Reeders, and Allen Bale are currently producing large quantities of physical mapping data, including large scale restriction maps, sets of overlapping cosmids, mapping of yeast artificial chromosomes, and in situ hybridization data. We will develop and refine an appropriate representation for this data.  We will focus particularly on how best to represent the inherent uncertainties and interdependencies in the data, and consensus conclusions based on the data.  Intelligent Retrieval and Concise Display of the Data.  We will develop routines that incorporate several types of knowledge to allow intelligent retrieval of the data.  We will also develop routines to display the data graphically at different levels of detail, including the construction of gene maps.  Although the data in the database itself will be complex and interrelated, the display routines will be designed to present the data clearly, at an appropriate level of detail.  For example, a map of a chromosome or of a large or small chromosomal region will be concise and easily understood.  n/a",REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA,2208596,R01HG000175,"['artificial chromosomes', ' artificial intelligence', ' automated data processing', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' genetic polymorphism', ' hybrid cells', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' linkage mapping', ' nucleic acid sequence', ' restriction mapping']",NHGRI,YALE UNIVERSITY,R01,1993,313085,0.07243932600502229
"REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA We proposed to develop a database for storage, retrieval, and graphical display of physical mapping data being produced by several laboratories at the Yale Departments of Human Genetics and Biology.  In the near future, large amounts of physical mapping data describing the human genome will be produced at Yale and elsewhere, and will need to be stored in an organized fashion so it can be retrieved and displayed easily.  Many different types of data are being produced which characterize the genome at different levels of detail.  This information is typically uncertain and incomplete, and data at one level may interact with (reinforce, complement or contradict) data at another level.  The routines that retrieve this data should adapt intelligently to the uncertainty, incompleteness and interdependencies of the data.  Representation of Physical Mapping Data.  The laboratories of Drs. Kenneth Kidd, David Ward, Sherman Weissman, Frank Ruddle, Stephen Reeders, and Allen Bale are currently producing large quantities of physical mapping data, including large scale restriction maps, sets of overlapping cosmids, mapping of yeast artificial chromosomes, and in situ hybridization data. We will develop and refine an appropriate representation for this data.  We will focus particularly on how best to represent the inherent uncertainties and interdependencies in the data, and consensus conclusions based on the data.  Intelligent Retrieval and Concise Display of the Data.  We will develop routines that incorporate several types of knowledge to allow intelligent retrieval of the data.  We will also develop routines to display the data graphically at different levels of detail, including the construction of gene maps.  Although the data in the database itself will be complex and interrelated, the display routines will be designed to present the data clearly, at an appropriate level of detail.  For example, a map of a chromosome or of a large or small chromosomal region will be concise and easily understood.  n/a",REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA,3333224,R01HG000175,"['artificial chromosomes', ' artificial intelligence', ' automated data processing', ' computer graphics /printing', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' genetic polymorphism', ' hybrid cells', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' linkage mapping', ' nucleic acid sequence', ' restriction mapping']",NHGRI,YALE UNIVERSITY,R01,1992,308409,0.07243932600502229
"REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA We proposed to develop a database for storage, retrieval, and graphical display of physical mapping data being produced by several laboratories at the Yale Departments of Human Genetics and Biology.  In the near future, large amounts of physical mapping data describing the human genome will be produced at Yale and elsewhere, and will need to be stored in an organized fashion so it can be retrieved and displayed easily.  Many different types of data are being produced which characterize the genome at different levels of detail.  This information is typically uncertain and incomplete, and data at one level may interact with (reinforce, complement or contradict) data at another level.  The routines that retrieve this data should adapt intelligently to the uncertainty, incompleteness and interdependencies of the data.  Representation of Physical Mapping Data.  The laboratories of Drs. Kenneth Kidd, David Ward, Sherman Weissman, Frank Ruddle, Stephen Reeders, and Allen Bale are currently producing large quantities of physical mapping data, including large scale restriction maps, sets of overlapping cosmids, mapping of yeast artificial chromosomes, and in situ hybridization data. We will develop and refine an appropriate representation for this data.  We will focus particularly on how best to represent the inherent uncertainties and interdependencies in the data, and consensus conclusions based on the data.  Intelligent Retrieval and Concise Display of the Data.  We will develop routines that incorporate several types of knowledge to allow intelligent retrieval of the data.  We will also develop routines to display the data graphically at different levels of detail, including the construction of gene maps.  Although the data in the database itself will be complex and interrelated, the display routines will be designed to present the data clearly, at an appropriate level of detail.  For example, a map of a chromosome or of a large or small chromosomal region will be concise and easily understood.  n/a",REPRESENTATION AND RETRIEVAL OF PHYSICAL MAPPING DATA,3333222,R01HG000175,"['artificial intelligence', ' automated data processing', ' computer graphics /printing', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' genetic polymorphism', ' hybrid cells', ' information display', ' information retrieval', ' information system analysis', ' information systems', ' linkage mapping', ' nucleic acid sequence', ' restriction mapping']",NHGRI,YALE UNIVERSITY,R01,1991,309867,0.07243932600502229
"INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL DESCRIPTION (Adapted from the Investigator's Abstract):  Numerous  restriction mapping programs have been devised since 1978, but none of them  is as precise as manual map construction using digest gel photos, pencil,  and graph paper.  Given realistic data, programs usually find hundreds or  even thousands of solutions, only one of which can be correct.  Because of  this, slow and demanding manual techniques are still in common use.  The  researchers propose to develop public domain software implementing a  complete restriction mapping environment which will be far more powerful  and useful than current restriction mapping software.  This system will:  1) find solutions more quickly than any existing software; 2) find far  fewer false maps than any existing software; 3) allow the user to ""steer""  the entire mapping process (if desired); and 4) guide the user with  detailed, expert advice on handling specific mapping problems as they  arise.  In addition, the system will have:  5) built-in extensibility, so  that simple modifications will also allow other genetic marker mapping  problems to be solved by the same program and 6) the ability to record all  user activity transparently, providing quantitative data on successful  mapping strategies.    The system will be based on extant restriction mapping programs, but it  will overcome their limitations by including the following additional  capabilities:  1) All known heuristics will be implemented.  (Heuristics  are logical rules of thumb which guide the search towards a true solution.)  Existing programs use only a small subset of the known heuristics.  Every  added heuristic will speed up the search and reduce the set of possible  solutions to a problem.  2) Hand mapping will be simulated on-screen via a  ""what you see is what you get"" graphical user interface, with users  choosing fully automatic mapping (the default), fully manual mapping (with  simulated pencils and log paper), or various in-between levels of  semi-automatic assisted mapping.  This will allow users to control or  adjust any part of the mapping process if they so desire.  3) An expert  system (a program which can answer queries and make decisions by consulting  a knowledge database) will guide users through the mapping process.  It  will assist the process of data acquisition, help the user solve  difficulties, and tutor inexperienced users.    Considerable preliminary design work has already taken place, so  implementation can begin almost at once.  Software will be developed and  tested iteratively (""rapid prototyping"") to assure end-user satisfaction.  To insure portability at the source code level, the two major modules of  the system (fragment length derivation and mapping) will be coded in C++  using Boochs' object-oriented design methodology, and the user interface  will be designed using a portable interface-building tool that works on a  variety of computing platforms (including DOS machines, and the Macintosh).  The expert system will be implemented using CLIPS, a portable C-based  public domain expert system shell.  n/a",INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL,2209202,R01HG000972,"['artificial intelligence', ' automated data processing', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' restriction fragment length polymorphism', ' restriction mapping']",NHGRI,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,1995,134128,0.17326829396839824
"INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL DESCRIPTION (Adapted from the Investigator's Abstract):  Numerous restriction mapping programs have been devised since 1978, but none of them is as precise as manual map construction using digest gel photos, pencil, and graph paper.  Given realistic data, programs usually find hundreds or even thousands of solutions, only one of which can be correct.  Because of this, slow and demanding manual techniques are still in common use.  The researchers propose to develop public domain software implementing a complete restriction mapping environment which will be far more powerful and useful than current restriction mapping software.  This system will: 1) find solutions more quickly than any existing software; 2) find far fewer false maps than any existing software; 3) allow the user to ""steer"" the entire mapping process (if desired); and 4) guide the user with detailed, expert advice on handling specific mapping problems as they arise.  In addition, the system will have:  5) built-in extensibility, so that simple modifications will also allow other genetic marker mapping problems to be solved by the same program and 6) the ability to record all user activity transparently, providing quantitative data on successful mapping strategies.  The system will be based on extant restriction mapping programs, but it will overcome their limitations by including the following additional capabilities:  1) All known heuristics will be implemented.  (Heuristics are logical rules of thumb which guide the search towards a true solution.) Existing programs use only a small subset of the known heuristics.  Every added heuristic will speed up the search and reduce the set of possible solutions to a problem.  2) Hand mapping will be simulated on-screen via a ""what you see is what you get"" graphical user interface, with users choosing fully automatic mapping (the default), fully manual mapping (with simulated pencils and log paper), or various in-between levels of semi-automatic assisted mapping.  This will allow users to control or adjust any part of the mapping process if they so desire.  3) An expert system (a program which can answer queries and make decisions by consulting a knowledge database) will guide users through the mapping process.  It will assist the process of data acquisition, help the user solve difficulties, and tutor inexperienced users.  Considerable preliminary design work has already taken place, so implementation can begin almost at once.  Software will be developed and tested iteratively (""rapid prototyping"") to assure end-user satisfaction. To insure portability at the source code level, the two major modules of the system (fragment length derivation and mapping) will be coded in C++ using Boochs' object-oriented design methodology, and the user interface will be designed using a portable interface-building tool that works on a variety of computing platforms (including DOS machines, and the Macintosh). The expert system will be implemented using CLIPS, a portable C-based public domain expert system shell.  n/a",INTELLIGENT AUTOMATED RESTRICTION MAPPING TOOL,2209201,R01HG000972,"['artificial intelligence', ' automated data processing', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' genetic mapping', ' genetic markers', ' restriction fragment length polymorphism', ' restriction mapping']",NHGRI,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,1994,138701,0.17326829396839824
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,8309492,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Inbreeding', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Normalcy', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2012,333078,0.1634107964156916
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,8119139,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Inbreeding', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Normalcy', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2011,333078,0.1634107964156916
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,7902299,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Anus', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Hand', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2010,336442,0.1634107964156916
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,7681324,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Anus', 'Cations', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Hand', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2009,339841,0.1634107964156916
"Methods for Human Genetic Mapping    DESCRIPTION (provided by applicant): The long-term objective of the proposed research is development of statistical methods for mapping and genetic analysis of human complex traits, which account for a major portion of the health care burden in the United States. Complex traits are familial, but do not have simple patterns of transmission and are likely to result from the actions and interactions of multiple genetic and environmental factors. With the availability of high-density single-nucleotide polymorphism information, there is the potential to use association-based mapping methods to identify relevant genetic variants, as well as to clarify the role of environmental risk factors. Case-control association tests are more versatile in terms of the study designs they can accommodate than are TDT-type association tests. Most   case-control association mapping methods are designed for samples of unrelated individuals, but families containing two or more affected individuals remain a powerful resource for genetic association studies, because under complex genetic models, affected individuals with affected relatives are enriched for disease-predisposing alleles, compared to affected individuals without affected relatives. Thus, these individuals should be expected to contribute disproportionately to the power of a case-control association study. Robust, powerful association mapping methods are needed that will be useful in a full spectrum of study designs, from simple combinations of sibships with unrelated individuals on the one hand, to isolated founder populations with complex inbred pedigrees, on the other hand. Another critical aspect of association testing is the ability to detect and account for violation of assumptions that may cause false positive results, including (1) population stratification and (2) experimental artifacts that may cause artificial case-control differences. Our specific aims include methods development for (1) association mapping in samples that contain arbitrarily related individuals, including robust and powerful methods for both binary and quantitative   traits, allowing for haplotype effects, covariate information, effects of multiple loci, and possible   interactions among these, where these methods are broadly applicable across a wide range of study designs; (2) association mapping methods that simultaneously adjust for the possible presence of population stratification in the sample by principal components analysis and allow for related individuals in the sample; (3) tests for informative missingness of marker genotypes in the context of association testing, in order to detect possible false positive association results that are due to experimental artifacts.          n/a",Methods for Human Genetic Mapping,7464116,R01HG001645,"['Accounting', 'Address', 'Affect', 'Alleles', 'Anus', 'Cations', 'Class', 'Complex', 'Data', 'Dependence', 'Development', 'Disease', 'Environmental Risk Factor', 'Equilibrium', 'Family', 'Founder Generation', 'Funding', 'Genetic', 'Genetic Models', 'Genotype', 'Hand', 'Haplotypes', 'Healthcare', 'Human', 'Human Gene Mapping', 'Individual', 'Joints', 'Link', 'Maps', 'Methods', 'Modeling', 'Morphologic artifacts', 'Pattern', 'Phenotype', 'Population', 'Principal Component Analysis', 'Property', 'Range', 'Rate', 'Relative (related person)', 'Research', 'Research Design', 'Resources', 'Role', 'Sampling', 'Score', 'Scoring Method', 'Single Nucleotide Polymorphism', 'Standards of Weights and Measures', 'Statistical Methods', 'Stratification', 'Structure', 'Testing', 'Time', 'United States', 'Variant', 'Work', 'base', 'care burden', 'case control', 'density', 'design', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'method development', 'novel strategies', 'trait', 'transmission process']",NHGRI,UNIVERSITY OF CHICAGO,R01,2008,339841,0.1634107964156916
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7682282,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Other Genetics', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'flexibility', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'non-genetic', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2009,291480,0.08367095880172333
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7488003,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Disease regression', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Numbers', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Rate', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2008,291480,0.08367095880172333
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7930715,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Other Genetics', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'flexibility', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'non-genetic', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2010,288566,0.08367095880172333
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7292731,R01HG003618,"['Address', 'Biochemical Pathway', 'Biochemical Reaction', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Disease Outcome', 'Disease regression', 'Environment', 'Environmental Risk Factor', 'Finland', 'Genetic', 'Genome', 'Grant', 'Haplotypes', 'Human Gene Mapping', 'Human Genome Project', 'International', 'Investigation', 'Lead', 'Linkage Disequilibrium', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Normal Statistical Distribution', 'Numbers', 'Outcome', 'Paper', 'Pathway interactions', 'Performance', 'Procedures', 'Public Health', 'Rate', 'Relative (related person)', 'Research Design', 'Research Personnel', 'Resources', 'Screening procedure', 'Series', 'Severity of illness', 'Solutions', 'Statistical Methods', 'Techniques', 'Testing', 'United States', 'Variant', 'base', 'case control', 'disorder prevention', 'genetic analysis', 'genetic variant', 'human disease', 'improved', 'interest', 'novel', 'programs', 'simulation', 'trait', 'user-friendly']",NHGRI,EMORY UNIVERSITY,R01,2007,297126,0.08367095880172333
"Novel Statistical Methods for Human Gene Mapping    DESCRIPTION (provided by applicant): Many common human diseases originate in part from the complicated effects of multiple genetic variants found throughout the genome. Given the enormous impact of such diseases on public health, it is imperative to map relevant genetic variants to improve our understanding of the molecular basis of such diseases, as well as improve screening techniques for disease prevention. To this end, successful human gene mapping of complex diseases requires the development and application of powerful statistical methods that fully utilize the resources of the Human Genome Project. This grant proposes a set of such statistical methods that either address novel problems or improve existing solutions to problems in human gene mapping studies. These proposed methods are applicable to a variety of genetic studies as they address topics in linkage, linkage disequilibrium, and high-dimensional genetic analyses of complex diseases and disease-related quantitative traits. The methods can be partitioned into the two general groups: mixed-modeling procedures and case-control likelihood procedures. The mixed-modeling procedures considered include a general variance-component (VC) mapping framework for continuous and discrete trait data and a modified VC mapping framework that allows for haplotypes. Also considered is a novel linear-mixed-model framework that identifies a large combination of genetic variants that influence a quantitative trait using support-vector- machine regression. The case-control likelihood procedures considered are extensions of the approach of Epstein and Satten (2003) for haplotype inference on disease. Extensions considered include allowing for covariates and haplotype-covariate interactions, and also categorical disease outcomes. The proposed statistical methods in this grant have the potential to increase the power to identify genetic variants that influence complex diseases and disease-related quantitative traits. This project will evaluate the performance of these methods using simulations based on the study design and data from an existing gene mapping study of type 2 diabetes. Also, this grant will implement the proposed statistical methods in user- friendly, efficient software for public distribution. Finally, this project will be opportunistic in identifying and addressing unforseen statistical problems arising in human gene mapping studies.           n/a",Novel Statistical Methods for Human Gene Mapping,7146455,R01HG003618,"['clinical research', 'genes', 'genetics', 'human', 'model']",NHGRI,EMORY UNIVERSITY,R01,2006,306000,0.08367095880172333
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,8323569,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2012,380794,0.04131786105549995
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,8147862,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2011,380638,0.04131786105549995
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,7903895,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Arts', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2010,384328,0.04131786105549995
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,7688619,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Arts', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human Gene Mapping', 'Human Genetics', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Play', 'Population', 'Procedures', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2009,389374,0.04131786105549995
"Developing Statistical Methods for Disease Gene Discovery    DESCRIPTION (provided by applicant): Human genetics research has accelerated in the last decade owing to our evolving understanding of the human genome. With the recent completion of the International HapMap Project, the development of largescale genotyping technology, and rapid decline in genotyping costs, an immense amount of genotype data have been generated, which in turn raises many new challenging problems for analysis and interpretation of the data. This application proposes developing new statistical methodologies that aim to address a wide range of statistical issues in current candidate gene and genome-wide association (GWA) studies.       Specifically, the proposal will address the following problems. (1) Recent high-resolution genome mapping indicates that copy number variations (CNVs) are ubiquitous and common in the general population, and may play a major role in phenotypic variation. In Aim 1, we will develop a Bayesian hidden Markov model based algorithm for highresolution CNV detection using whole-genome SNP genotyping data. Our algorithm has the ability to incorporate both unrelated individuals and family data. (2) Given the high density of genetic markers in largescale candidate gene and GWA studies, it is reasonable to expect that multilocus genotypes offer more information on genetic association than single-marker analysis. In Aim 2, we will develop a powerful multimarker test for gene-based association analysis and extend the method to analysis of gene-gene interactions. The virtue of our method lies in its ability to borrow strength from nearby markers while reducing the degrees of freedom. (3) In many disease gene-mapping studies, individuals are ascertained from a recently admixed population. In Aim 3, we will develop novel association tests in genetics studies using recently admixed populations. By considering ancestry level and genotypes together, our method offers higher resolution and power than traditional admixture mapping methods. (4) Appropriate adjustment for multiple dependent tests has long been a problem in genetics studies, especially for studies with limited sample size and without replication datasets. In Aim 4, we propose new methods to estimate the effective number of tests that reflect the amount of independent information contained in the data. (5) In Aim 5, we will develop, test, distribute, and support freely available implementations of the methods proposed in this application. The methods will be evaluated through analytical approaches, computer simulations and applications to multiple real datasets.       Recent development of large-scale genotyping technologies has led to the generation of an immense amount of genotype data, which raises many new challenging problems for the analysis and interpretation of the data. This application proposes developing new statistical methodologies that address a set of unresolved issues.                 n/a",Developing Statistical Methods for Disease Gene Discovery,7528283,R01HG004517,"['Address', 'Admixture', 'Algorithms', 'Area', 'Arts', 'Candidate Disease Gene', 'Chromosome Mapping', 'Complex', 'Computer Simulation', 'Computer software', 'Copy Number Polymorphism', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Family', 'Freedom', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genome', 'Genome Mappings', 'Genotype', 'Human', 'Human Gene Mapping', 'Human Genome', 'Human Genome Project', 'Individual', 'International', 'Joints', 'Maps', 'Methodology', 'Methods', 'Numbers', 'Play', 'Population', 'Procedures', 'Range', 'Research Personnel', 'Resolution', 'Role', 'SNP genotyping', 'Sample Size', 'Scientific Advances and Accomplishments', 'Statistical Methods', 'Techniques', 'Testing', 'Variant', 'Work', 'base', 'computerized tools', 'cost', 'density', 'experience', 'gene discovery', 'gene interaction', 'genetic association', 'genome wide association study', 'genotyping technology', 'markov model', 'novel']",NHGRI,VANDERBILT UNIVERSITY,R01,2008,402542,0.04131786105549995
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or        improved methods and software for a number of computational problems in          molecular biology.  The proposal and the principal investigator's current        research efforts are divided into three projects, as follows.                                                                                                     The first project centers on computational problems in the sequencing of         DNA and physical mapping of genomes.  We propose to continue refining our        algorithms and software library for the fragment assembly problem, i.e.,         determining the most likely complete DNA sequence consistent with                electrophoresis data gathered from cloned fragments.  The refinements            consist of improved algorithms for all phases of the computation: ultra-         rapid overlap detection, assembly in the presence of constraints modeling        additional experimental information, a formulation of the problem that           correctly handles repetitive sequence, and a multi-alignment component           that accommodates base-calling quality figures.  We also propose work on         ordered shotgun sequencing (OSS) and a cDNA database for the data being          generated at Washington University under contract to Merck.  Lastly, there       is much similarity between fragment assembly and physical mapping, save          that the relative level of experimental error is higher.  We propose an          algorithm for STS content mapping based on rules-of-inference that are           true with very high probability.                                                                                                                                  The second project is to design better algorithms for a number of                computational problems arising in molecular biology.  Progress in this           arena tends to be inspired rather than calculated.  We demonstrate our           track record of producing interesting results and then describe the              following problems for which we have a number of ideas and preliminary           results: sublinear Smith-Waterman database searches, determining                 restriction maps from digest data, grammar-based pattern matching,               selecting PCR primers, predicting RNA secondary structure, and docking           rigid molecules (3D matching).                                                                                                                                    The final project involves the introduction into our funded research             activities of a new area, molecular graphics.  Earlier, we developed             MacMolecule 1.7 which rendered space-filling, ball-and-stock, and wire-          frame views of molecules.  We estimate 10,000 copies are currently in use        around the world.  Our aim is high-speed, high-quality graphics, on low-         end machines achieved by virtue of very efficient rendering algorithms.          We have begun to develop a new version of MacMolecule, called Linus 2.0,         which will deliver superior performance and visualizations along with            greater capabilities, including ribbon renderings of protein secondary           structure, zoom, hi-lighting, picking, and additional visualization modes.       We further propose to build a helper application supporting ""Linus""              content files so that Linus may be used with the World-Wide Web.  In             further years, we will support molecular animation, construction, and            possibly dynamics.                                                                n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,2635404,R01LM004960,"['Internet', ' artificial intelligence', ' computer assisted sequence analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' nucleic acid sequence', ' protein sequence']",NLM,UNIVERSITY OF ARIZONA,R01,1998,157399,0.011685557944587179
"EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES We propose to design efficient computer algorithms providing novel and/or        improved methods and software for a number of computational problems in          molecular biology.  The proposal and the principal investigator's current        research efforts are divided into three projects, as follows.                                                                                                     The first project centers on computational problems in the sequencing of         DNA and physical mapping of genomes.  We propose to continue refining our        algorithms and software library for the fragment assembly problem, i.e.,         determining the most likely complete DNA sequence consistent with                electrophoresis data gathered from cloned fragments.  The refinements            consist of improved algorithms for all phases of the computation: ultra-         rapid overlap detection, assembly in the presence of constraints modeling        additional experimental information, a formulation of the problem that           correctly handles repetitive sequence, and a multi-alignment component           that accommodates base-calling quality figures.  We also propose work on         ordered shotgun sequencing (OSS) and a cDNA database for the data being          generated at Washington University under contract to Merck.  Lastly, there       is much similarity between fragment assembly and physical mapping, save          that the relative level of experimental error is higher.  We propose an          algorithm for STS content mapping based on rules-of-inference that are           true with very high probability.                                                                                                                                  The second project is to design better algorithms for a number of                computational problems arising in molecular biology.  Progress in this           arena tends to be inspired rather than calculated.  We demonstrate our           track record of producing interesting results and then describe the              following problems for which we have a number of ideas and preliminary           results: sublinear Smith-Waterman database searches, determining                 restriction maps from digest data, grammar-based pattern matching,               selecting PCR primers, predicting RNA secondary structure, and docking           rigid molecules (3D matching).                                                                                                                                    The final project involves the introduction into our funded research             activities of a new area, molecular graphics.  Earlier, we developed             MacMolecule 1.7 which rendered space-filling, ball-and-stock, and wire-          frame views of molecules.  We estimate 10,000 copies are currently in use        around the world.  Our aim is high-speed, high-quality graphics, on low-         end machines achieved by virtue of very efficient rendering algorithms.          We have begun to develop a new version of MacMolecule, called Linus 2.0,         which will deliver superior performance and visualizations along with            greater capabilities, including ribbon renderings of protein secondary           structure, zoom, hi-lighting, picking, and additional visualization modes.       We further propose to build a helper application supporting ""Linus""              content files so that Linus may be used with the World-Wide Web.  In             further years, we will support molecular animation, construction, and            possibly dynamics.                                                                n/a",EFFICIENT SOFTWARE FOR THE ANALYSIS OF BIOSEQUENCES,2032335,R01LM004960,"['Internet', ' artificial intelligence', ' computer assisted sequence analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' nucleic acid sequence', ' protein sequence']",NLM,UNIVERSITY OF ARIZONA,R01,1997,157056,0.011685557944587179
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic         or semi-automatic classification and retrieval of natural language texts,        in support of reducing the cost and improving the quality of computerized        medical information. This proposal develops further and applies a novel          approach, the Linear Least Squares Fit (LLSF) mapping, to document               indexing and document retrieval of the MEDLINE database. LLSF mapping is         a statistical method developed by the PI for learning human knowledge            about matching queries, documents, and canonical concepts. The goal is to        improve the quality (recall and precision) of automatic document indexing        and retrieval, which cannot be achieved by surface-based matching without        using human knowledge or thesaurus-based matching dependent on manually          developed synonyms. This project applies LLSF to MEDLINE, the world's            largest and most frequently used on-line database, to evaluate the               effectiveness of this method and to explore the practical potential on           large scale databases. The specific aims and methods are:                                                                                                         l. To collect data needed for the training and evaluation of the LLSF            method. A collaboration with another research institute is planned for           utilizing and refining a large collection of MEDLINE retrieval data. A           sampling of MEDLINE searches at the Mayo Clinic will be employed for             obtaining additional tasks.                                                                                                                                       2. To develop automatic noise reduction techniques for improving both the        accuracy of the LLSF mapping and the efficiency of the computation. A            multi-step noise reduction in the training process of LLSF will be               investigated, including a statistical term weighting for the removal of          non-informative terms, a truncated singular value decomposition (SVD) for        reducing the noise at the semantic structure level, and the truncation of        insignificant elements in the LLSF solution matrix for noise-reduction at        the level of term-to-concept mapping.                                                                                                                             3. To scale-up the training capacity for enabling the LLSF to accommodate        the large size of MEDLINE data. A split-merge approach decomposes a large        training sample into tractable subsets, computes an LLSF mapping function        for each subset, and then merges the lcal mapping functions into a global        one.                                                                                                                                                              4. To improve the computational efficiency by employing algorithms               optimized for sparse matrices and for noise reduction. The potential             solutions include the Block Lanczos truncated SVD algorithm which can            reduce the cubic time complexity of standard SVD (on dense matrices) to a        quadratic complexity, a QR decomposition which solves the LLSF without           SVD, a sparse matrix algorithm which has shown a speed-up in matrix              multiplication and cosine computation by a factor of l to 4 magnitudes,          and parallel computing.                                                                                                                                           5. To evaluate the effectiveness of LLSF on large MEDLINE document sets          and compare with the performance of alternate indexing/retrieval systems.         n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2897374,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,CARNEGIE-MELLON UNIVERSITY,R29,1999,103033,0.12778678542689695
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic         or semi-automatic classification and retrieval of natural language texts,        in support of reducing the cost and improving the quality of computerized        medical information. This proposal develops further and applies a novel          approach, the Linear Least Squares Fit (LLSF) mapping, to document               indexing and document retrieval of the MEDLINE database. LLSF mapping is         a statistical method developed by the PI for learning human knowledge            about matching queries, documents, and canonical concepts. The goal is to        improve the quality (recall and precision) of automatic document indexing        and retrieval, which cannot be achieved by surface-based matching without        using human knowledge or thesaurus-based matching dependent on manually          developed synonyms. This project applies LLSF to MEDLINE, the world's            largest and most frequently used on-line database, to evaluate the               effectiveness of this method and to explore the practical potential on           large scale databases. The specific aims and methods are:                                                                                                         l. To collect data needed for the training and evaluation of the LLSF            method. A collaboration with another research institute is planned for           utilizing and refining a large collection of MEDLINE retrieval data. A           sampling of MEDLINE searches at the Mayo Clinic will be employed for             obtaining additional tasks.                                                                                                                                       2. To develop automatic noise reduction techniques for improving both the        accuracy of the LLSF mapping and the efficiency of the computation. A            multi-step noise reduction in the training process of LLSF will be               investigated, including a statistical term weighting for the removal of          non-informative terms, a truncated singular value decomposition (SVD) for        reducing the noise at the semantic structure level, and the truncation of        insignificant elements in the LLSF solution matrix for noise-reduction at        the level of term-to-concept mapping.                                                                                                                             3. To scale-up the training capacity for enabling the LLSF to accommodate        the large size of MEDLINE data. A split-merge approach decomposes a large        training sample into tractable subsets, computes an LLSF mapping function        for each subset, and then merges the lcal mapping functions into a global        one.                                                                                                                                                              4. To improve the computational efficiency by employing algorithms               optimized for sparse matrices and for noise reduction. The potential             solutions include the Block Lanczos truncated SVD algorithm which can            reduce the cubic time complexity of standard SVD (on dense matrices) to a        quadratic complexity, a QR decomposition which solves the LLSF without           SVD, a sparse matrix algorithm which has shown a speed-up in matrix              multiplication and cosine computation by a factor of l to 4 magnitudes,          and parallel computing.                                                                                                                                           5. To evaluate the effectiveness of LLSF on large MEDLINE document sets          and compare with the performance of alternate indexing/retrieval systems.         n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2685564,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,CARNEGIE-MELLON UNIVERSITY,R29,1998,99071,0.12778678542689695
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic         or semi-automatic classification and retrieval of natural language texts,        in support of reducing the cost and improving the quality of computerized        medical information. This proposal develops further and applies a novel          approach, the Linear Least Squares Fit (LLSF) mapping, to document               indexing and document retrieval of the MEDLINE database. LLSF mapping is         a statistical method developed by the PI for learning human knowledge            about matching queries, documents, and canonical concepts. The goal is to        improve the quality (recall and precision) of automatic document indexing        and retrieval, which cannot be achieved by surface-based matching without        using human knowledge or thesaurus-based matching dependent on manually          developed synonyms. This project applies LLSF to MEDLINE, the world's            largest and most frequently used on-line database, to evaluate the               effectiveness of this method and to explore the practical potential on           large scale databases. The specific aims and methods are:                                                                                                         l. To collect data needed for the training and evaluation of the LLSF            method. A collaboration with another research institute is planned for           utilizing and refining a large collection of MEDLINE retrieval data. A           sampling of MEDLINE searches at the Mayo Clinic will be employed for             obtaining additional tasks.                                                                                                                                       2. To develop automatic noise reduction techniques for improving both the        accuracy of the LLSF mapping and the efficiency of the computation. A            multi-step noise reduction in the training process of LLSF will be               investigated, including a statistical term weighting for the removal of          non-informative terms, a truncated singular value decomposition (SVD) for        reducing the noise at the semantic structure level, and the truncation of        insignificant elements in the LLSF solution matrix for noise-reduction at        the level of term-to-concept mapping.                                                                                                                             3. To scale-up the training capacity for enabling the LLSF to accommodate        the large size of MEDLINE data. A split-merge approach decomposes a large        training sample into tractable subsets, computes an LLSF mapping function        for each subset, and then merges the lcal mapping functions into a global        one.                                                                                                                                                              4. To improve the computational efficiency by employing algorithms               optimized for sparse matrices and for noise reduction. The potential             solutions include the Block Lanczos truncated SVD algorithm which can            reduce the cubic time complexity of standard SVD (on dense matrices) to a        quadratic complexity, a QR decomposition which solves the LLSF without           SVD, a sparse matrix algorithm which has shown a speed-up in matrix              multiplication and cosine computation by a factor of l to 4 magnitudes,          and parallel computing.                                                                                                                                           5. To evaluate the effectiveness of LLSF on large MEDLINE document sets          and compare with the performance of alternate indexing/retrieval systems.         n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2392815,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,CARNEGIE-MELLON UNIVERSITY,R29,1997,95259,0.12778678542689695
"LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE The long-term objective of our research group is to facilitate automatic  or semi-automatic classification and retrieval of natural language texts,  in support of reducing the cost and improving the quality of computerized  medical information. This proposal develops further and applies a novel  approach, the Linear Least Squares Fit (LLSF) mapping, to document  indexing and document retrieval of the MEDLINE database. LLSF mapping is  a statistical method developed by the PI for learning human knowledge  about matching queries, documents, and canonical concepts. The goal is to  improve the quality (recall and precision) of automatic document indexing  and retrieval, which cannot be achieved by surface-based matching without  using human knowledge or thesaurus-based matching dependent on manually  developed synonyms. This project applies LLSF to MEDLINE, the world's  largest and most frequently used on-line database, to evaluate the  effectiveness of this method and to explore the practical potential on  large scale databases. The specific aims and methods are:    l. To collect data needed for the training and evaluation of the LLSF  method. A collaboration with another research institute is planned for  utilizing and refining a large collection of MEDLINE retrieval data. A  sampling of MEDLINE searches at the Mayo Clinic will be employed for  obtaining additional tasks.    2. To develop automatic noise reduction techniques for improving both the  accuracy of the LLSF mapping and the efficiency of the computation. A  multi-step noise reduction in the training process of LLSF will be  investigated, including a statistical term weighting for the removal of  non-informative terms, a truncated singular value decomposition (SVD) for  reducing the noise at the semantic structure level, and the truncation of  insignificant elements in the LLSF solution matrix for noise-reduction at  the level of term-to-concept mapping.    3. To scale-up the training capacity for enabling the LLSF to accommodate  the large size of MEDLINE data. A split-merge approach decomposes a large  training sample into tractable subsets, computes an LLSF mapping function  for each subset, and then merges the lcal mapping functions into a global  one.    4. To improve the computational efficiency by employing algorithms  optimized for sparse matrices and for noise reduction. The potential  solutions include the Block Lanczos truncated SVD algorithm which can  reduce the cubic time complexity of standard SVD (on dense matrices) to a  quadratic complexity, a QR decomposition which solves the LLSF without  SVD, a sparse matrix algorithm which has shown a speed-up in matrix  multiplication and cosine computation by a factor of l to 4 magnitudes,  and parallel computing.    5. To evaluate the effectiveness of LLSF on large MEDLINE document sets  and compare with the performance of alternate indexing/retrieval systems.  n/a",LLSF MAPPING FOR INDEXING AND RETRIEVAL OF MEDLINE,2238093,R29LM005714,"['computer program /software', ' data collection methodology /evaluation', ' indexing', ' information retrieval', ' information systems', ' semantics', ' statistics /biometry', ' vocabulary development for information system']",NLM,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R29,1995,120129,0.12778678542689695
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9482429,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2018,356951,0.06462592195700047
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9308564,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2017,356951,0.06462592195700047
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9893014,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'R programming language ', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2020,356951,0.06462592195700047
"Models and Methods for Population Genomics Project Summary Title: Models and Methods for Population Genomics Abstract: Understanding genome-wide genetic variation and its role in health-related complex traits in humans is one of the most important goals of modern biomedical research. There continues to be a substantial need for new statistical models and methods that can be applied in these studies, particularly as study designs become more ambitious and sample sizes increase. The overall goal of the proposed research is to develop statistical methods and software useful in understanding population genomics studies that involve genome-wide genotyping, many simultaneously measured traits, and very large sample sizes. Our focus is on flexible modeling that adapts to systematic variation and robustly models data encountered in these modern studies. The specific aims involve (1) developing tests of association immune to arbitrary population structure that work for general distributions of traits, many simultaneous traits, or extreme large sample sizes; (2) introducing new models and estimates of kinship and FST in generalized settings, which will lead to improved quantitative genetic modeling of complex traits; (3) introducing new estimation and testing frameworks for population structure that show superior performance to existing approaches; (4) developing and distributing software; and (5) analyzing important data sets to discover new biology and validate our methods and software. Project Narrative Understanding genome-wide patterns of genetic variation among individuals and how this relates to complex diseases is one of the primary goals of modern medical research. The proposed research will contribute to this goal by tackling a number of open problems in such a way that a coherent statistical framework and set of methodologies will emerge that can be applied to data sets of genome-wide genetic variation to produce a clearer picture of the genetic basis of human disease.",Models and Methods for Population Genomics,9666919,R01HG006448,"['Admixture', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Complex', 'Computer software', 'Data', 'Data Set', 'Disease', 'Equilibrium', 'Family', 'Genetic', 'Genetic Markers', 'Genetic Models', 'Genetic Variation', 'Genomics', 'Genotype', 'Goals', 'Health', 'Heritability', 'Human', 'Immune', 'Individual', 'Measures', 'Medical Research', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Probability', 'Procedures', 'Programming Languages', 'Quantitative Genetics', 'R programming language\xa0', 'Research', 'Research Design', 'Role', 'Sample Size', 'Seminal', 'Source Code', 'Statistical Methods', 'Statistical Models', 'Structural Models', 'Structure', 'Techniques', 'Testing', 'Update', 'Variant', 'Work', 'Writing', 'data modeling', 'flexibility', 'genetic association', 'genome-wide', 'human disease', 'improved', 'theories', 'trait', 'web site']",NHGRI,PRINCETON UNIVERSITY,R01,2019,356951,0.06462592195700047
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8683213,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,221252,0.046045769280906486
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8518436,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,220626,0.046045769280906486
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.        PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.              DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8350385,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Base Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'RNA', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'tool', 'transcription factor', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2012,220000,0.021649211781180403
"Knowledge Mapping Across Disparate Patient Care Datasets DESCRIPTION: (provided by applicant) Health informatics can yield computational insight in assimilating knowledge from large clinical datasets for both research and policy discussion. The adoption of computerized patient records (CPR) by healthcare organizations promises to expand the sources potential research data to include clinical patient data. Applications of health informatics can enhance health services and clinical research, as well as improve healthcare quality. A primary goal of this traineeship in health informatics is to gain expertise in the modeling of clinical knowledge and the mapping of this knowledge to alternative taxonomies and meta-languages. A computational approach to this knowledge modeling and mapping will enable the creation of methodologies for aggregating clinical data from disparate data storage systems for large analyses. The proposed research is a first step in creating a regional health data repository. Broadly, this research will explore how various health data systems created by the private sector to facilitate healthcare delivery will support the secondary analysis of healthcare information for both health services and clinical research. Specifically, this research will examine the attributes and knowledge representation of multiple patient care data sources, and map the knowledge relevant to vancomycin-resistant nosocomial infections indexed to a common Unified Medical Language System (UMLS) integrated knowledge base for combined outcomes analyses. n/a",Knowledge Mapping Across Disparate Patient Care Datasets,6622211,F38LM007187,"['data collection methodology /evaluation', ' drug resistance', ' human data', ' indexing', ' informatics', ' information systems', ' information theory', ' medical records', ' nosocomial infections', ' patient care management', ' predoctoral investigator', ' vancomycin']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2003,58483,0.04380497308057333
"Knowledge Mapping Across Disparate Patient Care Datasets DESCRIPTION: (provided by applicant) Health informatics can yield computational insight in assimilating knowledge from large clinical datasets for both research and policy discussion. The adoption of computerized patient records (CPR) by healthcare organizations promises to expand the sources potential research data to include clinical patient data. Applications of health informatics can enhance health services and clinical research, as well as improve healthcare quality. A primary goal of this traineeship in health informatics is to gain expertise in the modeling of clinical knowledge and the mapping of this knowledge to alternative taxonomies and meta-languages. A computational approach to this knowledge modeling and mapping will enable the creation of methodologies for aggregating clinical data from disparate data storage systems for large analyses. The proposed research is a first step in creating a regional health data repository. Broadly, this research will explore how various health data systems created by the private sector to facilitate healthcare delivery will support the secondary analysis of healthcare information for both health services and clinical research. Specifically, this research will examine the attributes and knowledge representation of multiple patient care data sources, and map the knowledge relevant to vancomycin-resistant nosocomial infections indexed to a common Unified Medical Language System (UMLS) integrated knowledge base for combined outcomes analyses. n/a",Knowledge Mapping Across Disparate Patient Care Datasets,6442837,F38LM007187,"['data collection methodology /evaluation', ' drug resistance', ' human data', ' indexing', ' informatics', ' information systems', ' information theory', ' medical records', ' nosocomial infections', ' patient care management', ' predoctoral investigator', ' vancomycin']",NLM,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,F38,2002,57671,0.04380497308057333
"Medical Vocabulary Support for Patients DESCRIPTION (provided by applicant): Consumers and patients are confronted with a plethora of health and health care information, especially through the proliferation of web content resources. Democratization of the web is an important milestone for patients and consumers since it helps to empower them, make them better advocates on their own behalf and foster better, more informed decisions about their health. Nonetheless, they have difficulties in identifying and accessing information that answers their specific questions, through standard information retrieval (IR) and text-based search techniques. This is partly due to vocabulary mismatches between lay terminology and the concepts that underlie medical/technical content. In addition, mental models of patients may not match the conceptual models of content developers, or of content indexers. Although a rich array of tools and vocabularies exists, current term mapping methods and tools for medical professionals are not sufficient to meet patients' needs. The goal of this project is to develop an improved means for patients to search for information resources relating to questions they may have about their health. We will define the characteristics of patient terminology in the context of carrying out web-based IR tasks, and develop a new scalable and flexible patient term mapping and linking method by combining knowledge-based and data-driven approaches. The proposed method uses a semantic network with weighted relations among concepts where the weights signify the semantic closeness between the concepts. The weights and relations can be updated based on prior successful retrievals and can be adapted to specific application contexts. A patient-oriented medical vocabulary tool will be developed that will assist patients in formulating queries for retrieving resources from the Internet. The project will build on existing tools and vocabularies for health information indexing and retrieval, and enhance these resources by incorporating tools and methods that map patient-oriented concepts and mental models to them. The method and the tools developed will be evaluated for their impact on patient IR in a randomized controlled study. Subjects in the study will attempt to retrieve healthcare information pertaining to specific scenarios that they will be provided. We will measure IR precision and recall, discriminating ability, self-perceived success (by subjects), and user-satisfaction with and without the vocabulary support.  n/a",Medical Vocabulary Support for Patients,6699042,R01LM007222,"['Internet', 'abstracting', 'biotechnology', 'clinical research', 'educational resource design /development', 'health education', 'human subject', 'informatics', 'information retrieval', 'information system analysis', 'interview', 'library', 'vocabulary', 'vocabulary development for information system']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2004,238740,0.011391825653652102
"Medical Vocabulary Support for Patients DESCRIPTION (provided by applicant): Consumers and patients are confronted with a plethora of health and health care information, especially through the proliferation of web content resources. Democratization of the web is an important milestone for patients and consumers since it helps to empower them, make them better advocates on their own behalf and foster better, more informed decisions about their health. Nonetheless, they have difficulties in identifying and accessing information that answers their specific questions, through standard information retrieval (IR) and text-based search techniques. This is partly due to vocabulary mismatches between lay terminology and the concepts that underlie medical/technical content. In addition, mental models of patients may not match the conceptual models of content developers, or of content indexers. Although a rich array of tools and vocabularies exists, current term mapping methods and tools for medical professionals are not sufficient to meet patients' needs. The goal of this project is to develop an improved means for patients to search for information resources relating to questions they may have about their health. We will define the characteristics of patient terminology in the context of carrying out web-based IR tasks, and develop a new scalable and flexible patient term mapping and linking method by combining knowledge-based and data-driven approaches. The proposed method uses a semantic network with weighted relations among concepts where the weights signify the semantic closeness between the concepts. The weights and relations can be updated based on prior successful retrievals and can be adapted to specific application contexts. A patient-oriented medical vocabulary tool will be developed that will assist patients in formulating queries for retrieving resources from the Internet. The project will build on existing tools and vocabularies for health information indexing and retrieval, and enhance these resources by incorporating tools and methods that map patient-oriented concepts and mental models to them. The method and the tools developed will be evaluated for their impact on patient IR in a randomized controlled study. Subjects in the study will attempt to retrieve healthcare information pertaining to specific scenarios that they will be provided. We will measure IR precision and recall, discriminating ability, self-perceived success (by subjects), and user-satisfaction with and without the vocabulary support.  n/a",Medical Vocabulary Support for Patients,6620110,R01LM007222,"['Internet', ' abstracting', ' biotechnology', ' clinical research', ' educational resource design /development', ' health education', ' human subject', ' informatics', ' information retrieval', ' information system analysis', ' interview', ' library', ' vocabulary', ' vocabulary development for information system']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2003,238740,0.011391825653652102
"Medical Vocabulary Support for Patients DESCRIPTION (provided by applicant): Consumers and patients are confronted with a plethora of health and health care information, especially through the proliferation of web content resources. Democratization of the web is an important milestone for patients and consumers since it helps to empower them, make them better advocates on their own behalf and foster better, more informed decisions about their health. Nonetheless, they have difficulties in identifying and accessing information that answers their specific questions, through standard information retrieval (IR) and text-based search techniques. This is partly due to vocabulary mismatches between lay terminology and the concepts that underlie medical/technical content. In addition, mental models of patients may not match the conceptual models of content developers, or of content indexers. Although a rich array of tools and vocabularies exists, current term mapping methods and tools for medical professionals are not sufficient to meet patients' needs. The goal of this project is to develop an improved means for patients to search for information resources relating to questions they may have about their health. We will define the characteristics of patient terminology in the context of carrying out web-based IR tasks, and develop a new scalable and flexible patient term mapping and linking method by combining knowledge-based and data-driven approaches. The proposed method uses a semantic network with weighted relations among concepts where the weights signify the semantic closeness between the concepts. The weights and relations can be updated based on prior successful retrievals and can be adapted to specific application contexts. A patient-oriented medical vocabulary tool will be developed that will assist patients in formulating queries for retrieving resources from the Internet. The project will build on existing tools and vocabularies for health information indexing and retrieval, and enhance these resources by incorporating tools and methods that map patient-oriented concepts and mental models to them. The method and the tools developed will be evaluated for their impact on patient IR in a randomized controlled study. Subjects in the study will attempt to retrieve healthcare information pertaining to specific scenarios that they will be provided. We will measure IR precision and recall, discriminating ability, self-perceived success (by subjects), and user-satisfaction with and without the vocabulary support.  n/a",Medical Vocabulary Support for Patients,6368778,R01LM007222,"['Internet', ' abstracting', ' biotechnology', ' clinical research', ' educational resource design /development', ' health education', ' human subject', ' informatics', ' information retrieval', ' information system analysis', ' interview', ' library', ' vocabulary', ' vocabulary development for information system']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2002,235899,0.011391825653652102
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,8849936,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2015,681355,-0.011437750732886026
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,9121301,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2015,124339,-0.011437750732886026
"NHGRI PAGE Coordinating Center     DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE.         PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.                ",NHGRI PAGE Coordinating Center,8728994,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Metric', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2014,690507,-0.011437750732886026
"NHGRI PAGE Coordinating Center     DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE.         PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.                ",NHGRI PAGE Coordinating Center,8573120,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Metric', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Population Study', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'software development', 'success', 'symposium', 'tool', 'web site', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2013,720000,-0.011437750732886026
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,9065945,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Cataloging', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiologic Studies', 'Epidemiology', 'European', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Productivity', 'Protocols documentation', 'Publications', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost efficient', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'next generation sequencing', 'programs', 'public health relevance', 'rare variant', 'software development', 'study population', 'success', 'symposium', 'tool', 'web site', 'whole genome', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2016,728166,-0.011437750732886026
"NHGRI PAGE Coordinating Center DESCRIPTION (provided by applicant): NHGRI developed the Population Architecture Using Genomics and Epidemiology (PAGE) research program to identify and characterize genomic variants in non-European populations. To support the complexities of such an ambitious effort, we have convened a strong team of statistical, population, and molecular geneticists, computer and information scientists, biostatisticians, and project management staff with many years of related experience to serve as a Coordinating Center (CC). Specifically, the CC will serve as a centralized resource to facilitate and support the activities of the program and Study Investigators focused on characterization of causal variants by: (1) coordinating phenotype harmonization efforts, including mapping phenotype variables across studies and to the PhenX measures; (2) synthesizing individual-level data into centralized datasets to facilitate sharing of data within and outside of PAGE; (3) utilizing state-of-the-art computer and information science support and scientific workflows that will facilitate analyses, ancestry deconvolution, genotype calling and imputation, SNP annotation, and data synthesis; (4) rapidly disseminating all study data via dbGaP and/or the PAGE website or other applicable databases; and (5) serving as a centralized resource to facilitate, support, and manage program activities and logistics as requested by the Steering Committee or Project Office and as needed for successful coordination of the program. Coordination of the program will be done in a spirit of collaboration using creative and flexible approaches, while providing leadership in statistical genetic methodologies and approaches to project management. The ultimate goal of our CC is to facilitate the identification and characterization of genotype-phenotype associations, especially as relevant to non-European populations, thereby accelerating our understanding of ancestral differences in the genetic and environmental causes of common diseases. Critical to achieving this mission is the deployment of powerful methods for ancestry deconvolution, multi- and trans-ethnic mapping, and imputation. Building upon our success as the PAGE I CC, we have added additional investigators with expertise in these areas and consortium experience with next-generation sequence analysis of both whole-genome and exome data. Our collaborative team is ideally staffed to meet the challenges of the new round of PAGE. PUBLIC HEALTH RELEVANCE: The PAGE study focuses on analysis of existing large samples of primarily non- European ancestry to broaden our understanding of the ethnic differences in the genetic basis of complex disease. The PAGE coordinating center supports the functions of this study.",NHGRI PAGE Coordinating Center,9461800,U01HG007419,"['African American', 'Architecture', 'Area', 'Biological Assay', 'Catalogs', 'Collaborations', 'Communication', 'Complex', 'Computers', 'Custom', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Deposition', 'Disease', 'Documentation', 'Eligibility Determination', 'Ensure', 'Epidemiologic Methods', 'Epidemiology', 'Funding', 'Future', 'Genetic', 'Genome', 'Genomic Segment', 'Genotype', 'Goals', 'Group Meetings', 'Hispanics', 'Individual', 'Information Sciences', 'Informed Consent', 'Internet', 'Latino', 'Leadership', 'Letters', 'Logistics', 'Machine Learning', 'Measures', 'Methodology', 'Methods', 'Mining', 'Mission', 'Molecular', 'Monitor', 'National Heart, Lung, and Blood Institute', 'National Human Genome Research Institute', 'Phase', 'Phenotype', 'Population', 'Productivity', 'Protocols documentation', 'Publications', 'Recruitment Activity', 'Reporting', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Scientist', 'Sequence Analysis', 'Site', 'Source', 'Standardization', 'Technology', 'Time', 'Translational Research', 'Update', 'Variant', 'Voice', 'Work', 'base', 'computer science', 'cost efficient', 'data sharing', 'database of Genotypes and Phenotypes', 'design', 'disease phenotype', 'epidemiology study', 'ethnic difference', 'exome', 'exome sequencing', 'experience', 'flexibility', 'formycin triphosphate', 'genetic analysis', 'genetic epidemiology', 'genetic variant', 'genomic epidemiology', 'genomic variation', 'improved', 'instrument', 'meetings', 'next generation', 'programs', 'public health relevance', 'rare variant', 'software development', 'study population', 'success', 'symposium', 'tool', 'web site', 'whole genome', 'wiki', 'working group']",NHGRI,"RUTGERS, THE STATE UNIV OF N.J.",U01,2017,710189,-0.011437750732886026
"Enhanced Gene Identification in Complex Traits Using Kernel Machines DESCRIPTION (provided by applicant):     Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5). PUBLIC HEALTH RELEVANCE:     Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8894057,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genetic screening method', 'Genetic study', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'methylation pattern', 'next generation sequencing', 'novel', 'open source', 'population based', 'predictive modeling', 'rare variant', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2015,341249,0.12941386832870974
"Enhanced Gene Identification in Complex Traits Using Kernel Machines     DESCRIPTION (provided by applicant):     Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5).         PUBLIC HEALTH RELEVANCE:     Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.            ",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8729618,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Pattern', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Simulate', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'next generation sequencing', 'novel', 'open source', 'population based', 'public health relevance', 'rare variant', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2014,343000,0.12941386832870974
"Enhanced Gene Identification in Complex Traits Using Kernel Machines DESCRIPTION (provided by applicant):  Project Summary/Abstract Genome-wide association studies (GWAS) have mapped thousands of common trait-influencing variants yet the overwhelming majority of trait loci have yet to be discovered. The goal of this proposal is to develop and apply statistical approaches that move beyond the standard GWAS paradigm to map additional trait-influencing variation within the human genome. Most of our proposed tools are based on a flexible high-dimensional framework called kernel machine regression, which we have had past success employing for powerful gene mapping of complex traits in GWAS and next-generation sequencing (NGS) studies. We believe the inherent flexibility of the kernel framework makes it ideal for exploring new paradigms in gene mapping of complex human traits. Aim 1 proposes novel kernel methods for integrated analysis of both single-nucleotide variation data (derived from GWAS and/or NGS) and genomic data (such as gene-expression and methylation patterns) that we believe will provide improved power for trait mapping. Aim 2 proposes novel kernel methods for large scale gene-gene interaction analysis across the genome, as well as a computational approach that enables efficient adjustment for multiple testing when applying such exhaustive testing procedures. Aim 3 establishes novel kernel methods for association mapping of SNVs on the X chromosome. The flexible nature of kernel machines makes it ideal for modeling potential sex-specific effects on this chromosome and the methods further can accommodate random X inactivation. Aim 4 proposes novel kernel approach for robust analysis of rare trait-influencing variation within families; such family-based designs are generally not considered in current rare-variant procedures. We will evaluate these methods on large-scale datasets that we are actively involved in and will implement the methods in user-friendly software for public distribution (Aim 5). PUBLIC HEALTH RELEVANCE:  Project Narrative The goal of this project is to develop novel and powerful statistical tools for identifying genetic loci acting independently or in conjunction with other genetic/environmental factors to influence complex human diseases or disease-related quantitative traits. Application of the proposed methods to applied datasets should improve our understanding of the genetic origins of complex traits and enhance existing risk-prediction models of complex disease.",Enhanced Gene Identification in Complex Traits Using Kernel Machines,8598704,R01HG007508,"['Address', 'Biological', 'Chromosome Mapping', 'Chromosomes', 'Complex', 'Computer software', 'DNA Resequencing', 'Data', 'Data Set', 'Disease', 'Environmental Risk Factor', 'Epilepsy', 'Exhibits', 'Family', 'Gene Expression', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Human Genome', 'Individual', 'Joints', 'Link', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Methylation', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nuclear Family', 'Nucleotides', 'Other Genetics', 'Pattern', 'Performance', 'Play', 'Post-Traumatic Stress Disorders', 'Procedures', 'Public Health', 'Research Design', 'Research Personnel', 'Risk', 'Role', 'Scientific Advances and Accomplishments', 'Sex Bias', 'Simulate', 'Source', 'Statistical Methods', 'Study models', 'Technology', 'Testing', 'Variant', 'Work', 'X Chromosome', 'X Inactivation', 'X inherited trait', 'abstracting', 'base', 'case control', 'design', 'flexibility', 'gene interaction', 'genetic analysis', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'human disease', 'improved', 'interest', 'next generation sequencing', 'novel', 'open source', 'population based', 'sex', 'stem', 'success', 'tool', 'trait', 'user friendly software']",NHGRI,EMORY UNIVERSITY,R01,2013,350000,0.12941386832870974
"Advanced Gene Mapping Course DESCRIPTION (provided by applicant): The specific aim of this proposal is to carry out an annual, full week course in advanced gene mapping at The Rockefeller University in New York. The course is directed towards advanced researchers who are familiar with the basic aspects of statistical genetics but who need to become more proficient in the analysis of complex traits. The course will be held in Weiss Hall which is equipped with 34 laptops running Linux and windows.  Travel stipends will be provided to seven of the participants who are either predoctoral students or postdoctoral fellows to cover the cost of airfare, hotel and board.    The course consists of two components: lectures on important, current topics in gene mapping, as well as hands on exercises to be carried out with the latest software programs. The current emphasis of the course is association analysis of rare variants obtained from next generation sequence data. In the January 28February  1, 2013 Advanced Gene Mapping course topics will include: whole genome association analysis of quantitative  and qualitative traits (population and family based data); association analysis of common (generated from genotyping arrays) and of rare (obtained from next generation sequence data) variants; data quality control for  sequence and genotype data; functional prediction of variant sites, calling variants from sequence data,  controlling for population substructure\admixture;  data quality control (genotype and sequence data);  imputation of data from genotypes (e.g. HapMap) and whole genome sequence data (e.g. 1000genomes);  meta analysis;  gene x gene interaction; sample size estimation and evaluating power (for rare and common  variants). Programs that will be taught and utilized by course participants include: Armitage Power Tool, Eigenstrat, GenABEL, METAL, MINIMAC, Mutation Taster, PLINK, Polyphen2, PSEQ, QTDT, Quanto, R, RarePower, SIFT, SimRare UnMAKE, and variant association tool (VAT). Since gene mapping is a quickly changing field the topics and analytic programs will be updated and changed annually to reflect the latest developments in the field of statistical genetics. Given the large increases in the amount of genetic data being  generated, and in particular sequence data, it is extremely important to train researchers and give them the  necessary information and tools to analyze this data to bring about a better understanding of the etiology of  complex traits. PUBLIC HEALTH RELEVANCE: The goal of this grant is to provide training in gene mapping. This course will advance the training of researchers and students in the area of statistical genetics to allow them to perform gene mapping of complex  traits, which in turn will lead to an improvement in the analysis of genetic data thus increasing knowledge of the  genetics of complex disease etiology.",Advanced Gene Mapping Course,9039649,R25HG007511,"['Admixture', 'Area', 'Basic Science', 'Bioinformatics', 'Categories', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Files', 'Data Quality', 'Detection', 'Development', 'Disease', 'Educational process of instructing', 'Etiology', 'Exercise', 'Family', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genome', 'Genotype', 'Goals', 'Grant', 'Hand', 'Health', 'Human Gene Mapping', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Linux', 'Logistic Regressions', 'Memory', 'Meta-Analysis', 'Methods', 'Mutation', 'New York', 'Online Systems', 'Participant', 'Population', 'Population Control', 'Postdoctoral Fellow', 'Principal Component Analysis', 'Principal Investigator', 'Quality Control', 'Research', 'Research Personnel', 'Running', 'Sample Size', 'Sequence Analysis', 'Site', 'Students', 'System', 'Techniques', 'Training', 'Travel', 'Universities', 'Update', 'Variant', 'Waiting Lists', 'Wireless Technology', 'base', 'cost', 'experience', 'file format', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'human disease', 'laptop', 'lectures', 'meetings', 'next generation sequencing', 'population based', 'power analysis', 'pre-doctoral', 'programs', 'rare variant', 'theories', 'tool', 'trait', 'whole genome']",NHGRI,ROCKEFELLER UNIVERSITY,R25,2016,53995,0.030377624892506488
"Advanced Gene Mapping Course DESCRIPTION (provided by applicant): The specific aim of this proposal is to carry out an annual, full week course in advanced gene mapping at The Rockefeller University in New York. The course is directed towards advanced researchers who are familiar with the basic aspects of statistical genetics but who need to become more proficient in the analysis of complex traits. The course will be held in Weiss Hall which is equipped with 34 laptops running Linux and windows.  Travel stipends will be provided to seven of the participants who are either predoctoral students or postdoctoral fellows to cover the cost of airfare, hotel and board.    The course consists of two components: lectures on important, current topics in gene mapping, as well as hands on exercises to be carried out with the latest software programs. The current emphasis of the course is association analysis of rare variants obtained from next generation sequence data. In the January 28February  1, 2013 Advanced Gene Mapping course topics will include: whole genome association analysis of quantitative  and qualitative traits (population and family based data); association analysis of common (generated from genotyping arrays) and of rare (obtained from next generation sequence data) variants; data quality control for  sequence and genotype data; functional prediction of variant sites, calling variants from sequence data,  controlling for population substructure\admixture;  data quality control (genotype and sequence data);  imputation of data from genotypes (e.g. HapMap) and whole genome sequence data (e.g. 1000genomes);  meta analysis;  gene x gene interaction; sample size estimation and evaluating power (for rare and common  variants). Programs that will be taught and utilized by course participants include: Armitage Power Tool, Eigenstrat, GenABEL, METAL, MINIMAC, Mutation Taster, PLINK, Polyphen2, PSEQ, QTDT, Quanto, R, RarePower, SIFT, SimRare UnMAKE, and variant association tool (VAT). Since gene mapping is a quickly changing field the topics and analytic programs will be updated and changed annually to reflect the latest developments in the field of statistical genetics. Given the large increases in the amount of genetic data being  generated, and in particular sequence data, it is extremely important to train researchers and give them the  necessary information and tools to analyze this data to bring about a better understanding of the etiology of  complex traits. PUBLIC HEALTH RELEVANCE: The goal of this grant is to provide training in gene mapping. This course will advance the training of researchers and students in the area of statistical genetics to allow them to perform gene mapping of complex  traits, which in turn will lead to an improvement in the analysis of genetic data thus increasing knowledge of the  genetics of complex disease etiology.",Advanced Gene Mapping Course,8824548,R25HG007511,"['Admixture', 'Area', 'Basic Science', 'Bioinformatics', 'Categories', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Files', 'Data Quality', 'Databases', 'Detection', 'Development', 'Disease', 'Educational process of instructing', 'Etiology', 'Exercise', 'Family', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genome', 'Genotype', 'Goals', 'Grant', 'Hand', 'Health', 'Human Gene Mapping', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Linux', 'Logistic Regressions', 'Memory', 'Meta-Analysis', 'Methods', 'Mutation', 'New York', 'Online Systems', 'Participant', 'Population', 'Population Control', 'Postdoctoral Fellow', 'Principal Component Analysis', 'Principal Investigator', 'Quality Control', 'Research', 'Research Personnel', 'Running', 'Sample Size', 'Sequence Analysis', 'Site', 'Students', 'System', 'Techniques', 'Training', 'Travel', 'Universities', 'Update', 'Variant', 'Waiting Lists', 'Wireless Technology', 'base', 'cost', 'experience', 'file format', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'human disease', 'laptop', 'lectures', 'meetings', 'next generation sequencing', 'population based', 'pre-doctoral', 'programs', 'rare variant', 'theories', 'tool', 'trait']",NHGRI,ROCKEFELLER UNIVERSITY,R25,2015,53995,0.030377624892506488
"Advanced Gene Mapping Course     DESCRIPTION (provided by applicant): The specific aim of this proposal is to carry out an annual, full week course in advanced gene mapping at The Rockefeller University in New York. The course is directed towards advanced researchers who are familiar with the basic aspects of statistical genetics but who need to become more proficient in the analysis of complex traits. The course will be held in Weiss Hall which is equipped with 34 laptops running Linux and windows.  Travel stipends will be provided to seven of the participants who are either predoctoral students or postdoctoral fellows to cover the cost of airfare, hotel and board.    The course consists of two components: lectures on important, current topics in gene mapping, as well as hands on exercises to be carried out with the latest software programs. The current emphasis of the course is association analysis of rare variants obtained from next generation sequence data. In the January 28February  1, 2013 Advanced Gene Mapping course topics will include: whole genome association analysis of quantitative  and qualitative traits (population and family based data); association analysis of common (generated from genotyping arrays) and of rare (obtained from next generation sequence data) variants; data quality control for  sequence and genotype data; functional prediction of variant sites, calling variants from sequence data,  controlling for population substructure\admixture;  data quality control (genotype and sequence data);  imputation of data from genotypes (e.g. HapMap) and whole genome sequence data (e.g. 1000genomes);  meta analysis;  gene x gene interaction; sample size estimation and evaluating power (for rare and common  variants). Programs that will be taught and utilized by course participants include: Armitage Power Tool, Eigenstrat, GenABEL, METAL, MINIMAC, Mutation Taster, PLINK, Polyphen2, PSEQ, QTDT, Quanto, R, RarePower, SIFT, SimRare UnMAKE, and variant association tool (VAT). Since gene mapping is a quickly changing field the topics and analytic programs will be updated and changed annually to reflect the latest developments in the field of statistical genetics. Given the large increases in the amount of genetic data being  generated, and in particular sequence data, it is extremely important to train researchers and give them the  necessary information and tools to analyze this data to bring about a better understanding of the etiology of  complex traits.          PUBLIC HEALTH RELEVANCE: The goal of this grant is to provide training in gene mapping. This course will advance the training of researchers and students in the area of statistical genetics to allow them to perform gene mapping of complex  traits, which in turn will lead to an improvement in the analysis of genetic data thus increasing knowledge of the  genetics of complex disease etiology.                 ",Advanced Gene Mapping Course,8603701,R25HG007511,"['Admixture', 'Area', 'Basic Science', 'Bioinformatics', 'Categories', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Files', 'Data Quality', 'Databases', 'Detection', 'Development', 'Disease', 'Educational process of instructing', 'Etiology', 'Exercise', 'Family', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genome', 'Genotype', 'Goals', 'Grant', 'Hand', 'Human Gene Mapping', 'Internet', 'Knowledge', 'Lead', 'Libraries', 'Linux', 'Logistic Regressions', 'Memory', 'Meta-Analysis', 'Methods', 'Mutation', 'New York', 'Online Systems', 'Participant', 'Population', 'Population Control', 'Postdoctoral Fellow', 'Principal Component Analysis', 'Principal Investigator', 'Quality Control', 'Research', 'Research Personnel', 'Running', 'Sample Size', 'Sequence Analysis', 'Site', 'Students', 'System', 'Techniques', 'Training', 'Travel', 'Universities', 'Update', 'Variant', 'Waiting Lists', 'Wireless Technology', 'base', 'cost', 'experience', 'file format', 'genetic analysis', 'genetic epidemiology', 'genetic linkage analysis', 'genome sequencing', 'genome wide association study', 'human disease', 'laptop', 'lectures', 'meetings', 'next generation sequencing', 'population based', 'pre-doctoral', 'programs', 'public health relevance', 'rare variant', 'theories', 'tool', 'trait']",NHGRI,ROCKEFELLER UNIVERSITY,R25,2014,53995,0.030377624892506488
"Advanced Gene Mapping Course Project Summary  The specific aim of this proposal is to carry out an annual, full-week course in advanced gene mapping at The Rockefeller University in New York. The course is directed towards advanced researchers who are familiar with the basic aspects of statistical genetics but who need to become more proficient in the analysis of complex traits. The course will be held in the Great Hall in Welch which is equipped for the course with laptops running Linux. Thirty students will be accepted for each course.. Travel stipends will be provided to five of the participants who are either pre-doctoral students or post-doctoral fellows to cover the cost of airfare, hotel and board.  The course consists of two components: lectures on important, current topics in gene mapping, as well as hands on exercises to be carried out with the latest freeware software programs. The current emphasis of the course is association analysis of rare variants obtained from next generation sequence data. For the next Advanced Gene Mapping course held January 25-29, 2016 the topics will include: analysis of whole genome association studies; analysis of rare variants using next generation sequence data; analysis of qualitative and quantitative traits (population and family-based data); mixed linear models; eQTL mapping; prediction models using RNAseq and array data; inferences for heritability estimation and prediction; functional predication of variant sites, variant annotation; variant calling, controlling for population substructure/admixture (principal components analysis/multidimensionality scaling); data quality control of genotype and sequence data; meta-analysis; gene x gene interaction; sample size estimation and evaluating power for common and rare variants. Programs that will be taught and utilized by course participants include: ANNOVAR, BEAM3, CADD, GERP, GotCloud, GenAbel, PLINK, Polyphen-2, R, SEQPower, Variant Association Tools (VAT), etc. Since gene mapping is a quickly changing field, the topics and analytic programs will be updated and changed annually to reflect the latest developments in the field of statistical genetics. Given the large increases in the amount of genetic data being generated, and in particular sequence data, it is extremely important to train researchers and give them the necessary information and tools for data analysis to elucidate the etiology of complex traits. Project Narrative The aim of this proposal is to carry out an annual, full-week course in advanced gene mapping at The Rockefeller University in New York City. The course is directed towards advanced researchers with knowledge in statistics and genetics and will provide participants with information on the latest methods to identify disease genes for complex traits. Thirty participants will be admitted to the course and travel stipends will be provided to five participants who are either pre-doctoral students or post-doctoral fellows to cover the cost of airfare, hotel and board.  ",Advanced Gene Mapping Course,9463934,R25HG007511,"['Admixture', 'Basic Science', 'Bioinformatics', 'Categories', 'Chromosome Mapping', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Files', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Etiology', 'Evaluation', 'Exercise', 'Faculty', 'Family', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Predisposition to Disease', 'Genotype', 'Genus Mentha', 'Heritability', 'Human Gene Mapping', 'Individual', 'Knowledge', 'Libraries', 'Linear Models', 'Linux', 'Logistic Regressions', 'Memory', 'Meta-Analysis', 'Methodology', 'Methods', 'New York', 'New York City', 'Online Systems', 'Participant', 'Population', 'Population Control', 'Postdoctoral Fellow', 'Principal Component Analysis', 'Quality Control', 'Research Personnel', 'Running', 'S-nitro-N-acetylpenicillamine', 'Sample Size', 'Sequence Analysis', 'Site', 'Students', 'System', 'Techniques', 'Training', 'Travel', 'Universities', 'Update', 'Variant', 'base', 'cost', 'doctoral student', 'experience', 'file format', 'genetic epidemiology', 'genetic linkage analysis', 'genome wide association study', 'human disease', 'insight', 'instructor', 'laptop', 'learning materials', 'lectures', 'next generation sequence data', 'population based', 'power analysis', 'pre-doctoral', 'predictive modeling', 'programs', 'rare variant', 'statistics', 'theories', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'web site']",NHGRI,ROCKEFELLER UNIVERSITY,R25,2018,53621,0.009888961963040632
"Advanced Gene Mapping Course Project Summary  The specific aim of this proposal is to carry out an annual, full-week course in advanced gene mapping at The Rockefeller University in New York. The course is directed towards advanced researchers who are familiar with the basic aspects of statistical genetics but who need to become more proficient in the analysis of complex traits. The course will be held in the Great Hall in Welch which is equipped for the course with laptops running Linux. Thirty students will be accepted for each course.. Travel stipends will be provided to five of the participants who are either pre-doctoral students or post-doctoral fellows to cover the cost of airfare, hotel and board.  The course consists of two components: lectures on important, current topics in gene mapping, as well as hands on exercises to be carried out with the latest freeware software programs. The current emphasis of the course is association analysis of rare variants obtained from next generation sequence data. For the next Advanced Gene Mapping course held January 25-29, 2016 the topics will include: analysis of whole genome association studies; analysis of rare variants using next generation sequence data; analysis of qualitative and quantitative traits (population and family-based data); mixed linear models; eQTL mapping; prediction models using RNAseq and array data; inferences for heritability estimation and prediction; functional predication of variant sites, variant annotation; variant calling, controlling for population substructure/admixture (principal components analysis/multidimensionality scaling); data quality control of genotype and sequence data; meta-analysis; gene x gene interaction; sample size estimation and evaluating power for common and rare variants. Programs that will be taught and utilized by course participants include: ANNOVAR, BEAM3, CADD, GERP, GotCloud, GenAbel, PLINK, Polyphen-2, R, SEQPower, Variant Association Tools (VAT), etc. Since gene mapping is a quickly changing field, the topics and analytic programs will be updated and changed annually to reflect the latest developments in the field of statistical genetics. Given the large increases in the amount of genetic data being generated, and in particular sequence data, it is extremely important to train researchers and give them the necessary information and tools for data analysis to elucidate the etiology of complex traits. Project Narrative The aim of this proposal is to carry out an annual, full-week course in advanced gene mapping at The Rockefeller University in New York City. The course is directed towards advanced researchers with knowledge in statistics and genetics and will provide participants with information on the latest methods to identify disease genes for complex traits. Thirty participants will be admitted to the course and travel stipends will be provided to five participants who are either pre-doctoral students or post-doctoral fellows to cover the cost of airfare, hotel and board.  ",Advanced Gene Mapping Course,9208387,R25HG007511,"['Admixture', 'Basic Science', 'Bioinformatics', 'Categories', 'Chromosome Mapping', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Files', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Etiology', 'Evaluation', 'Exercise', 'Faculty', 'Family', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Predisposition to Disease', 'Genotype', 'Genus Mentha', 'Heritability', 'Human Gene Mapping', 'Individual', 'Knowledge', 'Libraries', 'Linear Models', 'Linux', 'Logistic Regressions', 'Memory', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'New York', 'New York City', 'Online Systems', 'Participant', 'Population', 'Population Control', 'Postdoctoral Fellow', 'Principal Component Analysis', 'Quality Control', 'Research Personnel', 'Running', 'S-nitro-N-acetylpenicillamine', 'Sample Size', 'Sequence Analysis', 'Site', 'Students', 'System', 'Techniques', 'Training', 'Travel', 'Universities', 'Update', 'Variant', 'base', 'cost', 'experience', 'file format', 'genetic epidemiology', 'genetic linkage analysis', 'genome wide association study', 'genome-wide analysis', 'human disease', 'insight', 'instructor', 'laptop', 'learning materials', 'lectures', 'next generation', 'population based', 'power analysis', 'pre-doctoral', 'programs', 'rare variant', 'statistics', 'theories', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'web site']",NHGRI,ROCKEFELLER UNIVERSITY,R25,2017,54000,0.009888961963040632
"Advanced Gene Mapping Course Project Summary  The specific aim of this proposal is to carry out an annual, full-week course in advanced gene mapping at The Rockefeller University in New York. The course is directed towards advanced researchers who are familiar with the basic aspects of statistical genetics but who need to become more proficient in the analysis of complex traits. The course will be held in the Great Hall in Welch which is equipped for the course with laptops running Linux. Thirty students will be accepted for each course.. Travel stipends will be provided to five of the participants who are either pre-doctoral students or post-doctoral fellows to cover the cost of airfare, hotel and board.  The course consists of two components: lectures on important, current topics in gene mapping, as well as hands on exercises to be carried out with the latest freeware software programs. The current emphasis of the course is association analysis of rare variants obtained from next generation sequence data. For the next Advanced Gene Mapping course held January 25-29, 2016 the topics will include: analysis of whole genome association studies; analysis of rare variants using next generation sequence data; analysis of qualitative and quantitative traits (population and family-based data); mixed linear models; eQTL mapping; prediction models using RNAseq and array data; inferences for heritability estimation and prediction; functional predication of variant sites, variant annotation; variant calling, controlling for population substructure/admixture (principal components analysis/multidimensionality scaling); data quality control of genotype and sequence data; meta-analysis; gene x gene interaction; sample size estimation and evaluating power for common and rare variants. Programs that will be taught and utilized by course participants include: ANNOVAR, BEAM3, CADD, GERP, GotCloud, GenAbel, PLINK, Polyphen-2, R, SEQPower, Variant Association Tools (VAT), etc. Since gene mapping is a quickly changing field, the topics and analytic programs will be updated and changed annually to reflect the latest developments in the field of statistical genetics. Given the large increases in the amount of genetic data being generated, and in particular sequence data, it is extremely important to train researchers and give them the necessary information and tools for data analysis to elucidate the etiology of complex traits. Project Narrative The aim of this proposal is to carry out an annual, full-week course in advanced gene mapping at The Rockefeller University in New York City. The course is directed towards advanced researchers with knowledge in statistics and genetics and will provide participants with information on the latest methods to identify disease genes for complex traits. Thirty participants will be admitted to the course and travel stipends will be provided to five participants who are either pre-doctoral students or post-doctoral fellows to cover the cost of airfare, hotel and board.  ",Advanced Gene Mapping Course,9663981,R25HG007511,"['Admixture', 'Basic Science', 'Categories', 'Chromosome Mapping', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Files', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Etiology', 'Evaluation', 'Exercise', 'Faculty', 'Family', 'Generations', 'Genes', 'Genetic', 'Genetic Epistasis', 'Genetic Predisposition to Disease', 'Genotype', 'Genus Mentha', 'Heritability', 'Human Gene Mapping', 'Individual', 'Knowledge', 'Libraries', 'Linear Models', 'Linux', 'Logistic Regressions', 'Memory', 'Meta-Analysis', 'Methodology', 'Methods', 'New York', 'New York City', 'Online Systems', 'Participant', 'Population', 'Population Control', 'Postdoctoral Fellow', 'Principal Component Analysis', 'Quality Control', 'Research Personnel', 'Running', 'S-nitro-N-acetylpenicillamine', 'Sample Size', 'Sequence Analysis', 'Site', 'Students', 'System', 'Techniques', 'Training', 'Travel', 'Universities', 'Update', 'Variant', 'base', 'bioinformatics tool', 'cost', 'doctoral student', 'experience', 'file format', 'genetic epidemiology', 'genetic linkage analysis', 'genome wide association study', 'human disease', 'insight', 'instructor', 'laptop', 'learning materials', 'lectures', 'next generation sequence data', 'population based', 'power analysis', 'pre-doctoral', 'predictive modeling', 'programs', 'rare variant', 'statistics', 'theories', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'web site']",NHGRI,ROCKEFELLER UNIVERSITY,R25,2019,53400,0.009888961963040632
"Estimating disease risk using genetic data Project Summary In the past 10 years, over 21,000 genetic variants have been linked to complex human traits through genome-wide association studies (GWAS). However, the predictive power of many of these variants remains limited, and it is still unclear how best to use the wealth of information generated by GWAS to impact personal health and clinical practice. For nearly 10 years, 23andMe has been not only a driving force in direct-to-consumer genetic testing but also has established an innovative crowd-sourced genetics research platform. This platform has yielded a compelling data resource and many genetic discoveries. In this proposal, we will address the next phase of 23andMe human genetics research: the development of highly scalable and accurate disease risk estimation. Two of the key challenges in human genetics research are (1) to determine how to use results of GWAS to paint an accurate picture of an individual's disease risk, and (2) to determine how these estimates can provide information of personal and clinical utility. These challenges are difficult due to many factors including the wide spectrum of disease classes, the paucity of genetic and phenotypic data and significant methodological and computational challenges. In this proposal, we present a plan to utilize the genetic and phenotypic data stores at 23andMe to ​develop validated risk estimation algorithms​. In Phase I, we will build a computational pipeline that will be used to develop predictive algorithms for estimating disease risk (Aim #1) and use this pipeline to evaluate predictive ability of different estimation approaches in a broad class of human complex traits (Aim #2). In Phase II, we will validate these algorithms in external cohorts and build customer-facing reports that we will test for user comprehension. We believe that the development of accurate risk estimation capability will have a major impact on both consumer genetics and clinical genetics markets.      Project Narrative   The promise of genetics-based estimation of disease risk has yet to be realized. In this project, 23andMe will use its database of genetic and phenotypic information from over 1,000,000 research participants who have contributed more than 285,000,000 phenotypic data points on a wide spectrum of disease to build risk estimation algorithms. This project will enable 23andMe to produce the first validated risk estimation algorithms that provide both personal and clinical utility.    ",Estimating disease risk using genetic data,9255753,R43HG009089,"['Address', 'Algorithms', 'Applications Grants', 'Catalogs', 'Clinical', 'Communities', 'Complement', 'Complex', 'Comprehension', 'Data', 'Data Reporting', 'Databases', 'Development', 'Disease', 'Environmental Risk Factor', 'Foundations', 'Frequencies', 'Genetic', 'Genetic Databases', 'Genetic Markers', 'Genetic Models', 'Genetic Research', 'Genetic Risk', 'Genetic screening method', 'Genome', 'Genotype', 'Goals', 'Grant', 'Health', 'Human', 'Human Genetics', 'Individual', 'Industry Collaboration', 'Knowledge', 'Link', 'Logistics', 'Machine Learning', 'Medical Genetics', 'Mendelian disorder', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Myopia', 'National Human Genome Research Institute', 'Online Systems', 'Paint', 'Participant', 'Patient Self-Report', 'Peer Review', 'Performance', 'Phase', 'Phenotype', 'Precision Medicine Initiative', 'Prevention', 'Public Health', 'Publications', 'Reporting', 'Research', 'Risk', 'Role', 'Services', 'Small Business Innovation Research Grant', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'clinical practice', 'clinically relevant', 'cohort', 'crowdsourcing', 'data resource', 'disorder risk', 'driving force', 'drug development', 'flexibility', 'genetic predictors', 'genetic variant', 'genome wide association study', 'health practice', 'human disease', 'improved', 'innovation', 'learning strategy', 'lifestyle factors', 'new therapeutic target', 'non-genetic', 'personalized medicine', 'phenotypic data', 'prediction algorithm', 'research and development', 'risk variant', 'trait']",NHGRI,"23ANDME, INC.",R43,2017,241905,-0.032149426016008925
"Predicting gene regulation across populations to understand mechanisms underlying complex traits Project Summary A better understanding of the degree of transferability of genetic association results and implicated genes across populations has implications for precision medicine and can only be accomplished by studying the genetic architecture of complex traits in diverse populations. For many complex traits, gene regulation is likely to play a crucial mechanistic role given the consistent enrichment of regulatory variants among trait-associated variants. We have developed a gene-level association method called PrediXcan that harnesses the regulatory knowledge generated by expression quantitative trait loci (eQTL) studies to directly test for genes associated with complex traits. An advantage of this gene-based approach over other aggregate variant approaches is that the results are inherently mechanistic and provide directionality, guiding follow-up experiments and future drug development. The genetic contribution to population phenotypic differentiation is driven by differences in causal allele frequencies, effect sizes, and genetic architectures. We propose to broaden the scope of PrediXcan to include diverse populations by (1) optimizing predictors of gene expression within and across diverse populations in multiple tissues and (2) performing gene-level association studies and quantifying regulability on a range of phenotypes in non-European populations. We will use machine learning to optimize predictive models of gene expression in datasets with both genome-wide genotype and gene expression data. We will integrate prior results from larger European populations when appropriate. Based on preliminary results, we expect a range of predictive power (assessed by cross-validation R2) will be observed across genes dependent on the heritability of each gene expression trait and differences in allele frequencies and effect sizes among populations. We will compare populations by 1) calculating the correlation between heritability estimates and cross-validated prediction performance and by 2) by calculating trans-population genetic effect size correlations (allele frequency independent) and trans-population genetic impact correlations (allele frequency dependent). The optimal models will also inform the underlying genetic architectures (sparse vs. polygenic) of gene expression traits and how they vary across populations. As we have done for European populations, the predictive models and heritability estimates developed here will be added to an open access database for use in PrediXcan and other studies. We hypothesize that PrediXcan will increase power to identify genes and implicate mechanisms underlying complex traits and that we can quantify the overall effect of phenotypic variation explained by transcriptome regulation within and across populations. We will compare gene-level results across populations to determine if the same and/or unique genes and pathways are implicated for a particular phenotype. We will estimate the proportion of phenotypic variance explained collectively by all gene expression levels, which we name the regulability of a trait. All results, scripts, and software will be available in publicly accessible databases and repositories. Project Narrative Differences in DNA sequence among individuals can lead to differences in gene expression levels, which in turn can lead to trait differences. We have developed a method that harnesses these DNA differences to predict gene expression levels, which are then tested for correlation with a disease or other trait of interest. Our project will lead to a better understanding of the degree of transferability of genetic association results and implicated genes across populations, which has the potential to improve the implementation of precision medicine among diverse populations and reduce health disparities.",Predicting gene regulation across populations to understand mechanisms underlying complex traits,9304684,R15HG009569,"['Alzheimer&apos', 's Disease', 'Architecture', 'Atherosclerosis', 'Biological', 'Cholesterol', 'Cohort Studies', 'Complex', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Disease', 'European', 'Future', 'Gene Expression', 'Gene Expression Regulation', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic study', 'Genome', 'Genotype', 'Genotype-Tissue Expression Project', 'Height', 'Heritability', 'Individual', 'Knowledge', 'Lead', 'Machine Learning', 'Methods', 'Modeling', 'Names', 'Open Reading Frames', 'Pathway interactions', 'Performance', 'Phenotype', 'Play', 'Population', 'Population Genetics', 'Population Heterogeneity', 'Quantitative Trait Loci', 'Regulation', 'Role', 'Scanning', 'T-Lymphocyte', 'Testing', 'Tissues', 'Transcript', 'Triglycerides', 'Validation', 'Variant', 'Weight', 'base', 'data access', 'database of Genotypes and Phenotypes', 'drug development', 'experimental study', 'falls', 'follow-up', 'genetic association', 'genetic variant', 'genome wide association study', 'genome-wide', 'health disparity', 'improved', 'interest', 'lymphoblastoid cell line', 'malignant breast neoplasm', 'monocyte', 'novel', 'phenotypic data', 'precision medicine', 'predictive modeling', 'repository', 'response', 'statistics', 'trait', 'transcriptome']",NHGRI,LOYOLA UNIVERSITY OF CHICAGO,R15,2017,429000,0.03163122422351302
"Predicting gene regulation across populations to understand mechanisms underlying complex traits Project Summary Deeper understanding of the degree of transferability of genetic association results and implicated biological mechanisms across populations is essential for equitable precision medicine implementation and can only be accomplished by studying the genetic architecture of complex traits in diverse populations. In our initial project period, we have shown that genetic correlation of gene expression depends on shared ancestry proportions in African American, Hispanic, and European populations. We identified a subset of genes that are well-predicted in one population, but poorly predicted in another and showed these differences are due to allele frequency differences between populations. Our results demonstrate that when comparing predicted expression levels to the observed, a balance of the training population with ancestry similar to the test population and total sample size leads to optimal predicted gene expression. Our studies of lipid traits in Yoruba, Filipino and Hispanic populations uncovered key genes likely regulated by variants that are monomorphic or rare in European populations, demonstrating why studies in diverse populations are crucial. We have optimized genetic prediction models of gene expression levels in diverse populations and thus have broadened the scope of PrediXcan. In this proposal, we seek to (1) optimize global and local ancestry-aware omics trait prediction models within and across diverse populations and (2) predict the intermediate omics traits and perform poly- omic PrediXcan analyses of complex traits in GWAS cohorts from diverse populations. We have gathered data of multiple omics traits from diverse populations for this project (genome-wide genotype, RNA-Seq, methylomics, metabolomics, and microbiome). We will use machine learning to optimize genotypic prediction models of gene expression levels, splicing ratios, methylation, metabolite levels, and microbial diversity. We expect a range of predictive power will be observed across omics traits dependent on the heritability of each trait and differences in allele frequencies and effect sizes among populations. We will integrate regulatory data and previous results from larger European populations when appropriate to prioritize functional variants in our prediction models. For each omics trait, we will survey its genetic architecture to inform the best prediction models. Our models will account for global and local ancestry and we will quantify the ancestry specific components of each omics trait. We will test the predicted omics traits for association with phenotypes of interest using either raw genotypes or summary statistics. We will use colocalization methods to determine if the SNPs driving each omics trait prediction model are also those most associated with the phenotype and thus most likely to be causal. We will combine predicted omics traits in poly-omic models to determine which genes and biological pathways are implicated for a particular phenotype. Our team is well positioned to perform novel PrediXcan-based analyses of omics traits in diverse populations and promises to maximize impact by making our scripts, models, and results publicly available. Project Narrative Differences in DNA sequence among individuals can lead to differences in omics traits like gene expression, splicing, methylation, metabolite levels, and microbial diversity, which in turn can lead to trait differences. We have developed a method that harnesses DNA differences to predict omics traits, which are then tested for association with a disease or other trait of interest. Our project will lead to a better understanding of the degree of transferability of genetic association results across populations, which has the potential to improve the implementation of precision medicine among diverse populations and reduce health disparities.",Predicting gene regulation across populations to understand mechanisms underlying complex traits,9880471,R15HG009569,"['Adopted', 'African American', 'Authorship', 'Automobile Driving', 'Awareness', 'Balance training', 'Biological', 'Bipolar Disorder', 'Catalogs', 'Cohort Studies', 'Communities', 'Complex', 'Complex Genetic Trait', 'DNA', 'DNA Sequence', 'Data', 'Disease', 'European', 'Filipino', 'Gene Expression', 'Gene Expression Regulation', 'Gene Frequency', 'Genes', 'Genetic', 'Genetic study', 'Genotype', 'Heritability', 'Hispanics', 'Individual', 'Knowledge', 'Lead', 'Lipids', 'Machine Learning', 'Malignant neoplasm of prostate', 'Manuscripts', 'Methods', 'Methylation', 'Mission', 'Modeling', 'Multiomic Data', 'Pathway interactions', 'Performance', 'Phenotype', 'Population', 'Population Heterogeneity', 'Positioning Attribute', 'Publishing', 'RNA Splicing', 'Sample Size', 'Schizophrenia', 'Surveys', 'Testing', 'Training', 'Trans-Omics for Precision Medicine', 'Variant', 'base', 'cohort', 'database of Genotypes and Phenotypes', 'epidemiological model', 'epigenomics', 'genetic architecture', 'genetic association', 'genetic predictors', 'genome wide association study', 'genome-wide', 'health disparity', 'improved', 'interest', 'metabolomics', 'methylomics', 'microbial', 'microbiome', 'microbiota', 'novel', 'precision medicine', 'predictive modeling', 'predictive test', 'statistics', 'trait', 'transcriptome', 'transcriptome sequencing', 'undergraduate student']",NHGRI,LOYOLA UNIVERSITY OF CHICAGO,R15,2020,436000,0.08260409424801853
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,7693803,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Classification', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'biomedical ontology', 'genome-wide', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2009,280000,-0.05549258548745241
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,7467204,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Classification', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Personal Satisfaction', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Today', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'concept', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2008,280000,-0.05549258548745241
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,8138486,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'biomedical ontology', 'genome-wide', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2011,266112,-0.05549258548745241
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,7929664,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'biomedical ontology', 'genome-wide', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2010,277200,-0.05549258548745241
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety  Of functions involved in the immune response, and influence  susceptibility to over 40 diseases.  Our understanding of the structure  and function of the HLA genes, their disease associations, and the  evolutionary features of this multigene family has benefitted from recent  advances in molecular biology, immunology, disease modelling and  population genetics.  Theoretical studies in the development of models to  determine the modes of inheritance of the HLA associated diseases have  led to a better understanding of the inheritance patterns in insulin  dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,  ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It  is now clear that many of the HLA associated diseases involve  heterogeneity in their HLA components, as well as non-HLA genetic  components.    The specific aims of our research are to study the genetic components in  the etiology of the HLA associated diseases, and population genetic  features of the HLA system.  A variety of methods to test modes of  inheritance of diseases using marker allele information, will be  developed.  Methods appropriate for the analysis of marker systems which  are not highly polymorphic, to both detect linkage and determine modes of  inheritance, will be investigated.  The information content of particular  pedigree types for LOD score analysis will be investigated.  Two methods  using patterns of linkage disequilibrium will be investigated to  determine their usefulness in mapping disease predisposing genes.  A  number of large collaborative data sets of HLA associated diseases will  be analyzed.  A framework for genetic counselling of HLA associated, and  other complex diseases, will be developed.  The results of our studies  are generally applicable to the mapping and characterization of complex  human genetic traits.  n/a",MODELS IN POPULATION GENETICS,2196932,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1995,203332,0.09987056372004582
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety Of functions involved in the immune response, and influence susceptibility to over 40 diseases.  Our understanding of the structure and function of the HLA genes, their disease associations, and the evolutionary features of this multigene family has benefitted from recent advances in molecular biology, immunology, disease modelling and population genetics.  Theoretical studies in the development of models to determine the modes of inheritance of the HLA associated diseases have led to a better understanding of the inheritance patterns in insulin dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis, ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It is now clear that many of the HLA associated diseases involve heterogeneity in their HLA components, as well as non-HLA genetic components.  The specific aims of our research are to study the genetic components in the etiology of the HLA associated diseases, and population genetic features of the HLA system.  A variety of methods to test modes of inheritance of diseases using marker allele information, will be developed.  Methods appropriate for the analysis of marker systems which are not highly polymorphic, to both detect linkage and determine modes of inheritance, will be investigated.  The information content of particular pedigree types for LOD score analysis will be investigated.  Two methods using patterns of linkage disequilibrium will be investigated to determine their usefulness in mapping disease predisposing genes.  A number of large collaborative data sets of HLA associated diseases will be analyzed.  A framework for genetic counselling of HLA associated, and other complex diseases, will be developed.  The results of our studies are generally applicable to the mapping and characterization of complex human genetic traits.  n/a",MODELS IN POPULATION GENETICS,2196931,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1994,170968,0.09987056372004582
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety Of functions involved in the immune response, and influence susceptibility to over 40 diseases.  Our understanding of the structure and function of the HLA genes, their disease associations, and the evolutionary features of this multigene family has benefitted from recent advances in molecular biology, immunology, disease modelling and population genetics.  Theoretical studies in the development of models to determine the modes of inheritance of the HLA associated diseases have led to a better understanding of the inheritance patterns in insulin dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis, ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It is now clear that many of the HLA associated diseases involve heterogeneity in their HLA components, as well as non-HLA genetic components.  The specific aims of our research are to study the genetic components in the etiology of the HLA associated diseases, and population genetic features of the HLA system.  A variety of methods to test modes of inheritance of diseases using marker allele information, will be developed.  Methods appropriate for the analysis of marker systems which are not highly polymorphic, to both detect linkage and determine modes of inheritance, will be investigated.  The information content of particular pedigree types for LOD score analysis will be investigated.  Two methods using patterns of linkage disequilibrium will be investigated to determine their usefulness in mapping disease predisposing genes.  A number of large collaborative data sets of HLA associated diseases will be analyzed.  A framework for genetic counselling of HLA associated, and other complex diseases, will be developed.  The results of our studies are generally applicable to the mapping and characterization of complex human genetic traits.  n/a",MODELS IN POPULATION GENETICS,3311999,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1993,154095,0.09987056372004582
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety Of functions involved in the immune response, and influence susceptibility to over 40 diseases.  Our understanding of the structure and function of the HLA genes, their disease associations, and the evolutionary features of this multigene family has benefitted from recent advances in molecular biology, immunology, disease modelling and population genetics.  Theoretical studies in the development of models to determine the modes of inheritance of the HLA associated diseases have led to a better understanding of the inheritance patterns in insulin dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis, ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It is now clear that many of the HLA associated diseases involve heterogeneity in their HLA components, as well as non-HLA genetic components.  The specific aims of our research are to study the genetic components in the etiology of the HLA associated diseases, and population genetic features of the HLA system.  A variety of methods to test modes of inheritance of diseases using marker allele information, will be developed.  Methods appropriate for the analysis of marker systems which are not highly polymorphic, to both detect linkage and determine modes of inheritance, will be investigated.  The information content of particular pedigree types for LOD score analysis will be investigated.  Two methods using patterns of linkage disequilibrium will be investigated to determine their usefulness in mapping disease predisposing genes.  A number of large collaborative data sets of HLA associated diseases will be analyzed.  A framework for genetic counselling of HLA associated, and other complex diseases, will be developed.  The results of our studies are generally applicable to the mapping and characterization of complex human genetic traits.  n/a",MODELS IN POPULATION GENETICS,3311992,R01HD012731,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage mapping', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NICHD,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1992,148906,0.09987056372004582
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,7051948,K01DA015129,"['artificial intelligence', 'behavioral /social science research tag', 'behavioral genetics', 'clinical research', 'computer simulation', 'data collection methodology /evaluation', 'drug addiction', 'family genetics', 'genetic susceptibility', 'human data', 'linkage mapping', 'mathematical model', 'nicotine', 'pharmacogenetics', 'smoking', 'tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2006,133928,0.08650048375600691
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6864825,K01DA015129,"['artificial intelligence', 'behavioral /social science research tag', 'behavioral genetics', 'clinical research', 'computer simulation', 'data collection methodology /evaluation', 'drug addiction', 'family genetics', 'genetic susceptibility', 'human data', 'linkage mapping', 'mathematical model', 'nicotine', 'pharmacogenetics', 'smoking', 'tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2005,129738,0.08650048375600691
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6745564,K01DA015129,"['artificial intelligence', 'behavioral /social science research tag', 'behavioral genetics', 'clinical research', 'computer simulation', 'data collection methodology /evaluation', 'drug addiction', 'family genetics', 'genetic susceptibility', 'human data', 'linkage mapping', 'mathematical model', 'nicotine', 'pharmacogenetics', 'smoking', 'tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2004,103831,0.08650048375600691
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6623318,K01DA015129,"['artificial intelligence', ' behavioral /social science research tag', ' behavioral genetics', ' clinical research', ' computer simulation', ' data collection methodology /evaluation', ' drug addiction', ' family genetics', ' genetic susceptibility', ' human data', ' linkage mapping', ' mathematical model', ' nicotine', ' pharmacogenetics', ' smoking', ' tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2003,102301,0.08650048375600691
"Quantitative Analysis Methods for Complex Trait Genetics DESCRIPTION: (Provided by Applicant): Cigarette smoking is a major risk factor for premature death and creates a substantial public health burden. While studies have shown that smoking and nicotine dependence are complex traits influenced by significant genetic components, further research is needed to identify genes that influence susceptibility and resistance. The research goal of this proposal is to develop and evaluate new methods for the genetic analysis of complex traits in the context of career development for the candidate, Dr. Nancy Saccone. Dr. Saccone will use artificial neural networks and logistic regression models as her primary methodological tools, and will develop and apply methods especially suited for studying the complex genetics of nicotine addiction and related phenotypes. Preliminary studies have been promising and indicate that further investigation of genetic methods based on these tools is warranted. The research plan will also extend the scope of these applications to include uses for genetic association analysis, as large-scale disequilibrium and association-based approaches are expected to become increasingly important for complex trait gene mapping. Dr. Saccone has chosen Dr. John Rice as mentor and will work with additional co-mentors and consultants. The training components of this proposal will expand Dr. Saccone?s experience to include: ongoing training in the ethical conduct of research, further training in the clinical and biological aspects of nicotine and other substance addiction, and the development of expertise in the use and analysis of other kinds of genetic data besides genotypic data, such as gene expression array data, which will play increasingly important roles in the study of human complex traits. The candidate has designed a program of coursework and mentoring to accomplish these research and training goals and thereby achieve research independence by the end of the award period.  n/a",Quantitative Analysis Methods for Complex Trait Genetics,6464747,K01DA015129,"['artificial intelligence', ' behavioral /social science research tag', ' behavioral genetics', ' clinical research', ' computer simulation', ' data collection methodology /evaluation', ' drug addiction', ' family genetics', ' genetic susceptibility', ' human data', ' linkage mapping', ' mathematical model', ' nicotine', ' pharmacogenetics', ' smoking', ' tobacco abuse']",NIDA,WASHINGTON UNIVERSITY,K01,2002,97825,0.08650048375600691
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9922272,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratory of Neuro Imaging Resource', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data curation', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'image archival system', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2020,1217435,0.07043944215090955
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9700661,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Database Management Systems', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Infrastructure', 'Ingestion', 'Investigation', 'Laboratories', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'analysis pipeline', 'autism spectrum disorder', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data archive', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'neuroimaging', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2019,1217435,0.07043944215090955
"Laboratory of Neuro Imaging Resource (LONIR) PROJECT SUMMARY - OVERALL The LONIR is focused on developing innovative solutions for the investigation of imaging, genetics, behavioral and clinical data. The LONIR structure is designed to facilitate studies of dynamically changing anatomic frameworks, e.g., developmental, neurodegenerative, traumatic, and metastatic, by providing methods for the comprehensive understanding of the nature and extent of these processes. Specifically, TR&D1 (Data Science) focuses on methodological developments for the management and informatics of brain and related data. This project will develop and issue new methods for robust scientific data management to create an environment where scientific analyses can be reproduced and/or enhanced, data can be easily discovered and reused, and analysis results can be visualized and made publicly searchable. TR&D2 (Diffusion MRI and Connectomics) seeks to advance the study of brain connectivity using diffusion imaging and its powerful extensions. This project will go beyond traditional tensor models of diffusion for assessing tissue and fiber microstructure and connectivity, develop tract-based statistical analysis tools using Deep Learning, introduce novel adaptive connectivity mapping approaches, using L1 fusion of multiple tractography methods, and provide mechanisms to study connectivity and diffusion imaging over 10,000 subjects. (This technology and these methods will be managed and executed by the TR&D1 framework to distributed datasets totaling over 10,000 subjects). Lastly, our TR&D3 (Intrinsic Surface Mapping) develops a general framework for surface mapping in the high dimensional Laplace-Beltrami embedding space via the mathematical optimization of their Riemannian metric. Our approach here overcomes fundamental limitations in existing methods based on spherical registration by eliminating the metric distortion during the parameterization step, thus achieving much improved accuracy in mapping brain anatomy. Coupled with a mature and efficient administrative structure and comprehensive training and dissemination, this program serves a wide and important need in the scientific community. PROJECT NARRATIVE - OVERALL The comprehensive suite of technologies include algorithmic and computational methods for image management, processing, data analysis and visualization. The technologies are ideally suited to enable holistic studies of the interactions between different imaging data modalities, phenotypic population characteristics, and physiological brain connectivity.",Laboratory of Neuro Imaging Resource (LONIR),9491555,P41EB015922,"['AIDS/HIV problem', 'Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Atlases', 'Autistic Disorder', 'Award', 'Behavioral', 'Books', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical Data', 'Clinical Research', 'Communities', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Databases', 'Dementia', 'Development', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Equilibrium', 'Evolution', 'Fiber', 'Funding', 'Image', 'Informatics', 'Investigation', 'Laboratories', 'Manuscripts', 'Mathematics', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Parkinson Disease', 'Peer Review', 'Phenotype', 'Physiological', 'Population', 'Population Characteristics', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Reproducibility', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schizophrenia', 'Science', 'Services', 'Software Tools', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Tissues', 'Training', 'United States National Institutes of Health', 'Visualization software', 'algorithmic methodologies', 'base', 'brain shape', 'cohort', 'computer grid', 'computer infrastructure', 'computerized data processing', 'data archive', 'data management', 'data resource', 'data visualization', 'deep learning', 'design', 'high dimensionality', 'imaging genetics', 'imaging modality', 'improved', 'innovation', 'morphometry', 'neuroimaging', 'new technology', 'novel', 'programs', 'symposium', 'synergism', 'technology research and development', 'tool', 'tractography', 'translational study', 'web services']",NIBIB,UNIVERSITY OF SOUTHERN CALIFORNIA,P41,2018,1717236,0.07043944215090955
"Beyond Association: Predictive Modeling of Nicotine Dependance    DESCRIPTION (provided by applicant): Tobacco use, primarily cigarette smoking, is the greatest source of preventable mortality in the world and costs over $160 million in health-related economic losses in the U.S. alone. Nicotine dependence is the primary reason that smokers continue smoking and that most unassisted quit attempts fail within a single week. It is known that nicotine dependence has a genetic component, but that it is a complex trait, i.e., no single gene is responsible for nicotine dependence. Thus, researchers and funding agencies have devoted considerable effort and support to identifying the genetic underpinnings of the trait through whole genome scans, putting us in a unique position to identify global genetic predictors of nicotine dependence. This study proposes to realize the promise of the NIDA-funded Collaborative Genetic Study of Nicotine Dependence (COGEND) whole genome data through the accomplishment of two specific aims: (1) to identify the set of genetic variations underlying the complex trait of nicotine dependence using a cutting-edge computational method called Bayesian networks and (2) to validate the prognostic model in an entirely independent population. This proposal represents the very first step of a broader research program aimed at discovering the complex network of interactions underpinning nicotine dependence. The ultimate result of this program will provide a clinical tool, which will accurately assess the risk of dependency, allow for individualized preventive measures, elucidate the molecular processes of dependence and nominate novel targets for the pharmaceutical treatment of nicotine addiction. Nicotine dependence places an enormous burden on individuals and society. Genetic factors are responsible for at least some part of the condition, and the NIDA has already funded a study, called COGEND, that examined over 40,000 genetic variations in people who were nicotine dependent and who were not nicotine dependent. We propose to use cutting-edge techniques to analyze this large dataset to identify a valid predictive model of nicotine dependence that will help us predict, diagnose, and treat this condition.        n/a",Beyond Association: Predictive Modeling of Nicotine Dependance,7617627,R21DA025168,"['Artificial Intelligence', 'Clinical', 'Complex', 'Computing Methodologies', 'Data', 'Data Set', 'Dental Schools', 'Dependence', 'Dependency', 'Diagnosis', 'Economics', 'Enrollment', 'Funding', 'Funding Agency', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Individual', 'Measures', 'Medicine', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'Nicotine', 'Nicotine Dependence', 'Pharmacologic Substance', 'Physiological Processes', 'Population', 'Positioning Attribute', 'Preventive', 'Principal Investigator', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Site', 'Smoker', 'Smoking', 'Societies', 'Source', 'Techniques', 'Tobacco use', 'Translating', 'Validation', 'Variant', 'base', 'cigarette smoking', 'clinical practice', 'computer based statistical methods', 'cost', 'genetic variant', 'genome wide association study', 'genome-wide', 'innovation', 'mortality', 'novel', 'predictive modeling', 'prognostic', 'programs', 'smoking cessation', 'statistics', 'tool', 'trait']",NIDA,BRIGHAM AND WOMEN'S HOSPITAL,R21,2009,175000,0.012313518818794247
"Beyond Association: Predictive Modeling of Nicotine Dependance    DESCRIPTION (provided by applicant): Tobacco use, primarily cigarette smoking, is the greatest source of preventable mortality in the world and costs over $160 million in health-related economic losses in the U.S. alone. Nicotine dependence is the primary reason that smokers continue smoking and that most unassisted quit attempts fail within a single week. It is known that nicotine dependence has a genetic component, but that it is a complex trait, i.e., no single gene is responsible for nicotine dependence. Thus, researchers and funding agencies have devoted considerable effort and support to identifying the genetic underpinnings of the trait through whole genome scans, putting us in a unique position to identify global genetic predictors of nicotine dependence. This study proposes to realize the promise of the NIDA-funded Collaborative Genetic Study of Nicotine Dependence (COGEND) whole genome data through the accomplishment of two specific aims: (1) to identify the set of genetic variations underlying the complex trait of nicotine dependence using a cutting-edge computational method called Bayesian networks and (2) to validate the prognostic model in an entirely independent population. This proposal represents the very first step of a broader research program aimed at discovering the complex network of interactions underpinning nicotine dependence. The ultimate result of this program will provide a clinical tool, which will accurately assess the risk of dependency, allow for individualized preventive measures, elucidate the molecular processes of dependence and nominate novel targets for the pharmaceutical treatment of nicotine addiction. Nicotine dependence places an enormous burden on individuals and society. Genetic factors are responsible for at least some part of the condition, and the NIDA has already funded a study, called COGEND, that examined over 40,000 genetic variations in people who were nicotine dependent and who were not nicotine dependent. We propose to use cutting-edge techniques to analyze this large dataset to identify a valid predictive model of nicotine dependence that will help us predict, diagnose, and treat this condition.        n/a",Beyond Association: Predictive Modeling of Nicotine Dependance,7509667,R21DA025168,"['Artificial Intelligence', 'Clinical', 'Complex', 'Computing Methodologies', 'Condition', 'Data', 'Data Set', 'Dental Schools', 'Dependence', 'Dependency', 'Diagnosis', 'Economics', 'Enrollment', 'Funding', 'Funding Agency', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Human', 'Individual', 'Measures', 'Medicine', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'Nicotine', 'Nicotine Dependence', 'Pharmacologic Substance', 'Physiological Processes', 'Population', 'Positioning Attribute', 'Preventive', 'Principal Investigator', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Site', 'Smoker', 'Smoking', 'Societies', 'Source', 'Techniques', 'Tobacco use', 'Translating', 'Validation', 'Variant', 'Week', 'base', 'cigarette smoking', 'computer based statistical methods', 'cost', 'genetic variant', 'genome wide association study', 'innovation', 'mortality', 'novel', 'predictive modeling', 'prognostic', 'programs', 'smoking cessation', 'statistics', 'tool', 'trait']",NIDA,BRIGHAM AND WOMEN'S HOSPITAL,R21,2008,175000,0.012313518818794247
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9988039,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2019,49496,0.031061674946481897
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9687220,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Research Infrastructure', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2018,330000,0.031061674946481897
"A New J-Resolved MRSI Framework for Whole-Brain Simultaneous Metabolite and Neurotransmitter Mapping PROJECT SUMMARY/ABSTRACT The metabolite and neurotransmitter profiles of neural tissues provide a unique window into brain’s physiological state and can be used to extract potential biomarkers for detecting and characterizing neurodegenerative diseases. Magnetic resonance spectroscopic imaging (MRSI) allows simultaneous mapping and quantification of a number of metabolites and neurotransmitters without exogenous contrast agents thus promised tremendous opportunities for molecular imaging of the brain. However, due to several fundamental technical challenges, including low SNR, poor spatial resolution, long imaging time and inaccurate separation of spectrally overlapping molecular signals, most in vivo MRSI studies to date are still limited to very low-resolution experiments (~1cm3 voxel size) with small brain coverages. The primary goal of this proposed research is to develop, optimize and evaluate a new framework to model, acquire and process MRSI data to enable simultaneous, high-resolution, whole- brain mapping of metabolites and neurotransmitters in clinically feasible time. To achieve this goal, in Aim 1, we will design and implement a novel acquisition strategy that synergistically combines SNR- efficient, multi-slab and multi-TE excitation, sparse sampling in a (k,t,TE)-space and optimized TE selection with maximum echo sampling to generate J-resolved (multi-TE) MRSI data with an unprecedented combination of speed, resolution and organ coverage. In Aim 2, we will develop novel nonlinear low-dimensional models of general MR spectra using a learning-based strategy that integrates the biochemical priors of neural tissues, known physics-based MRSI signal modeling and deep neural networks. These learned models will effectively reduce the dimensionality of the imaging problem and allow for significantly improved speed, resolution and SNR tradeoffs as well as signal separation. Novel computational solutions that effectively exploit the learned models and other spatial-spectral-TE constraints will be developed for spatiospectral reconstruction of metabolites and neurotransmitters from the noisy, high-resolution J-resolved MRSI data. Finally, in Aim 3, we will systematically evaluate the proposed technology in terms of speed, resolution, SNR, and quantitative accuracy using computer simulations, phantom and in vivo experiments. The feasibility and robustness of the proposed technology for mapping metabolites and neurotransmitters in both healthy volunteers and temporal lobe epilepsy patients with mesial temporal sclerosis will be demonstrated. The success of the proposed research will lead to significant progress for in vivo MRSI and represent an important step towards the creation of a powerful tool for studying the molecular basis of brain functions and diseases. This tool, when fully developed, will add a transformative dimension to the existing neuroimaging technology profiles, with the potential to impact the diagnosis and management of neurological and neurodegenerative diseases. PROJECT NARRATIVE Magnetic resonance spectroscopic imaging (MRSI) is a potentially powerful modality that allows simultaneous mapping of a number of metabolites and neurotransmitters noninvasively, which provide a unique window into brain’s physiological states and can be used to extract biomarkers for detecting and characterizing neurodegenerative diseases. However, the current MRSI techniques do not provide the desired combination of resolution, imaging speed and organ coverage for many basic science and clinical applications. The proposed research will develop a new rapid, J-resolved MRSI technology to enable high-resolution, whole-brain mapping of metabolites and neurotransmitters in clinically feasible time, which, if successful, will lead to significant progress for the field of MRSI and an important step towards the creation of a powerful tool for studying the molecular basis of brain functions and diseases.",A New J-Resolved MRSI Framework for Whole-Brain Simultaneous Metabolite and Neurotransmitter Mapping,10057847,R21EB029076,"['Address', 'Algorithmic Software', 'Basic Science', 'Biochemical', 'Biological Markers', 'Brain', 'Brain Mapping', 'Brain imaging', 'Clinical', 'Computer Simulation', 'Contrast Media', 'Coupling', 'Data', 'Diagnosis', 'Dimensions', 'Disease', 'Equation', 'Evaluation', 'Evolution', 'Experimental Designs', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Image', 'Imaging Techniques', 'Imaging problem', 'Imaging technology', 'Learning', 'Machine Learning', 'Maps', 'Mechanics', 'Metabolic', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Monitor', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurotransmitters', 'Noise', 'Organ', 'Pathologic', 'Patients', 'Physics', 'Physiologic pulse', 'Physiological', 'Physiological Processes', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Sampling', 'Scanning', 'Scheme', 'Scientist', 'Sclerosis', 'Signal Transduction', 'Software Tools', 'Solid', 'Spectrum Analysis', 'Speed', 'Technology', 'Temporal Lobe Epilepsy', 'Time', 'Tissues', 'Training', 'Validation', 'Variant', 'Water', 'base', 'clinical application', 'clinical translation', 'computerized data processing', 'deep neural network', 'design', 'experimental study', 'healthy volunteer', 'high dimensionality', 'imaging study', 'improved', 'in vivo', 'innovation', 'interest', 'magnetic field', 'magnetic resonance spectroscopic imaging', 'molecular imaging', 'nervous system disorder', 'neuroimaging', 'novel', 'novel strategies', 'patient population', 'potential biomarker', 'quantum', 'reconstruction', 'relating to nervous system', 'simulation', 'spectroscopic imaging', 'success', 'tool']",NIBIB,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R21,2020,565546,0.06376499058065109
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,6385414,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,2001,198845,0.09179523141745327
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,6179464,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,2000,195932,0.09179523141745327
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,6018534,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,1999,190226,0.09179523141745327
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims to: a) Improve the understanding of the               genetics of inherited diseases with unclear modes of transmission.               Studies will evaluate the effectiveness of current methods of analysis,          including classical linkage analysis, sib-pair or affected-pedigree-             member analysis and the use of measures of association in understanding          the underlying genetic mechanisms of such traits.  Simulation studies            will continue to provide a source of family data reflecting confounding          factors thought to be a problem in linkage analysis of certain complex           traits, such as psychiatric or behavioral disorders.  Factors to be              considered include assortative mating, genetic heterogeneity and multi-          locus disease determination.  The ability of current methods to                  correctly analyze traits with one or more of these factors will be               assessed and, where appropriate, alternative methods will be developed           and tested.  b) Apply techniques of neural network pattern matching to           problems of genetic systems.  Applications include: aid in phenotype             definition for traits with multiple clinical problems of genetic                 systems.  Applications include: aid in phenotype definition for traits           with multiple clinical characteristics; determination of risk of disease         based on phenotype, known risk factors and disease profiles in                   relatives; determination of organ transplant success based on HLA                antigen matching patterns; definition of disease phenotype based on              quantitative factors.  c) Develop and apply strategies for ordering              multiple linked loci using pairwise recombination data, radiation hybrid         data, or other physical mapping data.  Some of these ordering strategies         may be adaptable to the development of techniques for integrating map            information obtained by different methods, an important step in                  organizing a comprehensive, reliable map.  d) Carry out classical                linkage analysis for specific genetic diseases.  Currently, a genome             scan is underway to identify a gene or genes for polycystic liver                disease.  Other diseases to be studied include lymphoma and prostate             cancer. Methods to be tested in the simulation studies can be applied            to these analyses in order to better understand the complete genetic             picture, including identification of heterogeneity, by detecting linkage         of different disease forms to different marker loci. Such                        differentiation will help sharpen the clinical definition of various             forms of the diseases.                                                                                                                                            As a result of advances from this work, better mathematical tools for            the study of diseases with complex or ill-defined inheritance patterns           will be available.  Applications to specific diseases will increase              understanding of interactions between clinical definition and                    predisposing genetic factors.  This will increase the precision of               genetic counseling and suggest useful approaches for studying the                mechanisms involved in determining disease state.                                 n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,2693221,R01GM029177,"['alleles', ' artificial chromosomes', ' artificial intelligence', ' computational neuroscience', ' computer program /software', ' computer simulation', ' family genetics', ' gene expression', ' genetic disorder', ' genetic markers', ' genetic susceptibility', ' histocompatibility antigens', ' human data', ' human genetic material tag', ' linkage mapping', ' liver disorder', ' lymphoma', ' mathematical model', ' model design /development', ' phenotype', ' prostate neoplasms', ' quantitative trait loci', ' sequence tagged sites']",NIGMS,NEW YORK BLOOD CENTER,R01,1998,185170,0.09179523141745327
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims: to: a) Improve the understanding of the genetics of inherited diseases with unclear modes of transmission.  Studies will evaluate the effectiveness of current methods of analysis, in particular linkage analysis and the use of measures of association, in understanding the underlying genetic mechanisms of such traits.  Simulation studies will be used to generate data reflecting confounding factors thought to be a problem in linkage analysis of certain complex traits (for example psychiatric or behavioral disorders).  Factors to be considered include assortative mating; genetic heterogeneity and trait determination by more than one locus.  The ability of current methods to correctly analyze traits with these characteristics will be assessed and, where found lacking, alternative methods will be developed and tested.  b) Carry out classical linkage analysis for specific genetic diseases.  The diseases to be studied include tuberous sclerosis and Fanconi anemia, where evidence for genetic heterogeneity has already been detected.  Methods to be tested in the simulation studies can be applied to these analyses in order to better understand the complete genetic picture, including identification of heterogeneity by detecting linkage of different disease forms to different marker loci.  Such differentiation will help sharpen the clinical definition of various forms of the diseases.  c) Refine strategies for ordering multiple linked loci on linkage maps using either pairwise recombination data or data generated from radiation hybrid experiments. d) Apply techniques of neural network pattern matching to problems of genetic systems.  Applications include aid in phenotype definition for traits with multiple clinical characteristics, prediction of risk of disease based on phenotype, values of known risk factors and disease profiles in relatives and estimation of missing recombination data in multilocus data sets using information from other linkage relationships.  As a result of advances from this work, better mathematical tools for the study of diseases with complex or ill-defined inheritance patterns will be available.  Applications to specific diseases will increase understanding of interactions between clinical definition and predisposing genetic factors.  This will increase the precision of genetic counseling and suggest useful approaches for studying the mechanisms involved in determining disease state.  n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,2175416,R01GM029177,"[""Fabry's disease"", ' artificial intelligence', ' deToni Fanconi syndrome', ' disease /disorder proneness /risk', ' family genetics', ' genetic markers', ' genetic recombination', ' human genetic material tag', ' linkage mapping', ' mathematical model', ' model design /development', ' phenotype', ' tuberous sclerosis']",NIGMS,NEW YORK BLOOD CENTER,R01,1994,187963,0.1015781681307104
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims: to: a) Improve the understanding of the genetics of inherited diseases with unclear modes of transmission.  Studies will evaluate the effectiveness of current methods of analysis, in particular linkage analysis and the use of measures of association, in understanding the underlying genetic mechanisms of such traits.  Simulation studies will be used to generate data reflecting confounding factors thought to be a problem in linkage analysis of certain complex traits (for example psychiatric or behavioral disorders).  Factors to be considered include assortative mating; genetic heterogeneity and trait determination by more than one locus.  The ability of current methods to correctly analyze traits with these characteristics will be assessed and, where found lacking, alternative methods will be developed and tested.  b) Carry out classical linkage analysis for specific genetic diseases.  The diseases to be studied include tuberous sclerosis and Fanconi anemia, where evidence for genetic heterogeneity has already been detected.  Methods to be tested in the simulation studies can be applied to these analyses in order to better understand the complete genetic picture, including identification of heterogeneity by detecting linkage of different disease forms to different marker loci.  Such differentiation will help sharpen the clinical definition of various forms of the diseases.  c) Refine strategies for ordering multiple linked loci on linkage maps using either pairwise recombination data or data generated from radiation hybrid experiments. d) Apply techniques of neural network pattern matching to problems of genetic systems.  Applications include aid in phenotype definition for traits with multiple clinical characteristics, prediction of risk of disease based on phenotype, values of known risk factors and disease profiles in relatives and estimation of missing recombination data in multilocus data sets using information from other linkage relationships.  As a result of advances from this work, better mathematical tools for the study of diseases with complex or ill-defined inheritance patterns will be available.  Applications to specific diseases will increase understanding of interactions between clinical definition and predisposing genetic factors.  This will increase the precision of genetic counseling and suggest useful approaches for studying the mechanisms involved in determining disease state.  n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,3276698,R01GM029177,"[""Fabry's disease"", ' artificial intelligence', ' deToni Fanconi syndrome', ' disease /disorder proneness /risk', ' family genetics', ' genetic markers', ' genetic recombination', ' human genetic material tag', ' linkage mapping', ' mathematical model', ' model design /development', ' phenotype', ' tuberous sclerosis']",NIGMS,NEW YORK BLOOD CENTER,R01,1993,182788,0.1015781681307104
"LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE The proposed research aims: to: a) Improve the understanding of the genetics of inherited diseases with unclear modes of transmission.  Studies will evaluate the effectiveness of current methods of analysis, in particular linkage analysis and the use of measures of association, in understanding the underlying genetic mechanisms of such traits.  Simulation studies will be used to generate data reflecting confounding factors thought to be a problem in linkage analysis of certain complex traits (for example psychiatric or behavioral disorders).  Factors to be considered include assortative mating; genetic heterogeneity and trait determination by more than one locus.  The ability of current methods to correctly analyze traits with these characteristics will be assessed and, where found lacking, alternative methods will be developed and tested.  b) Carry out classical linkage analysis for specific genetic diseases.  The diseases to be studied include tuberous sclerosis and Fanconi anemia, where evidence for genetic heterogeneity has already been detected.  Methods to be tested in the simulation studies can be applied to these analyses in order to better understand the complete genetic picture, including identification of heterogeneity by detecting linkage of different disease forms to different marker loci.  Such differentiation will help sharpen the clinical definition of various forms of the diseases.  c) Refine strategies for ordering multiple linked loci on linkage maps using either pairwise recombination data or data generated from radiation hybrid experiments. d) Apply techniques of neural network pattern matching to problems of genetic systems.  Applications include aid in phenotype definition for traits with multiple clinical characteristics, prediction of risk of disease based on phenotype, values of known risk factors and disease profiles in relatives and estimation of missing recombination data in multilocus data sets using information from other linkage relationships.  As a result of advances from this work, better mathematical tools for the study of diseases with complex or ill-defined inheritance patterns will be available.  Applications to specific diseases will increase understanding of interactions between clinical definition and predisposing genetic factors.  This will increase the precision of genetic counseling and suggest useful approaches for studying the mechanisms involved in determining disease state.  n/a",LINKAGE AND ASSOCIATION OF GENETIC MARKERS AND DISEASE,3276690,R01GM029177,"[""Fabry's disease"", ' artificial intelligence', ' deToni Fanconi syndrome', ' disease /disorder proneness /risk', ' family genetics', ' genetic markers', ' genetic recombination', ' human genetic material tag', ' linkage mapping', ' mathematical model', ' model design /development', ' phenotype', ' tuberous sclerosis']",NIGMS,NEW YORK BLOOD CENTER,R01,1992,184674,0.1015781681307104
"Functional Data Analysis of Longitudinally Measured Genetic Traits.    DESCRIPTION (provided by applicant): There has been a growing interest in investigating genetic architecture of time-varying functional traits such as blood pressure, cholesterol levels or growth rate. Few of the methods proposed in the literature, however, are sufficiently general to apply to complicated situations in a computationally feasible fashion. The goal of this research is to develop general and more powerful statistical methods to map functional quantitative genetic traits. More specifically, in the first step we propose a non-parametric permutation test for overall genetic effect of functional traits by examining familial aggregation. When there is evidence for genetic contribution, the natural second step is to estimate this overall polygenic effect. We then develop methods based on mixed effects models for estimation and use functional principal components analysis to summarize the major temporal variation of the polygenic effect. When the overall genetic effect is reasonably strong, research interest lies in locating influential genes on the genome. In the third step, we propose general functional variance components models to test and estimate quantitative trait locus (QTL) genetic effects using marker genotype data in a genome-wide linkage study. Current ad-hoc methods either uses averages of repeated measurements in a univariate analysis or specifies a parametric form of time- dependent genetic effects in a longitudinal analysis. We propose a family of basis systems to capture genetic effects and estimate age-specific QTL heritability. The flexibility of such basis systems allow for identification of temporal trends of any shape. Within this functional mapping framework, we can answer research questions such as when is a QTL effect expressed to affect a trait, how does gene affect rate of change of traits and so on. Lastly, we propose to investigate our methods using Genetic Analysis Workshop (GAW) 13 simulated data, apply them to the Framingham Heart Study data, and implement them in a software package. Framingham Heart Study is a large prospective study of cardiovascular disease which aims to investigate risk factors and genetic architecture of this disease. The GAW13 simulation data was generated closely based on the Framingham Study, which provides a realistic and valuable resource for methods evaluation and comparison. An application of the developed methods to Framingham data may enhance our understanding of the genetic architecture of cardiovascular disease related traits. The developed software will be made publicly available to all investigators free of charge. PUBLIC HEALTH RELEVANCE: Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.              Project Narrative Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.",Functional Data Analysis of Longitudinally Measured Genetic Traits.,7862512,R03AG031113,"['Affect', 'Age', 'Architecture', 'Blood Pressure', 'Cardiovascular Diseases', 'Charge', 'Cholesterol', 'Complex', 'Computer software', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational workshop', 'Etiology', 'Evaluation', 'Family', 'Framingham Heart Study', 'Future', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genotype', 'Goals', 'Growth', 'Heritability', 'Influentials', 'Literature', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Pattern', 'Principal Component Analysis', 'Procedures', 'Prospective Studies', 'Public Domains', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Risk Factors', 'Scanning', 'Shapes', 'Simulate', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'base', 'flexibility', 'genetic analysis', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide linkage', 'insight', 'interest', 'longitudinal analysis', 'public health relevance', 'simulation', 'software development', 'statistics', 'theories', 'trait', 'trend', 'user friendly software']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2010,65986,0.11041967657428356
"Functional Data Analysis of Longitudinally Measured Genetic Traits.    DESCRIPTION (provided by applicant): There has been a growing interest in investigating genetic architecture of time-varying functional traits such as blood pressure, cholesterol levels or growth rate. Few of the methods proposed in the literature, however, are sufficiently general to apply to complicated situations in a computationally feasible fashion. The goal of this research is to develop general and more powerful statistical methods to map functional quantitative genetic traits. More specifically, in the first step we propose a non-parametric permutation test for overall genetic effect of functional traits by examining familial aggregation. When there is evidence for genetic contribution, the natural second step is to estimate this overall polygenic effect. We then develop methods based on mixed effects models for estimation and use functional principal components analysis to summarize the major temporal variation of the polygenic effect. When the overall genetic effect is reasonably strong, research interest lies in locating influential genes on the genome. In the third step, we propose general functional variance components models to test and estimate quantitative trait locus (QTL) genetic effects using marker genotype data in a genome-wide linkage study. Current ad-hoc methods either uses averages of repeated measurements in a univariate analysis or specifies a parametric form of time- dependent genetic effects in a longitudinal analysis. We propose a family of basis systems to capture genetic effects and estimate age-specific QTL heritability. The flexibility of such basis systems allow for identification of temporal trends of any shape. Within this functional mapping framework, we can answer research questions such as when is a QTL effect expressed to affect a trait, how does gene affect rate of change of traits and so on. Lastly, we propose to investigate our methods using Genetic Analysis Workshop (GAW) 13 simulated data, apply them to the Framingham Heart Study data, and implement them in a software package. Framingham Heart Study is a large prospective study of cardiovascular disease which aims to investigate risk factors and genetic architecture of this disease. The GAW13 simulation data was generated closely based on the Framingham Study, which provides a realistic and valuable resource for methods evaluation and comparison. An application of the developed methods to Framingham data may enhance our understanding of the genetic architecture of cardiovascular disease related traits. The developed software will be made publicly available to all investigators free of charge. PUBLIC HEALTH RELEVANCE: Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.              Project Narrative Dissecting genetic determinants of complex time-varying functional traits such as blood pressure, cholesterol levels or growth rate has been one of the most daunting tasks in genetic studies due to complicated nature of their etiology. This project develops new statistical methods to map genetic variants predisposing complex functional traits and applies methods to the Framingham Heart Study data. The study will offer general and more powerful analysis methods for mapping functional quantitative genetic trait and to answer research questions such as when is a gene expressed to affect a trait, how long does genetic effect last, and how does gene affect rate of change of traits.",Functional Data Analysis of Longitudinally Measured Genetic Traits.,7658423,R03AG031113,"['Affect', 'Age', 'Architecture', 'Blood Pressure', 'Cardiovascular Diseases', 'Charge', 'Cholesterol', 'Complex', 'Computer software', 'Cross-Sectional Studies', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational workshop', 'Etiology', 'Evaluation', 'Family', 'Framingham Heart Study', 'Future', 'Genes', 'Genetic', 'Genetic Determinism', 'Genome', 'Genotype', 'Goals', 'Growth', 'Heritability', 'Influentials', 'Literature', 'Maps', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Nature', 'Pattern', 'Principal Component Analysis', 'Procedures', 'Prospective Studies', 'Public Domains', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Residual state', 'Resources', 'Risk Factors', 'Scanning', 'Shapes', 'Simulate', 'Specific qualifier value', 'Statistical Methods', 'Structure', 'System', 'Testing', 'Time', 'Variant', 'base', 'flexibility', 'genetic analysis', 'genetic linkage', 'genetic risk factor', 'genetic variant', 'genome-wide linkage', 'insight', 'interest', 'longitudinal analysis', 'public health relevance', 'simulation', 'software development', 'statistics', 'theories', 'trait', 'trend', 'user friendly software']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R03,2009,65723,0.11041967657428356
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173928,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1991,130423,0.08033127954986904
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173927,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1990,129698,0.08033127954986904
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173926,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1989,128797,0.08033127954986904
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173925,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1988,126371,0.08033127954986904
"LINKAGE ANALYSIS AND MULTIPLE LOCI This research is designed to investigate the efficient localization and ordering of major genes through linkage analysis.  Although new gene mapping methods and programs have emerged, significant capabilities are still lacking and many of the statistical concepts are dated.  Gene mapping can be divided into two phases:  1) initial assignment of a gene to a chromosomal region, and 2) assignment of gene order and map distance of the disease locus to all of the markers.  The issues of significance and efficiency are different for these phases.  In the first phase, we are testing for linkage between the disease locus and well-spaced highly polymorphic markers.  Three locus evaluation of expected LOD scores and actual LOD scores are sufficient.  We will investigate significance levels of the three locus analysis for testing linkage on saturated maps.  For fine mapping we will compute expected LOD scores and LOD scores for gene order with multiple loci.  We will also establish significance levels for comparison of orders.  The preliminary LOD scores sufficient to justify a switch in strategy from localization to establishing order will be described.  As the set of tools for calculating expected LOD scores and LOD scores are investigated, a knowledge-based expert system will be developed which will integrate these tools with the appropriate databases and rules. The system will be an automated tool assisting in designing the experiments, evaluating data from the experiments, and redesigning the experiment in light of the preliminary results.  Thus, the large number of linkage experiments carried out in the near future can be performed efficiently.  n/a",LINKAGE ANALYSIS AND MULTIPLE LOCI,3173924,R01CA036362,"['computer simulation', ' genetic mapping', ' genetic markers', ' genetic models', ' hereditary hemochromatosis', ' linkage mapping', ' mathematical model']",NCI,UNIVERSITY OF UTAH,R01,1987,126620,0.08033127954986904
"Center for Genetic Studies of Drug Abuse in Outbred Rats Project Summary (Overall)  The purpose of this renewal application is to continue the successful activities of our center, which uses quantitative genetic techniques to study the genetic basis of drug abuse-related behaviors in outbred rats. When our center was initially funded in June 2014, our goal was to develop outbred N/NIH heterogeneous stock (HS) rats as a platform for genetic studies of behaviors that were difficult or impossible to study in mice. The first four years of funding have allowed us to establish a vibrant community of investigators using HS rats to study drug abuse and other traits, which we refer to as an ecosystem. This ecosystem includes both the investigators who are directly involved in this renewal application and many others who have obtained separate funding, some from NIDA, and some from other sources. The growth of this ecosystem reflects one of the ways that our center has served as national resource. We are proposing three projects that involved phenotyping HS rats for a variety of traits, including intravenous cocaine and nicotine self-administration, response to novelty, social behavior, reaction time, and delay discounting. Two of those projects are continuations from the prior funding period and are designed to increase our sample size from 1,600 to 3,200 rats per phenotype. We present data showing that such an increase produces an exponential increase in the number of significant findings. This approach parallels human genetics studies of SUD, which have also benefited tremendously from larger sample sizes. We will use these data to conduct genome-wide association studies (GWAS) and a suite of related techniques. In addition, we will measure gene expression in behaviorally naïve rats using RNASeq and use those data to identify expression quantitative trait loci (eQTLs). We will then integrate GWAS and eQTL data in an effort to identify specific genes that influence the behavioral phenotypes. Many of the behavioral domains being studied are known to be sexually dimorphic; our study will use both male and female rats, which will allow us to identify sex differences and sex by genotype interactions. We will also study genetic correlations, perform phenome-wide association studies (PheWAS), transcriptome wide association studies (TWAS) and explore a novel strategy called polygenic transcriptomic risk scores (PTRS), that is intended to allow translation of polygenic signals across species. Project 4 will use a network-based approach to extend our GWAS to account for known biological networks. This proposed renewal also includes a pilot project core to support new directions and take advantage of unforeseen opportunities. Finally we propose an administrative core that supports many activities of the center, including educational, career development and public outreach. The results of these studies will enhance our understanding of the role of genes in a range of psychologically complex behaviors and will provide novel biological insights that may support future efforts at preventing or treating drug abuse. Project Narrative (Overall)  Using powerful genetic, molecular and statistical techniques, we will study the genetic basis of traits that have well-established relevance to drug abuse. We expect that these studies will enhance our understanding of drug abuse and lead to the identification of specific genes and pathways. These discoveries will improve our understanding of genetic susceptibility to drug abuse in humans and may identify new opportunities to treat psychiatric disorders including but not limited to addiction.",Center for Genetic Studies of Drug Abuse in Outbred Rats,9971494,P50DA037844,"['Adolescent', 'Animal Model', 'Attention', 'Behavior', 'Behavioral', 'Biological', 'Brain region', 'Breeding', 'Cancer Grant Supplements (P30)', 'Cessation of life', 'Cocaine', 'Communities', 'Complex', 'Crime', 'Cues', 'DNA', 'Data', 'Databases', 'Development', 'Drug abuse', 'Ecosystem', 'Education', 'Esthesia', 'Female', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Recombination', 'Genetic Techniques', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Impulsivity', 'Inbred Strains Rats', 'Individual', 'Intravenous', 'Knowledge', 'Lead', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Molecular', 'Mus', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'National Institute of Drug Abuse', 'Network-based', 'Nicotine', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Productivity', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reaction Time', 'Regulation', 'Relapse', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Sample Size', 'Self Administration', 'Sex Differences', 'Signal Transduction', 'Social Behavior', 'Social Reinforcement', 'Source', 'Statistical Methods', 'Substance Use Disorder', 'System', 'Techniques', 'Translations', 'United States National Institutes of Health', 'addiction', 'behavior influence', 'behavioral phenotyping', 'behavioral study', 'career development', 'cocaine use', 'cost', 'deep learning', 'design', 'discounting', 'drug abuse related behavior', 'effective therapy', 'genetic analysis', 'genetic approach', 'genome wide association study', 'genome-wide', 'improved', 'insight', 'male', 'nicotine use', 'novel', 'novel strategies', 'outreach', 'phenome', 'phenotypic data', 'premature', 'preservation', 'prevent', 'psychologic', 'response', 'sex', 'sexual dimorphism', 'success', 'sustained attention', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'virtual', 'web site']",NIDA,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P50,2020,2985563,0.03352911914449429
"Center for Genetic Studies of Drug Abuse in Outbred Rats Project Summary (Overall)  The purpose of this renewal application is to continue the successful activities of our center, which uses quantitative genetic techniques to study the genetic basis of drug abuse-related behaviors in outbred rats. When our center was initially funded in June 2014, our goal was to develop outbred N/NIH heterogeneous stock (HS) rats as a platform for genetic studies of behaviors that were difficult or impossible to study in mice. The first four years of funding have allowed us to establish a vibrant community of investigators using HS rats to study drug abuse and other traits, which we refer to as an ecosystem. This ecosystem includes both the investigators who are directly involved in this renewal application and many others who have obtained separate funding, some from NIDA, and some from other sources. The growth of this ecosystem reflects one of the ways that our center has served as national resource. We are proposing three projects that involved phenotyping HS rats for a variety of traits, including intravenous cocaine and nicotine self-administration, response to novelty, social behavior, reaction time, and delay discounting. Two of those projects are continuations from the prior funding period and are designed to increase our sample size from 1,600 to 3,200 rats per phenotype. We present data showing that such an increase produces an exponential increase in the number of significant findings. This approach parallels human genetics studies of SUD, which have also benefited tremendously from larger sample sizes. We will use these data to conduct genome-wide association studies (GWAS) and a suite of related techniques. In addition, we will measure gene expression in behaviorally naïve rats using RNASeq and use those data to identify expression quantitative trait loci (eQTLs). We will then integrate GWAS and eQTL data in an effort to identify specific genes that influence the behavioral phenotypes. Many of the behavioral domains being studied are known to be sexually dimorphic; our study will use both male and female rats, which will allow us to identify sex differences and sex by genotype interactions. We will also study genetic correlations, perform phenome-wide association studies (PheWAS), transcriptome wide association studies (TWAS) and explore a novel strategy called polygenic transcriptomic risk scores (PTRS), that is intended to allow translation of polygenic signals across species. Project 4 will use a network-based approach to extend our GWAS to account for known biological networks. This proposed renewal also includes a pilot project core to support new directions and take advantage of unforeseen opportunities. Finally we propose an administrative core that supports many activities of the center, including educational, career development and public outreach. The results of these studies will enhance our understanding of the role of genes in a range of psychologically complex behaviors and will provide novel biological insights that may support future efforts at preventing or treating drug abuse. Project Narrative (Overall)  Using powerful genetic, molecular and statistical techniques, we will study the genetic basis of traits that have well-established relevance to drug abuse. We expect that these studies will enhance our understanding of drug abuse and lead to the identification of specific genes and pathways. These discoveries will improve our understanding of genetic susceptibility to drug abuse in humans and may identify new opportunities to treat psychiatric disorders including but not limited to addiction.",Center for Genetic Studies of Drug Abuse in Outbred Rats,9793600,P50DA037844,"['Adolescent', 'Animal Model', 'Attention', 'Behavior', 'Behavioral', 'Biological', 'Brain region', 'Breeding', 'Cancer Grant Supplements (P30)', 'Cessation of life', 'Cocaine', 'Communities', 'Complex', 'Crime', 'Cues', 'DNA', 'Data', 'Databases', 'Development', 'Drug abuse', 'Ecosystem', 'Education', 'Esthesia', 'Female', 'Foundations', 'Funding', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Genetic Predisposition to Disease', 'Genetic Recombination', 'Genetic Techniques', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Heritability', 'Human', 'Human Genetics', 'Human Genome', 'Impulsivity', 'Inbred Strains Rats', 'Individual', 'Intravenous', 'Knowledge', 'Lead', 'Maps', 'Measures', 'Mental disorders', 'Methods', 'Molecular', 'Mus', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'National Institute of Drug Abuse', 'Network-based', 'Nicotine', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phenotype', 'Pilot Projects', 'Population', 'Productivity', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reaction Time', 'Regulation', 'Relapse', 'Research Personnel', 'Resources', 'Risk', 'Role', 'Sample Size', 'Self Administration', 'Sex Differences', 'Signal Transduction', 'Social Behavior', 'Social Reinforcement', 'Source', 'Statistical Methods', 'Substance Use Disorder', 'System', 'Techniques', 'Translations', 'United States National Institutes of Health', 'addiction', 'behavior influence', 'behavioral study', 'career development', 'cocaine use', 'cost', 'deep learning', 'design', 'discount', 'discounting', 'drug abuse related behavior', 'effective therapy', 'genetic analysis', 'genome wide association study', 'genome-wide', 'improved', 'insight', 'male', 'nicotine use', 'novel', 'novel strategies', 'outreach', 'phenome', 'phenotypic data', 'premature', 'preservation', 'prevent', 'psychologic', 'response', 'sex', 'sexual dimorphism', 'success', 'sustained attention', 'tool', 'trait', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'virtual', 'web site']",NIDA,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P50,2019,2949105,0.03352911914449429
"STRUCTURAL PATTERN ANALYSIS OF HUMAN G-BANDED CHROMOSOME This is a proposal to study structural pattern analysis of human G- banded chromosomes by computer.  A database of approximately 7,000 digitized images of band-density profiles is available; each type is represented by about the same number of samples.  A mapped of the density profiles into finite strings of symbols will be developed to cast the problem as string/sequence structure analysis.  A specific mapping to be evaluated carefully is based on ""difference symbol"" strings; this mapping is simple to compute and should facilitate automatic machine learning (inference) of pattern structure from training samples.  For each chromosome type, a set of training strings will be used to infer a Markov chain as a statistical/structural model.  The inference algorithm will use dynamic programming with a relative frequency cost function to compute optimal string alignments sequentially as a search for recurrent substring patterns call ""landmark substrings"".  The inferred Markov networks will be analyzed themselves for ensemble properties of the training data and will be used in classification experiments with both the training data and separate test data.  n/a",STRUCTURAL PATTERN ANALYSIS OF HUMAN G-BANDED CHROMOSOME,3296831,R01GM039708,"['artificial intelligence', ' chromosomes', ' genetic library', ' genetic mapping', ' genetic models', ' human population genetics', ' information systems', ' mathematical model']",NIGMS,UNIVERSITY OF TENNESSEE KNOXVILLE,R01,1988,34793,0.03748062814548997
"MODULAR EXPERT SYSTEM FOR HPLC METHOD DEVELOPMENT Despite 10 years of intensive research into computer-assisted method development for HPLC separation, relatively few chromatographers use these techniques to a significant extent. We propose to develop a computer program (MOSES - Modular Optimization Software/Expert System) that addresses this problem. Computer-simulation modules based on chromatographic theory will be integrated into an expert system framework that addresses most of the problems encountered during HPLC method development. The program will be applicable to both small-molecule samples (which most previous work addresses) and to large biomolecules of interest in the life sciences. The program will also assist in the selection of initial conditions, sample pretreatment, optimizing the separation and scaling up for preparative separation. Previously recognized needs in computer-assisted method development (e.g., user-friendly environment, reliable and convenient mapping of separation, peak tracking, etc.) will be addressed.  n/a",MODULAR EXPERT SYSTEM FOR HPLC METHOD DEVELOPMENT,3498561,R43GM045095,"['artificial intelligence', ' biomedical equipment development', ' computer program /software', ' computer simulation', ' high performance liquid chromatography']",NIGMS,"LC RESOURCES, INC.",R43,1990,49700,0.04625723027113826
"LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM Neural systems often have significant components of their behavior that appear to be random.  Traditionally this randomness is modeled in stochastic and often linear terms.  Since neural systems consist of highly interconnected nonlinear elements, however, a natural alternative explanation is that the randomness derives from complex nonlinear dynamics such as chaos.  This has been suggested by experiments on several neural systems, including irregular firing patterns in the nervous systems of gastropod molluscs, the human electroencephalogram in deep sleep and epilepsy, single neuron recordings in the cat and monkey visual cortex, and hippus in the pupil-light reflex.  However, inmost cases the evidence for chaos remains inconclusive, in large part because the data analysis is based on techniques that are notoriously unreliable, such as currently popular algorithms for computing fractal dimension.  We have recently introduced a new approach to the analysis of experimental data, which is based on the identification of good features through nonlinear generalizations of principal component analysis, and the construction of nonlinear mappings using nonparametric techniques such as local approximation.  These nonlinear mappings can be used for several purposes, including prediction, noise reduction, and system characterization.  For time series data (e.g. sequences of interspike intervals) they provide more accurate and reliable methods for measuring fractal dimension and determining whether chaos is present.  For stimulus- response experiments (e.g. event related potentials and fields) they can be used to search for regularity and predictability, both for classification and generalization.  We propose to develop further our methods to cope with problems encountered in biological neural data, such as nonstationary behavior, and to apply our methods to data from neuroscience experiments including those listed above. This will allow us to determine with much more precision than has been achieved so far whether the apparent randomness of many neural phenomena derives from complex nonlinear dynamics.  If indeed this is the case, then the result might be a significant change in the paradigm used for modeling the nervous system.  If this is not the case, then we can avert pointless further work in this direction.  Our ultimate purpose is to discover any underlying deterministic structure that may currently lie hidden in apparently random neural phenomena.  n/a","LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM",3387004,R01MH047184,"['computer program /software', ' computer simulation', ' electroencephalography', ' evoked potentials', ' mathematical model', ' neural information processing', ' neurobiology', ' single cell analysis', ' stimulus /response']",NIMH,UNIVERSITY OF CALIF-LOS ALAMOS NAT LAB,R01,1991,114743,-0.024107878165450285
"LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM Neural systems often have significant components of their behavior that appear to be random.  Traditionally this randomness is modeled in stochastic and often linear terms.  Since neural systems consist of highly interconnected nonlinear elements, however, a natural alternative explanation is that the randomness derives from complex nonlinear dynamics such as chaos.  This has been suggested by experiments on several neural systems, including irregular firing patterns in the nervous systems of gastropod molluscs, the human electroencephalogram in deep sleep and epilepsy, single neuron recordings in the cat and monkey visual cortex, and hippus in the pupil-light reflex.  However, inmost cases the evidence for chaos remains inconclusive, in large part because the data analysis is based on techniques that are notoriously unreliable, such as currently popular algorithms for computing fractal dimension.  We have recently introduced a new approach to the analysis of experimental data, which is based on the identification of good features through nonlinear generalizations of principal component analysis, and the construction of nonlinear mappings using nonparametric techniques such as local approximation.  These nonlinear mappings can be used for several purposes, including prediction, noise reduction, and system characterization.  For time series data (e.g. sequences of interspike intervals) they provide more accurate and reliable methods for measuring fractal dimension and determining whether chaos is present.  For stimulus- response experiments (e.g. event related potentials and fields) they can be used to search for regularity and predictability, both for classification and generalization.  We propose to develop further our methods to cope with problems encountered in biological neural data, such as nonstationary behavior, and to apply our methods to data from neuroscience experiments including those listed above. This will allow us to determine with much more precision than has been achieved so far whether the apparent randomness of many neural phenomena derives from complex nonlinear dynamics.  If indeed this is the case, then the result might be a significant change in the paradigm used for modeling the nervous system.  If this is not the case, then we can avert pointless further work in this direction.  Our ultimate purpose is to discover any underlying deterministic structure that may currently lie hidden in apparently random neural phenomena.  n/a","LOW DIMENSIONAL CHAOS, NONLINEAR MAPS & NERVOUS SYSTEM",3387003,R01MH047184,"['computer program /software', ' computer simulation', ' electroencephalography', ' evoked potentials', ' mathematical model', ' neural information processing', ' neurobiology', ' single cell analysis', ' stimulus /response']",NIMH,UNIVERSITY OF CALIF-LOS ALAMOS NAT LAB,R01,1990,110200,-0.024107878165450285
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,6180774,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2000,283617,0.09987056372004582
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,2900912,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1999,207192,0.09987056372004582
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,2685132,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1998,172242,0.09987056372004582
"MODELS IN POPULATION GENETICS The genes of the human leukocyte antigen (HLA) region control a variety          Of functions involved in the immune response, and influence                      susceptibility to over 40 diseases.  Our understanding of the structure          and function of the HLA genes, their disease associations, and the               evolutionary features of this multigene family has benefitted from recent        advances in molecular biology, immunology, disease modelling and                 population genetics.  Theoretical studies in the development of models to        determine the modes of inheritance of the HLA associated diseases have           led to a better understanding of the inheritance patterns in insulin             dependent diabetes mellitus, rheumatoid arthritis, multiple sclerosis,           ankylosing spondylitis, hemochromatosis, celiac disease, and others.  It         is now clear that many of the HLA associated diseases involve                    heterogeneity in their HLA components, as well as non-HLA genetic                components.                                                                                                                                                       The specific aims of our research are to study the genetic components in         the etiology of the HLA associated diseases, and population genetic              features of the HLA system.  A variety of methods to test modes of               inheritance of diseases using marker allele information, will be                 developed.  Methods appropriate for the analysis of marker systems which         are not highly polymorphic, to both detect linkage and determine modes of        inheritance, will be investigated.  The information content of particular        pedigree types for LOD score analysis will be investigated.  Two methods         using patterns of linkage disequilibrium will be investigated to                 determine their usefulness in mapping disease predisposing genes.  A             number of large collaborative data sets of HLA associated diseases will          be analyzed.  A framework for genetic counselling of HLA associated, and         other complex diseases, will be developed.  The results of our studies           are generally applicable to the mapping and characterization of complex          human genetic traits.                                                             n/a",MODELS IN POPULATION GENETICS,2441883,R01GM056688,"['European', "" Hodgkin's disease"", ' MHC class I antigen', ' MHC class II antigen', ' T cell receptor', ' alleles', ' antiserum', ' artificial intelligence', ' biochemical evolution', ' celiac disease', ' computer assisted sequence analysis', ' computer data analysis', ' disease /disorder proneness /risk', ' gene frequency', ' genetic counseling', ' genetic disorder diagnosis', ' genetic markers', ' genetic models', ' genetic polymorphism', ' genotype', ' hereditary hemochromatosis', ' heterozygote', ' histocompatibility antigens', ' histocompatibility gene', ' homozygote', ' human genetic material tag', ' human population genetics', ' immunogenetics', ' insulin dependent diabetes mellitus', ' linkage disequilibriums', ' mathematical model', ' molecular genetics', ' multiple sclerosis', ' nucleic acid sequence', ' oligonucleotides', ' restriction fragment length polymorphism', ' rheumatoid arthritis', ' serotyping', ' statistics /biometry']",NIGMS,UNIVERSITY OF CALIFORNIA BERKELEY,R01,1997,185122,0.09987056372004582
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9923542,R01AG059874,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Differences', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data harmonization', 'data reuse', 'data sharing', 'data tools', 'demented', 'dementia risk', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2020,619917,0.01819216615589
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9750590,R01AG059874,"['Affect', 'Age', 'Aging', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Differences', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data sharing', 'demented', 'dementia risk', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2019,619917,0.01819216615589
"High resolution mapping of the genetic risk for disease in the aging brain ABSTRACT Brain structure undergoes changes throughout life as part of the normal healthy aging process, yet some genetic factors embedded in our DNA are believed to alter and potentially accelerate the aging process within the brain. While numerous neuroimaging studies have aimed to map the genetics of dementia, differences in populations and approaches confounded with the small effect sizes attributable to any single genetic variant leads to inconsistencies in findings and limited resources to investigate the truth. Dozens of neuroimaging genetic studies have been collected around the world to help better understand the link. However, the independent nature by which the studies often operate may be limiting scientific advance. Instead of collecting new data to answer the same questions, we harmonize brain mapping efforts across existing studies and pool information to not only study differences between the healthy and demented brain, but also examine normal healthy aging trends, and determine the first signs of deviation, and map out the neurobiological effect of genes that confer risk for dementia. In our effort, we aim to pinpoint mechanistic trajectories and brain circuits by which the widely studied ApoE4 genetic haplotype affects brain throughout life. Despite being identified as a genetic risk for Alzheimer's disease over 20 years ago, the effects on the brain in populations around the world are remarkably inconsistent. With novel brain mapping techniques across tens of thousands of individuals across the lifespan, we will perform the most well powered brain mapping initiative and build necessary tools to invite other researchers from around the world to add confidence to the findings. We will also determine – with unprecedented power -- how the aggregate risk for AD promotes accelerated brain degeneration with novel expedited longitudinal linear mixed modeling techniques for large scale epidemiological genetic studies with repeat data. Our proposal brings together contributions from multidisciplinary collaborators with world renowned expertise in neurodegeneration, brain mapping, big data, artificial intelligence, epidemiology, genomics and epigenomes, statistical genetics, and molecular and biological psychiatry. Our technical expertise will provide resources for visualizing genetic results at the finest resolution and provide tools for researchers to use our harmonized analyses to structure their own aging hypotheses in populations of men and women around the world, and even target sex-specific hypotheses in aging. As new brain imaging and genetic data is becoming rapidly available, we provide the tools to harmonize the data into this workflow for years to come. Driven by the data sharing and reuse of this proposal, we provide a portal for researchers of today and tomorrow to access findings from all the studies incorporated in this proposal and add to the collective repository of effects. We hope our careful harmonization of data, along with novel mathematics, tools, and selection of targeted hypotheses will guide future collaborative studies for continuous reuse. PROJECT NARRATIVE/RELEVANCE Brain aging is a global health concern and a major focus of dozens of large scale research initiatives around the world. Here, we propose a paradigm to use advanced brain imaging techniques in a harmonized fashion across numerous existing datasets, and to map the underlying genetic influences driving neurodegeneration across tens of thousands of individuals. We will provide advanced brain image processing, mathematical tools, and a portal for researchers to access and add to findings.",High resolution mapping of the genetic risk for disease in the aging brain,9578938,R01AG059874,"['Affect', 'Age', 'Aging', 'Aging-Related Process', 'Algorithmic Software', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'American', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Big Data', 'Biological', 'Biological Psychiatry', 'Brain', 'Brain Diseases', 'Brain Mapping', 'Brain imaging', 'Cardiovascular Diseases', 'Cardiovascular system', 'Chromosome Mapping', 'Chronic', 'Clinical', 'Collection', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Dementia', 'Diagnosis', 'Disease', 'Environmental Risk Factor', 'Epidemiology', 'Female', 'Foundations', 'Fright', 'Future', 'Genes', 'Genetic', 'Genetic Risk', 'Genetic study', 'Genomics', 'Genotype', 'Haplotypes', 'Healthcare', 'Heart Diseases', 'Human', 'Imaging Techniques', 'Impaired cognition', 'Individual', 'International', 'Lead', 'Life', 'Link', 'Literature', 'Longevity', 'Longitudinal Studies', 'Malignant Neoplasms', 'Maps', 'Mathematics', 'Medicine', 'Meta-Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurosciences', 'Participant', 'Population', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Sample Size', 'Scientific Advances and Accomplishments', 'Sex Characteristics', 'Structure', 'Surveys', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Uncertainty', 'Variant', 'Visualization software', 'Woman', 'Work', 'X Chromosome', 'aging brain', 'aging population', 'apolipoprotein E-4', 'biobank', 'brain health', 'cognitive testing', 'data sharing', 'demented', 'disorder risk', 'epidemiology study', 'epigenome', 'flexibility', 'gene environment interaction', 'genetic association', 'genetic epidemiology', 'genetic profiling', 'genetic variant', 'genome-wide', 'global health', 'healthy aging', 'image processing', 'imaging genetics', 'insight', 'male', 'men', 'multidisciplinary', 'neuroimaging', 'novel', 'novel therapeutics', 'repository', 'risk variant', 'screening', 'sex', 'tool', 'trait', 'trend']",NIA,UNIVERSITY OF SOUTHERN CALIFORNIA,R01,2018,619917,0.01819216615589
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures. Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8848345,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'differential expression', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait', 'transcriptome sequencing']",NIAMS,SOUTHWEST RESEARCH INSTITUTE,R01,2015,468202,0.10807710901094103
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.        Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8665879,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait', 'transcriptome sequencing']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2014,494390,0.10807710901094103
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.        Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8471655,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait', 'transcriptome sequencing']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2013,639128,0.10807710901094103
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.        Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8301575,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2012,713809,0.10807710901094103
"Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics    DESCRIPTION (provided by applicant): The structural integrity of bone in any mechanical loading environment is an integrative function of a multitude of complex and interrelated characteristics of bone at the macro-, micro- and ultrastructural levels of bone's structural organization. Bone fragility and increased fracture risk result from multiple, distinct combinations of scores of bone traits. A dynamic process of co-adaptation of traits provides for redundant combinations of traits through which structures are produced that provide adequate functionality under ""normal"" loading conditions. However, some of these combinations of traits can result in structures that are suboptimal when subjected to atypical or traumatic loads, such as those encountered in a fall. The dominant study design in skeletal genetics and biomechanics focuses on the role of one or a limited set of morphological and/or compositional factors in bone fragility. This approach is effective for identifying discrete traits that contribute to bone fracture resistance, but we cannot get a complete picture of the mechanobiological processes underlying fracture risk without a more comprehensive study design that captures variation at each of bone's hierarchical levels, since all of these traits work synergistically to control fracture risk. We propose a multi-disciplinary, integrative approach that is a major departure from traditional approaches to skeletal biomechanics and genetics. Our study is designed to identify composite traits comprising uncorrelated expression patterns of specific measures of bone quality and density that are linked to bone structural performance, to estimate the heritability (h2) of these composite traits, and to prioritize genes and gene networks most likely to affect fracture risk. Specifically, we aim to 1) measure a thorough suite of bone traits in the femurs of 100 pedigreed baboons, then use variable reduction methods to distill the multitude of interrelated, highly correlated traits down to a small set of uncorrelated descriptors of variation in bone morphology and composition. Hypothesis: There is a set of uncorrelated, composite traits that efficiently disentangles the elaborate network of compositional and morphological traits responsible for population-level normal variation in bone biomechanical behavior. 2) Characterize age and sex effects on these composite traits, 3) Assess femoral apparent biomechanical properties under normal and non-habitual loading conditions. Hypothesis: Differential expression of these traits in individuals results in structures that support normal functional musculoskeletal activities, a subset of which perform poorly when loaded in a non-habitual manner. 4) Detect and quantify the proportion of variation in each composite descriptor that is due to the additive effects of genes (h2), and 5) Identify genes and networks that are differentially active in bone tissue from strong for size vs. weak for size femurs. Such fundamental knowledge would allow for development of vastly improved preventative and therapeutic strategies for osteoporosis-related fractures.      PUBLIC HEALTH RELEVANCE: Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.           Osteoporosis is an age-related health problem of immediate public health concern that results in 1.5 million fractures in the U.S. each year. Great strides have been made in identifying a vast number of bone composition and shape traits that affect fracture risk, but traditional study designs limit our ability to understand how these traits work together to result in strong vs. weak bones. We will employ a more comprehensive study design that captures variation at each of bone's hierarchical levels to get a more complete picture of the mechanobiological processes underlying fracture risk, and to discover genes that mediate fracture risk. Such fundamental knowledge will speed development of vastly improved preventative and therapeutic strategies.         ",Bone Structural Integrity Profiling to Advance Skeletal Genetics and Biomechanics,8187565,R01AR060341,"['Adherence', 'Affect', 'Age', 'Area', 'Behavior', 'Biological', 'Biomechanics', 'Body Size', 'Bone Density', 'Bone Tissue', 'Characteristics', 'Complex', 'Computer Simulation', 'Descriptor', 'Development', 'Disease', 'Environment', 'Exhibits', 'Female', 'Femur', 'Fracture', 'Future', 'Gene Expression Profile', 'Genes', 'Genetic', 'Genetic Variation', 'Goals', 'H2 gene', 'Health', 'Heritability', 'Individual', 'Knowledge', 'Length', 'Link', 'Maintenance', 'Measures', 'Mechanics', 'Mediating', 'Methods', 'Molecular', 'Morphology', 'Musculoskeletal', 'Osteoporosis', 'Papio', 'Pathway Analysis', 'Pattern', 'Performance', 'Population', 'Principal Component Analysis', 'Process', 'Property', 'Public Health', 'Research Design', 'Resistance', 'Risk', 'Role', 'Shapes', 'Simulate', 'Speed', 'Structure', 'Testing', 'Therapeutic', 'Tissues', 'Variant', 'Work', 'age effect', 'age related', 'bone', 'bone quality', 'bone strength', 'design', 'falls', 'gene discovery', 'improved', 'male', 'sex', 'skeletal', 'substantia spongiosa', 'trait']",NIAMS,TEXAS BIOMEDICAL RESEARCH INSTITUTE,R01,2011,723535,0.10316020773674744
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7798636,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'disease diagnosis', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2010,35821,0.08000725434284
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7616408,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'disease diagnosis', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2009,35821,0.08000725434284
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7392804,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease regression', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Numbers', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2008,35821,0.08000725434284
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7269518,R01MH066990,"['Afferent Neurons', 'Algorithms', 'Area', 'Arts', 'Attention', 'Award', 'Back', 'Basic Science', 'Biological Neural Networks', 'Brain', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease regression', 'Drug Formulations', 'Engineering', 'Estimation Techniques', 'Feedback', 'Fostering', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Human', 'Imagery', 'Informatics', 'Intention', 'Lasso', 'Lead', 'Learning', 'Machine Learning', 'Macular degeneration', 'Maintenance', 'Maps', 'Medicine', 'Methods', 'Modeling', 'Motor', 'Neurosciences', 'Noise', 'Non-linear Models', 'Nonlinear Dynamics', 'Numbers', 'Peripheral', 'Physiological', 'Physiology', 'Procedures', 'Property', 'Recording of previous events', 'Response to stimulus physiology', 'Sensory', 'Sensory Process', 'Series', 'Software Tools', 'Specialist', 'Staging', 'Stimulus', 'Systems Analysis', 'Techniques', 'Training', 'Translating', 'Validation', 'Variant', 'analytical tool', 'base', 'diagnosis evaluation', 'feeding', 'motor control', 'neural prosthesis', 'neurophysiology', 'novel', 'receptive field', 'relating to nervous system', 'repository', 'research study', 'response', 'sensory stimulus', 'sensory system', 'statistics', 'tool', 'user friendly software']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2007,35821,0.08000725434284
"Quantitative Tools for Investigating Sensory Systems    DESCRIPTION (provided by applicant):  Our understanding the physiology of human brain relies on the detailed description of the mapping between sensory stimuli and neural responses.  These mappings are complex as they involve non-linear transformations, dynamics, learning and adaptation, feedback and priors due to natural or learned constraints.  Inspired by recent advances in the field of machine learning, we will investigate the use of a series of algorithms that will allow us to characterize such complex mappings.  The algorithms represent modern improvements to the classical engineering systems analysis approach that could only be applied to the most peripheral stages of sensory processing.  These new algorithms use the power of modern computers to efficiently find the simplest set of functions that describe dynamical and non-linear mappings.  Our first two aims focus on development of parametric and non-parametric algorithms to characterize general stimulus response mappings.  The parametric models include explicit formulations of adaptive gain control and feedback.  The non-parametric models are estimated from the data using several algorithms, including maximally informative dimensions, neural network analyses, Lasso regression and kernel regression.  Our third aim is to develop methods to validate various models.  We also propose to make these tools available to the neuroscience community at large by incorporating them into STRFPAK, a software package (released during the previous award period and undergoing continuous improvement) for estimating receptive fields of sensory neurons.  Finally, we propose to develop a database that will serve as a repository for neuro-physiological data and analysis tools developed in the community.  The database will encourage the validation and distributions of data analysis methods.  The database will also provide experimental data to theorist and modelers of brain function.  The stimulus-response mapping algorithms developed under this proposal will provide neurobiologists with quantitative tools previously only available to specialists.  They therefore will have a direct benefit on basic research.  A thorough understanding of the complex stimulus-response mapping of sensory systems will also have significant benefits for several areas of medicine:  evaluation and diagnosis of disease states such as macular degeneration, and improvements in neural prosthetics such as hearing aids.  The computational mechanisms governing how the brain represents the sensory world are in many respects similar to those governing how the brain translates motor intention to motor action.  Therefore, application of these algorithms is also likely to lead to eventual improvements in neural prosthetics for motor control and action.       n/a",Quantitative Tools for Investigating Sensory Systems,7125904,R01MH066990,"['bioinformatics', 'computational neuroscience', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'information system analysis', 'mathematical model', 'model design /development', 'neural information processing', 'neurophysiology', 'sensory feedback', 'sensory mechanism', 'statistics /biometry']",NIMH,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2006,295127,0.08000725434284
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6783325,R21HL070363,"['artificial intelligence', 'bioimaging /biomedical imaging', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'echocardiography', 'evaluation /testing', 'heart function', 'human subject', 'method development', 'swine']",NHLBI,MAYO CLINIC,R21,2004,144693,-0.0075296699865210325
"Multiparametric Computational Echocardiography DESCRIPTION (provided by applicant):    In the United States, myocardial ischemia is the underlying etiology in nearly 70% of the 5 million patients suffering from mechanical failure of the cardiac left ventricle (LV). Echocardiography (echo) is well suited for the analysis of LV function, however, the problem of conveying this clinically important information in a quantitative, objective, and reproducible manner persists.      To address this problem and respond to the NIH PA-00-117 solicitation for innovations in biomedical information science and technology, the long-term goal of the proposed R21/R33 project is to develop methods for 1) quantitative and objective measurement of LV function, 2) reproducible diagnostic interpretation based on these measurements, and 3) standardized topologic mapping and parametric display of the results. We defined 3 parameters of LV function: 1) rate of local deformation (strain rate), 2) amplitude of deformation (strain), and 3) time interval to the transition (crossover) point of cyclic deformation.      The practical implementation of the long-term objectives will be achieved through the development of a Multiparametric Computational Echo (MPCE) system. The main hypothesis of this R21/R33 project is that the MPCE system will a) precisely and accurately quantitate (R21 phase) and b) reproducibly clinically interpret (R33 phase) segmental LV function. This hypothesis will be tested on digital echo data from animal models and clinical cases of myocardial ischemia representing a wide range of segmental LV dysfunction.      Specific Aims (R21 phase):   Aim 1 - Develop algorithms for parametric analysis of local ventricular function (Year 1).   Aim 2 - Test precision and accuracy of local LV functional analysis using MPCE (Year 2).   Satisfaction of the predefined milestones will initiate the commencement of the R33 phase.      Specific Aims (R33 phase):   Aim 1 - Develop a neural network MPCE system and test it initially in animals (Year 3).   Aim 2 - Refine parametric mapping and test reproducibility of MPCE data in humans (Year 4).   Successful completion of this project will result in noninvasive, quantitative, objective, and reproducible interpretation of LV function, thus facilitating optimal diagnostic and therapeutic decisions in cardiology. n/a",Multiparametric Computational Echocardiography,6688878,R21HL070363,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' echocardiography', ' evaluation /testing', ' heart function', ' human subject', ' method development', ' swine']",NHLBI,"MAYO CLINIC COLL OF MEDICINE, ROCHESTER",R21,2003,136861,-0.0075296699865210325
"Genetical Genomics Analysis Software    DESCRIPTION (provided by applicant): Response to drug treatment is thought dependent upon genotype for many modern therapies. Knowledge of how each genotype responds to a particular therapy is bene?cial only in that one can identify portions of the population which cannot reap the benefits of said treatment. A better course of action is to identify not only which genotype responds, or not, to a particular therapy, but to identify which region of the genome is responding, or not, and how. We believe that this information will lead to new drug targets and better therapies that benefit a larger portion of the population. The goal of this proposal is to provide a suite of software tools for genetic and genomic scientists performing gene mapping experiments with genomic data as the response variable. These tools will ideally provide functionality for 1) detecting polymorphic regions of the genome that con- fer transcript expression differences, 2) identify polymorphic regions of the genome that impart expression differences in genes located elsewhere in the genome, and 3) detecting interactions between loci that may correspond to epistatic effects on transcription. Some software already exists to perform each of these tasks as distinct independent solutions. This proposal intends to produce an integrated solution, S+EQTL (S-PLUS for expression quantitative trait loci mapping), that utilizes the power of S-PLUS and both incorporates and extends the functionality of an exist- ing genetics suite. By providing scientists with an integrated set of tools for genomics experiments with a genetic component, more productive time can be spent interpreting the results rather than transforming data into different formats to be processed by multiple software analysis packages. This software should also address one of the most dif?cult aspects of genetical genomics exper- iments, the so called curse of dimensionality. As the genomics community continues gathering knowledge of transcripts in various organisms, the arrays that interrogate transcript abundance only grow larger in the number of transcript species included. In the absence of tools designed for this purpose, the research scientist is left with the option of either focusing on a narrow set of previously known genes or performing a grid-wise search on all genes in the array. The former is not interesting as these genes are likely well studied and may provide little novel insight. The latter is computationally demanding and may not be possible on the new, larger arrays. A recent publication presents a novel solution that may be enhanced to gain both power and scale using Bayesian methodology. Knowledge of how each genotype responds to a particular drug therapy is beneficial only in that one can identify portions of the population which cannot reap the benefits of said treatment. A better course of action is to identify not only which genotype responds, or not, to a particular therapy, but to identify which region of the genome is responding, or not, and how. We believe that the development of analytic tools for gene mapping experiments to identify this information will lead to new drug targets and better therapies that benefit a larger portion of the population.          n/a",Genetical Genomics Analysis Software,7216142,R43GM079852,"['Address', 'Air', 'Algorithms', 'Animal Genetics', 'Anus', 'Arizona', 'Bioconductor', 'Bioinformatics', 'Biological Markers', 'Biometry', 'Biotechnology', 'Bovine Spongiform Encephalopathy', 'Cations', 'Cattle', 'Chromosome Mapping', 'Code', 'Communities', 'Complex', 'Computer Simulation', 'Computer software', 'Con-fer', 'Data', 'Data Analyses', 'Data Set', 'Department of Defense', 'Depth', 'Development', 'Diagnostic', 'Disease', 'Disease regression', 'Doctor of Philosophy', 'Drug Delivery Systems', 'Educational process of instructing', 'Educational workshop', 'Employment', 'Ensure', 'Exons', 'Family suidae', 'Fatty acid glycerol esters', 'Foundations', 'Gene Combinations', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Research', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Government', 'Government Agencies', 'Graph', 'Imagery', 'Individual', 'Industry', 'Institution', 'International', 'Investments', 'Iowa', 'Knowledge', 'Lead', 'Left', 'Libraries', 'Literature', 'Liver', 'Location', 'Machine Learning', 'Manuals', 'Maps', 'Methodology', 'Methods', 'Microarray Analysis', 'Modeling', 'Molecular Genetics', 'Mus', 'Nebraska', 'North Carolina', 'Numbers', 'Obese Mice', 'Obesity', 'Organism', 'Output', 'Pathway interactions', 'Performance', 'Pharmaceutical Preparations', 'Pharmaceutical Services', 'Pharmacotherapy', 'Phase', 'Phenotype', 'Population', 'Principal Investigator', 'Process', 'Publications', 'Purpose', 'Quantitative Genetics', 'Quantitative Trait Loci', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Single Nucleotide Polymorphism', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Small Business Technology Transfer Research', 'Software Tools', 'Solutions', 'Standards of Weights and Measures', 'Sus scrofa', 'Techniques', 'Telecommunications', 'Testing', 'Therapeutic', 'Thermogenesis', 'Thinking', 'Time', 'Time Series Analysis', 'Tissues', 'Training', 'Transcript', 'Treatment Protocols', 'United States National Aeronautics and Space Administration', 'United States National Institutes of Health', 'Universities', 'Washington', 'Work', 'animal breeding', 'base', 'design', 'experience', 'expression vector', 'genetic pedigree', 'hazard', 'improved', 'insight', 'interest', 'lecturer', 'novel', 'professor', 'programs', 'prototype', 'research and development', 'research study', 'response', 'skills', 'software development', 'success', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R43,2007,101707,0.02147976277163646
"The Dynamics of Human Atrial Fibrillation Project Summary  Atrial fibrillation (AF) is a major arrhythmia worldwide, causing palpitations, stroke and mortality, and affecting 2-5 million Americans. Unfortunately, therapy to eliminate AF has had limited success. In our last funding cycle, we focused on localized drivers as potential AF mechanisms. Mapping of drivers has now been validated by concurrent optical mapping of human AF, and their features and have been validated by several other methods in patients. Nevertheless, ablation results for these and other proposed mechanisms for AF outside the pulmonary veins are mixed. It is unclear if this reflects difficulties of AF mapping, or different mechanisms between patients.  The project will develop a novel mechanistic framework for AF that simplifies existing indices by building on scientific consensus that organized AF is easier to treat, and disorganized AF has worse prognosis. This concept spans many existing indices and may help to reconcile them. We have 3 specific aims: (1) To define if the impact of ablation depends on the extent of organizing surrounding the ablation site; (2) To establish candidate mechanisms for organized and disorganized AF zones in individual patients with specific profiles, using machine learning applied to known cases with and without ablation success in our large registry. This comprises detailed AF maps during ablation and after Maze surgery, clinical data and outcomes. (3) To use novel clinical tools to predict whether patients will respond to PVI, other ablation or Maze surgery based on whether targeted regions control larger atrial areas and their locations.  This study will deliver immediate translational and clinical impact, and directly enable personalized medicine for AF ablation. We use detailed clinical mapping in patients, signal processing and computer modeling to develop a novel mechanistic framework and widely applicable clinical tools. We will use tools including machine learning and statistics to classify mechanisms based upon outcomes from ablation in individual patients. We will make our data and code available online. Our team is experienced in electrophysiology, computer science, machine learning, biological physics and statistics. The proposal is thus highly feasible. The Dynamics of Human Atrial Fibrillation Narrative Atrial fibrillation (AF) is an enormous public health problem in the United States, affecting 2-5 million Americans and causing rapid heart beats, stroke, heart failure or death. In this project, the applicant will develop a novel framework to better understand human AF that builds on agreement between several concepts for the disease. The applicant will develop strategies to identify AF patients who will best respond to each of several therapies, to guide personalized therapy.",The Dynamics of Human Atrial Fibrillation,10071621,R01HL083359,"['Ablation', 'Acute', 'Address', 'Affect', 'Agreement', 'American', 'Anatomy', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological', 'Biometry', 'Body Surface', 'Cessation of life', 'Clinical', 'Clinical Data', 'Code', 'Computer Models', 'Consensus', 'Data', 'Data Element', 'Disease', 'Electrocardiogram', 'Electrophysiology (science)', 'Fibrosis', 'Funding', 'Goals', 'Heart', 'Heart Atrium', 'Heart failure', 'Human', 'Image', 'Individual', 'Intervention', 'Lesion', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Methods', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Observational Study', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Palpitations', 'Paper', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Physics', 'Prediction of Response to Therapy', 'Procedures', 'Public Health', 'Pulmonary veins', 'Registries', 'Right atrial structure', 'Rotation', 'Schools', 'Site', 'Statistical Data Interpretation', 'Stroke', 'Structural defect', 'Techniques', 'Testing', 'Time', 'Tissues', 'United States', 'United States National Institutes of Health', 'Work', 'base', 'clinical application', 'cohort', 'computer science', 'demographics', 'digital', 'experience', 'genomic data', 'hands-on learning', 'indexing', 'individual patient', 'insight', 'mortality', 'novel', 'novel diagnostics', 'novel therapeutics', 'outcome forecast', 'patient stratification', 'personalized medicine', 'prevent', 'prospective', 'response', 'signal processing', 'statistics', 'success', 'therapy development', 'tool']",NHLBI,STANFORD UNIVERSITY,R01,2020,770947,-0.013516861934468483
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu    DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. PUBLIC HEALTH RELEVANCE: We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured association mapping between disease-relevant elements in the genome, transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and interdependent genome variations, structured association analysis at multi-omic level is not only needed, but also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view of complex diseases, which may lead to the identification of genes underlying disease processes; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.           Project Narrative We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured association mapping between disease-relevant elements in the genome, transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and interdependent genome variations, structured association analysis at multi-omic level is not only needed, but also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view of complex diseases, which may lead to the identification of genes underlying disease processes; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,7636332,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Architecture', 'Arts', 'Asthma', 'Atlases', 'Behavior', 'Biological', 'Biological Assay', 'Biological Markers', 'Blood Pressure', 'Body Weight', 'Bronchoalveolar Lavage', 'Cell model', 'Cells', 'Classification', 'Clinical', 'Clinical Research', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'Coupling', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Dependency', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Documentation', 'Elements', 'Enzyme-Linked Immunosorbent Assay', 'Epithelial', 'Etiology', 'Evaluation', 'Evolution', 'Exhibits', 'Family', 'Gene Conversion', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Gold', 'Graph', 'Hand', 'Haplotypes', 'Housing', 'Human', 'Hybrids', 'Indium', 'Individual', 'Internet', 'Investigation', 'Joints', 'Knock-out', 'Knowledge', 'Lasso', 'Lead', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measurement', 'Measures', 'Mediating', 'Medical center', 'Medicine', 'Methodology', 'Methods', 'Microsatellite Repeats', 'Mining', 'Modeling', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Mutation', 'Obesity', 'Ontology', 'Outcome', 'Output', 'Pathogenesis', 'Pathway interactions', 'Patients', 'Pattern', 'Penetrance', 'Performance', 'Phase', 'Phenotype', 'Plastics', 'Population', 'Procedures', 'Process', 'Proteins', 'Publishing', 'Quantitative Trait Loci', 'Recombinant Haplotype', 'Recruitment Activity', 'Regulation', 'Regulator Genes', 'Regulatory Element', 'Regulatory Pathway', 'Reporting', 'Research', 'Risk', 'Role', 'Sampling', 'Severities', 'Shapes', 'Signal Transduction', 'Simulate', 'Software Tools', 'Specificity', 'Statistical Models', 'Structure', 'Study Subject', 'Symptoms', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Transcription Regulation Pathway', 'Transcriptional Regulation', 'Trees', 'Triplet Multiple Birth', 'Unified Medical Language System', 'Universities', 'Validation', 'Variant', 'Western Blotting', 'Work', 'Yeasts', 'base', 'clinical phenotype', 'cohort', 'combinatorial', 'computer based statistical methods', 'cost', 'data integration', 'data mining', 'disease phenotype', 'disorder control', 'disorder subtype', 'gene function', 'genetic linkage analysis', 'genome wide association study', 'grasp', 'high throughput analysis', 'hydroxy-aluminum polymer', 'improved', 'innovation', 'mathematical model', 'molecular phenotype', 'network models', 'novel', 'phenome', 'programs', 'public health relevance', 'reconstruction', 'response', 'scale up', 'software systems', 'statistics', 'tool', 'trait', 'user friendly software']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2009,544383,0.02157986068902022
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,8054816,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic analysis', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2011,513100,0.020026458046349595
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu    DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. PUBLIC HEALTH RELEVANCE: We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured association mapping between disease-relevant elements in the genome, transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and interdependent genome variations, structured association analysis at multi-omic level is not only needed, but also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view of complex diseases, which may lead to the identification of genes underlying disease processes; in addition, such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.          Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,7845048,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'public health relevance', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2010,515713,0.02157986068902022
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,8656359,R01GM087694,"['Address', 'Admixture', 'Affect', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'High-Throughput Nucleotide Sequencing', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Algorithm', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic analysis', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2014,492794,0.020026458046349595
"Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu DESCRIPTION (provided by applicant): Many complex disease syndromes consist of a large number of highly related, rather than independent, clinical phenotypes. Differences between these syndromes involve the complex interplay of a large number of genomic variations that perturb the function of disease-related genes in the context of a regulatory network, rather than individually. Thus unraveling the causal genetic variations and understanding the mechanisms of consequent cell and tissue transformation requires an analysis that jointly considers the epistatic, pleiotropic, and plastic interactions of elements and modules within and between the genome (G), transcriptome (T), and phenome (P). Most conventional methods focus on associations between every individual marker genotype and every single phenotype; they have limited statistical power and overlook the complex omit structures. We propose a systematic attempt on methodological development for the largely unexplored but practically important problem of structured associations between the ""-omes"". Rather than testing each SNP separately for association and then applying a correction by multiple hypothesis test, a structured association analysis identifies associations between groups of entities each with its own sophisticated structure that can not be ignored, such as blocks of SNPs with high LD, modules of genes in the same pathway, and clusters of phenotypes belong to a system of clinical descriptors of a disease. We will develop a mathematically rigorous and computationally efficient machine learning platform and software to address the methodological challenges involved with unraveling the interplay between disease-relevant elements in the G, T, and P omes. Our technical innovations include novel statistical models and algorithms for haplotype inference, recombination hotspot detection, gene network and phenotype network inference, admixture association mapping, and most importantly, a family of new structured regression techniques such as the graph-regularized regression, graph- guided fused lasso and extensions, that perform functional approximations to the association functions among structural elements in the G, T, and P omes, and have provable guarantee on consistency and sparsistency. We envisage our proposed research will open a new paradigm for association studies of complex diseases, which facilitates: 1) Intra- and inter-omic integration of data for association mapping and disease gene/pathway discovery, 2) Thorough explorations of the internal structures within different omic data, so that cryptic associations that are not possibly detectable in unstructured analysis due to their weak statistical power can be now inferred. 3) Joint statistical inference of mechanisms and pathways of how variations in DNA lead to variations in complex traits flows through molecular networks, and inference of condition-specific state of gene function in the molecular networks, and 4) Development of faster and automated computational algorithm with greater scalability and robustness to large-scale inter-omic analysis, and more convenient software package and user interface. All the software tools will be made available for free to the public. Project Narrative  We propose a systematic attempt on methodological development for the largely unexplored but practically  important problem of structured association mapping between disease-relevant elements in the genome,  transcriptome, and phenome. Since many complex diseases involve composite phenotypes that are the  outcome of intricate perturbation of molecular network underlying gene regulatory resulted from complex and  interdependent genome variations, structured association analysis at multi-omic level is not only needed, but  also necessary, but it is beyond the grasp of convention methods and requires the methodological innovations  we propose. Characterizing such interactions can provide a more comprehensive genetic and molecular view  of complex diseases, which may lead to the identification of genes underlying disease processes; in addition,  such an approach will allow us to formulate hypotheses regarding the roles of these genes with respect to  disease pathogenesis, and to develop improved diagnostic biomarkers for multivariate clinical phenotypes.",Genome-Transcription-Phenome-Wide Association: a new paradigm for association stu,8251157,R01GM087694,"['Address', 'Admixture', 'Affect', 'Algorithms', 'Asthma', 'Biological Markers', 'Cells', 'Clinical', 'Code', 'Complex', 'Computational algorithm', 'Computer software', 'DNA', 'DNA Sequence', 'Data', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Elements', 'Family', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic Recombination', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Graph', 'Haplotypes', 'Indium', 'Individual', 'Joints', 'Lasso', 'Lead', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Methods', 'Molecular', 'Molecular Analysis', 'Molecular Genetics', 'Molecular Profiling', 'Obesity', 'Outcome', 'Pathogenesis', 'Pathway interactions', 'Phenotype', 'Plastics', 'Population', 'Process', 'Quantitative Trait Loci', 'Regulator Genes', 'Research', 'Role', 'Software Tools', 'Statistical Models', 'Structure', 'Study Subject', 'Syndrome', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissues', 'Transcript', 'Variant', 'Work', 'base', 'clinical phenotype', 'data integration', 'data mining', 'disorder control', 'gene function', 'genetic analysis', 'genetic linkage analysis', 'grasp', 'improved', 'innovation', 'novel', 'phenome', 'trait']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2013,477069,0.020026458046349595
"Tissue-specific protein interactome mapping in a vertebrate embryo Abstract Proteins rarely act in isolation, but rather function in multi-protein complexes. Accordingly, protein-protein interactomes are exceptionally valuable resources that provide deep mechanistic insights and generate myriad hypotheses. Current methods for interactome mapping, such as affinity purification mass-spectrometry (APMS), are extremely difficult to deploy in vivo, so little comprehensive interactome data yet exists for developing embryos and even less for specific tissues within embryos. This fact poses an especially acute problem for understanding highly dynamic processes in which post-transcriptional controls dominate, for example collective cell movements. Here, we will use tissue engaged in convergent extension, a crucial collective movement that elongates the axis of animal embryos, to test the efficacy of new label-free interactome mapping approaches. Successful completion of the project will therefore be significant both for developing broadly applicable new methods and also for providing systems-level insights into a disease- relevant, vertebrate collective cell movement. Project Narrative: This study centers on developing novel methods for systematically identifying protein-protein interactions in embryos. To explore the utility of the method, we focus our efforts on proteins involved in collective cell movements called convergent extension, which are governed by the planar cell polarity (or PCP) proteins. These experiments will be significant because defects in PCP proteins or convergent extension lead to “neural tube defects” such as spina bifida and anencephaly, as well as congenital skeletal dysplasias.",Tissue-specific protein interactome mapping in a vertebrate embryo,10104048,R21HD103882,"['Actomyosin', 'Acute', 'Adhesions', 'Affinity Chromatography', 'Amphibia', 'Anencephaly and spina bifida X linked', 'Animals', 'Biological', 'Cadherins', 'Cells', 'Cellular biology', 'Communities', 'Data', 'Data Set', 'Defect', 'Developmental Biology', 'Developmental Process', 'Disease', 'Dorsal', 'Embryo', 'Fractionation', 'Genetic', 'In Vitro', 'Label', 'Lead', 'Light', 'Machine Learning', 'Mammals', 'Mass Spectrum Analysis', 'Mesoderm', 'Methods', 'Modeling', 'Molecular', 'Movement', 'Multiprotein Complexes', 'Neural Tube Closure', 'Neural Tube Defects', 'Post-Transcriptional Regulation', 'Process', 'Protein Interaction Mapping', 'Protein-Protein Interaction Map', 'Proteins', 'Proteome', 'Proteomics', 'Rana', 'Resources', 'Sampling', 'Spectrometry', 'System', 'Testing', 'Tissues', 'Vertebrates', 'Work', 'Xenopus', 'base', 'cell motility', 'convergent extension', 'data integration', 'efficacy testing', 'embryo tissue', 'experimental study', 'improved', 'in vivo', 'insight', 'novel', 'planar cell polarity', 'protein complex', 'protein protein interaction', 'skeletal dysplasia', 'success', 'vertebrate embryos']",NICHD,"UNIVERSITY OF TEXAS, AUSTIN",R21,2020,237750,0.007623623818786221
"Predicted Gene Expression: High Power, Mechanism, and Direction of Effect ﻿    DESCRIPTION (provided by applicant): Although investments in genomic studies of mental disorders enabled the discovery of thousands of robustly associated variants with these complex diseases, the translation of these discoveries into actionable targets has been hampered by the lack of a mechanistic understanding on how genome variation relates to phenotype. Moreover, it has been widely shown that a substantial portion of the genetic control of complex traits, including mental disorders, is exerted through the regulation of gene expression. However, effective methods to fully harness this mechanism are lagging. To address these challenges, we propose a novel gene-based test -PrediXcan- that directly tests this regulatory mechanism and substantially improves power relative to single variant tests and other gene-based tests. PrediXcan is inherently mechanistic and provides directionality, highlighting its potential utility in identifying novel targets for therapy. The method consists of predicting the whole genome effect on expression traits and correlating this effect with disease risk to identify novel disease genes. In addition, we propose novel approaches to investigate the context-specificity of expression traits (Orthogonal Tissue Decomposition) and to quantify the collective effect of the regulated transcriptome on phenotypes of interest (Regulability). Regulability is similar to the concept of chip heritability (total variability explained collectivey by genotyped variants). First, we will develop cross-tissue, tissue-specific (for over 30 different human tissue types), and brain-region specific expression traits. We will use statistical machine learning methods to develop whole genome prediction models for these traits and extend this work to other molecular phenotypes. All models will be stored in open access databases. Next, we will apply the PrediXcan method to 7 mental disorder phenotypes. More specifically, we will compute genetically predicted levels of gene expression traits and correlate them with disease risk to identify genes involved in disease pathways. We will also quantify the collective effect of the predicted transcriptome (regulability) on mental disorder risk across multiple tissues. Finally we will extend PrediXcan method and develop a method to infer the results of PrediXcan using summary statistics data as opposed to individual level data. This will extend the applicability of the approach to all summary results generated by meta-analysis consortia and increase the power to discover novel genes given the larger sample sizes. The research we propose is driven by an extensive set of preliminary studies, and promises substantial deliverables in both new methods of analysis and public access results databases. PUBLIC HEALTH RELEVANCE: Large investments in genome studies have been made to understand the consequences of genetic variation on human traits. These have yielded many genetic variants reproducibly associated with disease but the underlying biology is still unclear. We propose a novel computational method that links mechanistically the genetic variability to disease risk and apply it to a range of mental disorder studies to provide more biological insights and enable discovery of potential targets for drug development.","Predicted Gene Expression: High Power, Mechanism, and Direction of Effect",9130902,R01MH107666,"['Address', 'Alzheimer&apos', 's Disease', 'Anorexia Nervosa', 'Architecture', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Bioinformatics', 'Biological', 'Biology', 'Bipolar Disorder', 'Brain region', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Set', 'Databases', 'Disease', 'Disease Pathway', 'Etiology', 'Exons', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Health', 'Heritability', 'Histocompatibility Testing', 'Human', 'Individual', 'Investments', 'Learning', 'Link', 'Machine Learning', 'Mental Depression', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Methylation', 'MicroRNAs', 'Modeling', 'Molecular', 'National Institute of Mental Health', 'Obsessive-Compulsive Disorder', 'Performance', 'Phenotype', 'Population', 'Process', 'Quality Control', 'Regulation', 'Research', 'Sample Size', 'Schizophrenia', 'Source', 'Specificity', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Translations', 'Variant', 'Work', 'base', 'database of Genotypes and Phenotypes', 'disorder risk', 'drug development', 'gene function', 'genetic variant', 'genome wide association study', 'human tissue', 'improved', 'insight', 'interest', 'learning strategy', 'molecular phenotype', 'new therapeutic target', 'novel', 'novel strategies', 'statistics', 'tool', 'trait', 'transcriptome', 'user friendly software', 'web app', 'whole genome']",NIMH,UNIVERSITY OF CHICAGO,R01,2016,430578,-0.022999621439866582
"Predicted Gene Expression: High Power, Mechanism, and Direction of Effect ﻿    DESCRIPTION (provided by applicant): Although investments in genomic studies of mental disorders enabled the discovery of thousands of robustly associated variants with these complex diseases, the translation of these discoveries into actionable targets has been hampered by the lack of a mechanistic understanding on how genome variation relates to phenotype. Moreover, it has been widely shown that a substantial portion of the genetic control of complex traits, including mental disorders, is exerted through the regulation of gene expression. However, effective methods to fully harness this mechanism are lagging. To address these challenges, we propose a novel gene-based test -PrediXcan- that directly tests this regulatory mechanism and substantially improves power relative to single variant tests and other gene-based tests. PrediXcan is inherently mechanistic and provides directionality, highlighting its potential utility in identifying novel targets for therapy. The method consists of predicting the whole genome effect on expression traits and correlating this effect with disease risk to identify novel disease genes. In addition, we propose novel approaches to investigate the context-specificity of expression traits (Orthogonal Tissue Decomposition) and to quantify the collective effect of the regulated transcriptome on phenotypes of interest (Regulability). Regulability is similar to the concept of chip heritability (total variability explained collectivey by genotyped variants). First, we will develop cross-tissue, tissue-specific (for over 30 different human tissue types), and brain-region specific expression traits. We will use statistical machine learning methods to develop whole genome prediction models for these traits and extend this work to other molecular phenotypes. All models will be stored in open access databases. Next, we will apply the PrediXcan method to 7 mental disorder phenotypes. More specifically, we will compute genetically predicted levels of gene expression traits and correlate them with disease risk to identify genes involved in disease pathways. We will also quantify the collective effect of the predicted transcriptome (regulability) on mental disorder risk across multiple tissues. Finally we will extend PrediXcan method and develop a method to infer the results of PrediXcan using summary statistics data as opposed to individual level data. This will extend the applicability of the approach to all summary results generated by meta-analysis consortia and increase the power to discover novel genes given the larger sample sizes. The research we propose is driven by an extensive set of preliminary studies, and promises substantial deliverables in both new methods of analysis and public access results databases.         PUBLIC HEALTH RELEVANCE: Large investments in genome studies have been made to understand the consequences of genetic variation on human traits. These have yielded many genetic variants reproducibly associated with disease but the underlying biology is still unclear. We propose a novel computational method that links mechanistically the genetic variability to disease risk and apply it to a range of mental disorder studies to provide more biological insights and enable discovery of potential targets for drug development.            ","Predicted Gene Expression: High Power, Mechanism, and Direction of Effect",8945859,R01MH107666,"['Address', 'Alzheimer&apos', 's Disease', 'Anorexia Nervosa', 'Architecture', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Bioinformatics', 'Biological', 'Biology', 'Bipolar Disorder', 'Brain region', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Set', 'Databases', 'Disease', 'Disease Pathway', 'Etiology', 'Exons', 'Gene Expression', 'Gene Expression Profile', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Heritability', 'Histocompatibility Testing', 'Human', 'Individual', 'Internet', 'Investments', 'Learning', 'Link', 'Machine Learning', 'Mental Depression', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Methylation', 'MicroRNAs', 'Modeling', 'Molecular', 'National Institute of Mental Health', 'Obsessive-Compulsive Disorder', 'Performance', 'Phenotype', 'Population', 'Process', 'Quality Control', 'Regulation', 'Relative (related person)', 'Research', 'Sample Size', 'Schizophrenia', 'Source', 'Specificity', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Translations', 'Variant', 'Work', 'base', 'database of Genotypes and Phenotypes', 'disorder risk', 'drug development', 'gene function', 'genetic variant', 'genome wide association study', 'human tissue', 'improved', 'insight', 'interest', 'molecular phenotype', 'novel', 'novel strategies', 'public health relevance', 'statistics', 'targeted treatment', 'tool', 'trait', 'user friendly software']",NIMH,UNIVERSITY OF CHICAGO,R01,2015,487902,-0.022999621439866582
"Predicted Gene Expression: High Power, Mechanism, and Direction of Effect ﻿    DESCRIPTION (provided by applicant): Although investments in genomic studies of mental disorders enabled the discovery of thousands of robustly associated variants with these complex diseases, the translation of these discoveries into actionable targets has been hampered by the lack of a mechanistic understanding on how genome variation relates to phenotype. Moreover, it has been widely shown that a substantial portion of the genetic control of complex traits, including mental disorders, is exerted through the regulation of gene expression. However, effective methods to fully harness this mechanism are lagging. To address these challenges, we propose a novel gene-based test -PrediXcan- that directly tests this regulatory mechanism and substantially improves power relative to single variant tests and other gene-based tests. PrediXcan is inherently mechanistic and provides directionality, highlighting its potential utility in identifying novel targets for therapy. The method consists of predicting the whole genome effect on expression traits and correlating this effect with disease risk to identify novel disease genes. In addition, we propose novel approaches to investigate the context-specificity of expression traits (Orthogonal Tissue Decomposition) and to quantify the collective effect of the regulated transcriptome on phenotypes of interest (Regulability). Regulability is similar to the concept of chip heritability (total variability explained collectivey by genotyped variants). First, we will develop cross-tissue, tissue-specific (for over 30 different human tissue types), and brain-region specific expression traits. We will use statistical machine learning methods to develop whole genome prediction models for these traits and extend this work to other molecular phenotypes. All models will be stored in open access databases. Next, we will apply the PrediXcan method to 7 mental disorder phenotypes. More specifically, we will compute genetically predicted levels of gene expression traits and correlate them with disease risk to identify genes involved in disease pathways. We will also quantify the collective effect of the predicted transcriptome (regulability) on mental disorder risk across multiple tissues. Finally we will extend PrediXcan method and develop a method to infer the results of PrediXcan using summary statistics data as opposed to individual level data. This will extend the applicability of the approach to all summary results generated by meta-analysis consortia and increase the power to discover novel genes given the larger sample sizes. The research we propose is driven by an extensive set of preliminary studies, and promises substantial deliverables in both new methods of analysis and public access results databases. PUBLIC HEALTH RELEVANCE: Large investments in genome studies have been made to understand the consequences of genetic variation on human traits. These have yielded many genetic variants reproducibly associated with disease but the underlying biology is still unclear. We propose a novel computational method that links mechanistically the genetic variability to disease risk and apply it to a range of mental disorder studies to provide more biological insights and enable discovery of potential targets for drug development.","Predicted Gene Expression: High Power, Mechanism, and Direction of Effect",9301667,R01MH107666,"['Address', 'Alzheimer&apos', 's Disease', 'Anorexia Nervosa', 'Architecture', 'Attention deficit hyperactivity disorder', 'Autistic Disorder', 'Bioinformatics', 'Biological', 'Biology', 'Bipolar Disorder', 'Brain region', 'Complex', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Set', 'Databases', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Etiology', 'Exons', 'Gene Expression', 'Gene Expression Regulation', 'Genes', 'Genetic', 'Genetic Variation', 'Genetic screening method', 'Genome', 'Genomics', 'Genotype', 'Genotype-Tissue Expression Project', 'Heritability', 'Human', 'Individual', 'Investments', 'Link', 'Machine Learning', 'Mathematics', 'Mental Depression', 'Mental disorders', 'Meta-Analysis', 'Methods', 'Methylation', 'MicroRNAs', 'Modeling', 'Molecular', 'National Institute of Mental Health', 'Obsessive-Compulsive Disorder', 'Performance', 'Phenotype', 'Population', 'Process', 'Quality Control', 'Regulation', 'Research', 'Sample Size', 'Schizophrenia', 'Source', 'Specificity', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Translations', 'Variant', 'Work', 'base', 'database of Genotypes and Phenotypes', 'disorder risk', 'drug development', 'gene function', 'genetic variant', 'genome wide association study', 'human tissue', 'improved', 'insight', 'interest', 'learning strategy', 'molecular phenotype', 'new therapeutic target', 'novel', 'novel strategies', 'phenotypic data', 'public health relevance', 'statistics', 'tool', 'trait', 'transcriptome', 'user friendly software', 'web app', 'whole genome']",NIMH,UNIVERSITY OF CHICAGO,R01,2017,430578,-0.022999621439866582
"Assessing psychosis-related deficits based on gaze behavior ﻿    DESCRIPTION (provided by applicant): Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, but rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance couple with biological validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis. PUBLIC HEALTH RELEVANCE: Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, bu rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance coupled with biologicl validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis.",Assessing psychosis-related deficits based on gaze behavior,9278261,R43MH111539,"['Academia', 'Attention', 'Basic Science', 'Behavior', 'Biological', 'Biology', 'Bipolar Disorder', 'Brain', 'Brain scan', 'Categories', 'Classification', 'Clinical', 'Cognitive', 'Computer software', 'Confidential Information', 'Coupled', 'Data', 'Data Files', 'Database Management Systems', 'Dimensions', 'Disease', 'Emotional', 'Etiology', 'Evaluation', 'Exhibits', 'Foundations', 'Future', 'Goals', 'Government', 'Individual', 'Industry', 'Link', 'Machine Learning', 'Masks', 'Measures', 'Memory', 'Monitor', 'Monte Carlo Method', 'Moods', 'Morphologic artifacts', 'Motivation', 'Neurologic', 'Outcome', 'Perception', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Psychopathology', 'Psychotic Disorders', 'ROC Curve', 'Reporting', 'Research', 'Risk', 'Saccades', 'Scanning', 'Schizophrenia', 'Severities', 'Software Tools', 'Solid', 'Stimulus', 'Symptoms', 'Techniques', 'Testing', 'Thalamic structure', 'Translations', 'Unconscious State', 'Vendor', 'Volition', 'Youth', 'base', 'behavioral health', 'case control', 'cingulate gyrus', 'clinical practice', 'cognitive testing', 'community setting', 'computerized data processing', 'cost', 'design', 'flexibility', 'frontal lobe', 'gaze', 'improved', 'indexing', 'innovation', 'outcome prediction', 'proband', 'prototype', 'public health relevance', 'software as a service', 'spatiotemporal', 'success', 'therapeutic development', 'trait', 'treatment response', 'user-friendly', 'vestibulo-ocular reflex', 'vigilance']",NIMH,"EYE-PREDICT, LLC",R43,2017,349999,0.032206968115067326
"Assessing psychosis-related deficits based on gaze behavior ﻿    DESCRIPTION (provided by applicant): Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, but rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance couple with biological validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis.         PUBLIC HEALTH RELEVANCE: Assessing psychosis-related deficits based on gaze behavior Existing tests of psychotic disorders are either functionally-informative or biologically-valid, bu rarely both. The ultimate project goal is to improve behavioral health and reduce societal costs by providing a battery of user-friendly tests that offer functional relevance coupled with biologicl validity. This project aims to establish the feasibility of using gaze measures as trait and state markers of psychosis.        ",Assessing psychosis-related deficits based on gaze behavior,9139172,R43MH111539,"['Academia', 'Attention', 'Basic Science', 'Behavior', 'Biological', 'Biology', 'Bipolar Disorder', 'Brain', 'Brain scan', 'Categories', 'Classification', 'Clinical', 'Cognitive', 'Computer software', 'Confidential Information', 'Coupled', 'Data', 'Data Files', 'Database Management Systems', 'Dimensions', 'Disease', 'Emotional', 'Evaluation', 'Exhibits', 'Foundations', 'Future', 'Goals', 'Government', 'Individual', 'Industry', 'Link', 'Machine Learning', 'Masks', 'Measures', 'Memory', 'Monitor', 'Monte Carlo Method', 'Moods', 'Morphologic artifacts', 'Motivation', 'Neurologic', 'Outcome', 'Perception', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Psychopathology', 'Psychotic Disorders', 'ROC Curve', 'Reporting', 'Research', 'Risk', 'Saccades', 'Scanning', 'Schizophrenia', 'Severities', 'Software Tools', 'Solid', 'Stimulus', 'Symptoms', 'Techniques', 'Testing', 'Thalamic structure', 'Translations', 'Unconscious State', 'Vendor', 'Work', 'Youth', 'base', 'behavioral health', 'case control', 'cingulate gyrus', 'clinical practice', 'cognitive testing', 'community setting', 'computerized data processing', 'cost', 'design', 'flexibility', 'frontal lobe', 'gaze', 'improved', 'indexing', 'innovation', 'proband', 'prototype', 'public health relevance', 'software as a service', 'spatiotemporal', 'success', 'therapeutic development', 'trait', 'treatment response', 'user-friendly', 'vestibulo-ocular reflex', 'vigilance']",NIMH,"EYE-PREDICT, LLC",R43,2016,349999,0.032206968115067326
"Neurosurgical Planning with Robust Eloquent area Delineation from Individualized Connectivity-based Techniques (NeuroPREDICT) Project Summary/Abstract  The idiosyncrasies of the human brain require that individualized mapping of functional regions be performed before surgical interventions for cancer or epilepsy. The success of this mapping procedure has direct effects on surgical outcomes and preserving cognitive and sensory function post-surgery. Current gold standard procedures for pre-surgical mapping are invasive, time-consuming, and technically demanding. Several non-invasive procedures have emerged in recent years; however, they have not yet displaced the gold standard procedures. Task-based functional magnetic resonance imaging (t-fMRI), the most widely used non-invasive pre-surgical mapping technique, requires that patients perform cognitive or motor tasks while in the scanner—a time-consuming and expensive procedure. Also, not all patients can perform fMRI tasks due to language barriers, sensory deficits, being unconscious, etc. Connectome Fingerprinting (CF) is a recently developed technique that uses machine learning to train a model capable of predicting functional brain activation from task-free resting-state fMRI (rs-fMRI). Once trained on a set of t-fMRI and rs- fMRI data, an unseen subject's unique pattern of brain activation can be predicted using only an rs-fMRI scan of their brain—therefore eliminating the need to perform tasks during the fMRI scan. Despite the promise of CF, the accuracy of the current best practice modeling techniques is not high enough yet to be clinically useful and studies applying CF have nearly always used healthy populations. Much research remains to be done to increase the accuracy of CF models before they can be deployed for pre-surgical mapping.  The long-term objective of the research proposed here is to develop a software application that combines applied machine learning with medical imaging to provide a non-invasive means for mapping the brains of neurosurgical patients before surgery. Importantly, we aim to increase the accuracy of CF modeling by expanding the modeling efforts to probabilistic Bayesian approaches that leverage prior information from the structure of the data. We will test a wide array of tunable data and model parameters to arrive at a current recommendation for best practices in CF research and applications. Finally, we will test our modeling procedures with a dataset of healthy control and pre-surgical patients diagnosed with brain tumors. We will test the software's ability to accurately predict functional brain organization in these patients and adaptively retrain the models to produce the most accurate results. This work has the potential to revolutionize pre-surgical brain mapping and expand its applicability to a greater number of patients. Project Narrative  In the United States, approximately 24,000 new cases of brain tumors are reported each year, with many patients requiring expensive pre-surgical planning and mapping of functional regions to minimize post-surgical impairments. In many neurosurgical practices [96% per 1], this involves performing a time-consuming and costly task-based fMRI acquisitions (nearly $1200/scan in 2014; [2]) before surgery to identify eloquent brain areas recruited for motor control, language, and cognition that must be spared during surgery. By combing task-based fMRI, resting-state fMRI and advanced machine learning to map the functional topology of the brain, the proposed technology will lower pre-surgical planning costs, reduce the burden on physicians and technicians, and expand pre-surgical mapping to previously excluded patients who cannot perform fMRI tasks.",Neurosurgical Planning with Robust Eloquent area Delineation from Individualized Connectivity-based Techniques (NeuroPREDICT),10139299,R43NS117226,"['Activities of Daily Living', 'Anatomy', 'Area', 'Bayesian Method', 'Blindness', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Cancer Intervention', 'Clinical', 'Cognition', 'Cognitive', 'Comb animal structure', 'Computer software', 'Conscious', 'Consumption', 'Cost Savings', 'Data', 'Data Set', 'Diagnosis', 'Engineering', 'Ensure', 'Epilepsy', 'Evaluation', 'Fingerprint', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Generations', 'Gold', 'Government', 'Health Care Costs', 'Healthcare Systems', 'Hospitals', 'Human', 'Impairment', 'Individual', 'Language', 'Learning', 'Linear Models', 'Machine Learning', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Motor', 'Neurologic', 'Neurosurgeon', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Performance', 'Persons', 'Phase', 'Physicians', 'Population', 'Preparation', 'Procedures', 'Recommendation', 'Reporting', 'Research', 'Rest', 'Scanning', 'Sensory', 'Software Engineering', 'Task Performances', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unconscious State', 'United States', 'Validation', 'Visual', 'Visual impairment', 'Woman', 'Work', 'anatomic imaging', 'base', 'cognitive task', 'compliance behavior', 'computerized data processing', 'connectome', 'cost', 'data acquisition', 'data quality', 'design', 'functional MRI scan', 'improved', 'individual variation', 'large scale data', 'motor control', 'multisensory', 'next generation', 'preservation', 'prototype', 'recruit', 'structured data', 'success', 'surgery outcome', 'usability']",NINDS,"CHARLES RIVER ANALYTICS, INC.",R43,2020,252569,0.017539695720764914
"Axonal connectomics: dense mapping of projection patterns between cortical areas Project Summary/Abstract Connectomics is a new field, created with the goal of densely or completely mapping the connections in the brain. Because this goal is at present only achievable for small organisms, connectomics has taken on two forms in the study of larger brains. Macroscale connectomics is used to describe the connections between brain areas, which in experimental animals is achieved with tracers, while humans it is typically pursued at a very coarse scale with diffusion imaging, a form of MRI. Microscale connectomics aims to create dense wiring diagrams of local circuits, small volumes of the brain with neurons that form rich networks within a local neighborhood. Macroscale connectomics lacks cellular resolution, while microscale connectomics can only reconstruct small volumes, with little information about the source of inputs entering the volume, or the targets of axons exiting it. We propose to develop a technique to bridge the gap between the microscale and the macroscale by creating experimental and analytical methods for mapping individual axons over long distances, concentrating on the largest 50% of myelinated axons (long-distance “wires”) in the brain. For the current RFA to develop “Tools to Facilitate High-Throughput Microconnectivity Analysis” we are specifically targeting one of the recommended goals, to “Develop a high-quality toolbox of methods for efficiently mapping and annotating projections” in the human brain. The method—based on high-resolution 3D imaging of antibody-stained axons—can be scaled to analyze entire brains, but here we propose to apply it to the posterior pole of a macaque brain, a large (~10 cm3) volume will contain >20 visual cortical areas. The goal is to trace most of the larger axons (>1 um) between these areas, thus creating a dense axonal connectomics data set from the cortical visual system, allowing us to examine not only the hierarchy of visual areas, but also the structure of computational maps. Ultimately, this approach will permit whole-brain analysis of axonal projections, with targeted examination of key circuits for microscale connectomics. While microscale connectomics of whole human brains will remain impossible for the foreseeable future, dense axonal mapping should be achievable in the next 5 to 10 years. This proposal offers a pathway towards this new type brain-wide anatomy: Axonal Connectomics. Project Narrative/Relevance This proposal will contribute to the fundamental question of how the brain is wired, in particular the pathways by which individual neurons communicate over long distances between different parts of the brain. One of the most promising treatments for a variety of brain disease—deep brain stimulation—is thought to work largely by activating these long distance “wires”, so a thorough understanding of their trajectories might have considerable long-term clinical importance.",Axonal connectomics: dense mapping of projection patterns between cortical areas,9822860,RF1MH117820,"['3-Dimensional', 'Anatomy', 'Animals', 'Antibodies', 'Area', 'Atlases', 'Automation', 'Axon', 'Big Data', 'Brain', 'Brain Diseases', 'Caliber', 'Cerebral cortex', 'Clinical', 'Data', 'Data Collection', 'Data Set', 'Deep Brain Stimulation', 'Diffusion', 'Electron Microscopy', 'Future', 'Goals', 'Human', 'Image', 'Individual', 'Informatics', 'Infrastructure', 'Judgment', 'Label', 'Laboratories', 'Lesion', 'Light', 'Lighting', 'Link', 'Macaca', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Methods', 'Microscopic', 'Microscopy', 'Mus', 'Neighborhoods', 'Neuroanatomy', 'Neurons', 'Neurosciences', 'Occipital lobe', 'Organism', 'Paper', 'Parietal Lobe', 'Pathway interactions', 'Pattern', 'Perception', 'Primates', 'Protocols documentation', 'Resolution', 'Site', 'Source', 'Speed', 'Stains', 'Structure', 'Techniques', 'Temporal Lobe', 'Three-Dimensional Imaging', 'Time', 'Tissues', 'Tracer', 'Visual Cortex', 'Visual system structure', 'Work', 'analytical method', 'base', 'brain volume', 'computerized tools', 'connectome', 'connectome data', 'extrastriate visual cortex', 'gray matter', 'imaging approach', 'light microscopy', 'neurofilament protein H', 'nonhuman primate', 'petabyte', 'physical mapping', 'programs', 'tissue processing', 'tool', 'vector', 'white matter']",NIMH,ALLEN INSTITUTE,RF1,2019,2312287,-0.01958616780191108
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9616870,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'cost', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'novel sequencing technology', 'phenotypic data', 'pleiotropism', 'population stratification', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2019,297373,0.019671316020769648
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9405576,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'cost', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'novel sequencing technology', 'phenotypic data', 'pleiotropism', 'population stratification', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2018,297619,0.019671316020769648
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3). PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9207474,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Categories', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Statistical Methods', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'cost', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'high dimensionality', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'phenotypic data', 'pleiotropism', 'population stratification', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2017,297842,0.019671316020769648
"Statistical Tests for Mapping Genetic Determinants of Complex Traits ﻿    DESCRIPTION (provided by applicant): Genotyping and emerging sequencing technologies have enabled comprehensive interrogation of genetic variation across the human genome, thereby facilitating a study's ability to map genetic variants that influence phenotypes of interes. Nevertheless, genome-wide association studies (GWAS) and next-generation sequencing (NGS) projects have uncovered only a limited number of trait-influencing loci. While large increases in sample size will improve power to detect such variation, the ascertainment and sequencing/genotyping of such samples are costly and inefficient. Therefore, it is desirable to increase power to detect such variants without requiring additional sample collection. We propose novel methods for improved gene mapping of common and rare susceptibility variants that move beyond standard strategies typically applied to GWAS and NGS studies of complex traits. The first topic we consider is pleiotropic or cross- phenotype effects of genetic variants. Empirical studies have suggested that pleiotropy is widespread throughout the genome and that leveraging this additional information for gene mapping yields a more powerful analysis than an analysis that ignores such information. In Aim 1, we propose novel statistical methods for genetic analysis of high-dimensional phenotype data using an innovative kernel distance-covariance (KDC) framework that allows for an arbitrary number of phenotypes both continuous and/or categorical in nature, as well as an arbitrary number of genotypes (permitting gene-based testing of both rare and common variants). We will use the KDC framework to implement tests of pleiotropy as well as tests of mediation. The second topic we consider is the mapping of rare susceptibility variants using affected pedigrees, which provide many attractive features for rare-variant testing that case-control studies lack. In Aim 2, we propose a series of powerful statistical methods for rare-variant association testing in affected pedigrees that are based on a framework (recently published in AJHG) for rare-variant association testing in affected sibships. The existing framework compares rare-variant burden in a region by an affected sib pair to the number of regions that pairs shares identical by descent. We have shown the method is more powerful than case-control association testing given fixed sample size and further is robust to population stratification. In this proposal, we will extend the framework to handle affected pedigrees of arbitrary size and structure (rather than just affected sib pairs) and devise a powerful two-stage screening and validation strategy for rare-variant mapping that first compares familial cases in the pedigrees to external controls and then follows up the most interesting findings using an independent test based on our identity-by-descent sharing statistic among the affected relatives used in the first stage. We will apply the methods in Aims 1-2 to relevant data from genetic studies of complex traits in which we are directly involved. We also will implement the methods in public user-friendly software (Aim 3).         PUBLIC HEALTH RELEVANCE: The goal of this project is to develop a set of statistical approaches to investigate two important topics in gene- mapping studies of complex human traits. First, we will develop techniques for identifying genes that have pleiotropic effects on phenotypes of possibly high dimension and further assess whether such genes have direct effects on such phenotypes or indirect effects through other possible factors. Second, we will develop tools to facilitate identification of rare polymorphic variation that increase risk for complex disease using data from affected pedigrees of arbitrary size and structure. We will evaluate these methods using simulated data and illustrate their value by applying them to genetic projects of complex traits in which we are actively involved. Application of the proposed methods to these datasets should improve our understanding of the genetic origins of various complex traits.                ",Statistical Tests for Mapping Genetic Determinants of Complex Traits,9055844,R01GM117946,"['Affect', 'Applied Genetics', 'Case-Control Studies', 'Chromosome Mapping', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dimensions', 'Disease', 'Family', 'Genes', 'Genetic', 'Genetic Determinism', 'Genetic Variation', 'Genetic screening method', 'Genetic study', 'Genets', 'Genome', 'Genotype', 'Goals', 'Human', 'Human Genome', 'Investigation', 'Joints', 'Machine Learning', 'Maps', 'Mediation', 'Methods', 'Modeling', 'Molecular', 'Nature', 'Phenotype', 'Population', 'Procedures', 'Public Health', 'Publishing', 'Risk', 'Sample Size', 'Sampling', 'Series', 'Siblings', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Staging', 'Statistical Methods', 'Stratification', 'Structure', 'Susceptibility Gene', 'Techniques', 'Technology', 'Testing', 'Validation', 'Variant', 'Work', 'base', 'case control', 'design', 'flexibility', 'genetic analysis', 'genetic association', 'genetic pedigree', 'genetic variant', 'genome wide association study', 'genome-wide', 'genome-wide analysis', 'human disease', 'identity by descent', 'improved', 'innovation', 'interest', 'next generation sequencing', 'novel', 'pleiotropism', 'public health relevance', 'rare variant', 'risk variant', 'sample collection', 'screening', 'statistics', 'tool', 'trait', 'user friendly software']",NIGMS,EMORY UNIVERSITY,R01,2016,309883,0.019671316020769648
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9750722,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'predictive modeling', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2019,527585,0.08351747788690966
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9530668,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'predictive modeling', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2018,584485,0.08351747788690966
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9355693,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Disease model', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Mathematics', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Taxonomy', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'experimental study', 'improved', 'infancy', 'insight', 'network models', 'novel', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2017,406785,0.08351747788690966
"Transmission Networks in Trait-Based Communities The complexity of ecological communities creates challenges to understanding multi-host parasite transmission. Pronounced heterogeneity in transmission among individuals, species and across space is the rule rather than the exception. Community ecologists are beginning to make great strides in predicting multi-species interactions using a trait-based rather than taxonomic approach, identifying key functional attributes of organisms and environments that are important to understanding the system. At the same time, disease ecologists generally use network modeling to understand parasite transmission in complex communities. Yet the merging of a trait-based approach with network modeling to understand multi-host transmission across space and time is in its infancy. We will take advantage of a highly tractable system - diverse communities of bees that transmit parasites via networks of flowering plants - to merge trait-based theory with network modeling, introducing a novel theoretical framework for multi-host parasite transmission in complex communities. We will collect empirical contact pattern and trait data from plant-pollinator networks to identify aspects of network structure that contribute to disease spread. Through the collection of extensive data on bee traits, floral traits and parasite spread, we will use machine learning techniques to construct and parameterize trait-based models of disease transmission in order to make falsifiable predictions for further testing. We will then test model predictions via whole-community manipulations of bees, parasites and plants in mesocosms. Such whole-community manipulations will offer unparalleled insight into the specific network patterns and traits that shape transmission in multi-host communities. Pollinators serve a critical role in our native ecosystems as well as agricultural crops, providing billions of dollars in pollination services annually. Recently, parasites have been linked to declines of several pollinator species. Thus, a better understanding of parasite transmission among bees has important conservation and economic implications.",Transmission Networks in Trait-Based Communities,9241579,R01GM122062,"['Address', 'Agricultural Crops', 'Angiosperms', 'Bees', 'Collection', 'Communities', 'Complex', 'Coupling', 'Data', 'Disease', 'Disease Vectors', 'Ecosystem', 'Environment', 'Epidemiology', 'Flowers', 'Goals', 'Heterogeneity', 'Individual', 'Infection', 'Knowledge', 'Link', 'Machine Learning', 'Modeling', 'Observational Study', 'Organism', 'Parasites', 'Pattern', 'Plants', 'Population', 'Prevalence', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Sampling', 'Services', 'Shapes', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'disease transmission', 'economic implication', 'improved', 'infancy', 'insight', 'model building', 'network models', 'novel', 'research study', 'theories', 'tool', 'trait', 'transmission process', 'vector']",NIGMS,CORNELL UNIVERSITY,R01,2016,409580,0.08351747788690966
"Clinical resting state fMRI software for surgical planning Abstract Classically, anatomic information provided by MRI has been essential to the neurosurgeon to maximize extent of tumor resection and, as a result, improve survival statistics. That said, it is not routine during resections to make use of similar imaging information that reflect the functional organization of the brain. Task-based fMRI has been employed as a means of pre-operatively localizing function. However, task-based fMRI depends on the patient’s ability to comply with the task paradigm, which frequently is lacking. This problem can be overcome by using the recently developed method of resting state functional magnetic resonance imaging (rsfMRI) to localize function. Moreover, rsfMRI is highly efficient, as multiple resting state networks (RSNs) associated with multiple cognitive domains can be mapped at the same time. With this in mind, the long-term goal of our research is to improve survival and quality of life after surgical resection of brain tumors by improving the identification/preservation of eloquent cortex. The current barrier that prevents the widespread use of rsfMRI is 1) the high degree of advanced imaging expertise currently necessary to create and interpret the images and 2) the necessary IT infrastructure necessary to support the analyses. To address this shortcoming, we propose to create a turnkey system for functional mapping within the brain that resides on a cloud-computing platform. At the heart of our methodology is a multi-layer perceptron (MLP) algorithm that assigns RSN membership to each locus within the brain using supervised classification of rsfMRI data. Current data demonstrate that MLP-based RSN mapping is more reliable than conventional task-based fMRI and is extremely sensitive to sites identified by cortical stimulation (the standard in intraoperative mapping). Translation of the science and techniques created at Washington University will be accomplished by a deep collaboration with Radiologics, an emerging company with strong expertise in cloud computing for clinical imaging. Towards this end, the overall objective of the proposed project is to create an imaging technology package, named Cirrus, that will integrate automatic MLP-based RSN mapping with cloud-based computing. The Specific Aims of this proposal are to 1) Create Cloud-Based rsfMRI Brain Mapping Capability - Cirrus, 2) Deploy Cloud-Based rsfMRI Capability (Cirrus Platform) to New User Host Institutions, and 3) Optimize the Clinical User Interface (UI) of Cirrus. The expected outcome of this translational strategy will be an integrated imaging/surgical presurgical mapping technology using rsfMRI with clearly defined performance capabilities, well delineated localization outputs, and a clinician friendly user experience that scales to all types of health care settings. Thus, this proposal is innovative because there currently does not exist any comparable system that integrates cutting edge image analysis tools with cloud-based capabilities. This work is significant because it will disseminate technology that fundamentally enhances the surgeon’s understanding of the functional implications of their surgical strategy, thereby enables safer, more tailored approaches to improving outcomes. Project Narrative The proposed research is an academic industry partnership that will make available, to any neurosurgical practice advanced functional MRI methodology to define critical regions in the brain. This development is relevant to public health because it has the potential to improve functional outcomes following surgical removal of brain tumors. Towards this end, we propose to create an imaging technology package that will integrate 1) advanced machine learning techniques using resting state functional magnetic resonance imaging, and 2) cloud-based computing, to perform advanced brain mapping. Thus, advanced functional localization can be standardized and acquired at any institution by being uniformly processed in the cloud and sent back to the home institution without the need for costly infrastructure. The integrated package will enable clinicians in any practice environment to efficiently and reliably visualize function on the brain’s anatomy prior to surgery.",Clinical resting state fMRI software for surgical planning,9409171,R44GM125438,"['Address', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Back', 'Biological Preservation', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Child', 'Classification', 'Clinical', 'Cloud Computing', 'Cognitive', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Environment', 'Excision', 'Failure', 'Functional Magnetic Resonance Imaging', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Home environment', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Institution', 'Intuition', 'Language', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Glioma', 'Maps', 'Methodology', 'Methods', 'Mind', 'Names', 'Network-based', 'Neural Network Simulation', 'Neurosurgeon', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Population', 'Process', 'Public Health', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Rest', 'Scanning', 'Science', 'Site', 'Standardization', 'Stress Tests', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training Activity', 'Translating', 'Translations', 'Universities', 'Washington', 'Work', 'base', 'brain tumor resection', 'clinical imaging', 'cloud based', 'computing resources', 'cost', 'experience', 'flexibility', 'functional outcomes', 'functional status', 'imaging capabilities', 'imaging software', 'improved', 'improved outcome', 'industry partner', 'innovation', 'patient population', 'personalized approach', 'prevent', 'statistics', 'tool', 'translational approach', 'tumor', 'user-friendly']",NIGMS,"RADIOLOGICS, INC.",R44,2017,749900,-0.001305693014965868
"Clinical resting state fMRI software for surgical planning Abstract Classically, anatomic information provided by MRI has been essential to the neurosurgeon to maximize extent of tumor resection and, as a result, improve survival statistics. That said, it is not routine during resections to make use of similar imaging information that reflect the functional organization of the brain. Task-based fMRI has been employed as a means of pre-operatively localizing function. However, task-based fMRI depends on the patient’s ability to comply with the task paradigm, which frequently is lacking. This problem can be overcome by using the recently developed method of resting state functional magnetic resonance imaging (rsfMRI) to localize function. Moreover, rsfMRI is highly efficient, as multiple resting state networks (RSNs) associated with multiple cognitive domains can be mapped at the same time. With this in mind, the long-term goal of our research is to improve survival and quality of life after surgical resection of brain tumors by improving the identification/preservation of eloquent cortex. The current barrier that prevents the widespread use of rsfMRI is 1) the high degree of advanced imaging expertise currently necessary to create and interpret the images and 2) the necessary IT infrastructure necessary to support the analyses. To address this shortcoming, we propose to create a turnkey system for functional mapping within the brain that resides on a cloud-computing platform. At the heart of our methodology is a multi-layer perceptron (MLP) algorithm that assigns RSN membership to each locus within the brain using supervised classification of rsfMRI data. Current data demonstrate that MLP-based RSN mapping is more reliable than conventional task-based fMRI and is extremely sensitive to sites identified by cortical stimulation (the standard in intraoperative mapping). Translation of the science and techniques created at Washington University will be accomplished by a deep collaboration with Radiologics, an emerging company with strong expertise in cloud computing for clinical imaging. Towards this end, the overall objective of the proposed project is to create an imaging technology package, named Cirrus, that will integrate automatic MLP-based RSN mapping with cloud-based computing. The Specific Aims of this proposal are to 1) Create Cloud-Based rsfMRI Brain Mapping Capability - Cirrus, 2) Deploy Cloud-Based rsfMRI Capability (Cirrus Platform) to New User Host Institutions, and 3) Optimize the Clinical User Interface (UI) of Cirrus. The expected outcome of this translational strategy will be an integrated imaging/surgical presurgical mapping technology using rsfMRI with clearly defined performance capabilities, well delineated localization outputs, and a clinician friendly user experience that scales to all types of health care settings. Thus, this proposal is innovative because there currently does not exist any comparable system that integrates cutting edge image analysis tools with cloud-based capabilities. This work is significant because it will disseminate technology that fundamentally enhances the surgeon’s understanding of the functional implications of their surgical strategy, thereby enables safer, more tailored approaches to improving outcomes. Project Narrative The proposed research is an academic industry partnership that will make available, to any neurosurgical practice advanced functional MRI methodology to define critical regions in the brain. This development is relevant to public health because it has the potential to improve functional outcomes following surgical removal of brain tumors. Towards this end, we propose to create an imaging technology package that will integrate 1) advanced machine learning techniques using resting state functional magnetic resonance imaging, and 2) cloud-based computing, to perform advanced brain mapping. Thus, advanced functional localization can be standardized and acquired at any institution by being uniformly processed in the cloud and sent back to the home institution without the need for costly infrastructure. The integrated package will enable clinicians in any practice environment to efficiently and reliably visualize function on the brain’s anatomy prior to surgery.",Clinical resting state fMRI software for surgical planning,9552903,R44GM125438,"['Address', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Back', 'Brain', 'Brain Mapping', 'Brain Neoplasms', 'Child', 'Classification', 'Clinical', 'Cloud Computing', 'Cognitive', 'Collaborations', 'Computer software', 'Data', 'Data Set', 'Development', 'Ensure', 'Environment', 'Excision', 'Failure', 'Functional Magnetic Resonance Imaging', 'Goals', 'Gold', 'Healthcare', 'Heart', 'Home environment', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Institution', 'Intuition', 'Language', 'Lesion', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Glioma', 'Maps', 'Methodology', 'Methods', 'Mind', 'Names', 'Network-based', 'Neural Network Simulation', 'Neurosurgeon', 'Operative Surgical Procedures', 'Outcome', 'Output', 'Patients', 'Performance', 'Picture Archiving and Communication System', 'Population', 'Process', 'Public Health', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Rest', 'Science', 'Site', 'Standardization', 'Stress Tests', 'Supervision', 'Surgeon', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training Activity', 'Translating', 'Translations', 'Universities', 'Washington', 'Work', 'base', 'brain tumor resection', 'clinical imaging', 'cloud based', 'computing resources', 'cost', 'experience', 'flexibility', 'functional outcomes', 'functional status', 'health care settings', 'imaging capabilities', 'imaging software', 'improved', 'improved outcome', 'industry partner', 'innovation', 'patient population', 'personalized approach', 'preservation', 'prevent', 'statistics', 'tool', 'translational approach', 'tumor', 'user-friendly']",NIGMS,"RADIOLOGICS, INC.",R44,2018,740001,-0.001305693014965868
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efficiently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be infinitely replicated. Their combination, the multiparental genetic reference population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, flies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions considered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and find variance-controlling genes; and more rigorous and expansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered include: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only fill significant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9893003,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'causal variant', 'computerized tools', 'design', 'fly', 'human disease', 'human model', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2020,336445,0.05741482669846621
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efficiently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be infinitely replicated. Their combination, the multiparental genetic reference population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, flies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions considered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and find variance-controlling genes; and more rigorous and expansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered include: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only fill significant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientific output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9672510,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'causal variant', 'computerized tools', 'design', 'fly', 'human disease', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2019,336445,0.05741482669846621
"Statistical Modeling of Multiparental and Genetic Reference Populations PROJECT SUMMARY / ABSTRACT Genetic crosses in model organisms play an essential role in understanding how heritable factors affect medically relevant traits. Such crosses have traditionally tended to be on a small scale with limited power to detect genetic effects, limited ability to localize causal variants, and limited options for replication. In the last decade, however, the emergence of larger-scale interdisciplinary research, cheaper genotyping and parallel advances in human genetics, has spurred the development of more sophisticated and powerful experimental designs. Foremost are those that incorporate two modern genetic design concepts: the multiparental population (MPP), whereby each subject is descended from a small, well-characterized set of genetically diverse inbred strains, with the goal of efﬁciently exploring a wide genetic landscape; and the genetic reference population (GRP), whereby subjects are drawn from a large and genetically diverse set of inbred strains, with the goal that the study population, and thereby the studies themselves, can be inﬁnitely replicated. Their combination, the multiparental genetic refer- ence population (MP-GRP), represents the state-of-the-art in complex trait genetics and has been implemented in a number of model organisms, including plants, ﬂies, and rodents.  The proposed program of research focuses on the development of statistical and computational tools to advance the design and analysis of studies using MPPs, GRPs and MP-GRPs. It centers around addressing three interconnected questions.  1) How to take advantage of biological replicates in a genetically varying population? Directions consid- ered include: more stable methods to detect genetically-induced phenotypic outliers; use of genetically-induced heteroskedasticity to improve statistical power and ﬁnd variance-controlling genes; and more rigorous and ex- pansive characterization of gene-by-treatment effects by using principles from causal inference.  2) How to navigate the complex design space of MP-GRPs and their derived crosses? Directions considered include: use of decision theory applied to Bayesian analysis of pilot data; incorporation of variance heterogeneity to control likely reproducibility.  3) How to approach quantitative trait locus (QTL) analysis in MPPs and MP-GRPs? Directions considered in- clude: making haplotype-based association more robust to uncertainty in haplotype state; combining haplotype- based with variant-based mapping; adaptive modeling of QTL complexity; machine learning of the allelic series; familywise error rate control through descent-based permutation.  Progress on these fronts will not only ﬁll signiﬁcant gaps in studies using MPPs, GRPs and MP-GRPs, but will also provide tools and insights that will allow these designs to be used in new and more powerful ways. PROJECT NARRATIVE (RELEVANCE) The proposed research will lead to improvements in the analysis and design of genetic studies on experimental models of human disease. Because the project focuses on statistical methodology applied to experimental model organism populations (including mouse, rats and Drosophila) the scientiﬁc output of the project is expected to be applicable to basic research focusing on any medical condition that can be studied in model organisms.",Statistical Modeling of Multiparental and Genetic Reference Populations,9485688,R35GM127000,"['Address', 'Affect', 'Alleles', 'Animal Model', 'Basic Science', 'Bayesian Analysis', 'Biological', 'Complex', 'Complex Genetic Trait', 'Data', 'Decision Theory', 'Development', 'Drosophila genus', 'Experimental Designs', 'Experimental Models', 'Genes', 'Genetic', 'Genetic Crosses', 'Genetic study', 'Genotype', 'Goals', 'Haplotypes', 'Heritability', 'Heterogeneity', 'Human Genetics', 'Inbred Strain', 'Interdisciplinary Study', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Mus', 'Output', 'Phenotype', 'Plants', 'Play', 'Population', 'Population Genetics', 'Quantitative Trait Loci', 'Rattus', 'Reproducibility', 'Research', 'Rodent', 'Role', 'Series', 'Statistical Models', 'Uncertainty', 'Variant', 'base', 'computerized tools', 'design', 'human disease', 'improved', 'insight', 'programs', 'study population', 'tool', 'trait', 'treatment effect']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R35,2018,336445,0.05741482669846621
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9763572,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Quantitative Trait Loci', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,396000,0.027480727643391146
"Joint Analysis of Microbiome and Other Genomic Data Types PROJECT SUMMARY In the same way that the human genome project created invaluable genomic maps, the objective of this project is to develop methods for eventual construction of comprehensive genetic and metabolomic by microbome relationship maps. Such maps would be an invaluable resource for improving our understanding as to the underlying mechanisms by which microbes and –omics features influence human diseases and conditions, potentially leading to identification of novel therapeutic targets. To these ends, this proposal seeks to develop statistical and computational tools for mapping associations and interactions between microbes and other – omic features and for further utilizing other –omics to improve microbiome based prediction models. Specifically, motivated by studies examining the role of the vaginal microbiome and other –omics in birth outcomes and menopause, we aim to develop statistical methodology for (1) mapping genetic variants that influence microbiome composition so as to understand the innate component of the microbiome as well as learn mechanisms by which genetics influence outcomes; (2) creating global metabolic maps integrating both microbes and metabolites which will enable understanding of how perturbations might influence the system and identify key pathways for therapeutic target; (3) exploiting other –omics in constructing more accurate microbiome based prediction models for preterm birth; (4) developing, distributing and supporting software packages for the proposed methods. The methods are based on frameworks in which we have considerable experience, but novel technical contributions are made to accommodate features of the data such as population stratification and relatedness in genetics, phylogenetic structure, and compositionality, as well as practical considerations such as availability of samples and other –omics data. Consequently, these new methods have the potential for accelerating mechanistic and translational microbiome studies, developing vital resources for enabling systematic achievement of many biological, clinical, and public health problems that have eluded researchers for decades. PROJECT NARRATIVE The methods developed in this proposal will enable improved understanding of the interactions between microbes and other –omics, thus aiding in elucidation of the mechanisms by which microbes and –omic features influence health outcomes and aiding in identification of potential molecular targets. Further emphasis is placed on utilization of other –omics to develop microbiome based prediction models in pregnancy outcomes, improving early detection of women who are at risk of preterm delivery.",Joint Analysis of Microbiome and Other Genomic Data Types,9577818,R01GM129512,"['Achievement', 'Address', 'Area', 'Automobile Driving', 'Biological', 'Birth', 'Chromosome Mapping', 'Clinical', 'Complex', 'Computer software', 'Data', 'Data Set', 'Development', 'Early Diagnosis', 'Future', 'Genes', 'Genetic', 'Genomics', 'Grouping', 'Health', 'Human Genome Project', 'Joints', 'Lasso', 'Learning', 'Machine Learning', 'Maintenance', 'Maps', 'Medical', 'Menopause', 'Metabolic', 'Methodology', 'Methods', 'Microbe', 'Modeling', 'Modification', 'Molecular Target', 'Network-based', 'Outcome', 'Pathway interactions', 'Performance', 'Phylogenetic Analysis', 'Pregnancy Outcome', 'Premature Birth', 'Procedures', 'Public Health', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'Sampling', 'Scientific Advances and Accomplishments', 'Structure', 'System', 'Taxonomy', 'Training', 'Woman', 'Work', 'base', 'biological systems', 'computerized tools', 'experience', 'genetic variant', 'genomic data', 'human disease', 'improved', 'interest', 'loss of function', 'metabolomics', 'microbial', 'microbial community', 'microbiome', 'microbiome analysis', 'microbiome components', 'microbiome composition', 'microbiome research', 'new therapeutic target', 'novel', 'open source', 'population stratification', 'predictive modeling', 'simulation', 'software development', 'therapeutic target', 'tool', 'translational study', 'user friendly software', 'vaginal microbiome']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2018,396000,0.027480727643391146
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9936138,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,617708,-0.046115412745279215
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9703885,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,625626,-0.046115412745279215
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9501686,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,633392,-0.046115412745279215
"Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1 Project Summary HIV-1 poses a substantial health and economic burden, with more than 30 million people currently infected worldwide. The search for an effective HIV-1 vaccine remains a top priority, and a deeper understanding of how the immune system recognizes HIV-1 can help inform vaccine design. Lately, much effort has focused on understanding the antibody responses to HIV-1 infection. However, the polyclonal neutralizing antibody responses in an individual are very complex. Standard methods for mapping such responses include various experimental techniques, but more recently, computational methods were also developed. These computational methods, which we call NFP (neutralization fingerprinting), are based on analysis of serum neutralization data that is typically obtained in the very first stages of donor sample characterization, and are therefore an efficient technology for accurately mapping antibody specificities in polyclonal responses. The NFP algorithms have already become an important tool in the HIV field and are being used extensively by laboratories throughout the world, including Duke CHAVI-ID, CAPRISA, NIH VRC, and MHRP.  Here, we propose to develop next-generation NFP algorithms and apply them to address biological questions with important implications for understanding the interactions between HIV-neutralizing antibodies and the virus. Specifically, we will develop and apply novel algorithms for: (1) Antibody specificity prediction with significantly improved accuracy and reliability. These algorithms will immensely improve the utility of the NFP approach for prospective identification of antibody specificities in polyclonal sera. (2) Mapping broadly neutralizing antibody responses against novel epitopes on HIV-1 Env. We will use epitope- structural analysis and computational search algorithms to identify novel Env epitopes, and will screen donor samples for the presence of related NFP signals. Promising signals for novel antibody specificities will be characterized further through collaborations. (3) Population-level analysis of broadly neutralizing antibody responses to HIV-1. We will analyze large collections of samples from diverse HIV infection cohorts in order to determine common antibody specificities elicited in response to HIV-1, as well as patterns of potential association between features of the infecting virus sequence and the elicited epitope specificities.  The proposed NFP algorithms will be made available to the public, and will be useful in a number of high-impact areas in the HIV field, including mapping of antibody specificities in previously uncharacterized samples, identification of novel Env epitopes, and large-scale analysis of broadly neutralizing antibody responses within a cohort, or at a population level. Overall, this work will lead to a better understanding of the neutralizing antibody responses against HIV-1 and will build a more complete picture of the epitopes on Env. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health. Project Narrative  This project aims at developing next-generation neutralization fingerprinting algorithms for the analysis of antibody specificities in polyclonal responses against HIV-1. Overall, this work will build a more complete picture of the broadly neutralizing antibody epitopes on Env, and will lead to a better understanding of the antibody responses against HIV-1 both at the individual and population levels. The proposed algorithmic framework should be generalizable to other important viruses, such as influenza and hepatitis C, and therefore has the potential for a far-reaching impact on public health.",Neutralization Fingerprinting Analysis of Polyclonal Antibody Responses against HIV-1,9407909,R01AI131722,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Antibodies', 'Antibody Response', 'Antibody Specificity', 'Antigens', 'Area', 'Binding', 'Biological', 'Characteristics', 'Collaborations', 'Collection', 'Complex', 'Computer Analysis', 'Computing Methodologies', 'Data', 'Derivation procedure', 'Development', 'Donor Selection', 'Economic Burden', 'Epitope Mapping', 'Epitopes', 'Fingerprint', 'Generations', 'Genetic', 'Goals', 'HIV', 'HIV Infections', 'HIV-1', 'HIV-1 vaccine', 'Hepatitis C', 'Immune system', 'Individual', 'Infection', 'Influenza C Virus', 'Knock-out', 'Laboratories', 'Least-Squares Analysis', 'Letters', 'Machine Learning', 'Methods', 'Monoclonal Antibodies', 'Mutation', 'Pattern', 'Phenotype', 'Population', 'Public Health', 'Sampling', 'Serum', 'Signal Transduction', 'Specificity', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Vaccine Design', 'Validation', 'Variant', 'Virus', 'Work', 'base', 'cohort', 'health economics', 'improved', 'neutralizing antibody', 'next generation', 'novel', 'polyclonal antibody', 'prospective', 'response', 'sample collection', 'tool']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2017,650713,-0.046115412745279215
"Software for Antibody Epitope Prediction Accurate epitope prediction is important for the development of antibody-based therapies. When multiple new antibodies are discovered against the whole antigen, their epitopes and, therefore, potential novelty and mechanism of action are usually unknown Site-directed mutagenesis, the routine method for epitope mapping, requires testing a large number of mutants since any part of the antigen can potentially form an epitope The goal of this proposal is developing methodology and software for the accurate computational prediction of discontinuous B-cell epitopes based on the structure of an antigen and the structure or sequence of an antibody. Our starting point is PIPER, a protein-protein docking program licensed by Acpharis from Boston University. PIPER is the docking engine in the software packages BioLuminate by Schrodinger and the CyrusBench Suite of Cyrus Biotechnology, as well as in the public server ClusPro. PIPER has a special option for antibody-antigen docking, and has been used for epitope prediction. However, in its present form the software generally results in a high number of putative epitopes, and more accurate prediction requires substantial experimental efforts, e.g., by site-directed mutagenesis. We will modify PIPER to maximize the information available from the docking by generating a large ensemble of low energy docked structures and calculating a contact map rather than discrete docked structures. The number of potential epitopes will be further reduced by a template-based approach based on vector contact maps to characterize antibody-antigen interfaces. We also explore predicting the epitope based on models of the CDR regions. Generating large ensembles of docked structures with a large variety of CDR conformations will reduce the sensitivity of the method to inevitable modeling and docking uncertainty. By increasing the reliability of the predicted epitopes, we expect to reduce or even to eliminate the need for mutagenesis experiments. Finally, we will develop a machine- learning algorithm for the mapping of amino acid composition of CDR regions into epitope composition, a method that can be used when only the antibody sequence available and structure prediction is uncertain due to the lack of suitable templates. When multiple new antibodies are discovered against a whole antigen, their epitopes and, therefore, potential novelty and mechanism of action are usually unknown. Computational software tools can significantly reduce experimental efforts required for epitope determination by guiding experimental efforts toward most probable epitope locations. We propose new computational capabilities based on protein-protein docking and machine learning, which are specifically designed to improve the accuracy of epitope prediction.",Software for Antibody Epitope Prediction,9845171,R43GM134769,"['Address', 'Amino Acid Sequence', 'Amino Acids', 'Antibodies', 'Antibody Binding Sites', 'Antibody Therapy', 'Antigen-Antibody Complex', 'Antigens', 'B-Lymphocyte Epitopes', 'Base Sequence', 'Biotechnology', 'Boston', 'Collection', 'Computer software', 'Consensus', 'Crystallization', 'Data', 'Data Set', 'Databases', 'Development', 'Docking', 'Epitope Mapping', 'Epitopes', 'Goals', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Mutagenesis', 'Probability', 'Property', 'Proteins', 'Scheme', 'Site-Directed Mutagenesis', 'Software Tools', 'Specific qualifier value', 'Structure', 'Surface Antigens', 'Techniques', 'Testing', 'Training', 'Uncertainty', 'Universities', 'Vertebral column', 'artificial neural network', 'base', 'design', 'experimental study', 'improved', 'machine learning algorithm', 'mutant', 'programs', 'relating to nervous system', 'vector']",NIGMS,"ACPHARIS, INC.",R43,2019,149999,0.060766215970403055
"Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry PROJECT SUMMARY Determination of the molecular structures of B cell epitopes recognized by protective antibodies provides essential insights to guide rational vaccine design. Obtaining atomically-resolved maps that comprehensively cover the surface of the antigen represents an ideal goal that would provide invaluable information to guide vaccine development. While X-ray crystallography can provide atomically-resolved maps of epitopes, at the present time, it does not have sufficient throughput for deep analysis of the diversity of the antibody repertoire. Hydrogen exchange-mass spectrometry (HX-MS) is emerging as an effective tool for epitope mapping. While promising, the method is limited both by data analysis bottlenecks and limited spatial resolution that prevent it from achieving its full potential for high resolution, high throughput epitope mapping. This collaborative research between Dr. David Weis and Dr. Jeffrey Gray brings together their complementary expertise in HX-MS and protein modelling to produce new software tools to improve the accuracy, resolution, and throughput of HX-MS-based epitope mapping. The outcome will enable epitope-mapping pipelines capable of generating 10-20 atomically-resolved epitopes per week, allowing researchers to more fully define the repertoire of antibody responses to infectious agents and toxins. This research is significant because it will yield new tools to accelerate the rational design and testing of much-needed vaccines to counteract emerging infectious diseases and biothreat agents within NIAID's portfolio. The specific aims of this proposal are to develop new algorithms and software for (1) rapid, fully-automated processing of HX-MS data, (2) fully-automated classification of HX-MS results, and (3) obtaining atomically- resolved epitopes from HX-MS data. The product of the proposed research will be new software tools that implement innovative algorithms. To accomplish Aim #1, algorithms that treat HX-MS data as two-dimensional images and adapt image comparison algorithms to identify and extract the shifted mass spectra will be developed. To accomplish Aim #2, significance testing based on the volcano plot method and classify the results using k-means clustering will be used. To accomplish Aim #3, medium-resolution HX-MS-mapped epitope will be used to constrain computational protein docking between the solved antigen structure and the modeled antibody using the Rosetta protein modeling suite. Through an existing collaboration with Dr. Nicholas Mantis sponsored by NIAID, the team has access to VHHs and an expanding library of solved structures of these VHHs bound to ricin toxin. The solved structures present a unique opportunity to independently refine and validate the epitope mapping pipeline based on solved structures. PROJECT NARRATIVE Vaccines stimulate the immune system to produce antibodies that recognize specific regions called epitopes on bacteria, viruses, and toxins. Information about the molecular structures of these epitopes can provide useful guidance to the development of new vaccines. The proposed research is relevant to public health because it is expected to contribute new tools to determine epitope structures more quickly.",Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry,9610636,R21AI135701,"['Algorithmic Software', 'Algorithms', 'Amino Acids', 'Antibodies', 'Antibody Diversity', 'Antibody Repertoire', 'Antibody Response', 'Antigens', 'Area', 'B-Lymphocyte Epitopes', 'Bacteria', 'Basic Science', 'Benchmarking', 'Binding', 'Chemistry', 'Classification', 'Collaborations', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic Reagent', 'Distal', 'Docking', 'Emerging Communicable Diseases', 'Engineering', 'Epitope Mapping', 'Epitopes', 'Glycoproteins', 'Goals', 'Human Resources', 'Hydrogen', 'Image', 'Immune system', 'Immunology', 'Individual', 'Infectious Agent', 'Informatics', 'Length', 'Letters', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Structure', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Outcomes Research', 'Peptoids', 'Performance', 'Pharmacologic Substance', 'Proteins', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Ricin', 'Site', 'Software Tools', 'Structural Models', 'Structure', 'Surface Antigens', 'Testing', 'Therapeutic', 'Time', 'Toxin', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Virus', 'X-Ray Crystallography', 'analysis pipeline', 'antibody libraries', 'automated analysis', 'base', 'biothreat', 'computerized tools', 'computing resources', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'novel vaccines', 'open source', 'prevent', 'structural biology', 'tool', 'two-dimensional', 'vaccine development', 'vaccine discovery', 'volcano']",NIAID,UNIVERSITY OF KANSAS LAWRENCE,R21,2019,192392,0.07050063030912707
"Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry PROJECT SUMMARY Determination of the molecular structures of B cell epitopes recognized by protective antibodies provides essential insights to guide rational vaccine design. Obtaining atomically-resolved maps that comprehensively cover the surface of the antigen represents an ideal goal that would provide invaluable information to guide vaccine development. While X-ray crystallography can provide atomically-resolved maps of epitopes, at the present time, it does not have sufficient throughput for deep analysis of the diversity of the antibody repertoire. Hydrogen exchange-mass spectrometry (HX-MS) is emerging as an effective tool for epitope mapping. While promising, the method is limited both by data analysis bottlenecks and limited spatial resolution that prevent it from achieving its full potential for high resolution, high throughput epitope mapping. This collaborative research between Dr. David Weis and Dr. Jeffrey Gray brings together their complementary expertise in HX-MS and protein modelling to produce new software tools to improve the accuracy, resolution, and throughput of HX-MS-based epitope mapping. The outcome will enable epitope-mapping pipelines capable of generating 10-20 atomically-resolved epitopes per week, allowing researchers to more fully define the repertoire of antibody responses to infectious agents and toxins. This research is significant because it will yield new tools to accelerate the rational design and testing of much-needed vaccines to counteract emerging infectious diseases and biothreat agents within NIAID's portfolio. The specific aims of this proposal are to develop new algorithms and software for (1) rapid, fully-automated processing of HX-MS data, (2) fully-automated classification of HX-MS results, and (3) obtaining atomically- resolved epitopes from HX-MS data. The product of the proposed research will be new software tools that implement innovative algorithms. To accomplish Aim #1, algorithms that treat HX-MS data as two-dimensional images and adapt image comparison algorithms to identify and extract the shifted mass spectra will be developed. To accomplish Aim #2, significance testing based on the volcano plot method and classify the results using k-means clustering will be used. To accomplish Aim #3, medium-resolution HX-MS-mapped epitope will be used to constrain computational protein docking between the solved antigen structure and the modeled antibody using the Rosetta protein modeling suite. Through an existing collaboration with Dr. Nicholas Mantis sponsored by NIAID, the team has access to VHHs and an expanding library of solved structures of these VHHs bound to ricin toxin. The solved structures present a unique opportunity to independently refine and validate the epitope mapping pipeline based on solved structures. PROJECT NARRATIVE Vaccines stimulate the immune system to produce antibodies that recognize specific regions called epitopes on bacteria, viruses, and toxins. Information about the molecular structures of these epitopes can provide useful guidance to the development of new vaccines. The proposed research is relevant to public health because it is expected to contribute new tools to determine epitope structures more quickly.",Improved Informatics for Epitope Mapping by Hydrogen Exchange-Mass Spectrometry,9435525,R21AI135701,"['Algorithmic Software', 'Algorithms', 'Amino Acids', 'Antibodies', 'Antibody Diversity', 'Antibody Repertoire', 'Antibody Response', 'Antigens', 'Area', 'B-Lymphocyte Epitopes', 'Bacteria', 'Basic Science', 'Benchmarking', 'Binding', 'Chemistry', 'Classification', 'Collaborations', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnostic Reagent', 'Distal', 'Docking', 'Emerging Communicable Diseases', 'Engineering', 'Epitope Mapping', 'Epitopes', 'Glycoproteins', 'Goals', 'Gray unit of radiation dose', 'Human Resources', 'Hydrogen', 'Image', 'Immune system', 'Immunology', 'Individual', 'Infectious Agent', 'Informatics', 'Length', 'Letters', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Structure', 'National Institute of Allergy and Infectious Disease', 'Outcome', 'Outcomes Research', 'Peptoids', 'Performance', 'Pharmacologic Substance', 'Proteins', 'Public Health', 'Research', 'Research Personnel', 'Resolution', 'Ricin', 'Site', 'Software Tools', 'Structure', 'Surface Antigens', 'Testing', 'Therapeutic', 'Time', 'Toxin', 'Training', 'Update', 'Vaccine Design', 'Vaccines', 'Virus', 'X-Ray Crystallography', 'antibody libraries', 'base', 'biothreat', 'computerized tools', 'computing resources', 'design', 'experimental study', 'improved', 'innovation', 'insight', 'novel vaccines', 'open source', 'prevent', 'structural biology', 'tool', 'two-dimensional', 'vaccine development', 'vaccine discovery', 'volcano']",NIAID,UNIVERSITY OF KANSAS LAWRENCE,R21,2018,243366,0.07050063030912707
"Predictive engineering of cellular transcriptional state PROJECT SUMMARY/ABSTRACT Specific combinations of transcription factors (TFs) exhibit emergent properties when functioning together, enabling the generation of diverse cell types and behaviors. However, identifying which combinations regulate a behavior of interest requires overcoming a combinatorial explosion, as among the ~1,600 TFs in the human genome there are ~1.3 million possible pairs alone. This scaling challenge has forced past efforts at systematically mapping such genetic interactions (GIs) to rely on simple, parallelizable measures of phenotype such as growth rate. Each GI is then characterized only by a single number, obscuring the mechanistic or molecular basis for any particular interaction: put simply, there are many ways for cells to appear equally “unfit.” Finally, many human cell types are quiescent or post-mitotic, so that the growth-based measures of interaction that have been highly successful in model organisms such as yeast do not apply. Here we address these challenges by introducing a new, massively parallel method for studying GIs in human cells that combines rich phenotyping of single cells with an analytical framework for predicting which combinations are most informative to measure. We leverage the recently developed Perturb-seq screening technology, which allows pooled profiling of CRISPR-mediated genetic perturbations with single-cell RNA sequencing as the phenotypic readout. This approach allows us to overexpress many programmed combinations of TFs using CRISPR activation (CRISPRa) and obtain a direct readout of their transcriptional consequences. The resulting rich phenotypes yield insight into the biological origins of GIs, and can for example identify combinations of TFs that promote differentiation to diverse cell states. They also provide a critical “handle” to apply modern machine learning methods. Using techniques from the field of compressed sensing, we propose a predictive approach for searching combinatorial spaces of GIs that would be too large to profile exhaustively by any experimental technology. Since the transcriptome is a direct readout of TF function and TFs interact via specific mechanisms such as cooperative binding at target promoters, these large-scale experiments can also be used to study deeper questions on how GIs emerge mechanistically, and how neomorphic (i.e. entirely new or unpredictable) phenotypes are generated. Our research provides the first scalable method for simultaneously finding and characterizing GIs in any system, a technique for rapidly mapping the “levers” controlling cell fate in diverse models of development and disease, and a model for how machine learning can be used to design the large combinatorial genetics experiments made possible by Cas9. PROJECT NARRATIVE Understanding how genes work together to realize different cellular phenotypes is one of the core problems of genetics. This proposal develops a new experimental and computational approach for mapping the different states that cells can occupy, and for identifying combinations of genes that push cells into these states. This technique will help us understand how complex interactions among genes affect human health and disease.",Predictive engineering of cellular transcriptional state,10001677,DP2GM140925,"['Address', 'Affect', 'Animal Model', 'Behavior', 'Binding', 'Biological', 'Cells', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Complex', 'Disease', 'Exhibits', 'Explosion', 'Gene Combinations', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic study', 'Growth', 'Health', 'Human', 'Human Genome', 'Machine Learning', 'Measures', 'Mediating', 'Methods', 'Mitotic', 'Modeling', 'Modernization', 'Molecular', 'Phenotype', 'Property', 'Research', 'System', 'Techniques', 'Technology', 'Work', 'Yeasts', 'base', 'cell behavior', 'cell type', 'cellular engineering', 'combinatorial', 'design', 'exhaustion', 'experimental study', 'insight', 'interest', 'machine learning method', 'model development', 'overexpression', 'promoter', 'rapid technique', 'screening', 'single-cell RNA sequencing', 'transcription factor', 'transcriptome']",NIGMS,SLOAN-KETTERING INST CAN RESEARCH,DP2,2020,2655000,0.008412369057814707
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,9893208,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human body', 'Image', 'Image Analysis', 'Imagery', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed\xa0imaging', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2019,587413,0.047701197529597374
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,10246250,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Visualization', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed imaging', 'multiscale data', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'three-dimensional visualization', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2020,750000,0.047701197529597374
